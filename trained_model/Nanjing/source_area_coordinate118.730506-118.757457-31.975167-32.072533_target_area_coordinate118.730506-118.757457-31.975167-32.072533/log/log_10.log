2020-11-05 18:44:01,264 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.730506-118.757457-31.975167-32.072533_target_area_coordinate118.730506-118.757457-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], target_enterprise='大众书局')
2020-11-05 18:44:01,264 - root - INFO - --------------parse args and init done.
2020-11-05 18:44:05,622 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 18:44:13,543 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 18:44:13,543 - root - INFO - n_source_grid: 95, n_target_grid: 152
2020-11-05 18:44:13,543 - root - INFO - [3 /10]       split grid done.
2020-11-05 18:44:14,911 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 18:44:14,916 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 18:44:14,998 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 18:44:15,113 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 18:44:15,113 - root - INFO - [8 /10]       combine features done.
2020-11-05 18:44:15,171 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 18:44:15,172 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 18:44:15,204 - root - INFO - --------------load data done.
2020-11-05 18:44:15,207 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 18:44:15,209 - root - INFO - --------------construct model and optimizer done.
2020-11-05 18:44:15,209 - root - INFO - --------------initialize metrics done.
2020-11-05 18:44:15,209 - root - INFO - [!]-----------start training.
2020-11-05 18:44:15,218 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 599.9505 | Iter Mean Loss 599.9505
2020-11-05 18:44:15,226 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 563.8873 | Iter Mean Loss 581.9189
2020-11-05 18:44:15,233 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 584.5262 | Iter Mean Loss 582.7880
2020-11-05 18:44:15,240 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 507.9936 | Iter Mean Loss 564.0894
2020-11-05 18:44:15,248 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 458.8430 | Iter Mean Loss 543.0401
2020-11-05 18:44:15,251 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.6699
2020-11-05 18:44:15,259 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 471.0423 | Iter Mean Loss 471.0423
2020-11-05 18:44:15,266 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 438.9006 | Iter Mean Loss 454.9715
2020-11-05 18:44:15,274 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 467.8340 | Iter Mean Loss 459.2590
2020-11-05 18:44:15,281 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 403.4666 | Iter Mean Loss 445.3109
2020-11-05 18:44:15,288 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 363.2046 | Iter Mean Loss 428.8896
2020-11-05 18:44:15,290 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.6592
2020-11-05 18:44:15,298 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 370.4881 | Iter Mean Loss 370.4881
2020-11-05 18:44:15,306 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 342.5330 | Iter Mean Loss 356.5105
2020-11-05 18:44:15,314 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 377.8442 | Iter Mean Loss 363.6218
2020-11-05 18:44:15,324 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 323.3188 | Iter Mean Loss 353.5460
2020-11-05 18:44:15,331 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 289.7713 | Iter Mean Loss 340.7911
2020-11-05 18:44:15,334 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.6435
2020-11-05 18:44:15,343 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 293.7136 | Iter Mean Loss 293.7136
2020-11-05 18:44:15,351 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 270.0704 | Iter Mean Loss 281.8920
2020-11-05 18:44:15,362 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 310.1771 | Iter Mean Loss 291.3204
2020-11-05 18:44:15,370 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 263.4282 | Iter Mean Loss 284.3473
2020-11-05 18:44:15,379 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 234.8489 | Iter Mean Loss 274.4476
2020-11-05 18:44:15,381 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.6286
2020-11-05 18:44:15,392 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 236.6264 | Iter Mean Loss 236.6264
2020-11-05 18:44:15,400 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 217.0520 | Iter Mean Loss 226.8392
2020-11-05 18:44:15,409 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.5522 | Iter Mean Loss 238.0769
2020-11-05 18:44:15,417 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 219.7862 | Iter Mean Loss 233.5042
2020-11-05 18:44:15,427 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 194.8294 | Iter Mean Loss 225.7692
2020-11-05 18:44:15,429 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.6161
2020-11-05 18:44:15,439 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 195.2402 | Iter Mean Loss 195.2402
2020-11-05 18:44:15,447 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 179.2348 | Iter Mean Loss 187.2375
2020-11-05 18:44:15,458 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 224.8896 | Iter Mean Loss 199.7882
2020-11-05 18:44:15,465 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 188.5862 | Iter Mean Loss 196.9877
2020-11-05 18:44:15,475 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 166.2150 | Iter Mean Loss 190.8331
2020-11-05 18:44:15,477 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6060
2020-11-05 18:44:15,485 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7128 | Iter Mean Loss 165.7128
2020-11-05 18:44:15,495 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 152.6226 | Iter Mean Loss 159.1677
2020-11-05 18:44:15,503 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 199.3787 | Iter Mean Loss 172.5714
2020-11-05 18:44:15,513 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 166.3069 | Iter Mean Loss 171.0053
2020-11-05 18:44:15,522 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 145.7488 | Iter Mean Loss 165.9540
2020-11-05 18:44:15,525 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.5978
2020-11-05 18:44:15,536 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 144.5331 | Iter Mean Loss 144.5331
2020-11-05 18:44:15,547 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 133.6582 | Iter Mean Loss 139.0957
2020-11-05 18:44:15,556 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 180.6999 | Iter Mean Loss 152.9638
2020-11-05 18:44:15,564 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 149.9379 | Iter Mean Loss 152.2073
2020-11-05 18:44:15,575 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 130.6678 | Iter Mean Loss 147.8994
2020-11-05 18:44:15,578 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5912
2020-11-05 18:44:15,587 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 128.7950 | Iter Mean Loss 128.7950
2020-11-05 18:44:15,597 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 119.4939 | Iter Mean Loss 124.1445
2020-11-05 18:44:15,607 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 166.2718 | Iter Mean Loss 138.1869
2020-11-05 18:44:15,614 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 137.1909 | Iter Mean Loss 137.9379
2020-11-05 18:44:15,622 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 118.9059 | Iter Mean Loss 134.1315
2020-11-05 18:44:15,625 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5858
2020-11-05 18:44:15,634 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 116.3777 | Iter Mean Loss 116.3777
2020-11-05 18:44:15,642 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.1299 | Iter Mean Loss 112.2538
2020-11-05 18:44:15,651 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 154.3308 | Iter Mean Loss 126.2795
2020-11-05 18:44:15,659 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 126.5405 | Iter Mean Loss 126.3447
2020-11-05 18:44:15,669 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 109.1168 | Iter Mean Loss 122.8991
2020-11-05 18:44:15,671 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.5813
2020-11-05 18:44:15,682 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 105.9358 | Iter Mean Loss 105.9358
2020-11-05 18:44:15,691 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 98.3574 | Iter Mean Loss 102.1466
2020-11-05 18:44:15,700 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 143.8448 | Iter Mean Loss 116.0460
2020-11-05 18:44:15,709 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 117.1201 | Iter Mean Loss 116.3145
2020-11-05 18:44:15,719 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 100.5567 | Iter Mean Loss 113.1630
2020-11-05 18:44:15,722 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.5768
2020-11-05 18:44:15,732 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 96.7500 | Iter Mean Loss 96.7500
2020-11-05 18:44:15,742 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 89.5796 | Iter Mean Loss 93.1648
2020-11-05 18:44:15,754 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.3275 | Iter Mean Loss 106.8857
2020-11-05 18:44:15,766 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 108.5400 | Iter Mean Loss 107.2993
2020-11-05 18:44:15,775 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 92.8969 | Iter Mean Loss 104.4188
2020-11-05 18:44:15,778 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.5719
2020-11-05 18:44:15,787 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 88.5143 | Iter Mean Loss 88.5143
2020-11-05 18:44:15,796 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 81.5814 | Iter Mean Loss 85.0478
2020-11-05 18:44:15,805 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 125.6180 | Iter Mean Loss 98.5712
2020-11-05 18:44:15,813 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.6804 | Iter Mean Loss 99.0985
2020-11-05 18:44:15,822 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 86.0280 | Iter Mean Loss 96.4844
2020-11-05 18:44:15,824 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.5662
2020-11-05 18:44:15,833 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 81.1286 | Iter Mean Loss 81.1286
2020-11-05 18:44:15,842 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 74.3207 | Iter Mean Loss 77.7246
2020-11-05 18:44:15,850 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 117.6934 | Iter Mean Loss 91.0476
2020-11-05 18:44:15,858 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.5280 | Iter Mean Loss 91.6677
2020-11-05 18:44:15,867 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 79.9200 | Iter Mean Loss 89.3181
2020-11-05 18:44:15,870 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.5598
2020-11-05 18:44:15,879 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.5577 | Iter Mean Loss 74.5577
2020-11-05 18:44:15,888 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 67.7987 | Iter Mean Loss 71.1782
2020-11-05 18:44:15,896 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 110.5582 | Iter Mean Loss 84.3049
2020-11-05 18:44:15,905 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.0850 | Iter Mean Loss 84.9999
2020-11-05 18:44:15,913 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 74.5488 | Iter Mean Loss 82.9097
2020-11-05 18:44:15,916 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.5531
2020-11-05 18:44:15,925 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.7612 | Iter Mean Loss 68.7612
2020-11-05 18:44:15,933 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 61.9997 | Iter Mean Loss 65.3805
2020-11-05 18:44:15,941 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 104.1932 | Iter Mean Loss 78.3180
2020-11-05 18:44:15,950 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.3271 | Iter Mean Loss 79.0703
2020-11-05 18:44:15,958 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 69.8635 | Iter Mean Loss 77.2289
2020-11-05 18:44:15,960 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.5464
2020-11-05 18:44:15,970 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.6676 | Iter Mean Loss 63.6676
2020-11-05 18:44:15,978 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 56.8697 | Iter Mean Loss 60.2687
2020-11-05 18:44:15,987 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 98.5402 | Iter Mean Loss 73.0259
2020-11-05 18:44:15,995 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.1936 | Iter Mean Loss 73.8178
2020-11-05 18:44:16,004 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 65.7818 | Iter Mean Loss 72.2106
2020-11-05 18:44:16,006 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.5403
2020-11-05 18:44:16,015 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.1769 | Iter Mean Loss 59.1769
2020-11-05 18:44:16,024 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 52.3209 | Iter Mean Loss 55.7489
2020-11-05 18:44:16,032 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 93.5118 | Iter Mean Loss 68.3365
2020-11-05 18:44:16,041 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 71.5985 | Iter Mean Loss 69.1520
2020-11-05 18:44:16,050 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 62.2030 | Iter Mean Loss 67.7622
2020-11-05 18:44:16,052 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.5349
2020-11-05 18:44:16,061 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.1791 | Iter Mean Loss 55.1791
2020-11-05 18:44:16,071 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 48.2524 | Iter Mean Loss 51.7158
2020-11-05 18:44:16,079 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 89.0110 | Iter Mean Loss 64.1475
2020-11-05 18:44:16,087 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 67.4521 | Iter Mean Loss 64.9737
2020-11-05 18:44:16,095 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 59.0294 | Iter Mean Loss 63.7848
2020-11-05 18:44:16,098 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.5301
2020-11-05 18:44:16,107 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.5756 | Iter Mean Loss 51.5756
2020-11-05 18:44:16,116 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.5715 | Iter Mean Loss 48.0735
2020-11-05 18:44:16,124 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 84.9521 | Iter Mean Loss 60.3664
2020-11-05 18:44:16,132 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 63.6805 | Iter Mean Loss 61.1949
2020-11-05 18:44:16,141 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 56.1838 | Iter Mean Loss 60.1927
2020-11-05 18:44:16,143 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.5260
2020-11-05 18:44:16,154 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2950 | Iter Mean Loss 48.2950
2020-11-05 18:44:16,163 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2096 | Iter Mean Loss 44.7523
2020-11-05 18:44:16,173 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 81.2730 | Iter Mean Loss 56.9259
2020-11-05 18:44:16,181 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 60.2347 | Iter Mean Loss 57.7531
2020-11-05 18:44:16,191 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 53.6153 | Iter Mean Loss 56.9255
2020-11-05 18:44:16,193 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.5224
2020-11-05 18:44:16,204 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.2965 | Iter Mean Loss 45.2965
2020-11-05 18:44:16,213 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.1255 | Iter Mean Loss 41.7110
2020-11-05 18:44:16,223 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.9367 | Iter Mean Loss 53.7862
2020-11-05 18:44:16,231 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 57.0892 | Iter Mean Loss 54.6120
2020-11-05 18:44:16,241 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 51.2955 | Iter Mean Loss 53.9487
2020-11-05 18:44:16,243 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.5192
2020-11-05 18:44:16,254 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.5641 | Iter Mean Loss 42.5641
2020-11-05 18:44:16,263 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.3007 | Iter Mean Loss 38.9324
2020-11-05 18:44:16,273 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 74.9256 | Iter Mean Loss 50.9301
2020-11-05 18:44:16,282 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 54.2351 | Iter Mean Loss 51.7564
2020-11-05 18:44:16,292 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 49.2126 | Iter Mean Loss 51.2476
2020-11-05 18:44:16,294 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.5164
2020-11-05 18:44:16,305 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.0977 | Iter Mean Loss 40.0977
2020-11-05 18:44:16,315 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 32.7323 | Iter Mean Loss 36.4150
2020-11-05 18:44:16,326 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.2329 | Iter Mean Loss 48.3543
2020-11-05 18:44:16,335 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.6722 | Iter Mean Loss 49.1838
2020-11-05 18:44:16,344 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 47.3629 | Iter Mean Loss 48.8196
2020-11-05 18:44:16,346 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.5139
2020-11-05 18:44:16,355 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.9030 | Iter Mean Loss 37.9030
2020-11-05 18:44:16,362 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 30.4248 | Iter Mean Loss 34.1639
2020-11-05 18:44:16,370 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.8550 | Iter Mean Loss 46.0609
2020-11-05 18:44:16,378 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.4024 | Iter Mean Loss 46.8963
2020-11-05 18:44:16,386 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.7445 | Iter Mean Loss 46.6659
2020-11-05 18:44:16,388 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.5117
2020-11-05 18:44:16,396 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9842 | Iter Mean Loss 35.9842
2020-11-05 18:44:16,404 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.3828 | Iter Mean Loss 32.1835
2020-11-05 18:44:16,412 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.7854 | Iter Mean Loss 44.0508
2020-11-05 18:44:16,420 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.4234 | Iter Mean Loss 44.8940
2020-11-05 18:44:16,428 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 44.3515 | Iter Mean Loss 44.7855
2020-11-05 18:44:16,430 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.5098
2020-11-05 18:44:16,438 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.3389 | Iter Mean Loss 34.3389
2020-11-05 18:44:16,446 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.6056 | Iter Mean Loss 30.4722
2020-11-05 18:44:16,453 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0123 | Iter Mean Loss 42.3189
2020-11-05 18:44:16,461 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.7268 | Iter Mean Loss 43.1709
2020-11-05 18:44:16,469 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 43.1727 | Iter Mean Loss 43.1712
2020-11-05 18:44:16,471 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.5081
2020-11-05 18:44:16,479 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.9560 | Iter Mean Loss 32.9560
2020-11-05 18:44:16,487 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.0850 | Iter Mean Loss 29.0205
2020-11-05 18:44:16,494 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.5169 | Iter Mean Loss 40.8526
2020-11-05 18:44:16,502 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.2964 | Iter Mean Loss 41.7136
2020-11-05 18:44:16,510 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 42.1911 | Iter Mean Loss 41.8091
2020-11-05 18:44:16,512 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.5066
2020-11-05 18:44:16,520 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.8164 | Iter Mean Loss 31.8164
2020-11-05 18:44:16,528 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.8048 | Iter Mean Loss 27.8106
2020-11-05 18:44:16,536 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2742 | Iter Mean Loss 39.6318
2020-11-05 18:44:16,544 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.1094 | Iter Mean Loss 40.5012
2020-11-05 18:44:16,554 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 41.3853 | Iter Mean Loss 40.6780
2020-11-05 18:44:16,556 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.5052
2020-11-05 18:44:16,566 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.8940 | Iter Mean Loss 30.8940
2020-11-05 18:44:16,575 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7426 | Iter Mean Loss 26.8183
2020-11-05 18:44:16,585 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.2539 | Iter Mean Loss 38.6302
2020-11-05 18:44:16,596 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1375 | Iter Mean Loss 39.5070
2020-11-05 18:44:16,604 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.7305 | Iter Mean Loss 39.7517
2020-11-05 18:44:16,607 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.5041
2020-11-05 18:44:16,616 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1582 | Iter Mean Loss 30.1582
2020-11-05 18:44:16,623 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.8714 | Iter Mean Loss 26.0148
2020-11-05 18:44:16,631 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.4230 | Iter Mean Loss 37.8175
2020-11-05 18:44:16,638 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3496 | Iter Mean Loss 38.7006
2020-11-05 18:44:16,646 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.2007 | Iter Mean Loss 39.0006
2020-11-05 18:44:16,648 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.2817 | MSE 0.5031
2020-11-05 18:44:16,656 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.5766 | Iter Mean Loss 29.5766
2020-11-05 18:44:16,663 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.1624 | Iter Mean Loss 25.3695
2020-11-05 18:44:16,671 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.7478 | Iter Mean Loss 37.1623
2020-11-05 18:44:16,678 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.7138 | Iter Mean Loss 38.0501
2020-11-05 18:44:16,686 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.7704 | Iter Mean Loss 38.3942
2020-11-05 18:44:16,688 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.2817 | MSE 0.5022
2020-11-05 18:44:16,696 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.1174 | Iter Mean Loss 29.1174
2020-11-05 18:44:16,703 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5868 | Iter Mean Loss 24.8521
2020-11-05 18:44:16,711 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.1961 | Iter Mean Loss 36.6334
2020-11-05 18:44:16,719 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1997 | Iter Mean Loss 37.5250
2020-11-05 18:44:16,728 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.4166 | Iter Mean Loss 37.9033
2020-11-05 18:44:16,731 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.2817 | MSE 0.5015
2020-11-05 18:44:16,740 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.7520 | Iter Mean Loss 28.7520
2020-11-05 18:44:16,748 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1178 | Iter Mean Loss 24.4349
2020-11-05 18:44:16,756 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.7387 | Iter Mean Loss 36.2028
2020-11-05 18:44:16,763 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7799 | Iter Mean Loss 37.0971
2020-11-05 18:44:16,771 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.1192 | Iter Mean Loss 37.5015
2020-11-05 18:44:16,773 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.2817 | MSE 0.5009
2020-11-05 18:44:16,781 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4556 | Iter Mean Loss 28.4556
2020-11-05 18:44:16,789 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7321 | Iter Mean Loss 24.0938
2020-11-05 18:44:16,796 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3507 | Iter Mean Loss 35.8461
2020-11-05 18:44:16,804 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4309 | Iter Mean Loss 36.7423
2020-11-05 18:44:16,811 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.8614 | Iter Mean Loss 37.1661
2020-11-05 18:44:16,813 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.2817 | MSE 0.5003
2020-11-05 18:44:16,821 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2086 | Iter Mean Loss 28.2086
2020-11-05 18:44:16,830 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.4101 | Iter Mean Loss 23.8093
2020-11-05 18:44:16,837 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0119 | Iter Mean Loss 35.5435
2020-11-05 18:44:16,845 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1339 | Iter Mean Loss 36.4411
2020-11-05 18:44:16,852 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.6306 | Iter Mean Loss 36.8790
2020-11-05 18:44:16,854 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.2817 | MSE 0.4999
2020-11-05 18:44:16,862 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.9961 | Iter Mean Loss 27.9961
2020-11-05 18:44:16,870 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1364 | Iter Mean Loss 23.5663
2020-11-05 18:44:16,877 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7064 | Iter Mean Loss 35.2796
2020-11-05 18:44:16,885 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8739 | Iter Mean Loss 36.1782
2020-11-05 18:44:16,892 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.4172 | Iter Mean Loss 36.6260
2020-11-05 18:44:16,894 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.2817 | MSE 0.4996
2020-11-05 18:44:16,902 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8074 | Iter Mean Loss 27.8074
2020-11-05 18:44:16,910 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8993 | Iter Mean Loss 23.3534
2020-11-05 18:44:16,917 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.4225 | Iter Mean Loss 35.0431
2020-11-05 18:44:16,924 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6401 | Iter Mean Loss 35.9423
2020-11-05 18:44:16,932 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.2145 | Iter Mean Loss 36.3967
2020-11-05 18:44:16,934 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.2817 | MSE 0.4993
2020-11-05 18:44:16,942 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.6351 | Iter Mean Loss 27.6351
2020-11-05 18:44:16,950 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6900 | Iter Mean Loss 23.1625
2020-11-05 18:44:16,958 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.1517 | Iter Mean Loss 34.8256
2020-11-05 18:44:16,965 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.4241 | Iter Mean Loss 35.7252
2020-11-05 18:44:16,972 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.0179 | Iter Mean Loss 36.1837
2020-11-05 18:44:16,974 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.2817 | MSE 0.4991
2020-11-05 18:44:16,982 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.4741 | Iter Mean Loss 27.4741
2020-11-05 18:44:16,990 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.5017 | Iter Mean Loss 22.9879
2020-11-05 18:44:16,997 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.8881 | Iter Mean Loss 34.6213
2020-11-05 18:44:17,005 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2203 | Iter Mean Loss 35.5210
2020-11-05 18:44:17,012 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.8245 | Iter Mean Loss 35.9817
2020-11-05 18:44:17,014 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.2817 | MSE 0.4989
2020-11-05 18:44:17,023 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3210 | Iter Mean Loss 27.3210
2020-11-05 18:44:17,032 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3295 | Iter Mean Loss 22.8252
2020-11-05 18:44:17,040 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.6279 | Iter Mean Loss 34.4261
2020-11-05 18:44:17,047 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0246 | Iter Mean Loss 35.3257
2020-11-05 18:44:17,056 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.6324 | Iter Mean Loss 35.7871
2020-11-05 18:44:17,060 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.2817 | MSE 0.4988
2020-11-05 18:44:17,072 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.1733 | Iter Mean Loss 27.1733
2020-11-05 18:44:17,082 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.1695 | Iter Mean Loss 22.6714
2020-11-05 18:44:17,092 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3683 | Iter Mean Loss 34.2370
2020-11-05 18:44:17,104 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8340 | Iter Mean Loss 35.1363
2020-11-05 18:44:17,116 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.4404 | Iter Mean Loss 35.5971
2020-11-05 18:44:17,119 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.2817 | MSE 0.4987
2020-11-05 18:44:17,130 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0294 | Iter Mean Loss 27.0294
2020-11-05 18:44:17,139 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0186 | Iter Mean Loss 22.5240
2020-11-05 18:44:17,149 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.1077 | Iter Mean Loss 34.0519
2020-11-05 18:44:17,157 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.6466 | Iter Mean Loss 34.9506
2020-11-05 18:44:17,165 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.2477 | Iter Mean Loss 35.4100
2020-11-05 18:44:17,167 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.2817 | MSE 0.4986
2020-11-05 18:44:17,175 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.8878 | Iter Mean Loss 26.8878
2020-11-05 18:44:17,183 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.8743 | Iter Mean Loss 22.3811
2020-11-05 18:44:17,193 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.8452 | Iter Mean Loss 33.8691
2020-11-05 18:44:17,203 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.4607 | Iter Mean Loss 34.7670
2020-11-05 18:44:17,212 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.0539 | Iter Mean Loss 35.2244
2020-11-05 18:44:17,215 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.2817 | MSE 0.4986
2020-11-05 18:44:17,224 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7473 | Iter Mean Loss 26.7473
2020-11-05 18:44:17,233 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7345 | Iter Mean Loss 22.2409
2020-11-05 18:44:17,240 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.5801 | Iter Mean Loss 33.6873
2020-11-05 18:44:17,248 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2753 | Iter Mean Loss 34.5843
2020-11-05 18:44:17,255 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.8584 | Iter Mean Loss 35.0391
2020-11-05 18:44:17,257 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:44:17,265 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6069 | Iter Mean Loss 26.6069
2020-11-05 18:44:17,273 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5973 | Iter Mean Loss 22.1021
2020-11-05 18:44:17,282 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.3121 | Iter Mean Loss 33.5054
2020-11-05 18:44:17,289 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0895 | Iter Mean Loss 34.4015
2020-11-05 18:44:17,297 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6610 | Iter Mean Loss 34.8534
2020-11-05 18:44:17,299 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:44:17,308 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.4657 | Iter Mean Loss 26.4657
2020-11-05 18:44:17,320 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4612 | Iter Mean Loss 21.9635
2020-11-05 18:44:17,329 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.0410 | Iter Mean Loss 33.3226
2020-11-05 18:44:17,337 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.9027 | Iter Mean Loss 34.2176
2020-11-05 18:44:17,346 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.4613 | Iter Mean Loss 34.6664
2020-11-05 18:44:17,349 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:44:17,358 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3228 | Iter Mean Loss 26.3228
2020-11-05 18:44:17,368 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.3249 | Iter Mean Loss 21.8239
2020-11-05 18:44:17,376 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.7666 | Iter Mean Loss 33.1381
2020-11-05 18:44:17,385 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.7143 | Iter Mean Loss 34.0322
2020-11-05 18:44:17,394 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.2590 | Iter Mean Loss 34.4775
2020-11-05 18:44:17,397 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:44:17,406 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1776 | Iter Mean Loss 26.1776
2020-11-05 18:44:17,415 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.1874 | Iter Mean Loss 21.6825
2020-11-05 18:44:17,423 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.4889 | Iter Mean Loss 32.9513
2020-11-05 18:44:17,431 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.5238 | Iter Mean Loss 33.8444
2020-11-05 18:44:17,440 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.0538 | Iter Mean Loss 34.2863
2020-11-05 18:44:17,442 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:44:17,452 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.0292 | Iter Mean Loss 26.0292
2020-11-05 18:44:17,460 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0477 | Iter Mean Loss 21.5385
2020-11-05 18:44:17,469 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.2077 | Iter Mean Loss 32.7616
2020-11-05 18:44:17,477 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.3308 | Iter Mean Loss 33.6539
2020-11-05 18:44:17,487 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.8454 | Iter Mean Loss 34.0922
2020-11-05 18:44:17,489 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,498 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8773 | Iter Mean Loss 25.8773
2020-11-05 18:44:17,507 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.9051 | Iter Mean Loss 21.3912
2020-11-05 18:44:17,515 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.9228 | Iter Mean Loss 32.5684
2020-11-05 18:44:17,523 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.1349 | Iter Mean Loss 33.4600
2020-11-05 18:44:17,531 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.6332 | Iter Mean Loss 33.8947
2020-11-05 18:44:17,534 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,543 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7211 | Iter Mean Loss 25.7211
2020-11-05 18:44:17,552 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7588 | Iter Mean Loss 21.2400
2020-11-05 18:44:17,561 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.6339 | Iter Mean Loss 32.3713
2020-11-05 18:44:17,570 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.9358 | Iter Mean Loss 33.2624
2020-11-05 18:44:17,578 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.4170 | Iter Mean Loss 33.6933
2020-11-05 18:44:17,581 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,591 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.5602 | Iter Mean Loss 25.5602
2020-11-05 18:44:17,599 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.6084 | Iter Mean Loss 21.0843
2020-11-05 18:44:17,609 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.3408 | Iter Mean Loss 32.1698
2020-11-05 18:44:17,617 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.7330 | Iter Mean Loss 33.0606
2020-11-05 18:44:17,625 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.1963 | Iter Mean Loss 33.4877
2020-11-05 18:44:17,628 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,637 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3942 | Iter Mean Loss 25.3942
2020-11-05 18:44:17,645 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.4533 | Iter Mean Loss 20.9238
2020-11-05 18:44:17,654 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0431 | Iter Mean Loss 31.9635
2020-11-05 18:44:17,662 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.5263 | Iter Mean Loss 32.8542
2020-11-05 18:44:17,671 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.9707 | Iter Mean Loss 33.2775
2020-11-05 18:44:17,673 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,682 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2227 | Iter Mean Loss 25.2227
2020-11-05 18:44:17,691 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.2930 | Iter Mean Loss 20.7579
2020-11-05 18:44:17,698 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.7405 | Iter Mean Loss 31.7521
2020-11-05 18:44:17,707 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.3152 | Iter Mean Loss 32.6429
2020-11-05 18:44:17,715 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.7399 | Iter Mean Loss 33.0623
2020-11-05 18:44:17,719 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,727 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0453 | Iter Mean Loss 25.0453
2020-11-05 18:44:17,736 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1273 | Iter Mean Loss 20.5863
2020-11-05 18:44:17,744 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.4327 | Iter Mean Loss 31.5351
2020-11-05 18:44:17,753 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0995 | Iter Mean Loss 32.4262
2020-11-05 18:44:17,761 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.5034 | Iter Mean Loss 32.8417
2020-11-05 18:44:17,763 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,774 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8616 | Iter Mean Loss 24.8616
2020-11-05 18:44:17,782 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9557 | Iter Mean Loss 20.4086
2020-11-05 18:44:17,791 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.1193 | Iter Mean Loss 31.3122
2020-11-05 18:44:17,798 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.8789 | Iter Mean Loss 32.2039
2020-11-05 18:44:17,807 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.2609 | Iter Mean Loss 32.6153
2020-11-05 18:44:17,810 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,819 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6712 | Iter Mean Loss 24.6712
2020-11-05 18:44:17,828 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.7779 | Iter Mean Loss 20.2245
2020-11-05 18:44:17,837 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.7999 | Iter Mean Loss 31.0830
2020-11-05 18:44:17,845 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.6530 | Iter Mean Loss 31.9755
2020-11-05 18:44:17,854 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.0120 | Iter Mean Loss 32.3828
2020-11-05 18:44:17,856 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,864 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4738 | Iter Mean Loss 24.4738
2020-11-05 18:44:17,873 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.5936 | Iter Mean Loss 20.0337
2020-11-05 18:44:17,881 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.4743 | Iter Mean Loss 30.8472
2020-11-05 18:44:17,890 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.4216 | Iter Mean Loss 31.7408
2020-11-05 18:44:17,898 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.7564 | Iter Mean Loss 32.1439
2020-11-05 18:44:17,901 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:44:17,910 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2691 | Iter Mean Loss 24.2691
2020-11-05 18:44:17,918 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4025 | Iter Mean Loss 19.8358
2020-11-05 18:44:17,927 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.1423 | Iter Mean Loss 30.6046
2020-11-05 18:44:17,936 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1844 | Iter Mean Loss 31.4996
2020-11-05 18:44:17,945 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.4938 | Iter Mean Loss 31.8984
2020-11-05 18:44:17,947 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:17,956 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0568 | Iter Mean Loss 24.0568
2020-11-05 18:44:17,964 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2046 | Iter Mean Loss 19.6307
2020-11-05 18:44:17,973 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.8035 | Iter Mean Loss 30.3549
2020-11-05 18:44:17,981 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.9413 | Iter Mean Loss 31.2515
2020-11-05 18:44:17,990 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.2241 | Iter Mean Loss 31.6460
2020-11-05 18:44:17,992 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,001 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8366 | Iter Mean Loss 23.8366
2020-11-05 18:44:18,010 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.9995 | Iter Mean Loss 19.4181
2020-11-05 18:44:18,019 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.4578 | Iter Mean Loss 30.0980
2020-11-05 18:44:18,027 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6920 | Iter Mean Loss 30.9965
2020-11-05 18:44:18,036 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9471 | Iter Mean Loss 31.3866
2020-11-05 18:44:18,039 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,047 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6084 | Iter Mean Loss 23.6084
2020-11-05 18:44:18,057 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7872 | Iter Mean Loss 19.1978
2020-11-05 18:44:18,064 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1051 | Iter Mean Loss 29.8336
2020-11-05 18:44:18,073 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4366 | Iter Mean Loss 30.7343
2020-11-05 18:44:18,081 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.6626 | Iter Mean Loss 31.1200
2020-11-05 18:44:18,084 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,093 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3720 | Iter Mean Loss 23.3720
2020-11-05 18:44:18,102 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5678 | Iter Mean Loss 18.9699
2020-11-05 18:44:18,111 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7455 | Iter Mean Loss 29.5618
2020-11-05 18:44:18,119 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1749 | Iter Mean Loss 30.4650
2020-11-05 18:44:18,128 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.3708 | Iter Mean Loss 30.8462
2020-11-05 18:44:18,130 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,139 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1274 | Iter Mean Loss 23.1274
2020-11-05 18:44:18,147 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.3412 | Iter Mean Loss 18.7343
2020-11-05 18:44:18,156 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3788 | Iter Mean Loss 29.2825
2020-11-05 18:44:18,164 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9071 | Iter Mean Loss 30.1886
2020-11-05 18:44:18,173 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.0718 | Iter Mean Loss 30.5653
2020-11-05 18:44:18,176 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,185 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8747 | Iter Mean Loss 22.8747
2020-11-05 18:44:18,194 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.1076 | Iter Mean Loss 18.4912
2020-11-05 18:44:18,202 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.0055 | Iter Mean Loss 28.9959
2020-11-05 18:44:18,210 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6333 | Iter Mean Loss 29.9053
2020-11-05 18:44:18,219 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.7657 | Iter Mean Loss 30.2774
2020-11-05 18:44:18,222 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,230 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6140 | Iter Mean Loss 22.6140
2020-11-05 18:44:18,240 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.8674 | Iter Mean Loss 18.2407
2020-11-05 18:44:18,248 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.6256 | Iter Mean Loss 28.7023
2020-11-05 18:44:18,257 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.3538 | Iter Mean Loss 29.6152
2020-11-05 18:44:18,265 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.4529 | Iter Mean Loss 29.9827
2020-11-05 18:44:18,269 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,278 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3457 | Iter Mean Loss 22.3457
2020-11-05 18:44:18,287 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.6209 | Iter Mean Loss 17.9833
2020-11-05 18:44:18,296 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.2396 | Iter Mean Loss 28.4020
2020-11-05 18:44:18,305 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.0689 | Iter Mean Loss 29.3188
2020-11-05 18:44:18,313 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.1339 | Iter Mean Loss 29.6818
2020-11-05 18:44:18,316 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:44:18,327 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0700 | Iter Mean Loss 22.0700
2020-11-05 18:44:18,335 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.3688 | Iter Mean Loss 17.7194
2020-11-05 18:44:18,343 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.8480 | Iter Mean Loss 28.0956
2020-11-05 18:44:18,351 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7791 | Iter Mean Loss 29.0165
2020-11-05 18:44:18,358 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 29.3751
2020-11-05 18:44:18,360 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:44:18,368 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7878 | Iter Mean Loss 21.7878
2020-11-05 18:44:18,375 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.1117 | Iter Mean Loss 17.4497
2020-11-05 18:44:18,382 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.4515 | Iter Mean Loss 27.7837
2020-11-05 18:44:18,390 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.4851 | Iter Mean Loss 28.7090
2020-11-05 18:44:18,397 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.4802 | Iter Mean Loss 29.0633
2020-11-05 18:44:18,399 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:44:18,407 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4996 | Iter Mean Loss 21.4996
2020-11-05 18:44:18,417 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.8505 | Iter Mean Loss 17.1750
2020-11-05 18:44:18,429 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.0509 | Iter Mean Loss 27.4670
2020-11-05 18:44:18,440 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.1877 | Iter Mean Loss 28.3972
2020-11-05 18:44:18,449 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.1473 | Iter Mean Loss 28.7472
2020-11-05 18:44:18,453 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:44:18,466 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2065 | Iter Mean Loss 21.2065
2020-11-05 18:44:18,476 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5862 | Iter Mean Loss 16.8963
2020-11-05 18:44:18,487 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.6471 | Iter Mean Loss 27.1466
2020-11-05 18:44:18,499 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8876 | Iter Mean Loss 28.0818
2020-11-05 18:44:18,509 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.8117 | Iter Mean Loss 28.4278
2020-11-05 18:44:18,511 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:44:18,522 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9094 | Iter Mean Loss 20.9094
2020-11-05 18:44:18,531 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.3201 | Iter Mean Loss 16.6147
2020-11-05 18:44:18,541 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.2411 | Iter Mean Loss 26.8235
2020-11-05 18:44:18,551 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5859 | Iter Mean Loss 27.7641
2020-11-05 18:44:18,561 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4748 | Iter Mean Loss 28.1063
2020-11-05 18:44:18,564 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.2817 | MSE 0.4981
2020-11-05 18:44:18,574 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6096 | Iter Mean Loss 20.6096
2020-11-05 18:44:18,585 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.0533 | Iter Mean Loss 16.3314
2020-11-05 18:44:18,595 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.8343 | Iter Mean Loss 26.4990
2020-11-05 18:44:18,604 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.2837 | Iter Mean Loss 27.4452
2020-11-05 18:44:18,614 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.1379 | Iter Mean Loss 27.7837
2020-11-05 18:44:18,618 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.2817 | MSE 0.4981
2020-11-05 18:44:18,628 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3084 | Iter Mean Loss 20.3084
2020-11-05 18:44:18,637 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7873 | Iter Mean Loss 16.0478
2020-11-05 18:44:18,646 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.4277 | Iter Mean Loss 26.1744
2020-11-05 18:44:18,655 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9821 | Iter Mean Loss 27.1264
2020-11-05 18:44:18,663 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.8025 | Iter Mean Loss 27.4616
2020-11-05 18:44:18,666 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.2817 | MSE 0.4980
2020-11-05 18:44:18,675 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0072 | Iter Mean Loss 20.0072
2020-11-05 18:44:18,684 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.5235 | Iter Mean Loss 15.7653
2020-11-05 18:44:18,693 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.0226 | Iter Mean Loss 25.8511
2020-11-05 18:44:18,701 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6824 | Iter Mean Loss 26.8089
2020-11-05 18:44:18,710 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.4702 | Iter Mean Loss 27.1412
2020-11-05 18:44:18,712 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.2817 | MSE 0.4980
2020-11-05 18:44:18,722 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7075 | Iter Mean Loss 19.7075
2020-11-05 18:44:18,731 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2634 | Iter Mean Loss 15.4854
2020-11-05 18:44:18,740 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.6204 | Iter Mean Loss 25.5304
2020-11-05 18:44:18,748 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.3856 | Iter Mean Loss 26.4942
2020-11-05 18:44:18,757 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.1424 | Iter Mean Loss 26.8239
2020-11-05 18:44:18,760 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.2817 | MSE 0.4979
2020-11-05 18:44:18,768 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4107 | Iter Mean Loss 19.4107
2020-11-05 18:44:18,778 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.0085 | Iter Mean Loss 15.2096
2020-11-05 18:44:18,787 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.2223 | Iter Mean Loss 25.2138
2020-11-05 18:44:18,795 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0930 | Iter Mean Loss 26.1836
2020-11-05 18:44:18,805 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.8205 | Iter Mean Loss 26.5110
2020-11-05 18:44:18,807 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.2817 | MSE 0.4978
2020-11-05 18:44:18,816 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1182 | Iter Mean Loss 19.1182
2020-11-05 18:44:18,825 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7601 | Iter Mean Loss 14.9391
2020-11-05 18:44:18,833 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.8294 | Iter Mean Loss 24.9026
2020-11-05 18:44:18,844 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8055 | Iter Mean Loss 25.8783
2020-11-05 18:44:18,852 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.5060 | Iter Mean Loss 26.2038
2020-11-05 18:44:18,855 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.2817 | MSE 0.4978
2020-11-05 18:44:18,863 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8312 | Iter Mean Loss 18.8312
2020-11-05 18:44:18,871 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5194 | Iter Mean Loss 14.6753
2020-11-05 18:44:18,878 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.4427 | Iter Mean Loss 24.5978
2020-11-05 18:44:18,885 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.5241 | Iter Mean Loss 25.5794
2020-11-05 18:44:18,892 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.1998 | Iter Mean Loss 25.9034
2020-11-05 18:44:18,894 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.2817 | MSE 0.4977
2020-11-05 18:44:18,902 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5509 | Iter Mean Loss 18.5509
2020-11-05 18:44:18,909 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.2874 | Iter Mean Loss 14.4192
2020-11-05 18:44:18,917 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0630 | Iter Mean Loss 24.3004
2020-11-05 18:44:18,924 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.2495 | Iter Mean Loss 25.2877
2020-11-05 18:44:18,931 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.9029 | Iter Mean Loss 25.6107
2020-11-05 18:44:18,934 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.2817 | MSE 0.4975
2020-11-05 18:44:18,942 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2782 | Iter Mean Loss 18.2782
2020-11-05 18:44:18,949 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0649 | Iter Mean Loss 14.1715
2020-11-05 18:44:18,957 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6909 | Iter Mean Loss 24.0113
2020-11-05 18:44:18,964 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9822 | Iter Mean Loss 25.0040
2020-11-05 18:44:18,971 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.6160 | Iter Mean Loss 25.3264
2020-11-05 18:44:18,973 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.2817 | MSE 0.4974
2020-11-05 18:44:18,981 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0136 | Iter Mean Loss 18.0136
2020-11-05 18:44:18,988 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8524 | Iter Mean Loss 13.9330
2020-11-05 18:44:18,995 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3267 | Iter Mean Loss 23.7309
2020-11-05 18:44:19,003 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7225 | Iter Mean Loss 24.7288
2020-11-05 18:44:19,010 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.3393 | Iter Mean Loss 25.0509
2020-11-05 18:44:19,012 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.2817 | MSE 0.4972
2020-11-05 18:44:19,020 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7576 | Iter Mean Loss 17.7576
2020-11-05 18:44:19,027 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6501 | Iter Mean Loss 13.7039
2020-11-05 18:44:19,035 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.9706 | Iter Mean Loss 23.4594
2020-11-05 18:44:19,042 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.4706 | Iter Mean Loss 24.4622
2020-11-05 18:44:19,050 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.0730 | Iter Mean Loss 24.7844
2020-11-05 18:44:19,052 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.2817 | MSE 0.4971
2020-11-05 18:44:19,059 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5104 | Iter Mean Loss 17.5104
2020-11-05 18:44:19,067 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4581 | Iter Mean Loss 13.4843
2020-11-05 18:44:19,074 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6225 | Iter Mean Loss 23.1970
2020-11-05 18:44:19,081 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.2264 | Iter Mean Loss 24.2044
2020-11-05 18:44:19,089 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.8169 | Iter Mean Loss 24.5269
2020-11-05 18:44:19,090 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.2817 | MSE 0.4969
2020-11-05 18:44:19,098 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2718 | Iter Mean Loss 17.2718
2020-11-05 18:44:19,106 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2762 | Iter Mean Loss 13.2740
2020-11-05 18:44:19,113 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.2822 | Iter Mean Loss 22.9434
2020-11-05 18:44:19,120 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9895 | Iter Mean Loss 23.9549
2020-11-05 18:44:19,127 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.5706 | Iter Mean Loss 24.2781
2020-11-05 18:44:19,129 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.2817 | MSE 0.4966
2020-11-05 18:44:19,137 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0416 | Iter Mean Loss 17.0416
2020-11-05 18:44:19,144 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.1037 | Iter Mean Loss 13.0727
2020-11-05 18:44:19,152 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.9491 | Iter Mean Loss 22.6982
2020-11-05 18:44:19,159 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7597 | Iter Mean Loss 23.7136
2020-11-05 18:44:19,166 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.3335 | Iter Mean Loss 24.0375
2020-11-05 18:44:19,168 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.2817 | MSE 0.4964
2020-11-05 18:44:19,176 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8193 | Iter Mean Loss 16.8193
2020-11-05 18:44:19,183 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.9402 | Iter Mean Loss 12.8798
2020-11-05 18:44:19,190 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.6228 | Iter Mean Loss 22.4608
2020-11-05 18:44:19,198 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.5364 | Iter Mean Loss 23.4797
2020-11-05 18:44:19,205 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.1048 | Iter Mean Loss 23.8047
2020-11-05 18:44:19,207 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.2817 | MSE 0.4961
2020-11-05 18:44:19,215 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6043 | Iter Mean Loss 16.6043
2020-11-05 18:44:19,222 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.7848 | Iter Mean Loss 12.6946
2020-11-05 18:44:19,229 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3025 | Iter Mean Loss 22.2305
2020-11-05 18:44:19,237 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.3189 | Iter Mean Loss 23.2526
2020-11-05 18:44:19,244 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.8837 | Iter Mean Loss 23.5788
2020-11-05 18:44:19,246 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.2817 | MSE 0.4958
2020-11-05 18:44:19,254 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3959 | Iter Mean Loss 16.3959
2020-11-05 18:44:19,261 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 12.5163
2020-11-05 18:44:19,269 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.9874 | Iter Mean Loss 22.0067
2020-11-05 18:44:19,276 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.1066 | Iter Mean Loss 23.0316
2020-11-05 18:44:19,283 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.6691 | Iter Mean Loss 23.3591
2020-11-05 18:44:19,285 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.2817 | MSE 0.4955
2020-11-05 18:44:19,293 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1933 | Iter Mean Loss 16.1933
2020-11-05 18:44:19,300 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 12.3441
2020-11-05 18:44:19,307 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.6769 | Iter Mean Loss 21.7883
2020-11-05 18:44:19,315 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8988 | Iter Mean Loss 22.8159
2020-11-05 18:44:19,324 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.4602 | Iter Mean Loss 23.1448
2020-11-05 18:44:19,326 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.2817 | MSE 0.4952
2020-11-05 18:44:19,335 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9957 | Iter Mean Loss 15.9957
2020-11-05 18:44:19,344 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3584 | Iter Mean Loss 12.1771
2020-11-05 18:44:19,352 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.3700 | Iter Mean Loss 21.5747
2020-11-05 18:44:19,361 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6948 | Iter Mean Loss 22.6047
2020-11-05 18:44:19,369 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.2559 | Iter Mean Loss 22.9350
2020-11-05 18:44:19,372 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.2817 | MSE 0.4948
2020-11-05 18:44:19,381 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8024 | Iter Mean Loss 15.8024
2020-11-05 18:44:19,390 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 12.0144
2020-11-05 18:44:19,398 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.0662 | Iter Mean Loss 21.3650
2020-11-05 18:44:19,407 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4940 | Iter Mean Loss 22.3973
2020-11-05 18:44:19,415 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.0553 | Iter Mean Loss 22.7289
2020-11-05 18:44:19,417 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.2817 | MSE 0.4944
2020-11-05 18:44:19,427 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6127 | Iter Mean Loss 15.6127
2020-11-05 18:44:19,436 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.0982 | Iter Mean Loss 11.8555
2020-11-05 18:44:19,445 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.7648 | Iter Mean Loss 21.1586
2020-11-05 18:44:19,452 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2957 | Iter Mean Loss 22.1929
2020-11-05 18:44:19,462 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.8577 | Iter Mean Loss 22.5259
2020-11-05 18:44:19,464 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.2817 | MSE 0.4940
2020-11-05 18:44:19,473 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4260 | Iter Mean Loss 15.4260
2020-11-05 18:44:19,481 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9730 | Iter Mean Loss 11.6995
2020-11-05 18:44:19,490 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.4652 | Iter Mean Loss 20.9547
2020-11-05 18:44:19,498 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0996 | Iter Mean Loss 21.9909
2020-11-05 18:44:19,507 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.6624 | Iter Mean Loss 22.3252
2020-11-05 18:44:19,509 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.2817 | MSE 0.4936
2020-11-05 18:44:19,518 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2417 | Iter Mean Loss 15.2417
2020-11-05 18:44:19,528 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.8501 | Iter Mean Loss 11.5459
2020-11-05 18:44:19,536 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.1670 | Iter Mean Loss 20.7529
2020-11-05 18:44:19,544 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.9051 | Iter Mean Loss 21.7910
2020-11-05 18:44:19,552 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.4687 | Iter Mean Loss 22.1265
2020-11-05 18:44:19,554 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.2817 | MSE 0.4932
2020-11-05 18:44:19,564 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0594 | Iter Mean Loss 15.0594
2020-11-05 18:44:19,573 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7290 | Iter Mean Loss 11.3942
2020-11-05 18:44:19,581 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.8697 | Iter Mean Loss 20.5527
2020-11-05 18:44:19,591 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7120 | Iter Mean Loss 21.5925
2020-11-05 18:44:19,599 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.2761 | Iter Mean Loss 21.9292
2020-11-05 18:44:19,601 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.2817 | MSE 0.4927
2020-11-05 18:44:19,610 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8789 | Iter Mean Loss 14.8789
2020-11-05 18:44:19,618 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 11.2441
2020-11-05 18:44:19,628 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.5732 | Iter Mean Loss 20.3538
2020-11-05 18:44:19,636 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5200 | Iter Mean Loss 21.3953
2020-11-05 18:44:19,645 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.0843 | Iter Mean Loss 21.7331
2020-11-05 18:44:19,647 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.2817 | MSE 0.4922
2020-11-05 18:44:19,656 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6999 | Iter Mean Loss 14.6999
2020-11-05 18:44:19,664 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4908 | Iter Mean Loss 11.0953
2020-11-05 18:44:19,674 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.2772 | Iter Mean Loss 20.1560
2020-11-05 18:44:19,682 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3290 | Iter Mean Loss 21.1992
2020-11-05 18:44:19,691 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.8930 | Iter Mean Loss 21.5380
2020-11-05 18:44:19,693 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.2817 | MSE 0.4917
2020-11-05 18:44:19,702 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5223 | Iter Mean Loss 14.5223
2020-11-05 18:44:19,711 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.3731 | Iter Mean Loss 10.9477
2020-11-05 18:44:19,719 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.9818 | Iter Mean Loss 19.9591
2020-11-05 18:44:19,728 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1389 | Iter Mean Loss 21.0040
2020-11-05 18:44:19,737 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.7019 | Iter Mean Loss 21.3436
2020-11-05 18:44:19,740 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.2817 | MSE 0.4912
2020-11-05 18:44:19,748 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3462 | Iter Mean Loss 14.3462
2020-11-05 18:44:19,757 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2563 | Iter Mean Loss 10.8012
2020-11-05 18:44:19,765 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.6868 | Iter Mean Loss 19.7631
2020-11-05 18:44:19,774 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9496 | Iter Mean Loss 20.8097
2020-11-05 18:44:19,782 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.5111 | Iter Mean Loss 21.1500
2020-11-05 18:44:19,785 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.2817 | MSE 0.4907
2020-11-05 18:44:19,795 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1715 | Iter Mean Loss 14.1715
2020-11-05 18:44:19,803 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1402 | Iter Mean Loss 10.6558
2020-11-05 18:44:19,812 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.3925 | Iter Mean Loss 19.5681
2020-11-05 18:44:19,821 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.7613 | Iter Mean Loss 20.6164
2020-11-05 18:44:19,829 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.3204 | Iter Mean Loss 20.9572
2020-11-05 18:44:19,831 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.2817 | MSE 0.4902
2020-11-05 18:44:19,843 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9984 | Iter Mean Loss 13.9984
2020-11-05 18:44:19,851 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.0249 | Iter Mean Loss 10.5117
2020-11-05 18:44:19,860 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.0988 | Iter Mean Loss 19.3741
2020-11-05 18:44:19,869 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5741 | Iter Mean Loss 20.4241
2020-11-05 18:44:19,878 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.1299 | Iter Mean Loss 20.7652
2020-11-05 18:44:19,880 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.2817 | MSE 0.4896
2020-11-05 18:44:19,889 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8272 | Iter Mean Loss 13.8272
2020-11-05 18:44:19,897 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9105 | Iter Mean Loss 10.3689
2020-11-05 18:44:19,907 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.8061 | Iter Mean Loss 19.1813
2020-11-05 18:44:19,915 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3881 | Iter Mean Loss 20.2330
2020-11-05 18:44:19,923 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.9397 | Iter Mean Loss 20.5743
2020-11-05 18:44:19,926 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.2817 | MSE 0.4890
2020-11-05 18:44:19,935 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6581 | Iter Mean Loss 13.6581
2020-11-05 18:44:19,944 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7971 | Iter Mean Loss 10.2276
2020-11-05 18:44:19,952 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.5145 | Iter Mean Loss 18.9899
2020-11-05 18:44:19,961 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2034 | Iter Mean Loss 20.0433
2020-11-05 18:44:19,969 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.7500 | Iter Mean Loss 20.3846
2020-11-05 18:44:19,972 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.2817 | MSE 0.4885
2020-11-05 18:44:19,980 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4913 | Iter Mean Loss 13.4913
2020-11-05 18:44:19,990 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6850 | Iter Mean Loss 10.0881
2020-11-05 18:44:19,998 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2243 | Iter Mean Loss 18.8002
2020-11-05 18:44:20,008 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0204 | Iter Mean Loss 19.8553
2020-11-05 18:44:20,016 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 20.1964
2020-11-05 18:44:20,019 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.2817 | MSE 0.4879
2020-11-05 18:44:20,028 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3273 | Iter Mean Loss 13.3273
2020-11-05 18:44:20,036 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.5742 | Iter Mean Loss 9.9508
2020-11-05 18:44:20,045 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9359 | Iter Mean Loss 18.6125
2020-11-05 18:44:20,053 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8393 | Iter Mean Loss 19.6692
2020-11-05 18:44:20,062 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.3726 | Iter Mean Loss 20.0099
2020-11-05 18:44:20,064 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.2817 | MSE 0.4873
2020-11-05 18:44:20,073 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1664 | Iter Mean Loss 13.1664
2020-11-05 18:44:20,082 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4650 | Iter Mean Loss 9.8157
2020-11-05 18:44:20,091 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.6495 | Iter Mean Loss 18.4270
2020-11-05 18:44:20,099 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6602 | Iter Mean Loss 19.4853
2020-11-05 18:44:20,107 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.1854 | Iter Mean Loss 19.8253
2020-11-05 18:44:20,110 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.2817 | MSE 0.4867
2020-11-05 18:44:20,118 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0090 | Iter Mean Loss 13.0090
2020-11-05 18:44:20,128 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3577 | Iter Mean Loss 9.6834
2020-11-05 18:44:20,136 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.3655 | Iter Mean Loss 18.2441
2020-11-05 18:44:20,144 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4836 | Iter Mean Loss 19.3040
2020-11-05 18:44:20,152 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.9996 | Iter Mean Loss 19.6431
2020-11-05 18:44:20,155 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.2817 | MSE 0.4860
2020-11-05 18:44:20,164 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8554 | Iter Mean Loss 12.8554
2020-11-05 18:44:20,173 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.2525 | Iter Mean Loss 9.5540
2020-11-05 18:44:20,182 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0843 | Iter Mean Loss 18.0641
2020-11-05 18:44:20,191 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3097 | Iter Mean Loss 19.1255
2020-11-05 18:44:20,199 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.8154 | Iter Mean Loss 19.4635
2020-11-05 18:44:20,202 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.2817 | MSE 0.4854
2020-11-05 18:44:20,212 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7061 | Iter Mean Loss 12.7061
2020-11-05 18:44:20,221 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 9.4279
2020-11-05 18:44:20,229 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.8062 | Iter Mean Loss 17.8873
2020-11-05 18:44:20,238 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1387 | Iter Mean Loss 18.9502
2020-11-05 18:44:20,246 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.6330 | Iter Mean Loss 19.2867
2020-11-05 18:44:20,248 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.2817 | MSE 0.4848
2020-11-05 18:44:20,258 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5615 | Iter Mean Loss 12.5615
2020-11-05 18:44:20,266 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.0494 | Iter Mean Loss 9.3055
2020-11-05 18:44:20,276 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5314 | Iter Mean Loss 17.7141
2020-11-05 18:44:20,284 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9709 | Iter Mean Loss 18.7783
2020-11-05 18:44:20,293 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.4529 | Iter Mean Loss 19.1132
2020-11-05 18:44:20,295 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.2817 | MSE 0.4841
2020-11-05 18:44:20,305 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4218 | Iter Mean Loss 12.4218
2020-11-05 18:44:20,314 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9520 | Iter Mean Loss 9.1869
2020-11-05 18:44:20,323 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.2604 | Iter Mean Loss 17.5448
2020-11-05 18:44:20,331 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8066 | Iter Mean Loss 18.6102
2020-11-05 18:44:20,340 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.2752 | Iter Mean Loss 18.9432
2020-11-05 18:44:20,342 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.2817 | MSE 0.4835
2020-11-05 18:44:20,350 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2876 | Iter Mean Loss 12.2876
2020-11-05 18:44:20,359 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8576 | Iter Mean Loss 9.0726
2020-11-05 18:44:20,366 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9935 | Iter Mean Loss 17.3795
2020-11-05 18:44:20,373 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6460 | Iter Mean Loss 18.4462
2020-11-05 18:44:20,381 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.1002 | Iter Mean Loss 18.7770
2020-11-05 18:44:20,383 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.2817 | MSE 0.4828
2020-11-05 18:44:20,391 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1589 | Iter Mean Loss 12.1589
2020-11-05 18:44:20,400 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.7664 | Iter Mean Loss 8.9627
2020-11-05 18:44:20,408 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7308 | Iter Mean Loss 17.2187
2020-11-05 18:44:20,415 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4892 | Iter Mean Loss 18.2863
2020-11-05 18:44:20,423 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.9281 | Iter Mean Loss 18.6147
2020-11-05 18:44:20,426 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.2817 | MSE 0.4821
2020-11-05 18:44:20,435 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0362 | Iter Mean Loss 12.0362
2020-11-05 18:44:20,442 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6785 | Iter Mean Loss 8.8574
2020-11-05 18:44:20,451 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4727 | Iter Mean Loss 17.0625
2020-11-05 18:44:20,458 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3365 | Iter Mean Loss 18.1310
2020-11-05 18:44:20,465 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.7593 | Iter Mean Loss 18.4567
2020-11-05 18:44:20,468 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.2817 | MSE 0.4815
2020-11-05 18:44:20,477 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9197 | Iter Mean Loss 11.9197
2020-11-05 18:44:20,485 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5942 | Iter Mean Loss 8.7570
2020-11-05 18:44:20,493 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2193 | Iter Mean Loss 16.9111
2020-11-05 18:44:20,500 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1879 | Iter Mean Loss 17.9803
2020-11-05 18:44:20,508 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5939 | Iter Mean Loss 18.3030
2020-11-05 18:44:20,512 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.2817 | MSE 0.4808
2020-11-05 18:44:20,520 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8095 | Iter Mean Loss 11.8095
2020-11-05 18:44:20,528 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5136 | Iter Mean Loss 8.6615
2020-11-05 18:44:20,536 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9707 | Iter Mean Loss 16.7646
2020-11-05 18:44:20,544 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0436 | Iter Mean Loss 17.8343
2020-11-05 18:44:20,553 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.4321 | Iter Mean Loss 18.1539
2020-11-05 18:44:20,555 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.2817 | MSE 0.4801
2020-11-05 18:44:20,563 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7057 | Iter Mean Loss 11.7057
2020-11-05 18:44:20,570 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4366 | Iter Mean Loss 8.5711
2020-11-05 18:44:20,577 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7271 | Iter Mean Loss 16.6231
2020-11-05 18:44:20,585 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9036 | Iter Mean Loss 17.6932
2020-11-05 18:44:20,594 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.2740 | Iter Mean Loss 18.0094
2020-11-05 18:44:20,597 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.2817 | MSE 0.4794
2020-11-05 18:44:20,605 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6085 | Iter Mean Loss 11.6085
2020-11-05 18:44:20,612 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.3634 | Iter Mean Loss 8.4859
2020-11-05 18:44:20,620 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4886 | Iter Mean Loss 16.4868
2020-11-05 18:44:20,629 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7679 | Iter Mean Loss 17.5571
2020-11-05 18:44:20,637 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.1197 | Iter Mean Loss 17.8696
2020-11-05 18:44:20,639 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.2817 | MSE 0.4786
2020-11-05 18:44:20,646 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5178 | Iter Mean Loss 11.5178
2020-11-05 18:44:20,654 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2939 | Iter Mean Loss 8.4058
2020-11-05 18:44:20,661 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2551 | Iter Mean Loss 16.3556
2020-11-05 18:44:20,668 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6366 | Iter Mean Loss 17.4258
2020-11-05 18:44:20,677 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.9694 | Iter Mean Loss 17.7345
2020-11-05 18:44:20,680 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.2817 | MSE 0.4779
2020-11-05 18:44:20,688 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4336 | Iter Mean Loss 11.4336
2020-11-05 18:44:20,695 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2283 | Iter Mean Loss 8.3309
2020-11-05 18:44:20,703 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0266 | Iter Mean Loss 16.2295
2020-11-05 18:44:20,712 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5095 | Iter Mean Loss 17.2995
2020-11-05 18:44:20,720 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.8231 | Iter Mean Loss 17.6042
2020-11-05 18:44:20,722 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.2817 | MSE 0.4772
2020-11-05 18:44:20,730 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3558 | Iter Mean Loss 11.3558
2020-11-05 18:44:20,737 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1663 | Iter Mean Loss 8.2611
2020-11-05 18:44:20,744 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8031 | Iter Mean Loss 16.1084
2020-11-05 18:44:20,751 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3867 | Iter Mean Loss 17.1780
2020-11-05 18:44:20,758 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.6807 | Iter Mean Loss 17.4785
2020-11-05 18:44:20,760 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.2817 | MSE 0.4764
2020-11-05 18:44:20,768 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2844 | Iter Mean Loss 11.2844
2020-11-05 18:44:20,776 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 8.1962
2020-11-05 18:44:20,783 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.5845 | Iter Mean Loss 15.9923
2020-11-05 18:44:20,790 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2679 | Iter Mean Loss 17.0612
2020-11-05 18:44:20,797 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.5423 | Iter Mean Loss 17.3574
2020-11-05 18:44:20,799 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.2817 | MSE 0.4757
2020-11-05 18:44:20,807 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2192 | Iter Mean Loss 11.2192
2020-11-05 18:44:20,814 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0534 | Iter Mean Loss 8.1363
2020-11-05 18:44:20,822 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3707 | Iter Mean Loss 15.8811
2020-11-05 18:44:20,829 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1531 | Iter Mean Loss 16.9491
2020-11-05 18:44:20,836 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.4078 | Iter Mean Loss 17.2409
2020-11-05 18:44:20,838 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.2817 | MSE 0.4749
2020-11-05 18:44:20,846 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1600 | Iter Mean Loss 11.1600
2020-11-05 18:44:20,853 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0022 | Iter Mean Loss 8.0811
2020-11-05 18:44:20,861 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1615 | Iter Mean Loss 15.7746
2020-11-05 18:44:20,868 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0422 | Iter Mean Loss 16.8415
2020-11-05 18:44:20,875 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.2772 | Iter Mean Loss 17.1286
2020-11-05 18:44:20,877 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.2817 | MSE 0.4741
2020-11-05 18:44:20,885 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1065 | Iter Mean Loss 11.1065
2020-11-05 18:44:20,892 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9544 | Iter Mean Loss 8.0304
2020-11-05 18:44:20,900 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.9567 | Iter Mean Loss 15.6725
2020-11-05 18:44:20,907 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9349 | Iter Mean Loss 16.7381
2020-11-05 18:44:20,914 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.1504 | Iter Mean Loss 17.0206
2020-11-05 18:44:20,916 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.2817 | MSE 0.4734
2020-11-05 18:44:20,924 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0586 | Iter Mean Loss 11.0586
2020-11-05 18:44:20,931 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9098 | Iter Mean Loss 7.9842
2020-11-05 18:44:20,939 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7562 | Iter Mean Loss 15.5749
2020-11-05 18:44:20,946 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8310 | Iter Mean Loss 16.6389
2020-11-05 18:44:20,953 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.0272 | Iter Mean Loss 16.9166
2020-11-05 18:44:20,955 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.2817 | MSE 0.4726
2020-11-05 18:44:20,963 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0159 | Iter Mean Loss 11.0159
2020-11-05 18:44:20,971 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8683 | Iter Mean Loss 7.9421
2020-11-05 18:44:20,978 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5597 | Iter Mean Loss 15.4813
2020-11-05 18:44:20,985 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7305 | Iter Mean Loss 16.5436
2020-11-05 18:44:20,992 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9075 | Iter Mean Loss 16.8164
2020-11-05 18:44:20,994 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.2817 | MSE 0.4718
2020-11-05 18:44:21,002 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9782 | Iter Mean Loss 10.9782
2020-11-05 18:44:21,009 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8298 | Iter Mean Loss 7.9040
2020-11-05 18:44:21,017 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3670 | Iter Mean Loss 15.3917
2020-11-05 18:44:21,024 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6330 | Iter Mean Loss 16.4520
2020-11-05 18:44:21,031 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.7911 | Iter Mean Loss 16.7198
2020-11-05 18:44:21,033 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.2817 | MSE 0.4710
2020-11-05 18:44:21,042 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9452 | Iter Mean Loss 10.9452
2020-11-05 18:44:21,049 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7940 | Iter Mean Loss 7.8696
2020-11-05 18:44:21,057 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1779 | Iter Mean Loss 15.3057
2020-11-05 18:44:21,066 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5384 | Iter Mean Loss 16.3639
2020-11-05 18:44:21,075 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.6780 | Iter Mean Loss 16.6267
2020-11-05 18:44:21,077 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.2817 | MSE 0.4702
2020-11-05 18:44:21,087 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9165 | Iter Mean Loss 10.9165
2020-11-05 18:44:21,096 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7609 | Iter Mean Loss 7.8387
2020-11-05 18:44:21,105 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9922 | Iter Mean Loss 15.2232
2020-11-05 18:44:21,114 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4465 | Iter Mean Loss 16.2790
2020-11-05 18:44:21,122 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.5679 | Iter Mean Loss 16.5368
2020-11-05 18:44:21,124 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.2817 | MSE 0.4694
2020-11-05 18:44:21,132 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8920 | Iter Mean Loss 10.8920
2020-11-05 18:44:21,140 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7302 | Iter Mean Loss 7.8111
2020-11-05 18:44:21,148 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8097 | Iter Mean Loss 15.1440
2020-11-05 18:44:21,155 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3571 | Iter Mean Loss 16.1972
2020-11-05 18:44:21,163 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.4607 | Iter Mean Loss 16.4499
2020-11-05 18:44:21,164 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.2817 | MSE 0.4685
2020-11-05 18:44:21,173 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 18:44:21,180 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7018 | Iter Mean Loss 7.7865
2020-11-05 18:44:21,188 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6301 | Iter Mean Loss 15.0677
2020-11-05 18:44:21,195 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2699 | Iter Mean Loss 16.1183
2020-11-05 18:44:21,203 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.3562 | Iter Mean Loss 16.3659
2020-11-05 18:44:21,205 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.2817 | MSE 0.4677
2020-11-05 18:44:21,213 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8540 | Iter Mean Loss 10.8540
2020-11-05 18:44:21,221 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 7.7648
2020-11-05 18:44:21,229 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4533 | Iter Mean Loss 14.9943
2020-11-05 18:44:21,236 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1848 | Iter Mean Loss 16.0419
2020-11-05 18:44:21,245 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.2542 | Iter Mean Loss 16.2844
2020-11-05 18:44:21,247 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.2817 | MSE 0.4668
2020-11-05 18:44:21,255 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8400 | Iter Mean Loss 10.8400
2020-11-05 18:44:21,262 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6512 | Iter Mean Loss 7.7456
2020-11-05 18:44:21,269 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2789 | Iter Mean Loss 14.9234
2020-11-05 18:44:21,277 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1017 | Iter Mean Loss 15.9679
2020-11-05 18:44:21,284 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.1545 | Iter Mean Loss 16.2053
2020-11-05 18:44:21,286 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.2817 | MSE 0.4660
2020-11-05 18:44:21,293 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8289 | Iter Mean Loss 10.8289
2020-11-05 18:44:21,301 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6287 | Iter Mean Loss 7.7288
2020-11-05 18:44:21,308 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1069 | Iter Mean Loss 14.8548
2020-11-05 18:44:21,316 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0203 | Iter Mean Loss 15.8962
2020-11-05 18:44:21,324 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.0571 | Iter Mean Loss 16.1284
2020-11-05 18:44:21,327 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.2817 | MSE 0.4651
2020-11-05 18:44:21,335 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8205 | Iter Mean Loss 10.8205
2020-11-05 18:44:21,345 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6078 | Iter Mean Loss 7.7142
2020-11-05 18:44:21,353 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9371 | Iter Mean Loss 14.7885
2020-11-05 18:44:21,361 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9405 | Iter Mean Loss 15.8265
2020-11-05 18:44:21,369 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.9616 | Iter Mean Loss 16.0535
2020-11-05 18:44:21,371 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.2817 | MSE 0.4643
2020-11-05 18:44:21,381 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8146 | Iter Mean Loss 10.8146
2020-11-05 18:44:21,391 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5885 | Iter Mean Loss 7.7015
2020-11-05 18:44:21,399 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7693 | Iter Mean Loss 14.7241
2020-11-05 18:44:21,406 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8621 | Iter Mean Loss 15.7586
2020-11-05 18:44:21,413 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.8681 | Iter Mean Loss 15.9805
2020-11-05 18:44:21,415 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.2817 | MSE 0.4634
2020-11-05 18:44:21,425 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:44:21,435 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5705 | Iter Mean Loss 7.6907
2020-11-05 18:44:21,444 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6033 | Iter Mean Loss 14.6616
2020-11-05 18:44:21,453 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7850 | Iter Mean Loss 15.6924
2020-11-05 18:44:21,461 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.7762 | Iter Mean Loss 15.9092
2020-11-05 18:44:21,463 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.2817 | MSE 0.4625
2020-11-05 18:44:21,472 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8091 | Iter Mean Loss 10.8091
2020-11-05 18:44:21,481 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5538 | Iter Mean Loss 7.6815
2020-11-05 18:44:21,489 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4390 | Iter Mean Loss 14.6007
2020-11-05 18:44:21,497 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7092 | Iter Mean Loss 15.6278
2020-11-05 18:44:21,506 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6860 | Iter Mean Loss 15.8394
2020-11-05 18:44:21,508 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.2817 | MSE 0.4617
2020-11-05 18:44:21,517 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8092 | Iter Mean Loss 10.8092
2020-11-05 18:44:21,527 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5383 | Iter Mean Loss 7.6738
2020-11-05 18:44:21,535 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2763 | Iter Mean Loss 14.5413
2020-11-05 18:44:21,543 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6344 | Iter Mean Loss 15.5646
2020-11-05 18:44:21,551 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5972 | Iter Mean Loss 15.7711
2020-11-05 18:44:21,555 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.2817 | MSE 0.4608
2020-11-05 18:44:21,563 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:44:21,572 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5238 | Iter Mean Loss 7.6673
2020-11-05 18:44:21,580 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1151 | Iter Mean Loss 14.4833
2020-11-05 18:44:21,589 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5606 | Iter Mean Loss 15.5026
2020-11-05 18:44:21,597 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5098 | Iter Mean Loss 15.7040
2020-11-05 18:44:21,599 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.2817 | MSE 0.4599
2020-11-05 18:44:21,609 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8140 | Iter Mean Loss 10.8140
2020-11-05 18:44:21,617 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 7.6621
2020-11-05 18:44:21,627 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9552 | Iter Mean Loss 14.4265
2020-11-05 18:44:21,634 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4877 | Iter Mean Loss 15.4418
2020-11-05 18:44:21,644 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.4236 | Iter Mean Loss 15.6382
2020-11-05 18:44:21,646 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.2817 | MSE 0.4590
2020-11-05 18:44:21,656 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8184 | Iter Mean Loss 10.8184
2020-11-05 18:44:21,665 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4975 | Iter Mean Loss 7.6580
2020-11-05 18:44:21,675 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7967 | Iter Mean Loss 14.3709
2020-11-05 18:44:21,683 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4156 | Iter Mean Loss 15.3820
2020-11-05 18:44:21,693 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.3386 | Iter Mean Loss 15.5734
2020-11-05 18:44:21,695 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.2817 | MSE 0.4581
2020-11-05 18:44:21,704 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8240 | Iter Mean Loss 10.8240
2020-11-05 18:44:21,714 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4856 | Iter Mean Loss 7.6548
2020-11-05 18:44:21,724 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6393 | Iter Mean Loss 14.3163
2020-11-05 18:44:21,732 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3442 | Iter Mean Loss 15.3233
2020-11-05 18:44:21,742 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.2546 | Iter Mean Loss 15.5095
2020-11-05 18:44:21,744 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.2817 | MSE 0.4572
2020-11-05 18:44:21,753 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8305 | Iter Mean Loss 10.8305
2020-11-05 18:44:21,762 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4743 | Iter Mean Loss 7.6524
2020-11-05 18:44:21,770 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4831 | Iter Mean Loss 14.2626
2020-11-05 18:44:21,780 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2736 | Iter Mean Loss 15.2654
2020-11-05 18:44:21,789 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.1716 | Iter Mean Loss 15.4466
2020-11-05 18:44:21,792 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.2817 | MSE 0.4563
2020-11-05 18:44:21,800 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8379 | Iter Mean Loss 10.8379
2020-11-05 18:44:21,810 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4637 | Iter Mean Loss 7.6508
2020-11-05 18:44:21,818 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3279 | Iter Mean Loss 14.2098
2020-11-05 18:44:21,827 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2035 | Iter Mean Loss 15.2083
2020-11-05 18:44:21,835 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0894 | Iter Mean Loss 15.3845
2020-11-05 18:44:21,838 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.2817 | MSE 0.4554
2020-11-05 18:44:21,848 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 10.8461
2020-11-05 18:44:21,857 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4536 | Iter Mean Loss 7.6499
2020-11-05 18:44:21,866 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1738 | Iter Mean Loss 14.1579
2020-11-05 18:44:21,876 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1341 | Iter Mean Loss 15.1519
2020-11-05 18:44:21,884 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0081 | Iter Mean Loss 15.3232
2020-11-05 18:44:21,886 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.2817 | MSE 0.4544
2020-11-05 18:44:21,896 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8550 | Iter Mean Loss 10.8550
2020-11-05 18:44:21,904 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4440 | Iter Mean Loss 7.6495
2020-11-05 18:44:21,913 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0207 | Iter Mean Loss 14.1066
2020-11-05 18:44:21,921 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 15.0962
2020-11-05 18:44:21,930 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.9276 | Iter Mean Loss 15.2625
2020-11-05 18:44:21,932 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.2817 | MSE 0.4535
2020-11-05 18:44:21,940 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8645 | Iter Mean Loss 10.8645
2020-11-05 18:44:21,949 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4349 | Iter Mean Loss 7.6497
2020-11-05 18:44:21,957 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8685 | Iter Mean Loss 14.0560
2020-11-05 18:44:21,966 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9969 | Iter Mean Loss 15.0412
2020-11-05 18:44:21,974 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.8477 | Iter Mean Loss 15.2025
2020-11-05 18:44:21,977 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.2817 | MSE 0.4526
2020-11-05 18:44:21,986 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8745 | Iter Mean Loss 10.8745
2020-11-05 18:44:21,994 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4262 | Iter Mean Loss 7.6504
2020-11-05 18:44:22,003 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7173 | Iter Mean Loss 14.0060
2020-11-05 18:44:22,011 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9290 | Iter Mean Loss 14.9868
2020-11-05 18:44:22,020 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.7685 | Iter Mean Loss 15.1431
2020-11-05 18:44:22,022 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.2817 | MSE 0.4517
2020-11-05 18:44:22,032 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8849 | Iter Mean Loss 10.8849
2020-11-05 18:44:22,040 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 7.6514
2020-11-05 18:44:22,049 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5669 | Iter Mean Loss 13.9566
2020-11-05 18:44:22,058 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8617 | Iter Mean Loss 14.9329
2020-11-05 18:44:22,066 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6900 | Iter Mean Loss 15.0843
2020-11-05 18:44:22,068 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.2817 | MSE 0.4508
2020-11-05 18:44:22,077 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8957 | Iter Mean Loss 10.8957
2020-11-05 18:44:22,085 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4099 | Iter Mean Loss 7.6528
2020-11-05 18:44:22,093 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4174 | Iter Mean Loss 13.9077
2020-11-05 18:44:22,102 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7948 | Iter Mean Loss 14.8795
2020-11-05 18:44:22,110 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6120 | Iter Mean Loss 15.0260
2020-11-05 18:44:22,113 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.2817 | MSE 0.4498
2020-11-05 18:44:22,122 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9069 | Iter Mean Loss 10.9069
2020-11-05 18:44:22,130 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4022 | Iter Mean Loss 7.6545
2020-11-05 18:44:22,139 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2688 | Iter Mean Loss 13.8593
2020-11-05 18:44:22,147 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7283 | Iter Mean Loss 14.8265
2020-11-05 18:44:22,156 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5345 | Iter Mean Loss 14.9681
2020-11-05 18:44:22,158 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.2817 | MSE 0.4489
2020-11-05 18:44:22,167 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9183 | Iter Mean Loss 10.9183
2020-11-05 18:44:22,175 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3948 | Iter Mean Loss 7.6565
2020-11-05 18:44:22,183 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1211 | Iter Mean Loss 13.8114
2020-11-05 18:44:22,193 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6622 | Iter Mean Loss 14.7741
2020-11-05 18:44:22,201 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.4576 | Iter Mean Loss 14.9108
2020-11-05 18:44:22,204 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.2817 | MSE 0.4480
2020-11-05 18:44:22,212 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9299 | Iter Mean Loss 10.9299
2020-11-05 18:44:22,221 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3876 | Iter Mean Loss 7.6587
2020-11-05 18:44:22,229 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9742 | Iter Mean Loss 13.7639
2020-11-05 18:44:22,238 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5966 | Iter Mean Loss 14.7221
2020-11-05 18:44:22,245 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3811 | Iter Mean Loss 14.8539
2020-11-05 18:44:22,248 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.2817 | MSE 0.4471
2020-11-05 18:44:22,258 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9416 | Iter Mean Loss 10.9416
2020-11-05 18:44:22,266 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3807 | Iter Mean Loss 7.6612
2020-11-05 18:44:22,274 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8281 | Iter Mean Loss 13.7168
2020-11-05 18:44:22,282 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5314 | Iter Mean Loss 14.6705
2020-11-05 18:44:22,290 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3051 | Iter Mean Loss 14.7974
2020-11-05 18:44:22,292 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.2817 | MSE 0.4461
2020-11-05 18:44:22,302 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9536 | Iter Mean Loss 10.9536
2020-11-05 18:44:22,310 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3739 | Iter Mean Loss 7.6638
2020-11-05 18:44:22,320 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6829 | Iter Mean Loss 13.6701
2020-11-05 18:44:22,328 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4666 | Iter Mean Loss 14.6192
2020-11-05 18:44:22,337 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.2295 | Iter Mean Loss 14.7413
2020-11-05 18:44:22,339 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.2817 | MSE 0.4452
2020-11-05 18:44:22,347 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9656 | Iter Mean Loss 10.9656
2020-11-05 18:44:22,354 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3674 | Iter Mean Loss 7.6665
2020-11-05 18:44:22,361 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5385 | Iter Mean Loss 13.6238
2020-11-05 18:44:22,369 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4022 | Iter Mean Loss 14.5684
2020-11-05 18:44:22,376 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.1544 | Iter Mean Loss 14.6856
2020-11-05 18:44:22,378 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.2817 | MSE 0.4443
2020-11-05 18:44:22,386 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9776 | Iter Mean Loss 10.9776
2020-11-05 18:44:22,393 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3610 | Iter Mean Loss 7.6693
2020-11-05 18:44:22,401 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3949 | Iter Mean Loss 13.5779
2020-11-05 18:44:22,408 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3382 | Iter Mean Loss 14.5179
2020-11-05 18:44:22,415 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0796 | Iter Mean Loss 14.6303
2020-11-05 18:44:22,417 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.2817 | MSE 0.4433
2020-11-05 18:44:22,425 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9897 | Iter Mean Loss 10.9897
2020-11-05 18:44:22,432 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3548 | Iter Mean Loss 7.6723
2020-11-05 18:44:22,440 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2522 | Iter Mean Loss 13.5322
2020-11-05 18:44:22,447 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2746 | Iter Mean Loss 14.4678
2020-11-05 18:44:22,454 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0053 | Iter Mean Loss 14.5753
2020-11-05 18:44:22,456 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.2817 | MSE 0.4424
2020-11-05 18:44:22,464 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0019 | Iter Mean Loss 11.0019
2020-11-05 18:44:22,471 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3487 | Iter Mean Loss 7.6753
2020-11-05 18:44:22,479 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1103 | Iter Mean Loss 13.4870
2020-11-05 18:44:22,486 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2114 | Iter Mean Loss 14.4181
2020-11-05 18:44:22,493 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.9313 | Iter Mean Loss 14.5207
2020-11-05 18:44:22,495 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.2817 | MSE 0.4415
2020-11-05 18:44:22,503 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 11.0139
2020-11-05 18:44:22,511 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3428 | Iter Mean Loss 7.6784
2020-11-05 18:44:22,518 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9693 | Iter Mean Loss 13.4420
2020-11-05 18:44:22,525 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1485 | Iter Mean Loss 14.3686
2020-11-05 18:44:22,532 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.8577 | Iter Mean Loss 14.4664
2020-11-05 18:44:22,534 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.2817 | MSE 0.4406
2020-11-05 18:44:22,542 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0260 | Iter Mean Loss 11.0260
2020-11-05 18:44:22,549 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3370 | Iter Mean Loss 7.6815
2020-11-05 18:44:22,557 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8291 | Iter Mean Loss 13.3974
2020-11-05 18:44:22,564 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0861 | Iter Mean Loss 14.3195
2020-11-05 18:44:22,571 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7844 | Iter Mean Loss 14.4125
2020-11-05 18:44:22,573 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.2817 | MSE 0.4396
2020-11-05 18:44:22,581 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0380 | Iter Mean Loss 11.0380
2020-11-05 18:44:22,589 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3312 | Iter Mean Loss 7.6846
2020-11-05 18:44:22,597 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6898 | Iter Mean Loss 13.3530
2020-11-05 18:44:22,604 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0241 | Iter Mean Loss 14.2708
2020-11-05 18:44:22,611 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7115 | Iter Mean Loss 14.3589
2020-11-05 18:44:22,613 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.2817 | MSE 0.4387
2020-11-05 18:44:22,621 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0499 | Iter Mean Loss 11.0499
2020-11-05 18:44:22,629 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3256 | Iter Mean Loss 7.6878
2020-11-05 18:44:22,636 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5513 | Iter Mean Loss 13.3090
2020-11-05 18:44:22,643 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9624 | Iter Mean Loss 14.2223
2020-11-05 18:44:22,651 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.6390 | Iter Mean Loss 14.3057
2020-11-05 18:44:22,653 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.2817 | MSE 0.4378
2020-11-05 18:44:22,660 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0617 | Iter Mean Loss 11.0617
2020-11-05 18:44:22,668 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 7.6909
2020-11-05 18:44:22,675 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4137 | Iter Mean Loss 13.2652
2020-11-05 18:44:22,682 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9011 | Iter Mean Loss 14.1742
2020-11-05 18:44:22,690 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5668 | Iter Mean Loss 14.2527
2020-11-05 18:44:22,692 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.2817 | MSE 0.4369
2020-11-05 18:44:22,699 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0734 | Iter Mean Loss 11.0734
2020-11-05 18:44:22,707 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3147 | Iter Mean Loss 7.6941
2020-11-05 18:44:22,714 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2770 | Iter Mean Loss 13.2217
2020-11-05 18:44:22,722 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8403 | Iter Mean Loss 14.1263
2020-11-05 18:44:22,729 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4949 | Iter Mean Loss 14.2001
2020-11-05 18:44:22,731 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.2817 | MSE 0.4360
2020-11-05 18:44:22,739 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0850 | Iter Mean Loss 11.0850
2020-11-05 18:44:22,746 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3094 | Iter Mean Loss 7.6972
2020-11-05 18:44:22,753 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1411 | Iter Mean Loss 13.1785
2020-11-05 18:44:22,761 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7798 | Iter Mean Loss 14.0788
2020-11-05 18:44:22,768 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4233 | Iter Mean Loss 14.1477
2020-11-05 18:44:22,770 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.2817 | MSE 0.4350
2020-11-05 18:44:22,778 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0964 | Iter Mean Loss 11.0964
2020-11-05 18:44:22,785 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3041 | Iter Mean Loss 7.7003
2020-11-05 18:44:22,793 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0062 | Iter Mean Loss 13.1356
2020-11-05 18:44:22,800 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7197 | Iter Mean Loss 14.0316
2020-11-05 18:44:22,808 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.3521 | Iter Mean Loss 14.0957
2020-11-05 18:44:22,810 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.2817 | MSE 0.4341
2020-11-05 18:44:22,818 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.1076
2020-11-05 18:44:22,825 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 7.7033
2020-11-05 18:44:22,832 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8721 | Iter Mean Loss 13.0929
2020-11-05 18:44:22,840 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6600 | Iter Mean Loss 13.9846
2020-11-05 18:44:22,847 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2812 | Iter Mean Loss 14.0440
2020-11-05 18:44:22,849 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.2817 | MSE 0.4332
2020-11-05 18:44:22,857 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1187 | Iter Mean Loss 11.1187
2020-11-05 18:44:22,864 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2938 | Iter Mean Loss 7.7063
2020-11-05 18:44:22,871 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7389 | Iter Mean Loss 13.0505
2020-11-05 18:44:22,878 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6006 | Iter Mean Loss 13.9380
2020-11-05 18:44:22,886 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2106 | Iter Mean Loss 13.9925
2020-11-05 18:44:22,888 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.2817 | MSE 0.4323
2020-11-05 18:44:22,896 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1296 | Iter Mean Loss 11.1296
2020-11-05 18:44:22,903 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2888 | Iter Mean Loss 7.7092
2020-11-05 18:44:22,910 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6065 | Iter Mean Loss 13.0083
2020-11-05 18:44:22,918 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5417 | Iter Mean Loss 13.8917
2020-11-05 18:44:22,925 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.1404 | Iter Mean Loss 13.9414
2020-11-05 18:44:22,927 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.2817 | MSE 0.4314
2020-11-05 18:44:22,935 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1403 | Iter Mean Loss 11.1403
2020-11-05 18:44:22,942 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2838 | Iter Mean Loss 7.7120
2020-11-05 18:44:22,949 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4751 | Iter Mean Loss 12.9664
2020-11-05 18:44:22,957 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4831 | Iter Mean Loss 13.8456
2020-11-05 18:44:22,966 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0704 | Iter Mean Loss 13.8906
2020-11-05 18:44:22,968 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.2817 | MSE 0.4305
2020-11-05 18:44:22,976 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1508 | Iter Mean Loss 11.1508
2020-11-05 18:44:22,983 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 7.7148
2020-11-05 18:44:22,991 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3446 | Iter Mean Loss 12.9247
2020-11-05 18:44:22,998 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4250 | Iter Mean Loss 13.7998
2020-11-05 18:44:23,005 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0008 | Iter Mean Loss 13.8400
2020-11-05 18:44:23,007 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.2817 | MSE 0.4296
2020-11-05 18:44:23,015 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1611 | Iter Mean Loss 11.1611
2020-11-05 18:44:23,022 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2739 | Iter Mean Loss 7.7175
2020-11-05 18:44:23,030 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2150 | Iter Mean Loss 12.8833
2020-11-05 18:44:23,037 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3672 | Iter Mean Loss 13.7543
2020-11-05 18:44:23,044 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.9315 | Iter Mean Loss 13.7897
2020-11-05 18:44:23,046 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.2817 | MSE 0.4287
2020-11-05 18:44:23,054 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1711 | Iter Mean Loss 11.1711
2020-11-05 18:44:23,061 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2691 | Iter Mean Loss 7.7201
2020-11-05 18:44:23,069 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0863 | Iter Mean Loss 12.8422
2020-11-05 18:44:23,076 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3098 | Iter Mean Loss 13.7091
2020-11-05 18:44:23,084 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.8625 | Iter Mean Loss 13.7398
2020-11-05 18:44:23,086 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.2817 | MSE 0.4278
2020-11-05 18:44:23,094 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1809 | Iter Mean Loss 11.1809
2020-11-05 18:44:23,101 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2643 | Iter Mean Loss 7.7226
2020-11-05 18:44:23,108 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9586 | Iter Mean Loss 12.8013
2020-11-05 18:44:23,116 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2528 | Iter Mean Loss 13.6641
2020-11-05 18:44:23,123 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.6901
2020-11-05 18:44:23,125 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.2817 | MSE 0.4270
2020-11-05 18:44:23,133 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1905 | Iter Mean Loss 11.1905
2020-11-05 18:44:23,140 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 7.7250
2020-11-05 18:44:23,147 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8317 | Iter Mean Loss 12.7606
2020-11-05 18:44:23,155 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1962 | Iter Mean Loss 13.6195
2020-11-05 18:44:23,162 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7255 | Iter Mean Loss 13.6407
2020-11-05 18:44:23,164 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.2817 | MSE 0.4261
2020-11-05 18:44:23,172 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1998 | Iter Mean Loss 11.1998
2020-11-05 18:44:23,179 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 7.7273
2020-11-05 18:44:23,186 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7058 | Iter Mean Loss 12.7201
2020-11-05 18:44:23,193 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1399 | Iter Mean Loss 13.5751
2020-11-05 18:44:23,201 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.6575 | Iter Mean Loss 13.5916
2020-11-05 18:44:23,203 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.2817 | MSE 0.4252
2020-11-05 18:44:23,210 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2088 | Iter Mean Loss 11.2088
2020-11-05 18:44:23,218 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2502 | Iter Mean Loss 7.7295
2020-11-05 18:44:23,225 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5808 | Iter Mean Loss 12.6799
2020-11-05 18:44:23,232 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0841 | Iter Mean Loss 13.5310
2020-11-05 18:44:23,239 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5898 | Iter Mean Loss 13.5427
2020-11-05 18:44:23,241 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.2817 | MSE 0.4243
2020-11-05 18:44:23,250 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2176 | Iter Mean Loss 11.2176
2020-11-05 18:44:23,258 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2456 | Iter Mean Loss 7.7316
2020-11-05 18:44:23,267 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4567 | Iter Mean Loss 12.6400
2020-11-05 18:44:23,274 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0286 | Iter Mean Loss 13.4871
2020-11-05 18:44:23,281 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5224 | Iter Mean Loss 13.4942
2020-11-05 18:44:23,283 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.2817 | MSE 0.4235
2020-11-05 18:44:23,292 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2261 | Iter Mean Loss 11.2261
2020-11-05 18:44:23,301 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2410 | Iter Mean Loss 7.7336
2020-11-05 18:44:23,309 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3335 | Iter Mean Loss 12.6002
2020-11-05 18:44:23,317 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9735 | Iter Mean Loss 13.4435
2020-11-05 18:44:23,328 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.4554 | Iter Mean Loss 13.4459
2020-11-05 18:44:23,330 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.2817 | MSE 0.4226
2020-11-05 18:44:23,342 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2343 | Iter Mean Loss 11.2343
2020-11-05 18:44:23,351 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 7.7354
2020-11-05 18:44:23,362 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2113 | Iter Mean Loss 12.5607
2020-11-05 18:44:23,372 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9187 | Iter Mean Loss 13.4002
2020-11-05 18:44:23,381 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3886 | Iter Mean Loss 13.3979
2020-11-05 18:44:23,384 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.2817 | MSE 0.4217
2020-11-05 18:44:23,396 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2423 | Iter Mean Loss 11.2423
2020-11-05 18:44:23,408 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2319 | Iter Mean Loss 7.7371
2020-11-05 18:44:23,416 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0900 | Iter Mean Loss 12.5214
2020-11-05 18:44:23,426 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8644 | Iter Mean Loss 13.3571
2020-11-05 18:44:23,436 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3222 | Iter Mean Loss 13.3502
2020-11-05 18:44:23,439 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.2817 | MSE 0.4209
2020-11-05 18:44:23,449 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2499 | Iter Mean Loss 11.2499
2020-11-05 18:44:23,458 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2274 | Iter Mean Loss 7.7387
2020-11-05 18:44:23,469 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9697 | Iter Mean Loss 12.4823
2020-11-05 18:44:23,477 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8104 | Iter Mean Loss 13.3143
2020-11-05 18:44:23,487 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.2561 | Iter Mean Loss 13.3027
2020-11-05 18:44:23,490 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.2817 | MSE 0.4200
2020-11-05 18:44:23,500 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2573 | Iter Mean Loss 11.2573
2020-11-05 18:44:23,509 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2229 | Iter Mean Loss 7.7401
2020-11-05 18:44:23,519 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8502 | Iter Mean Loss 12.4435
2020-11-05 18:44:23,527 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7568 | Iter Mean Loss 13.2718
2020-11-05 18:44:23,537 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1904 | Iter Mean Loss 13.2555
2020-11-05 18:44:23,540 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.2817 | MSE 0.4192
2020-11-05 18:44:23,550 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2643 | Iter Mean Loss 11.2643
2020-11-05 18:44:23,559 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2185 | Iter Mean Loss 7.7414
2020-11-05 18:44:23,569 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7318 | Iter Mean Loss 12.4049
2020-11-05 18:44:23,577 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7035 | Iter Mean Loss 13.2295
2020-11-05 18:44:23,588 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1250 | Iter Mean Loss 13.2086
2020-11-05 18:44:23,591 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.2817 | MSE 0.4184
2020-11-05 18:44:23,602 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2711 | Iter Mean Loss 11.2711
2020-11-05 18:44:23,611 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2141 | Iter Mean Loss 7.7426
2020-11-05 18:44:23,621 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6142 | Iter Mean Loss 12.3665
2020-11-05 18:44:23,629 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6507 | Iter Mean Loss 13.1875
2020-11-05 18:44:23,639 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.0599 | Iter Mean Loss 13.1620
2020-11-05 18:44:23,641 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.2817 | MSE 0.4175
2020-11-05 18:44:23,651 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2775 | Iter Mean Loss 11.2775
2020-11-05 18:44:23,660 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2097 | Iter Mean Loss 7.7436
2020-11-05 18:44:23,670 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4976 | Iter Mean Loss 12.3283
2020-11-05 18:44:23,678 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5982 | Iter Mean Loss 13.1457
2020-11-05 18:44:23,688 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9951 | Iter Mean Loss 13.1156
2020-11-05 18:44:23,691 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.2817 | MSE 0.4167
2020-11-05 18:44:23,701 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2837 | Iter Mean Loss 11.2837
2020-11-05 18:44:23,710 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2053 | Iter Mean Loss 7.7445
2020-11-05 18:44:23,720 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3819 | Iter Mean Loss 12.2903
2020-11-05 18:44:23,728 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5460 | Iter Mean Loss 13.1042
2020-11-05 18:44:23,738 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9307 | Iter Mean Loss 13.0695
2020-11-05 18:44:23,741 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.2817 | MSE 0.4159
2020-11-05 18:44:23,751 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2895 | Iter Mean Loss 11.2895
2020-11-05 18:44:23,760 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2009 | Iter Mean Loss 7.7452
2020-11-05 18:44:23,770 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2671 | Iter Mean Loss 12.2525
2020-11-05 18:44:23,778 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4942 | Iter Mean Loss 13.0629
2020-11-05 18:44:23,788 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8666 | Iter Mean Loss 13.0237
2020-11-05 18:44:23,791 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.2817 | MSE 0.4150
2020-11-05 18:44:23,800 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2950 | Iter Mean Loss 11.2950
2020-11-05 18:44:23,810 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1966 | Iter Mean Loss 7.7458
2020-11-05 18:44:23,819 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1533 | Iter Mean Loss 12.2150
2020-11-05 18:44:23,828 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4428 | Iter Mean Loss 13.0219
2020-11-05 18:44:23,837 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8028 | Iter Mean Loss 12.9781
2020-11-05 18:44:23,839 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.2817 | MSE 0.4142
2020-11-05 18:44:23,850 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3002 | Iter Mean Loss 11.3002
2020-11-05 18:44:23,860 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1923 | Iter Mean Loss 7.7462
2020-11-05 18:44:23,869 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0404 | Iter Mean Loss 12.1776
2020-11-05 18:44:23,878 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3918 | Iter Mean Loss 12.9811
2020-11-05 18:44:23,888 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.7394 | Iter Mean Loss 12.9328
2020-11-05 18:44:23,891 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.2817 | MSE 0.4134
2020-11-05 18:44:23,901 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3050 | Iter Mean Loss 11.3050
2020-11-05 18:44:23,911 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1880 | Iter Mean Loss 7.7465
2020-11-05 18:44:23,920 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9284 | Iter Mean Loss 12.1405
2020-11-05 18:44:23,929 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3411 | Iter Mean Loss 12.9406
2020-11-05 18:44:23,939 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6763 | Iter Mean Loss 12.8878
2020-11-05 18:44:23,942 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.2817 | MSE 0.4126
2020-11-05 18:44:23,952 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3096 | Iter Mean Loss 11.3096
2020-11-05 18:44:23,962 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 7.7466
2020-11-05 18:44:23,972 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8174 | Iter Mean Loss 12.1035
2020-11-05 18:44:23,980 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2907 | Iter Mean Loss 12.9003
2020-11-05 18:44:23,990 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6136 | Iter Mean Loss 12.8430
2020-11-05 18:44:23,993 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.2817 | MSE 0.4118
2020-11-05 18:44:24,003 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3138 | Iter Mean Loss 11.3138
2020-11-05 18:44:24,012 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1794 | Iter Mean Loss 7.7466
2020-11-05 18:44:24,022 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7072 | Iter Mean Loss 12.0668
2020-11-05 18:44:24,031 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2407 | Iter Mean Loss 12.8603
2020-11-05 18:44:24,040 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.5512 | Iter Mean Loss 12.7985
2020-11-05 18:44:24,043 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.2817 | MSE 0.4110
2020-11-05 18:44:24,053 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3177 | Iter Mean Loss 11.3177
2020-11-05 18:44:24,062 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1751 | Iter Mean Loss 7.7464
2020-11-05 18:44:24,072 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5980 | Iter Mean Loss 12.0303
2020-11-05 18:44:24,080 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1911 | Iter Mean Loss 12.8205
2020-11-05 18:44:24,090 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4891 | Iter Mean Loss 12.7542
2020-11-05 18:44:24,093 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.2817 | MSE 0.4102
2020-11-05 18:44:24,103 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3212 | Iter Mean Loss 11.3212
2020-11-05 18:44:24,112 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1709 | Iter Mean Loss 7.7460
2020-11-05 18:44:24,122 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4897 | Iter Mean Loss 11.9939
2020-11-05 18:44:24,130 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1418 | Iter Mean Loss 12.7809
2020-11-05 18:44:24,140 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4274 | Iter Mean Loss 12.7102
2020-11-05 18:44:24,143 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.2817 | MSE 0.4095
2020-11-05 18:44:24,152 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3244 | Iter Mean Loss 11.3244
2020-11-05 18:44:24,162 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1666 | Iter Mean Loss 7.7455
2020-11-05 18:44:24,171 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3824 | Iter Mean Loss 11.9578
2020-11-05 18:44:24,180 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0928 | Iter Mean Loss 12.7416
2020-11-05 18:44:24,189 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3661 | Iter Mean Loss 12.6665
2020-11-05 18:44:24,192 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.2817 | MSE 0.4087
2020-11-05 18:44:24,202 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3273 | Iter Mean Loss 11.3273
2020-11-05 18:44:24,212 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1624 | Iter Mean Loss 7.7449
2020-11-05 18:44:24,223 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2759 | Iter Mean Loss 11.9219
2020-11-05 18:44:24,231 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0442 | Iter Mean Loss 12.7025
2020-11-05 18:44:24,243 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3051 | Iter Mean Loss 12.6230
2020-11-05 18:44:24,245 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.2817 | MSE 0.4079
2020-11-05 18:44:24,257 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3299 | Iter Mean Loss 11.3299
2020-11-05 18:44:24,266 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1582 | Iter Mean Loss 7.7440
2020-11-05 18:44:24,275 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1703 | Iter Mean Loss 11.8861
2020-11-05 18:44:24,283 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9960 | Iter Mean Loss 12.6636
2020-11-05 18:44:24,293 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.2444 | Iter Mean Loss 12.5798
2020-11-05 18:44:24,295 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.2817 | MSE 0.4072
2020-11-05 18:44:24,305 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3321 | Iter Mean Loss 11.3321
2020-11-05 18:44:24,314 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1540 | Iter Mean Loss 7.7431
2020-11-05 18:44:24,325 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0657 | Iter Mean Loss 11.8506
2020-11-05 18:44:24,333 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9480 | Iter Mean Loss 12.6250
2020-11-05 18:44:24,341 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1841 | Iter Mean Loss 12.5368
2020-11-05 18:44:24,343 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.2817 | MSE 0.4064
2020-11-05 18:44:24,351 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3340 | Iter Mean Loss 11.3340
2020-11-05 18:44:24,359 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1498 | Iter Mean Loss 7.7419
2020-11-05 18:44:24,366 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9620 | Iter Mean Loss 11.8153
2020-11-05 18:44:24,374 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9004 | Iter Mean Loss 12.5866
2020-11-05 18:44:24,381 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1242 | Iter Mean Loss 12.4941
2020-11-05 18:44:24,383 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.2817 | MSE 0.4056
2020-11-05 18:44:24,391 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3356 | Iter Mean Loss 11.3356
2020-11-05 18:44:24,399 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1456 | Iter Mean Loss 7.7406
2020-11-05 18:44:24,406 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8591 | Iter Mean Loss 11.7801
2020-11-05 18:44:24,414 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8532 | Iter Mean Loss 12.5484
2020-11-05 18:44:24,421 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0646 | Iter Mean Loss 12.4516
2020-11-05 18:44:24,423 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.2817 | MSE 0.4049
2020-11-05 18:44:24,431 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3368 | Iter Mean Loss 11.3368
2020-11-05 18:44:24,438 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1414 | Iter Mean Loss 7.7391
2020-11-05 18:44:24,446 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7571 | Iter Mean Loss 11.7451
2020-11-05 18:44:24,453 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8063 | Iter Mean Loss 12.5104
2020-11-05 18:44:24,460 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0053 | Iter Mean Loss 12.4094
2020-11-05 18:44:24,462 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.2817 | MSE 0.4042
2020-11-05 18:44:24,470 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3378 | Iter Mean Loss 11.3378
2020-11-05 18:44:24,477 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1372 | Iter Mean Loss 7.7375
2020-11-05 18:44:24,485 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6561 | Iter Mean Loss 11.7103
2020-11-05 18:44:24,492 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7597 | Iter Mean Loss 12.4727
2020-11-05 18:44:24,499 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.9465 | Iter Mean Loss 12.3674
2020-11-05 18:44:24,501 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.2817 | MSE 0.4034
2020-11-05 18:44:24,509 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3383 | Iter Mean Loss 11.3383
2020-11-05 18:44:24,517 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1330 | Iter Mean Loss 7.7357
2020-11-05 18:44:24,524 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5559 | Iter Mean Loss 11.6757
2020-11-05 18:44:24,531 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7135 | Iter Mean Loss 12.4352
2020-11-05 18:44:24,538 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8880 | Iter Mean Loss 12.3257
2020-11-05 18:44:24,540 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.2817 | MSE 0.4027
2020-11-05 18:44:24,548 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3386 | Iter Mean Loss 11.3386
2020-11-05 18:44:24,555 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 7.7337
2020-11-05 18:44:24,563 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4566 | Iter Mean Loss 11.6413
2020-11-05 18:44:24,570 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6676 | Iter Mean Loss 12.3979
2020-11-05 18:44:24,577 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8298 | Iter Mean Loss 12.2843
2020-11-05 18:44:24,579 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.2817 | MSE 0.4020
2020-11-05 18:44:24,587 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3385 | Iter Mean Loss 11.3385
2020-11-05 18:44:24,595 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1246 | Iter Mean Loss 7.7316
2020-11-05 18:44:24,603 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3582 | Iter Mean Loss 11.6071
2020-11-05 18:44:24,610 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6220 | Iter Mean Loss 12.3608
2020-11-05 18:44:24,617 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7720 | Iter Mean Loss 12.2431
2020-11-05 18:44:24,619 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.2817 | MSE 0.4012
2020-11-05 18:44:24,627 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3381 | Iter Mean Loss 11.3381
2020-11-05 18:44:24,635 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1204 | Iter Mean Loss 7.7293
2020-11-05 18:44:24,642 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2606 | Iter Mean Loss 11.5731
2020-11-05 18:44:24,649 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5767 | Iter Mean Loss 12.3240
2020-11-05 18:44:24,656 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7146 | Iter Mean Loss 12.2021
2020-11-05 18:44:24,658 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.2817 | MSE 0.4005
2020-11-05 18:44:24,666 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3374 | Iter Mean Loss 11.3374
2020-11-05 18:44:24,673 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1163 | Iter Mean Loss 7.7268
2020-11-05 18:44:24,681 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1639 | Iter Mean Loss 11.5392
2020-11-05 18:44:24,688 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5317 | Iter Mean Loss 12.2873
2020-11-05 18:44:24,695 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6576 | Iter Mean Loss 12.1614
2020-11-05 18:44:24,697 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.2817 | MSE 0.3998
2020-11-05 18:44:24,705 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3364 | Iter Mean Loss 11.3364
2020-11-05 18:44:24,712 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1121 | Iter Mean Loss 7.7242
2020-11-05 18:44:24,719 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0681 | Iter Mean Loss 11.5055
2020-11-05 18:44:24,727 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4871 | Iter Mean Loss 12.2509
2020-11-05 18:44:24,734 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6009 | Iter Mean Loss 12.1209
2020-11-05 18:44:24,736 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.2817 | MSE 0.3991
2020-11-05 18:44:24,744 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3350 | Iter Mean Loss 11.3350
2020-11-05 18:44:24,751 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1079 | Iter Mean Loss 7.7215
2020-11-05 18:44:24,758 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9731 | Iter Mean Loss 11.4720
2020-11-05 18:44:24,765 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4428 | Iter Mean Loss 12.2147
2020-11-05 18:44:24,773 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.5446 | Iter Mean Loss 12.0807
2020-11-05 18:44:24,775 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.2817 | MSE 0.3984
2020-11-05 18:44:24,782 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3334 | Iter Mean Loss 11.3334
2020-11-05 18:44:24,790 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1037 | Iter Mean Loss 7.7185
2020-11-05 18:44:24,797 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8790 | Iter Mean Loss 11.4387
2020-11-05 18:44:24,805 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3988 | Iter Mean Loss 12.1787
2020-11-05 18:44:24,812 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4887 | Iter Mean Loss 12.0407
2020-11-05 18:44:24,814 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.2817 | MSE 0.3977
2020-11-05 18:44:24,822 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3314 | Iter Mean Loss 11.3314
2020-11-05 18:44:24,830 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0995 | Iter Mean Loss 7.7154
2020-11-05 18:44:24,837 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7857 | Iter Mean Loss 11.4055
2020-11-05 18:44:24,845 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3551 | Iter Mean Loss 12.1429
2020-11-05 18:44:24,852 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4331 | Iter Mean Loss 12.0010
2020-11-05 18:44:24,854 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.2817 | MSE 0.3970
2020-11-05 18:44:24,862 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3290 | Iter Mean Loss 11.3290
2020-11-05 18:44:24,869 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0953 | Iter Mean Loss 7.7122
2020-11-05 18:44:24,876 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6933 | Iter Mean Loss 11.3726
2020-11-05 18:44:24,883 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3118 | Iter Mean Loss 12.1074
2020-11-05 18:44:24,891 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3779 | Iter Mean Loss 11.9615
2020-11-05 18:44:24,892 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.2817 | MSE 0.3963
2020-11-05 18:44:24,900 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3264 | Iter Mean Loss 11.3264
2020-11-05 18:44:24,908 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0911 | Iter Mean Loss 7.7088
2020-11-05 18:44:24,915 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6017 | Iter Mean Loss 11.3397
2020-11-05 18:44:24,922 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2687 | Iter Mean Loss 12.0720
2020-11-05 18:44:24,929 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3231 | Iter Mean Loss 11.9222
2020-11-05 18:44:24,931 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.2817 | MSE 0.3956
2020-11-05 18:44:24,939 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3235 | Iter Mean Loss 11.3235
2020-11-05 18:44:24,946 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0869 | Iter Mean Loss 7.7052
2020-11-05 18:44:24,954 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5109 | Iter Mean Loss 11.3071
2020-11-05 18:44:24,961 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2260 | Iter Mean Loss 12.0368
2020-11-05 18:44:24,968 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2687 | Iter Mean Loss 11.8832
2020-11-05 18:44:24,970 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.2817 | MSE 0.3950
2020-11-05 18:44:24,978 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3203 | Iter Mean Loss 11.3203
2020-11-05 18:44:24,985 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0827 | Iter Mean Loss 7.7015
2020-11-05 18:44:24,992 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4210 | Iter Mean Loss 11.2746
2020-11-05 18:44:25,000 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1835 | Iter Mean Loss 12.0019
2020-11-05 18:44:25,007 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2146 | Iter Mean Loss 11.8444
2020-11-05 18:44:25,009 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.2817 | MSE 0.3943
2020-11-05 18:44:25,017 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3167 | Iter Mean Loss 11.3167
2020-11-05 18:44:25,024 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0785 | Iter Mean Loss 7.6976
2020-11-05 18:44:25,031 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3319 | Iter Mean Loss 11.2424
2020-11-05 18:44:25,038 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1414 | Iter Mean Loss 11.9671
2020-11-05 18:44:25,046 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1609 | Iter Mean Loss 11.8059
2020-11-05 18:44:25,048 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.2817 | MSE 0.3936
2020-11-05 18:44:25,055 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3129 | Iter Mean Loss 11.3129
2020-11-05 18:44:25,063 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0743 | Iter Mean Loss 7.6936
2020-11-05 18:44:25,070 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.2102
2020-11-05 18:44:25,077 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0995 | Iter Mean Loss 11.9325
2020-11-05 18:44:25,084 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.7676
2020-11-05 18:44:25,086 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.2817 | MSE 0.3930
2020-11-05 18:44:25,094 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3087 | Iter Mean Loss 11.3087
2020-11-05 18:44:25,101 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0700 | Iter Mean Loss 7.6894
2020-11-05 18:44:25,108 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1560 | Iter Mean Loss 11.1783
2020-11-05 18:44:25,115 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0579 | Iter Mean Loss 11.8982
2020-11-05 18:44:25,123 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0547 | Iter Mean Loss 11.7295
2020-11-05 18:44:25,125 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.2817 | MSE 0.3923
2020-11-05 18:44:25,133 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 11.3043
2020-11-05 18:44:25,140 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 7.6850
2020-11-05 18:44:25,147 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0693 | Iter Mean Loss 11.1465
2020-11-05 18:44:25,154 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0167 | Iter Mean Loss 11.8640
2020-11-05 18:44:25,161 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0022 | Iter Mean Loss 11.6917
2020-11-05 18:44:25,163 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.2817 | MSE 0.3917
2020-11-05 18:44:25,171 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2995 | Iter Mean Loss 11.2995
2020-11-05 18:44:25,179 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0615 | Iter Mean Loss 7.6805
2020-11-05 18:44:25,186 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9834 | Iter Mean Loss 11.1148
2020-11-05 18:44:25,193 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9757 | Iter Mean Loss 11.8301
2020-11-05 18:44:25,200 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.9500 | Iter Mean Loss 11.6540
2020-11-05 18:44:25,202 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.2817 | MSE 0.3910
2020-11-05 18:44:25,210 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 11.2945
2020-11-05 18:44:25,217 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0573 | Iter Mean Loss 7.6759
2020-11-05 18:44:25,224 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8983 | Iter Mean Loss 11.0834
2020-11-05 18:44:25,232 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9350 | Iter Mean Loss 11.7963
2020-11-05 18:44:25,239 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8983 | Iter Mean Loss 11.6167
2020-11-05 18:44:25,241 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.2817 | MSE 0.3904
2020-11-05 18:44:25,250 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2892 | Iter Mean Loss 11.2892
2020-11-05 18:44:25,260 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0530 | Iter Mean Loss 7.6711
2020-11-05 18:44:25,270 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8140 | Iter Mean Loss 11.0521
2020-11-05 18:44:25,280 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8946 | Iter Mean Loss 11.7627
2020-11-05 18:44:25,289 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8469 | Iter Mean Loss 11.5795
2020-11-05 18:44:25,291 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.2817 | MSE 0.3898
2020-11-05 18:44:25,300 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2836 | Iter Mean Loss 11.2836
2020-11-05 18:44:25,310 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0487 | Iter Mean Loss 7.6661
2020-11-05 18:44:25,322 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7304 | Iter Mean Loss 11.0209
2020-11-05 18:44:25,332 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8545 | Iter Mean Loss 11.7293
2020-11-05 18:44:25,345 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7959 | Iter Mean Loss 11.5426
2020-11-05 18:44:25,347 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.2817 | MSE 0.3891
2020-11-05 18:44:25,359 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2777 | Iter Mean Loss 11.2777
2020-11-05 18:44:25,370 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0445 | Iter Mean Loss 7.6611
2020-11-05 18:44:25,382 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6476 | Iter Mean Loss 10.9899
2020-11-05 18:44:25,394 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8146 | Iter Mean Loss 11.6961
2020-11-05 18:44:25,405 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7453 | Iter Mean Loss 11.5059
2020-11-05 18:44:25,408 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.2817 | MSE 0.3885
2020-11-05 18:44:25,418 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2715 | Iter Mean Loss 11.2715
2020-11-05 18:44:25,428 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0402 | Iter Mean Loss 7.6558
2020-11-05 18:44:25,437 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5656 | Iter Mean Loss 10.9591
2020-11-05 18:44:25,446 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7750 | Iter Mean Loss 11.6631
2020-11-05 18:44:25,456 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6950 | Iter Mean Loss 11.4695
2020-11-05 18:44:25,458 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.2817 | MSE 0.3879
2020-11-05 18:44:25,467 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2650 | Iter Mean Loss 11.2650
2020-11-05 18:44:25,477 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0358 | Iter Mean Loss 7.6504
2020-11-05 18:44:25,485 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4844 | Iter Mean Loss 10.9284
2020-11-05 18:44:25,494 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7357 | Iter Mean Loss 11.6302
2020-11-05 18:44:25,503 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6452 | Iter Mean Loss 11.4332
2020-11-05 18:44:25,506 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.2817 | MSE 0.3873
2020-11-05 18:44:25,514 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2583 | Iter Mean Loss 11.2583
2020-11-05 18:44:25,524 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0315 | Iter Mean Loss 7.6449
2020-11-05 18:44:25,532 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4038 | Iter Mean Loss 10.8979
2020-11-05 18:44:25,541 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6967 | Iter Mean Loss 11.5976
2020-11-05 18:44:25,549 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5957 | Iter Mean Loss 11.3972
2020-11-05 18:44:25,553 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.2817 | MSE 0.3867
2020-11-05 18:44:25,562 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2513 | Iter Mean Loss 11.2513
2020-11-05 18:44:25,572 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 7.6392
2020-11-05 18:44:25,580 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3241 | Iter Mean Loss 10.8675
2020-11-05 18:44:25,590 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6579 | Iter Mean Loss 11.5651
2020-11-05 18:44:25,598 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5466 | Iter Mean Loss 11.3614
2020-11-05 18:44:25,600 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.2817 | MSE 0.3860
2020-11-05 18:44:25,610 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2440 | Iter Mean Loss 11.2440
2020-11-05 18:44:25,618 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0228 | Iter Mean Loss 7.6334
2020-11-05 18:44:25,627 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2451 | Iter Mean Loss 10.8373
2020-11-05 18:44:25,636 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6194 | Iter Mean Loss 11.5328
2020-11-05 18:44:25,645 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4979 | Iter Mean Loss 11.3258
2020-11-05 18:44:25,647 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.2817 | MSE 0.3854
2020-11-05 18:44:25,656 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2365 | Iter Mean Loss 11.2365
2020-11-05 18:44:25,664 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0185 | Iter Mean Loss 7.6275
2020-11-05 18:44:25,674 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1668 | Iter Mean Loss 10.8072
2020-11-05 18:44:25,681 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5811 | Iter Mean Loss 11.5007
2020-11-05 18:44:25,690 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4496 | Iter Mean Loss 11.2905
2020-11-05 18:44:25,693 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.2817 | MSE 0.3848
2020-11-05 18:44:25,702 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2287 | Iter Mean Loss 11.2287
2020-11-05 18:44:25,711 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 7.6214
2020-11-05 18:44:25,719 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0892 | Iter Mean Loss 10.7773
2020-11-05 18:44:25,728 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5431 | Iter Mean Loss 11.4688
2020-11-05 18:44:25,736 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4017 | Iter Mean Loss 11.2553
2020-11-05 18:44:25,739 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.2817 | MSE 0.3843
2020-11-05 18:44:25,748 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2206 | Iter Mean Loss 11.2206
2020-11-05 18:44:25,757 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0097 | Iter Mean Loss 7.6152
2020-11-05 18:44:25,765 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0124 | Iter Mean Loss 10.7476
2020-11-05 18:44:25,773 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5053 | Iter Mean Loss 11.4370
2020-11-05 18:44:25,781 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3541 | Iter Mean Loss 11.2204
2020-11-05 18:44:25,784 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.2817 | MSE 0.3837
2020-11-05 18:44:25,794 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2123 | Iter Mean Loss 11.2123
2020-11-05 18:44:25,802 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0053 | Iter Mean Loss 7.6088
2020-11-05 18:44:25,811 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9363 | Iter Mean Loss 10.7179
2020-11-05 18:44:25,819 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4678 | Iter Mean Loss 11.4054
2020-11-05 18:44:25,829 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3070 | Iter Mean Loss 11.1857
2020-11-05 18:44:25,831 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.2817 | MSE 0.3831
2020-11-05 18:44:25,841 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2037 | Iter Mean Loss 11.2037
2020-11-05 18:44:25,849 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0009 | Iter Mean Loss 7.6023
2020-11-05 18:44:25,859 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8608 | Iter Mean Loss 10.6885
2020-11-05 18:44:25,866 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4305 | Iter Mean Loss 11.3740
2020-11-05 18:44:25,876 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2602 | Iter Mean Loss 11.1512
2020-11-05 18:44:25,879 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.2817 | MSE 0.3825
2020-11-05 18:44:25,889 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1949 | Iter Mean Loss 11.1949
2020-11-05 18:44:25,897 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9964 | Iter Mean Loss 7.5957
2020-11-05 18:44:25,906 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7861 | Iter Mean Loss 10.6591
2020-11-05 18:44:25,914 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3934 | Iter Mean Loss 11.3427
2020-11-05 18:44:25,924 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2138 | Iter Mean Loss 11.1169
2020-11-05 18:44:25,926 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.2817 | MSE 0.3819
2020-11-05 18:44:25,935 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1858 | Iter Mean Loss 11.1858
2020-11-05 18:44:25,945 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9920 | Iter Mean Loss 7.5889
2020-11-05 18:44:25,953 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7121 | Iter Mean Loss 10.6300
2020-11-05 18:44:25,962 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3566 | Iter Mean Loss 11.3116
2020-11-05 18:44:25,970 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1677 | Iter Mean Loss 11.0829
2020-11-05 18:44:25,973 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.2817 | MSE 0.3813
2020-11-05 18:44:25,981 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1765 | Iter Mean Loss 11.1765
2020-11-05 18:44:25,990 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9875 | Iter Mean Loss 7.5820
2020-11-05 18:44:25,998 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6388 | Iter Mean Loss 10.6009
2020-11-05 18:44:26,008 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3200 | Iter Mean Loss 11.2807
2020-11-05 18:44:26,017 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1221 | Iter Mean Loss 11.0490
2020-11-05 18:44:26,021 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.2817 | MSE 0.3808
2020-11-05 18:44:26,030 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1669 | Iter Mean Loss 11.1669
2020-11-05 18:44:26,040 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9830 | Iter Mean Loss 7.5750
2020-11-05 18:44:26,049 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5662 | Iter Mean Loss 10.5720
2020-11-05 18:44:26,059 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2837 | Iter Mean Loss 11.2499
2020-11-05 18:44:26,069 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0768 | Iter Mean Loss 11.0153
2020-11-05 18:44:26,073 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.2817 | MSE 0.3802
2020-11-05 18:44:26,083 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1571 | Iter Mean Loss 11.1571
2020-11-05 18:44:26,093 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 7.5678
2020-11-05 18:44:26,102 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4942 | Iter Mean Loss 10.5433
2020-11-05 18:44:26,112 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2475 | Iter Mean Loss 11.2193
2020-11-05 18:44:26,121 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0319 | Iter Mean Loss 10.9818
2020-11-05 18:44:26,124 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.2817 | MSE 0.3797
2020-11-05 18:44:26,133 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1471 | Iter Mean Loss 11.1471
2020-11-05 18:44:26,143 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9740 | Iter Mean Loss 7.5605
2020-11-05 18:44:26,151 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4229 | Iter Mean Loss 10.5146
2020-11-05 18:44:26,161 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2116 | Iter Mean Loss 11.1889
2020-11-05 18:44:26,171 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9874 | Iter Mean Loss 10.9486
2020-11-05 18:44:26,174 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.2817 | MSE 0.3791
2020-11-05 18:44:26,183 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1368 | Iter Mean Loss 11.1368
2020-11-05 18:44:26,193 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9694 | Iter Mean Loss 7.5531
2020-11-05 18:44:26,202 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3523 | Iter Mean Loss 10.4861
2020-11-05 18:44:26,211 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1758 | Iter Mean Loss 11.1586
2020-11-05 18:44:26,221 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9432 | Iter Mean Loss 10.9155
2020-11-05 18:44:26,224 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.2817 | MSE 0.3786
2020-11-05 18:44:26,232 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1263 | Iter Mean Loss 11.1263
2020-11-05 18:44:26,243 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9648 | Iter Mean Loss 7.5456
2020-11-05 18:44:26,251 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2823 | Iter Mean Loss 10.4578
2020-11-05 18:44:26,261 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1403 | Iter Mean Loss 11.1284
2020-11-05 18:44:26,269 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8995 | Iter Mean Loss 10.8826
2020-11-05 18:44:26,273 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.2817 | MSE 0.3780
2020-11-05 18:44:26,282 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1155 | Iter Mean Loss 11.1155
2020-11-05 18:44:26,293 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9603 | Iter Mean Loss 7.5379
2020-11-05 18:44:26,301 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2130 | Iter Mean Loss 10.4296
2020-11-05 18:44:26,311 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1050 | Iter Mean Loss 11.0984
2020-11-05 18:44:26,322 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8560 | Iter Mean Loss 10.8499
2020-11-05 18:44:26,325 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.2817 | MSE 0.3775
2020-11-05 18:44:26,334 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1045 | Iter Mean Loss 11.1045
2020-11-05 18:44:26,343 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9556 | Iter Mean Loss 7.5301
2020-11-05 18:44:26,351 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1443 | Iter Mean Loss 10.4015
2020-11-05 18:44:26,358 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0698 | Iter Mean Loss 11.0686
2020-11-05 18:44:26,366 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8130 | Iter Mean Loss 10.8175
2020-11-05 18:44:26,369 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.2817 | MSE 0.3769
2020-11-05 18:44:26,380 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0934 | Iter Mean Loss 11.0934
2020-11-05 18:44:26,389 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9510 | Iter Mean Loss 7.5222
2020-11-05 18:44:26,397 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0763 | Iter Mean Loss 10.3735
2020-11-05 18:44:26,405 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0349 | Iter Mean Loss 11.0389
2020-11-05 18:44:26,415 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7703 | Iter Mean Loss 10.7852
2020-11-05 18:44:26,417 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.2817 | MSE 0.3764
2020-11-05 18:44:26,426 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0819 | Iter Mean Loss 11.0819
2020-11-05 18:44:26,434 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9464 | Iter Mean Loss 7.5141
2020-11-05 18:44:26,443 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0088 | Iter Mean Loss 10.3457
2020-11-05 18:44:26,451 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0002 | Iter Mean Loss 11.0093
2020-11-05 18:44:26,463 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7280 | Iter Mean Loss 10.7531
2020-11-05 18:44:26,466 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.2817 | MSE 0.3759
2020-11-05 18:44:26,476 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0703 | Iter Mean Loss 11.0703
2020-11-05 18:44:26,488 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9417 | Iter Mean Loss 7.5060
2020-11-05 18:44:26,500 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9421 | Iter Mean Loss 10.3180
2020-11-05 18:44:26,512 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9656 | Iter Mean Loss 10.9799
2020-11-05 18:44:26,524 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 10.7211
2020-11-05 18:44:26,529 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.2817 | MSE 0.3753
2020-11-05 18:44:26,542 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0585 | Iter Mean Loss 11.0585
2020-11-05 18:44:26,552 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 7.4977
2020-11-05 18:44:26,563 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8759 | Iter Mean Loss 10.2904
2020-11-05 18:44:26,576 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9312 | Iter Mean Loss 10.9506
2020-11-05 18:44:26,587 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6444 | Iter Mean Loss 10.6894
2020-11-05 18:44:26,593 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.2817 | MSE 0.3748
2020-11-05 18:44:26,606 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0464 | Iter Mean Loss 11.0464
2020-11-05 18:44:26,618 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9323 | Iter Mean Loss 7.4893
2020-11-05 18:44:26,629 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.2630
2020-11-05 18:44:26,639 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8970 | Iter Mean Loss 10.9215
2020-11-05 18:44:26,649 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6031 | Iter Mean Loss 10.6578
2020-11-05 18:44:26,653 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.2817 | MSE 0.3743
2020-11-05 18:44:26,666 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0341 | Iter Mean Loss 11.0341
2020-11-05 18:44:26,677 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9275 | Iter Mean Loss 7.4808
2020-11-05 18:44:26,690 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7454 | Iter Mean Loss 10.2357
2020-11-05 18:44:26,703 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8630 | Iter Mean Loss 10.8925
2020-11-05 18:44:26,715 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5622 | Iter Mean Loss 10.6264
2020-11-05 18:44:26,718 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.2817 | MSE 0.3738
2020-11-05 18:44:26,729 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0216 | Iter Mean Loss 11.0216
2020-11-05 18:44:26,743 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9228 | Iter Mean Loss 7.4722
2020-11-05 18:44:26,754 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6810 | Iter Mean Loss 10.2085
2020-11-05 18:44:26,764 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8291 | Iter Mean Loss 10.8636
2020-11-05 18:44:26,776 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5216 | Iter Mean Loss 10.5952
2020-11-05 18:44:26,781 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.2817 | MSE 0.3733
2020-11-05 18:44:26,793 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0089 | Iter Mean Loss 11.0089
2020-11-05 18:44:26,804 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9180 | Iter Mean Loss 7.4635
2020-11-05 18:44:26,815 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6173 | Iter Mean Loss 10.1814
2020-11-05 18:44:26,830 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7954 | Iter Mean Loss 10.8349
2020-11-05 18:44:26,840 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4813 | Iter Mean Loss 10.5642
2020-11-05 18:44:26,843 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.2817 | MSE 0.3727
2020-11-05 18:44:26,854 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9961 | Iter Mean Loss 10.9961
2020-11-05 18:44:26,866 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9132 | Iter Mean Loss 7.4546
2020-11-05 18:44:26,876 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5541 | Iter Mean Loss 10.1544
2020-11-05 18:44:26,886 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7618 | Iter Mean Loss 10.8063
2020-11-05 18:44:26,895 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4415 | Iter Mean Loss 10.5333
2020-11-05 18:44:26,898 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.2817 | MSE 0.3722
2020-11-05 18:44:26,907 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9830 | Iter Mean Loss 10.9830
2020-11-05 18:44:26,917 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9083 | Iter Mean Loss 7.4456
2020-11-05 18:44:26,924 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4915 | Iter Mean Loss 10.1276
2020-11-05 18:44:26,932 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7284 | Iter Mean Loss 10.7778
2020-11-05 18:44:26,942 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4019 | Iter Mean Loss 10.5026
2020-11-05 18:44:26,947 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.2817 | MSE 0.3717
2020-11-05 18:44:26,956 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9697 | Iter Mean Loss 10.9697
2020-11-05 18:44:26,964 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 7.4366
2020-11-05 18:44:26,972 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4295 | Iter Mean Loss 10.1009
2020-11-05 18:44:26,980 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6952 | Iter Mean Loss 10.7494
2020-11-05 18:44:26,988 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3627 | Iter Mean Loss 10.4721
2020-11-05 18:44:26,991 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.2817 | MSE 0.3712
2020-11-05 18:44:26,999 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9562 | Iter Mean Loss 10.9562
2020-11-05 18:44:27,007 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8986 | Iter Mean Loss 7.4274
2020-11-05 18:44:27,015 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3680 | Iter Mean Loss 10.0742
2020-11-05 18:44:27,023 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6621 | Iter Mean Loss 10.7212
2020-11-05 18:44:27,032 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3238 | Iter Mean Loss 10.4417
2020-11-05 18:44:27,034 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.2817 | MSE 0.3708
2020-11-05 18:44:27,043 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9425 | Iter Mean Loss 10.9425
2020-11-05 18:44:27,051 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8936 | Iter Mean Loss 7.4181
2020-11-05 18:44:27,059 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3071 | Iter Mean Loss 10.0477
2020-11-05 18:44:27,068 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6291 | Iter Mean Loss 10.6931
2020-11-05 18:44:27,078 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2852 | Iter Mean Loss 10.4115
2020-11-05 18:44:27,080 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.2817 | MSE 0.3703
2020-11-05 18:44:27,090 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9286 | Iter Mean Loss 10.9286
2020-11-05 18:44:27,098 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8887 | Iter Mean Loss 7.4086
2020-11-05 18:44:27,106 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2467 | Iter Mean Loss 10.0213
2020-11-05 18:44:27,114 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5963 | Iter Mean Loss 10.6651
2020-11-05 18:44:27,122 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2470 | Iter Mean Loss 10.3815
2020-11-05 18:44:27,124 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.2817 | MSE 0.3698
2020-11-05 18:44:27,133 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9145 | Iter Mean Loss 10.9145
2020-11-05 18:44:27,141 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8837 | Iter Mean Loss 7.3991
2020-11-05 18:44:27,149 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1869 | Iter Mean Loss 9.9951
2020-11-05 18:44:27,157 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5636 | Iter Mean Loss 10.6372
2020-11-05 18:44:27,165 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2090 | Iter Mean Loss 10.3516
2020-11-05 18:44:27,167 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.2817 | MSE 0.3693
2020-11-05 18:44:27,175 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9003 | Iter Mean Loss 10.9003
2020-11-05 18:44:27,183 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8787 | Iter Mean Loss 7.3895
2020-11-05 18:44:27,191 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1276 | Iter Mean Loss 9.9689
2020-11-05 18:44:27,199 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5310 | Iter Mean Loss 10.6094
2020-11-05 18:44:27,207 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1714 | Iter Mean Loss 10.3218
2020-11-05 18:44:27,209 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.2817 | MSE 0.3688
2020-11-05 18:44:27,218 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8858 | Iter Mean Loss 10.8858
2020-11-05 18:44:27,226 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 7.3798
2020-11-05 18:44:27,236 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0689 | Iter Mean Loss 9.9428
2020-11-05 18:44:27,245 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4986 | Iter Mean Loss 10.5818
2020-11-05 18:44:27,253 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1341 | Iter Mean Loss 10.2922
2020-11-05 18:44:27,255 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.2817 | MSE 0.3683
2020-11-05 18:44:27,264 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 18:44:27,272 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8686 | Iter Mean Loss 7.3699
2020-11-05 18:44:27,280 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0107 | Iter Mean Loss 9.9168
2020-11-05 18:44:27,290 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4663 | Iter Mean Loss 10.5542
2020-11-05 18:44:27,300 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0971 | Iter Mean Loss 10.2628
2020-11-05 18:44:27,303 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.2817 | MSE 0.3679
2020-11-05 18:44:27,311 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8564 | Iter Mean Loss 10.8564
2020-11-05 18:44:27,321 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8635 | Iter Mean Loss 7.3600
2020-11-05 18:44:27,331 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9530 | Iter Mean Loss 9.8910
2020-11-05 18:44:27,343 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4341 | Iter Mean Loss 10.5268
2020-11-05 18:44:27,352 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0604 | Iter Mean Loss 10.2335
2020-11-05 18:44:27,357 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.2817 | MSE 0.3674
2020-11-05 18:44:27,366 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8414 | Iter Mean Loss 10.8414
2020-11-05 18:44:27,378 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8584 | Iter Mean Loss 7.3499
2020-11-05 18:44:27,388 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8958 | Iter Mean Loss 9.8652
2020-11-05 18:44:27,399 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4020 | Iter Mean Loss 10.4994
2020-11-05 18:44:27,409 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0240 | Iter Mean Loss 10.2043
2020-11-05 18:44:27,413 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.2817 | MSE 0.3669
2020-11-05 18:44:27,423 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8262 | Iter Mean Loss 10.8262
2020-11-05 18:44:27,433 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8533 | Iter Mean Loss 7.3398
2020-11-05 18:44:27,444 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8391 | Iter Mean Loss 9.8395
2020-11-05 18:44:27,453 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3701 | Iter Mean Loss 10.4722
2020-11-05 18:44:27,464 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9879 | Iter Mean Loss 10.1753
2020-11-05 18:44:27,467 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.2817 | MSE 0.3665
2020-11-05 18:44:27,478 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:44:27,488 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8481 | Iter Mean Loss 7.3295
2020-11-05 18:44:27,498 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7829 | Iter Mean Loss 9.8140
2020-11-05 18:44:27,508 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3383 | Iter Mean Loss 10.4450
2020-11-05 18:44:27,518 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9521 | Iter Mean Loss 10.1464
2020-11-05 18:44:27,521 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.2817 | MSE 0.3660
2020-11-05 18:44:27,532 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7954 | Iter Mean Loss 10.7954
2020-11-05 18:44:27,541 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8429 | Iter Mean Loss 7.3191
2020-11-05 18:44:27,552 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7272 | Iter Mean Loss 9.7885
2020-11-05 18:44:27,561 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3065 | Iter Mean Loss 10.4180
2020-11-05 18:44:27,572 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9165 | Iter Mean Loss 10.1177
2020-11-05 18:44:27,575 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.2817 | MSE 0.3655
2020-11-05 18:44:27,586 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7797 | Iter Mean Loss 10.7797
2020-11-05 18:44:27,597 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8377 | Iter Mean Loss 7.3087
2020-11-05 18:44:27,607 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6720 | Iter Mean Loss 9.7631
2020-11-05 18:44:27,617 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2749 | Iter Mean Loss 10.3911
2020-11-05 18:44:27,626 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8813 | Iter Mean Loss 10.0891
2020-11-05 18:44:27,630 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.2817 | MSE 0.3651
2020-11-05 18:44:27,640 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7638 | Iter Mean Loss 10.7638
2020-11-05 18:44:27,650 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8324 | Iter Mean Loss 7.2981
2020-11-05 18:44:27,661 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6173 | Iter Mean Loss 9.7378
2020-11-05 18:44:27,671 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2434 | Iter Mean Loss 10.3642
2020-11-05 18:44:27,681 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8463 | Iter Mean Loss 10.0606
2020-11-05 18:44:27,684 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.2817 | MSE 0.3646
2020-11-05 18:44:27,695 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7478 | Iter Mean Loss 10.7478
2020-11-05 18:44:27,706 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8271 | Iter Mean Loss 7.2874
2020-11-05 18:44:27,716 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5630 | Iter Mean Loss 9.7126
2020-11-05 18:44:27,727 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2119 | Iter Mean Loss 10.3374
2020-11-05 18:44:27,740 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8116 | Iter Mean Loss 10.0323
2020-11-05 18:44:27,742 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.2817 | MSE 0.3642
2020-11-05 18:44:27,754 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7316 | Iter Mean Loss 10.7316
2020-11-05 18:44:27,765 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8218 | Iter Mean Loss 7.2767
2020-11-05 18:44:27,774 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5092 | Iter Mean Loss 9.6875
2020-11-05 18:44:27,785 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1806 | Iter Mean Loss 10.3108
2020-11-05 18:44:27,793 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7772 | Iter Mean Loss 10.0041
2020-11-05 18:44:27,798 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.2817 | MSE 0.3638
2020-11-05 18:44:27,811 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7152 | Iter Mean Loss 10.7152
2020-11-05 18:44:27,823 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8164 | Iter Mean Loss 7.2658
2020-11-05 18:44:27,833 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4559 | Iter Mean Loss 9.6625
2020-11-05 18:44:27,842 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1494 | Iter Mean Loss 10.2842
2020-11-05 18:44:27,853 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7431 | Iter Mean Loss 9.9760
2020-11-05 18:44:27,855 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.2817 | MSE 0.3633
2020-11-05 18:44:27,866 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6986 | Iter Mean Loss 10.6986
2020-11-05 18:44:27,875 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8110 | Iter Mean Loss 7.2548
2020-11-05 18:44:27,885 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4030 | Iter Mean Loss 9.6375
2020-11-05 18:44:27,894 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1182 | Iter Mean Loss 10.2577
2020-11-05 18:44:27,904 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7092 | Iter Mean Loss 9.9480
2020-11-05 18:44:27,906 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.2817 | MSE 0.3629
2020-11-05 18:44:27,917 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6819 | Iter Mean Loss 10.6819
2020-11-05 18:44:27,926 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8056 | Iter Mean Loss 7.2438
2020-11-05 18:44:27,936 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3506 | Iter Mean Loss 9.6127
2020-11-05 18:44:27,944 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0872 | Iter Mean Loss 10.2313
2020-11-05 18:44:27,954 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6755 | Iter Mean Loss 9.9202
2020-11-05 18:44:27,956 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.2817 | MSE 0.3624
2020-11-05 18:44:27,966 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6651 | Iter Mean Loss 10.6651
2020-11-05 18:44:27,975 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8001 | Iter Mean Loss 7.2326
2020-11-05 18:44:27,985 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2986 | Iter Mean Loss 9.5879
2020-11-05 18:44:27,993 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0562 | Iter Mean Loss 10.2050
2020-11-05 18:44:28,003 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6422 | Iter Mean Loss 9.8924
2020-11-05 18:44:28,006 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.2817 | MSE 0.3620
2020-11-05 18:44:28,016 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6480 | Iter Mean Loss 10.6480
2020-11-05 18:44:28,025 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7946 | Iter Mean Loss 7.2213
2020-11-05 18:44:28,035 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2470 | Iter Mean Loss 9.5632
2020-11-05 18:44:28,044 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0253 | Iter Mean Loss 10.1787
2020-11-05 18:44:28,055 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6090 | Iter Mean Loss 9.8648
2020-11-05 18:44:28,057 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.2817 | MSE 0.3616
2020-11-05 18:44:28,068 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6309 | Iter Mean Loss 10.6309
2020-11-05 18:44:28,077 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7891 | Iter Mean Loss 7.2100
2020-11-05 18:44:28,088 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1959 | Iter Mean Loss 9.5386
2020-11-05 18:44:28,098 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9945 | Iter Mean Loss 10.1526
2020-11-05 18:44:28,107 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5762 | Iter Mean Loss 9.8373
2020-11-05 18:44:28,109 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.2817 | MSE 0.3612
2020-11-05 18:44:28,121 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6135 | Iter Mean Loss 10.6135
2020-11-05 18:44:28,129 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7835 | Iter Mean Loss 7.1985
2020-11-05 18:44:28,140 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1451 | Iter Mean Loss 9.5141
2020-11-05 18:44:28,148 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9638 | Iter Mean Loss 10.1265
2020-11-05 18:44:28,157 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 9.8099
2020-11-05 18:44:28,160 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.2817 | MSE 0.3607
2020-11-05 18:44:28,170 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5960 | Iter Mean Loss 10.5960
2020-11-05 18:44:28,179 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7779 | Iter Mean Loss 7.1869
2020-11-05 18:44:28,189 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0949 | Iter Mean Loss 9.4896
2020-11-05 18:44:28,197 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9331 | Iter Mean Loss 10.1005
2020-11-05 18:44:28,207 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5111 | Iter Mean Loss 9.7826
2020-11-05 18:44:28,209 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.2817 | MSE 0.3603
2020-11-05 18:44:28,220 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5783 | Iter Mean Loss 10.5783
2020-11-05 18:44:28,229 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 7.1753
2020-11-05 18:44:28,240 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0450 | Iter Mean Loss 9.4652
2020-11-05 18:44:28,250 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9026 | Iter Mean Loss 10.0745
2020-11-05 18:44:28,259 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4790 | Iter Mean Loss 9.7554
2020-11-05 18:44:28,262 - root - INFO - Evaluate: Epoch 0285 | NDCG 1.0000 | MSE 0.3599
2020-11-05 18:44:28,272 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5605 | Iter Mean Loss 10.5605
2020-11-05 18:44:28,282 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7666 | Iter Mean Loss 7.1636
2020-11-05 18:44:28,292 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9955 | Iter Mean Loss 9.4409
2020-11-05 18:44:28,301 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8721 | Iter Mean Loss 10.0487
2020-11-05 18:44:28,310 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4471 | Iter Mean Loss 9.7283
2020-11-05 18:44:28,315 - root - INFO - Evaluate: Epoch 0286 | NDCG 1.0000 | MSE 0.3595
2020-11-05 18:44:28,326 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5426 | Iter Mean Loss 10.5426
2020-11-05 18:44:28,337 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7609 | Iter Mean Loss 7.1517
2020-11-05 18:44:28,346 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9464 | Iter Mean Loss 9.4166
2020-11-05 18:44:28,356 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8416 | Iter Mean Loss 10.0229
2020-11-05 18:44:28,366 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 9.7014
2020-11-05 18:44:28,369 - root - INFO - Evaluate: Epoch 0287 | NDCG 1.0000 | MSE 0.3591
2020-11-05 18:44:28,380 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5244 | Iter Mean Loss 10.5244
2020-11-05 18:44:28,392 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7551 | Iter Mean Loss 7.1398
2020-11-05 18:44:28,401 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8977 | Iter Mean Loss 9.3924
2020-11-05 18:44:28,411 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8113 | Iter Mean Loss 9.9971
2020-11-05 18:44:28,420 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3839 | Iter Mean Loss 9.6745
2020-11-05 18:44:28,423 - root - INFO - Evaluate: Epoch 0288 | NDCG 1.0000 | MSE 0.3587
2020-11-05 18:44:28,435 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5062 | Iter Mean Loss 10.5062
2020-11-05 18:44:28,446 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7493 | Iter Mean Loss 7.1278
2020-11-05 18:44:28,455 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8494 | Iter Mean Loss 9.3683
2020-11-05 18:44:28,463 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7810 | Iter Mean Loss 9.9715
2020-11-05 18:44:28,472 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3526 | Iter Mean Loss 9.6477
2020-11-05 18:44:28,474 - root - INFO - Evaluate: Epoch 0289 | NDCG 1.0000 | MSE 0.3583
2020-11-05 18:44:28,483 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4878 | Iter Mean Loss 10.4878
2020-11-05 18:44:28,492 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7435 | Iter Mean Loss 7.1156
2020-11-05 18:44:28,501 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8015 | Iter Mean Loss 9.3442
2020-11-05 18:44:28,509 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7508 | Iter Mean Loss 9.9459
2020-11-05 18:44:28,517 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3216 | Iter Mean Loss 9.6210
2020-11-05 18:44:28,519 - root - INFO - Evaluate: Epoch 0290 | NDCG 1.0000 | MSE 0.3579
2020-11-05 18:44:28,529 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4692 | Iter Mean Loss 10.4692
2020-11-05 18:44:28,538 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7376 | Iter Mean Loss 7.1034
2020-11-05 18:44:28,547 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7539 | Iter Mean Loss 9.3203
2020-11-05 18:44:28,555 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7206 | Iter Mean Loss 9.9203
2020-11-05 18:44:28,563 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2908 | Iter Mean Loss 9.5944
2020-11-05 18:44:28,565 - root - INFO - Evaluate: Epoch 0291 | NDCG 1.0000 | MSE 0.3575
2020-11-05 18:44:28,573 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4505 | Iter Mean Loss 10.4505
2020-11-05 18:44:28,581 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7318 | Iter Mean Loss 7.0911
2020-11-05 18:44:28,589 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7068 | Iter Mean Loss 9.2963
2020-11-05 18:44:28,597 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6905 | Iter Mean Loss 9.8949
2020-11-05 18:44:28,606 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2602 | Iter Mean Loss 9.5679
2020-11-05 18:44:28,608 - root - INFO - Evaluate: Epoch 0292 | NDCG 1.0000 | MSE 0.3571
2020-11-05 18:44:28,616 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4316 | Iter Mean Loss 10.4316
2020-11-05 18:44:28,624 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7258 | Iter Mean Loss 7.0787
2020-11-05 18:44:28,633 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6599 | Iter Mean Loss 9.2725
2020-11-05 18:44:28,641 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6605 | Iter Mean Loss 9.8695
2020-11-05 18:44:28,649 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2298 | Iter Mean Loss 9.5415
2020-11-05 18:44:28,652 - root - INFO - Evaluate: Epoch 0293 | NDCG 1.0000 | MSE 0.3567
2020-11-05 18:44:28,662 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4126 | Iter Mean Loss 10.4126
2020-11-05 18:44:28,670 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7198 | Iter Mean Loss 7.0662
2020-11-05 18:44:28,679 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6135 | Iter Mean Loss 9.2486
2020-11-05 18:44:28,688 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6305 | Iter Mean Loss 9.8441
2020-11-05 18:44:28,697 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1996 | Iter Mean Loss 9.5152
2020-11-05 18:44:28,699 - root - INFO - Evaluate: Epoch 0294 | NDCG 1.0000 | MSE 0.3563
2020-11-05 18:44:28,709 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3934 | Iter Mean Loss 10.3934
2020-11-05 18:44:28,717 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7138 | Iter Mean Loss 7.0536
2020-11-05 18:44:28,726 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5674 | Iter Mean Loss 9.2249
2020-11-05 18:44:28,734 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6006 | Iter Mean Loss 9.8188
2020-11-05 18:44:28,743 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1696 | Iter Mean Loss 9.4890
2020-11-05 18:44:28,745 - root - INFO - Evaluate: Epoch 0295 | NDCG 1.0000 | MSE 0.3559
2020-11-05 18:44:28,754 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3741 | Iter Mean Loss 10.3741
2020-11-05 18:44:28,761 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7078 | Iter Mean Loss 7.0410
2020-11-05 18:44:28,769 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5216 | Iter Mean Loss 9.2012
2020-11-05 18:44:28,776 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 9.7936
2020-11-05 18:44:28,784 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1398 | Iter Mean Loss 9.4628
2020-11-05 18:44:28,786 - root - INFO - Evaluate: Epoch 0296 | NDCG 1.0000 | MSE 0.3555
2020-11-05 18:44:28,794 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3547 | Iter Mean Loss 10.3547
2020-11-05 18:44:28,802 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7017 | Iter Mean Loss 7.0282
2020-11-05 18:44:28,810 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4762 | Iter Mean Loss 9.1775
2020-11-05 18:44:28,817 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5410 | Iter Mean Loss 9.7684
2020-11-05 18:44:28,825 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1102 | Iter Mean Loss 9.4368
2020-11-05 18:44:28,827 - root - INFO - Evaluate: Epoch 0297 | NDCG 1.0000 | MSE 0.3552
2020-11-05 18:44:28,836 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3351 | Iter Mean Loss 10.3351
2020-11-05 18:44:28,844 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6956 | Iter Mean Loss 7.0153
2020-11-05 18:44:28,852 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4311 | Iter Mean Loss 9.1539
2020-11-05 18:44:28,860 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5113 | Iter Mean Loss 9.7433
2020-11-05 18:44:28,868 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0808 | Iter Mean Loss 9.4108
2020-11-05 18:44:28,870 - root - INFO - Evaluate: Epoch 0298 | NDCG 1.0000 | MSE 0.3548
2020-11-05 18:44:28,880 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3154 | Iter Mean Loss 10.3154
2020-11-05 18:44:28,888 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6894 | Iter Mean Loss 7.0024
2020-11-05 18:44:28,897 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3864 | Iter Mean Loss 9.1304
2020-11-05 18:44:28,905 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4816 | Iter Mean Loss 9.7182
2020-11-05 18:44:28,913 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0516 | Iter Mean Loss 9.3849
2020-11-05 18:44:28,915 - root - INFO - Evaluate: Epoch 0299 | NDCG 1.0000 | MSE 0.3544
2020-11-05 18:44:28,924 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2955 | Iter Mean Loss 10.2955
2020-11-05 18:44:28,933 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6832 | Iter Mean Loss 6.9894
2020-11-05 18:44:28,941 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3420 | Iter Mean Loss 9.1069
2020-11-05 18:44:28,950 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4520 | Iter Mean Loss 9.6932
2020-11-05 18:44:28,958 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0226 | Iter Mean Loss 9.3591
2020-11-05 18:44:28,961 - root - INFO - Evaluate: Epoch 0300 | NDCG 1.0000 | MSE 0.3540
2020-11-05 18:44:28,970 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2755 | Iter Mean Loss 10.2755
2020-11-05 18:44:28,977 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6770 | Iter Mean Loss 6.9762
2020-11-05 18:44:28,985 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2979 | Iter Mean Loss 9.0835
2020-11-05 18:44:28,992 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4224 | Iter Mean Loss 9.6682
2020-11-05 18:44:28,999 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9937 | Iter Mean Loss 9.3333
2020-11-05 18:44:29,002 - root - INFO - Evaluate: Epoch 0301 | NDCG 1.0000 | MSE 0.3537
2020-11-05 18:44:29,010 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2554 | Iter Mean Loss 10.2554
2020-11-05 18:44:29,017 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6707 | Iter Mean Loss 6.9630
2020-11-05 18:44:29,025 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2541 | Iter Mean Loss 9.0601
2020-11-05 18:44:29,032 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3929 | Iter Mean Loss 9.6433
2020-11-05 18:44:29,041 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 9.3076
2020-11-05 18:44:29,043 - root - INFO - Evaluate: Epoch 0302 | NDCG 1.0000 | MSE 0.3533
2020-11-05 18:44:29,052 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2351 | Iter Mean Loss 10.2351
2020-11-05 18:44:29,061 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6644 | Iter Mean Loss 6.9497
2020-11-05 18:44:29,068 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2107 | Iter Mean Loss 9.0367
2020-11-05 18:44:29,077 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3635 | Iter Mean Loss 9.6184
2020-11-05 18:44:29,085 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9366 | Iter Mean Loss 9.2821
2020-11-05 18:44:29,089 - root - INFO - Evaluate: Epoch 0303 | NDCG 1.0000 | MSE 0.3529
2020-11-05 18:44:29,097 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2147 | Iter Mean Loss 10.2147
2020-11-05 18:44:29,106 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6580 | Iter Mean Loss 6.9364
2020-11-05 18:44:29,114 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1675 | Iter Mean Loss 9.0134
2020-11-05 18:44:29,122 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3341 | Iter Mean Loss 9.5936
2020-11-05 18:44:29,130 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9083 | Iter Mean Loss 9.2565
2020-11-05 18:44:29,133 - root - INFO - Evaluate: Epoch 0304 | NDCG 1.0000 | MSE 0.3526
2020-11-05 18:44:29,142 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1942 | Iter Mean Loss 10.1942
2020-11-05 18:44:29,150 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6516 | Iter Mean Loss 6.9229
2020-11-05 18:44:29,157 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1247 | Iter Mean Loss 8.9902
2020-11-05 18:44:29,165 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3047 | Iter Mean Loss 9.5688
2020-11-05 18:44:29,172 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8802 | Iter Mean Loss 9.2311
2020-11-05 18:44:29,174 - root - INFO - Evaluate: Epoch 0305 | NDCG 1.0000 | MSE 0.3522
2020-11-05 18:44:29,182 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1735 | Iter Mean Loss 10.1735
2020-11-05 18:44:29,191 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6452 | Iter Mean Loss 6.9093
2020-11-05 18:44:29,200 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0822 | Iter Mean Loss 8.9670
2020-11-05 18:44:29,207 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2754 | Iter Mean Loss 9.5441
2020-11-05 18:44:29,215 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8522 | Iter Mean Loss 9.2057
2020-11-05 18:44:29,218 - root - INFO - Evaluate: Epoch 0306 | NDCG 1.0000 | MSE 0.3519
2020-11-05 18:44:29,226 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1527 | Iter Mean Loss 10.1527
2020-11-05 18:44:29,234 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6387 | Iter Mean Loss 6.8957
2020-11-05 18:44:29,243 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0399 | Iter Mean Loss 8.9438
2020-11-05 18:44:29,252 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2462 | Iter Mean Loss 9.5194
2020-11-05 18:44:29,264 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8245 | Iter Mean Loss 9.1804
2020-11-05 18:44:29,266 - root - INFO - Evaluate: Epoch 0307 | NDCG 1.0000 | MSE 0.3515
2020-11-05 18:44:29,279 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1318 | Iter Mean Loss 10.1318
2020-11-05 18:44:29,288 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 6.8820
2020-11-05 18:44:29,299 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9980 | Iter Mean Loss 8.9207
2020-11-05 18:44:29,311 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2170 | Iter Mean Loss 9.4947
2020-11-05 18:44:29,321 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7968 | Iter Mean Loss 9.1552
2020-11-05 18:44:29,327 - root - INFO - Evaluate: Epoch 0308 | NDCG 1.0000 | MSE 0.3512
2020-11-05 18:44:29,338 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1107 | Iter Mean Loss 10.1107
2020-11-05 18:44:29,349 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 6.8682
2020-11-05 18:44:29,360 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9563 | Iter Mean Loss 8.8976
2020-11-05 18:44:29,369 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1878 | Iter Mean Loss 9.4701
2020-11-05 18:44:29,380 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7694 | Iter Mean Loss 9.1300
2020-11-05 18:44:29,382 - root - INFO - Evaluate: Epoch 0309 | NDCG 1.0000 | MSE 0.3508
2020-11-05 18:44:29,393 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0895 | Iter Mean Loss 10.0895
2020-11-05 18:44:29,403 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6191 | Iter Mean Loss 6.8543
2020-11-05 18:44:29,415 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9149 | Iter Mean Loss 8.8745
2020-11-05 18:44:29,426 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1587 | Iter Mean Loss 9.4456
2020-11-05 18:44:29,439 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7421 | Iter Mean Loss 9.1049
2020-11-05 18:44:29,442 - root - INFO - Evaluate: Epoch 0310 | NDCG 1.0000 | MSE 0.3505
2020-11-05 18:44:29,454 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0682 | Iter Mean Loss 10.0682
2020-11-05 18:44:29,465 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6124 | Iter Mean Loss 6.8403
2020-11-05 18:44:29,477 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8738 | Iter Mean Loss 8.8515
2020-11-05 18:44:29,488 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1297 | Iter Mean Loss 9.4210
2020-11-05 18:44:29,498 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7150 | Iter Mean Loss 9.0798
2020-11-05 18:44:29,503 - root - INFO - Evaluate: Epoch 0311 | NDCG 1.0000 | MSE 0.3501
2020-11-05 18:44:29,515 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0468 | Iter Mean Loss 10.0468
2020-11-05 18:44:29,527 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6058 | Iter Mean Loss 6.8263
2020-11-05 18:44:29,540 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8330 | Iter Mean Loss 8.8285
2020-11-05 18:44:29,551 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1007 | Iter Mean Loss 9.3966
2020-11-05 18:44:29,561 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6881 | Iter Mean Loss 9.0549
2020-11-05 18:44:29,563 - root - INFO - Evaluate: Epoch 0312 | NDCG 1.0000 | MSE 0.3498
2020-11-05 18:44:29,575 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0253 | Iter Mean Loss 10.0253
2020-11-05 18:44:29,584 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5991 | Iter Mean Loss 6.8122
2020-11-05 18:44:29,596 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7925 | Iter Mean Loss 8.8056
2020-11-05 18:44:29,606 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0717 | Iter Mean Loss 9.3721
2020-11-05 18:44:29,615 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6613 | Iter Mean Loss 9.0300
2020-11-05 18:44:29,619 - root - INFO - Evaluate: Epoch 0313 | NDCG 1.0000 | MSE 0.3494
2020-11-05 18:44:29,632 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0036 | Iter Mean Loss 10.0036
2020-11-05 18:44:29,644 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 6.7980
2020-11-05 18:44:29,654 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7522 | Iter Mean Loss 8.7827
2020-11-05 18:44:29,664 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0428 | Iter Mean Loss 9.3477
2020-11-05 18:44:29,673 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6347 | Iter Mean Loss 9.0051
2020-11-05 18:44:29,676 - root - INFO - Evaluate: Epoch 0314 | NDCG 1.0000 | MSE 0.3491
2020-11-05 18:44:29,685 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9818 | Iter Mean Loss 9.9818
2020-11-05 18:44:29,696 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5856 | Iter Mean Loss 6.7837
2020-11-05 18:44:29,704 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7122 | Iter Mean Loss 8.7599
2020-11-05 18:44:29,713 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 9.3234
2020-11-05 18:44:29,722 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6082 | Iter Mean Loss 8.9803
2020-11-05 18:44:29,725 - root - INFO - Evaluate: Epoch 0315 | NDCG 1.0000 | MSE 0.3488
2020-11-05 18:44:29,734 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9599 | Iter Mean Loss 9.9599
2020-11-05 18:44:29,744 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5788 | Iter Mean Loss 6.7693
2020-11-05 18:44:29,752 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6724 | Iter Mean Loss 8.7370
2020-11-05 18:44:29,761 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9851 | Iter Mean Loss 9.2991
2020-11-05 18:44:29,769 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5819 | Iter Mean Loss 8.9556
2020-11-05 18:44:29,772 - root - INFO - Evaluate: Epoch 0316 | NDCG 1.0000 | MSE 0.3484
2020-11-05 18:44:29,781 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9379 | Iter Mean Loss 9.9379
2020-11-05 18:44:29,792 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5719 | Iter Mean Loss 6.7549
2020-11-05 18:44:29,800 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6329 | Iter Mean Loss 8.7143
2020-11-05 18:44:29,809 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9564 | Iter Mean Loss 9.2748
2020-11-05 18:44:29,817 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5558 | Iter Mean Loss 8.9310
2020-11-05 18:44:29,819 - root - INFO - Evaluate: Epoch 0317 | NDCG 1.0000 | MSE 0.3481
2020-11-05 18:44:29,830 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9158 | Iter Mean Loss 9.9158
2020-11-05 18:44:29,839 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5651 | Iter Mean Loss 6.7404
2020-11-05 18:44:29,847 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5937 | Iter Mean Loss 8.6915
2020-11-05 18:44:29,857 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9277 | Iter Mean Loss 9.2505
2020-11-05 18:44:29,865 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5298 | Iter Mean Loss 8.9064
2020-11-05 18:44:29,868 - root - INFO - Evaluate: Epoch 0318 | NDCG 1.0000 | MSE 0.3478
2020-11-05 18:44:29,878 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8935 | Iter Mean Loss 9.8935
2020-11-05 18:44:29,888 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5581 | Iter Mean Loss 6.7258
2020-11-05 18:44:29,897 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5547 | Iter Mean Loss 8.6688
2020-11-05 18:44:29,906 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8990 | Iter Mean Loss 9.2264
2020-11-05 18:44:29,914 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5039 | Iter Mean Loss 8.8819
2020-11-05 18:44:29,916 - root - INFO - Evaluate: Epoch 0319 | NDCG 1.0000 | MSE 0.3475
2020-11-05 18:44:29,927 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8712 | Iter Mean Loss 9.8712
2020-11-05 18:44:29,935 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5512 | Iter Mean Loss 6.7112
2020-11-05 18:44:29,946 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5160 | Iter Mean Loss 8.6461
2020-11-05 18:44:29,954 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8704 | Iter Mean Loss 9.2022
2020-11-05 18:44:29,964 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4783 | Iter Mean Loss 8.8574
2020-11-05 18:44:29,966 - root - INFO - Evaluate: Epoch 0320 | NDCG 1.0000 | MSE 0.3472
2020-11-05 18:44:29,976 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8487 | Iter Mean Loss 9.8487
2020-11-05 18:44:29,984 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5442 | Iter Mean Loss 6.6965
2020-11-05 18:44:29,993 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4775 | Iter Mean Loss 8.6235
2020-11-05 18:44:30,001 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8418 | Iter Mean Loss 9.1781
2020-11-05 18:44:30,010 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4527 | Iter Mean Loss 8.8330
2020-11-05 18:44:30,012 - root - INFO - Evaluate: Epoch 0321 | NDCG 1.0000 | MSE 0.3468
2020-11-05 18:44:30,022 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8262 | Iter Mean Loss 9.8262
2020-11-05 18:44:30,030 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5372 | Iter Mean Loss 6.6817
2020-11-05 18:44:30,039 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4393 | Iter Mean Loss 8.6009
2020-11-05 18:44:30,047 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8133 | Iter Mean Loss 9.1540
2020-11-05 18:44:30,057 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4274 | Iter Mean Loss 8.8087
2020-11-05 18:44:30,060 - root - INFO - Evaluate: Epoch 0322 | NDCG 1.0000 | MSE 0.3465
2020-11-05 18:44:30,069 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8036 | Iter Mean Loss 9.8036
2020-11-05 18:44:30,079 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5302 | Iter Mean Loss 6.6669
2020-11-05 18:44:30,087 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4013 | Iter Mean Loss 8.5784
2020-11-05 18:44:30,097 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7848 | Iter Mean Loss 9.1300
2020-11-05 18:44:30,107 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4022 | Iter Mean Loss 8.7844
2020-11-05 18:44:30,110 - root - INFO - Evaluate: Epoch 0323 | NDCG 1.0000 | MSE 0.3462
2020-11-05 18:44:30,118 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7808 | Iter Mean Loss 9.7808
2020-11-05 18:44:30,129 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5231 | Iter Mean Loss 6.6520
2020-11-05 18:44:30,137 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3635 | Iter Mean Loss 8.5558
2020-11-05 18:44:30,147 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7564 | Iter Mean Loss 9.1060
2020-11-05 18:44:30,157 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 8.7602
2020-11-05 18:44:30,160 - root - INFO - Evaluate: Epoch 0324 | NDCG 1.0000 | MSE 0.3459
2020-11-05 18:44:30,168 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7580 | Iter Mean Loss 9.7580
2020-11-05 18:44:30,178 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5160 | Iter Mean Loss 6.6370
2020-11-05 18:44:30,187 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 8.5334
2020-11-05 18:44:30,195 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7281 | Iter Mean Loss 9.0820
2020-11-05 18:44:30,203 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3522 | Iter Mean Loss 8.7361
2020-11-05 18:44:30,208 - root - INFO - Evaluate: Epoch 0325 | NDCG 1.0000 | MSE 0.3456
2020-11-05 18:44:30,216 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7351 | Iter Mean Loss 9.7351
2020-11-05 18:44:30,226 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5089 | Iter Mean Loss 6.6220
2020-11-05 18:44:30,234 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2888 | Iter Mean Loss 8.5109
2020-11-05 18:44:30,243 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6998 | Iter Mean Loss 9.0581
2020-11-05 18:44:30,252 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3274 | Iter Mean Loss 8.7120
2020-11-05 18:44:30,255 - root - INFO - Evaluate: Epoch 0326 | NDCG 1.0000 | MSE 0.3453
2020-11-05 18:44:30,264 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7120 | Iter Mean Loss 9.7120
2020-11-05 18:44:30,274 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5018 | Iter Mean Loss 6.6069
2020-11-05 18:44:30,282 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2517 | Iter Mean Loss 8.4885
2020-11-05 18:44:30,291 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6715 | Iter Mean Loss 9.0343
2020-11-05 18:44:30,299 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3028 | Iter Mean Loss 8.6880
2020-11-05 18:44:30,303 - root - INFO - Evaluate: Epoch 0327 | NDCG 1.0000 | MSE 0.3450
2020-11-05 18:44:30,313 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6890 | Iter Mean Loss 9.6890
2020-11-05 18:44:30,323 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4946 | Iter Mean Loss 6.5918
2020-11-05 18:44:30,331 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2149 | Iter Mean Loss 8.4662
2020-11-05 18:44:30,340 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6433 | Iter Mean Loss 9.0104
2020-11-05 18:44:30,348 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2784 | Iter Mean Loss 8.6640
2020-11-05 18:44:30,350 - root - INFO - Evaluate: Epoch 0328 | NDCG 1.0000 | MSE 0.3447
2020-11-05 18:44:30,358 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6658 | Iter Mean Loss 9.6658
2020-11-05 18:44:30,367 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4874 | Iter Mean Loss 6.5766
2020-11-05 18:44:30,375 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1783 | Iter Mean Loss 8.4438
2020-11-05 18:44:30,383 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6152 | Iter Mean Loss 8.9867
2020-11-05 18:44:30,390 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2541 | Iter Mean Loss 8.6402
2020-11-05 18:44:30,392 - root - INFO - Evaluate: Epoch 0329 | NDCG 1.0000 | MSE 0.3444
2020-11-05 18:44:30,400 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6425 | Iter Mean Loss 9.6425
2020-11-05 18:44:30,407 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4802 | Iter Mean Loss 6.5614
2020-11-05 18:44:30,415 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1420 | Iter Mean Loss 8.4216
2020-11-05 18:44:30,422 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5871 | Iter Mean Loss 8.9629
2020-11-05 18:44:30,429 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2300 | Iter Mean Loss 8.6164
2020-11-05 18:44:30,431 - root - INFO - Evaluate: Epoch 0330 | NDCG 1.0000 | MSE 0.3441
2020-11-05 18:44:30,439 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6192 | Iter Mean Loss 9.6192
2020-11-05 18:44:30,446 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4730 | Iter Mean Loss 6.5461
2020-11-05 18:44:30,454 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1058 | Iter Mean Loss 8.3993
2020-11-05 18:44:30,461 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5591 | Iter Mean Loss 8.9393
2020-11-05 18:44:30,468 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2060 | Iter Mean Loss 8.5926
2020-11-05 18:44:30,470 - root - INFO - Evaluate: Epoch 0331 | NDCG 1.0000 | MSE 0.3438
2020-11-05 18:44:30,479 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.5958
2020-11-05 18:44:30,487 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4657 | Iter Mean Loss 6.5308
2020-11-05 18:44:30,495 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0699 | Iter Mean Loss 8.3772
2020-11-05 18:44:30,503 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5311 | Iter Mean Loss 8.9156
2020-11-05 18:44:30,511 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1822 | Iter Mean Loss 8.5689
2020-11-05 18:44:30,514 - root - INFO - Evaluate: Epoch 0332 | NDCG 1.0000 | MSE 0.3435
2020-11-05 18:44:30,522 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5724 | Iter Mean Loss 9.5724
2020-11-05 18:44:30,530 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4584 | Iter Mean Loss 6.5154
2020-11-05 18:44:30,538 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0343 | Iter Mean Loss 8.3550
2020-11-05 18:44:30,547 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5032 | Iter Mean Loss 8.8921
2020-11-05 18:44:30,554 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1585 | Iter Mean Loss 8.5454
2020-11-05 18:44:30,557 - root - INFO - Evaluate: Epoch 0333 | NDCG 1.0000 | MSE 0.3433
2020-11-05 18:44:30,566 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5489 | Iter Mean Loss 9.5489
2020-11-05 18:44:30,573 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4511 | Iter Mean Loss 6.5000
2020-11-05 18:44:30,581 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9988 | Iter Mean Loss 8.3329
2020-11-05 18:44:30,589 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4754 | Iter Mean Loss 8.8685
2020-11-05 18:44:30,597 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1350 | Iter Mean Loss 8.5218
2020-11-05 18:44:30,600 - root - INFO - Evaluate: Epoch 0334 | NDCG 1.0000 | MSE 0.3430
2020-11-05 18:44:30,608 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5253 | Iter Mean Loss 9.5253
2020-11-05 18:44:30,615 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4438 | Iter Mean Loss 6.4846
2020-11-05 18:44:30,622 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 8.3109
2020-11-05 18:44:30,629 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4476 | Iter Mean Loss 8.8451
2020-11-05 18:44:30,637 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1116 | Iter Mean Loss 8.4984
2020-11-05 18:44:30,639 - root - INFO - Evaluate: Epoch 0335 | NDCG 1.0000 | MSE 0.3427
2020-11-05 18:44:30,646 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5017 | Iter Mean Loss 9.5017
2020-11-05 18:44:30,654 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4365 | Iter Mean Loss 6.4691
2020-11-05 18:44:30,661 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9286 | Iter Mean Loss 8.2889
2020-11-05 18:44:30,668 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4199 | Iter Mean Loss 8.8217
2020-11-05 18:44:30,676 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0884 | Iter Mean Loss 8.4750
2020-11-05 18:44:30,678 - root - INFO - Evaluate: Epoch 0336 | NDCG 1.0000 | MSE 0.3424
2020-11-05 18:44:30,687 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4780 | Iter Mean Loss 9.4780
2020-11-05 18:44:30,695 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4292 | Iter Mean Loss 6.4536
2020-11-05 18:44:30,703 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8938 | Iter Mean Loss 8.2670
2020-11-05 18:44:30,711 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3922 | Iter Mean Loss 8.7983
2020-11-05 18:44:30,719 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0654 | Iter Mean Loss 8.4517
2020-11-05 18:44:30,722 - root - INFO - Evaluate: Epoch 0337 | NDCG 1.0000 | MSE 0.3421
2020-11-05 18:44:30,731 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4543 | Iter Mean Loss 9.4543
2020-11-05 18:44:30,739 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4218 | Iter Mean Loss 6.4381
2020-11-05 18:44:30,747 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8592 | Iter Mean Loss 8.2451
2020-11-05 18:44:30,755 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3647 | Iter Mean Loss 8.7750
2020-11-05 18:44:30,763 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0425 | Iter Mean Loss 8.4285
2020-11-05 18:44:30,765 - root - INFO - Evaluate: Epoch 0338 | NDCG 1.0000 | MSE 0.3419
2020-11-05 18:44:30,774 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4306 | Iter Mean Loss 9.4306
2020-11-05 18:44:30,782 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.4225
2020-11-05 18:44:30,790 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8248 | Iter Mean Loss 8.2233
2020-11-05 18:44:30,798 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3371 | Iter Mean Loss 8.7518
2020-11-05 18:44:30,805 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0198 | Iter Mean Loss 8.4054
2020-11-05 18:44:30,807 - root - INFO - Evaluate: Epoch 0339 | NDCG 1.0000 | MSE 0.3416
2020-11-05 18:44:30,815 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 9.4068
2020-11-05 18:44:30,822 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4071 | Iter Mean Loss 6.4070
2020-11-05 18:44:30,830 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7907 | Iter Mean Loss 8.2015
2020-11-05 18:44:30,837 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3097 | Iter Mean Loss 8.7286
2020-11-05 18:44:30,844 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9972 | Iter Mean Loss 8.3823
2020-11-05 18:44:30,846 - root - INFO - Evaluate: Epoch 0340 | NDCG 1.0000 | MSE 0.3413
2020-11-05 18:44:30,854 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3830 | Iter Mean Loss 9.3830
2020-11-05 18:44:30,861 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3998 | Iter Mean Loss 6.3914
2020-11-05 18:44:30,868 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7568 | Iter Mean Loss 8.1798
2020-11-05 18:44:30,876 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2824 | Iter Mean Loss 8.7055
2020-11-05 18:44:30,883 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9748 | Iter Mean Loss 8.3593
2020-11-05 18:44:30,886 - root - INFO - Evaluate: Epoch 0341 | NDCG 1.0000 | MSE 0.3411
2020-11-05 18:44:30,894 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3592 | Iter Mean Loss 9.3592
2020-11-05 18:44:30,902 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3924 | Iter Mean Loss 6.3758
2020-11-05 18:44:30,910 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7231 | Iter Mean Loss 8.1582
2020-11-05 18:44:30,918 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2551 | Iter Mean Loss 8.6824
2020-11-05 18:44:30,926 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9526 | Iter Mean Loss 8.3365
2020-11-05 18:44:30,929 - root - INFO - Evaluate: Epoch 0342 | NDCG 1.0000 | MSE 0.3408
2020-11-05 18:44:30,938 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3354 | Iter Mean Loss 9.3354
2020-11-05 18:44:30,946 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3850 | Iter Mean Loss 6.3602
2020-11-05 18:44:30,954 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6896 | Iter Mean Loss 8.1367
2020-11-05 18:44:30,962 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2279 | Iter Mean Loss 8.6595
2020-11-05 18:44:30,970 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9305 | Iter Mean Loss 8.3137
2020-11-05 18:44:30,973 - root - INFO - Evaluate: Epoch 0343 | NDCG 1.0000 | MSE 0.3406
2020-11-05 18:44:30,982 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3115 | Iter Mean Loss 9.3115
2020-11-05 18:44:30,990 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3777 | Iter Mean Loss 6.3446
2020-11-05 18:44:30,998 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6563 | Iter Mean Loss 8.1152
2020-11-05 18:44:31,005 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2007 | Iter Mean Loss 8.6366
2020-11-05 18:44:31,012 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 8.2910
2020-11-05 18:44:31,014 - root - INFO - Evaluate: Epoch 0344 | NDCG 1.0000 | MSE 0.3403
2020-11-05 18:44:31,022 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2877 | Iter Mean Loss 9.2877
2020-11-05 18:44:31,030 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3703 | Iter Mean Loss 6.3290
2020-11-05 18:44:31,037 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6232 | Iter Mean Loss 8.0937
2020-11-05 18:44:31,044 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1737 | Iter Mean Loss 8.6137
2020-11-05 18:44:31,052 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 8.2683
2020-11-05 18:44:31,054 - root - INFO - Evaluate: Epoch 0345 | NDCG 1.0000 | MSE 0.3401
2020-11-05 18:44:31,062 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2638 | Iter Mean Loss 9.2638
2020-11-05 18:44:31,070 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3629 | Iter Mean Loss 6.3134
2020-11-05 18:44:31,077 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5904 | Iter Mean Loss 8.0724
2020-11-05 18:44:31,085 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1467 | Iter Mean Loss 8.5910
2020-11-05 18:44:31,092 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8652 | Iter Mean Loss 8.2458
2020-11-05 18:44:31,095 - root - INFO - Evaluate: Epoch 0346 | NDCG 1.0000 | MSE 0.3398
2020-11-05 18:44:31,104 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2400 | Iter Mean Loss 9.2400
2020-11-05 18:44:31,112 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.2978
2020-11-05 18:44:31,121 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5577 | Iter Mean Loss 8.0511
2020-11-05 18:44:31,128 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1199 | Iter Mean Loss 8.5683
2020-11-05 18:44:31,137 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8438 | Iter Mean Loss 8.2234
2020-11-05 18:44:31,139 - root - INFO - Evaluate: Epoch 0347 | NDCG 1.0000 | MSE 0.3396
2020-11-05 18:44:31,148 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2162 | Iter Mean Loss 9.2162
2020-11-05 18:44:31,156 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3482 | Iter Mean Loss 6.2822
2020-11-05 18:44:31,164 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5253 | Iter Mean Loss 8.0299
2020-11-05 18:44:31,171 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0931 | Iter Mean Loss 8.5457
2020-11-05 18:44:31,179 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8226 | Iter Mean Loss 8.2011
2020-11-05 18:44:31,181 - root - INFO - Evaluate: Epoch 0348 | NDCG 1.0000 | MSE 0.3393
2020-11-05 18:44:31,190 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1924 | Iter Mean Loss 9.1924
2020-11-05 18:44:31,198 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3409 | Iter Mean Loss 6.2666
2020-11-05 18:44:31,206 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4931 | Iter Mean Loss 8.0088
2020-11-05 18:44:31,214 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 8.5232
2020-11-05 18:44:31,221 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8015 | Iter Mean Loss 8.1788
2020-11-05 18:44:31,223 - root - INFO - Evaluate: Epoch 0349 | NDCG 1.0000 | MSE 0.3391
2020-11-05 18:44:31,231 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1686 | Iter Mean Loss 9.1686
2020-11-05 18:44:31,238 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3336 | Iter Mean Loss 6.2511
2020-11-05 18:44:31,246 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4611 | Iter Mean Loss 7.9878
2020-11-05 18:44:31,253 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0398 | Iter Mean Loss 8.5008
2020-11-05 18:44:31,260 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7806 | Iter Mean Loss 8.1567
2020-11-05 18:44:31,262 - root - INFO - Evaluate: Epoch 0350 | NDCG 1.0000 | MSE 0.3389
2020-11-05 18:44:31,270 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1448 | Iter Mean Loss 9.1448
2020-11-05 18:44:31,277 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3263 | Iter Mean Loss 6.2355
2020-11-05 18:44:31,284 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4293 | Iter Mean Loss 7.9668
2020-11-05 18:44:31,292 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0133 | Iter Mean Loss 8.4784
2020-11-05 18:44:31,300 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 8.1347
2020-11-05 18:44:31,302 - root - INFO - Evaluate: Epoch 0351 | NDCG 1.0000 | MSE 0.3386
2020-11-05 18:44:31,311 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1211 | Iter Mean Loss 9.1211
2020-11-05 18:44:31,322 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3190 | Iter Mean Loss 6.2200
2020-11-05 18:44:31,332 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3978 | Iter Mean Loss 7.9460
2020-11-05 18:44:31,340 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9869 | Iter Mean Loss 8.4562
2020-11-05 18:44:31,349 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7392 | Iter Mean Loss 8.1128
2020-11-05 18:44:31,352 - root - INFO - Evaluate: Epoch 0352 | NDCG 1.0000 | MSE 0.3384
2020-11-05 18:44:31,361 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0974 | Iter Mean Loss 9.0974
2020-11-05 18:44:31,369 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3117 | Iter Mean Loss 6.2046
2020-11-05 18:44:31,377 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3664 | Iter Mean Loss 7.9252
2020-11-05 18:44:31,386 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9606 | Iter Mean Loss 8.4340
2020-11-05 18:44:31,395 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7188 | Iter Mean Loss 8.0910
2020-11-05 18:44:31,398 - root - INFO - Evaluate: Epoch 0353 | NDCG 1.0000 | MSE 0.3382
2020-11-05 18:44:31,406 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0738 | Iter Mean Loss 9.0738
2020-11-05 18:44:31,414 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3045 | Iter Mean Loss 6.1891
2020-11-05 18:44:31,422 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3353 | Iter Mean Loss 7.9045
2020-11-05 18:44:31,432 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9343 | Iter Mean Loss 8.4120
2020-11-05 18:44:31,442 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6986 | Iter Mean Loss 8.0693
2020-11-05 18:44:31,444 - root - INFO - Evaluate: Epoch 0354 | NDCG 1.0000 | MSE 0.3380
2020-11-05 18:44:31,452 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0502 | Iter Mean Loss 9.0502
2020-11-05 18:44:31,462 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2973 | Iter Mean Loss 6.1737
2020-11-05 18:44:31,469 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 7.8839
2020-11-05 18:44:31,478 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9082 | Iter Mean Loss 8.3900
2020-11-05 18:44:31,486 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6785 | Iter Mean Loss 8.0477
2020-11-05 18:44:31,489 - root - INFO - Evaluate: Epoch 0355 | NDCG 1.0000 | MSE 0.3377
2020-11-05 18:44:31,498 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0267 | Iter Mean Loss 9.0267
2020-11-05 18:44:31,506 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2901 | Iter Mean Loss 6.1584
2020-11-05 18:44:31,515 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2736 | Iter Mean Loss 7.8635
2020-11-05 18:44:31,523 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8822 | Iter Mean Loss 8.3681
2020-11-05 18:44:31,532 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6586 | Iter Mean Loss 8.0262
2020-11-05 18:44:31,534 - root - INFO - Evaluate: Epoch 0356 | NDCG 1.0000 | MSE 0.3375
2020-11-05 18:44:31,544 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0032 | Iter Mean Loss 9.0032
2020-11-05 18:44:31,553 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2829 | Iter Mean Loss 6.1431
2020-11-05 18:44:31,563 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2431 | Iter Mean Loss 7.8431
2020-11-05 18:44:31,571 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8563 | Iter Mean Loss 8.3464
2020-11-05 18:44:31,580 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6389 | Iter Mean Loss 8.0049
2020-11-05 18:44:31,582 - root - INFO - Evaluate: Epoch 0357 | NDCG 1.0000 | MSE 0.3373
2020-11-05 18:44:31,592 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9799 | Iter Mean Loss 8.9799
2020-11-05 18:44:31,602 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2758 | Iter Mean Loss 6.1278
2020-11-05 18:44:31,611 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2128 | Iter Mean Loss 7.8228
2020-11-05 18:44:31,619 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8306 | Iter Mean Loss 8.3247
2020-11-05 18:44:31,628 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6193 | Iter Mean Loss 7.9837
2020-11-05 18:44:31,630 - root - INFO - Evaluate: Epoch 0358 | NDCG 1.0000 | MSE 0.3371
2020-11-05 18:44:31,639 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9565 | Iter Mean Loss 8.9565
2020-11-05 18:44:31,648 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2687 | Iter Mean Loss 6.1126
2020-11-05 18:44:31,656 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1827 | Iter Mean Loss 7.8026
2020-11-05 18:44:31,664 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8049 | Iter Mean Loss 8.3032
2020-11-05 18:44:31,672 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5999 | Iter Mean Loss 7.9625
2020-11-05 18:44:31,674 - root - INFO - Evaluate: Epoch 0359 | NDCG 1.0000 | MSE 0.3369
2020-11-05 18:44:31,684 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9333 | Iter Mean Loss 8.9333
2020-11-05 18:44:31,692 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2616 | Iter Mean Loss 6.0975
2020-11-05 18:44:31,701 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1528 | Iter Mean Loss 7.7826
2020-11-05 18:44:31,710 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7793 | Iter Mean Loss 8.2818
2020-11-05 18:44:31,719 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5807 | Iter Mean Loss 7.9416
2020-11-05 18:44:31,722 - root - INFO - Evaluate: Epoch 0360 | NDCG 1.0000 | MSE 0.3367
2020-11-05 18:44:31,731 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9102 | Iter Mean Loss 8.9102
2020-11-05 18:44:31,739 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 6.0824
2020-11-05 18:44:31,748 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1232 | Iter Mean Loss 7.7626
2020-11-05 18:44:31,757 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7539 | Iter Mean Loss 8.2604
2020-11-05 18:44:31,765 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5616 | Iter Mean Loss 7.9207
2020-11-05 18:44:31,768 - root - INFO - Evaluate: Epoch 0361 | NDCG 1.0000 | MSE 0.3365
2020-11-05 18:44:31,778 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8871 | Iter Mean Loss 8.8871
2020-11-05 18:44:31,787 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2475 | Iter Mean Loss 6.0673
2020-11-05 18:44:31,797 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0937 | Iter Mean Loss 7.7428
2020-11-05 18:44:31,805 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7285 | Iter Mean Loss 8.2392
2020-11-05 18:44:31,814 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5428 | Iter Mean Loss 7.8999
2020-11-05 18:44:31,816 - root - INFO - Evaluate: Epoch 0362 | NDCG 1.0000 | MSE 0.3363
2020-11-05 18:44:31,825 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8642 | Iter Mean Loss 8.8642
2020-11-05 18:44:31,834 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2406 | Iter Mean Loss 6.0524
2020-11-05 18:44:31,843 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0645 | Iter Mean Loss 7.7231
2020-11-05 18:44:31,852 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7033 | Iter Mean Loss 8.2181
2020-11-05 18:44:31,860 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5241 | Iter Mean Loss 7.8793
2020-11-05 18:44:31,863 - root - INFO - Evaluate: Epoch 0363 | NDCG 1.0000 | MSE 0.3361
2020-11-05 18:44:31,872 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8413 | Iter Mean Loss 8.8413
2020-11-05 18:44:31,880 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2337 | Iter Mean Loss 6.0375
2020-11-05 18:44:31,889 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0355 | Iter Mean Loss 7.7035
2020-11-05 18:44:31,897 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6783 | Iter Mean Loss 8.1972
2020-11-05 18:44:31,906 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5055 | Iter Mean Loss 7.8588
2020-11-05 18:44:31,908 - root - INFO - Evaluate: Epoch 0364 | NDCG 1.0000 | MSE 0.3359
2020-11-05 18:44:31,918 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8186 | Iter Mean Loss 8.8186
2020-11-05 18:44:31,926 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2268 | Iter Mean Loss 6.0227
2020-11-05 18:44:31,935 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0066 | Iter Mean Loss 7.6840
2020-11-05 18:44:31,943 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6533 | Iter Mean Loss 8.1763
2020-11-05 18:44:31,952 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4871 | Iter Mean Loss 7.8385
2020-11-05 18:44:31,955 - root - INFO - Evaluate: Epoch 0365 | NDCG 1.0000 | MSE 0.3357
2020-11-05 18:44:31,965 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7960 | Iter Mean Loss 8.7960
2020-11-05 18:44:31,974 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2199 | Iter Mean Loss 6.0079
2020-11-05 18:44:31,983 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9780 | Iter Mean Loss 7.6646
2020-11-05 18:44:31,991 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6285 | Iter Mean Loss 8.1556
2020-11-05 18:44:32,000 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4689 | Iter Mean Loss 7.8183
2020-11-05 18:44:32,003 - root - INFO - Evaluate: Epoch 0366 | NDCG 1.0000 | MSE 0.3355
2020-11-05 18:44:32,013 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7734 | Iter Mean Loss 8.7734
2020-11-05 18:44:32,022 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2131 | Iter Mean Loss 5.9933
2020-11-05 18:44:32,030 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9496 | Iter Mean Loss 7.6454
2020-11-05 18:44:32,039 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6037 | Iter Mean Loss 8.1350
2020-11-05 18:44:32,047 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4509 | Iter Mean Loss 7.7982
2020-11-05 18:44:32,050 - root - INFO - Evaluate: Epoch 0367 | NDCG 1.0000 | MSE 0.3353
2020-11-05 18:44:32,059 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7510 | Iter Mean Loss 8.7510
2020-11-05 18:44:32,068 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2064 | Iter Mean Loss 5.9787
2020-11-05 18:44:32,076 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9214 | Iter Mean Loss 7.6263
2020-11-05 18:44:32,084 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5792 | Iter Mean Loss 8.1145
2020-11-05 18:44:32,092 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4330 | Iter Mean Loss 7.7782
2020-11-05 18:44:32,095 - root - INFO - Evaluate: Epoch 0368 | NDCG 1.0000 | MSE 0.3351
2020-11-05 18:44:32,105 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7288 | Iter Mean Loss 8.7288
2020-11-05 18:44:32,114 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1997 | Iter Mean Loss 5.9642
2020-11-05 18:44:32,123 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8934 | Iter Mean Loss 7.6073
2020-11-05 18:44:32,131 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5547 | Iter Mean Loss 8.0941
2020-11-05 18:44:32,139 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4153 | Iter Mean Loss 7.7584
2020-11-05 18:44:32,142 - root - INFO - Evaluate: Epoch 0369 | NDCG 1.0000 | MSE 0.3350
2020-11-05 18:44:32,151 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7066 | Iter Mean Loss 8.7066
2020-11-05 18:44:32,159 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1930 | Iter Mean Loss 5.9498
2020-11-05 18:44:32,169 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8657 | Iter Mean Loss 7.5884
2020-11-05 18:44:32,177 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5304 | Iter Mean Loss 8.0739
2020-11-05 18:44:32,186 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3977 | Iter Mean Loss 7.7387
2020-11-05 18:44:32,188 - root - INFO - Evaluate: Epoch 0370 | NDCG 1.0000 | MSE 0.3348
2020-11-05 18:44:32,198 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6846 | Iter Mean Loss 8.6846
2020-11-05 18:44:32,207 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1864 | Iter Mean Loss 5.9355
2020-11-05 18:44:32,216 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8381 | Iter Mean Loss 7.5697
2020-11-05 18:44:32,224 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5062 | Iter Mean Loss 8.0538
2020-11-05 18:44:32,232 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3803 | Iter Mean Loss 7.7191
2020-11-05 18:44:32,235 - root - INFO - Evaluate: Epoch 0371 | NDCG 1.0000 | MSE 0.3346
2020-11-05 18:44:32,243 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6628 | Iter Mean Loss 8.6628
2020-11-05 18:44:32,253 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1799 | Iter Mean Loss 5.9213
2020-11-05 18:44:32,261 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 7.5511
2020-11-05 18:44:32,270 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 8.0339
2020-11-05 18:44:32,278 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3631 | Iter Mean Loss 7.6997
2020-11-05 18:44:32,281 - root - INFO - Evaluate: Epoch 0372 | NDCG 1.0000 | MSE 0.3344
2020-11-05 18:44:32,290 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6410 | Iter Mean Loss 8.6410
2020-11-05 18:44:32,299 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.9072
2020-11-05 18:44:32,307 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7835 | Iter Mean Loss 7.5326
2020-11-05 18:44:32,318 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4582 | Iter Mean Loss 8.0140
2020-11-05 18:44:32,326 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3460 | Iter Mean Loss 7.6804
2020-11-05 18:44:32,329 - root - INFO - Evaluate: Epoch 0373 | NDCG 1.0000 | MSE 0.3343
2020-11-05 18:44:32,338 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6194 | Iter Mean Loss 8.6194
2020-11-05 18:44:32,347 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1669 | Iter Mean Loss 5.8932
2020-11-05 18:44:32,356 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7566 | Iter Mean Loss 7.5143
2020-11-05 18:44:32,363 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4344 | Iter Mean Loss 7.9943
2020-11-05 18:44:32,372 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3291 | Iter Mean Loss 7.6613
2020-11-05 18:44:32,374 - root - INFO - Evaluate: Epoch 0374 | NDCG 1.0000 | MSE 0.3341
2020-11-05 18:44:32,383 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5980 | Iter Mean Loss 8.5980
2020-11-05 18:44:32,392 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1605 | Iter Mean Loss 5.8792
2020-11-05 18:44:32,400 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7298 | Iter Mean Loss 7.4961
2020-11-05 18:44:32,408 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4108 | Iter Mean Loss 7.9748
2020-11-05 18:44:32,420 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3124 | Iter Mean Loss 7.6423
2020-11-05 18:44:32,423 - root - INFO - Evaluate: Epoch 0375 | NDCG 1.0000 | MSE 0.3339
2020-11-05 18:44:32,434 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5767
2020-11-05 18:44:32,444 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 5.8654
2020-11-05 18:44:32,452 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7033 | Iter Mean Loss 7.4780
2020-11-05 18:44:32,460 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3873 | Iter Mean Loss 7.9553
2020-11-05 18:44:32,467 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2958 | Iter Mean Loss 7.6234
2020-11-05 18:44:32,469 - root - INFO - Evaluate: Epoch 0376 | NDCG 1.0000 | MSE 0.3338
2020-11-05 18:44:32,478 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5555 | Iter Mean Loss 8.5555
2020-11-05 18:44:32,486 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1479 | Iter Mean Loss 5.8517
2020-11-05 18:44:32,493 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6769 | Iter Mean Loss 7.4601
2020-11-05 18:44:32,502 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3639 | Iter Mean Loss 7.9360
2020-11-05 18:44:32,511 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2793 | Iter Mean Loss 7.6047
2020-11-05 18:44:32,514 - root - INFO - Evaluate: Epoch 0377 | NDCG 1.0000 | MSE 0.3336
2020-11-05 18:44:32,523 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5346 | Iter Mean Loss 8.5346
2020-11-05 18:44:32,533 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1416 | Iter Mean Loss 5.8381
2020-11-05 18:44:32,543 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6507 | Iter Mean Loss 7.4423
2020-11-05 18:44:32,554 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3407 | Iter Mean Loss 7.9169
2020-11-05 18:44:32,565 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2630 | Iter Mean Loss 7.5861
2020-11-05 18:44:32,568 - root - INFO - Evaluate: Epoch 0378 | NDCG 1.0000 | MSE 0.3335
2020-11-05 18:44:32,579 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5137 | Iter Mean Loss 8.5137
2020-11-05 18:44:32,589 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1355 | Iter Mean Loss 5.8246
2020-11-05 18:44:32,598 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6248 | Iter Mean Loss 7.4246
2020-11-05 18:44:32,608 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3176 | Iter Mean Loss 7.8979
2020-11-05 18:44:32,618 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2468 | Iter Mean Loss 7.5677
2020-11-05 18:44:32,621 - root - INFO - Evaluate: Epoch 0379 | NDCG 1.0000 | MSE 0.3333
2020-11-05 18:44:32,629 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4930 | Iter Mean Loss 8.4930
2020-11-05 18:44:32,638 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1293 | Iter Mean Loss 5.8112
2020-11-05 18:44:32,646 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5990 | Iter Mean Loss 7.4071
2020-11-05 18:44:32,654 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2946 | Iter Mean Loss 7.8790
2020-11-05 18:44:32,662 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2308 | Iter Mean Loss 7.5494
2020-11-05 18:44:32,664 - root - INFO - Evaluate: Epoch 0380 | NDCG 1.0000 | MSE 0.3332
2020-11-05 18:44:32,672 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4725 | Iter Mean Loss 8.4725
2020-11-05 18:44:32,681 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1233 | Iter Mean Loss 5.7979
2020-11-05 18:44:32,689 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 7.3897
2020-11-05 18:44:32,696 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2718 | Iter Mean Loss 7.8602
2020-11-05 18:44:32,703 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2150 | Iter Mean Loss 7.5312
2020-11-05 18:44:32,705 - root - INFO - Evaluate: Epoch 0381 | NDCG 1.0000 | MSE 0.3330
2020-11-05 18:44:32,713 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 18:44:32,721 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1172 | Iter Mean Loss 5.7847
2020-11-05 18:44:32,730 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5480 | Iter Mean Loss 7.3725
2020-11-05 18:44:32,738 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2491 | Iter Mean Loss 7.8416
2020-11-05 18:44:32,747 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 7.5132
2020-11-05 18:44:32,749 - root - INFO - Evaluate: Epoch 0382 | NDCG 1.0000 | MSE 0.3329
2020-11-05 18:44:32,758 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4320 | Iter Mean Loss 8.4320
2020-11-05 18:44:32,767 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1113 | Iter Mean Loss 5.7716
2020-11-05 18:44:32,775 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5228 | Iter Mean Loss 7.3554
2020-11-05 18:44:32,783 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2266 | Iter Mean Loss 7.8232
2020-11-05 18:44:32,791 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1836 | Iter Mean Loss 7.4953
2020-11-05 18:44:32,794 - root - INFO - Evaluate: Epoch 0383 | NDCG 1.0000 | MSE 0.3327
2020-11-05 18:44:32,803 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4119 | Iter Mean Loss 8.4119
2020-11-05 18:44:32,812 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1054 | Iter Mean Loss 5.7587
2020-11-05 18:44:32,821 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4978 | Iter Mean Loss 7.3384
2020-11-05 18:44:32,829 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2042 | Iter Mean Loss 7.8048
2020-11-05 18:44:32,837 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1682 | Iter Mean Loss 7.4775
2020-11-05 18:44:32,840 - root - INFO - Evaluate: Epoch 0384 | NDCG 1.0000 | MSE 0.3326
2020-11-05 18:44:32,849 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3921 | Iter Mean Loss 8.3921
2020-11-05 18:44:32,857 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0996 | Iter Mean Loss 5.7458
2020-11-05 18:44:32,864 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4730 | Iter Mean Loss 7.3215
2020-11-05 18:44:32,872 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1820 | Iter Mean Loss 7.7867
2020-11-05 18:44:32,879 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1529 | Iter Mean Loss 7.4599
2020-11-05 18:44:32,881 - root - INFO - Evaluate: Epoch 0385 | NDCG 1.0000 | MSE 0.3324
2020-11-05 18:44:32,889 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3724 | Iter Mean Loss 8.3724
2020-11-05 18:44:32,898 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0938 | Iter Mean Loss 5.7331
2020-11-05 18:44:32,905 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4483 | Iter Mean Loss 7.3048
2020-11-05 18:44:32,913 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1599 | Iter Mean Loss 7.7686
2020-11-05 18:44:32,920 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1377 | Iter Mean Loss 7.4424
2020-11-05 18:44:32,923 - root - INFO - Evaluate: Epoch 0386 | NDCG 1.0000 | MSE 0.3323
2020-11-05 18:44:32,932 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3528 | Iter Mean Loss 8.3528
2020-11-05 18:44:32,940 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0880 | Iter Mean Loss 5.7204
2020-11-05 18:44:32,948 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4239 | Iter Mean Loss 7.2883
2020-11-05 18:44:32,956 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1379 | Iter Mean Loss 7.7507
2020-11-05 18:44:32,965 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1227 | Iter Mean Loss 7.4251
2020-11-05 18:44:32,967 - root - INFO - Evaluate: Epoch 0387 | NDCG 1.0000 | MSE 0.3322
2020-11-05 18:44:32,976 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.3335
2020-11-05 18:44:32,985 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0824 | Iter Mean Loss 5.7079
2020-11-05 18:44:32,993 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3996 | Iter Mean Loss 7.2718
2020-11-05 18:44:33,002 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1161 | Iter Mean Loss 7.7329
2020-11-05 18:44:33,012 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1077 | Iter Mean Loss 7.4079
2020-11-05 18:44:33,014 - root - INFO - Evaluate: Epoch 0388 | NDCG 1.0000 | MSE 0.3320
2020-11-05 18:44:33,022 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3143 | Iter Mean Loss 8.3143
2020-11-05 18:44:33,030 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0768 | Iter Mean Loss 5.6955
2020-11-05 18:44:33,039 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3755 | Iter Mean Loss 7.2555
2020-11-05 18:44:33,046 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0945 | Iter Mean Loss 7.7153
2020-11-05 18:44:33,055 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0929 | Iter Mean Loss 7.3908
2020-11-05 18:44:33,058 - root - INFO - Evaluate: Epoch 0389 | NDCG 1.0000 | MSE 0.3319
2020-11-05 18:44:33,067 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2953 | Iter Mean Loss 8.2953
2020-11-05 18:44:33,076 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0712 | Iter Mean Loss 5.6832
2020-11-05 18:44:33,083 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3516 | Iter Mean Loss 7.2393
2020-11-05 18:44:33,091 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0729 | Iter Mean Loss 7.6977
2020-11-05 18:44:33,100 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0783 | Iter Mean Loss 7.3738
2020-11-05 18:44:33,102 - root - INFO - Evaluate: Epoch 0390 | NDCG 1.0000 | MSE 0.3318
2020-11-05 18:44:33,110 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2764 | Iter Mean Loss 8.2764
2020-11-05 18:44:33,117 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0657 | Iter Mean Loss 5.6711
2020-11-05 18:44:33,126 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3278 | Iter Mean Loss 7.2233
2020-11-05 18:44:33,134 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0516 | Iter Mean Loss 7.6804
2020-11-05 18:44:33,142 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0637 | Iter Mean Loss 7.3570
2020-11-05 18:44:33,145 - root - INFO - Evaluate: Epoch 0391 | NDCG 1.0000 | MSE 0.3317
2020-11-05 18:44:33,154 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2577 | Iter Mean Loss 8.2577
2020-11-05 18:44:33,161 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0603 | Iter Mean Loss 5.6590
2020-11-05 18:44:33,170 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3042 | Iter Mean Loss 7.2074
2020-11-05 18:44:33,178 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0303 | Iter Mean Loss 7.6631
2020-11-05 18:44:33,188 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0493 | Iter Mean Loss 7.3404
2020-11-05 18:44:33,190 - root - INFO - Evaluate: Epoch 0392 | NDCG 1.0000 | MSE 0.3315
2020-11-05 18:44:33,198 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2392 | Iter Mean Loss 8.2392
2020-11-05 18:44:33,207 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0549 | Iter Mean Loss 5.6470
2020-11-05 18:44:33,215 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2808 | Iter Mean Loss 7.1916
2020-11-05 18:44:33,223 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0092 | Iter Mean Loss 7.6460
2020-11-05 18:44:33,230 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0350 | Iter Mean Loss 7.3238
2020-11-05 18:44:33,233 - root - INFO - Evaluate: Epoch 0393 | NDCG 1.0000 | MSE 0.3314
2020-11-05 18:44:33,243 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2208 | Iter Mean Loss 8.2208
2020-11-05 18:44:33,251 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0495 | Iter Mean Loss 5.6352
2020-11-05 18:44:33,259 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2576 | Iter Mean Loss 7.1760
2020-11-05 18:44:33,266 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9883 | Iter Mean Loss 7.6291
2020-11-05 18:44:33,273 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0208 | Iter Mean Loss 7.3074
2020-11-05 18:44:33,275 - root - INFO - Evaluate: Epoch 0394 | NDCG 1.0000 | MSE 0.3313
2020-11-05 18:44:33,283 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2026 | Iter Mean Loss 8.2026
2020-11-05 18:44:33,291 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0443 | Iter Mean Loss 5.6234
2020-11-05 18:44:33,298 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2345 | Iter Mean Loss 7.1605
2020-11-05 18:44:33,305 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9675 | Iter Mean Loss 7.6122
2020-11-05 18:44:33,313 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0067 | Iter Mean Loss 7.2911
2020-11-05 18:44:33,315 - root - INFO - Evaluate: Epoch 0395 | NDCG 1.0000 | MSE 0.3312
2020-11-05 18:44:33,327 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1846 | Iter Mean Loss 8.1846
2020-11-05 18:44:33,337 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0390 | Iter Mean Loss 5.6118
2020-11-05 18:44:33,347 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2116 | Iter Mean Loss 7.1451
2020-11-05 18:44:33,357 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 7.5955
2020-11-05 18:44:33,365 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9927 | Iter Mean Loss 7.2749
2020-11-05 18:44:33,369 - root - INFO - Evaluate: Epoch 0396 | NDCG 1.0000 | MSE 0.3310
2020-11-05 18:44:33,379 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1667 | Iter Mean Loss 8.1667
2020-11-05 18:44:33,390 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0339 | Iter Mean Loss 5.6003
2020-11-05 18:44:33,399 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1889 | Iter Mean Loss 7.1298
2020-11-05 18:44:33,410 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9263 | Iter Mean Loss 7.5789
2020-11-05 18:44:33,419 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9788 | Iter Mean Loss 7.2589
2020-11-05 18:44:33,423 - root - INFO - Evaluate: Epoch 0397 | NDCG 1.0000 | MSE 0.3309
2020-11-05 18:44:33,433 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1490 | Iter Mean Loss 8.1490
2020-11-05 18:44:33,446 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0287 | Iter Mean Loss 5.5889
2020-11-05 18:44:33,458 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1663 | Iter Mean Loss 7.1147
2020-11-05 18:44:33,466 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9059 | Iter Mean Loss 7.5625
2020-11-05 18:44:33,478 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9650 | Iter Mean Loss 7.2430
2020-11-05 18:44:33,480 - root - INFO - Evaluate: Epoch 0398 | NDCG 1.0000 | MSE 0.3308
2020-11-05 18:44:33,489 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1315 | Iter Mean Loss 8.1315
2020-11-05 18:44:33,499 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0237 | Iter Mean Loss 5.5776
2020-11-05 18:44:33,508 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1439 | Iter Mean Loss 7.0997
2020-11-05 18:44:33,518 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8856 | Iter Mean Loss 7.5462
2020-11-05 18:44:33,527 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 7.2272
2020-11-05 18:44:33,530 - root - INFO - Evaluate: Epoch 0399 | NDCG 1.0000 | MSE 0.3307
2020-11-05 18:44:33,540 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1141 | Iter Mean Loss 8.1141
2020-11-05 18:44:33,550 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0187 | Iter Mean Loss 5.5664
2020-11-05 18:44:33,559 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1216 | Iter Mean Loss 7.0848
2020-11-05 18:44:33,569 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8655 | Iter Mean Loss 7.5300
2020-11-05 18:44:33,578 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9378 | Iter Mean Loss 7.2115
2020-11-05 18:44:33,582 - root - INFO - Evaluate: Epoch 0400 | NDCG 1.0000 | MSE 0.3306
2020-11-05 18:44:33,592 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0969 | Iter Mean Loss 8.0969
2020-11-05 18:44:33,603 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0137 | Iter Mean Loss 5.5553
2020-11-05 18:44:33,611 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0995 | Iter Mean Loss 7.0700
2020-11-05 18:44:33,622 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8455 | Iter Mean Loss 7.5139
2020-11-05 18:44:33,630 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9243 | Iter Mean Loss 7.1960
2020-11-05 18:44:33,633 - root - INFO - Evaluate: Epoch 0401 | NDCG 1.0000 | MSE 0.3305
2020-11-05 18:44:33,643 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0799 | Iter Mean Loss 8.0799
2020-11-05 18:44:33,653 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0088 | Iter Mean Loss 5.5443
2020-11-05 18:44:33,662 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0775 | Iter Mean Loss 7.0554
2020-11-05 18:44:33,672 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8257 | Iter Mean Loss 7.4979
2020-11-05 18:44:33,680 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9110 | Iter Mean Loss 7.1806
2020-11-05 18:44:33,683 - root - INFO - Evaluate: Epoch 0402 | NDCG 1.0000 | MSE 0.3304
2020-11-05 18:44:33,693 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0630 | Iter Mean Loss 8.0630
2020-11-05 18:44:33,703 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0039 | Iter Mean Loss 5.5334
2020-11-05 18:44:33,711 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0557 | Iter Mean Loss 7.0409
2020-11-05 18:44:33,722 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8059 | Iter Mean Loss 7.4821
2020-11-05 18:44:33,730 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8977 | Iter Mean Loss 7.1652
2020-11-05 18:44:33,733 - root - INFO - Evaluate: Epoch 0403 | NDCG 1.0000 | MSE 0.3303
2020-11-05 18:44:33,743 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0462 | Iter Mean Loss 8.0462
2020-11-05 18:44:33,754 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9991 | Iter Mean Loss 5.5227
2020-11-05 18:44:33,762 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0340 | Iter Mean Loss 7.0264
2020-11-05 18:44:33,772 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7864 | Iter Mean Loss 7.4664
2020-11-05 18:44:33,780 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8845 | Iter Mean Loss 7.1500
2020-11-05 18:44:33,784 - root - INFO - Evaluate: Epoch 0404 | NDCG 1.0000 | MSE 0.3302
2020-11-05 18:44:33,793 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0297 | Iter Mean Loss 8.0297
2020-11-05 18:44:33,804 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9943 | Iter Mean Loss 5.5120
2020-11-05 18:44:33,812 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0125 | Iter Mean Loss 7.0122
2020-11-05 18:44:33,822 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7669 | Iter Mean Loss 7.4508
2020-11-05 18:44:33,830 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8714 | Iter Mean Loss 7.1350
2020-11-05 18:44:33,834 - root - INFO - Evaluate: Epoch 0405 | NDCG 1.0000 | MSE 0.3301
2020-11-05 18:44:33,843 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0132 | Iter Mean Loss 8.0132
2020-11-05 18:44:33,854 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9896 | Iter Mean Loss 5.5014
2020-11-05 18:44:33,862 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9911 | Iter Mean Loss 6.9980
2020-11-05 18:44:33,872 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7476 | Iter Mean Loss 7.4354
2020-11-05 18:44:33,880 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8584 | Iter Mean Loss 7.1200
2020-11-05 18:44:33,883 - root - INFO - Evaluate: Epoch 0406 | NDCG 1.0000 | MSE 0.3300
2020-11-05 18:44:33,893 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9970 | Iter Mean Loss 7.9970
2020-11-05 18:44:33,903 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9849 | Iter Mean Loss 5.4909
2020-11-05 18:44:33,911 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9699 | Iter Mean Loss 6.9839
2020-11-05 18:44:33,921 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7284 | Iter Mean Loss 7.4200
2020-11-05 18:44:33,929 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8454 | Iter Mean Loss 7.1051
2020-11-05 18:44:33,932 - root - INFO - Evaluate: Epoch 0407 | NDCG 1.0000 | MSE 0.3299
2020-11-05 18:44:33,942 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9808 | Iter Mean Loss 7.9808
2020-11-05 18:44:33,952 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9803 | Iter Mean Loss 5.4806
2020-11-05 18:44:33,960 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9488 | Iter Mean Loss 6.9700
2020-11-05 18:44:33,970 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7094 | Iter Mean Loss 7.4048
2020-11-05 18:44:33,978 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8326 | Iter Mean Loss 7.0904
2020-11-05 18:44:33,982 - root - INFO - Evaluate: Epoch 0408 | NDCG 1.0000 | MSE 0.3298
2020-11-05 18:44:33,993 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9649 | Iter Mean Loss 7.9649
2020-11-05 18:44:34,003 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9757 | Iter Mean Loss 5.4703
2020-11-05 18:44:34,011 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9278 | Iter Mean Loss 6.9561
2020-11-05 18:44:34,021 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6904 | Iter Mean Loss 7.3897
2020-11-05 18:44:34,029 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8198 | Iter Mean Loss 7.0757
2020-11-05 18:44:34,032 - root - INFO - Evaluate: Epoch 0409 | NDCG 1.0000 | MSE 0.3297
2020-11-05 18:44:34,042 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9490 | Iter Mean Loss 7.9490
2020-11-05 18:44:34,053 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9712 | Iter Mean Loss 5.4601
2020-11-05 18:44:34,061 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9070 | Iter Mean Loss 6.9424
2020-11-05 18:44:34,070 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6716 | Iter Mean Loss 7.3747
2020-11-05 18:44:34,078 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8072 | Iter Mean Loss 7.0612
2020-11-05 18:44:34,081 - root - INFO - Evaluate: Epoch 0410 | NDCG 1.0000 | MSE 0.3296
2020-11-05 18:44:34,091 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9334 | Iter Mean Loss 7.9334
2020-11-05 18:44:34,099 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9667 | Iter Mean Loss 5.4500
2020-11-05 18:44:34,109 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 6.9288
2020-11-05 18:44:34,118 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6530 | Iter Mean Loss 7.3598
2020-11-05 18:44:34,127 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7945 | Iter Mean Loss 7.0468
2020-11-05 18:44:34,129 - root - INFO - Evaluate: Epoch 0411 | NDCG 1.0000 | MSE 0.3295
2020-11-05 18:44:34,140 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9178 | Iter Mean Loss 7.9178
2020-11-05 18:44:34,148 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9622 | Iter Mean Loss 5.4400
2020-11-05 18:44:34,158 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8657 | Iter Mean Loss 6.9153
2020-11-05 18:44:34,166 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6344 | Iter Mean Loss 7.3450
2020-11-05 18:44:34,175 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7820 | Iter Mean Loss 7.0324
2020-11-05 18:44:34,177 - root - INFO - Evaluate: Epoch 0412 | NDCG 1.0000 | MSE 0.3294
2020-11-05 18:44:34,188 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9025 | Iter Mean Loss 7.9025
2020-11-05 18:44:34,196 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9578 | Iter Mean Loss 5.4301
2020-11-05 18:44:34,206 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8453 | Iter Mean Loss 6.9018
2020-11-05 18:44:34,214 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6160 | Iter Mean Loss 7.3304
2020-11-05 18:44:34,224 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7696 | Iter Mean Loss 7.0182
2020-11-05 18:44:34,226 - root - INFO - Evaluate: Epoch 0413 | NDCG 1.0000 | MSE 0.3293
2020-11-05 18:44:34,236 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8872 | Iter Mean Loss 7.8872
2020-11-05 18:44:34,245 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 5.4203
2020-11-05 18:44:34,256 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8250 | Iter Mean Loss 6.8885
2020-11-05 18:44:34,264 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5977 | Iter Mean Loss 7.3158
2020-11-05 18:44:34,274 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7572 | Iter Mean Loss 7.0041
2020-11-05 18:44:34,276 - root - INFO - Evaluate: Epoch 0414 | NDCG 1.0000 | MSE 0.3292
2020-11-05 18:44:34,285 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8721 | Iter Mean Loss 7.8721
2020-11-05 18:44:34,294 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9491 | Iter Mean Loss 5.4106
2020-11-05 18:44:34,304 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8048 | Iter Mean Loss 6.8753
2020-11-05 18:44:34,313 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5795 | Iter Mean Loss 7.3014
2020-11-05 18:44:34,324 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7449 | Iter Mean Loss 6.9901
2020-11-05 18:44:34,327 - root - INFO - Evaluate: Epoch 0415 | NDCG 1.0000 | MSE 0.3291
2020-11-05 18:44:34,335 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8571 | Iter Mean Loss 7.8571
2020-11-05 18:44:34,344 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9448 | Iter Mean Loss 5.4010
2020-11-05 18:44:34,351 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7847 | Iter Mean Loss 6.8622
2020-11-05 18:44:34,359 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5615 | Iter Mean Loss 7.2870
2020-11-05 18:44:34,366 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7326 | Iter Mean Loss 6.9761
2020-11-05 18:44:34,370 - root - INFO - Evaluate: Epoch 0416 | NDCG 1.0000 | MSE 0.3290
2020-11-05 18:44:34,379 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8423 | Iter Mean Loss 7.8423
2020-11-05 18:44:34,387 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9405 | Iter Mean Loss 5.3914
2020-11-05 18:44:34,395 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7648 | Iter Mean Loss 6.8492
2020-11-05 18:44:34,403 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 7.2728
2020-11-05 18:44:34,412 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7205 | Iter Mean Loss 6.9623
2020-11-05 18:44:34,414 - root - INFO - Evaluate: Epoch 0417 | NDCG 1.0000 | MSE 0.3289
2020-11-05 18:44:34,424 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 7.8276
2020-11-05 18:44:34,432 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 5.3820
2020-11-05 18:44:34,440 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7449 | Iter Mean Loss 6.8363
2020-11-05 18:44:34,448 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5257 | Iter Mean Loss 7.2586
2020-11-05 18:44:34,455 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7083 | Iter Mean Loss 6.9486
2020-11-05 18:44:34,457 - root - INFO - Evaluate: Epoch 0418 | NDCG 1.0000 | MSE 0.3288
2020-11-05 18:44:34,467 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8131 | Iter Mean Loss 7.8131
2020-11-05 18:44:34,474 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9321 | Iter Mean Loss 5.3726
2020-11-05 18:44:34,482 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7252 | Iter Mean Loss 6.8235
2020-11-05 18:44:34,490 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5080 | Iter Mean Loss 7.2446
2020-11-05 18:44:34,497 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6963 | Iter Mean Loss 6.9349
2020-11-05 18:44:34,499 - root - INFO - Evaluate: Epoch 0419 | NDCG 1.0000 | MSE 0.3287
2020-11-05 18:44:34,507 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7986 | Iter Mean Loss 7.7986
2020-11-05 18:44:34,515 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9279 | Iter Mean Loss 5.3633
2020-11-05 18:44:34,522 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7056 | Iter Mean Loss 6.8107
2020-11-05 18:44:34,529 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4904 | Iter Mean Loss 7.2307
2020-11-05 18:44:34,536 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6843 | Iter Mean Loss 6.9214
2020-11-05 18:44:34,538 - root - INFO - Evaluate: Epoch 0420 | NDCG 1.0000 | MSE 0.3286
2020-11-05 18:44:34,546 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7843 | Iter Mean Loss 7.7843
2020-11-05 18:44:34,554 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9238 | Iter Mean Loss 5.3541
2020-11-05 18:44:34,561 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6862 | Iter Mean Loss 6.7981
2020-11-05 18:44:34,569 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4729 | Iter Mean Loss 7.2168
2020-11-05 18:44:34,577 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6724 | Iter Mean Loss 6.9079
2020-11-05 18:44:34,579 - root - INFO - Evaluate: Epoch 0421 | NDCG 1.0000 | MSE 0.3285
2020-11-05 18:44:34,587 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7701 | Iter Mean Loss 7.7701
2020-11-05 18:44:34,596 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9197 | Iter Mean Loss 5.3449
2020-11-05 18:44:34,604 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6668 | Iter Mean Loss 6.7856
2020-11-05 18:44:34,612 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4555 | Iter Mean Loss 7.2031
2020-11-05 18:44:34,620 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6605 | Iter Mean Loss 6.8946
2020-11-05 18:44:34,622 - root - INFO - Evaluate: Epoch 0422 | NDCG 1.0000 | MSE 0.3284
2020-11-05 18:44:34,632 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7561 | Iter Mean Loss 7.7561
2020-11-05 18:44:34,639 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9157 | Iter Mean Loss 5.3359
2020-11-05 18:44:34,648 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6476 | Iter Mean Loss 6.7731
2020-11-05 18:44:34,656 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4383 | Iter Mean Loss 7.1894
2020-11-05 18:44:34,665 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6488 | Iter Mean Loss 6.8813
2020-11-05 18:44:34,668 - root - INFO - Evaluate: Epoch 0423 | NDCG 1.0000 | MSE 0.3284
2020-11-05 18:44:34,677 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7422 | Iter Mean Loss 7.7422
2020-11-05 18:44:34,687 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9117 | Iter Mean Loss 5.3269
2020-11-05 18:44:34,696 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6284 | Iter Mean Loss 6.7608
2020-11-05 18:44:34,705 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4211 | Iter Mean Loss 7.1758
2020-11-05 18:44:34,715 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6370 | Iter Mean Loss 6.8681
2020-11-05 18:44:34,717 - root - INFO - Evaluate: Epoch 0424 | NDCG 1.0000 | MSE 0.3283
2020-11-05 18:44:34,726 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7284 | Iter Mean Loss 7.7284
2020-11-05 18:44:34,736 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9077 | Iter Mean Loss 5.3180
2020-11-05 18:44:34,744 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6094 | Iter Mean Loss 6.7485
2020-11-05 18:44:34,753 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4041 | Iter Mean Loss 7.1624
2020-11-05 18:44:34,763 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6253 | Iter Mean Loss 6.8550
2020-11-05 18:44:34,767 - root - INFO - Evaluate: Epoch 0425 | NDCG 1.0000 | MSE 0.3282
2020-11-05 18:44:34,776 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7147 | Iter Mean Loss 7.7147
2020-11-05 18:44:34,785 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9037 | Iter Mean Loss 5.3092
2020-11-05 18:44:34,794 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5905 | Iter Mean Loss 6.7363
2020-11-05 18:44:34,803 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3871 | Iter Mean Loss 7.1490
2020-11-05 18:44:34,812 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6137 | Iter Mean Loss 6.8419
2020-11-05 18:44:34,816 - root - INFO - Evaluate: Epoch 0426 | NDCG 1.0000 | MSE 0.3281
2020-11-05 18:44:34,826 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7011 | Iter Mean Loss 7.7011
2020-11-05 18:44:34,835 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8998 | Iter Mean Loss 5.3005
2020-11-05 18:44:34,844 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5716 | Iter Mean Loss 6.7242
2020-11-05 18:44:34,854 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3703 | Iter Mean Loss 7.1357
2020-11-05 18:44:34,863 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6021 | Iter Mean Loss 6.8290
2020-11-05 18:44:34,868 - root - INFO - Evaluate: Epoch 0427 | NDCG 1.0000 | MSE 0.3280
2020-11-05 18:44:34,878 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6877 | Iter Mean Loss 7.6877
2020-11-05 18:44:34,888 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8959 | Iter Mean Loss 5.2918
2020-11-05 18:44:34,896 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5529 | Iter Mean Loss 6.7122
2020-11-05 18:44:34,905 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3536 | Iter Mean Loss 7.1225
2020-11-05 18:44:34,914 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5906 | Iter Mean Loss 6.8161
2020-11-05 18:44:34,917 - root - INFO - Evaluate: Epoch 0428 | NDCG 1.0000 | MSE 0.3279
2020-11-05 18:44:34,926 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6743 | Iter Mean Loss 7.6743
2020-11-05 18:44:34,935 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8920 | Iter Mean Loss 5.2832
2020-11-05 18:44:34,943 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5343 | Iter Mean Loss 6.7002
2020-11-05 18:44:34,952 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3370 | Iter Mean Loss 7.1094
2020-11-05 18:44:34,960 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5791 | Iter Mean Loss 6.8034
2020-11-05 18:44:34,962 - root - INFO - Evaluate: Epoch 0429 | NDCG 1.0000 | MSE 0.3278
2020-11-05 18:44:34,974 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6611 | Iter Mean Loss 7.6611
2020-11-05 18:44:34,983 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8882 | Iter Mean Loss 5.2747
2020-11-05 18:44:34,994 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 6.6884
2020-11-05 18:44:35,004 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3204 | Iter Mean Loss 7.0964
2020-11-05 18:44:35,012 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5677 | Iter Mean Loss 6.7907
2020-11-05 18:44:35,015 - root - INFO - Evaluate: Epoch 0430 | NDCG 1.0000 | MSE 0.3278
2020-11-05 18:44:35,027 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6480 | Iter Mean Loss 7.6480
2020-11-05 18:44:35,038 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8844 | Iter Mean Loss 5.2662
2020-11-05 18:44:35,047 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4974 | Iter Mean Loss 6.6766
2020-11-05 18:44:35,057 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3040 | Iter Mean Loss 7.0834
2020-11-05 18:44:35,066 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5564 | Iter Mean Loss 6.7780
2020-11-05 18:44:35,071 - root - INFO - Evaluate: Epoch 0431 | NDCG 1.0000 | MSE 0.3277
2020-11-05 18:44:35,080 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6350 | Iter Mean Loss 7.6350
2020-11-05 18:44:35,090 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8806 | Iter Mean Loss 5.2578
2020-11-05 18:44:35,099 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4791 | Iter Mean Loss 6.6649
2020-11-05 18:44:35,107 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 7.0706
2020-11-05 18:44:35,114 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5451 | Iter Mean Loss 6.7655
2020-11-05 18:44:35,117 - root - INFO - Evaluate: Epoch 0432 | NDCG 1.0000 | MSE 0.3276
2020-11-05 18:44:35,124 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6221 | Iter Mean Loss 7.6221
2020-11-05 18:44:35,132 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8768 | Iter Mean Loss 5.2495
2020-11-05 18:44:35,139 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4609 | Iter Mean Loss 6.6533
2020-11-05 18:44:35,146 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2714 | Iter Mean Loss 7.0578
2020-11-05 18:44:35,154 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5338 | Iter Mean Loss 6.7530
2020-11-05 18:44:35,156 - root - INFO - Evaluate: Epoch 0433 | NDCG 1.0000 | MSE 0.3275
2020-11-05 18:44:35,163 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 7.6093
2020-11-05 18:44:35,171 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8731 | Iter Mean Loss 5.2412
2020-11-05 18:44:35,178 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4427 | Iter Mean Loss 6.6417
2020-11-05 18:44:35,186 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2553 | Iter Mean Loss 7.0451
2020-11-05 18:44:35,194 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5226 | Iter Mean Loss 6.7406
2020-11-05 18:44:35,196 - root - INFO - Evaluate: Epoch 0434 | NDCG 1.0000 | MSE 0.3274
2020-11-05 18:44:35,204 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5966 | Iter Mean Loss 7.5966
2020-11-05 18:44:35,212 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8694 | Iter Mean Loss 5.2330
2020-11-05 18:44:35,220 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4247 | Iter Mean Loss 6.6302
2020-11-05 18:44:35,228 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2393 | Iter Mean Loss 7.0325
2020-11-05 18:44:35,236 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5114 | Iter Mean Loss 6.7283
2020-11-05 18:44:35,238 - root - INFO - Evaluate: Epoch 0435 | NDCG 1.0000 | MSE 0.3274
2020-11-05 18:44:35,247 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5840 | Iter Mean Loss 7.5840
2020-11-05 18:44:35,254 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8657 | Iter Mean Loss 5.2249
2020-11-05 18:44:35,262 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 6.6188
2020-11-05 18:44:35,270 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2233 | Iter Mean Loss 7.0200
2020-11-05 18:44:35,278 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5003 | Iter Mean Loss 6.7160
2020-11-05 18:44:35,281 - root - INFO - Evaluate: Epoch 0436 | NDCG 1.0000 | MSE 0.3273
2020-11-05 18:44:35,289 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5716 | Iter Mean Loss 7.5716
2020-11-05 18:44:35,297 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8620 | Iter Mean Loss 5.2168
2020-11-05 18:44:35,304 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3889 | Iter Mean Loss 6.6075
2020-11-05 18:44:35,312 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2075 | Iter Mean Loss 7.0075
2020-11-05 18:44:35,321 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4892 | Iter Mean Loss 6.7038
2020-11-05 18:44:35,324 - root - INFO - Evaluate: Epoch 0437 | NDCG 1.0000 | MSE 0.3272
2020-11-05 18:44:35,332 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5592 | Iter Mean Loss 7.5592
2020-11-05 18:44:35,342 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8584 | Iter Mean Loss 5.2088
2020-11-05 18:44:35,350 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3712 | Iter Mean Loss 6.5962
2020-11-05 18:44:35,359 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1917 | Iter Mean Loss 6.9951
2020-11-05 18:44:35,368 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4782 | Iter Mean Loss 6.6917
2020-11-05 18:44:35,371 - root - INFO - Evaluate: Epoch 0438 | NDCG 1.0000 | MSE 0.3271
2020-11-05 18:44:35,380 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5469 | Iter Mean Loss 7.5469
2020-11-05 18:44:35,390 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8548 | Iter Mean Loss 5.2008
2020-11-05 18:44:35,398 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3535 | Iter Mean Loss 6.5851
2020-11-05 18:44:35,407 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1760 | Iter Mean Loss 6.9828
2020-11-05 18:44:35,415 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4672 | Iter Mean Loss 6.6797
2020-11-05 18:44:35,419 - root - INFO - Evaluate: Epoch 0439 | NDCG 1.0000 | MSE 0.3270
2020-11-05 18:44:35,429 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5347 | Iter Mean Loss 7.5347
2020-11-05 18:44:35,439 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8512 | Iter Mean Loss 5.1930
2020-11-05 18:44:35,447 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3359 | Iter Mean Loss 6.5739
2020-11-05 18:44:35,457 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 6.9706
2020-11-05 18:44:35,466 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4562 | Iter Mean Loss 6.6677
2020-11-05 18:44:35,470 - root - INFO - Evaluate: Epoch 0440 | NDCG 1.0000 | MSE 0.3270
2020-11-05 18:44:35,479 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5227 | Iter Mean Loss 7.5227
2020-11-05 18:44:35,488 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8476 | Iter Mean Loss 5.1851
2020-11-05 18:44:35,496 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3184 | Iter Mean Loss 6.5629
2020-11-05 18:44:35,508 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1449 | Iter Mean Loss 6.9584
2020-11-05 18:44:35,517 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4453 | Iter Mean Loss 6.6558
2020-11-05 18:44:35,520 - root - INFO - Evaluate: Epoch 0441 | NDCG 1.0000 | MSE 0.3269
2020-11-05 18:44:35,533 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5107 | Iter Mean Loss 7.5107
2020-11-05 18:44:35,545 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8440 | Iter Mean Loss 5.1773
2020-11-05 18:44:35,557 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3010 | Iter Mean Loss 6.5519
2020-11-05 18:44:35,568 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1295 | Iter Mean Loss 6.9463
2020-11-05 18:44:35,579 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4344 | Iter Mean Loss 6.6439
2020-11-05 18:44:35,582 - root - INFO - Evaluate: Epoch 0442 | NDCG 1.0000 | MSE 0.3268
2020-11-05 18:44:35,594 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4988 | Iter Mean Loss 7.4988
2020-11-05 18:44:35,605 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8405 | Iter Mean Loss 5.1696
2020-11-05 18:44:35,614 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2837 | Iter Mean Loss 6.5410
2020-11-05 18:44:35,626 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1142 | Iter Mean Loss 6.9343
2020-11-05 18:44:35,638 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4236 | Iter Mean Loss 6.6321
2020-11-05 18:44:35,641 - root - INFO - Evaluate: Epoch 0443 | NDCG 1.0000 | MSE 0.3267
2020-11-05 18:44:35,652 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4870 | Iter Mean Loss 7.4870
2020-11-05 18:44:35,664 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8370 | Iter Mean Loss 5.1620
2020-11-05 18:44:35,676 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 6.5301
2020-11-05 18:44:35,688 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0989 | Iter Mean Loss 6.9223
2020-11-05 18:44:35,698 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4128 | Iter Mean Loss 6.6204
2020-11-05 18:44:35,702 - root - INFO - Evaluate: Epoch 0444 | NDCG 1.0000 | MSE 0.3267
2020-11-05 18:44:35,712 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4752 | Iter Mean Loss 7.4752
2020-11-05 18:44:35,722 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8334 | Iter Mean Loss 5.1543
2020-11-05 18:44:35,730 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2493 | Iter Mean Loss 6.5193
2020-11-05 18:44:35,740 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0837 | Iter Mean Loss 6.9104
2020-11-05 18:44:35,749 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4021 | Iter Mean Loss 6.6088
2020-11-05 18:44:35,753 - root - INFO - Evaluate: Epoch 0445 | NDCG 1.0000 | MSE 0.3266
2020-11-05 18:44:35,762 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4636 | Iter Mean Loss 7.4636
2020-11-05 18:44:35,771 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8300 | Iter Mean Loss 5.1468
2020-11-05 18:44:35,779 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2322 | Iter Mean Loss 6.5086
2020-11-05 18:44:35,788 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0686 | Iter Mean Loss 6.8986
2020-11-05 18:44:35,797 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3914 | Iter Mean Loss 6.5972
2020-11-05 18:44:35,799 - root - INFO - Evaluate: Epoch 0446 | NDCG 1.0000 | MSE 0.3265
2020-11-05 18:44:35,809 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4521 | Iter Mean Loss 7.4521
2020-11-05 18:44:35,817 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8265 | Iter Mean Loss 5.1393
2020-11-05 18:44:35,826 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2152 | Iter Mean Loss 6.4979
2020-11-05 18:44:35,835 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0536 | Iter Mean Loss 6.8868
2020-11-05 18:44:35,844 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3807 | Iter Mean Loss 6.5856
2020-11-05 18:44:35,847 - root - INFO - Evaluate: Epoch 0447 | NDCG 1.0000 | MSE 0.3264
2020-11-05 18:44:35,856 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4406 | Iter Mean Loss 7.4406
2020-11-05 18:44:35,864 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8230 | Iter Mean Loss 5.1318
2020-11-05 18:44:35,874 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1983 | Iter Mean Loss 6.4873
2020-11-05 18:44:35,882 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0387 | Iter Mean Loss 6.8752
2020-11-05 18:44:35,891 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3701 | Iter Mean Loss 6.5741
2020-11-05 18:44:35,894 - root - INFO - Evaluate: Epoch 0448 | NDCG 1.0000 | MSE 0.3264
2020-11-05 18:44:35,903 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4293 | Iter Mean Loss 7.4293
2020-11-05 18:44:35,912 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 5.1244
2020-11-05 18:44:35,920 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1815 | Iter Mean Loss 6.4768
2020-11-05 18:44:35,929 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0238 | Iter Mean Loss 6.8635
2020-11-05 18:44:35,938 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 6.5627
2020-11-05 18:44:35,940 - root - INFO - Evaluate: Epoch 0449 | NDCG 1.0000 | MSE 0.3263
2020-11-05 18:44:35,949 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 7.4180
2020-11-05 18:44:35,958 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8162 | Iter Mean Loss 5.1171
2020-11-05 18:44:35,965 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1647 | Iter Mean Loss 6.4663
2020-11-05 18:44:35,974 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0090 | Iter Mean Loss 6.8520
2020-11-05 18:44:35,982 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3489 | Iter Mean Loss 6.5514
2020-11-05 18:44:35,985 - root - INFO - Evaluate: Epoch 0450 | NDCG 1.0000 | MSE 0.3262
2020-11-05 18:44:35,995 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4068 | Iter Mean Loss 7.4068
2020-11-05 18:44:36,005 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8128 | Iter Mean Loss 5.1098
2020-11-05 18:44:36,013 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1480 | Iter Mean Loss 6.4558
2020-11-05 18:44:36,023 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9943 | Iter Mean Loss 6.8405
2020-11-05 18:44:36,031 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3384 | Iter Mean Loss 6.5401
2020-11-05 18:44:36,033 - root - INFO - Evaluate: Epoch 0451 | NDCG 1.0000 | MSE 0.3261
2020-11-05 18:44:36,044 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3956 | Iter Mean Loss 7.3956
2020-11-05 18:44:36,053 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8094 | Iter Mean Loss 5.1025
2020-11-05 18:44:36,062 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1314 | Iter Mean Loss 6.4455
2020-11-05 18:44:36,072 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9797 | Iter Mean Loss 6.8290
2020-11-05 18:44:36,080 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3279 | Iter Mean Loss 6.5288
2020-11-05 18:44:36,082 - root - INFO - Evaluate: Epoch 0452 | NDCG 1.0000 | MSE 0.3261
2020-11-05 18:44:36,092 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3846 | Iter Mean Loss 7.3846
2020-11-05 18:44:36,100 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8060 | Iter Mean Loss 5.0953
2020-11-05 18:44:36,110 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1149 | Iter Mean Loss 6.4351
2020-11-05 18:44:36,118 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 6.8176
2020-11-05 18:44:36,127 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3175 | Iter Mean Loss 6.5176
2020-11-05 18:44:36,129 - root - INFO - Evaluate: Epoch 0453 | NDCG 1.0000 | MSE 0.3260
2020-11-05 18:44:36,139 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3736 | Iter Mean Loss 7.3736
2020-11-05 18:44:36,147 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8026 | Iter Mean Loss 5.0881
2020-11-05 18:44:36,157 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 6.4249
2020-11-05 18:44:36,165 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9506 | Iter Mean Loss 6.8063
2020-11-05 18:44:36,174 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3071 | Iter Mean Loss 6.5065
2020-11-05 18:44:36,176 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:44:36,185 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3627 | Iter Mean Loss 7.3627
2020-11-05 18:44:36,194 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7992 | Iter Mean Loss 5.0810
2020-11-05 18:44:36,202 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0820 | Iter Mean Loss 6.4147
2020-11-05 18:44:36,212 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9362 | Iter Mean Loss 6.7951
2020-11-05 18:44:36,220 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2967 | Iter Mean Loss 6.4954
2020-11-05 18:44:36,224 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:44:36,233 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3519 | Iter Mean Loss 7.3519
2020-11-05 18:44:36,243 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7959 | Iter Mean Loss 5.0739
2020-11-05 18:44:36,252 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0657 | Iter Mean Loss 6.4045
2020-11-05 18:44:36,263 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9219 | Iter Mean Loss 6.7838
2020-11-05 18:44:36,272 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2863 | Iter Mean Loss 6.4843
2020-11-05 18:44:36,276 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:44:36,285 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3412 | Iter Mean Loss 7.3412
2020-11-05 18:44:36,294 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7926 | Iter Mean Loss 5.0669
2020-11-05 18:44:36,304 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0495 | Iter Mean Loss 6.3944
2020-11-05 18:44:36,313 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9076 | Iter Mean Loss 6.7727
2020-11-05 18:44:36,322 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2760 | Iter Mean Loss 6.4734
2020-11-05 18:44:36,325 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:44:36,334 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3305 | Iter Mean Loss 7.3305
2020-11-05 18:44:36,342 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7892 | Iter Mean Loss 5.0599
2020-11-05 18:44:36,350 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0333 | Iter Mean Loss 6.3844
2020-11-05 18:44:36,357 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8934 | Iter Mean Loss 6.7616
2020-11-05 18:44:36,364 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2657 | Iter Mean Loss 6.4624
2020-11-05 18:44:36,366 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:44:36,374 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3199 | Iter Mean Loss 7.3199
2020-11-05 18:44:36,381 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7859 | Iter Mean Loss 5.0529
2020-11-05 18:44:36,389 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0172 | Iter Mean Loss 6.3743
2020-11-05 18:44:36,396 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8792 | Iter Mean Loss 6.7506
2020-11-05 18:44:36,403 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2555 | Iter Mean Loss 6.4515
2020-11-05 18:44:36,406 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:44:36,414 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3094 | Iter Mean Loss 7.3094
2020-11-05 18:44:36,421 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7826 | Iter Mean Loss 5.0460
2020-11-05 18:44:36,430 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0011 | Iter Mean Loss 6.3644
2020-11-05 18:44:36,437 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8651 | Iter Mean Loss 6.7396
2020-11-05 18:44:36,446 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 6.4407
2020-11-05 18:44:36,448 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:44:36,457 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2990 | Iter Mean Loss 7.2990
2020-11-05 18:44:36,466 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7793 | Iter Mean Loss 5.0391
2020-11-05 18:44:36,473 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9852 | Iter Mean Loss 6.3545
2020-11-05 18:44:36,481 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8511 | Iter Mean Loss 6.7286
2020-11-05 18:44:36,489 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2351 | Iter Mean Loss 6.4299
2020-11-05 18:44:36,491 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:44:36,499 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2886 | Iter Mean Loss 7.2886
2020-11-05 18:44:36,508 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7760 | Iter Mean Loss 5.0323
2020-11-05 18:44:36,516 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9693 | Iter Mean Loss 6.3446
2020-11-05 18:44:36,524 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8371 | Iter Mean Loss 6.7178
2020-11-05 18:44:36,531 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2249 | Iter Mean Loss 6.4192
2020-11-05 18:44:36,533 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:44:36,541 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2783 | Iter Mean Loss 7.2783
2020-11-05 18:44:36,549 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7728 | Iter Mean Loss 5.0255
2020-11-05 18:44:36,556 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9534 | Iter Mean Loss 6.3348
2020-11-05 18:44:36,563 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8232 | Iter Mean Loss 6.7069
2020-11-05 18:44:36,571 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2148 | Iter Mean Loss 6.4085
2020-11-05 18:44:36,573 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:44:36,581 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2680 | Iter Mean Loss 7.2680
2020-11-05 18:44:36,589 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7695 | Iter Mean Loss 5.0188
2020-11-05 18:44:36,596 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9377 | Iter Mean Loss 6.3251
2020-11-05 18:44:36,604 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8094 | Iter Mean Loss 6.6961
2020-11-05 18:44:36,613 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2047 | Iter Mean Loss 6.3979
2020-11-05 18:44:36,615 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:44:36,624 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2578 | Iter Mean Loss 7.2578
2020-11-05 18:44:36,633 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7662 | Iter Mean Loss 5.0120
2020-11-05 18:44:36,640 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9220 | Iter Mean Loss 6.3153
2020-11-05 18:44:36,649 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7956 | Iter Mean Loss 6.6854
2020-11-05 18:44:36,657 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1947 | Iter Mean Loss 6.3873
2020-11-05 18:44:36,660 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:44:36,669 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2477 | Iter Mean Loss 7.2477
2020-11-05 18:44:36,678 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7630 | Iter Mean Loss 5.0054
2020-11-05 18:44:36,685 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9063 | Iter Mean Loss 6.3057
2020-11-05 18:44:36,694 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7819 | Iter Mean Loss 6.6747
2020-11-05 18:44:36,702 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1846 | Iter Mean Loss 6.3767
2020-11-05 18:44:36,704 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:44:36,713 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2377 | Iter Mean Loss 7.2377
2020-11-05 18:44:36,721 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7597 | Iter Mean Loss 4.9987
2020-11-05 18:44:36,728 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8907 | Iter Mean Loss 6.2961
2020-11-05 18:44:36,736 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7682 | Iter Mean Loss 6.6641
2020-11-05 18:44:36,743 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1746 | Iter Mean Loss 6.3662
2020-11-05 18:44:36,745 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:44:36,753 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2277 | Iter Mean Loss 7.2277
2020-11-05 18:44:36,760 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7565 | Iter Mean Loss 4.9921
2020-11-05 18:44:36,768 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8752 | Iter Mean Loss 6.2865
2020-11-05 18:44:36,775 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7546 | Iter Mean Loss 6.6535
2020-11-05 18:44:36,782 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 6.3557
2020-11-05 18:44:36,784 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:44:36,792 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2178 | Iter Mean Loss 7.2178
2020-11-05 18:44:36,799 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7533 | Iter Mean Loss 4.9855
2020-11-05 18:44:36,807 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8597 | Iter Mean Loss 6.2769
2020-11-05 18:44:36,814 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7411 | Iter Mean Loss 6.6430
2020-11-05 18:44:36,823 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1547 | Iter Mean Loss 6.3453
2020-11-05 18:44:36,825 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:44:36,833 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2079 | Iter Mean Loss 7.2079
2020-11-05 18:44:36,842 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7501 | Iter Mean Loss 4.9790
2020-11-05 18:44:36,849 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8443 | Iter Mean Loss 6.2674
2020-11-05 18:44:36,858 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7276 | Iter Mean Loss 6.6325
2020-11-05 18:44:36,866 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1448 | Iter Mean Loss 6.3349
2020-11-05 18:44:36,868 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:44:36,878 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1981 | Iter Mean Loss 7.1981
2020-11-05 18:44:36,885 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7468 | Iter Mean Loss 4.9725
2020-11-05 18:44:36,894 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8290 | Iter Mean Loss 6.2580
2020-11-05 18:44:36,901 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7141 | Iter Mean Loss 6.6220
2020-11-05 18:44:36,910 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1349 | Iter Mean Loss 6.3246
2020-11-05 18:44:36,913 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:44:36,920 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1884 | Iter Mean Loss 7.1884
2020-11-05 18:44:36,929 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7436 | Iter Mean Loss 4.9660
2020-11-05 18:44:36,936 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8137 | Iter Mean Loss 6.2486
2020-11-05 18:44:36,943 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7007 | Iter Mean Loss 6.6116
2020-11-05 18:44:36,950 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1250 | Iter Mean Loss 6.3143
2020-11-05 18:44:36,953 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:44:36,960 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1787 | Iter Mean Loss 7.1787
2020-11-05 18:44:36,968 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7404 | Iter Mean Loss 4.9595
2020-11-05 18:44:36,975 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7985 | Iter Mean Loss 6.2392
2020-11-05 18:44:36,983 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6874 | Iter Mean Loss 6.6012
2020-11-05 18:44:36,990 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1152 | Iter Mean Loss 6.3040
2020-11-05 18:44:36,992 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:44:37,000 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1690 | Iter Mean Loss 7.1690
2020-11-05 18:44:37,007 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7372 | Iter Mean Loss 4.9531
2020-11-05 18:44:37,015 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7833 | Iter Mean Loss 6.2299
2020-11-05 18:44:37,023 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6741 | Iter Mean Loss 6.5909
2020-11-05 18:44:37,030 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1054 | Iter Mean Loss 6.2938
2020-11-05 18:44:37,033 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:44:37,041 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1595 | Iter Mean Loss 7.1595
2020-11-05 18:44:37,050 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7340 | Iter Mean Loss 4.9467
2020-11-05 18:44:37,059 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7682 | Iter Mean Loss 6.2206
2020-11-05 18:44:37,068 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6609 | Iter Mean Loss 6.5806
2020-11-05 18:44:37,075 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0956 | Iter Mean Loss 6.2836
2020-11-05 18:44:37,078 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:44:37,087 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1500 | Iter Mean Loss 7.1500
2020-11-05 18:44:37,095 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7308 | Iter Mean Loss 4.9404
2020-11-05 18:44:37,103 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7532 | Iter Mean Loss 6.2113
2020-11-05 18:44:37,112 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6477 | Iter Mean Loss 6.5704
2020-11-05 18:44:37,120 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0858 | Iter Mean Loss 6.2735
2020-11-05 18:44:37,122 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:44:37,131 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1405 | Iter Mean Loss 7.1405
2020-11-05 18:44:37,138 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7276 | Iter Mean Loss 4.9340
2020-11-05 18:44:37,145 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7382 | Iter Mean Loss 6.2021
2020-11-05 18:44:37,153 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6345 | Iter Mean Loss 6.5602
2020-11-05 18:44:37,160 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0761 | Iter Mean Loss 6.2634
2020-11-05 18:44:37,162 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:44:37,170 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1311 | Iter Mean Loss 7.1311
2020-11-05 18:44:37,178 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7244 | Iter Mean Loss 4.9277
2020-11-05 18:44:37,185 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7232 | Iter Mean Loss 6.1929
2020-11-05 18:44:37,192 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6215 | Iter Mean Loss 6.5501
2020-11-05 18:44:37,199 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0664 | Iter Mean Loss 6.2533
2020-11-05 18:44:37,201 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:44:37,209 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1218 | Iter Mean Loss 7.1218
2020-11-05 18:44:37,217 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7212 | Iter Mean Loss 4.9215
2020-11-05 18:44:37,225 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7084 | Iter Mean Loss 6.1838
2020-11-05 18:44:37,233 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6084 | Iter Mean Loss 6.5399
2020-11-05 18:44:37,241 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0567 | Iter Mean Loss 6.2433
2020-11-05 18:44:37,243 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:44:37,252 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1125 | Iter Mean Loss 7.1125
2020-11-05 18:44:37,260 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7180 | Iter Mean Loss 4.9152
2020-11-05 18:44:37,269 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6935 | Iter Mean Loss 6.1747
2020-11-05 18:44:37,277 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5954 | Iter Mean Loss 6.5299
2020-11-05 18:44:37,286 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0470 | Iter Mean Loss 6.2333
2020-11-05 18:44:37,288 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:44:37,296 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1032 | Iter Mean Loss 7.1032
2020-11-05 18:44:37,305 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7148 | Iter Mean Loss 4.9090
2020-11-05 18:44:37,313 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6787 | Iter Mean Loss 6.1656
2020-11-05 18:44:37,323 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5825 | Iter Mean Loss 6.5198
2020-11-05 18:44:37,332 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0374 | Iter Mean Loss 6.2233
2020-11-05 18:44:37,335 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:44:37,344 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0940 | Iter Mean Loss 7.0940
2020-11-05 18:44:37,353 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7116 | Iter Mean Loss 4.9028
2020-11-05 18:44:37,361 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6640 | Iter Mean Loss 6.1566
2020-11-05 18:44:37,371 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5696 | Iter Mean Loss 6.5098
2020-11-05 18:44:37,379 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0278 | Iter Mean Loss 6.2134
2020-11-05 18:44:37,381 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:44:37,391 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0849 | Iter Mean Loss 7.0849
2020-11-05 18:44:37,399 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7084 | Iter Mean Loss 4.8967
2020-11-05 18:44:37,408 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6493 | Iter Mean Loss 6.1476
2020-11-05 18:44:37,415 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5567 | Iter Mean Loss 6.4998
2020-11-05 18:44:37,425 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0182 | Iter Mean Loss 6.2035
2020-11-05 18:44:37,428 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:44:37,439 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0758 | Iter Mean Loss 7.0758
2020-11-05 18:44:37,447 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7053 | Iter Mean Loss 4.8905
2020-11-05 18:44:37,457 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6347 | Iter Mean Loss 6.1386
2020-11-05 18:44:37,465 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5439 | Iter Mean Loss 6.4899
2020-11-05 18:44:37,475 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0086 | Iter Mean Loss 6.1936
2020-11-05 18:44:37,477 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:44:37,488 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0667 | Iter Mean Loss 7.0667
2020-11-05 18:44:37,497 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7021 | Iter Mean Loss 4.8844
2020-11-05 18:44:37,506 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1296
2020-11-05 18:44:37,514 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5311 | Iter Mean Loss 6.4800
2020-11-05 18:44:37,524 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9991 | Iter Mean Loss 6.1838
2020-11-05 18:44:37,526 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:44:37,536 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0577 | Iter Mean Loss 7.0577
2020-11-05 18:44:37,545 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6989 | Iter Mean Loss 4.8783
2020-11-05 18:44:37,554 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6056 | Iter Mean Loss 6.1207
2020-11-05 18:44:37,562 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5184 | Iter Mean Loss 6.4702
2020-11-05 18:44:37,571 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9895 | Iter Mean Loss 6.1740
2020-11-05 18:44:37,574 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:44:37,582 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0488 | Iter Mean Loss 7.0488
2020-11-05 18:44:37,591 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 4.8722
2020-11-05 18:44:37,600 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5911 | Iter Mean Loss 6.1119
2020-11-05 18:44:37,609 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 6.4603
2020-11-05 18:44:37,618 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9800 | Iter Mean Loss 6.1643
2020-11-05 18:44:37,621 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:44:37,630 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0399 | Iter Mean Loss 7.0399
2020-11-05 18:44:37,640 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 4.8662
2020-11-05 18:44:37,647 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 6.1030
2020-11-05 18:44:37,658 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4931 | Iter Mean Loss 6.4505
2020-11-05 18:44:37,671 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9706 | Iter Mean Loss 6.1545
2020-11-05 18:44:37,674 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:44:37,687 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0310 | Iter Mean Loss 7.0310
2020-11-05 18:44:37,695 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 4.8602
2020-11-05 18:44:37,704 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5623 | Iter Mean Loss 6.0942
2020-11-05 18:44:37,712 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4804 | Iter Mean Loss 6.4408
2020-11-05 18:44:37,722 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9611 | Iter Mean Loss 6.1448
2020-11-05 18:44:37,724 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:44:37,733 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0222 | Iter Mean Loss 7.0222
2020-11-05 18:44:37,742 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6861 | Iter Mean Loss 4.8542
2020-11-05 18:44:37,751 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5479 | Iter Mean Loss 6.0854
2020-11-05 18:44:37,760 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4679 | Iter Mean Loss 6.4310
2020-11-05 18:44:37,768 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9517 | Iter Mean Loss 6.1352
2020-11-05 18:44:37,771 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:44:37,780 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 7.0135
2020-11-05 18:44:37,789 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6829 | Iter Mean Loss 4.8482
2020-11-05 18:44:37,796 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5337 | Iter Mean Loss 6.0767
2020-11-05 18:44:37,805 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4553 | Iter Mean Loss 6.4213
2020-11-05 18:44:37,813 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9422 | Iter Mean Loss 6.1255
2020-11-05 18:44:37,816 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:44:37,826 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0047 | Iter Mean Loss 7.0047
2020-11-05 18:44:37,834 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6797 | Iter Mean Loss 4.8422
2020-11-05 18:44:37,843 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5194 | Iter Mean Loss 6.0679
2020-11-05 18:44:37,853 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4428 | Iter Mean Loss 6.4117
2020-11-05 18:44:37,862 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9328 | Iter Mean Loss 6.1159
2020-11-05 18:44:37,864 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:44:37,874 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9961 | Iter Mean Loss 6.9961
2020-11-05 18:44:37,883 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6765 | Iter Mean Loss 4.8363
2020-11-05 18:44:37,893 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5052 | Iter Mean Loss 6.0592
2020-11-05 18:44:37,901 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4304 | Iter Mean Loss 6.4020
2020-11-05 18:44:37,910 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9235 | Iter Mean Loss 6.1063
2020-11-05 18:44:37,913 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:44:37,923 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9874 | Iter Mean Loss 6.9874
2020-11-05 18:44:37,931 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6733 | Iter Mean Loss 4.8304
2020-11-05 18:44:37,940 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4910 | Iter Mean Loss 6.0506
2020-11-05 18:44:37,948 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 6.3924
2020-11-05 18:44:37,957 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9141 | Iter Mean Loss 6.0968
2020-11-05 18:44:37,959 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:44:37,968 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9788 | Iter Mean Loss 6.9788
2020-11-05 18:44:37,977 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6701 | Iter Mean Loss 4.8244
2020-11-05 18:44:37,986 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4769 | Iter Mean Loss 6.0419
2020-11-05 18:44:37,994 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4056 | Iter Mean Loss 6.3828
2020-11-05 18:44:38,003 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9048 | Iter Mean Loss 6.0872
2020-11-05 18:44:38,005 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:44:38,014 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9703 | Iter Mean Loss 6.9703
2020-11-05 18:44:38,023 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6668 | Iter Mean Loss 4.8186
2020-11-05 18:44:38,031 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4628 | Iter Mean Loss 6.0333
2020-11-05 18:44:38,040 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3932 | Iter Mean Loss 6.3733
2020-11-05 18:44:38,049 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8955 | Iter Mean Loss 6.0777
2020-11-05 18:44:38,052 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:44:38,062 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9618 | Iter Mean Loss 6.9618
2020-11-05 18:44:38,071 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6636 | Iter Mean Loss 4.8127
2020-11-05 18:44:38,080 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4488 | Iter Mean Loss 6.0247
2020-11-05 18:44:38,089 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3809 | Iter Mean Loss 6.3638
2020-11-05 18:44:38,097 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8861 | Iter Mean Loss 6.0682
2020-11-05 18:44:38,099 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:44:38,109 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9533 | Iter Mean Loss 6.9533
2020-11-05 18:44:38,117 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6604 | Iter Mean Loss 4.8068
2020-11-05 18:44:38,127 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4348 | Iter Mean Loss 6.0162
2020-11-05 18:44:38,135 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3686 | Iter Mean Loss 6.3543
2020-11-05 18:44:38,145 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8769 | Iter Mean Loss 6.0588
2020-11-05 18:44:38,147 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:44:38,158 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9449 | Iter Mean Loss 6.9449
2020-11-05 18:44:38,166 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6571 | Iter Mean Loss 4.8010
2020-11-05 18:44:38,174 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4209 | Iter Mean Loss 6.0076
2020-11-05 18:44:38,183 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3564 | Iter Mean Loss 6.3448
2020-11-05 18:44:38,191 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8676 | Iter Mean Loss 6.0494
2020-11-05 18:44:38,195 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:44:38,203 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9365 | Iter Mean Loss 6.9365
2020-11-05 18:44:38,213 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6539 | Iter Mean Loss 4.7952
2020-11-05 18:44:38,221 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4069 | Iter Mean Loss 5.9991
2020-11-05 18:44:38,230 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.3354
2020-11-05 18:44:38,238 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 6.0400
2020-11-05 18:44:38,240 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:44:38,250 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9281 | Iter Mean Loss 6.9281
2020-11-05 18:44:38,259 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6507 | Iter Mean Loss 4.7894
2020-11-05 18:44:38,268 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3931 | Iter Mean Loss 5.9906
2020-11-05 18:44:38,277 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3320 | Iter Mean Loss 6.3260
2020-11-05 18:44:38,287 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8491 | Iter Mean Loss 6.0306
2020-11-05 18:44:38,289 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:44:38,299 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9198 | Iter Mean Loss 6.9198
2020-11-05 18:44:38,307 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6474 | Iter Mean Loss 4.7836
2020-11-05 18:44:38,319 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 5.9821
2020-11-05 18:44:38,328 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3198 | Iter Mean Loss 6.3166
2020-11-05 18:44:38,336 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8399 | Iter Mean Loss 6.0212
2020-11-05 18:44:38,339 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:44:38,348 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9115 | Iter Mean Loss 6.9115
2020-11-05 18:44:38,355 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6441 | Iter Mean Loss 4.7778
2020-11-05 18:44:38,363 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3654 | Iter Mean Loss 5.9737
2020-11-05 18:44:38,370 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3077 | Iter Mean Loss 6.3072
2020-11-05 18:44:38,377 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8307 | Iter Mean Loss 6.0119
2020-11-05 18:44:38,379 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:44:38,387 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9033 | Iter Mean Loss 6.9033
2020-11-05 18:44:38,394 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6409 | Iter Mean Loss 4.7721
2020-11-05 18:44:38,401 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3517 | Iter Mean Loss 5.9653
2020-11-05 18:44:38,408 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2956 | Iter Mean Loss 6.2978
2020-11-05 18:44:38,416 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8215 | Iter Mean Loss 6.0026
2020-11-05 18:44:38,418 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:44:38,425 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8951 | Iter Mean Loss 6.8951
2020-11-05 18:44:38,432 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6376 | Iter Mean Loss 4.7663
2020-11-05 18:44:38,440 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3379 | Iter Mean Loss 5.9569
2020-11-05 18:44:38,447 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2835 | Iter Mean Loss 6.2885
2020-11-05 18:44:38,455 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8124 | Iter Mean Loss 5.9933
2020-11-05 18:44:38,457 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:44:38,466 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8869 | Iter Mean Loss 6.8869
2020-11-05 18:44:38,473 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6343 | Iter Mean Loss 4.7606
2020-11-05 18:44:38,481 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3242 | Iter Mean Loss 5.9485
2020-11-05 18:44:38,489 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2715 | Iter Mean Loss 6.2792
2020-11-05 18:44:38,497 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8032 | Iter Mean Loss 5.9840
2020-11-05 18:44:38,499 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:44:38,508 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8788 | Iter Mean Loss 6.8788
2020-11-05 18:44:38,516 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6310 | Iter Mean Loss 4.7549
2020-11-05 18:44:38,525 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3106 | Iter Mean Loss 5.9401
2020-11-05 18:44:38,532 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2594 | Iter Mean Loss 6.2700
2020-11-05 18:44:38,542 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7941 | Iter Mean Loss 5.9748
2020-11-05 18:44:38,544 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:44:38,555 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8707 | Iter Mean Loss 6.8707
2020-11-05 18:44:38,563 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6277 | Iter Mean Loss 4.7492
2020-11-05 18:44:38,570 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9318
2020-11-05 18:44:38,578 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2475 | Iter Mean Loss 6.2607
2020-11-05 18:44:38,586 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7849 | Iter Mean Loss 5.9655
2020-11-05 18:44:38,588 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:44:38,595 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8626 | Iter Mean Loss 6.8626
2020-11-05 18:44:38,603 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6244 | Iter Mean Loss 4.7435
2020-11-05 18:44:38,611 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2834 | Iter Mean Loss 5.9235
2020-11-05 18:44:38,619 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2355 | Iter Mean Loss 6.2515
2020-11-05 18:44:38,626 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7758 | Iter Mean Loss 5.9563
2020-11-05 18:44:38,628 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:44:38,636 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8546 | Iter Mean Loss 6.8546
2020-11-05 18:44:38,643 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6211 | Iter Mean Loss 4.7378
2020-11-05 18:44:38,650 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2698 | Iter Mean Loss 5.9152
2020-11-05 18:44:38,658 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2236 | Iter Mean Loss 6.2423
2020-11-05 18:44:38,665 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7667 | Iter Mean Loss 5.9471
2020-11-05 18:44:38,668 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:44:38,677 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 6.8466
2020-11-05 18:44:38,685 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6177 | Iter Mean Loss 4.7321
2020-11-05 18:44:38,693 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2563 | Iter Mean Loss 5.9069
2020-11-05 18:44:38,701 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2116 | Iter Mean Loss 6.2331
2020-11-05 18:44:38,709 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7576 | Iter Mean Loss 5.9380
2020-11-05 18:44:38,711 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:44:38,720 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8386 | Iter Mean Loss 6.8386
2020-11-05 18:44:38,728 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6144 | Iter Mean Loss 4.7265
2020-11-05 18:44:38,736 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2428 | Iter Mean Loss 5.8986
2020-11-05 18:44:38,744 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1998 | Iter Mean Loss 6.2239
2020-11-05 18:44:38,752 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7486 | Iter Mean Loss 5.9288
2020-11-05 18:44:38,755 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:44:38,763 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8307 | Iter Mean Loss 6.8307
2020-11-05 18:44:38,771 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6110 | Iter Mean Loss 4.7208
2020-11-05 18:44:38,779 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2293 | Iter Mean Loss 5.8903
2020-11-05 18:44:38,786 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1879 | Iter Mean Loss 6.2147
2020-11-05 18:44:38,793 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 5.9197
2020-11-05 18:44:38,795 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:44:38,803 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8228 | Iter Mean Loss 6.8228
2020-11-05 18:44:38,810 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6076 | Iter Mean Loss 4.7152
2020-11-05 18:44:38,818 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2159 | Iter Mean Loss 5.8821
2020-11-05 18:44:38,825 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1761 | Iter Mean Loss 6.2056
2020-11-05 18:44:38,834 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7305 | Iter Mean Loss 5.9106
2020-11-05 18:44:38,836 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:44:38,844 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8149 | Iter Mean Loss 6.8149
2020-11-05 18:44:38,851 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6042 | Iter Mean Loss 4.7096
2020-11-05 18:44:38,859 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2025 | Iter Mean Loss 5.8739
2020-11-05 18:44:38,866 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1642 | Iter Mean Loss 6.1965
2020-11-05 18:44:38,875 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7214 | Iter Mean Loss 5.9015
2020-11-05 18:44:38,877 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:44:38,886 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8070 | Iter Mean Loss 6.8070
2020-11-05 18:44:38,894 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6008 | Iter Mean Loss 4.7039
2020-11-05 18:44:38,902 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1891 | Iter Mean Loss 5.8657
2020-11-05 18:44:38,911 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1524 | Iter Mean Loss 6.1874
2020-11-05 18:44:38,919 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7124 | Iter Mean Loss 5.8924
2020-11-05 18:44:38,923 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:44:38,931 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7992 | Iter Mean Loss 6.7992
2020-11-05 18:44:38,939 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5974 | Iter Mean Loss 4.6983
2020-11-05 18:44:38,947 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1758 | Iter Mean Loss 5.8575
2020-11-05 18:44:38,955 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1407 | Iter Mean Loss 6.1783
2020-11-05 18:44:38,965 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7034 | Iter Mean Loss 5.8833
2020-11-05 18:44:38,967 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:44:38,975 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7914 | Iter Mean Loss 6.7914
2020-11-05 18:44:38,983 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5940 | Iter Mean Loss 4.6927
2020-11-05 18:44:38,991 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1625 | Iter Mean Loss 5.8493
2020-11-05 18:44:39,000 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1289 | Iter Mean Loss 6.1692
2020-11-05 18:44:39,008 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6944 | Iter Mean Loss 5.8742
2020-11-05 18:44:39,010 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:44:39,017 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7837 | Iter Mean Loss 6.7837
2020-11-05 18:44:39,025 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5906 | Iter Mean Loss 4.6871
2020-11-05 18:44:39,032 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1492 | Iter Mean Loss 5.8411
2020-11-05 18:44:39,039 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1172 | Iter Mean Loss 6.1602
2020-11-05 18:44:39,048 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6854 | Iter Mean Loss 5.8652
2020-11-05 18:44:39,050 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:44:39,058 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7759 | Iter Mean Loss 6.7759
2020-11-05 18:44:39,066 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5871 | Iter Mean Loss 4.6815
2020-11-05 18:44:39,075 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1359 | Iter Mean Loss 5.8330
2020-11-05 18:44:39,082 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1054 | Iter Mean Loss 6.1511
2020-11-05 18:44:39,091 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6764 | Iter Mean Loss 5.8562
2020-11-05 18:44:39,093 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:44:39,101 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7682 | Iter Mean Loss 6.7682
2020-11-05 18:44:39,112 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5837 | Iter Mean Loss 4.6759
2020-11-05 18:44:39,119 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1227 | Iter Mean Loss 5.8249
2020-11-05 18:44:39,127 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0937 | Iter Mean Loss 6.1421
2020-11-05 18:44:39,135 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6674 | Iter Mean Loss 5.8472
2020-11-05 18:44:39,138 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:44:39,146 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7605 | Iter Mean Loss 6.7605
2020-11-05 18:44:39,154 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5802 | Iter Mean Loss 4.6704
2020-11-05 18:44:39,164 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 5.8167
2020-11-05 18:44:39,172 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0821 | Iter Mean Loss 6.1331
2020-11-05 18:44:39,180 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6585 | Iter Mean Loss 5.8381
2020-11-05 18:44:39,182 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:44:39,191 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7529 | Iter Mean Loss 6.7529
2020-11-05 18:44:39,199 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5767 | Iter Mean Loss 4.6648
2020-11-05 18:44:39,207 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0963 | Iter Mean Loss 5.8086
2020-11-05 18:44:39,214 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0704 | Iter Mean Loss 6.1241
2020-11-05 18:44:39,221 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6495 | Iter Mean Loss 5.8292
2020-11-05 18:44:39,223 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:44:39,231 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7453 | Iter Mean Loss 6.7453
2020-11-05 18:44:39,239 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 4.6592
2020-11-05 18:44:39,248 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0831 | Iter Mean Loss 5.8005
2020-11-05 18:44:39,255 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0588 | Iter Mean Loss 6.1151
2020-11-05 18:44:39,262 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6406 | Iter Mean Loss 5.8202
2020-11-05 18:44:39,264 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:44:39,273 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7377 | Iter Mean Loss 6.7377
2020-11-05 18:44:39,282 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5696 | Iter Mean Loss 4.6536
2020-11-05 18:44:39,289 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0700 | Iter Mean Loss 5.7924
2020-11-05 18:44:39,297 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0471 | Iter Mean Loss 6.1061
2020-11-05 18:44:39,305 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6316 | Iter Mean Loss 5.8112
2020-11-05 18:44:39,307 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:44:39,317 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7301 | Iter Mean Loss 6.7301
2020-11-05 18:44:39,326 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5661 | Iter Mean Loss 4.6481
2020-11-05 18:44:39,335 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0569 | Iter Mean Loss 5.7843
2020-11-05 18:44:39,343 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0355 | Iter Mean Loss 6.0971
2020-11-05 18:44:39,352 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6227 | Iter Mean Loss 5.8022
2020-11-05 18:44:39,354 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:44:39,364 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7225 | Iter Mean Loss 6.7225
2020-11-05 18:44:39,373 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5625 | Iter Mean Loss 4.6425
2020-11-05 18:44:39,381 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0438 | Iter Mean Loss 5.7763
2020-11-05 18:44:39,390 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0239 | Iter Mean Loss 6.0882
2020-11-05 18:44:39,398 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6137 | Iter Mean Loss 5.7933
2020-11-05 18:44:39,400 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:44:39,409 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7150 | Iter Mean Loss 6.7150
2020-11-05 18:44:39,419 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5589 | Iter Mean Loss 4.6370
2020-11-05 18:44:39,427 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0307 | Iter Mean Loss 5.7682
2020-11-05 18:44:39,435 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0123 | Iter Mean Loss 6.0792
2020-11-05 18:44:39,443 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6048 | Iter Mean Loss 5.7844
2020-11-05 18:44:39,447 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:44:39,456 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7075 | Iter Mean Loss 6.7075
2020-11-05 18:44:39,465 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5553 | Iter Mean Loss 4.6314
2020-11-05 18:44:39,473 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0176 | Iter Mean Loss 5.7601
2020-11-05 18:44:39,482 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0008 | Iter Mean Loss 6.0703
2020-11-05 18:44:39,491 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5959 | Iter Mean Loss 5.7754
2020-11-05 18:44:39,493 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:44:39,504 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7000 | Iter Mean Loss 6.7000
2020-11-05 18:44:39,512 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5517 | Iter Mean Loss 4.6258
2020-11-05 18:44:39,523 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0046 | Iter Mean Loss 5.7521
2020-11-05 18:44:39,532 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9892 | Iter Mean Loss 6.0614
2020-11-05 18:44:39,541 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5870 | Iter Mean Loss 5.7665
2020-11-05 18:44:39,543 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:44:39,553 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6925 | Iter Mean Loss 6.6925
2020-11-05 18:44:39,562 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5480 | Iter Mean Loss 4.6203
2020-11-05 18:44:39,572 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9916 | Iter Mean Loss 5.7441
2020-11-05 18:44:39,582 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9776 | Iter Mean Loss 6.0525
2020-11-05 18:44:39,591 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5781 | Iter Mean Loss 5.7576
2020-11-05 18:44:39,593 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:44:39,604 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6851 | Iter Mean Loss 6.6851
2020-11-05 18:44:39,613 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5444 | Iter Mean Loss 4.6147
2020-11-05 18:44:39,622 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9786 | Iter Mean Loss 5.7360
2020-11-05 18:44:39,630 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9661 | Iter Mean Loss 6.0435
2020-11-05 18:44:39,639 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5692 | Iter Mean Loss 5.7487
2020-11-05 18:44:39,641 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:44:39,650 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6777 | Iter Mean Loss 6.6777
2020-11-05 18:44:39,659 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5407 | Iter Mean Loss 4.6092
2020-11-05 18:44:39,667 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9656 | Iter Mean Loss 5.7280
2020-11-05 18:44:39,675 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9546 | Iter Mean Loss 6.0346
2020-11-05 18:44:39,684 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5603 | Iter Mean Loss 5.7398
2020-11-05 18:44:39,687 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:44:39,695 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6703 | Iter Mean Loss 6.6703
2020-11-05 18:44:39,705 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5370 | Iter Mean Loss 4.6036
2020-11-05 18:44:39,713 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9526 | Iter Mean Loss 5.7200
2020-11-05 18:44:39,722 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9431 | Iter Mean Loss 6.0257
2020-11-05 18:44:39,730 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5514 | Iter Mean Loss 5.7309
2020-11-05 18:44:39,734 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:44:39,743 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6629 | Iter Mean Loss 6.6629
2020-11-05 18:44:39,752 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5333 | Iter Mean Loss 4.5981
2020-11-05 18:44:39,761 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9397 | Iter Mean Loss 5.7119
2020-11-05 18:44:39,770 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9316 | Iter Mean Loss 6.0169
2020-11-05 18:44:39,778 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5425 | Iter Mean Loss 5.7220
2020-11-05 18:44:39,781 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:44:39,791 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6556 | Iter Mean Loss 6.6556
2020-11-05 18:44:39,799 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5295 | Iter Mean Loss 4.5925
2020-11-05 18:44:39,807 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9267 | Iter Mean Loss 5.7039
2020-11-05 18:44:39,816 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9201 | Iter Mean Loss 6.0080
2020-11-05 18:44:39,824 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5336 | Iter Mean Loss 5.7131
2020-11-05 18:44:39,826 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:44:39,836 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6482 | Iter Mean Loss 6.6482
2020-11-05 18:44:39,844 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5257 | Iter Mean Loss 4.5870
2020-11-05 18:44:39,853 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9138 | Iter Mean Loss 5.6959
2020-11-05 18:44:39,861 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 5.9991
2020-11-05 18:44:39,870 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5247 | Iter Mean Loss 5.7042
2020-11-05 18:44:39,872 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:44:39,881 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6409 | Iter Mean Loss 6.6409
2020-11-05 18:44:39,891 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5219 | Iter Mean Loss 4.5814
2020-11-05 18:44:39,899 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 5.6879
2020-11-05 18:44:39,907 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8971 | Iter Mean Loss 5.9902
2020-11-05 18:44:39,916 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5158 | Iter Mean Loss 5.6953
2020-11-05 18:44:39,919 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:44:39,928 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6336 | Iter Mean Loss 6.6336
2020-11-05 18:44:39,938 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5181 | Iter Mean Loss 4.5759
2020-11-05 18:44:39,946 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8880 | Iter Mean Loss 5.6799
2020-11-05 18:44:39,955 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8856 | Iter Mean Loss 5.9813
2020-11-05 18:44:39,963 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 5.6865
2020-11-05 18:44:39,967 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:44:39,976 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6263 | Iter Mean Loss 6.6263
2020-11-05 18:44:39,986 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5143 | Iter Mean Loss 4.5703
2020-11-05 18:44:39,994 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8751 | Iter Mean Loss 5.6719
2020-11-05 18:44:40,003 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8742 | Iter Mean Loss 5.9725
2020-11-05 18:44:40,011 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4980 | Iter Mean Loss 5.6776
2020-11-05 18:44:40,013 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:44:40,023 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6191 | Iter Mean Loss 6.6191
2020-11-05 18:44:40,031 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5104 | Iter Mean Loss 4.5647
2020-11-05 18:44:40,040 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8623 | Iter Mean Loss 5.6639
2020-11-05 18:44:40,048 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8627 | Iter Mean Loss 5.9636
2020-11-05 18:44:40,058 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4891 | Iter Mean Loss 5.6687
2020-11-05 18:44:40,060 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:44:40,070 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6118 | Iter Mean Loss 6.6118
2020-11-05 18:44:40,078 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5065 | Iter Mean Loss 4.5592
2020-11-05 18:44:40,087 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 5.6559
2020-11-05 18:44:40,096 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8513 | Iter Mean Loss 5.9547
2020-11-05 18:44:40,106 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4802 | Iter Mean Loss 5.6598
2020-11-05 18:44:40,108 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:44:40,119 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.6046
2020-11-05 18:44:40,128 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5026 | Iter Mean Loss 4.5536
2020-11-05 18:44:40,137 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8365 | Iter Mean Loss 5.6479
2020-11-05 18:44:40,146 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8398 | Iter Mean Loss 5.9459
2020-11-05 18:44:40,157 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4713 | Iter Mean Loss 5.6510
2020-11-05 18:44:40,159 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:40,169 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5974 | Iter Mean Loss 6.5974
2020-11-05 18:44:40,179 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4986 | Iter Mean Loss 4.5480
2020-11-05 18:44:40,188 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8237 | Iter Mean Loss 5.6399
2020-11-05 18:44:40,196 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8284 | Iter Mean Loss 5.9370
2020-11-05 18:44:40,206 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4624 | Iter Mean Loss 5.6421
2020-11-05 18:44:40,209 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:40,218 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5902 | Iter Mean Loss 6.5902
2020-11-05 18:44:40,228 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4947 | Iter Mean Loss 4.5424
2020-11-05 18:44:40,239 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8109 | Iter Mean Loss 5.6319
2020-11-05 18:44:40,247 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8169 | Iter Mean Loss 5.9282
2020-11-05 18:44:40,257 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 5.6332
2020-11-05 18:44:40,260 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:40,269 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5830 | Iter Mean Loss 6.5830
2020-11-05 18:44:40,278 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4907 | Iter Mean Loss 4.5368
2020-11-05 18:44:40,286 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7981 | Iter Mean Loss 5.6239
2020-11-05 18:44:40,295 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8055 | Iter Mean Loss 5.9193
2020-11-05 18:44:40,305 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4446 | Iter Mean Loss 5.6244
2020-11-05 18:44:40,308 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:40,317 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5758 | Iter Mean Loss 6.5758
2020-11-05 18:44:40,328 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4866 | Iter Mean Loss 4.5312
2020-11-05 18:44:40,336 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7852 | Iter Mean Loss 5.6159
2020-11-05 18:44:40,346 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7941 | Iter Mean Loss 5.9104
2020-11-05 18:44:40,355 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4357 | Iter Mean Loss 5.6155
2020-11-05 18:44:40,358 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:40,367 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5687 | Iter Mean Loss 6.5687
2020-11-05 18:44:40,377 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4826 | Iter Mean Loss 4.5256
2020-11-05 18:44:40,385 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7724 | Iter Mean Loss 5.6079
2020-11-05 18:44:40,395 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7826 | Iter Mean Loss 5.9016
2020-11-05 18:44:40,405 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4268 | Iter Mean Loss 5.6066
2020-11-05 18:44:40,408 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:44:40,417 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5615 | Iter Mean Loss 6.5615
2020-11-05 18:44:40,426 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4785 | Iter Mean Loss 4.5200
2020-11-05 18:44:40,434 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7596 | Iter Mean Loss 5.5999
2020-11-05 18:44:40,444 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7712 | Iter Mean Loss 5.8927
2020-11-05 18:44:40,452 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 5.5978
2020-11-05 18:44:40,456 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:44:40,465 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5544 | Iter Mean Loss 6.5544
2020-11-05 18:44:40,475 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4744 | Iter Mean Loss 4.5144
2020-11-05 18:44:40,483 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7468 | Iter Mean Loss 5.5919
2020-11-05 18:44:40,493 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 5.8839
2020-11-05 18:44:40,501 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4090 | Iter Mean Loss 5.5889
2020-11-05 18:44:40,506 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:40,516 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5473 | Iter Mean Loss 6.5473
2020-11-05 18:44:40,524 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4703 | Iter Mean Loss 4.5088
2020-11-05 18:44:40,532 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7340 | Iter Mean Loss 5.5839
2020-11-05 18:44:40,541 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7484 | Iter Mean Loss 5.8750
2020-11-05 18:44:40,549 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 5.5800
2020-11-05 18:44:40,551 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:40,561 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5402 | Iter Mean Loss 6.5402
2020-11-05 18:44:40,569 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4661 | Iter Mean Loss 4.5031
2020-11-05 18:44:40,577 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7212 | Iter Mean Loss 5.5758
2020-11-05 18:44:40,585 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7369 | Iter Mean Loss 5.8661
2020-11-05 18:44:40,593 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3911 | Iter Mean Loss 5.5711
2020-11-05 18:44:40,595 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:40,604 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5331 | Iter Mean Loss 6.5331
2020-11-05 18:44:40,613 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4619 | Iter Mean Loss 4.4975
2020-11-05 18:44:40,620 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7085 | Iter Mean Loss 5.5678
2020-11-05 18:44:40,628 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7255 | Iter Mean Loss 5.8572
2020-11-05 18:44:40,636 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3822 | Iter Mean Loss 5.5622
2020-11-05 18:44:40,638 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:40,646 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5260 | Iter Mean Loss 6.5260
2020-11-05 18:44:40,653 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4576 | Iter Mean Loss 4.4918
2020-11-05 18:44:40,661 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6957 | Iter Mean Loss 5.5598
2020-11-05 18:44:40,668 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7141 | Iter Mean Loss 5.8484
2020-11-05 18:44:40,675 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3733 | Iter Mean Loss 5.5533
2020-11-05 18:44:40,677 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:40,685 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5190 | Iter Mean Loss 6.5190
2020-11-05 18:44:40,692 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 4.4862
2020-11-05 18:44:40,699 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6829 | Iter Mean Loss 5.5518
2020-11-05 18:44:40,706 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7026 | Iter Mean Loss 5.8395
2020-11-05 18:44:40,715 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3643 | Iter Mean Loss 5.5444
2020-11-05 18:44:40,717 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:44:40,726 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5119 | Iter Mean Loss 6.5119
2020-11-05 18:44:40,734 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4491 | Iter Mean Loss 4.4805
2020-11-05 18:44:40,742 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6701 | Iter Mean Loss 5.5437
2020-11-05 18:44:40,749 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6912 | Iter Mean Loss 5.8306
2020-11-05 18:44:40,758 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3553 | Iter Mean Loss 5.5355
2020-11-05 18:44:40,761 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:44:40,769 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5049 | Iter Mean Loss 6.5049
2020-11-05 18:44:40,778 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4447 | Iter Mean Loss 4.4748
2020-11-05 18:44:40,786 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6573 | Iter Mean Loss 5.5357
2020-11-05 18:44:40,794 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6798 | Iter Mean Loss 5.8217
2020-11-05 18:44:40,802 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3464 | Iter Mean Loss 5.5266
2020-11-05 18:44:40,804 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:40,813 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4979 | Iter Mean Loss 6.4979
2020-11-05 18:44:40,820 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4404 | Iter Mean Loss 4.4691
2020-11-05 18:44:40,828 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6445 | Iter Mean Loss 5.5276
2020-11-05 18:44:40,836 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6683 | Iter Mean Loss 5.8128
2020-11-05 18:44:40,843 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3374 | Iter Mean Loss 5.5177
2020-11-05 18:44:40,845 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:40,853 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4909 | Iter Mean Loss 6.4909
2020-11-05 18:44:40,861 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4360 | Iter Mean Loss 4.4634
2020-11-05 18:44:40,868 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5195
2020-11-05 18:44:40,875 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6569 | Iter Mean Loss 5.8039
2020-11-05 18:44:40,882 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3284 | Iter Mean Loss 5.5088
2020-11-05 18:44:40,884 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:40,892 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4839 | Iter Mean Loss 6.4839
2020-11-05 18:44:40,899 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4315 | Iter Mean Loss 4.4577
2020-11-05 18:44:40,907 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6190 | Iter Mean Loss 5.5115
2020-11-05 18:44:40,915 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6454 | Iter Mean Loss 5.7949
2020-11-05 18:44:40,923 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3194 | Iter Mean Loss 5.4998
2020-11-05 18:44:40,925 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:40,934 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4769 | Iter Mean Loss 6.4769
2020-11-05 18:44:40,942 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4271 | Iter Mean Loss 4.4520
2020-11-05 18:44:40,950 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6062 | Iter Mean Loss 5.5034
2020-11-05 18:44:40,959 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6339 | Iter Mean Loss 5.7860
2020-11-05 18:44:40,967 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3104 | Iter Mean Loss 5.4909
2020-11-05 18:44:40,970 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:40,979 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4699 | Iter Mean Loss 6.4699
2020-11-05 18:44:40,987 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4226 | Iter Mean Loss 4.4462
2020-11-05 18:44:40,995 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5934 | Iter Mean Loss 5.4953
2020-11-05 18:44:41,002 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6225 | Iter Mean Loss 5.7771
2020-11-05 18:44:41,011 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3014 | Iter Mean Loss 5.4819
2020-11-05 18:44:41,013 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:41,021 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4629 | Iter Mean Loss 6.4629
2020-11-05 18:44:41,029 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4180 | Iter Mean Loss 4.4405
2020-11-05 18:44:41,037 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5806 | Iter Mean Loss 5.4872
2020-11-05 18:44:41,044 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6110 | Iter Mean Loss 5.7681
2020-11-05 18:44:41,051 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2924 | Iter Mean Loss 5.4730
2020-11-05 18:44:41,053 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:41,061 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4560 | Iter Mean Loss 6.4560
2020-11-05 18:44:41,069 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4134 | Iter Mean Loss 4.4347
2020-11-05 18:44:41,077 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5678 | Iter Mean Loss 5.4791
2020-11-05 18:44:41,084 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5995 | Iter Mean Loss 5.7592
2020-11-05 18:44:41,092 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2833 | Iter Mean Loss 5.4640
2020-11-05 18:44:41,094 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:41,101 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4490 | Iter Mean Loss 6.4490
2020-11-05 18:44:41,109 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4088 | Iter Mean Loss 4.4289
2020-11-05 18:44:41,117 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5550 | Iter Mean Loss 5.4709
2020-11-05 18:44:41,125 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5880 | Iter Mean Loss 5.7502
2020-11-05 18:44:41,133 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2743 | Iter Mean Loss 5.4550
2020-11-05 18:44:41,135 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:41,144 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4421 | Iter Mean Loss 6.4421
2020-11-05 18:44:41,152 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4042 | Iter Mean Loss 4.4231
2020-11-05 18:44:41,161 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5422 | Iter Mean Loss 5.4628
2020-11-05 18:44:41,169 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5765 | Iter Mean Loss 5.7412
2020-11-05 18:44:41,177 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2652 | Iter Mean Loss 5.4460
2020-11-05 18:44:41,180 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:41,188 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4351 | Iter Mean Loss 6.4351
2020-11-05 18:44:41,197 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3995 | Iter Mean Loss 4.4173
2020-11-05 18:44:41,205 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5294 | Iter Mean Loss 5.4547
2020-11-05 18:44:41,213 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5650 | Iter Mean Loss 5.7323
2020-11-05 18:44:41,221 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2561 | Iter Mean Loss 5.4370
2020-11-05 18:44:41,224 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:41,232 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4282 | Iter Mean Loss 6.4282
2020-11-05 18:44:41,239 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3948 | Iter Mean Loss 4.4115
2020-11-05 18:44:41,246 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5166 | Iter Mean Loss 5.4465
2020-11-05 18:44:41,256 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5535 | Iter Mean Loss 5.7233
2020-11-05 18:44:41,266 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2470 | Iter Mean Loss 5.4280
2020-11-05 18:44:41,268 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:41,278 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4213 | Iter Mean Loss 6.4213
2020-11-05 18:44:41,287 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3900 | Iter Mean Loss 4.4056
2020-11-05 18:44:41,295 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5037 | Iter Mean Loss 5.4383
2020-11-05 18:44:41,304 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5419 | Iter Mean Loss 5.7142
2020-11-05 18:44:41,314 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2379 | Iter Mean Loss 5.4190
2020-11-05 18:44:41,317 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:41,332 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4144 | Iter Mean Loss 6.4144
2020-11-05 18:44:41,344 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3852 | Iter Mean Loss 4.3998
2020-11-05 18:44:41,353 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4909 | Iter Mean Loss 5.4302
2020-11-05 18:44:41,366 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5304 | Iter Mean Loss 5.7052
2020-11-05 18:44:41,378 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2288 | Iter Mean Loss 5.4099
2020-11-05 18:44:41,381 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:41,395 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4075 | Iter Mean Loss 6.4075
2020-11-05 18:44:41,407 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3803 | Iter Mean Loss 4.3939
2020-11-05 18:44:41,416 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4781 | Iter Mean Loss 5.4220
2020-11-05 18:44:41,423 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5188 | Iter Mean Loss 5.6962
2020-11-05 18:44:41,431 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2197 | Iter Mean Loss 5.4009
2020-11-05 18:44:41,433 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:41,446 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4006 | Iter Mean Loss 6.4006
2020-11-05 18:44:41,459 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3755 | Iter Mean Loss 4.3880
2020-11-05 18:44:41,468 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4652 | Iter Mean Loss 5.4137
2020-11-05 18:44:41,477 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5073 | Iter Mean Loss 5.6871
2020-11-05 18:44:41,486 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2105 | Iter Mean Loss 5.3918
2020-11-05 18:44:41,488 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:41,497 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3937 | Iter Mean Loss 6.3937
2020-11-05 18:44:41,506 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3705 | Iter Mean Loss 4.3821
2020-11-05 18:44:41,514 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4524 | Iter Mean Loss 5.4055
2020-11-05 18:44:41,523 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4957 | Iter Mean Loss 5.6781
2020-11-05 18:44:41,531 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2013 | Iter Mean Loss 5.3827
2020-11-05 18:44:41,534 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:41,544 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3868 | Iter Mean Loss 6.3868
2020-11-05 18:44:41,554 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3656 | Iter Mean Loss 4.3762
2020-11-05 18:44:41,563 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4395 | Iter Mean Loss 5.3973
2020-11-05 18:44:41,572 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4841 | Iter Mean Loss 5.6690
2020-11-05 18:44:41,581 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1922 | Iter Mean Loss 5.3736
2020-11-05 18:44:41,583 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:41,593 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3799 | Iter Mean Loss 6.3799
2020-11-05 18:44:41,602 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3606 | Iter Mean Loss 4.3702
2020-11-05 18:44:41,612 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4266 | Iter Mean Loss 5.3890
2020-11-05 18:44:41,622 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4725 | Iter Mean Loss 5.6599
2020-11-05 18:44:41,630 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1830 | Iter Mean Loss 5.3645
2020-11-05 18:44:41,632 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:41,642 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3730 | Iter Mean Loss 6.3730
2020-11-05 18:44:41,651 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3555 | Iter Mean Loss 4.3643
2020-11-05 18:44:41,661 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4137 | Iter Mean Loss 5.3807
2020-11-05 18:44:41,669 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4609 | Iter Mean Loss 5.6508
2020-11-05 18:44:41,678 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1737 | Iter Mean Loss 5.3554
2020-11-05 18:44:41,680 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:41,690 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 6.3662
2020-11-05 18:44:41,698 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3504 | Iter Mean Loss 4.3583
2020-11-05 18:44:41,707 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4008 | Iter Mean Loss 5.3725
2020-11-05 18:44:41,715 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4493 | Iter Mean Loss 5.6417
2020-11-05 18:44:41,724 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1645 | Iter Mean Loss 5.3462
2020-11-05 18:44:41,727 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:41,738 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3593 | Iter Mean Loss 6.3593
2020-11-05 18:44:41,746 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3453 | Iter Mean Loss 4.3523
2020-11-05 18:44:41,756 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3879 | Iter Mean Loss 5.3642
2020-11-05 18:44:41,764 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4376 | Iter Mean Loss 5.6325
2020-11-05 18:44:41,774 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1552 | Iter Mean Loss 5.3371
2020-11-05 18:44:41,778 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:41,789 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3524 | Iter Mean Loss 6.3524
2020-11-05 18:44:41,797 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3401 | Iter Mean Loss 4.3463
2020-11-05 18:44:41,807 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3750 | Iter Mean Loss 5.3558
2020-11-05 18:44:41,816 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4259 | Iter Mean Loss 5.6234
2020-11-05 18:44:41,824 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1460 | Iter Mean Loss 5.3279
2020-11-05 18:44:41,827 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:41,836 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3456 | Iter Mean Loss 6.3456
2020-11-05 18:44:41,845 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3349 | Iter Mean Loss 4.3403
2020-11-05 18:44:41,854 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3620 | Iter Mean Loss 5.3475
2020-11-05 18:44:41,862 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4143 | Iter Mean Loss 5.6142
2020-11-05 18:44:41,870 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1367 | Iter Mean Loss 5.3187
2020-11-05 18:44:41,874 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:41,883 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3388 | Iter Mean Loss 6.3388
2020-11-05 18:44:41,891 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3297 | Iter Mean Loss 4.3342
2020-11-05 18:44:41,899 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3491 | Iter Mean Loss 5.3392
2020-11-05 18:44:41,909 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4026 | Iter Mean Loss 5.6050
2020-11-05 18:44:41,917 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1274 | Iter Mean Loss 5.3095
2020-11-05 18:44:41,920 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:41,929 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3319 | Iter Mean Loss 6.3319
2020-11-05 18:44:41,937 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3244 | Iter Mean Loss 4.3281
2020-11-05 18:44:41,947 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3361 | Iter Mean Loss 5.3308
2020-11-05 18:44:41,956 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3909 | Iter Mean Loss 5.5958
2020-11-05 18:44:41,964 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1180 | Iter Mean Loss 5.3002
2020-11-05 18:44:41,967 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:41,977 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3251 | Iter Mean Loss 6.3251
2020-11-05 18:44:41,985 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3190 | Iter Mean Loss 4.3220
2020-11-05 18:44:41,995 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3231 | Iter Mean Loss 5.3224
2020-11-05 18:44:42,004 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3791 | Iter Mean Loss 5.5866
2020-11-05 18:44:42,012 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1087 | Iter Mean Loss 5.2910
2020-11-05 18:44:42,014 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:42,024 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3183 | Iter Mean Loss 6.3183
2020-11-05 18:44:42,033 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3136 | Iter Mean Loss 4.3159
2020-11-05 18:44:42,043 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3101 | Iter Mean Loss 5.3140
2020-11-05 18:44:42,051 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3674 | Iter Mean Loss 5.5773
2020-11-05 18:44:42,061 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0993 | Iter Mean Loss 5.2817
2020-11-05 18:44:42,063 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:42,072 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3114 | Iter Mean Loss 6.3114
2020-11-05 18:44:42,080 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3082 | Iter Mean Loss 4.3098
2020-11-05 18:44:42,089 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2971 | Iter Mean Loss 5.3056
2020-11-05 18:44:42,097 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3556 | Iter Mean Loss 5.5681
2020-11-05 18:44:42,106 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 5.2725
2020-11-05 18:44:42,108 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:42,117 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3046 | Iter Mean Loss 6.3046
2020-11-05 18:44:42,126 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3027 | Iter Mean Loss 4.3037
2020-11-05 18:44:42,135 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2841 | Iter Mean Loss 5.2971
2020-11-05 18:44:42,144 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3438 | Iter Mean Loss 5.5588
2020-11-05 18:44:42,152 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0805 | Iter Mean Loss 5.2632
2020-11-05 18:44:42,156 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:42,164 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2978 | Iter Mean Loss 6.2978
2020-11-05 18:44:42,174 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2972 | Iter Mean Loss 4.2975
2020-11-05 18:44:42,182 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2710 | Iter Mean Loss 5.2887
2020-11-05 18:44:42,191 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3320 | Iter Mean Loss 5.5495
2020-11-05 18:44:42,199 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 5.2538
2020-11-05 18:44:42,203 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:42,212 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2910 | Iter Mean Loss 6.2910
2020-11-05 18:44:42,222 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 4.2913
2020-11-05 18:44:42,230 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2580 | Iter Mean Loss 5.2802
2020-11-05 18:44:42,239 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3202 | Iter Mean Loss 5.5402
2020-11-05 18:44:42,247 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0616 | Iter Mean Loss 5.2445
2020-11-05 18:44:42,250 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:42,260 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2842 | Iter Mean Loss 6.2842
2020-11-05 18:44:42,268 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2860 | Iter Mean Loss 4.2851
2020-11-05 18:44:42,277 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2449 | Iter Mean Loss 5.2717
2020-11-05 18:44:42,285 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3084 | Iter Mean Loss 5.5309
2020-11-05 18:44:42,294 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0522 | Iter Mean Loss 5.2351
2020-11-05 18:44:42,296 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:42,306 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2774 | Iter Mean Loss 6.2774
2020-11-05 18:44:42,317 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2804 | Iter Mean Loss 4.2789
2020-11-05 18:44:42,329 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2318 | Iter Mean Loss 5.2632
2020-11-05 18:44:42,338 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2966 | Iter Mean Loss 5.5215
2020-11-05 18:44:42,345 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0427 | Iter Mean Loss 5.2258
2020-11-05 18:44:42,347 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:42,357 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 6.2706
2020-11-05 18:44:42,365 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2747 | Iter Mean Loss 4.2727
2020-11-05 18:44:42,374 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2187 | Iter Mean Loss 5.2547
2020-11-05 18:44:42,381 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2847 | Iter Mean Loss 5.5122
2020-11-05 18:44:42,389 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0332 | Iter Mean Loss 5.2164
2020-11-05 18:44:42,391 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:42,399 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2639 | Iter Mean Loss 6.2639
2020-11-05 18:44:42,409 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2690 | Iter Mean Loss 4.2664
2020-11-05 18:44:42,417 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2056 | Iter Mean Loss 5.2461
2020-11-05 18:44:42,425 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2728 | Iter Mean Loss 5.5028
2020-11-05 18:44:42,433 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0236 | Iter Mean Loss 5.2070
2020-11-05 18:44:42,435 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:42,446 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2571 | Iter Mean Loss 6.2571
2020-11-05 18:44:42,455 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2632 | Iter Mean Loss 4.2601
2020-11-05 18:44:42,465 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1925 | Iter Mean Loss 5.2376
2020-11-05 18:44:42,478 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2609 | Iter Mean Loss 5.4934
2020-11-05 18:44:42,488 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 5.1975
2020-11-05 18:44:42,492 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:42,502 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2503 | Iter Mean Loss 6.2503
2020-11-05 18:44:42,511 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2574 | Iter Mean Loss 4.2538
2020-11-05 18:44:42,521 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1793 | Iter Mean Loss 5.2290
2020-11-05 18:44:42,533 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2490 | Iter Mean Loss 5.4840
2020-11-05 18:44:42,542 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0045 | Iter Mean Loss 5.1881
2020-11-05 18:44:42,546 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:42,557 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2436 | Iter Mean Loss 6.2436
2020-11-05 18:44:42,567 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2515 | Iter Mean Loss 4.2475
2020-11-05 18:44:42,575 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1661 | Iter Mean Loss 5.2204
2020-11-05 18:44:42,586 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2370 | Iter Mean Loss 5.4746
2020-11-05 18:44:42,594 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9949 | Iter Mean Loss 5.1786
2020-11-05 18:44:42,597 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:42,606 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2368 | Iter Mean Loss 6.2368
2020-11-05 18:44:42,616 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2456 | Iter Mean Loss 4.2412
2020-11-05 18:44:42,625 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1530 | Iter Mean Loss 5.2118
2020-11-05 18:44:42,635 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2251 | Iter Mean Loss 5.4651
2020-11-05 18:44:42,644 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9853 | Iter Mean Loss 5.1691
2020-11-05 18:44:42,647 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:42,656 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2300 | Iter Mean Loss 6.2300
2020-11-05 18:44:42,663 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2397 | Iter Mean Loss 4.2349
2020-11-05 18:44:42,670 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1398 | Iter Mean Loss 5.2032
2020-11-05 18:44:42,677 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.4556
2020-11-05 18:44:42,685 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9757 | Iter Mean Loss 5.1596
2020-11-05 18:44:42,687 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:42,695 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2233 | Iter Mean Loss 6.2233
2020-11-05 18:44:42,702 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2337 | Iter Mean Loss 4.2285
2020-11-05 18:44:42,709 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1266 | Iter Mean Loss 5.1945
2020-11-05 18:44:42,717 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2011 | Iter Mean Loss 5.4462
2020-11-05 18:44:42,724 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9660 | Iter Mean Loss 5.1501
2020-11-05 18:44:42,726 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:42,733 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2166 | Iter Mean Loss 6.2166
2020-11-05 18:44:42,741 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2276 | Iter Mean Loss 4.2221
2020-11-05 18:44:42,748 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1133 | Iter Mean Loss 5.1859
2020-11-05 18:44:42,757 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1891 | Iter Mean Loss 5.4367
2020-11-05 18:44:42,764 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9563 | Iter Mean Loss 5.1406
2020-11-05 18:44:42,766 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:42,775 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2098 | Iter Mean Loss 6.2098
2020-11-05 18:44:42,783 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2216 | Iter Mean Loss 4.2157
2020-11-05 18:44:42,791 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1001 | Iter Mean Loss 5.1772
2020-11-05 18:44:42,798 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1771 | Iter Mean Loss 5.4271
2020-11-05 18:44:42,807 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9466 | Iter Mean Loss 5.1310
2020-11-05 18:44:42,809 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:42,817 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2031 | Iter Mean Loss 6.2031
2020-11-05 18:44:42,825 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2155 | Iter Mean Loss 4.2093
2020-11-05 18:44:42,832 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0869 | Iter Mean Loss 5.1685
2020-11-05 18:44:42,841 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1650 | Iter Mean Loss 5.4176
2020-11-05 18:44:42,848 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9369 | Iter Mean Loss 5.1215
2020-11-05 18:44:42,850 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:42,859 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1964 | Iter Mean Loss 6.1964
2020-11-05 18:44:42,867 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2093 | Iter Mean Loss 4.2029
2020-11-05 18:44:42,874 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0736 | Iter Mean Loss 5.1598
2020-11-05 18:44:42,881 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1530 | Iter Mean Loss 5.4081
2020-11-05 18:44:42,889 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9272 | Iter Mean Loss 5.1119
2020-11-05 18:44:42,891 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:42,898 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1897 | Iter Mean Loss 6.1897
2020-11-05 18:44:42,906 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2031 | Iter Mean Loss 4.1964
2020-11-05 18:44:42,913 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0603 | Iter Mean Loss 5.1510
2020-11-05 18:44:42,920 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1409 | Iter Mean Loss 5.3985
2020-11-05 18:44:42,927 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9175 | Iter Mean Loss 5.1023
2020-11-05 18:44:42,929 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:42,937 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 6.1830
2020-11-05 18:44:42,944 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1969 | Iter Mean Loss 4.1899
2020-11-05 18:44:42,952 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0470 | Iter Mean Loss 5.1423
2020-11-05 18:44:42,960 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1288 | Iter Mean Loss 5.3889
2020-11-05 18:44:42,968 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9077 | Iter Mean Loss 5.0927
2020-11-05 18:44:42,970 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:42,978 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1763 | Iter Mean Loss 6.1763
2020-11-05 18:44:42,986 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 4.1835
2020-11-05 18:44:42,993 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0337 | Iter Mean Loss 5.1336
2020-11-05 18:44:43,002 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1167 | Iter Mean Loss 5.3793
2020-11-05 18:44:43,009 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8979 | Iter Mean Loss 5.0830
2020-11-05 18:44:43,011 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:43,020 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1696 | Iter Mean Loss 6.1696
2020-11-05 18:44:43,028 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1843 | Iter Mean Loss 4.1770
2020-11-05 18:44:43,036 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0204 | Iter Mean Loss 5.1248
2020-11-05 18:44:43,044 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1045 | Iter Mean Loss 5.3697
2020-11-05 18:44:43,052 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8881 | Iter Mean Loss 5.0734
2020-11-05 18:44:43,055 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:43,063 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1630 | Iter Mean Loss 6.1630
2020-11-05 18:44:43,072 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1780 | Iter Mean Loss 4.1705
2020-11-05 18:44:43,079 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0071 | Iter Mean Loss 5.1160
2020-11-05 18:44:43,087 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0924 | Iter Mean Loss 5.3601
2020-11-05 18:44:43,094 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8783 | Iter Mean Loss 5.0637
2020-11-05 18:44:43,096 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:43,104 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1563 | Iter Mean Loss 6.1563
2020-11-05 18:44:43,111 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1716 | Iter Mean Loss 4.1640
2020-11-05 18:44:43,119 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9937 | Iter Mean Loss 5.1072
2020-11-05 18:44:43,126 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0803 | Iter Mean Loss 5.3505
2020-11-05 18:44:43,133 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8685 | Iter Mean Loss 5.0541
2020-11-05 18:44:43,135 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:43,143 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 6.1497
2020-11-05 18:44:43,150 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1652 | Iter Mean Loss 4.1574
2020-11-05 18:44:43,158 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9804 | Iter Mean Loss 5.0984
2020-11-05 18:44:43,165 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0681 | Iter Mean Loss 5.3408
2020-11-05 18:44:43,173 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8586 | Iter Mean Loss 5.0444
2020-11-05 18:44:43,175 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:43,184 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1430 | Iter Mean Loss 6.1430
2020-11-05 18:44:43,192 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1588 | Iter Mean Loss 4.1509
2020-11-05 18:44:43,200 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9670 | Iter Mean Loss 5.0896
2020-11-05 18:44:43,207 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0559 | Iter Mean Loss 5.3312
2020-11-05 18:44:43,215 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8488 | Iter Mean Loss 5.0347
2020-11-05 18:44:43,218 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:43,226 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1364 | Iter Mean Loss 6.1364
2020-11-05 18:44:43,235 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1523 | Iter Mean Loss 4.1443
2020-11-05 18:44:43,242 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9537 | Iter Mean Loss 5.0808
2020-11-05 18:44:43,250 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0437 | Iter Mean Loss 5.3215
2020-11-05 18:44:43,258 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8389 | Iter Mean Loss 5.0250
2020-11-05 18:44:43,260 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:43,268 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1298 | Iter Mean Loss 6.1298
2020-11-05 18:44:43,276 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1458 | Iter Mean Loss 4.1378
2020-11-05 18:44:43,284 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9403 | Iter Mean Loss 5.0719
2020-11-05 18:44:43,291 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0315 | Iter Mean Loss 5.3118
2020-11-05 18:44:43,298 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8290 | Iter Mean Loss 5.0153
2020-11-05 18:44:43,300 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:43,308 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1232 | Iter Mean Loss 6.1232
2020-11-05 18:44:43,316 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1392 | Iter Mean Loss 4.1312
2020-11-05 18:44:43,327 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9269 | Iter Mean Loss 5.0631
2020-11-05 18:44:43,335 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0193 | Iter Mean Loss 5.3022
2020-11-05 18:44:43,346 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8191 | Iter Mean Loss 5.0055
2020-11-05 18:44:43,349 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:43,361 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1166 | Iter Mean Loss 6.1166
2020-11-05 18:44:43,371 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1327 | Iter Mean Loss 4.1246
2020-11-05 18:44:43,380 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9135 | Iter Mean Loss 5.0543
2020-11-05 18:44:43,392 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0071 | Iter Mean Loss 5.2925
2020-11-05 18:44:43,400 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8092 | Iter Mean Loss 4.9958
2020-11-05 18:44:43,405 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:43,415 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1100 | Iter Mean Loss 6.1100
2020-11-05 18:44:43,427 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1261 | Iter Mean Loss 4.1180
2020-11-05 18:44:43,436 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9002 | Iter Mean Loss 5.0454
2020-11-05 18:44:43,447 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9949 | Iter Mean Loss 5.2828
2020-11-05 18:44:43,456 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7993 | Iter Mean Loss 4.9861
2020-11-05 18:44:43,458 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:43,469 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1034 | Iter Mean Loss 6.1034
2020-11-05 18:44:43,478 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1195 | Iter Mean Loss 4.1114
2020-11-05 18:44:43,488 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 5.0366
2020-11-05 18:44:43,496 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9827 | Iter Mean Loss 5.2731
2020-11-05 18:44:43,506 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7893 | Iter Mean Loss 4.9763
2020-11-05 18:44:43,508 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:43,517 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0969 | Iter Mean Loss 6.0969
2020-11-05 18:44:43,526 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1128 | Iter Mean Loss 4.1048
2020-11-05 18:44:43,536 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8734 | Iter Mean Loss 5.0277
2020-11-05 18:44:43,544 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9704 | Iter Mean Loss 5.2634
2020-11-05 18:44:43,553 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7794 | Iter Mean Loss 4.9666
2020-11-05 18:44:43,555 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:43,565 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0903 | Iter Mean Loss 6.0903
2020-11-05 18:44:43,575 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1062 | Iter Mean Loss 4.0982
2020-11-05 18:44:43,586 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8600 | Iter Mean Loss 5.0188
2020-11-05 18:44:43,594 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9582 | Iter Mean Loss 5.2537
2020-11-05 18:44:43,604 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7695 | Iter Mean Loss 4.9568
2020-11-05 18:44:43,607 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:43,616 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0838 | Iter Mean Loss 6.0838
2020-11-05 18:44:43,626 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0995 | Iter Mean Loss 4.0916
2020-11-05 18:44:43,635 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 5.0100
2020-11-05 18:44:43,644 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9459 | Iter Mean Loss 5.2440
2020-11-05 18:44:43,654 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7595 | Iter Mean Loss 4.9471
2020-11-05 18:44:43,657 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:43,667 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0773 | Iter Mean Loss 6.0773
2020-11-05 18:44:43,677 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0928 | Iter Mean Loss 4.0850
2020-11-05 18:44:43,687 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8332 | Iter Mean Loss 5.0011
2020-11-05 18:44:43,695 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9337 | Iter Mean Loss 5.2342
2020-11-05 18:44:43,704 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7495 | Iter Mean Loss 4.9373
2020-11-05 18:44:43,707 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:43,716 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0708 | Iter Mean Loss 6.0708
2020-11-05 18:44:43,726 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0860 | Iter Mean Loss 4.0784
2020-11-05 18:44:43,735 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8198 | Iter Mean Loss 4.9922
2020-11-05 18:44:43,744 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9215 | Iter Mean Loss 5.2245
2020-11-05 18:44:43,753 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7396 | Iter Mean Loss 4.9275
2020-11-05 18:44:43,756 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:43,764 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0643 | Iter Mean Loss 6.0643
2020-11-05 18:44:43,775 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0793 | Iter Mean Loss 4.0718
2020-11-05 18:44:43,784 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8064 | Iter Mean Loss 4.9834
2020-11-05 18:44:43,793 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9092 | Iter Mean Loss 5.2148
2020-11-05 18:44:43,803 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7296 | Iter Mean Loss 4.9178
2020-11-05 18:44:43,806 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:43,815 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0579 | Iter Mean Loss 6.0579
2020-11-05 18:44:43,825 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0725 | Iter Mean Loss 4.0652
2020-11-05 18:44:43,835 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7931 | Iter Mean Loss 4.9745
2020-11-05 18:44:43,844 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8970 | Iter Mean Loss 5.2051
2020-11-05 18:44:43,854 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7197 | Iter Mean Loss 4.9080
2020-11-05 18:44:43,857 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:43,866 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0514 | Iter Mean Loss 6.0514
2020-11-05 18:44:43,876 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0657 | Iter Mean Loss 4.0586
2020-11-05 18:44:43,885 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7797 | Iter Mean Loss 4.9656
2020-11-05 18:44:43,894 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8847 | Iter Mean Loss 5.1954
2020-11-05 18:44:43,904 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7097 | Iter Mean Loss 4.8983
2020-11-05 18:44:43,906 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:43,915 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0450 | Iter Mean Loss 6.0450
2020-11-05 18:44:43,925 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0589 | Iter Mean Loss 4.0520
2020-11-05 18:44:43,933 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7664 | Iter Mean Loss 4.9568
2020-11-05 18:44:43,942 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8725 | Iter Mean Loss 5.1857
2020-11-05 18:44:43,950 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6998 | Iter Mean Loss 4.8885
2020-11-05 18:44:43,954 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:43,964 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0386 | Iter Mean Loss 6.0386
2020-11-05 18:44:43,973 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0521 | Iter Mean Loss 4.0454
2020-11-05 18:44:43,982 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7530 | Iter Mean Loss 4.9479
2020-11-05 18:44:43,992 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8603 | Iter Mean Loss 5.1760
2020-11-05 18:44:44,000 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6898 | Iter Mean Loss 4.8788
2020-11-05 18:44:44,004 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:44,014 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0322 | Iter Mean Loss 6.0322
2020-11-05 18:44:44,025 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0453 | Iter Mean Loss 4.0388
2020-11-05 18:44:44,033 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7397 | Iter Mean Loss 4.9391
2020-11-05 18:44:44,043 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8481 | Iter Mean Loss 5.1663
2020-11-05 18:44:44,051 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6799 | Iter Mean Loss 4.8690
2020-11-05 18:44:44,055 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:44,064 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0259 | Iter Mean Loss 6.0259
2020-11-05 18:44:44,074 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0385 | Iter Mean Loss 4.0322
2020-11-05 18:44:44,082 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7264 | Iter Mean Loss 4.9303
2020-11-05 18:44:44,092 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.1567
2020-11-05 18:44:44,100 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6699 | Iter Mean Loss 4.8593
2020-11-05 18:44:44,104 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:44,113 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0195 | Iter Mean Loss 6.0195
2020-11-05 18:44:44,122 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0317 | Iter Mean Loss 4.0256
2020-11-05 18:44:44,131 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7131 | Iter Mean Loss 4.9214
2020-11-05 18:44:44,140 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8237 | Iter Mean Loss 5.1470
2020-11-05 18:44:44,149 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6600 | Iter Mean Loss 4.8496
2020-11-05 18:44:44,151 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,161 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0132 | Iter Mean Loss 6.0132
2020-11-05 18:44:44,170 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0249 | Iter Mean Loss 4.0191
2020-11-05 18:44:44,179 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6998 | Iter Mean Loss 4.9126
2020-11-05 18:44:44,188 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8115 | Iter Mean Loss 5.1373
2020-11-05 18:44:44,196 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6501 | Iter Mean Loss 4.8399
2020-11-05 18:44:44,198 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,209 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0069 | Iter Mean Loss 6.0069
2020-11-05 18:44:44,217 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0181 | Iter Mean Loss 4.0125
2020-11-05 18:44:44,227 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6865 | Iter Mean Loss 4.9038
2020-11-05 18:44:44,235 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7993 | Iter Mean Loss 5.1277
2020-11-05 18:44:44,244 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6401 | Iter Mean Loss 4.8302
2020-11-05 18:44:44,247 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,257 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0007 | Iter Mean Loss 6.0007
2020-11-05 18:44:44,265 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0112 | Iter Mean Loss 4.0059
2020-11-05 18:44:44,275 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6733 | Iter Mean Loss 4.8950
2020-11-05 18:44:44,283 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7872 | Iter Mean Loss 5.1181
2020-11-05 18:44:44,293 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6302 | Iter Mean Loss 4.8205
2020-11-05 18:44:44,295 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,305 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9944 | Iter Mean Loss 5.9944
2020-11-05 18:44:44,314 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0044 | Iter Mean Loss 3.9994
2020-11-05 18:44:44,324 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 4.8863
2020-11-05 18:44:44,332 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7751 | Iter Mean Loss 5.1085
2020-11-05 18:44:44,341 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6204 | Iter Mean Loss 4.8109
2020-11-05 18:44:44,343 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,351 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9882 | Iter Mean Loss 5.9882
2020-11-05 18:44:44,358 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9976 | Iter Mean Loss 3.9929
2020-11-05 18:44:44,366 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6468 | Iter Mean Loss 4.8775
2020-11-05 18:44:44,373 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7629 | Iter Mean Loss 5.0989
2020-11-05 18:44:44,380 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6105 | Iter Mean Loss 4.8012
2020-11-05 18:44:44,382 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,390 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9820 | Iter Mean Loss 5.9820
2020-11-05 18:44:44,399 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9908 | Iter Mean Loss 3.9864
2020-11-05 18:44:44,407 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6337 | Iter Mean Loss 4.8688
2020-11-05 18:44:44,415 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7509 | Iter Mean Loss 5.0893
2020-11-05 18:44:44,423 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6006 | Iter Mean Loss 4.7916
2020-11-05 18:44:44,426 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,434 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9758 | Iter Mean Loss 5.9758
2020-11-05 18:44:44,443 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9840 | Iter Mean Loss 3.9799
2020-11-05 18:44:44,451 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6205 | Iter Mean Loss 4.8601
2020-11-05 18:44:44,459 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7388 | Iter Mean Loss 5.0798
2020-11-05 18:44:44,467 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5908 | Iter Mean Loss 4.7820
2020-11-05 18:44:44,469 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:44,478 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9696 | Iter Mean Loss 5.9696
2020-11-05 18:44:44,486 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9772 | Iter Mean Loss 3.9734
2020-11-05 18:44:44,495 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6074 | Iter Mean Loss 4.8514
2020-11-05 18:44:44,503 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7268 | Iter Mean Loss 5.0702
2020-11-05 18:44:44,511 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5810 | Iter Mean Loss 4.7724
2020-11-05 18:44:44,513 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,521 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9635 | Iter Mean Loss 5.9635
2020-11-05 18:44:44,530 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9704 | Iter Mean Loss 3.9670
2020-11-05 18:44:44,542 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5943 | Iter Mean Loss 4.8427
2020-11-05 18:44:44,554 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7148 | Iter Mean Loss 5.0607
2020-11-05 18:44:44,563 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5712 | Iter Mean Loss 4.7628
2020-11-05 18:44:44,565 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,573 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9574 | Iter Mean Loss 5.9574
2020-11-05 18:44:44,583 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9637 | Iter Mean Loss 3.9605
2020-11-05 18:44:44,592 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5813 | Iter Mean Loss 4.8341
2020-11-05 18:44:44,602 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7028 | Iter Mean Loss 5.0513
2020-11-05 18:44:44,612 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5615 | Iter Mean Loss 4.7533
2020-11-05 18:44:44,614 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,628 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9513 | Iter Mean Loss 5.9513
2020-11-05 18:44:44,640 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9569 | Iter Mean Loss 3.9541
2020-11-05 18:44:44,650 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5683 | Iter Mean Loss 4.8255
2020-11-05 18:44:44,660 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6908 | Iter Mean Loss 5.0418
2020-11-05 18:44:44,669 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5517 | Iter Mean Loss 4.7438
2020-11-05 18:44:44,673 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,681 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9453 | Iter Mean Loss 5.9453
2020-11-05 18:44:44,689 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9502 | Iter Mean Loss 3.9477
2020-11-05 18:44:44,699 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5553 | Iter Mean Loss 4.8169
2020-11-05 18:44:44,707 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6789 | Iter Mean Loss 5.0324
2020-11-05 18:44:44,716 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5420 | Iter Mean Loss 4.7343
2020-11-05 18:44:44,719 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,728 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9393 | Iter Mean Loss 5.9393
2020-11-05 18:44:44,738 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9435 | Iter Mean Loss 3.9414
2020-11-05 18:44:44,745 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5423 | Iter Mean Loss 4.8084
2020-11-05 18:44:44,752 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6670 | Iter Mean Loss 5.0230
2020-11-05 18:44:44,759 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5323 | Iter Mean Loss 4.7249
2020-11-05 18:44:44,761 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,769 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9333 | Iter Mean Loss 5.9333
2020-11-05 18:44:44,778 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9368 | Iter Mean Loss 3.9350
2020-11-05 18:44:44,787 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5294 | Iter Mean Loss 4.7998
2020-11-05 18:44:44,794 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6552 | Iter Mean Loss 5.0137
2020-11-05 18:44:44,802 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5227 | Iter Mean Loss 4.7155
2020-11-05 18:44:44,805 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,813 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9273 | Iter Mean Loss 5.9273
2020-11-05 18:44:44,821 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9301 | Iter Mean Loss 3.9287
2020-11-05 18:44:44,829 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5166 | Iter Mean Loss 4.7913
2020-11-05 18:44:44,837 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6434 | Iter Mean Loss 5.0043
2020-11-05 18:44:44,845 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5131 | Iter Mean Loss 4.7061
2020-11-05 18:44:44,847 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,855 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9214 | Iter Mean Loss 5.9214
2020-11-05 18:44:44,864 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9235 | Iter Mean Loss 3.9224
2020-11-05 18:44:44,872 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5038 | Iter Mean Loss 4.7829
2020-11-05 18:44:44,881 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6316 | Iter Mean Loss 4.9951
2020-11-05 18:44:44,888 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 4.6967
2020-11-05 18:44:44,891 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,900 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9154 | Iter Mean Loss 5.9154
2020-11-05 18:44:44,908 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9169 | Iter Mean Loss 3.9162
2020-11-05 18:44:44,917 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4910 | Iter Mean Loss 4.7745
2020-11-05 18:44:44,924 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6199 | Iter Mean Loss 4.9858
2020-11-05 18:44:44,931 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4939 | Iter Mean Loss 4.6874
2020-11-05 18:44:44,933 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,941 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9096 | Iter Mean Loss 5.9096
2020-11-05 18:44:44,949 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9103 | Iter Mean Loss 3.9100
2020-11-05 18:44:44,956 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4783 | Iter Mean Loss 4.7661
2020-11-05 18:44:44,963 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 4.9766
2020-11-05 18:44:44,970 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4844 | Iter Mean Loss 4.6782
2020-11-05 18:44:44,972 - root - INFO - Evaluate: Epoch 0647 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:44,980 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9037 | Iter Mean Loss 5.9037
2020-11-05 18:44:44,987 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9038 | Iter Mean Loss 3.9038
2020-11-05 18:44:44,995 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4656 | Iter Mean Loss 4.7577
2020-11-05 18:44:45,002 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5966 | Iter Mean Loss 4.9674
2020-11-05 18:44:45,011 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4749 | Iter Mean Loss 4.6689
2020-11-05 18:44:45,013 - root - INFO - Evaluate: Epoch 0648 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,021 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8979 | Iter Mean Loss 5.8979
2020-11-05 18:44:45,029 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8973 | Iter Mean Loss 3.8976
2020-11-05 18:44:45,037 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4530 | Iter Mean Loss 4.7494
2020-11-05 18:44:45,045 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5850 | Iter Mean Loss 4.9583
2020-11-05 18:44:45,054 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4655 | Iter Mean Loss 4.6597
2020-11-05 18:44:45,056 - root - INFO - Evaluate: Epoch 0649 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,066 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8921 | Iter Mean Loss 5.8921
2020-11-05 18:44:45,073 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8908 | Iter Mean Loss 3.8915
2020-11-05 18:44:45,082 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4404 | Iter Mean Loss 4.7411
2020-11-05 18:44:45,090 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5734 | Iter Mean Loss 4.9492
2020-11-05 18:44:45,099 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4561 | Iter Mean Loss 4.6506
2020-11-05 18:44:45,102 - root - INFO - Evaluate: Epoch 0650 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,110 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8864 | Iter Mean Loss 5.8864
2020-11-05 18:44:45,118 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8844 | Iter Mean Loss 3.8854
2020-11-05 18:44:45,126 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4279 | Iter Mean Loss 4.7329
2020-11-05 18:44:45,133 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5619 | Iter Mean Loss 4.9402
2020-11-05 18:44:45,140 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4468 | Iter Mean Loss 4.6415
2020-11-05 18:44:45,142 - root - INFO - Evaluate: Epoch 0651 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,150 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8806 | Iter Mean Loss 5.8806
2020-11-05 18:44:45,158 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8780 | Iter Mean Loss 3.8793
2020-11-05 18:44:45,167 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4154 | Iter Mean Loss 4.7247
2020-11-05 18:44:45,175 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5505 | Iter Mean Loss 4.9311
2020-11-05 18:44:45,183 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4375 | Iter Mean Loss 4.6324
2020-11-05 18:44:45,186 - root - INFO - Evaluate: Epoch 0652 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,193 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8749 | Iter Mean Loss 5.8749
2020-11-05 18:44:45,201 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8717 | Iter Mean Loss 3.8733
2020-11-05 18:44:45,209 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4030 | Iter Mean Loss 4.7165
2020-11-05 18:44:45,217 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5391 | Iter Mean Loss 4.9222
2020-11-05 18:44:45,227 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4282 | Iter Mean Loss 4.6234
2020-11-05 18:44:45,229 - root - INFO - Evaluate: Epoch 0653 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,237 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8693 | Iter Mean Loss 5.8693
2020-11-05 18:44:45,246 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8654 | Iter Mean Loss 3.8673
2020-11-05 18:44:45,254 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3907 | Iter Mean Loss 4.7084
2020-11-05 18:44:45,263 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5278 | Iter Mean Loss 4.9133
2020-11-05 18:44:45,271 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4190 | Iter Mean Loss 4.6144
2020-11-05 18:44:45,274 - root - INFO - Evaluate: Epoch 0654 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,282 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8636 | Iter Mean Loss 5.8636
2020-11-05 18:44:45,290 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8591 | Iter Mean Loss 3.8614
2020-11-05 18:44:45,298 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3784 | Iter Mean Loss 4.7004
2020-11-05 18:44:45,307 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5165 | Iter Mean Loss 4.9044
2020-11-05 18:44:45,317 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4099 | Iter Mean Loss 4.6055
2020-11-05 18:44:45,320 - root - INFO - Evaluate: Epoch 0655 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,329 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 5.8580
2020-11-05 18:44:45,339 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 3.8555
2020-11-05 18:44:45,347 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 4.6924
2020-11-05 18:44:45,356 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5053 | Iter Mean Loss 4.8956
2020-11-05 18:44:45,364 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4008 | Iter Mean Loss 4.5966
2020-11-05 18:44:45,366 - root - INFO - Evaluate: Epoch 0656 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,375 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8525 | Iter Mean Loss 5.8525
2020-11-05 18:44:45,384 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8467 | Iter Mean Loss 3.8496
2020-11-05 18:44:45,392 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3540 | Iter Mean Loss 4.6844
2020-11-05 18:44:45,401 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4941 | Iter Mean Loss 4.8868
2020-11-05 18:44:45,409 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 4.5878
2020-11-05 18:44:45,411 - root - INFO - Evaluate: Epoch 0657 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,421 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 5.8469
2020-11-05 18:44:45,430 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8406 | Iter Mean Loss 3.8438
2020-11-05 18:44:45,439 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3419 | Iter Mean Loss 4.6765
2020-11-05 18:44:45,447 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4830 | Iter Mean Loss 4.8781
2020-11-05 18:44:45,456 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3827 | Iter Mean Loss 4.5790
2020-11-05 18:44:45,458 - root - INFO - Evaluate: Epoch 0658 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,468 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8414 | Iter Mean Loss 5.8414
2020-11-05 18:44:45,477 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8346 | Iter Mean Loss 3.8380
2020-11-05 18:44:45,486 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3298 | Iter Mean Loss 4.6686
2020-11-05 18:44:45,494 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4719 | Iter Mean Loss 4.8694
2020-11-05 18:44:45,504 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3737 | Iter Mean Loss 4.5703
2020-11-05 18:44:45,507 - root - INFO - Evaluate: Epoch 0659 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,517 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.8359
2020-11-05 18:44:45,526 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8285 | Iter Mean Loss 3.8322
2020-11-05 18:44:45,535 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3179 | Iter Mean Loss 4.6608
2020-11-05 18:44:45,544 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4610 | Iter Mean Loss 4.8608
2020-11-05 18:44:45,553 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 4.5616
2020-11-05 18:44:45,556 - root - INFO - Evaluate: Epoch 0660 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,566 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8305 | Iter Mean Loss 5.8305
2020-11-05 18:44:45,575 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8226 | Iter Mean Loss 3.8265
2020-11-05 18:44:45,584 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3060 | Iter Mean Loss 4.6530
2020-11-05 18:44:45,592 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4500 | Iter Mean Loss 4.8523
2020-11-05 18:44:45,601 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3560 | Iter Mean Loss 4.5530
2020-11-05 18:44:45,604 - root - INFO - Evaluate: Epoch 0661 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,616 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8251 | Iter Mean Loss 5.8251
2020-11-05 18:44:45,625 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8167 | Iter Mean Loss 3.8209
2020-11-05 18:44:45,634 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 4.6453
2020-11-05 18:44:45,643 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4392 | Iter Mean Loss 4.8438
2020-11-05 18:44:45,653 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3472 | Iter Mean Loss 4.5444
2020-11-05 18:44:45,655 - root - INFO - Evaluate: Epoch 0662 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,665 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8197 | Iter Mean Loss 5.8197
2020-11-05 18:44:45,676 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8108 | Iter Mean Loss 3.8153
2020-11-05 18:44:45,686 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2823 | Iter Mean Loss 4.6376
2020-11-05 18:44:45,694 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4284 | Iter Mean Loss 4.8353
2020-11-05 18:44:45,704 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3385 | Iter Mean Loss 4.5359
2020-11-05 18:44:45,706 - root - INFO - Evaluate: Epoch 0663 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,717 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8144 | Iter Mean Loss 5.8144
2020-11-05 18:44:45,725 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8050 | Iter Mean Loss 3.8097
2020-11-05 18:44:45,734 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 4.6300
2020-11-05 18:44:45,742 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4176 | Iter Mean Loss 4.8269
2020-11-05 18:44:45,751 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 4.5275
2020-11-05 18:44:45,753 - root - INFO - Evaluate: Epoch 0664 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,762 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8090 | Iter Mean Loss 5.8090
2020-11-05 18:44:45,771 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7993 | Iter Mean Loss 3.8042
2020-11-05 18:44:45,779 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2590 | Iter Mean Loss 4.6224
2020-11-05 18:44:45,788 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4070 | Iter Mean Loss 4.8186
2020-11-05 18:44:45,796 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3212 | Iter Mean Loss 4.5191
2020-11-05 18:44:45,800 - root - INFO - Evaluate: Epoch 0665 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,809 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8038 | Iter Mean Loss 5.8038
2020-11-05 18:44:45,819 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7936 | Iter Mean Loss 3.7987
2020-11-05 18:44:45,827 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2474 | Iter Mean Loss 4.6149
2020-11-05 18:44:45,837 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3964 | Iter Mean Loss 4.8103
2020-11-05 18:44:45,845 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3126 | Iter Mean Loss 4.5107
2020-11-05 18:44:45,848 - root - INFO - Evaluate: Epoch 0666 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,859 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7985 | Iter Mean Loss 5.7985
2020-11-05 18:44:45,869 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7880 | Iter Mean Loss 3.7932
2020-11-05 18:44:45,878 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2359 | Iter Mean Loss 4.6074
2020-11-05 18:44:45,888 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3858 | Iter Mean Loss 4.8020
2020-11-05 18:44:45,897 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3041 | Iter Mean Loss 4.5025
2020-11-05 18:44:45,901 - root - INFO - Evaluate: Epoch 0667 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,911 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7933 | Iter Mean Loss 5.7933
2020-11-05 18:44:45,921 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7824 | Iter Mean Loss 3.7878
2020-11-05 18:44:45,930 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2244 | Iter Mean Loss 4.6000
2020-11-05 18:44:45,939 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 4.7939
2020-11-05 18:44:45,947 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2957 | Iter Mean Loss 4.4942
2020-11-05 18:44:45,950 - root - INFO - Evaluate: Epoch 0668 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:45,959 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7881 | Iter Mean Loss 5.7881
2020-11-05 18:44:45,968 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7769 | Iter Mean Loss 3.7825
2020-11-05 18:44:45,976 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 4.5927
2020-11-05 18:44:45,984 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3649 | Iter Mean Loss 4.7857
2020-11-05 18:44:45,992 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2873 | Iter Mean Loss 4.4861
2020-11-05 18:44:45,994 - root - INFO - Evaluate: Epoch 0669 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:46,003 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7829 | Iter Mean Loss 5.7829
2020-11-05 18:44:46,011 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7714 | Iter Mean Loss 3.7772
2020-11-05 18:44:46,020 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2018 | Iter Mean Loss 4.5854
2020-11-05 18:44:46,028 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3546 | Iter Mean Loss 4.7777
2020-11-05 18:44:46,037 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2790 | Iter Mean Loss 4.4779
2020-11-05 18:44:46,040 - root - INFO - Evaluate: Epoch 0670 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:46,049 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7778 | Iter Mean Loss 5.7778
2020-11-05 18:44:46,058 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7660 | Iter Mean Loss 3.7719
2020-11-05 18:44:46,067 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1905 | Iter Mean Loss 4.5781
2020-11-05 18:44:46,076 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3443 | Iter Mean Loss 4.7697
2020-11-05 18:44:46,084 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2708 | Iter Mean Loss 4.4699
2020-11-05 18:44:46,087 - root - INFO - Evaluate: Epoch 0671 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:46,096 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7727 | Iter Mean Loss 5.7727
2020-11-05 18:44:46,105 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7607 | Iter Mean Loss 3.7667
2020-11-05 18:44:46,113 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1794 | Iter Mean Loss 4.5709
2020-11-05 18:44:46,123 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3341 | Iter Mean Loss 4.7617
2020-11-05 18:44:46,131 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2626 | Iter Mean Loss 4.4619
2020-11-05 18:44:46,135 - root - INFO - Evaluate: Epoch 0672 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:44:46,143 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7677 | Iter Mean Loss 5.7677
2020-11-05 18:44:46,152 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7554 | Iter Mean Loss 3.7615
2020-11-05 18:44:46,160 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1683 | Iter Mean Loss 4.5638
2020-11-05 18:44:46,168 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3240 | Iter Mean Loss 4.7538
2020-11-05 18:44:46,177 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2544 | Iter Mean Loss 4.4540
2020-11-05 18:44:46,179 - root - INFO - Evaluate: Epoch 0673 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,189 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7626 | Iter Mean Loss 5.7626
2020-11-05 18:44:46,196 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7502 | Iter Mean Loss 3.7564
2020-11-05 18:44:46,205 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1573 | Iter Mean Loss 4.5567
2020-11-05 18:44:46,213 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3139 | Iter Mean Loss 4.7460
2020-11-05 18:44:46,222 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2464 | Iter Mean Loss 4.4461
2020-11-05 18:44:46,225 - root - INFO - Evaluate: Epoch 0674 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,234 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7576 | Iter Mean Loss 5.7576
2020-11-05 18:44:46,243 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7450 | Iter Mean Loss 3.7513
2020-11-05 18:44:46,252 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1463 | Iter Mean Loss 4.5497
2020-11-05 18:44:46,261 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3039 | Iter Mean Loss 4.7382
2020-11-05 18:44:46,270 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2384 | Iter Mean Loss 4.4382
2020-11-05 18:44:46,273 - root - INFO - Evaluate: Epoch 0675 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,282 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7527 | Iter Mean Loss 5.7527
2020-11-05 18:44:46,291 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7399 | Iter Mean Loss 3.7463
2020-11-05 18:44:46,301 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1354 | Iter Mean Loss 4.5427
2020-11-05 18:44:46,309 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2940 | Iter Mean Loss 4.7305
2020-11-05 18:44:46,319 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2304 | Iter Mean Loss 4.4305
2020-11-05 18:44:46,322 - root - INFO - Evaluate: Epoch 0676 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,331 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7477 | Iter Mean Loss 5.7477
2020-11-05 18:44:46,340 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7349 | Iter Mean Loss 3.7413
2020-11-05 18:44:46,348 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1246 | Iter Mean Loss 4.5358
2020-11-05 18:44:46,355 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2841 | Iter Mean Loss 4.7228
2020-11-05 18:44:46,362 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 4.4228
2020-11-05 18:44:46,364 - root - INFO - Evaluate: Epoch 0677 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,372 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7428 | Iter Mean Loss 5.7428
2020-11-05 18:44:46,379 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7299 | Iter Mean Loss 3.7364
2020-11-05 18:44:46,387 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1139 | Iter Mean Loss 4.5289
2020-11-05 18:44:46,394 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2743 | Iter Mean Loss 4.7152
2020-11-05 18:44:46,401 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2147 | Iter Mean Loss 4.4151
2020-11-05 18:44:46,403 - root - INFO - Evaluate: Epoch 0678 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,411 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7379 | Iter Mean Loss 5.7379
2020-11-05 18:44:46,418 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7250 | Iter Mean Loss 3.7315
2020-11-05 18:44:46,425 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1032 | Iter Mean Loss 4.5221
2020-11-05 18:44:46,433 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2646 | Iter Mean Loss 4.7077
2020-11-05 18:44:46,441 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 4.4075
2020-11-05 18:44:46,443 - root - INFO - Evaluate: Epoch 0679 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,452 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7331 | Iter Mean Loss 5.7331
2020-11-05 18:44:46,460 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7201 | Iter Mean Loss 3.7266
2020-11-05 18:44:46,468 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0926 | Iter Mean Loss 4.5153
2020-11-05 18:44:46,476 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2549 | Iter Mean Loss 4.7002
2020-11-05 18:44:46,484 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1992 | Iter Mean Loss 4.4000
2020-11-05 18:44:46,487 - root - INFO - Evaluate: Epoch 0680 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,495 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7283 | Iter Mean Loss 5.7283
2020-11-05 18:44:46,504 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7153 | Iter Mean Loss 3.7218
2020-11-05 18:44:46,511 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0821 | Iter Mean Loss 4.5086
2020-11-05 18:44:46,519 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.6928
2020-11-05 18:44:46,528 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1916 | Iter Mean Loss 4.3925
2020-11-05 18:44:46,530 - root - INFO - Evaluate: Epoch 0681 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:44:46,538 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7235 | Iter Mean Loss 5.7235
2020-11-05 18:44:46,546 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7106 | Iter Mean Loss 3.7170
2020-11-05 18:44:46,553 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0717 | Iter Mean Loss 4.5019
2020-11-05 18:44:46,560 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2358 | Iter Mean Loss 4.6854
2020-11-05 18:44:46,568 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1840 | Iter Mean Loss 4.3851
2020-11-05 18:44:46,570 - root - INFO - Evaluate: Epoch 0682 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,578 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7187 | Iter Mean Loss 5.7187
2020-11-05 18:44:46,586 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7059 | Iter Mean Loss 3.7123
2020-11-05 18:44:46,593 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0613 | Iter Mean Loss 4.4953
2020-11-05 18:44:46,601 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2263 | Iter Mean Loss 4.6781
2020-11-05 18:44:46,608 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1765 | Iter Mean Loss 4.3778
2020-11-05 18:44:46,610 - root - INFO - Evaluate: Epoch 0683 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,619 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7140 | Iter Mean Loss 5.7140
2020-11-05 18:44:46,627 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7013 | Iter Mean Loss 3.7077
2020-11-05 18:44:46,635 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0510 | Iter Mean Loss 4.4888
2020-11-05 18:44:46,643 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2169 | Iter Mean Loss 4.6708
2020-11-05 18:44:46,650 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1690 | Iter Mean Loss 4.3705
2020-11-05 18:44:46,652 - root - INFO - Evaluate: Epoch 0684 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,661 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7093 | Iter Mean Loss 5.7093
2020-11-05 18:44:46,670 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6968 | Iter Mean Loss 3.7030
2020-11-05 18:44:46,678 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0407 | Iter Mean Loss 4.4823
2020-11-05 18:44:46,686 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2076 | Iter Mean Loss 4.6636
2020-11-05 18:44:46,693 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1616 | Iter Mean Loss 4.3632
2020-11-05 18:44:46,696 - root - INFO - Evaluate: Epoch 0685 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,704 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7046 | Iter Mean Loss 5.7046
2020-11-05 18:44:46,712 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6923 | Iter Mean Loss 3.6984
2020-11-05 18:44:46,720 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0305 | Iter Mean Loss 4.4758
2020-11-05 18:44:46,728 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1984 | Iter Mean Loss 4.6564
2020-11-05 18:44:46,736 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1543 | Iter Mean Loss 4.3560
2020-11-05 18:44:46,738 - root - INFO - Evaluate: Epoch 0686 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,747 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7000 | Iter Mean Loss 5.7000
2020-11-05 18:44:46,754 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6878 | Iter Mean Loss 3.6939
2020-11-05 18:44:46,762 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0204 | Iter Mean Loss 4.4694
2020-11-05 18:44:46,769 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1891 | Iter Mean Loss 4.6493
2020-11-05 18:44:46,776 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1470 | Iter Mean Loss 4.3489
2020-11-05 18:44:46,778 - root - INFO - Evaluate: Epoch 0687 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,786 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6953 | Iter Mean Loss 5.6953
2020-11-05 18:44:46,793 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6834 | Iter Mean Loss 3.6894
2020-11-05 18:44:46,800 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0104 | Iter Mean Loss 4.4630
2020-11-05 18:44:46,807 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1800 | Iter Mean Loss 4.6423
2020-11-05 18:44:46,815 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1398 | Iter Mean Loss 4.3418
2020-11-05 18:44:46,817 - root - INFO - Evaluate: Epoch 0688 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:44:46,824 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6907 | Iter Mean Loss 5.6907
2020-11-05 18:44:46,832 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6791 | Iter Mean Loss 3.6849
2020-11-05 18:44:46,840 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0004 | Iter Mean Loss 4.4567
2020-11-05 18:44:46,847 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1709 | Iter Mean Loss 4.6353
2020-11-05 18:44:46,854 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1326 | Iter Mean Loss 4.3348
2020-11-05 18:44:46,856 - root - INFO - Evaluate: Epoch 0689 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:46,865 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6862 | Iter Mean Loss 5.6862
2020-11-05 18:44:46,873 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6748 | Iter Mean Loss 3.6805
2020-11-05 18:44:46,881 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9905 | Iter Mean Loss 4.4505
2020-11-05 18:44:46,889 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1619 | Iter Mean Loss 4.6283
2020-11-05 18:44:46,897 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1255 | Iter Mean Loss 4.3278
2020-11-05 18:44:46,899 - root - INFO - Evaluate: Epoch 0690 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:46,907 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6816 | Iter Mean Loss 5.6816
2020-11-05 18:44:46,915 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6706 | Iter Mean Loss 3.6761
2020-11-05 18:44:46,923 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9806 | Iter Mean Loss 4.4443
2020-11-05 18:44:46,931 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1530 | Iter Mean Loss 4.6215
2020-11-05 18:44:46,939 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1185 | Iter Mean Loss 4.3209
2020-11-05 18:44:46,941 - root - INFO - Evaluate: Epoch 0691 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:46,949 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6771 | Iter Mean Loss 5.6771
2020-11-05 18:44:46,957 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6664 | Iter Mean Loss 3.6718
2020-11-05 18:44:46,964 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9708 | Iter Mean Loss 4.4381
2020-11-05 18:44:46,971 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1441 | Iter Mean Loss 4.6146
2020-11-05 18:44:46,978 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1115 | Iter Mean Loss 4.3140
2020-11-05 18:44:46,980 - root - INFO - Evaluate: Epoch 0692 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:46,988 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6726 | Iter Mean Loss 5.6726
2020-11-05 18:44:46,995 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6623 | Iter Mean Loss 3.6675
2020-11-05 18:44:47,003 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9611 | Iter Mean Loss 4.4320
2020-11-05 18:44:47,010 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1352 | Iter Mean Loss 4.6078
2020-11-05 18:44:47,017 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1046 | Iter Mean Loss 4.3072
2020-11-05 18:44:47,019 - root - INFO - Evaluate: Epoch 0693 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:47,027 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6682 | Iter Mean Loss 5.6682
2020-11-05 18:44:47,034 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6583 | Iter Mean Loss 3.6632
2020-11-05 18:44:47,041 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 4.4260
2020-11-05 18:44:47,049 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1265 | Iter Mean Loss 4.6011
2020-11-05 18:44:47,057 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0977 | Iter Mean Loss 4.3004
2020-11-05 18:44:47,059 - root - INFO - Evaluate: Epoch 0694 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:44:47,068 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6637 | Iter Mean Loss 5.6637
2020-11-05 18:44:47,075 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 3.6590
2020-11-05 18:44:47,083 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9418 | Iter Mean Loss 4.4199
2020-11-05 18:44:47,091 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1178 | Iter Mean Loss 4.5944
2020-11-05 18:44:47,099 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0909 | Iter Mean Loss 4.2937
2020-11-05 18:44:47,102 - root - INFO - Evaluate: Epoch 0695 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,110 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6593 | Iter Mean Loss 5.6593
2020-11-05 18:44:47,118 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6503 | Iter Mean Loss 3.6548
2020-11-05 18:44:47,126 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9323 | Iter Mean Loss 4.4140
2020-11-05 18:44:47,133 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1091 | Iter Mean Loss 4.5878
2020-11-05 18:44:47,142 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0841 | Iter Mean Loss 4.2870
2020-11-05 18:44:47,144 - root - INFO - Evaluate: Epoch 0696 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,153 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6549 | Iter Mean Loss 5.6549
2020-11-05 18:44:47,161 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6464 | Iter Mean Loss 3.6507
2020-11-05 18:44:47,168 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9228 | Iter Mean Loss 4.4081
2020-11-05 18:44:47,179 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1005 | Iter Mean Loss 4.5812
2020-11-05 18:44:47,191 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0774 | Iter Mean Loss 4.2804
2020-11-05 18:44:47,195 - root - INFO - Evaluate: Epoch 0697 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,206 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6506 | Iter Mean Loss 5.6506
2020-11-05 18:44:47,216 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6426 | Iter Mean Loss 3.6466
2020-11-05 18:44:47,224 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9134 | Iter Mean Loss 4.4022
2020-11-05 18:44:47,231 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0920 | Iter Mean Loss 4.5746
2020-11-05 18:44:47,240 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0707 | Iter Mean Loss 4.2738
2020-11-05 18:44:47,242 - root - INFO - Evaluate: Epoch 0698 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,253 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6462 | Iter Mean Loss 5.6462
2020-11-05 18:44:47,263 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6388 | Iter Mean Loss 3.6425
2020-11-05 18:44:47,272 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9040 | Iter Mean Loss 4.3963
2020-11-05 18:44:47,282 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0835 | Iter Mean Loss 4.5681
2020-11-05 18:44:47,291 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0641 | Iter Mean Loss 4.2673
2020-11-05 18:44:47,293 - root - INFO - Evaluate: Epoch 0699 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,302 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6419 | Iter Mean Loss 5.6419
2020-11-05 18:44:47,312 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6350 | Iter Mean Loss 3.6385
2020-11-05 18:44:47,324 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8947 | Iter Mean Loss 4.3906
2020-11-05 18:44:47,334 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0751 | Iter Mean Loss 4.5617
2020-11-05 18:44:47,344 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0576 | Iter Mean Loss 4.2609
2020-11-05 18:44:47,348 - root - INFO - Evaluate: Epoch 0700 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:44:47,358 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6376 | Iter Mean Loss 5.6376
2020-11-05 18:44:47,368 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6313 | Iter Mean Loss 3.6345
2020-11-05 18:44:47,378 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8855 | Iter Mean Loss 4.3848
2020-11-05 18:44:47,388 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0667 | Iter Mean Loss 4.5553
2020-11-05 18:44:47,396 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0511 | Iter Mean Loss 4.2544
2020-11-05 18:44:47,399 - root - INFO - Evaluate: Epoch 0701 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:47,408 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6334 | Iter Mean Loss 5.6334
2020-11-05 18:44:47,417 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6277 | Iter Mean Loss 3.6305
2020-11-05 18:44:47,425 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8763 | Iter Mean Loss 4.3791
2020-11-05 18:44:47,434 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0584 | Iter Mean Loss 4.5489
2020-11-05 18:44:47,442 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0446 | Iter Mean Loss 4.2481
2020-11-05 18:44:47,444 - root - INFO - Evaluate: Epoch 0702 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:47,455 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6291 | Iter Mean Loss 5.6291
2020-11-05 18:44:47,462 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6240 | Iter Mean Loss 3.6266
2020-11-05 18:44:47,471 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8671 | Iter Mean Loss 4.3734
2020-11-05 18:44:47,479 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0501 | Iter Mean Loss 4.5426
2020-11-05 18:44:47,488 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0382 | Iter Mean Loss 4.2417
2020-11-05 18:44:47,490 - root - INFO - Evaluate: Epoch 0703 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:47,500 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6249 | Iter Mean Loss 5.6249
2020-11-05 18:44:47,508 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6205 | Iter Mean Loss 3.6227
2020-11-05 18:44:47,517 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 4.3678
2020-11-05 18:44:47,525 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0419 | Iter Mean Loss 4.5363
2020-11-05 18:44:47,534 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0319 | Iter Mean Loss 4.2354
2020-11-05 18:44:47,537 - root - INFO - Evaluate: Epoch 0704 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:47,546 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6207 | Iter Mean Loss 5.6207
2020-11-05 18:44:47,555 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6170 | Iter Mean Loss 3.6188
2020-11-05 18:44:47,563 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8490 | Iter Mean Loss 4.3622
2020-11-05 18:44:47,572 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0337 | Iter Mean Loss 4.5301
2020-11-05 18:44:47,580 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0255 | Iter Mean Loss 4.2292
2020-11-05 18:44:47,583 - root - INFO - Evaluate: Epoch 0705 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:44:47,592 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6165 | Iter Mean Loss 5.6165
2020-11-05 18:44:47,600 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6135 | Iter Mean Loss 3.6150
2020-11-05 18:44:47,609 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8400 | Iter Mean Loss 4.3567
2020-11-05 18:44:47,617 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0256 | Iter Mean Loss 4.5239
2020-11-05 18:44:47,625 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0193 | Iter Mean Loss 4.2230
2020-11-05 18:44:47,627 - root - INFO - Evaluate: Epoch 0706 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:47,636 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6124 | Iter Mean Loss 5.6124
2020-11-05 18:44:47,645 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6101 | Iter Mean Loss 3.6112
2020-11-05 18:44:47,655 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8311 | Iter Mean Loss 4.3512
2020-11-05 18:44:47,663 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0176 | Iter Mean Loss 4.5178
2020-11-05 18:44:47,672 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0131 | Iter Mean Loss 4.2168
2020-11-05 18:44:47,675 - root - INFO - Evaluate: Epoch 0707 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:47,684 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 5.6082
2020-11-05 18:44:47,693 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6067 | Iter Mean Loss 3.6075
2020-11-05 18:44:47,702 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8222 | Iter Mean Loss 4.3457
2020-11-05 18:44:47,710 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0096 | Iter Mean Loss 4.5117
2020-11-05 18:44:47,719 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0069 | Iter Mean Loss 4.2107
2020-11-05 18:44:47,722 - root - INFO - Evaluate: Epoch 0708 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:47,730 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6041 | Iter Mean Loss 5.6041
2020-11-05 18:44:47,740 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6033 | Iter Mean Loss 3.6037
2020-11-05 18:44:47,748 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8134 | Iter Mean Loss 4.3403
2020-11-05 18:44:47,757 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0016 | Iter Mean Loss 4.5056
2020-11-05 18:44:47,765 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0008 | Iter Mean Loss 4.2047
2020-11-05 18:44:47,768 - root - INFO - Evaluate: Epoch 0709 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:47,777 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6000 | Iter Mean Loss 5.6000
2020-11-05 18:44:47,786 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6000 | Iter Mean Loss 3.6000
2020-11-05 18:44:47,794 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8047 | Iter Mean Loss 4.3349
2020-11-05 18:44:47,803 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9937 | Iter Mean Loss 4.4996
2020-11-05 18:44:47,811 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9947 | Iter Mean Loss 4.1986
2020-11-05 18:44:47,813 - root - INFO - Evaluate: Epoch 0710 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:44:47,823 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5959 | Iter Mean Loss 5.5959
2020-11-05 18:44:47,831 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5968 | Iter Mean Loss 3.5964
2020-11-05 18:44:47,840 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7959 | Iter Mean Loss 4.3295
2020-11-05 18:44:47,847 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9858 | Iter Mean Loss 4.4936
2020-11-05 18:44:47,857 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9887 | Iter Mean Loss 4.1926
2020-11-05 18:44:47,859 - root - INFO - Evaluate: Epoch 0711 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:47,869 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5919 | Iter Mean Loss 5.5919
2020-11-05 18:44:47,878 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5935 | Iter Mean Loss 3.5927
2020-11-05 18:44:47,887 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7873 | Iter Mean Loss 4.3242
2020-11-05 18:44:47,895 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9780 | Iter Mean Loss 4.4877
2020-11-05 18:44:47,905 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9827 | Iter Mean Loss 4.1867
2020-11-05 18:44:47,907 - root - INFO - Evaluate: Epoch 0712 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:47,916 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5879 | Iter Mean Loss 5.5879
2020-11-05 18:44:47,926 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5904 | Iter Mean Loss 3.5891
2020-11-05 18:44:47,934 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7786 | Iter Mean Loss 4.3189
2020-11-05 18:44:47,943 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9702 | Iter Mean Loss 4.4818
2020-11-05 18:44:47,952 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9768 | Iter Mean Loss 4.1808
2020-11-05 18:44:47,955 - root - INFO - Evaluate: Epoch 0713 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:47,963 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5838 | Iter Mean Loss 5.5838
2020-11-05 18:44:47,973 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 3.5855
2020-11-05 18:44:47,981 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7701 | Iter Mean Loss 4.3137
2020-11-05 18:44:47,989 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9625 | Iter Mean Loss 4.4759
2020-11-05 18:44:47,997 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9709 | Iter Mean Loss 4.1749
2020-11-05 18:44:48,000 - root - INFO - Evaluate: Epoch 0714 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:44:48,009 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5798 | Iter Mean Loss 5.5798
2020-11-05 18:44:48,019 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5841 | Iter Mean Loss 3.5820
2020-11-05 18:44:48,028 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7615 | Iter Mean Loss 4.3085
2020-11-05 18:44:48,036 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9548 | Iter Mean Loss 4.4701
2020-11-05 18:44:48,044 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9650 | Iter Mean Loss 4.1691
2020-11-05 18:44:48,046 - root - INFO - Evaluate: Epoch 0715 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:48,056 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5759 | Iter Mean Loss 5.5759
2020-11-05 18:44:48,064 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5810 | Iter Mean Loss 3.5784
2020-11-05 18:44:48,073 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7530 | Iter Mean Loss 4.3033
2020-11-05 18:44:48,081 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9472 | Iter Mean Loss 4.4643
2020-11-05 18:44:48,090 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9592 | Iter Mean Loss 4.1633
2020-11-05 18:44:48,093 - root - INFO - Evaluate: Epoch 0716 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:48,103 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5719 | Iter Mean Loss 5.5719
2020-11-05 18:44:48,112 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5780 | Iter Mean Loss 3.5749
2020-11-05 18:44:48,120 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7446 | Iter Mean Loss 4.2982
2020-11-05 18:44:48,129 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9396 | Iter Mean Loss 4.4585
2020-11-05 18:44:48,137 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 4.1575
2020-11-05 18:44:48,141 - root - INFO - Evaluate: Epoch 0717 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:48,150 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5680 | Iter Mean Loss 5.5680
2020-11-05 18:44:48,160 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5750 | Iter Mean Loss 3.5715
2020-11-05 18:44:48,168 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7362 | Iter Mean Loss 4.2931
2020-11-05 18:44:48,178 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9320 | Iter Mean Loss 4.4528
2020-11-05 18:44:48,185 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9477 | Iter Mean Loss 4.1518
2020-11-05 18:44:48,189 - root - INFO - Evaluate: Epoch 0718 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:48,198 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5640 | Iter Mean Loss 5.5640
2020-11-05 18:44:48,208 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5720 | Iter Mean Loss 3.5680
2020-11-05 18:44:48,216 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7278 | Iter Mean Loss 4.2880
2020-11-05 18:44:48,226 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9245 | Iter Mean Loss 4.4471
2020-11-05 18:44:48,233 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 4.1461
2020-11-05 18:44:48,236 - root - INFO - Evaluate: Epoch 0719 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:44:48,246 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5601 | Iter Mean Loss 5.5601
2020-11-05 18:44:48,253 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5691 | Iter Mean Loss 3.5646
2020-11-05 18:44:48,264 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7195 | Iter Mean Loss 4.2829
2020-11-05 18:44:48,272 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9170 | Iter Mean Loss 4.4414
2020-11-05 18:44:48,281 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 4.1404
2020-11-05 18:44:48,283 - root - INFO - Evaluate: Epoch 0720 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:48,292 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5562 | Iter Mean Loss 5.5562
2020-11-05 18:44:48,301 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5662 | Iter Mean Loss 3.5612
2020-11-05 18:44:48,310 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7113 | Iter Mean Loss 4.2779
2020-11-05 18:44:48,321 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9095 | Iter Mean Loss 4.4358
2020-11-05 18:44:48,331 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9307 | Iter Mean Loss 4.1348
2020-11-05 18:44:48,334 - root - INFO - Evaluate: Epoch 0721 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:48,343 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5524 | Iter Mean Loss 5.5524
2020-11-05 18:44:48,352 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 3.5578
2020-11-05 18:44:48,360 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7030 | Iter Mean Loss 4.2729
2020-11-05 18:44:48,368 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9021 | Iter Mean Loss 4.4302
2020-11-05 18:44:48,377 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9251 | Iter Mean Loss 4.1292
2020-11-05 18:44:48,380 - root - INFO - Evaluate: Epoch 0722 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:48,388 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5485 | Iter Mean Loss 5.5485
2020-11-05 18:44:48,396 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5605 | Iter Mean Loss 3.5545
2020-11-05 18:44:48,403 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6949 | Iter Mean Loss 4.2679
2020-11-05 18:44:48,410 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8948 | Iter Mean Loss 4.4247
2020-11-05 18:44:48,417 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9195 | Iter Mean Loss 4.1236
2020-11-05 18:44:48,419 - root - INFO - Evaluate: Epoch 0723 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:44:48,430 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5447 | Iter Mean Loss 5.5447
2020-11-05 18:44:48,438 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5577 | Iter Mean Loss 3.5512
2020-11-05 18:44:48,445 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6867 | Iter Mean Loss 4.2630
2020-11-05 18:44:48,453 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8875 | Iter Mean Loss 4.4191
2020-11-05 18:44:48,462 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9140 | Iter Mean Loss 4.1181
2020-11-05 18:44:48,464 - root - INFO - Evaluate: Epoch 0724 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:48,473 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5408 | Iter Mean Loss 5.5408
2020-11-05 18:44:48,483 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5549 | Iter Mean Loss 3.5479
2020-11-05 18:44:48,490 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6786 | Iter Mean Loss 4.2581
2020-11-05 18:44:48,498 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8802 | Iter Mean Loss 4.4136
2020-11-05 18:44:48,506 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9085 | Iter Mean Loss 4.1126
2020-11-05 18:44:48,509 - root - INFO - Evaluate: Epoch 0725 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:48,518 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5370 | Iter Mean Loss 5.5370
2020-11-05 18:44:48,527 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5522 | Iter Mean Loss 3.5446
2020-11-05 18:44:48,536 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6705 | Iter Mean Loss 4.2532
2020-11-05 18:44:48,544 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8729 | Iter Mean Loss 4.4082
2020-11-05 18:44:48,553 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9031 | Iter Mean Loss 4.1071
2020-11-05 18:44:48,555 - root - INFO - Evaluate: Epoch 0726 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:48,565 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5332 | Iter Mean Loss 5.5332
2020-11-05 18:44:48,573 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5495 | Iter Mean Loss 3.5413
2020-11-05 18:44:48,581 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6625 | Iter Mean Loss 4.2484
2020-11-05 18:44:48,589 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8657 | Iter Mean Loss 4.4027
2020-11-05 18:44:48,597 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8977 | Iter Mean Loss 4.1017
2020-11-05 18:44:48,600 - root - INFO - Evaluate: Epoch 0727 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:48,608 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5294 | Iter Mean Loss 5.5294
2020-11-05 18:44:48,617 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5468 | Iter Mean Loss 3.5381
2020-11-05 18:44:48,625 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6545 | Iter Mean Loss 4.2436
2020-11-05 18:44:48,634 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8585 | Iter Mean Loss 4.3973
2020-11-05 18:44:48,641 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8923 | Iter Mean Loss 4.0963
2020-11-05 18:44:48,643 - root - INFO - Evaluate: Epoch 0728 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:44:48,651 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5257 | Iter Mean Loss 5.5257
2020-11-05 18:44:48,659 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5441 | Iter Mean Loss 3.5349
2020-11-05 18:44:48,668 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6465 | Iter Mean Loss 4.2388
2020-11-05 18:44:48,675 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8514 | Iter Mean Loss 4.3919
2020-11-05 18:44:48,684 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 4.0909
2020-11-05 18:44:48,686 - root - INFO - Evaluate: Epoch 0729 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:48,694 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5219 | Iter Mean Loss 5.5219
2020-11-05 18:44:48,702 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5415 | Iter Mean Loss 3.5317
2020-11-05 18:44:48,711 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6386 | Iter Mean Loss 4.2340
2020-11-05 18:44:48,720 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8443 | Iter Mean Loss 4.3866
2020-11-05 18:44:48,727 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8817 | Iter Mean Loss 4.0856
2020-11-05 18:44:48,730 - root - INFO - Evaluate: Epoch 0730 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:48,739 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5182 | Iter Mean Loss 5.5182
2020-11-05 18:44:48,748 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5389 | Iter Mean Loss 3.5286
2020-11-05 18:44:48,755 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6307 | Iter Mean Loss 4.2293
2020-11-05 18:44:48,763 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8372 | Iter Mean Loss 4.3813
2020-11-05 18:44:48,771 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8764 | Iter Mean Loss 4.0803
2020-11-05 18:44:48,773 - root - INFO - Evaluate: Epoch 0731 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:48,781 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5145 | Iter Mean Loss 5.5145
2020-11-05 18:44:48,790 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5363 | Iter Mean Loss 3.5254
2020-11-05 18:44:48,797 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6229 | Iter Mean Loss 4.2246
2020-11-05 18:44:48,804 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8302 | Iter Mean Loss 4.3760
2020-11-05 18:44:48,812 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8711 | Iter Mean Loss 4.0750
2020-11-05 18:44:48,814 - root - INFO - Evaluate: Epoch 0732 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:44:48,821 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5108 | Iter Mean Loss 5.5108
2020-11-05 18:44:48,829 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5338 | Iter Mean Loss 3.5223
2020-11-05 18:44:48,836 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6151 | Iter Mean Loss 4.2199
2020-11-05 18:44:48,843 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8231 | Iter Mean Loss 4.3707
2020-11-05 18:44:48,850 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8659 | Iter Mean Loss 4.0697
2020-11-05 18:44:48,853 - root - INFO - Evaluate: Epoch 0733 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:48,860 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5071 | Iter Mean Loss 5.5071
2020-11-05 18:44:48,868 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5313 | Iter Mean Loss 3.5192
2020-11-05 18:44:48,875 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6073 | Iter Mean Loss 4.2152
2020-11-05 18:44:48,883 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8162 | Iter Mean Loss 4.3654
2020-11-05 18:44:48,891 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8608 | Iter Mean Loss 4.0645
2020-11-05 18:44:48,893 - root - INFO - Evaluate: Epoch 0734 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:48,901 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5034 | Iter Mean Loss 5.5034
2020-11-05 18:44:48,909 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5288 | Iter Mean Loss 3.5161
2020-11-05 18:44:48,916 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5995 | Iter Mean Loss 4.2106
2020-11-05 18:44:48,924 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8092 | Iter Mean Loss 4.3602
2020-11-05 18:44:48,932 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8556 | Iter Mean Loss 4.0593
2020-11-05 18:44:48,934 - root - INFO - Evaluate: Epoch 0735 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:48,943 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4997 | Iter Mean Loss 5.4997
2020-11-05 18:44:48,951 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5263 | Iter Mean Loss 3.5130
2020-11-05 18:44:48,959 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5918 | Iter Mean Loss 4.2059
2020-11-05 18:44:48,966 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8023 | Iter Mean Loss 4.3550
2020-11-05 18:44:48,975 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8505 | Iter Mean Loss 4.0541
2020-11-05 18:44:48,977 - root - INFO - Evaluate: Epoch 0736 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:44:48,985 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4961 | Iter Mean Loss 5.4961
2020-11-05 18:44:48,993 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5239 | Iter Mean Loss 3.5100
2020-11-05 18:44:49,000 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5841 | Iter Mean Loss 4.2013
2020-11-05 18:44:49,007 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7954 | Iter Mean Loss 4.3499
2020-11-05 18:44:49,015 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8454 | Iter Mean Loss 4.0490
2020-11-05 18:44:49,017 - root - INFO - Evaluate: Epoch 0737 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:49,024 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4924 | Iter Mean Loss 5.4924
2020-11-05 18:44:49,032 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5214 | Iter Mean Loss 3.5069
2020-11-05 18:44:49,039 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5765 | Iter Mean Loss 4.1968
2020-11-05 18:44:49,046 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7886 | Iter Mean Loss 4.3447
2020-11-05 18:44:49,053 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8403 | Iter Mean Loss 4.0438
2020-11-05 18:44:49,055 - root - INFO - Evaluate: Epoch 0738 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:49,063 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4888 | Iter Mean Loss 5.4888
2020-11-05 18:44:49,071 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5190 | Iter Mean Loss 3.5039
2020-11-05 18:44:49,078 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5688 | Iter Mean Loss 4.1922
2020-11-05 18:44:49,086 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7817 | Iter Mean Loss 4.3396
2020-11-05 18:44:49,094 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8353 | Iter Mean Loss 4.0387
2020-11-05 18:44:49,096 - root - INFO - Evaluate: Epoch 0739 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:49,104 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4852 | Iter Mean Loss 5.4852
2020-11-05 18:44:49,112 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5166 | Iter Mean Loss 3.5009
2020-11-05 18:44:49,120 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5612 | Iter Mean Loss 4.1877
2020-11-05 18:44:49,128 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7749 | Iter Mean Loss 4.3345
2020-11-05 18:44:49,136 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 4.0337
2020-11-05 18:44:49,138 - root - INFO - Evaluate: Epoch 0740 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:44:49,146 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4816 | Iter Mean Loss 5.4816
2020-11-05 18:44:49,154 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5143 | Iter Mean Loss 3.4979
2020-11-05 18:44:49,162 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5537 | Iter Mean Loss 4.1832
2020-11-05 18:44:49,170 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7682 | Iter Mean Loss 4.3294
2020-11-05 18:44:49,178 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8253 | Iter Mean Loss 4.0286
2020-11-05 18:44:49,181 - root - INFO - Evaluate: Epoch 0741 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:49,189 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4780 | Iter Mean Loss 5.4780
2020-11-05 18:44:49,197 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5120 | Iter Mean Loss 3.4950
2020-11-05 18:44:49,205 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5462 | Iter Mean Loss 4.1787
2020-11-05 18:44:49,212 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7614 | Iter Mean Loss 4.3244
2020-11-05 18:44:49,219 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8203 | Iter Mean Loss 4.0236
2020-11-05 18:44:49,221 - root - INFO - Evaluate: Epoch 0742 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:49,229 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4744 | Iter Mean Loss 5.4744
2020-11-05 18:44:49,236 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5096 | Iter Mean Loss 3.4920
2020-11-05 18:44:49,244 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5386 | Iter Mean Loss 4.1742
2020-11-05 18:44:49,251 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7547 | Iter Mean Loss 4.3194
2020-11-05 18:44:49,258 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8154 | Iter Mean Loss 4.0186
2020-11-05 18:44:49,260 - root - INFO - Evaluate: Epoch 0743 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:49,268 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4709 | Iter Mean Loss 5.4709
2020-11-05 18:44:49,275 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5073 | Iter Mean Loss 3.4891
2020-11-05 18:44:49,282 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5312 | Iter Mean Loss 4.1698
2020-11-05 18:44:49,290 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7480 | Iter Mean Loss 4.3144
2020-11-05 18:44:49,297 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8105 | Iter Mean Loss 4.0136
2020-11-05 18:44:49,300 - root - INFO - Evaluate: Epoch 0744 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:44:49,308 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4673 | Iter Mean Loss 5.4673
2020-11-05 18:44:49,317 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5051 | Iter Mean Loss 3.4862
2020-11-05 18:44:49,325 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5237 | Iter Mean Loss 4.1654
2020-11-05 18:44:49,334 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 4.3094
2020-11-05 18:44:49,343 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8056 | Iter Mean Loss 4.0086
2020-11-05 18:44:49,346 - root - INFO - Evaluate: Epoch 0745 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:49,355 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4638 | Iter Mean Loss 5.4638
2020-11-05 18:44:49,365 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5028 | Iter Mean Loss 3.4833
2020-11-05 18:44:49,373 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5163 | Iter Mean Loss 4.1610
2020-11-05 18:44:49,382 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7348 | Iter Mean Loss 4.3044
2020-11-05 18:44:49,391 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8008 | Iter Mean Loss 4.0037
2020-11-05 18:44:49,393 - root - INFO - Evaluate: Epoch 0746 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:49,403 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4602 | Iter Mean Loss 5.4602
2020-11-05 18:44:49,412 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5006 | Iter Mean Loss 3.4804
2020-11-05 18:44:49,423 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5089 | Iter Mean Loss 4.1566
2020-11-05 18:44:49,433 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7281 | Iter Mean Loss 4.2995
2020-11-05 18:44:49,442 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7960 | Iter Mean Loss 3.9988
2020-11-05 18:44:49,445 - root - INFO - Evaluate: Epoch 0747 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:44:49,456 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4567 | Iter Mean Loss 5.4567
2020-11-05 18:44:49,465 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4984 | Iter Mean Loss 3.4776
2020-11-05 18:44:49,474 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5016 | Iter Mean Loss 4.1522
2020-11-05 18:44:49,484 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7216 | Iter Mean Loss 4.2946
2020-11-05 18:44:49,493 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7912 | Iter Mean Loss 3.9939
2020-11-05 18:44:49,497 - root - INFO - Evaluate: Epoch 0748 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:49,509 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4532 | Iter Mean Loss 5.4532
2020-11-05 18:44:49,518 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4962 | Iter Mean Loss 3.4747
2020-11-05 18:44:49,530 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4942 | Iter Mean Loss 4.1479
2020-11-05 18:44:49,540 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7150 | Iter Mean Loss 4.2897
2020-11-05 18:44:49,549 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7864 | Iter Mean Loss 3.9890
2020-11-05 18:44:49,552 - root - INFO - Evaluate: Epoch 0749 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:49,562 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4497 | Iter Mean Loss 5.4497
2020-11-05 18:44:49,572 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4940 | Iter Mean Loss 3.4719
2020-11-05 18:44:49,582 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4869 | Iter Mean Loss 4.1435
2020-11-05 18:44:49,591 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7085 | Iter Mean Loss 4.2848
2020-11-05 18:44:49,601 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7817 | Iter Mean Loss 3.9842
2020-11-05 18:44:49,604 - root - INFO - Evaluate: Epoch 0750 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:49,615 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4462 | Iter Mean Loss 5.4462
2020-11-05 18:44:49,624 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4918 | Iter Mean Loss 3.4690
2020-11-05 18:44:49,632 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4796 | Iter Mean Loss 4.1392
2020-11-05 18:44:49,641 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7020 | Iter Mean Loss 4.2799
2020-11-05 18:44:49,649 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7769 | Iter Mean Loss 3.9793
2020-11-05 18:44:49,652 - root - INFO - Evaluate: Epoch 0751 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:44:49,660 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4428 | Iter Mean Loss 5.4428
2020-11-05 18:44:49,669 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4897 | Iter Mean Loss 3.4662
2020-11-05 18:44:49,677 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4724 | Iter Mean Loss 4.1349
2020-11-05 18:44:49,686 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6955 | Iter Mean Loss 4.2751
2020-11-05 18:44:49,694 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7722 | Iter Mean Loss 3.9745
2020-11-05 18:44:49,697 - root - INFO - Evaluate: Epoch 0752 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:49,706 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4393 | Iter Mean Loss 5.4393
2020-11-05 18:44:49,715 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4876 | Iter Mean Loss 3.4634
2020-11-05 18:44:49,724 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4651 | Iter Mean Loss 4.1307
2020-11-05 18:44:49,732 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6891 | Iter Mean Loss 4.2703
2020-11-05 18:44:49,741 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7676 | Iter Mean Loss 3.9697
2020-11-05 18:44:49,743 - root - INFO - Evaluate: Epoch 0753 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:49,752 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4358 | Iter Mean Loss 5.4358
2020-11-05 18:44:49,761 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 3.4607
2020-11-05 18:44:49,770 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4579 | Iter Mean Loss 4.1264
2020-11-05 18:44:49,778 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6826 | Iter Mean Loss 4.2655
2020-11-05 18:44:49,787 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7629 | Iter Mean Loss 3.9650
2020-11-05 18:44:49,789 - root - INFO - Evaluate: Epoch 0754 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:49,799 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4324 | Iter Mean Loss 5.4324
2020-11-05 18:44:49,807 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4834 | Iter Mean Loss 3.4579
2020-11-05 18:44:49,816 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4507 | Iter Mean Loss 4.1222
2020-11-05 18:44:49,824 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6762 | Iter Mean Loss 4.2607
2020-11-05 18:44:49,832 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7583 | Iter Mean Loss 3.9602
2020-11-05 18:44:49,834 - root - INFO - Evaluate: Epoch 0755 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:44:49,843 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4290 | Iter Mean Loss 5.4290
2020-11-05 18:44:49,852 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4813 | Iter Mean Loss 3.4551
2020-11-05 18:44:49,860 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4436 | Iter Mean Loss 4.1180
2020-11-05 18:44:49,868 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6698 | Iter Mean Loss 4.2559
2020-11-05 18:44:49,876 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7537 | Iter Mean Loss 3.9555
2020-11-05 18:44:49,878 - root - INFO - Evaluate: Epoch 0756 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:49,888 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4255 | Iter Mean Loss 5.4255
2020-11-05 18:44:49,896 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4793 | Iter Mean Loss 3.4524
2020-11-05 18:44:49,905 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4365 | Iter Mean Loss 4.1137
2020-11-05 18:44:49,913 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6635 | Iter Mean Loss 4.2512
2020-11-05 18:44:49,922 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7491 | Iter Mean Loss 3.9508
2020-11-05 18:44:49,925 - root - INFO - Evaluate: Epoch 0757 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:49,934 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4221 | Iter Mean Loss 5.4221
2020-11-05 18:44:49,942 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4772 | Iter Mean Loss 3.4497
2020-11-05 18:44:49,952 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4293 | Iter Mean Loss 4.1096
2020-11-05 18:44:49,960 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6572 | Iter Mean Loss 4.2465
2020-11-05 18:44:49,969 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7445 | Iter Mean Loss 3.9461
2020-11-05 18:44:49,971 - root - INFO - Evaluate: Epoch 0758 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:49,981 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4187 | Iter Mean Loss 5.4187
2020-11-05 18:44:49,992 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4752 | Iter Mean Loss 3.4469
2020-11-05 18:44:50,006 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4223 | Iter Mean Loss 4.1054
2020-11-05 18:44:50,017 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6508 | Iter Mean Loss 4.2417
2020-11-05 18:44:50,025 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7400 | Iter Mean Loss 3.9414
2020-11-05 18:44:50,028 - root - INFO - Evaluate: Epoch 0759 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:44:50,037 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4153 | Iter Mean Loss 5.4153
2020-11-05 18:44:50,045 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4732 | Iter Mean Loss 3.4442
2020-11-05 18:44:50,054 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4152 | Iter Mean Loss 4.1012
2020-11-05 18:44:50,062 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6445 | Iter Mean Loss 4.2371
2020-11-05 18:44:50,070 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7354 | Iter Mean Loss 3.9367
2020-11-05 18:44:50,072 - root - INFO - Evaluate: Epoch 0760 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:50,082 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4119 | Iter Mean Loss 5.4119
2020-11-05 18:44:50,090 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4712 | Iter Mean Loss 3.4416
2020-11-05 18:44:50,099 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4081 | Iter Mean Loss 4.0971
2020-11-05 18:44:50,107 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6383 | Iter Mean Loss 4.2324
2020-11-05 18:44:50,116 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7309 | Iter Mean Loss 3.9321
2020-11-05 18:44:50,118 - root - INFO - Evaluate: Epoch 0761 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:50,127 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4086 | Iter Mean Loss 5.4086
2020-11-05 18:44:50,136 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4692 | Iter Mean Loss 3.4389
2020-11-05 18:44:50,144 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4011 | Iter Mean Loss 4.0930
2020-11-05 18:44:50,153 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6320 | Iter Mean Loss 4.2277
2020-11-05 18:44:50,162 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7265 | Iter Mean Loss 3.9275
2020-11-05 18:44:50,165 - root - INFO - Evaluate: Epoch 0762 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:44:50,175 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4052 | Iter Mean Loss 5.4052
2020-11-05 18:44:50,184 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4672 | Iter Mean Loss 3.4362
2020-11-05 18:44:50,192 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3941 | Iter Mean Loss 4.0888
2020-11-05 18:44:50,201 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6258 | Iter Mean Loss 4.2231
2020-11-05 18:44:50,209 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7220 | Iter Mean Loss 3.9229
2020-11-05 18:44:50,211 - root - INFO - Evaluate: Epoch 0763 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:50,221 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4018 | Iter Mean Loss 5.4018
2020-11-05 18:44:50,229 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4653 | Iter Mean Loss 3.4336
2020-11-05 18:44:50,238 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3872 | Iter Mean Loss 4.0848
2020-11-05 18:44:50,245 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6196 | Iter Mean Loss 4.2185
2020-11-05 18:44:50,254 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7176 | Iter Mean Loss 3.9183
2020-11-05 18:44:50,256 - root - INFO - Evaluate: Epoch 0764 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:50,265 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3985 | Iter Mean Loss 5.3985
2020-11-05 18:44:50,274 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4633 | Iter Mean Loss 3.4309
2020-11-05 18:44:50,282 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3802 | Iter Mean Loss 4.0807
2020-11-05 18:44:50,291 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6134 | Iter Mean Loss 4.2139
2020-11-05 18:44:50,300 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7131 | Iter Mean Loss 3.9137
2020-11-05 18:44:50,303 - root - INFO - Evaluate: Epoch 0765 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:50,312 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3951 | Iter Mean Loss 5.3951
2020-11-05 18:44:50,322 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4614 | Iter Mean Loss 3.4283
2020-11-05 18:44:50,331 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3733 | Iter Mean Loss 4.0766
2020-11-05 18:44:50,339 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6072 | Iter Mean Loss 4.2093
2020-11-05 18:44:50,347 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7087 | Iter Mean Loss 3.9092
2020-11-05 18:44:50,349 - root - INFO - Evaluate: Epoch 0766 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:44:50,358 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3918 | Iter Mean Loss 5.3918
2020-11-05 18:44:50,367 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4595 | Iter Mean Loss 3.4257
2020-11-05 18:44:50,375 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3664 | Iter Mean Loss 4.0726
2020-11-05 18:44:50,383 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6011 | Iter Mean Loss 4.2047
2020-11-05 18:44:50,390 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7044 | Iter Mean Loss 3.9046
2020-11-05 18:44:50,393 - root - INFO - Evaluate: Epoch 0767 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:50,402 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3885 | Iter Mean Loss 5.3885
2020-11-05 18:44:50,409 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 3.4230
2020-11-05 18:44:50,417 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 4.0685
2020-11-05 18:44:50,425 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5950 | Iter Mean Loss 4.2001
2020-11-05 18:44:50,432 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7000 | Iter Mean Loss 3.9001
2020-11-05 18:44:50,434 - root - INFO - Evaluate: Epoch 0768 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:50,442 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3852 | Iter Mean Loss 5.3852
2020-11-05 18:44:50,449 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4557 | Iter Mean Loss 3.4204
2020-11-05 18:44:50,456 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3526 | Iter Mean Loss 4.0645
2020-11-05 18:44:50,463 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5889 | Iter Mean Loss 4.1956
2020-11-05 18:44:50,471 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 3.8956
2020-11-05 18:44:50,473 - root - INFO - Evaluate: Epoch 0769 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:44:50,480 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3818 | Iter Mean Loss 5.3818
2020-11-05 18:44:50,488 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4538 | Iter Mean Loss 3.4178
2020-11-05 18:44:50,495 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3457 | Iter Mean Loss 4.0605
2020-11-05 18:44:50,502 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5828 | Iter Mean Loss 4.1911
2020-11-05 18:44:50,510 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6913 | Iter Mean Loss 3.8911
2020-11-05 18:44:50,512 - root - INFO - Evaluate: Epoch 0770 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:44:50,521 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3785 | Iter Mean Loss 5.3785
2020-11-05 18:44:50,529 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4520 | Iter Mean Loss 3.4153
2020-11-05 18:44:50,537 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3389 | Iter Mean Loss 4.0565
2020-11-05 18:44:50,544 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5767 | Iter Mean Loss 4.1865
2020-11-05 18:44:50,553 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6870 | Iter Mean Loss 3.8866
2020-11-05 18:44:50,555 - root - INFO - Evaluate: Epoch 0771 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:44:50,564 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 5.3753
2020-11-05 18:44:50,571 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4501 | Iter Mean Loss 3.4127
2020-11-05 18:44:50,579 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3321 | Iter Mean Loss 4.0525
2020-11-05 18:44:50,587 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5707 | Iter Mean Loss 4.1820
2020-11-05 18:44:50,594 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 3.8822
2020-11-05 18:44:50,596 - root - INFO - Evaluate: Epoch 0772 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:44:50,605 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3720 | Iter Mean Loss 5.3720
2020-11-05 18:44:50,613 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4483 | Iter Mean Loss 3.4101
2020-11-05 18:44:50,622 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3253 | Iter Mean Loss 4.0485
2020-11-05 18:44:50,629 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5647 | Iter Mean Loss 4.1776
2020-11-05 18:44:50,636 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6785 | Iter Mean Loss 3.8777
2020-11-05 18:44:50,638 - root - INFO - Evaluate: Epoch 0773 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:50,646 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3687 | Iter Mean Loss 5.3687
2020-11-05 18:44:50,653 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4465 | Iter Mean Loss 3.4076
2020-11-05 18:44:50,660 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3185 | Iter Mean Loss 4.0446
2020-11-05 18:44:50,668 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5586 | Iter Mean Loss 4.1731
2020-11-05 18:44:50,675 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6742 | Iter Mean Loss 3.8733
2020-11-05 18:44:50,677 - root - INFO - Evaluate: Epoch 0774 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:50,685 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3654 | Iter Mean Loss 5.3654
2020-11-05 18:44:50,692 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4447 | Iter Mean Loss 3.4050
2020-11-05 18:44:50,699 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3118 | Iter Mean Loss 4.0406
2020-11-05 18:44:50,706 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5527 | Iter Mean Loss 4.1686
2020-11-05 18:44:50,714 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6700 | Iter Mean Loss 3.8689
2020-11-05 18:44:50,717 - root - INFO - Evaluate: Epoch 0775 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:50,724 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3622 | Iter Mean Loss 5.3622
2020-11-05 18:44:50,732 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4429 | Iter Mean Loss 3.4025
2020-11-05 18:44:50,740 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3050 | Iter Mean Loss 4.0367
2020-11-05 18:44:50,747 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5467 | Iter Mean Loss 4.1642
2020-11-05 18:44:50,756 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6658 | Iter Mean Loss 3.8645
2020-11-05 18:44:50,758 - root - INFO - Evaluate: Epoch 0776 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:44:50,766 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3589 | Iter Mean Loss 5.3589
2020-11-05 18:44:50,775 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4411 | Iter Mean Loss 3.4000
2020-11-05 18:44:50,782 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 4.0328
2020-11-05 18:44:50,790 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5407 | Iter Mean Loss 4.1598
2020-11-05 18:44:50,798 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6616 | Iter Mean Loss 3.8601
2020-11-05 18:44:50,800 - root - INFO - Evaluate: Epoch 0777 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:50,809 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3557 | Iter Mean Loss 5.3557
2020-11-05 18:44:50,816 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4393 | Iter Mean Loss 3.3975
2020-11-05 18:44:50,824 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2916 | Iter Mean Loss 4.0289
2020-11-05 18:44:50,832 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5348 | Iter Mean Loss 4.1553
2020-11-05 18:44:50,839 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6574 | Iter Mean Loss 3.8558
2020-11-05 18:44:50,841 - root - INFO - Evaluate: Epoch 0778 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:50,849 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3524 | Iter Mean Loss 5.3524
2020-11-05 18:44:50,856 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4375 | Iter Mean Loss 3.3950
2020-11-05 18:44:50,864 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2850 | Iter Mean Loss 4.0250
2020-11-05 18:44:50,871 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5289 | Iter Mean Loss 4.1509
2020-11-05 18:44:50,878 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6532 | Iter Mean Loss 3.8514
2020-11-05 18:44:50,880 - root - INFO - Evaluate: Epoch 0779 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:44:50,888 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3492 | Iter Mean Loss 5.3492
2020-11-05 18:44:50,895 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 3.3925
2020-11-05 18:44:50,902 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2783 | Iter Mean Loss 4.0211
2020-11-05 18:44:50,910 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5230 | Iter Mean Loss 4.1466
2020-11-05 18:44:50,917 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6491 | Iter Mean Loss 3.8471
2020-11-05 18:44:50,920 - root - INFO - Evaluate: Epoch 0780 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:44:50,929 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3460 | Iter Mean Loss 5.3460
2020-11-05 18:44:50,939 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4340 | Iter Mean Loss 3.3900
2020-11-05 18:44:50,947 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2717 | Iter Mean Loss 4.0172
2020-11-05 18:44:50,957 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 4.1422
2020-11-05 18:44:50,966 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6449 | Iter Mean Loss 3.8427
2020-11-05 18:44:50,970 - root - INFO - Evaluate: Epoch 0781 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:44:50,979 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3427 | Iter Mean Loss 5.3427
2020-11-05 18:44:50,989 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4323 | Iter Mean Loss 3.3875
2020-11-05 18:44:50,997 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2650 | Iter Mean Loss 4.0133
2020-11-05 18:44:51,007 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5112 | Iter Mean Loss 4.1378
2020-11-05 18:44:51,015 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6408 | Iter Mean Loss 3.8384
2020-11-05 18:44:51,019 - root - INFO - Evaluate: Epoch 0782 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:44:51,029 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3395 | Iter Mean Loss 5.3395
2020-11-05 18:44:51,038 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4305 | Iter Mean Loss 3.3850
2020-11-05 18:44:51,046 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2584 | Iter Mean Loss 4.0095
2020-11-05 18:44:51,056 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5054 | Iter Mean Loss 4.1335
2020-11-05 18:44:51,064 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6367 | Iter Mean Loss 3.8341
2020-11-05 18:44:51,068 - root - INFO - Evaluate: Epoch 0783 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:51,078 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3363 | Iter Mean Loss 5.3363
2020-11-05 18:44:51,087 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4288 | Iter Mean Loss 3.3826
2020-11-05 18:44:51,095 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2518 | Iter Mean Loss 4.0057
2020-11-05 18:44:51,104 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4996 | Iter Mean Loss 4.1291
2020-11-05 18:44:51,113 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6326 | Iter Mean Loss 3.8298
2020-11-05 18:44:51,115 - root - INFO - Evaluate: Epoch 0784 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:51,126 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3331 | Iter Mean Loss 5.3331
2020-11-05 18:44:51,134 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4271 | Iter Mean Loss 3.3801
2020-11-05 18:44:51,144 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.0018
2020-11-05 18:44:51,153 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4938 | Iter Mean Loss 4.1248
2020-11-05 18:44:51,163 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6286 | Iter Mean Loss 3.8256
2020-11-05 18:44:51,165 - root - INFO - Evaluate: Epoch 0785 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:51,176 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3299 | Iter Mean Loss 5.3299
2020-11-05 18:44:51,184 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4254 | Iter Mean Loss 3.3777
2020-11-05 18:44:51,195 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2387 | Iter Mean Loss 3.9980
2020-11-05 18:44:51,203 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4880 | Iter Mean Loss 4.1205
2020-11-05 18:44:51,213 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6245 | Iter Mean Loss 3.8213
2020-11-05 18:44:51,215 - root - INFO - Evaluate: Epoch 0786 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:44:51,227 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3267 | Iter Mean Loss 5.3267
2020-11-05 18:44:51,236 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4237 | Iter Mean Loss 3.3752
2020-11-05 18:44:51,246 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2322 | Iter Mean Loss 3.9942
2020-11-05 18:44:51,255 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4822 | Iter Mean Loss 4.1162
2020-11-05 18:44:51,264 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6205 | Iter Mean Loss 3.8171
2020-11-05 18:44:51,266 - root - INFO - Evaluate: Epoch 0787 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:51,277 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3236 | Iter Mean Loss 5.3236
2020-11-05 18:44:51,287 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4220 | Iter Mean Loss 3.3728
2020-11-05 18:44:51,296 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2256 | Iter Mean Loss 3.9904
2020-11-05 18:44:51,306 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4764 | Iter Mean Loss 4.1119
2020-11-05 18:44:51,316 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6165 | Iter Mean Loss 3.8128
2020-11-05 18:44:51,320 - root - INFO - Evaluate: Epoch 0788 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:51,330 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3204 | Iter Mean Loss 5.3204
2020-11-05 18:44:51,340 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4204 | Iter Mean Loss 3.3704
2020-11-05 18:44:51,348 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2191 | Iter Mean Loss 3.9866
2020-11-05 18:44:51,357 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4707 | Iter Mean Loss 4.1076
2020-11-05 18:44:51,365 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6125 | Iter Mean Loss 3.8086
2020-11-05 18:44:51,369 - root - INFO - Evaluate: Epoch 0789 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:44:51,379 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3172 | Iter Mean Loss 5.3172
2020-11-05 18:44:51,388 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4187 | Iter Mean Loss 3.3680
2020-11-05 18:44:51,397 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2126 | Iter Mean Loss 3.9829
2020-11-05 18:44:51,407 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4649 | Iter Mean Loss 4.1034
2020-11-05 18:44:51,415 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6085 | Iter Mean Loss 3.8044
2020-11-05 18:44:51,417 - root - INFO - Evaluate: Epoch 0790 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:44:51,425 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3141 | Iter Mean Loss 5.3141
2020-11-05 18:44:51,432 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4171 | Iter Mean Loss 3.3656
2020-11-05 18:44:51,444 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2062 | Iter Mean Loss 3.9791
2020-11-05 18:44:51,454 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4592 | Iter Mean Loss 4.0991
2020-11-05 18:44:51,463 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6045 | Iter Mean Loss 3.8002
2020-11-05 18:44:51,465 - root - INFO - Evaluate: Epoch 0791 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:44:51,476 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3109 | Iter Mean Loss 5.3109
2020-11-05 18:44:51,485 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 3.3632
2020-11-05 18:44:51,495 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1997 | Iter Mean Loss 3.9753
2020-11-05 18:44:51,506 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 4.0949
2020-11-05 18:44:51,514 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6005 | Iter Mean Loss 3.7960
2020-11-05 18:44:51,516 - root - INFO - Evaluate: Epoch 0792 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:44:51,528 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3078 | Iter Mean Loss 5.3078
2020-11-05 18:44:51,538 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4138 | Iter Mean Loss 3.3608
2020-11-05 18:44:51,547 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1933 | Iter Mean Loss 3.9716
2020-11-05 18:44:51,557 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 4.0907
2020-11-05 18:44:51,566 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5966 | Iter Mean Loss 3.7918
2020-11-05 18:44:51,569 - root - INFO - Evaluate: Epoch 0793 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:44:51,581 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3046 | Iter Mean Loss 5.3046
2020-11-05 18:44:51,593 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4122 | Iter Mean Loss 3.3584
2020-11-05 18:44:51,601 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1868 | Iter Mean Loss 3.9679
2020-11-05 18:44:51,613 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4422 | Iter Mean Loss 4.0864
2020-11-05 18:44:51,626 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5927 | Iter Mean Loss 3.7877
2020-11-05 18:44:51,628 - root - INFO - Evaluate: Epoch 0794 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:44:51,641 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3015 | Iter Mean Loss 5.3015
2020-11-05 18:44:51,649 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4105 | Iter Mean Loss 3.3560
2020-11-05 18:44:51,660 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1804 | Iter Mean Loss 3.9641
2020-11-05 18:44:51,669 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4365 | Iter Mean Loss 4.0822
2020-11-05 18:44:51,680 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5887 | Iter Mean Loss 3.7835
2020-11-05 18:44:51,682 - root - INFO - Evaluate: Epoch 0795 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:44:51,692 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 5.2983
2020-11-05 18:44:51,702 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4089 | Iter Mean Loss 3.3536
2020-11-05 18:44:51,711 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1740 | Iter Mean Loss 3.9604
2020-11-05 18:44:51,721 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4309 | Iter Mean Loss 4.0780
2020-11-05 18:44:51,731 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5848 | Iter Mean Loss 3.7794
2020-11-05 18:44:51,734 - root - INFO - Evaluate: Epoch 0796 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:44:51,744 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2952 | Iter Mean Loss 5.2952
2020-11-05 18:44:51,755 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4073 | Iter Mean Loss 3.3513
2020-11-05 18:44:51,765 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1677 | Iter Mean Loss 3.9567
2020-11-05 18:44:51,774 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4253 | Iter Mean Loss 4.0739
2020-11-05 18:44:51,784 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5809 | Iter Mean Loss 3.7753
2020-11-05 18:44:51,787 - root - INFO - Evaluate: Epoch 0797 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:44:51,797 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2921 | Iter Mean Loss 5.2921
2020-11-05 18:44:51,807 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4057 | Iter Mean Loss 3.3489
2020-11-05 18:44:51,816 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1613 | Iter Mean Loss 3.9530
2020-11-05 18:44:51,824 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4197 | Iter Mean Loss 4.0697
2020-11-05 18:44:51,834 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5771 | Iter Mean Loss 3.7712
2020-11-05 18:44:51,837 - root - INFO - Evaluate: Epoch 0798 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:44:51,846 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2890 | Iter Mean Loss 5.2890
2020-11-05 18:44:51,856 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4041 | Iter Mean Loss 3.3466
2020-11-05 18:44:51,864 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1549 | Iter Mean Loss 3.9494
2020-11-05 18:44:51,873 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4141 | Iter Mean Loss 4.0655
2020-11-05 18:44:51,881 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 3.7671
2020-11-05 18:44:51,884 - root - INFO - Evaluate: Epoch 0799 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:44:51,893 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2859 | Iter Mean Loss 5.2859
2020-11-05 18:44:51,902 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4025 | Iter Mean Loss 3.3442
2020-11-05 18:44:51,910 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1486 | Iter Mean Loss 3.9457
2020-11-05 18:44:51,920 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4085 | Iter Mean Loss 4.0614
2020-11-05 18:44:51,928 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5694 | Iter Mean Loss 3.7630
2020-11-05 18:44:51,932 - root - INFO - Evaluate: Epoch 0800 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:44:51,941 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2828 | Iter Mean Loss 5.2828
2020-11-05 18:44:51,951 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4010 | Iter Mean Loss 3.3419
2020-11-05 18:44:51,960 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1423 | Iter Mean Loss 3.9420
2020-11-05 18:44:51,970 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4029 | Iter Mean Loss 4.0572
2020-11-05 18:44:51,978 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5655 | Iter Mean Loss 3.7589
2020-11-05 18:44:51,982 - root - INFO - Evaluate: Epoch 0801 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:44:51,991 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2797 | Iter Mean Loss 5.2797
2020-11-05 18:44:52,001 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3994 | Iter Mean Loss 3.3395
2020-11-05 18:44:52,009 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1360 | Iter Mean Loss 3.9383
2020-11-05 18:44:52,019 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3974 | Iter Mean Loss 4.0531
2020-11-05 18:44:52,027 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5617 | Iter Mean Loss 3.7548
2020-11-05 18:44:52,031 - root - INFO - Evaluate: Epoch 0802 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:44:52,041 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2766 | Iter Mean Loss 5.2766
2020-11-05 18:44:52,050 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3978 | Iter Mean Loss 3.3372
2020-11-05 18:44:52,058 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1297 | Iter Mean Loss 3.9347
2020-11-05 18:44:52,067 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3918 | Iter Mean Loss 4.0490
2020-11-05 18:44:52,076 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5579 | Iter Mean Loss 3.7508
2020-11-05 18:44:52,079 - root - INFO - Evaluate: Epoch 0803 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:44:52,089 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2735 | Iter Mean Loss 5.2735
2020-11-05 18:44:52,097 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3963 | Iter Mean Loss 3.3349
2020-11-05 18:44:52,106 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1234 | Iter Mean Loss 3.9311
2020-11-05 18:44:52,115 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3863 | Iter Mean Loss 4.0449
2020-11-05 18:44:52,124 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5541 | Iter Mean Loss 3.7467
2020-11-05 18:44:52,126 - root - INFO - Evaluate: Epoch 0804 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:44:52,136 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2704 | Iter Mean Loss 5.2704
2020-11-05 18:44:52,144 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3947 | Iter Mean Loss 3.3326
2020-11-05 18:44:52,154 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1172 | Iter Mean Loss 3.9274
2020-11-05 18:44:52,162 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3808 | Iter Mean Loss 4.0408
2020-11-05 18:44:52,172 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5503 | Iter Mean Loss 3.7427
2020-11-05 18:44:52,174 - root - INFO - Evaluate: Epoch 0805 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:44:52,185 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2673 | Iter Mean Loss 5.2673
2020-11-05 18:44:52,194 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3932 | Iter Mean Loss 3.3303
2020-11-05 18:44:52,203 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1109 | Iter Mean Loss 3.9238
2020-11-05 18:44:52,211 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3753 | Iter Mean Loss 4.0367
2020-11-05 18:44:52,221 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5465 | Iter Mean Loss 3.7387
2020-11-05 18:44:52,224 - root - INFO - Evaluate: Epoch 0806 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:44:52,233 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2642 | Iter Mean Loss 5.2642
2020-11-05 18:44:52,243 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3917 | Iter Mean Loss 3.3279
2020-11-05 18:44:52,253 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1047 | Iter Mean Loss 3.9202
2020-11-05 18:44:52,261 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3698 | Iter Mean Loss 4.0326
2020-11-05 18:44:52,270 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5428 | Iter Mean Loss 3.7346
2020-11-05 18:44:52,273 - root - INFO - Evaluate: Epoch 0807 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:44:52,281 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2612 | Iter Mean Loss 5.2612
2020-11-05 18:44:52,291 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3901 | Iter Mean Loss 3.3256
2020-11-05 18:44:52,299 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0985 | Iter Mean Loss 3.9166
2020-11-05 18:44:52,308 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3644 | Iter Mean Loss 4.0285
2020-11-05 18:44:52,319 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5390 | Iter Mean Loss 3.7306
2020-11-05 18:44:52,322 - root - INFO - Evaluate: Epoch 0808 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:44:52,331 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2581 | Iter Mean Loss 5.2581
2020-11-05 18:44:52,340 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3886 | Iter Mean Loss 3.3234
2020-11-05 18:44:52,348 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0922 | Iter Mean Loss 3.9130
2020-11-05 18:44:52,357 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 4.0245
2020-11-05 18:44:52,364 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5353 | Iter Mean Loss 3.7266
2020-11-05 18:44:52,368 - root - INFO - Evaluate: Epoch 0809 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:44:52,377 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2550 | Iter Mean Loss 5.2550
2020-11-05 18:44:52,385 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3871 | Iter Mean Loss 3.3211
2020-11-05 18:44:52,393 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0861 | Iter Mean Loss 3.9094
2020-11-05 18:44:52,402 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3535 | Iter Mean Loss 4.0204
2020-11-05 18:44:52,410 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5316 | Iter Mean Loss 3.7227
2020-11-05 18:44:52,412 - root - INFO - Evaluate: Epoch 0810 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:44:52,421 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2520 | Iter Mean Loss 5.2520
2020-11-05 18:44:52,429 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3856 | Iter Mean Loss 3.3188
2020-11-05 18:44:52,437 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0799 | Iter Mean Loss 3.9058
2020-11-05 18:44:52,445 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3481 | Iter Mean Loss 4.0164
2020-11-05 18:44:52,454 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5279 | Iter Mean Loss 3.7187
2020-11-05 18:44:52,456 - root - INFO - Evaluate: Epoch 0811 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:44:52,464 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2489 | Iter Mean Loss 5.2489
2020-11-05 18:44:52,471 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3841 | Iter Mean Loss 3.3165
2020-11-05 18:44:52,479 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0737 | Iter Mean Loss 3.9022
2020-11-05 18:44:52,486 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3427 | Iter Mean Loss 4.0123
2020-11-05 18:44:52,493 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5242 | Iter Mean Loss 3.7147
2020-11-05 18:44:52,495 - root - INFO - Evaluate: Epoch 0812 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:44:52,503 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2458 | Iter Mean Loss 5.2458
2020-11-05 18:44:52,510 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3826 | Iter Mean Loss 3.3142
2020-11-05 18:44:52,518 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0676 | Iter Mean Loss 3.8987
2020-11-05 18:44:52,525 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3373 | Iter Mean Loss 4.0083
2020-11-05 18:44:52,532 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5205 | Iter Mean Loss 3.7108
2020-11-05 18:44:52,534 - root - INFO - Evaluate: Epoch 0813 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:44:52,542 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2428 | Iter Mean Loss 5.2428
2020-11-05 18:44:52,549 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3811 | Iter Mean Loss 3.3120
2020-11-05 18:44:52,558 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0614 | Iter Mean Loss 3.8951
2020-11-05 18:44:52,565 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3319 | Iter Mean Loss 4.0043
2020-11-05 18:44:52,574 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5168 | Iter Mean Loss 3.7068
2020-11-05 18:44:52,576 - root - INFO - Evaluate: Epoch 0814 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:44:52,585 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2398 | Iter Mean Loss 5.2398
2020-11-05 18:44:52,593 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3796 | Iter Mean Loss 3.3097
2020-11-05 18:44:52,601 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0553 | Iter Mean Loss 3.8916
2020-11-05 18:44:52,609 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3265 | Iter Mean Loss 4.0003
2020-11-05 18:44:52,617 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5132 | Iter Mean Loss 3.7029
2020-11-05 18:44:52,620 - root - INFO - Evaluate: Epoch 0815 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:44:52,629 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2367 | Iter Mean Loss 5.2367
2020-11-05 18:44:52,637 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 3.3074
2020-11-05 18:44:52,646 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0492 | Iter Mean Loss 3.8880
2020-11-05 18:44:52,653 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3212 | Iter Mean Loss 3.9963
2020-11-05 18:44:52,661 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5095 | Iter Mean Loss 3.6989
2020-11-05 18:44:52,664 - root - INFO - Evaluate: Epoch 0816 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:44:52,672 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2337 | Iter Mean Loss 5.2337
2020-11-05 18:44:52,679 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3767 | Iter Mean Loss 3.3052
2020-11-05 18:44:52,686 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0431 | Iter Mean Loss 3.8845
2020-11-05 18:44:52,693 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3158 | Iter Mean Loss 3.9923
2020-11-05 18:44:52,700 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5059 | Iter Mean Loss 3.6950
2020-11-05 18:44:52,702 - root - INFO - Evaluate: Epoch 0817 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:44:52,710 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2306 | Iter Mean Loss 5.2306
2020-11-05 18:44:52,718 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3752 | Iter Mean Loss 3.3029
2020-11-05 18:44:52,725 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0370 | Iter Mean Loss 3.8809
2020-11-05 18:44:52,732 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3105 | Iter Mean Loss 3.9883
2020-11-05 18:44:52,739 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5023 | Iter Mean Loss 3.6911
2020-11-05 18:44:52,741 - root - INFO - Evaluate: Epoch 0818 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:44:52,749 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2276 | Iter Mean Loss 5.2276
2020-11-05 18:44:52,757 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3737 | Iter Mean Loss 3.3007
2020-11-05 18:44:52,765 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0309 | Iter Mean Loss 3.8774
2020-11-05 18:44:52,772 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3052 | Iter Mean Loss 3.9844
2020-11-05 18:44:52,780 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4987 | Iter Mean Loss 3.6872
2020-11-05 18:44:52,783 - root - INFO - Evaluate: Epoch 0819 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:44:52,791 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2246 | Iter Mean Loss 5.2246
2020-11-05 18:44:52,799 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3723 | Iter Mean Loss 3.2984
2020-11-05 18:44:52,807 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0248 | Iter Mean Loss 3.8739
2020-11-05 18:44:52,815 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.9804
2020-11-05 18:44:52,823 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4951 | Iter Mean Loss 3.6833
2020-11-05 18:44:52,825 - root - INFO - Evaluate: Epoch 0820 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:44:52,834 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2216 | Iter Mean Loss 5.2216
2020-11-05 18:44:52,842 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3708 | Iter Mean Loss 3.2962
2020-11-05 18:44:52,851 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0188 | Iter Mean Loss 3.8704
2020-11-05 18:44:52,858 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 3.9764
2020-11-05 18:44:52,866 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4915 | Iter Mean Loss 3.6794
2020-11-05 18:44:52,869 - root - INFO - Evaluate: Epoch 0821 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:44:52,876 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2185 | Iter Mean Loss 5.2185
2020-11-05 18:44:52,884 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3694 | Iter Mean Loss 3.2940
2020-11-05 18:44:52,891 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0128 | Iter Mean Loss 3.8669
2020-11-05 18:44:52,898 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2893 | Iter Mean Loss 3.9725
2020-11-05 18:44:52,905 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4879 | Iter Mean Loss 3.6756
2020-11-05 18:44:52,907 - root - INFO - Evaluate: Epoch 0822 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:44:52,915 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2155 | Iter Mean Loss 5.2155
2020-11-05 18:44:52,922 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3679 | Iter Mean Loss 3.2917
2020-11-05 18:44:52,929 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0067 | Iter Mean Loss 3.8634
2020-11-05 18:44:52,937 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2840 | Iter Mean Loss 3.9686
2020-11-05 18:44:52,944 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4843 | Iter Mean Loss 3.6717
2020-11-05 18:44:52,946 - root - INFO - Evaluate: Epoch 0823 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:44:52,954 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2125 | Iter Mean Loss 5.2125
2020-11-05 18:44:52,962 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3665 | Iter Mean Loss 3.2895
2020-11-05 18:44:52,970 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0007 | Iter Mean Loss 3.8599
2020-11-05 18:44:52,977 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 3.9646
2020-11-05 18:44:52,985 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4808 | Iter Mean Loss 3.6679
2020-11-05 18:44:52,987 - root - INFO - Evaluate: Epoch 0824 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:44:52,995 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2095 | Iter Mean Loss 5.2095
2020-11-05 18:44:53,004 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3651 | Iter Mean Loss 3.2873
2020-11-05 18:44:53,012 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9947 | Iter Mean Loss 3.8564
2020-11-05 18:44:53,020 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2735 | Iter Mean Loss 3.9607
2020-11-05 18:44:53,028 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4772 | Iter Mean Loss 3.6640
2020-11-05 18:44:53,030 - root - INFO - Evaluate: Epoch 0825 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:44:53,039 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2065 | Iter Mean Loss 5.2065
2020-11-05 18:44:53,047 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3636 | Iter Mean Loss 3.2851
2020-11-05 18:44:53,056 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9887 | Iter Mean Loss 3.8529
2020-11-05 18:44:53,063 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2683 | Iter Mean Loss 3.9568
2020-11-05 18:44:53,071 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4737 | Iter Mean Loss 3.6602
2020-11-05 18:44:53,073 - root - INFO - Evaluate: Epoch 0826 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:44:53,082 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2035 | Iter Mean Loss 5.2035
2020-11-05 18:44:53,090 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3622 | Iter Mean Loss 3.2828
2020-11-05 18:44:53,098 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9827 | Iter Mean Loss 3.8495
2020-11-05 18:44:53,105 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 3.9529
2020-11-05 18:44:53,112 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4701 | Iter Mean Loss 3.6563
2020-11-05 18:44:53,114 - root - INFO - Evaluate: Epoch 0827 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:44:53,122 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2005 | Iter Mean Loss 5.2005
2020-11-05 18:44:53,129 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3608 | Iter Mean Loss 3.2806
2020-11-05 18:44:53,136 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9768 | Iter Mean Loss 3.8460
2020-11-05 18:44:53,143 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2579 | Iter Mean Loss 3.9490
2020-11-05 18:44:53,151 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4666 | Iter Mean Loss 3.6525
2020-11-05 18:44:53,153 - root - INFO - Evaluate: Epoch 0828 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:44:53,160 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1975 | Iter Mean Loss 5.1975
2020-11-05 18:44:53,169 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 3.2784
2020-11-05 18:44:53,176 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9708 | Iter Mean Loss 3.8426
2020-11-05 18:44:53,184 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2527 | Iter Mean Loss 3.9451
2020-11-05 18:44:53,192 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4631 | Iter Mean Loss 3.6487
2020-11-05 18:44:53,194 - root - INFO - Evaluate: Epoch 0829 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:44:53,203 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1945 | Iter Mean Loss 5.1945
2020-11-05 18:44:53,211 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3580 | Iter Mean Loss 3.2762
2020-11-05 18:44:53,219 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9649 | Iter Mean Loss 3.8391
2020-11-05 18:44:53,227 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2475 | Iter Mean Loss 3.9412
2020-11-05 18:44:53,235 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4596 | Iter Mean Loss 3.6449
2020-11-05 18:44:53,237 - root - INFO - Evaluate: Epoch 0830 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:44:53,245 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1915 | Iter Mean Loss 5.1915
2020-11-05 18:44:53,255 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3566 | Iter Mean Loss 3.2740
2020-11-05 18:44:53,268 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 3.8357
2020-11-05 18:44:53,278 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2423 | Iter Mean Loss 3.9373
2020-11-05 18:44:53,287 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4561 | Iter Mean Loss 3.6411
2020-11-05 18:44:53,289 - root - INFO - Evaluate: Epoch 0831 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:44:53,297 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1885 | Iter Mean Loss 5.1885
2020-11-05 18:44:53,305 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3552 | Iter Mean Loss 3.2718
2020-11-05 18:44:53,312 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9530 | Iter Mean Loss 3.8322
2020-11-05 18:44:53,322 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2372 | Iter Mean Loss 3.9335
2020-11-05 18:44:53,332 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4527 | Iter Mean Loss 3.6373
2020-11-05 18:44:53,335 - root - INFO - Evaluate: Epoch 0832 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:44:53,348 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1855 | Iter Mean Loss 5.1855
2020-11-05 18:44:53,359 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3538 | Iter Mean Loss 3.2696
2020-11-05 18:44:53,369 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9471 | Iter Mean Loss 3.8288
2020-11-05 18:44:53,382 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2320 | Iter Mean Loss 3.9296
2020-11-05 18:44:53,395 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4492 | Iter Mean Loss 3.6335
2020-11-05 18:44:53,397 - root - INFO - Evaluate: Epoch 0833 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:44:53,409 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1825 | Iter Mean Loss 5.1825
2020-11-05 18:44:53,418 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3524 | Iter Mean Loss 3.2674
2020-11-05 18:44:53,431 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9412 | Iter Mean Loss 3.8254
2020-11-05 18:44:53,443 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2269 | Iter Mean Loss 3.9257
2020-11-05 18:44:53,454 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4457 | Iter Mean Loss 3.6297
2020-11-05 18:44:53,458 - root - INFO - Evaluate: Epoch 0834 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:44:53,467 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1795 | Iter Mean Loss 5.1795
2020-11-05 18:44:53,479 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3510 | Iter Mean Loss 3.2652
2020-11-05 18:44:53,488 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9353 | Iter Mean Loss 3.8219
2020-11-05 18:44:53,496 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 3.9219
2020-11-05 18:44:53,504 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4423 | Iter Mean Loss 3.6260
2020-11-05 18:44:53,509 - root - INFO - Evaluate: Epoch 0835 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:44:53,517 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1765 | Iter Mean Loss 5.1765
2020-11-05 18:44:53,527 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3496 | Iter Mean Loss 3.2631
2020-11-05 18:44:53,535 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9295 | Iter Mean Loss 3.8185
2020-11-05 18:44:53,544 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2166 | Iter Mean Loss 3.9181
2020-11-05 18:44:53,552 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4389 | Iter Mean Loss 3.6222
2020-11-05 18:44:53,556 - root - INFO - Evaluate: Epoch 0836 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:44:53,565 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1735 | Iter Mean Loss 5.1735
2020-11-05 18:44:53,576 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3482 | Iter Mean Loss 3.2609
2020-11-05 18:44:53,584 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 3.8151
2020-11-05 18:44:53,594 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2115 | Iter Mean Loss 3.9142
2020-11-05 18:44:53,602 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4354 | Iter Mean Loss 3.6185
2020-11-05 18:44:53,605 - root - INFO - Evaluate: Epoch 0837 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:44:53,615 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1706 | Iter Mean Loss 5.1706
2020-11-05 18:44:53,625 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3468 | Iter Mean Loss 3.2587
2020-11-05 18:44:53,633 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9178 | Iter Mean Loss 3.8117
2020-11-05 18:44:53,643 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2065 | Iter Mean Loss 3.9104
2020-11-05 18:44:53,651 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4320 | Iter Mean Loss 3.6147
2020-11-05 18:44:53,654 - root - INFO - Evaluate: Epoch 0838 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:44:53,663 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1676 | Iter Mean Loss 5.1676
2020-11-05 18:44:53,672 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3454 | Iter Mean Loss 3.2565
2020-11-05 18:44:53,681 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9119 | Iter Mean Loss 3.8083
2020-11-05 18:44:53,689 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2014 | Iter Mean Loss 3.9066
2020-11-05 18:44:53,698 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4286 | Iter Mean Loss 3.6110
2020-11-05 18:44:53,700 - root - INFO - Evaluate: Epoch 0839 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:44:53,709 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 5.1646
2020-11-05 18:44:53,718 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3441 | Iter Mean Loss 3.2543
2020-11-05 18:44:53,726 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9061 | Iter Mean Loss 3.8049
2020-11-05 18:44:53,734 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1963 | Iter Mean Loss 3.9028
2020-11-05 18:44:53,742 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4252 | Iter Mean Loss 3.6073
2020-11-05 18:44:53,745 - root - INFO - Evaluate: Epoch 0840 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:44:53,755 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1616 | Iter Mean Loss 5.1616
2020-11-05 18:44:53,763 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 3.2522
2020-11-05 18:44:53,772 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9003 | Iter Mean Loss 3.8015
2020-11-05 18:44:53,780 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1913 | Iter Mean Loss 3.8990
2020-11-05 18:44:53,789 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4218 | Iter Mean Loss 3.6035
2020-11-05 18:44:53,791 - root - INFO - Evaluate: Epoch 0841 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:44:53,801 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1586 | Iter Mean Loss 5.1586
2020-11-05 18:44:53,809 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 3.2500
2020-11-05 18:44:53,818 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8945 | Iter Mean Loss 3.7981
2020-11-05 18:44:53,826 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1862 | Iter Mean Loss 3.8952
2020-11-05 18:44:53,835 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4184 | Iter Mean Loss 3.5998
2020-11-05 18:44:53,838 - root - INFO - Evaluate: Epoch 0842 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:44:53,847 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1557 | Iter Mean Loss 5.1557
2020-11-05 18:44:53,857 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3400 | Iter Mean Loss 3.2478
2020-11-05 18:44:53,865 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8887 | Iter Mean Loss 3.7948
2020-11-05 18:44:53,874 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1812 | Iter Mean Loss 3.8914
2020-11-05 18:44:53,882 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4151 | Iter Mean Loss 3.5961
2020-11-05 18:44:53,885 - root - INFO - Evaluate: Epoch 0843 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:44:53,894 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1527 | Iter Mean Loss 5.1527
2020-11-05 18:44:53,903 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3386 | Iter Mean Loss 3.2456
2020-11-05 18:44:53,911 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8829 | Iter Mean Loss 3.7914
2020-11-05 18:44:53,919 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1761 | Iter Mean Loss 3.8876
2020-11-05 18:44:53,928 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4117 | Iter Mean Loss 3.5924
2020-11-05 18:44:53,931 - root - INFO - Evaluate: Epoch 0844 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:44:53,940 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1497 | Iter Mean Loss 5.1497
2020-11-05 18:44:53,948 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3372 | Iter Mean Loss 3.2435
2020-11-05 18:44:53,957 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8771 | Iter Mean Loss 3.7880
2020-11-05 18:44:53,965 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1711 | Iter Mean Loss 3.8838
2020-11-05 18:44:53,973 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4084 | Iter Mean Loss 3.5887
2020-11-05 18:44:53,975 - root - INFO - Evaluate: Epoch 0845 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:44:53,985 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1467 | Iter Mean Loss 5.1467
2020-11-05 18:44:53,993 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3359 | Iter Mean Loss 3.2413
2020-11-05 18:44:54,002 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8713 | Iter Mean Loss 3.7846
2020-11-05 18:44:54,010 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1661 | Iter Mean Loss 3.8800
2020-11-05 18:44:54,019 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4050 | Iter Mean Loss 3.5850
2020-11-05 18:44:54,022 - root - INFO - Evaluate: Epoch 0846 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:44:54,031 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1438 | Iter Mean Loss 5.1438
2020-11-05 18:44:54,040 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3345 | Iter Mean Loss 3.2391
2020-11-05 18:44:54,048 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8656 | Iter Mean Loss 3.7813
2020-11-05 18:44:54,057 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1611 | Iter Mean Loss 3.8762
2020-11-05 18:44:54,065 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4017 | Iter Mean Loss 3.5813
2020-11-05 18:44:54,069 - root - INFO - Evaluate: Epoch 0847 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:44:54,078 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1408 | Iter Mean Loss 5.1408
2020-11-05 18:44:54,087 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3332 | Iter Mean Loss 3.2370
2020-11-05 18:44:54,095 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8598 | Iter Mean Loss 3.7779
2020-11-05 18:44:54,104 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1561 | Iter Mean Loss 3.8725
2020-11-05 18:44:54,112 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3983 | Iter Mean Loss 3.5777
2020-11-05 18:44:54,114 - root - INFO - Evaluate: Epoch 0848 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:44:54,124 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1378 | Iter Mean Loss 5.1378
2020-11-05 18:44:54,131 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3318 | Iter Mean Loss 3.2348
2020-11-05 18:44:54,141 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8541 | Iter Mean Loss 3.7746
2020-11-05 18:44:54,148 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1512 | Iter Mean Loss 3.8687
2020-11-05 18:44:54,158 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3950 | Iter Mean Loss 3.5740
2020-11-05 18:44:54,161 - root - INFO - Evaluate: Epoch 0849 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:44:54,171 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1348 | Iter Mean Loss 5.1348
2020-11-05 18:44:54,180 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3305 | Iter Mean Loss 3.2327
2020-11-05 18:44:54,189 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8484 | Iter Mean Loss 3.7712
2020-11-05 18:44:54,197 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1462 | Iter Mean Loss 3.8650
2020-11-05 18:44:54,207 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3917 | Iter Mean Loss 3.5703
2020-11-05 18:44:54,209 - root - INFO - Evaluate: Epoch 0850 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:44:54,220 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1319 | Iter Mean Loss 5.1319
2020-11-05 18:44:54,228 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3292 | Iter Mean Loss 3.2305
2020-11-05 18:44:54,237 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8426 | Iter Mean Loss 3.7679
2020-11-05 18:44:54,245 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1413 | Iter Mean Loss 3.8612
2020-11-05 18:44:54,254 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3884 | Iter Mean Loss 3.5667
2020-11-05 18:44:54,257 - root - INFO - Evaluate: Epoch 0851 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:44:54,265 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1289 | Iter Mean Loss 5.1289
2020-11-05 18:44:54,274 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3278 | Iter Mean Loss 3.2284
2020-11-05 18:44:54,282 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8369 | Iter Mean Loss 3.7645
2020-11-05 18:44:54,291 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1363 | Iter Mean Loss 3.8575
2020-11-05 18:44:54,299 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3851 | Iter Mean Loss 3.5630
2020-11-05 18:44:54,303 - root - INFO - Evaluate: Epoch 0852 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:44:54,313 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1259 | Iter Mean Loss 5.1259
2020-11-05 18:44:54,322 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 3.2262
2020-11-05 18:44:54,330 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 3.7612
2020-11-05 18:44:54,339 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1314 | Iter Mean Loss 3.8538
2020-11-05 18:44:54,346 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3818 | Iter Mean Loss 3.5594
2020-11-05 18:44:54,348 - root - INFO - Evaluate: Epoch 0853 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:44:54,356 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1230 | Iter Mean Loss 5.1230
2020-11-05 18:44:54,364 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 3.2240
2020-11-05 18:44:54,371 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8255 | Iter Mean Loss 3.7579
2020-11-05 18:44:54,378 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1265 | Iter Mean Loss 3.8500
2020-11-05 18:44:54,385 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3786 | Iter Mean Loss 3.5557
2020-11-05 18:44:54,387 - root - INFO - Evaluate: Epoch 0854 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:44:54,395 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1200 | Iter Mean Loss 5.1200
2020-11-05 18:44:54,404 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3238 | Iter Mean Loss 3.2219
2020-11-05 18:44:54,412 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8199 | Iter Mean Loss 3.7546
2020-11-05 18:44:54,421 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1216 | Iter Mean Loss 3.8463
2020-11-05 18:44:54,428 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3753 | Iter Mean Loss 3.5521
2020-11-05 18:44:54,430 - root - INFO - Evaluate: Epoch 0855 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:44:54,440 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1170 | Iter Mean Loss 5.1170
2020-11-05 18:44:54,449 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3225 | Iter Mean Loss 3.2197
2020-11-05 18:44:54,458 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8142 | Iter Mean Loss 3.7512
2020-11-05 18:44:54,465 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1166 | Iter Mean Loss 3.8426
2020-11-05 18:44:54,474 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3720 | Iter Mean Loss 3.5485
2020-11-05 18:44:54,476 - root - INFO - Evaluate: Epoch 0856 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:44:54,484 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1140 | Iter Mean Loss 5.1140
2020-11-05 18:44:54,494 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3211 | Iter Mean Loss 3.2176
2020-11-05 18:44:54,502 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8085 | Iter Mean Loss 3.7479
2020-11-05 18:44:54,510 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1118 | Iter Mean Loss 3.8389
2020-11-05 18:44:54,518 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3688 | Iter Mean Loss 3.5448
2020-11-05 18:44:54,521 - root - INFO - Evaluate: Epoch 0857 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:44:54,530 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1111 | Iter Mean Loss 5.1111
2020-11-05 18:44:54,538 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3198 | Iter Mean Loss 3.2154
2020-11-05 18:44:54,545 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8029 | Iter Mean Loss 3.7446
2020-11-05 18:44:54,552 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1069 | Iter Mean Loss 3.8352
2020-11-05 18:44:54,559 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3655 | Iter Mean Loss 3.5412
2020-11-05 18:44:54,561 - root - INFO - Evaluate: Epoch 0858 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:44:54,569 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 5.1081
2020-11-05 18:44:54,577 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3185 | Iter Mean Loss 3.2133
2020-11-05 18:44:54,584 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7973 | Iter Mean Loss 3.7413
2020-11-05 18:44:54,593 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1020 | Iter Mean Loss 3.8315
2020-11-05 18:44:54,601 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3623 | Iter Mean Loss 3.5376
2020-11-05 18:44:54,604 - root - INFO - Evaluate: Epoch 0859 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:44:54,614 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1051 | Iter Mean Loss 5.1051
2020-11-05 18:44:54,623 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3172 | Iter Mean Loss 3.2111
2020-11-05 18:44:54,631 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7916 | Iter Mean Loss 3.7380
2020-11-05 18:44:54,639 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0971 | Iter Mean Loss 3.8278
2020-11-05 18:44:54,648 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3591 | Iter Mean Loss 3.5340
2020-11-05 18:44:54,650 - root - INFO - Evaluate: Epoch 0860 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:44:54,659 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1021 | Iter Mean Loss 5.1021
2020-11-05 18:44:54,667 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3158 | Iter Mean Loss 3.2090
2020-11-05 18:44:54,675 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7860 | Iter Mean Loss 3.7347
2020-11-05 18:44:54,682 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0923 | Iter Mean Loss 3.8241
2020-11-05 18:44:54,693 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3558 | Iter Mean Loss 3.5304
2020-11-05 18:44:54,695 - root - INFO - Evaluate: Epoch 0861 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:44:54,703 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0992 | Iter Mean Loss 5.0992
2020-11-05 18:44:54,712 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3145 | Iter Mean Loss 3.2068
2020-11-05 18:44:54,719 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7804 | Iter Mean Loss 3.7314
2020-11-05 18:44:54,728 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0874 | Iter Mean Loss 3.8204
2020-11-05 18:44:54,736 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3526 | Iter Mean Loss 3.5268
2020-11-05 18:44:54,738 - root - INFO - Evaluate: Epoch 0862 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:44:54,746 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0962 | Iter Mean Loss 5.0962
2020-11-05 18:44:54,753 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3132 | Iter Mean Loss 3.2047
2020-11-05 18:44:54,760 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7748 | Iter Mean Loss 3.7281
2020-11-05 18:44:54,768 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0826 | Iter Mean Loss 3.8167
2020-11-05 18:44:54,776 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3494 | Iter Mean Loss 3.5232
2020-11-05 18:44:54,779 - root - INFO - Evaluate: Epoch 0863 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:44:54,787 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0932 | Iter Mean Loss 5.0932
2020-11-05 18:44:54,794 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 3.2025
2020-11-05 18:44:54,802 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7692 | Iter Mean Loss 3.7248
2020-11-05 18:44:54,811 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0778 | Iter Mean Loss 3.8130
2020-11-05 18:44:54,819 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3462 | Iter Mean Loss 3.5197
2020-11-05 18:44:54,821 - root - INFO - Evaluate: Epoch 0864 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:44:54,829 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0902 | Iter Mean Loss 5.0902
2020-11-05 18:44:54,838 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3106 | Iter Mean Loss 3.2004
2020-11-05 18:44:54,845 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7636 | Iter Mean Loss 3.7215
2020-11-05 18:44:54,853 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0730 | Iter Mean Loss 3.8093
2020-11-05 18:44:54,862 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3430 | Iter Mean Loss 3.5161
2020-11-05 18:44:54,864 - root - INFO - Evaluate: Epoch 0865 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:44:54,874 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0872 | Iter Mean Loss 5.0872
2020-11-05 18:44:54,881 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3093 | Iter Mean Loss 3.1982
2020-11-05 18:44:54,890 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7580 | Iter Mean Loss 3.7182
2020-11-05 18:44:54,898 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0682 | Iter Mean Loss 3.8057
2020-11-05 18:44:54,907 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3398 | Iter Mean Loss 3.5125
2020-11-05 18:44:54,909 - root - INFO - Evaluate: Epoch 0866 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:44:54,917 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0843 | Iter Mean Loss 5.0843
2020-11-05 18:44:54,926 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3079 | Iter Mean Loss 3.1961
2020-11-05 18:44:54,933 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7525 | Iter Mean Loss 3.7149
2020-11-05 18:44:54,941 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0634 | Iter Mean Loss 3.8020
2020-11-05 18:44:54,950 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3366 | Iter Mean Loss 3.5089
2020-11-05 18:44:54,952 - root - INFO - Evaluate: Epoch 0867 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:44:54,960 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0813 | Iter Mean Loss 5.0813
2020-11-05 18:44:54,967 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3066 | Iter Mean Loss 3.1939
2020-11-05 18:44:54,975 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7469 | Iter Mean Loss 3.7116
2020-11-05 18:44:54,984 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0586 | Iter Mean Loss 3.7983
2020-11-05 18:44:54,991 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 3.5054
2020-11-05 18:44:54,993 - root - INFO - Evaluate: Epoch 0868 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:44:55,001 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0783 | Iter Mean Loss 5.0783
2020-11-05 18:44:55,009 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3053 | Iter Mean Loss 3.1918
2020-11-05 18:44:55,017 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 3.7083
2020-11-05 18:44:55,024 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0538 | Iter Mean Loss 3.7947
2020-11-05 18:44:55,032 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3303 | Iter Mean Loss 3.5018
2020-11-05 18:44:55,035 - root - INFO - Evaluate: Epoch 0869 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:44:55,043 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0753 | Iter Mean Loss 5.0753
2020-11-05 18:44:55,051 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3040 | Iter Mean Loss 3.1896
2020-11-05 18:44:55,059 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7358 | Iter Mean Loss 3.7050
2020-11-05 18:44:55,067 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0490 | Iter Mean Loss 3.7910
2020-11-05 18:44:55,075 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3271 | Iter Mean Loss 3.4983
2020-11-05 18:44:55,077 - root - INFO - Evaluate: Epoch 0870 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:44:55,086 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0723 | Iter Mean Loss 5.0723
2020-11-05 18:44:55,093 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3027 | Iter Mean Loss 3.1875
2020-11-05 18:44:55,100 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7303 | Iter Mean Loss 3.7018
2020-11-05 18:44:55,108 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0443 | Iter Mean Loss 3.7874
2020-11-05 18:44:55,116 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3240 | Iter Mean Loss 3.4947
2020-11-05 18:44:55,118 - root - INFO - Evaluate: Epoch 0871 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:44:55,127 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0693 | Iter Mean Loss 5.0693
2020-11-05 18:44:55,135 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3014 | Iter Mean Loss 3.1853
2020-11-05 18:44:55,142 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7248 | Iter Mean Loss 3.6985
2020-11-05 18:44:55,149 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0395 | Iter Mean Loss 3.7837
2020-11-05 18:44:55,156 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3208 | Iter Mean Loss 3.4912
2020-11-05 18:44:55,158 - root - INFO - Evaluate: Epoch 0872 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:44:55,166 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0663 | Iter Mean Loss 5.0663
2020-11-05 18:44:55,173 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3001 | Iter Mean Loss 3.1832
2020-11-05 18:44:55,180 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7193 | Iter Mean Loss 3.6952
2020-11-05 18:44:55,188 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 3.7801
2020-11-05 18:44:55,195 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3177 | Iter Mean Loss 3.4876
2020-11-05 18:44:55,197 - root - INFO - Evaluate: Epoch 0873 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:44:55,205 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0633 | Iter Mean Loss 5.0633
2020-11-05 18:44:55,212 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 3.1810
2020-11-05 18:44:55,220 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7138 | Iter Mean Loss 3.6919
2020-11-05 18:44:55,228 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0300 | Iter Mean Loss 3.7765
2020-11-05 18:44:55,235 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3146 | Iter Mean Loss 3.4841
2020-11-05 18:44:55,237 - root - INFO - Evaluate: Epoch 0874 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:44:55,246 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0603 | Iter Mean Loss 5.0603
2020-11-05 18:44:55,254 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2975 | Iter Mean Loss 3.1789
2020-11-05 18:44:55,262 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7083 | Iter Mean Loss 3.6887
2020-11-05 18:44:55,270 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0253 | Iter Mean Loss 3.7728
2020-11-05 18:44:55,278 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3114 | Iter Mean Loss 3.4806
2020-11-05 18:44:55,280 - root - INFO - Evaluate: Epoch 0875 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:44:55,288 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0573 | Iter Mean Loss 5.0573
2020-11-05 18:44:55,297 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2961 | Iter Mean Loss 3.1767
2020-11-05 18:44:55,305 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7028 | Iter Mean Loss 3.6854
2020-11-05 18:44:55,314 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0206 | Iter Mean Loss 3.7692
2020-11-05 18:44:55,323 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3083 | Iter Mean Loss 3.4770
2020-11-05 18:44:55,325 - root - INFO - Evaluate: Epoch 0876 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:44:55,334 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0543 | Iter Mean Loss 5.0543
2020-11-05 18:44:55,343 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2948 | Iter Mean Loss 3.1746
2020-11-05 18:44:55,352 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6973 | Iter Mean Loss 3.6821
2020-11-05 18:44:55,360 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0159 | Iter Mean Loss 3.7656
2020-11-05 18:44:55,369 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3052 | Iter Mean Loss 3.4735
2020-11-05 18:44:55,372 - root - INFO - Evaluate: Epoch 0877 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:44:55,381 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0513 | Iter Mean Loss 5.0513
2020-11-05 18:44:55,390 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2935 | Iter Mean Loss 3.1724
2020-11-05 18:44:55,399 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6918 | Iter Mean Loss 3.6789
2020-11-05 18:44:55,407 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0112 | Iter Mean Loss 3.7620
2020-11-05 18:44:55,415 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3021 | Iter Mean Loss 3.4700
2020-11-05 18:44:55,418 - root - INFO - Evaluate: Epoch 0878 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:44:55,427 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0483 | Iter Mean Loss 5.0483
2020-11-05 18:44:55,436 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2922 | Iter Mean Loss 3.1703
2020-11-05 18:44:55,445 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6864 | Iter Mean Loss 3.6756
2020-11-05 18:44:55,453 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0065 | Iter Mean Loss 3.7583
2020-11-05 18:44:55,463 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2990 | Iter Mean Loss 3.4665
2020-11-05 18:44:55,465 - root - INFO - Evaluate: Epoch 0879 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:44:55,474 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0453 | Iter Mean Loss 5.0453
2020-11-05 18:44:55,483 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2909 | Iter Mean Loss 3.1681
2020-11-05 18:44:55,491 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6809 | Iter Mean Loss 3.6724
2020-11-05 18:44:55,500 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0018 | Iter Mean Loss 3.7547
2020-11-05 18:44:55,508 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2959 | Iter Mean Loss 3.4630
2020-11-05 18:44:55,511 - root - INFO - Evaluate: Epoch 0880 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:44:55,521 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0423 | Iter Mean Loss 5.0423
2020-11-05 18:44:55,530 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2896 | Iter Mean Loss 3.1659
2020-11-05 18:44:55,539 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 3.6691
2020-11-05 18:44:55,547 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9971 | Iter Mean Loss 3.7511
2020-11-05 18:44:55,556 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2928 | Iter Mean Loss 3.4594
2020-11-05 18:44:55,558 - root - INFO - Evaluate: Epoch 0881 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:44:55,567 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0392 | Iter Mean Loss 5.0392
2020-11-05 18:44:55,575 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2883 | Iter Mean Loss 3.1638
2020-11-05 18:44:55,585 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6700 | Iter Mean Loss 3.6659
2020-11-05 18:44:55,593 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9924 | Iter Mean Loss 3.7475
2020-11-05 18:44:55,602 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2897 | Iter Mean Loss 3.4559
2020-11-05 18:44:55,604 - root - INFO - Evaluate: Epoch 0882 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:44:55,615 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0362 | Iter Mean Loss 5.0362
2020-11-05 18:44:55,623 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 3.1616
2020-11-05 18:44:55,632 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6646 | Iter Mean Loss 3.6626
2020-11-05 18:44:55,640 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9878 | Iter Mean Loss 3.7439
2020-11-05 18:44:55,649 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2866 | Iter Mean Loss 3.4524
2020-11-05 18:44:55,651 - root - INFO - Evaluate: Epoch 0883 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:44:55,660 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0332 | Iter Mean Loss 5.0332
2020-11-05 18:44:55,671 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2857 | Iter Mean Loss 3.1594
2020-11-05 18:44:55,682 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6592 | Iter Mean Loss 3.6593
2020-11-05 18:44:55,693 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9831 | Iter Mean Loss 3.7403
2020-11-05 18:44:55,704 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2836 | Iter Mean Loss 3.4489
2020-11-05 18:44:55,707 - root - INFO - Evaluate: Epoch 0884 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:44:55,719 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0301 | Iter Mean Loss 5.0301
2020-11-05 18:44:55,730 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2844 | Iter Mean Loss 3.1573
2020-11-05 18:44:55,741 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 3.6561
2020-11-05 18:44:55,751 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 3.7367
2020-11-05 18:44:55,761 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2805 | Iter Mean Loss 3.4455
2020-11-05 18:44:55,764 - root - INFO - Evaluate: Epoch 0885 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:44:55,776 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0271 | Iter Mean Loss 5.0271
2020-11-05 18:44:55,787 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2831 | Iter Mean Loss 3.1551
2020-11-05 18:44:55,797 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6483 | Iter Mean Loss 3.6528
2020-11-05 18:44:55,808 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9738 | Iter Mean Loss 3.7331
2020-11-05 18:44:55,819 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2774 | Iter Mean Loss 3.4420
2020-11-05 18:44:55,823 - root - INFO - Evaluate: Epoch 0886 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:44:55,836 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0241 | Iter Mean Loss 5.0241
2020-11-05 18:44:55,846 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2818 | Iter Mean Loss 3.1529
2020-11-05 18:44:55,858 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6429 | Iter Mean Loss 3.6496
2020-11-05 18:44:55,871 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 3.7295
2020-11-05 18:44:55,882 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2744 | Iter Mean Loss 3.4385
2020-11-05 18:44:55,887 - root - INFO - Evaluate: Epoch 0887 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:44:55,899 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0210 | Iter Mean Loss 5.0210
2020-11-05 18:44:55,909 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2805 | Iter Mean Loss 3.1507
2020-11-05 18:44:55,919 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6375 | Iter Mean Loss 3.6463
2020-11-05 18:44:55,927 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 3.7259
2020-11-05 18:44:55,936 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2713 | Iter Mean Loss 3.4350
2020-11-05 18:44:55,939 - root - INFO - Evaluate: Epoch 0888 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:44:55,947 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0180 | Iter Mean Loss 5.0180
2020-11-05 18:44:55,956 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2791 | Iter Mean Loss 3.1486
2020-11-05 18:44:55,964 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6322 | Iter Mean Loss 3.6431
2020-11-05 18:44:55,973 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9600 | Iter Mean Loss 3.7223
2020-11-05 18:44:55,981 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2683 | Iter Mean Loss 3.4315
2020-11-05 18:44:55,984 - root - INFO - Evaluate: Epoch 0889 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:44:55,994 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0149 | Iter Mean Loss 5.0149
2020-11-05 18:44:56,003 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2778 | Iter Mean Loss 3.1464
2020-11-05 18:44:56,011 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6268 | Iter Mean Loss 3.6398
2020-11-05 18:44:56,019 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9554 | Iter Mean Loss 3.7187
2020-11-05 18:44:56,028 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2652 | Iter Mean Loss 3.4280
2020-11-05 18:44:56,030 - root - INFO - Evaluate: Epoch 0890 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:44:56,040 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0119 | Iter Mean Loss 5.0119
2020-11-05 18:44:56,048 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2765 | Iter Mean Loss 3.1442
2020-11-05 18:44:56,057 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6214 | Iter Mean Loss 3.6366
2020-11-05 18:44:56,066 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9508 | Iter Mean Loss 3.7151
2020-11-05 18:44:56,076 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2622 | Iter Mean Loss 3.4246
2020-11-05 18:44:56,078 - root - INFO - Evaluate: Epoch 0891 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:44:56,089 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0088 | Iter Mean Loss 5.0088
2020-11-05 18:44:56,097 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2752 | Iter Mean Loss 3.1420
2020-11-05 18:44:56,107 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6160 | Iter Mean Loss 3.6334
2020-11-05 18:44:56,116 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9462 | Iter Mean Loss 3.7116
2020-11-05 18:44:56,125 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2592 | Iter Mean Loss 3.4211
2020-11-05 18:44:56,127 - root - INFO - Evaluate: Epoch 0892 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:44:56,138 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0057 | Iter Mean Loss 5.0057
2020-11-05 18:44:56,146 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2739 | Iter Mean Loss 3.1398
2020-11-05 18:44:56,156 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6107 | Iter Mean Loss 3.6301
2020-11-05 18:44:56,163 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 3.7080
2020-11-05 18:44:56,173 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2561 | Iter Mean Loss 3.4176
2020-11-05 18:44:56,175 - root - INFO - Evaluate: Epoch 0893 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:44:56,184 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0027 | Iter Mean Loss 5.0027
2020-11-05 18:44:56,193 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2726 | Iter Mean Loss 3.1376
2020-11-05 18:44:56,202 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6053 | Iter Mean Loss 3.6269
2020-11-05 18:44:56,211 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 3.7044
2020-11-05 18:44:56,219 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2531 | Iter Mean Loss 3.4141
2020-11-05 18:44:56,222 - root - INFO - Evaluate: Epoch 0894 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:44:56,230 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9996 | Iter Mean Loss 4.9996
2020-11-05 18:44:56,239 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2713 | Iter Mean Loss 3.1354
2020-11-05 18:44:56,248 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6000 | Iter Mean Loss 3.6236
2020-11-05 18:44:56,256 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9324 | Iter Mean Loss 3.7008
2020-11-05 18:44:56,264 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2501 | Iter Mean Loss 3.4107
2020-11-05 18:44:56,267 - root - INFO - Evaluate: Epoch 0895 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:44:56,277 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9965 | Iter Mean Loss 4.9965
2020-11-05 18:44:56,285 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2700 | Iter Mean Loss 3.1332
2020-11-05 18:44:56,294 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5947 | Iter Mean Loss 3.6204
2020-11-05 18:44:56,302 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9279 | Iter Mean Loss 3.6972
2020-11-05 18:44:56,312 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2471 | Iter Mean Loss 3.4072
2020-11-05 18:44:56,316 - root - INFO - Evaluate: Epoch 0896 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:44:56,330 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9934 | Iter Mean Loss 4.9934
2020-11-05 18:44:56,339 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2686 | Iter Mean Loss 3.1310
2020-11-05 18:44:56,348 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5893 | Iter Mean Loss 3.6171
2020-11-05 18:44:56,358 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9233 | Iter Mean Loss 3.6937
2020-11-05 18:44:56,366 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2441 | Iter Mean Loss 3.4038
2020-11-05 18:44:56,369 - root - INFO - Evaluate: Epoch 0897 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:44:56,379 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9903 | Iter Mean Loss 4.9903
2020-11-05 18:44:56,388 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2673 | Iter Mean Loss 3.1288
2020-11-05 18:44:56,397 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5840 | Iter Mean Loss 3.6139
2020-11-05 18:44:56,406 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9188 | Iter Mean Loss 3.6901
2020-11-05 18:44:56,417 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2411 | Iter Mean Loss 3.4003
2020-11-05 18:44:56,422 - root - INFO - Evaluate: Epoch 0898 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:44:56,433 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9872 | Iter Mean Loss 4.9872
2020-11-05 18:44:56,442 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 3.1266
2020-11-05 18:44:56,450 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5787 | Iter Mean Loss 3.6106
2020-11-05 18:44:56,463 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9142 | Iter Mean Loss 3.6865
2020-11-05 18:44:56,472 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2381 | Iter Mean Loss 3.3968
2020-11-05 18:44:56,477 - root - INFO - Evaluate: Epoch 0899 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:44:56,488 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9841 | Iter Mean Loss 4.9841
2020-11-05 18:44:56,499 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2647 | Iter Mean Loss 3.1244
2020-11-05 18:44:56,510 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5734 | Iter Mean Loss 3.6074
2020-11-05 18:44:56,522 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9097 | Iter Mean Loss 3.6830
2020-11-05 18:44:56,532 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2351 | Iter Mean Loss 3.3934
2020-11-05 18:44:56,535 - root - INFO - Evaluate: Epoch 0900 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:44:56,548 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9810 | Iter Mean Loss 4.9810
2020-11-05 18:44:56,560 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2634 | Iter Mean Loss 3.1222
2020-11-05 18:44:56,573 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5681 | Iter Mean Loss 3.6041
2020-11-05 18:44:56,584 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9052 | Iter Mean Loss 3.6794
2020-11-05 18:44:56,597 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2321 | Iter Mean Loss 3.3899
2020-11-05 18:44:56,600 - root - INFO - Evaluate: Epoch 0901 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:44:56,610 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9778 | Iter Mean Loss 4.9778
2020-11-05 18:44:56,622 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2620 | Iter Mean Loss 3.1199
2020-11-05 18:44:56,632 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5628 | Iter Mean Loss 3.6009
2020-11-05 18:44:56,641 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9007 | Iter Mean Loss 3.6758
2020-11-05 18:44:56,650 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2291 | Iter Mean Loss 3.3865
2020-11-05 18:44:56,653 - root - INFO - Evaluate: Epoch 0902 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:44:56,664 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9747 | Iter Mean Loss 4.9747
2020-11-05 18:44:56,673 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2607 | Iter Mean Loss 3.1177
2020-11-05 18:44:56,682 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5575 | Iter Mean Loss 3.5976
2020-11-05 18:44:56,691 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8961 | Iter Mean Loss 3.6723
2020-11-05 18:44:56,699 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 3.3830
2020-11-05 18:44:56,702 - root - INFO - Evaluate: Epoch 0903 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:44:56,712 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9716 | Iter Mean Loss 4.9716
2020-11-05 18:44:56,723 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2594 | Iter Mean Loss 3.1155
2020-11-05 18:44:56,732 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5522 | Iter Mean Loss 3.5944
2020-11-05 18:44:56,741 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8916 | Iter Mean Loss 3.6687
2020-11-05 18:44:56,750 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2231 | Iter Mean Loss 3.3796
2020-11-05 18:44:56,753 - root - INFO - Evaluate: Epoch 0904 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:44:56,762 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9684 | Iter Mean Loss 4.9684
2020-11-05 18:44:56,771 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2581 | Iter Mean Loss 3.1132
2020-11-05 18:44:56,779 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5469 | Iter Mean Loss 3.5911
2020-11-05 18:44:56,787 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8871 | Iter Mean Loss 3.6651
2020-11-05 18:44:56,795 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2202 | Iter Mean Loss 3.3761
2020-11-05 18:44:56,797 - root - INFO - Evaluate: Epoch 0905 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:44:56,805 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9653 | Iter Mean Loss 4.9653
2020-11-05 18:44:56,812 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2567 | Iter Mean Loss 3.1110
2020-11-05 18:44:56,819 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5417 | Iter Mean Loss 3.5879
2020-11-05 18:44:56,827 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8826 | Iter Mean Loss 3.6616
2020-11-05 18:44:56,834 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2172 | Iter Mean Loss 3.3727
2020-11-05 18:44:56,836 - root - INFO - Evaluate: Epoch 0906 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:44:56,844 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9621 | Iter Mean Loss 4.9621
2020-11-05 18:44:56,851 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2554 | Iter Mean Loss 3.1088
2020-11-05 18:44:56,858 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5364 | Iter Mean Loss 3.5846
2020-11-05 18:44:56,867 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8782 | Iter Mean Loss 3.6580
2020-11-05 18:44:56,874 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2142 | Iter Mean Loss 3.3693
2020-11-05 18:44:56,876 - root - INFO - Evaluate: Epoch 0907 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:44:56,885 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 4.9590
2020-11-05 18:44:56,893 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2541 | Iter Mean Loss 3.1065
2020-11-05 18:44:56,902 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5311 | Iter Mean Loss 3.5814
2020-11-05 18:44:56,909 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 3.6545
2020-11-05 18:44:56,917 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2113 | Iter Mean Loss 3.3658
2020-11-05 18:44:56,920 - root - INFO - Evaluate: Epoch 0908 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:44:56,928 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9558 | Iter Mean Loss 4.9558
2020-11-05 18:44:56,936 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2527 | Iter Mean Loss 3.1043
2020-11-05 18:44:56,943 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5259 | Iter Mean Loss 3.5781
2020-11-05 18:44:56,951 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8692 | Iter Mean Loss 3.6509
2020-11-05 18:44:56,959 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2083 | Iter Mean Loss 3.3624
2020-11-05 18:44:56,961 - root - INFO - Evaluate: Epoch 0909 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:44:56,969 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9526 | Iter Mean Loss 4.9526
2020-11-05 18:44:56,977 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2514 | Iter Mean Loss 3.1020
2020-11-05 18:44:56,985 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5207 | Iter Mean Loss 3.5749
2020-11-05 18:44:56,992 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8647 | Iter Mean Loss 3.6473
2020-11-05 18:44:56,999 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2054 | Iter Mean Loss 3.3589
2020-11-05 18:44:57,001 - root - INFO - Evaluate: Epoch 0910 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:44:57,009 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9494 | Iter Mean Loss 4.9494
2020-11-05 18:44:57,017 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2500 | Iter Mean Loss 3.0997
2020-11-05 18:44:57,024 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5154 | Iter Mean Loss 3.5716
2020-11-05 18:44:57,031 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8603 | Iter Mean Loss 3.6438
2020-11-05 18:44:57,038 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2024 | Iter Mean Loss 3.3555
2020-11-05 18:44:57,040 - root - INFO - Evaluate: Epoch 0911 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:44:57,048 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9462 | Iter Mean Loss 4.9462
2020-11-05 18:44:57,056 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2487 | Iter Mean Loss 3.0975
2020-11-05 18:44:57,063 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 3.5684
2020-11-05 18:44:57,071 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8558 | Iter Mean Loss 3.6402
2020-11-05 18:44:57,079 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1995 | Iter Mean Loss 3.3521
2020-11-05 18:44:57,081 - root - INFO - Evaluate: Epoch 0912 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:44:57,090 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9430 | Iter Mean Loss 4.9430
2020-11-05 18:44:57,098 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2473 | Iter Mean Loss 3.0952
2020-11-05 18:44:57,106 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 3.5651
2020-11-05 18:44:57,114 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8514 | Iter Mean Loss 3.6367
2020-11-05 18:44:57,122 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1965 | Iter Mean Loss 3.3486
2020-11-05 18:44:57,124 - root - INFO - Evaluate: Epoch 0913 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:44:57,132 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9398 | Iter Mean Loss 4.9398
2020-11-05 18:44:57,141 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2460 | Iter Mean Loss 3.0929
2020-11-05 18:44:57,148 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4997 | Iter Mean Loss 3.5618
2020-11-05 18:44:57,156 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8469 | Iter Mean Loss 3.6331
2020-11-05 18:44:57,164 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1936 | Iter Mean Loss 3.3452
2020-11-05 18:44:57,166 - root - INFO - Evaluate: Epoch 0914 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:44:57,175 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9366 | Iter Mean Loss 4.9366
2020-11-05 18:44:57,183 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2446 | Iter Mean Loss 3.0906
2020-11-05 18:44:57,190 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4945 | Iter Mean Loss 3.5586
2020-11-05 18:44:57,197 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8425 | Iter Mean Loss 3.6296
2020-11-05 18:44:57,205 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 3.3418
2020-11-05 18:44:57,207 - root - INFO - Evaluate: Epoch 0915 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:44:57,215 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9334 | Iter Mean Loss 4.9334
2020-11-05 18:44:57,223 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2433 | Iter Mean Loss 3.0883
2020-11-05 18:44:57,232 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4893 | Iter Mean Loss 3.5553
2020-11-05 18:44:57,239 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8380 | Iter Mean Loss 3.6260
2020-11-05 18:44:57,247 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1877 | Iter Mean Loss 3.3383
2020-11-05 18:44:57,249 - root - INFO - Evaluate: Epoch 0916 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:44:57,256 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9301 | Iter Mean Loss 4.9301
2020-11-05 18:44:57,264 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2419 | Iter Mean Loss 3.0860
2020-11-05 18:44:57,271 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4841 | Iter Mean Loss 3.5520
2020-11-05 18:44:57,279 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8336 | Iter Mean Loss 3.6224
2020-11-05 18:44:57,287 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1848 | Iter Mean Loss 3.3349
2020-11-05 18:44:57,289 - root - INFO - Evaluate: Epoch 0917 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:44:57,297 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9269 | Iter Mean Loss 4.9269
2020-11-05 18:44:57,306 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2406 | Iter Mean Loss 3.0837
2020-11-05 18:44:57,316 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4789 | Iter Mean Loss 3.5488
2020-11-05 18:44:57,327 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8292 | Iter Mean Loss 3.6189
2020-11-05 18:44:57,336 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1818 | Iter Mean Loss 3.3315
2020-11-05 18:44:57,339 - root - INFO - Evaluate: Epoch 0918 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:44:57,347 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 4.9236
2020-11-05 18:44:57,356 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2392 | Iter Mean Loss 3.0814
2020-11-05 18:44:57,364 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4737 | Iter Mean Loss 3.5455
2020-11-05 18:44:57,373 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8248 | Iter Mean Loss 3.6153
2020-11-05 18:44:57,382 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1789 | Iter Mean Loss 3.3280
2020-11-05 18:44:57,385 - root - INFO - Evaluate: Epoch 0919 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:44:57,394 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9203 | Iter Mean Loss 4.9203
2020-11-05 18:44:57,403 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2378 | Iter Mean Loss 3.0791
2020-11-05 18:44:57,411 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4685 | Iter Mean Loss 3.5422
2020-11-05 18:44:57,420 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8204 | Iter Mean Loss 3.6118
2020-11-05 18:44:57,428 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1760 | Iter Mean Loss 3.3246
2020-11-05 18:44:57,430 - root - INFO - Evaluate: Epoch 0920 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:44:57,440 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9171 | Iter Mean Loss 4.9171
2020-11-05 18:44:57,448 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2364 | Iter Mean Loss 3.0767
2020-11-05 18:44:57,456 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4633 | Iter Mean Loss 3.5389
2020-11-05 18:44:57,464 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8160 | Iter Mean Loss 3.6082
2020-11-05 18:44:57,474 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1730 | Iter Mean Loss 3.3212
2020-11-05 18:44:57,476 - root - INFO - Evaluate: Epoch 0921 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:44:57,487 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9138 | Iter Mean Loss 4.9138
2020-11-05 18:44:57,495 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2351 | Iter Mean Loss 3.0744
2020-11-05 18:44:57,504 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4582 | Iter Mean Loss 3.5357
2020-11-05 18:44:57,512 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8116 | Iter Mean Loss 3.6046
2020-11-05 18:44:57,521 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1701 | Iter Mean Loss 3.3177
2020-11-05 18:44:57,524 - root - INFO - Evaluate: Epoch 0922 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:44:57,533 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9105 | Iter Mean Loss 4.9105
2020-11-05 18:44:57,543 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2337 | Iter Mean Loss 3.0721
2020-11-05 18:44:57,552 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4530 | Iter Mean Loss 3.5324
2020-11-05 18:44:57,560 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8072 | Iter Mean Loss 3.6011
2020-11-05 18:44:57,570 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1672 | Iter Mean Loss 3.3143
2020-11-05 18:44:57,573 - root - INFO - Evaluate: Epoch 0923 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:44:57,582 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9072 | Iter Mean Loss 4.9072
2020-11-05 18:44:57,592 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2323 | Iter Mean Loss 3.0697
2020-11-05 18:44:57,599 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 3.5291
2020-11-05 18:44:57,609 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8028 | Iter Mean Loss 3.5975
2020-11-05 18:44:57,617 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1643 | Iter Mean Loss 3.3109
2020-11-05 18:44:57,621 - root - INFO - Evaluate: Epoch 0924 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:44:57,630 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9038 | Iter Mean Loss 4.9038
2020-11-05 18:44:57,640 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2309 | Iter Mean Loss 3.0674
2020-11-05 18:44:57,648 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4427 | Iter Mean Loss 3.5258
2020-11-05 18:44:57,657 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7984 | Iter Mean Loss 3.5940
2020-11-05 18:44:57,665 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1614 | Iter Mean Loss 3.3074
2020-11-05 18:44:57,668 - root - INFO - Evaluate: Epoch 0925 | NDCG 0.2817 | MSE 0.3260
2020-11-05 18:44:57,678 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9005 | Iter Mean Loss 4.9005
2020-11-05 18:44:57,688 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2295 | Iter Mean Loss 3.0650
2020-11-05 18:44:57,697 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4375 | Iter Mean Loss 3.5225
2020-11-05 18:44:57,706 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7940 | Iter Mean Loss 3.5904
2020-11-05 18:44:57,714 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1585 | Iter Mean Loss 3.3040
2020-11-05 18:44:57,717 - root - INFO - Evaluate: Epoch 0926 | NDCG 0.2817 | MSE 0.3260
2020-11-05 18:44:57,727 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8972 | Iter Mean Loss 4.8972
2020-11-05 18:44:57,736 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2281 | Iter Mean Loss 3.0626
2020-11-05 18:44:57,746 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4324 | Iter Mean Loss 3.5192
2020-11-05 18:44:57,755 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7896 | Iter Mean Loss 3.5868
2020-11-05 18:44:57,764 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1556 | Iter Mean Loss 3.3006
2020-11-05 18:44:57,766 - root - INFO - Evaluate: Epoch 0927 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:44:57,777 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8938 | Iter Mean Loss 4.8938
2020-11-05 18:44:57,785 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2267 | Iter Mean Loss 3.0603
2020-11-05 18:44:57,794 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4272 | Iter Mean Loss 3.5159
2020-11-05 18:44:57,802 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7853 | Iter Mean Loss 3.5833
2020-11-05 18:44:57,811 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1526 | Iter Mean Loss 3.2971
2020-11-05 18:44:57,813 - root - INFO - Evaluate: Epoch 0928 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:44:57,823 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8904 | Iter Mean Loss 4.8904
2020-11-05 18:44:57,831 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2253 | Iter Mean Loss 3.0579
2020-11-05 18:44:57,840 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4221 | Iter Mean Loss 3.5126
2020-11-05 18:44:57,848 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7809 | Iter Mean Loss 3.5797
2020-11-05 18:44:57,858 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1497 | Iter Mean Loss 3.2937
2020-11-05 18:44:57,860 - root - INFO - Evaluate: Epoch 0929 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:44:57,870 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8871 | Iter Mean Loss 4.8871
2020-11-05 18:44:57,879 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2239 | Iter Mean Loss 3.0555
2020-11-05 18:44:57,890 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4169 | Iter Mean Loss 3.5093
2020-11-05 18:44:57,898 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7765 | Iter Mean Loss 3.5761
2020-11-05 18:44:57,908 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1468 | Iter Mean Loss 3.2903
2020-11-05 18:44:57,910 - root - INFO - Evaluate: Epoch 0930 | NDCG 0.2817 | MSE 0.3262
2020-11-05 18:44:57,921 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8837 | Iter Mean Loss 4.8837
2020-11-05 18:44:57,929 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2225 | Iter Mean Loss 3.0531
2020-11-05 18:44:57,939 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4118 | Iter Mean Loss 3.5060
2020-11-05 18:44:57,947 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 3.5725
2020-11-05 18:44:57,956 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1439 | Iter Mean Loss 3.2868
2020-11-05 18:44:57,959 - root - INFO - Evaluate: Epoch 0931 | NDCG 0.2817 | MSE 0.3262
2020-11-05 18:44:57,968 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8803 | Iter Mean Loss 4.8803
2020-11-05 18:44:57,977 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2211 | Iter Mean Loss 3.0507
2020-11-05 18:44:57,985 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4067 | Iter Mean Loss 3.5027
2020-11-05 18:44:57,995 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7678 | Iter Mean Loss 3.5690
2020-11-05 18:44:58,002 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1410 | Iter Mean Loss 3.2834
2020-11-05 18:44:58,004 - root - INFO - Evaluate: Epoch 0932 | NDCG 0.2817 | MSE 0.3263
2020-11-05 18:44:58,014 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8768 | Iter Mean Loss 4.8768
2020-11-05 18:44:58,022 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2197 | Iter Mean Loss 3.0483
2020-11-05 18:44:58,031 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4016 | Iter Mean Loss 3.4994
2020-11-05 18:44:58,040 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7635 | Iter Mean Loss 3.5654
2020-11-05 18:44:58,049 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1381 | Iter Mean Loss 3.2799
2020-11-05 18:44:58,051 - root - INFO - Evaluate: Epoch 0933 | NDCG 0.2817 | MSE 0.3263
2020-11-05 18:44:58,061 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8734 | Iter Mean Loss 4.8734
2020-11-05 18:44:58,070 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 3.0458
2020-11-05 18:44:58,079 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3964 | Iter Mean Loss 3.4960
2020-11-05 18:44:58,087 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7591 | Iter Mean Loss 3.5618
2020-11-05 18:44:58,096 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1352 | Iter Mean Loss 3.2765
2020-11-05 18:44:58,099 - root - INFO - Evaluate: Epoch 0934 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:44:58,108 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8700 | Iter Mean Loss 4.8700
2020-11-05 18:44:58,117 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2168 | Iter Mean Loss 3.0434
2020-11-05 18:44:58,125 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 3.4927
2020-11-05 18:44:58,134 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7548 | Iter Mean Loss 3.5582
2020-11-05 18:44:58,143 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1323 | Iter Mean Loss 3.2731
2020-11-05 18:44:58,145 - root - INFO - Evaluate: Epoch 0935 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:44:58,155 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8665 | Iter Mean Loss 4.8665
2020-11-05 18:44:58,164 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2154 | Iter Mean Loss 3.0410
2020-11-05 18:44:58,173 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3862 | Iter Mean Loss 3.4894
2020-11-05 18:44:58,182 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7505 | Iter Mean Loss 3.5546
2020-11-05 18:44:58,191 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1294 | Iter Mean Loss 3.2696
2020-11-05 18:44:58,193 - root - INFO - Evaluate: Epoch 0936 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:44:58,202 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8631 | Iter Mean Loss 4.8631
2020-11-05 18:44:58,210 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2140 | Iter Mean Loss 3.0385
2020-11-05 18:44:58,220 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3811 | Iter Mean Loss 3.4860
2020-11-05 18:44:58,228 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7461 | Iter Mean Loss 3.5511
2020-11-05 18:44:58,237 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1265 | Iter Mean Loss 3.2662
2020-11-05 18:44:58,239 - root - INFO - Evaluate: Epoch 0937 | NDCG 0.2817 | MSE 0.3265
2020-11-05 18:44:58,249 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8596 | Iter Mean Loss 4.8596
2020-11-05 18:44:58,257 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2125 | Iter Mean Loss 3.0360
2020-11-05 18:44:58,266 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3760 | Iter Mean Loss 3.4827
2020-11-05 18:44:58,274 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7418 | Iter Mean Loss 3.5475
2020-11-05 18:44:58,282 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1237 | Iter Mean Loss 3.2627
2020-11-05 18:44:58,285 - root - INFO - Evaluate: Epoch 0938 | NDCG 0.2817 | MSE 0.3265
2020-11-05 18:44:58,294 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8561 | Iter Mean Loss 4.8561
2020-11-05 18:44:58,304 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2111 | Iter Mean Loss 3.0336
2020-11-05 18:44:58,313 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3709 | Iter Mean Loss 3.4793
2020-11-05 18:44:58,324 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7375 | Iter Mean Loss 3.5439
2020-11-05 18:44:58,333 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1208 | Iter Mean Loss 3.2593
2020-11-05 18:44:58,336 - root - INFO - Evaluate: Epoch 0939 | NDCG 0.2817 | MSE 0.3266
2020-11-05 18:44:58,344 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8526 | Iter Mean Loss 4.8526
2020-11-05 18:44:58,352 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2096 | Iter Mean Loss 3.0311
2020-11-05 18:44:58,360 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3658 | Iter Mean Loss 3.4760
2020-11-05 18:44:58,368 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7332 | Iter Mean Loss 3.5403
2020-11-05 18:44:58,375 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1179 | Iter Mean Loss 3.2558
2020-11-05 18:44:58,377 - root - INFO - Evaluate: Epoch 0940 | NDCG 0.2817 | MSE 0.3266
2020-11-05 18:44:58,387 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8490 | Iter Mean Loss 4.8490
2020-11-05 18:44:58,394 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 3.0286
2020-11-05 18:44:58,403 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3607 | Iter Mean Loss 3.4726
2020-11-05 18:44:58,410 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7288 | Iter Mean Loss 3.5367
2020-11-05 18:44:58,417 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1150 | Iter Mean Loss 3.2523
2020-11-05 18:44:58,419 - root - INFO - Evaluate: Epoch 0941 | NDCG 0.2817 | MSE 0.3267
2020-11-05 18:44:58,427 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8455 | Iter Mean Loss 4.8455
2020-11-05 18:44:58,434 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2067 | Iter Mean Loss 3.0261
2020-11-05 18:44:58,442 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3556 | Iter Mean Loss 3.4693
2020-11-05 18:44:58,449 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7245 | Iter Mean Loss 3.5331
2020-11-05 18:44:58,456 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1121 | Iter Mean Loss 3.2489
2020-11-05 18:44:58,458 - root - INFO - Evaluate: Epoch 0942 | NDCG 0.2817 | MSE 0.3267
2020-11-05 18:44:58,466 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8420 | Iter Mean Loss 4.8420
2020-11-05 18:44:58,473 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2052 | Iter Mean Loss 3.0236
2020-11-05 18:44:58,481 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3505 | Iter Mean Loss 3.4659
2020-11-05 18:44:58,488 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7202 | Iter Mean Loss 3.5295
2020-11-05 18:44:58,496 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1092 | Iter Mean Loss 3.2454
2020-11-05 18:44:58,498 - root - INFO - Evaluate: Epoch 0943 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:44:58,506 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8384 | Iter Mean Loss 4.8384
2020-11-05 18:44:58,515 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2038 | Iter Mean Loss 3.0211
2020-11-05 18:44:58,522 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3455 | Iter Mean Loss 3.4625
2020-11-05 18:44:58,530 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7159 | Iter Mean Loss 3.5259
2020-11-05 18:44:58,538 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1063 | Iter Mean Loss 3.2420
2020-11-05 18:44:58,540 - root - INFO - Evaluate: Epoch 0944 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:44:58,549 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8348 | Iter Mean Loss 4.8348
2020-11-05 18:44:58,556 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2023 | Iter Mean Loss 3.0185
2020-11-05 18:44:58,564 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3404 | Iter Mean Loss 3.4592
2020-11-05 18:44:58,572 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7116 | Iter Mean Loss 3.5223
2020-11-05 18:44:58,580 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1034 | Iter Mean Loss 3.2385
2020-11-05 18:44:58,583 - root - INFO - Evaluate: Epoch 0945 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:44:58,591 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 4.8312
2020-11-05 18:44:58,599 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2008 | Iter Mean Loss 3.0160
2020-11-05 18:44:58,607 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3353 | Iter Mean Loss 3.4558
2020-11-05 18:44:58,614 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7073 | Iter Mean Loss 3.5187
2020-11-05 18:44:58,622 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1005 | Iter Mean Loss 3.2350
2020-11-05 18:44:58,624 - root - INFO - Evaluate: Epoch 0946 | NDCG 0.2817 | MSE 0.3269
2020-11-05 18:44:58,633 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8276 | Iter Mean Loss 4.8276
2020-11-05 18:44:58,640 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1993 | Iter Mean Loss 3.0134
2020-11-05 18:44:58,647 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3302 | Iter Mean Loss 3.4524
2020-11-05 18:44:58,654 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7030 | Iter Mean Loss 3.5150
2020-11-05 18:44:58,662 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0976 | Iter Mean Loss 3.2316
2020-11-05 18:44:58,664 - root - INFO - Evaluate: Epoch 0947 | NDCG 0.2817 | MSE 0.3269
2020-11-05 18:44:58,672 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8240 | Iter Mean Loss 4.8240
2020-11-05 18:44:58,679 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1978 | Iter Mean Loss 3.0109
2020-11-05 18:44:58,686 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3252 | Iter Mean Loss 3.4490
2020-11-05 18:44:58,694 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6987 | Iter Mean Loss 3.5114
2020-11-05 18:44:58,702 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0948 | Iter Mean Loss 3.2281
2020-11-05 18:44:58,704 - root - INFO - Evaluate: Epoch 0948 | NDCG 0.2817 | MSE 0.3270
2020-11-05 18:44:58,712 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8203 | Iter Mean Loss 4.8203
2020-11-05 18:44:58,720 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1963 | Iter Mean Loss 3.0083
2020-11-05 18:44:58,728 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 3.4456
2020-11-05 18:44:58,736 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6945 | Iter Mean Loss 3.5078
2020-11-05 18:44:58,745 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0919 | Iter Mean Loss 3.2246
2020-11-05 18:44:58,747 - root - INFO - Evaluate: Epoch 0949 | NDCG 0.2817 | MSE 0.3270
2020-11-05 18:44:58,755 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8166 | Iter Mean Loss 4.8166
2020-11-05 18:44:58,764 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1948 | Iter Mean Loss 3.0057
2020-11-05 18:44:58,772 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 3.4422
2020-11-05 18:44:58,780 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6902 | Iter Mean Loss 3.5042
2020-11-05 18:44:58,787 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0890 | Iter Mean Loss 3.2211
2020-11-05 18:44:58,791 - root - INFO - Evaluate: Epoch 0950 | NDCG 0.2817 | MSE 0.3271
2020-11-05 18:44:58,800 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8130 | Iter Mean Loss 4.8130
2020-11-05 18:44:58,808 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1933 | Iter Mean Loss 3.0031
2020-11-05 18:44:58,816 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3100 | Iter Mean Loss 3.4387
2020-11-05 18:44:58,823 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6859 | Iter Mean Loss 3.5005
2020-11-05 18:44:58,830 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0861 | Iter Mean Loss 3.2176
2020-11-05 18:44:58,832 - root - INFO - Evaluate: Epoch 0951 | NDCG 0.2817 | MSE 0.3271
2020-11-05 18:44:58,840 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8093 | Iter Mean Loss 4.8093
2020-11-05 18:44:58,847 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1918 | Iter Mean Loss 3.0005
2020-11-05 18:44:58,855 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3049 | Iter Mean Loss 3.4353
2020-11-05 18:44:58,862 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6816 | Iter Mean Loss 3.4969
2020-11-05 18:44:58,869 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0832 | Iter Mean Loss 3.2142
2020-11-05 18:44:58,871 - root - INFO - Evaluate: Epoch 0952 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:44:58,879 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8055 | Iter Mean Loss 4.8055
2020-11-05 18:44:58,887 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1902 | Iter Mean Loss 2.9979
2020-11-05 18:44:58,894 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.4319
2020-11-05 18:44:58,901 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6773 | Iter Mean Loss 3.4933
2020-11-05 18:44:58,909 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0803 | Iter Mean Loss 3.2107
2020-11-05 18:44:58,911 - root - INFO - Evaluate: Epoch 0953 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:44:58,920 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8018 | Iter Mean Loss 4.8018
2020-11-05 18:44:58,928 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1887 | Iter Mean Loss 2.9953
2020-11-05 18:44:58,936 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2948 | Iter Mean Loss 3.4285
2020-11-05 18:44:58,944 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6731 | Iter Mean Loss 3.4896
2020-11-05 18:44:58,953 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0774 | Iter Mean Loss 3.2072
2020-11-05 18:44:58,955 - root - INFO - Evaluate: Epoch 0954 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:44:58,964 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7981 | Iter Mean Loss 4.7981
2020-11-05 18:44:58,972 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1872 | Iter Mean Loss 2.9926
2020-11-05 18:44:58,980 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2898 | Iter Mean Loss 3.4250
2020-11-05 18:44:58,988 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6688 | Iter Mean Loss 3.4860
2020-11-05 18:44:58,996 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0745 | Iter Mean Loss 3.2037
2020-11-05 18:44:58,999 - root - INFO - Evaluate: Epoch 0955 | NDCG 0.2817 | MSE 0.3273
2020-11-05 18:44:59,007 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7943 | Iter Mean Loss 4.7943
2020-11-05 18:44:59,015 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1856 | Iter Mean Loss 2.9900
2020-11-05 18:44:59,023 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 3.4216
2020-11-05 18:44:59,030 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6645 | Iter Mean Loss 3.4823
2020-11-05 18:44:59,038 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0716 | Iter Mean Loss 3.2002
2020-11-05 18:44:59,040 - root - INFO - Evaluate: Epoch 0956 | NDCG 0.2817 | MSE 0.3273
2020-11-05 18:44:59,047 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7905 | Iter Mean Loss 4.7905
2020-11-05 18:44:59,055 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1841 | Iter Mean Loss 2.9873
2020-11-05 18:44:59,062 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2797 | Iter Mean Loss 3.4181
2020-11-05 18:44:59,070 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6603 | Iter Mean Loss 3.4786
2020-11-05 18:44:59,077 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0687 | Iter Mean Loss 3.1967
2020-11-05 18:44:59,079 - root - INFO - Evaluate: Epoch 0957 | NDCG 0.2817 | MSE 0.3274
2020-11-05 18:44:59,087 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7867 | Iter Mean Loss 4.7867
2020-11-05 18:44:59,095 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1825 | Iter Mean Loss 2.9846
2020-11-05 18:44:59,102 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2747 | Iter Mean Loss 3.4146
2020-11-05 18:44:59,111 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6560 | Iter Mean Loss 3.4750
2020-11-05 18:44:59,119 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0659 | Iter Mean Loss 3.1931
2020-11-05 18:44:59,121 - root - INFO - Evaluate: Epoch 0958 | NDCG 0.2817 | MSE 0.3274
2020-11-05 18:44:59,131 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7829 | Iter Mean Loss 4.7829
2020-11-05 18:44:59,139 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1809 | Iter Mean Loss 2.9819
2020-11-05 18:44:59,147 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2696 | Iter Mean Loss 3.4112
2020-11-05 18:44:59,155 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6517 | Iter Mean Loss 3.4713
2020-11-05 18:44:59,163 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0630 | Iter Mean Loss 3.1896
2020-11-05 18:44:59,165 - root - INFO - Evaluate: Epoch 0959 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:44:59,174 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7790 | Iter Mean Loss 4.7790
2020-11-05 18:44:59,183 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1794 | Iter Mean Loss 2.9792
2020-11-05 18:44:59,190 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2646 | Iter Mean Loss 3.4077
2020-11-05 18:44:59,198 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6475 | Iter Mean Loss 3.4676
2020-11-05 18:44:59,206 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0601 | Iter Mean Loss 3.1861
2020-11-05 18:44:59,208 - root - INFO - Evaluate: Epoch 0960 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:44:59,217 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7752 | Iter Mean Loss 4.7752
2020-11-05 18:44:59,225 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1778 | Iter Mean Loss 2.9765
2020-11-05 18:44:59,232 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 3.4042
2020-11-05 18:44:59,239 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 3.4639
2020-11-05 18:44:59,247 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0572 | Iter Mean Loss 3.1826
2020-11-05 18:44:59,249 - root - INFO - Evaluate: Epoch 0961 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:44:59,257 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7713 | Iter Mean Loss 4.7713
2020-11-05 18:44:59,264 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1762 | Iter Mean Loss 2.9738
2020-11-05 18:44:59,271 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2545 | Iter Mean Loss 3.4007
2020-11-05 18:44:59,279 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6390 | Iter Mean Loss 3.4603
2020-11-05 18:44:59,286 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0543 | Iter Mean Loss 3.1791
2020-11-05 18:44:59,288 - root - INFO - Evaluate: Epoch 0962 | NDCG 0.2817 | MSE 0.3276
2020-11-05 18:44:59,296 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7674 | Iter Mean Loss 4.7674
2020-11-05 18:44:59,303 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1746 | Iter Mean Loss 2.9710
2020-11-05 18:44:59,311 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2495 | Iter Mean Loss 3.3972
2020-11-05 18:44:59,321 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6347 | Iter Mean Loss 3.4566
2020-11-05 18:44:59,329 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0514 | Iter Mean Loss 3.1755
2020-11-05 18:44:59,333 - root - INFO - Evaluate: Epoch 0963 | NDCG 0.2817 | MSE 0.3276
2020-11-05 18:44:59,341 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7635 | Iter Mean Loss 4.7635
2020-11-05 18:44:59,350 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1730 | Iter Mean Loss 2.9682
2020-11-05 18:44:59,358 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2445 | Iter Mean Loss 3.3937
2020-11-05 18:44:59,366 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6305 | Iter Mean Loss 3.4529
2020-11-05 18:44:59,375 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0485 | Iter Mean Loss 3.1720
2020-11-05 18:44:59,378 - root - INFO - Evaluate: Epoch 0964 | NDCG 0.2817 | MSE 0.3277
2020-11-05 18:44:59,388 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7595 | Iter Mean Loss 4.7595
2020-11-05 18:44:59,396 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 2.9655
2020-11-05 18:44:59,405 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2395 | Iter Mean Loss 3.3901
2020-11-05 18:44:59,414 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6262 | Iter Mean Loss 3.4492
2020-11-05 18:44:59,428 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0456 | Iter Mean Loss 3.1684
2020-11-05 18:44:59,432 - root - INFO - Evaluate: Epoch 0965 | NDCG 0.2817 | MSE 0.3277
2020-11-05 18:44:59,447 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7556 | Iter Mean Loss 4.7556
2020-11-05 18:44:59,459 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1698 | Iter Mean Loss 2.9627
2020-11-05 18:44:59,470 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2344 | Iter Mean Loss 3.3866
2020-11-05 18:44:59,480 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6220 | Iter Mean Loss 3.4454
2020-11-05 18:44:59,490 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0427 | Iter Mean Loss 3.1649
2020-11-05 18:44:59,493 - root - INFO - Evaluate: Epoch 0966 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:44:59,504 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7516 | Iter Mean Loss 4.7516
2020-11-05 18:44:59,513 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1682 | Iter Mean Loss 2.9599
2020-11-05 18:44:59,523 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2294 | Iter Mean Loss 3.3831
2020-11-05 18:44:59,532 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6177 | Iter Mean Loss 3.4417
2020-11-05 18:44:59,543 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0398 | Iter Mean Loss 3.1613
2020-11-05 18:44:59,546 - root - INFO - Evaluate: Epoch 0967 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:44:59,556 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7476 | Iter Mean Loss 4.7476
2020-11-05 18:44:59,565 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1665 | Iter Mean Loss 2.9571
2020-11-05 18:44:59,576 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2244 | Iter Mean Loss 3.3795
2020-11-05 18:44:59,586 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6135 | Iter Mean Loss 3.4380
2020-11-05 18:44:59,596 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0369 | Iter Mean Loss 3.1578
2020-11-05 18:44:59,598 - root - INFO - Evaluate: Epoch 0968 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:44:59,610 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7436 | Iter Mean Loss 4.7436
2020-11-05 18:44:59,622 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1649 | Iter Mean Loss 2.9542
2020-11-05 18:44:59,630 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2194 | Iter Mean Loss 3.3760
2020-11-05 18:44:59,640 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6092 | Iter Mean Loss 3.4343
2020-11-05 18:44:59,648 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0339 | Iter Mean Loss 3.1542
2020-11-05 18:44:59,651 - root - INFO - Evaluate: Epoch 0969 | NDCG 0.2817 | MSE 0.3279
2020-11-05 18:44:59,661 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 4.7395
2020-11-05 18:44:59,670 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1633 | Iter Mean Loss 2.9514
2020-11-05 18:44:59,678 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2144 | Iter Mean Loss 3.3724
2020-11-05 18:44:59,688 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6050 | Iter Mean Loss 3.4305
2020-11-05 18:44:59,696 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0310 | Iter Mean Loss 3.1506
2020-11-05 18:44:59,698 - root - INFO - Evaluate: Epoch 0970 | NDCG 0.2817 | MSE 0.3279
2020-11-05 18:44:59,708 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7354 | Iter Mean Loss 4.7354
2020-11-05 18:44:59,716 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1616 | Iter Mean Loss 2.9485
2020-11-05 18:44:59,726 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2094 | Iter Mean Loss 3.3688
2020-11-05 18:44:59,736 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6008 | Iter Mean Loss 3.4268
2020-11-05 18:44:59,744 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0281 | Iter Mean Loss 3.1471
2020-11-05 18:44:59,746 - root - INFO - Evaluate: Epoch 0971 | NDCG 0.2817 | MSE 0.3280
2020-11-05 18:44:59,757 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7313 | Iter Mean Loss 4.7313
2020-11-05 18:44:59,765 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1600 | Iter Mean Loss 2.9457
2020-11-05 18:44:59,774 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2043 | Iter Mean Loss 3.3652
2020-11-05 18:44:59,782 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5965 | Iter Mean Loss 3.4230
2020-11-05 18:44:59,791 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0252 | Iter Mean Loss 3.1435
2020-11-05 18:44:59,793 - root - INFO - Evaluate: Epoch 0972 | NDCG 0.2817 | MSE 0.3280
2020-11-05 18:44:59,803 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7272 | Iter Mean Loss 4.7272
2020-11-05 18:44:59,812 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1583 | Iter Mean Loss 2.9428
2020-11-05 18:44:59,821 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1993 | Iter Mean Loss 3.3616
2020-11-05 18:44:59,829 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 3.4193
2020-11-05 18:44:59,838 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0223 | Iter Mean Loss 3.1399
2020-11-05 18:44:59,840 - root - INFO - Evaluate: Epoch 0973 | NDCG 0.2817 | MSE 0.3281
2020-11-05 18:44:59,849 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7231 | Iter Mean Loss 4.7231
2020-11-05 18:44:59,858 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1566 | Iter Mean Loss 2.9399
2020-11-05 18:44:59,866 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1943 | Iter Mean Loss 3.3580
2020-11-05 18:44:59,875 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5881 | Iter Mean Loss 3.4155
2020-11-05 18:44:59,883 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0194 | Iter Mean Loss 3.1363
2020-11-05 18:44:59,887 - root - INFO - Evaluate: Epoch 0974 | NDCG 0.2817 | MSE 0.3281
2020-11-05 18:44:59,895 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7189 | Iter Mean Loss 4.7189
2020-11-05 18:44:59,904 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1549 | Iter Mean Loss 2.9369
2020-11-05 18:44:59,913 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1893 | Iter Mean Loss 3.3544
2020-11-05 18:44:59,921 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5838 | Iter Mean Loss 3.4118
2020-11-05 18:44:59,930 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0164 | Iter Mean Loss 3.1327
2020-11-05 18:44:59,932 - root - INFO - Evaluate: Epoch 0975 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:44:59,942 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7148 | Iter Mean Loss 4.7148
2020-11-05 18:44:59,951 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1533 | Iter Mean Loss 2.9340
2020-11-05 18:44:59,960 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1843 | Iter Mean Loss 3.3508
2020-11-05 18:44:59,968 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5796 | Iter Mean Loss 3.4080
2020-11-05 18:44:59,978 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0135 | Iter Mean Loss 3.1291
2020-11-05 18:44:59,980 - root - INFO - Evaluate: Epoch 0976 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:44:59,990 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7106 | Iter Mean Loss 4.7106
2020-11-05 18:44:59,998 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 2.9311
2020-11-05 18:45:00,008 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1793 | Iter Mean Loss 3.3471
2020-11-05 18:45:00,016 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5754 | Iter Mean Loss 3.4042
2020-11-05 18:45:00,025 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0106 | Iter Mean Loss 3.1255
2020-11-05 18:45:00,027 - root - INFO - Evaluate: Epoch 0977 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:45:00,037 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7063 | Iter Mean Loss 4.7063
2020-11-05 18:45:00,046 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1499 | Iter Mean Loss 2.9281
2020-11-05 18:45:00,055 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1743 | Iter Mean Loss 3.3435
2020-11-05 18:45:00,063 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5711 | Iter Mean Loss 3.4004
2020-11-05 18:45:00,072 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0076 | Iter Mean Loss 3.1218
2020-11-05 18:45:00,075 - root - INFO - Evaluate: Epoch 0978 | NDCG 0.2817 | MSE 0.3283
2020-11-05 18:45:00,083 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7021 | Iter Mean Loss 4.7021
2020-11-05 18:45:00,093 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1481 | Iter Mean Loss 2.9251
2020-11-05 18:45:00,101 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1693 | Iter Mean Loss 3.3398
2020-11-05 18:45:00,110 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5669 | Iter Mean Loss 3.3966
2020-11-05 18:45:00,118 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0047 | Iter Mean Loss 3.1182
2020-11-05 18:45:00,121 - root - INFO - Evaluate: Epoch 0979 | NDCG 0.2817 | MSE 0.3283
2020-11-05 18:45:00,130 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6978 | Iter Mean Loss 4.6978
2020-11-05 18:45:00,139 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1464 | Iter Mean Loss 2.9221
2020-11-05 18:45:00,148 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1643 | Iter Mean Loss 3.3362
2020-11-05 18:45:00,158 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5627 | Iter Mean Loss 3.3928
2020-11-05 18:45:00,167 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0018 | Iter Mean Loss 3.1146
2020-11-05 18:45:00,170 - root - INFO - Evaluate: Epoch 0980 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:45:00,180 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6935 | Iter Mean Loss 4.6935
2020-11-05 18:45:00,191 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1447 | Iter Mean Loss 2.9191
2020-11-05 18:45:00,202 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1592 | Iter Mean Loss 3.3325
2020-11-05 18:45:00,213 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5584 | Iter Mean Loss 3.3890
2020-11-05 18:45:00,225 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9988 | Iter Mean Loss 3.1109
2020-11-05 18:45:00,228 - root - INFO - Evaluate: Epoch 0981 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:45:00,240 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6892 | Iter Mean Loss 4.6892
2020-11-05 18:45:00,248 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1430 | Iter Mean Loss 2.9161
2020-11-05 18:45:00,256 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1542 | Iter Mean Loss 3.3288
2020-11-05 18:45:00,264 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5542 | Iter Mean Loss 3.3851
2020-11-05 18:45:00,273 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9959 | Iter Mean Loss 3.1073
2020-11-05 18:45:00,275 - root - INFO - Evaluate: Epoch 0982 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:45:00,284 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6848 | Iter Mean Loss 4.6848
2020-11-05 18:45:00,294 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1412 | Iter Mean Loss 2.9130
2020-11-05 18:45:00,302 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1492 | Iter Mean Loss 3.3251
2020-11-05 18:45:00,311 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5500 | Iter Mean Loss 3.3813
2020-11-05 18:45:00,320 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9929 | Iter Mean Loss 3.1036
2020-11-05 18:45:00,323 - root - INFO - Evaluate: Epoch 0983 | NDCG 0.2817 | MSE 0.3285
2020-11-05 18:45:00,332 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6805 | Iter Mean Loss 4.6805
2020-11-05 18:45:00,343 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1395 | Iter Mean Loss 2.9100
2020-11-05 18:45:00,352 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1442 | Iter Mean Loss 3.3214
2020-11-05 18:45:00,360 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5458 | Iter Mean Loss 3.3775
2020-11-05 18:45:00,368 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9900 | Iter Mean Loss 3.1000
2020-11-05 18:45:00,371 - root - INFO - Evaluate: Epoch 0984 | NDCG 0.2817 | MSE 0.3285
2020-11-05 18:45:00,380 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6761 | Iter Mean Loss 4.6761
2020-11-05 18:45:00,389 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1377 | Iter Mean Loss 2.9069
2020-11-05 18:45:00,397 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1392 | Iter Mean Loss 3.3177
2020-11-05 18:45:00,405 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5415 | Iter Mean Loss 3.3736
2020-11-05 18:45:00,412 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9870 | Iter Mean Loss 3.0963
2020-11-05 18:45:00,415 - root - INFO - Evaluate: Epoch 0985 | NDCG 0.2817 | MSE 0.3286
2020-11-05 18:45:00,424 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6716 | Iter Mean Loss 4.6716
2020-11-05 18:45:00,432 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1359 | Iter Mean Loss 2.9038
2020-11-05 18:45:00,440 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1342 | Iter Mean Loss 3.3139
2020-11-05 18:45:00,448 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5373 | Iter Mean Loss 3.3698
2020-11-05 18:45:00,455 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9841 | Iter Mean Loss 3.0926
2020-11-05 18:45:00,457 - root - INFO - Evaluate: Epoch 0986 | NDCG 0.2817 | MSE 0.3286
2020-11-05 18:45:00,465 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6672 | Iter Mean Loss 4.6672
2020-11-05 18:45:00,472 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1342 | Iter Mean Loss 2.9007
2020-11-05 18:45:00,480 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1292 | Iter Mean Loss 3.3102
2020-11-05 18:45:00,487 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5331 | Iter Mean Loss 3.3659
2020-11-05 18:45:00,494 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9811 | Iter Mean Loss 3.0889
2020-11-05 18:45:00,496 - root - INFO - Evaluate: Epoch 0987 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:45:00,504 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6627 | Iter Mean Loss 4.6627
2020-11-05 18:45:00,512 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1324 | Iter Mean Loss 2.8975
2020-11-05 18:45:00,519 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1242 | Iter Mean Loss 3.3064
2020-11-05 18:45:00,526 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5289 | Iter Mean Loss 3.3620
2020-11-05 18:45:00,534 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9781 | Iter Mean Loss 3.0853
2020-11-05 18:45:00,537 - root - INFO - Evaluate: Epoch 0988 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:45:00,545 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6582 | Iter Mean Loss 4.6582
2020-11-05 18:45:00,553 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1306 | Iter Mean Loss 2.8944
2020-11-05 18:45:00,561 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1192 | Iter Mean Loss 3.3027
2020-11-05 18:45:00,569 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5246 | Iter Mean Loss 3.3582
2020-11-05 18:45:00,577 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9752 | Iter Mean Loss 3.0816
2020-11-05 18:45:00,580 - root - INFO - Evaluate: Epoch 0989 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:45:00,588 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 4.6537
2020-11-05 18:45:00,597 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1288 | Iter Mean Loss 2.8912
2020-11-05 18:45:00,605 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1142 | Iter Mean Loss 3.2989
2020-11-05 18:45:00,613 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5204 | Iter Mean Loss 3.3543
2020-11-05 18:45:00,622 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9722 | Iter Mean Loss 3.0779
2020-11-05 18:45:00,625 - root - INFO - Evaluate: Epoch 0990 | NDCG 0.2817 | MSE 0.3288
2020-11-05 18:45:00,633 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6491 | Iter Mean Loss 4.6491
2020-11-05 18:45:00,644 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1270 | Iter Mean Loss 2.8881
2020-11-05 18:45:00,651 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 3.2951
2020-11-05 18:45:00,658 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5162 | Iter Mean Loss 3.3504
2020-11-05 18:45:00,666 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9692 | Iter Mean Loss 3.0741
2020-11-05 18:45:00,668 - root - INFO - Evaluate: Epoch 0991 | NDCG 0.2817 | MSE 0.3288
2020-11-05 18:45:00,677 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6446 | Iter Mean Loss 4.6446
2020-11-05 18:45:00,686 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1252 | Iter Mean Loss 2.8849
2020-11-05 18:45:00,693 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1042 | Iter Mean Loss 3.2913
2020-11-05 18:45:00,701 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5120 | Iter Mean Loss 3.3465
2020-11-05 18:45:00,709 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9662 | Iter Mean Loss 3.0704
2020-11-05 18:45:00,712 - root - INFO - Evaluate: Epoch 0992 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:45:00,721 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6400 | Iter Mean Loss 4.6400
2020-11-05 18:45:00,728 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1234 | Iter Mean Loss 2.8817
2020-11-05 18:45:00,736 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0991 | Iter Mean Loss 3.2875
2020-11-05 18:45:00,744 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5077 | Iter Mean Loss 3.3425
2020-11-05 18:45:00,752 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9633 | Iter Mean Loss 3.0667
2020-11-05 18:45:00,754 - root - INFO - Evaluate: Epoch 0993 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:45:00,764 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6353 | Iter Mean Loss 4.6353
2020-11-05 18:45:00,772 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1215 | Iter Mean Loss 2.8784
2020-11-05 18:45:00,781 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0941 | Iter Mean Loss 3.2837
2020-11-05 18:45:00,791 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 3.3386
2020-11-05 18:45:00,802 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9603 | Iter Mean Loss 3.0629
2020-11-05 18:45:00,804 - root - INFO - Evaluate: Epoch 0994 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:45:00,816 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6307 | Iter Mean Loss 4.6307
2020-11-05 18:45:00,825 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1197 | Iter Mean Loss 2.8752
2020-11-05 18:45:00,836 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0891 | Iter Mean Loss 3.2798
2020-11-05 18:45:00,844 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4993 | Iter Mean Loss 3.3347
2020-11-05 18:45:00,853 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9573 | Iter Mean Loss 3.0592
2020-11-05 18:45:00,855 - root - INFO - Evaluate: Epoch 0995 | NDCG 0.2817 | MSE 0.3290
2020-11-05 18:45:00,863 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6260 | Iter Mean Loss 4.6260
2020-11-05 18:45:00,870 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1178 | Iter Mean Loss 2.8719
2020-11-05 18:45:00,880 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0841 | Iter Mean Loss 3.2760
2020-11-05 18:45:00,887 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4950 | Iter Mean Loss 3.3307
2020-11-05 18:45:00,895 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9543 | Iter Mean Loss 3.0555
2020-11-05 18:45:00,897 - root - INFO - Evaluate: Epoch 0996 | NDCG 0.2817 | MSE 0.3290
2020-11-05 18:45:00,905 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6213 | Iter Mean Loss 4.6213
2020-11-05 18:45:00,912 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1160 | Iter Mean Loss 2.8686
2020-11-05 18:45:00,919 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 3.2721
2020-11-05 18:45:00,928 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4908 | Iter Mean Loss 3.3268
2020-11-05 18:45:00,936 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9513 | Iter Mean Loss 3.0517
2020-11-05 18:45:00,939 - root - INFO - Evaluate: Epoch 0997 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:45:00,948 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6166 | Iter Mean Loss 4.6166
2020-11-05 18:45:00,956 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1141 | Iter Mean Loss 2.8653
2020-11-05 18:45:00,965 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0741 | Iter Mean Loss 3.2683
2020-11-05 18:45:00,973 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4866 | Iter Mean Loss 3.3228
2020-11-05 18:45:00,981 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9483 | Iter Mean Loss 3.0479
2020-11-05 18:45:00,984 - root - INFO - Evaluate: Epoch 0998 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:45:00,992 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6118 | Iter Mean Loss 4.6118
2020-11-05 18:45:01,001 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1123 | Iter Mean Loss 2.8620
2020-11-05 18:45:01,009 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0691 | Iter Mean Loss 3.2644
2020-11-05 18:45:01,018 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4824 | Iter Mean Loss 3.3189
2020-11-05 18:45:01,025 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9452 | Iter Mean Loss 3.0441
2020-11-05 18:45:01,028 - root - INFO - Evaluate: Epoch 0999 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:45:01,028 - root - INFO - [!]-----------training done.
2020-11-05 18:45:01,160 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 18:45:01,160 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,161 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,161 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,161 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,161 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,161 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 18:45:01,162 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,163 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,164 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,165 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,166 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,167 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,168 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,168 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,168 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,168 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,168 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,169 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,170 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,171 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,172 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,173 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,174 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,175 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,176 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 18:45:01,177 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,178 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,179 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,180 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,181 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,182 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,183 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,184 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 18:45:01,185 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,186 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,187 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,188 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,189 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,190 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,191 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,192 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,193 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,194 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 18:45:01,195 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,196 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,197 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,198 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,199 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,200 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,201 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,202 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,202 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,202 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,202 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,202 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 18:45:01,203 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,204 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,204 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,204 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,204 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,204 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,205 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,206 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,207 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,207 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,207 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,207 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,207 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,208 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,209 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,210 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,211 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,212 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,213 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,214 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,215 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 18:45:01,216 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,217 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 18:45:01,218 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,219 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,220 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,221 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,222 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,223 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,224 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,225 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,226 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,227 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,228 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,229 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,230 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,231 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,232 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,233 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,234 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,235 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,236 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,237 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:45:01,238 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,239 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:45:01,240 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,241 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,241 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:45:01,241 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 18:45:01,463 - root - INFO - [!]-----------start testing.
2020-11-05 18:45:01,465 - root - INFO - Real Rank:
2020-11-05 18:45:01,465 - root - INFO - [116 142]
2020-11-05 18:45:01,465 - root - INFO - Pred Rank:
2020-11-05 18:45:01,465 - root - INFO - [142  91 116 135]
2020-11-05 18:45:55,812 - root - INFO - Test Result: NDCG 0.2817 | MSE 0.3291
