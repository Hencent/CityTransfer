2020-11-05 18:53:35,598 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.730506-118.757457-31.975167-32.072533_target_area_coordinate118.730506-118.757457-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], target_enterprise='大众书局')
2020-11-05 18:53:35,598 - root - INFO - --------------parse args and init done.
2020-11-05 18:53:38,383 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 19:04:54,315 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 19:04:54,316 - root - INFO - n_source_grid: 95, n_target_grid: 152
2020-11-05 19:04:54,316 - root - INFO - [3 /10]       split grid done.
2020-11-05 19:04:55,618 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 19:04:55,622 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 19:04:55,710 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 19:04:55,839 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 19:04:55,839 - root - INFO - [8 /10]       combine features done.
2020-11-05 19:04:55,901 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 19:04:55,902 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 19:04:55,902 - root - INFO - --------------load data done.
2020-11-05 19:04:55,905 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 19:04:55,906 - root - INFO - --------------construct model and optimizer done.
2020-11-05 19:04:55,907 - root - INFO - --------------initialize metrics done.
2020-11-05 19:04:55,907 - root - INFO - [!]-----------start training.
2020-11-05 19:04:55,916 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 599.9505 | Iter Mean Loss 599.9505
2020-11-05 19:04:55,924 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 563.8873 | Iter Mean Loss 581.9189
2020-11-05 19:04:55,932 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 584.5262 | Iter Mean Loss 582.7880
2020-11-05 19:04:55,940 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 507.9936 | Iter Mean Loss 564.0894
2020-11-05 19:04:55,947 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 458.8430 | Iter Mean Loss 543.0401
2020-11-05 19:04:55,950 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.6699
2020-11-05 19:04:55,959 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 471.0423 | Iter Mean Loss 471.0423
2020-11-05 19:04:55,967 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 438.9006 | Iter Mean Loss 454.9715
2020-11-05 19:04:55,975 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 467.8340 | Iter Mean Loss 459.2590
2020-11-05 19:04:55,983 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 403.4666 | Iter Mean Loss 445.3109
2020-11-05 19:04:55,991 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 363.2046 | Iter Mean Loss 428.8896
2020-11-05 19:04:55,993 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.6592
2020-11-05 19:04:56,002 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 370.4881 | Iter Mean Loss 370.4881
2020-11-05 19:04:56,011 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 342.5330 | Iter Mean Loss 356.5105
2020-11-05 19:04:56,019 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 377.8442 | Iter Mean Loss 363.6218
2020-11-05 19:04:56,028 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 323.3188 | Iter Mean Loss 353.5460
2020-11-05 19:04:56,036 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 289.7713 | Iter Mean Loss 340.7911
2020-11-05 19:04:56,039 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.6435
2020-11-05 19:04:56,049 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 293.7136 | Iter Mean Loss 293.7136
2020-11-05 19:04:56,059 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 270.0704 | Iter Mean Loss 281.8920
2020-11-05 19:04:56,068 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 310.1771 | Iter Mean Loss 291.3204
2020-11-05 19:04:56,077 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 263.4282 | Iter Mean Loss 284.3473
2020-11-05 19:04:56,086 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 234.8489 | Iter Mean Loss 274.4476
2020-11-05 19:04:56,089 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.6286
2020-11-05 19:04:56,100 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 236.6264 | Iter Mean Loss 236.6264
2020-11-05 19:04:56,110 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 217.0520 | Iter Mean Loss 226.8392
2020-11-05 19:04:56,119 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.5522 | Iter Mean Loss 238.0769
2020-11-05 19:04:56,128 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 219.7862 | Iter Mean Loss 233.5042
2020-11-05 19:04:56,137 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 194.8294 | Iter Mean Loss 225.7692
2020-11-05 19:04:56,139 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.6161
2020-11-05 19:04:56,149 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 195.2402 | Iter Mean Loss 195.2402
2020-11-05 19:04:56,158 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 179.2348 | Iter Mean Loss 187.2375
2020-11-05 19:04:56,167 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 224.8896 | Iter Mean Loss 199.7882
2020-11-05 19:04:56,175 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 188.5862 | Iter Mean Loss 196.9877
2020-11-05 19:04:56,183 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 166.2150 | Iter Mean Loss 190.8331
2020-11-05 19:04:56,186 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6060
2020-11-05 19:04:56,194 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7128 | Iter Mean Loss 165.7128
2020-11-05 19:04:56,202 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 152.6226 | Iter Mean Loss 159.1677
2020-11-05 19:04:56,210 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 199.3787 | Iter Mean Loss 172.5714
2020-11-05 19:04:56,218 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 166.3069 | Iter Mean Loss 171.0053
2020-11-05 19:04:56,226 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 145.7488 | Iter Mean Loss 165.9540
2020-11-05 19:04:56,229 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.5978
2020-11-05 19:04:56,237 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 144.5331 | Iter Mean Loss 144.5331
2020-11-05 19:04:56,245 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 133.6582 | Iter Mean Loss 139.0957
2020-11-05 19:04:56,253 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 180.6999 | Iter Mean Loss 152.9638
2020-11-05 19:04:56,262 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 149.9379 | Iter Mean Loss 152.2073
2020-11-05 19:04:56,271 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 130.6678 | Iter Mean Loss 147.8994
2020-11-05 19:04:56,274 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5912
2020-11-05 19:04:56,284 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 128.7950 | Iter Mean Loss 128.7950
2020-11-05 19:04:56,292 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 119.4939 | Iter Mean Loss 124.1445
2020-11-05 19:04:56,302 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 166.2718 | Iter Mean Loss 138.1869
2020-11-05 19:04:56,311 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 137.1909 | Iter Mean Loss 137.9379
2020-11-05 19:04:56,322 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 118.9059 | Iter Mean Loss 134.1315
2020-11-05 19:04:56,324 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5858
2020-11-05 19:04:56,335 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 116.3777 | Iter Mean Loss 116.3777
2020-11-05 19:04:56,343 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.1299 | Iter Mean Loss 112.2538
2020-11-05 19:04:56,353 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 154.3308 | Iter Mean Loss 126.2795
2020-11-05 19:04:56,362 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 126.5405 | Iter Mean Loss 126.3447
2020-11-05 19:04:56,371 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 109.1168 | Iter Mean Loss 122.8991
2020-11-05 19:04:56,373 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.5813
2020-11-05 19:04:56,381 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 105.9358 | Iter Mean Loss 105.9358
2020-11-05 19:04:56,389 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 98.3574 | Iter Mean Loss 102.1466
2020-11-05 19:04:56,398 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 143.8448 | Iter Mean Loss 116.0460
2020-11-05 19:04:56,406 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 117.1201 | Iter Mean Loss 116.3145
2020-11-05 19:04:56,417 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 100.5567 | Iter Mean Loss 113.1630
2020-11-05 19:04:56,422 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.5768
2020-11-05 19:04:56,436 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 96.7500 | Iter Mean Loss 96.7500
2020-11-05 19:04:56,446 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 89.5796 | Iter Mean Loss 93.1648
2020-11-05 19:04:56,456 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.3275 | Iter Mean Loss 106.8857
2020-11-05 19:04:56,467 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 108.5400 | Iter Mean Loss 107.2993
2020-11-05 19:04:56,476 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 92.8969 | Iter Mean Loss 104.4188
2020-11-05 19:04:56,479 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.5719
2020-11-05 19:04:56,492 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 88.5143 | Iter Mean Loss 88.5143
2020-11-05 19:04:56,504 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 81.5814 | Iter Mean Loss 85.0478
2020-11-05 19:04:56,513 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 125.6180 | Iter Mean Loss 98.5712
2020-11-05 19:04:56,524 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.6804 | Iter Mean Loss 99.0985
2020-11-05 19:04:56,534 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 86.0280 | Iter Mean Loss 96.4844
2020-11-05 19:04:56,537 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.5662
2020-11-05 19:04:56,547 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 81.1286 | Iter Mean Loss 81.1286
2020-11-05 19:04:56,556 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 74.3207 | Iter Mean Loss 77.7246
2020-11-05 19:04:56,564 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 117.6934 | Iter Mean Loss 91.0476
2020-11-05 19:04:56,573 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.5280 | Iter Mean Loss 91.6677
2020-11-05 19:04:56,581 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 79.9200 | Iter Mean Loss 89.3181
2020-11-05 19:04:56,583 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.5598
2020-11-05 19:04:56,591 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.5577 | Iter Mean Loss 74.5577
2020-11-05 19:04:56,599 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 67.7987 | Iter Mean Loss 71.1782
2020-11-05 19:04:56,607 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 110.5582 | Iter Mean Loss 84.3049
2020-11-05 19:04:56,614 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.0850 | Iter Mean Loss 84.9999
2020-11-05 19:04:56,622 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 74.5488 | Iter Mean Loss 82.9097
2020-11-05 19:04:56,624 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.5531
2020-11-05 19:04:56,632 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.7612 | Iter Mean Loss 68.7612
2020-11-05 19:04:56,640 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 61.9997 | Iter Mean Loss 65.3805
2020-11-05 19:04:56,648 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 104.1932 | Iter Mean Loss 78.3180
2020-11-05 19:04:56,657 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.3271 | Iter Mean Loss 79.0703
2020-11-05 19:04:56,665 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 69.8635 | Iter Mean Loss 77.2289
2020-11-05 19:04:56,668 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.5464
2020-11-05 19:04:56,676 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.6676 | Iter Mean Loss 63.6676
2020-11-05 19:04:56,686 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 56.8697 | Iter Mean Loss 60.2687
2020-11-05 19:04:56,694 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 98.5402 | Iter Mean Loss 73.0259
2020-11-05 19:04:56,703 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.1936 | Iter Mean Loss 73.8178
2020-11-05 19:04:56,711 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 65.7818 | Iter Mean Loss 72.2106
2020-11-05 19:04:56,713 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.5403
2020-11-05 19:04:56,723 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.1769 | Iter Mean Loss 59.1769
2020-11-05 19:04:56,731 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 52.3209 | Iter Mean Loss 55.7489
2020-11-05 19:04:56,739 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 93.5118 | Iter Mean Loss 68.3365
2020-11-05 19:04:56,747 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 71.5985 | Iter Mean Loss 69.1520
2020-11-05 19:04:56,755 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 62.2030 | Iter Mean Loss 67.7622
2020-11-05 19:04:56,758 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.5349
2020-11-05 19:04:56,767 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.1791 | Iter Mean Loss 55.1791
2020-11-05 19:04:56,777 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 48.2524 | Iter Mean Loss 51.7158
2020-11-05 19:04:56,785 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 89.0110 | Iter Mean Loss 64.1475
2020-11-05 19:04:56,794 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 67.4521 | Iter Mean Loss 64.9737
2020-11-05 19:04:56,802 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 59.0294 | Iter Mean Loss 63.7848
2020-11-05 19:04:56,804 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.5301
2020-11-05 19:04:56,812 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.5756 | Iter Mean Loss 51.5756
2020-11-05 19:04:56,820 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.5715 | Iter Mean Loss 48.0735
2020-11-05 19:04:56,829 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 84.9521 | Iter Mean Loss 60.3664
2020-11-05 19:04:56,836 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 63.6805 | Iter Mean Loss 61.1949
2020-11-05 19:04:56,844 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 56.1838 | Iter Mean Loss 60.1927
2020-11-05 19:04:56,846 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.5260
2020-11-05 19:04:56,856 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2950 | Iter Mean Loss 48.2950
2020-11-05 19:04:56,863 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2096 | Iter Mean Loss 44.7523
2020-11-05 19:04:56,872 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 81.2730 | Iter Mean Loss 56.9259
2020-11-05 19:04:56,881 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 60.2347 | Iter Mean Loss 57.7531
2020-11-05 19:04:56,889 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 53.6153 | Iter Mean Loss 56.9255
2020-11-05 19:04:56,892 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.5224
2020-11-05 19:04:56,902 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.2965 | Iter Mean Loss 45.2965
2020-11-05 19:04:56,911 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.1255 | Iter Mean Loss 41.7110
2020-11-05 19:04:56,920 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.9367 | Iter Mean Loss 53.7862
2020-11-05 19:04:56,929 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 57.0892 | Iter Mean Loss 54.6120
2020-11-05 19:04:56,938 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 51.2955 | Iter Mean Loss 53.9487
2020-11-05 19:04:56,940 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.5192
2020-11-05 19:04:56,951 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.5641 | Iter Mean Loss 42.5641
2020-11-05 19:04:56,959 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.3007 | Iter Mean Loss 38.9324
2020-11-05 19:04:56,969 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 74.9256 | Iter Mean Loss 50.9301
2020-11-05 19:04:56,977 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 54.2351 | Iter Mean Loss 51.7564
2020-11-05 19:04:56,986 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 49.2126 | Iter Mean Loss 51.2476
2020-11-05 19:04:56,989 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.5164
2020-11-05 19:04:56,997 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.0977 | Iter Mean Loss 40.0977
2020-11-05 19:04:57,005 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 32.7323 | Iter Mean Loss 36.4150
2020-11-05 19:04:57,013 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.2329 | Iter Mean Loss 48.3543
2020-11-05 19:04:57,021 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.6722 | Iter Mean Loss 49.1838
2020-11-05 19:04:57,029 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 47.3629 | Iter Mean Loss 48.8196
2020-11-05 19:04:57,031 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.5139
2020-11-05 19:04:57,039 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.9030 | Iter Mean Loss 37.9030
2020-11-05 19:04:57,048 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 30.4248 | Iter Mean Loss 34.1639
2020-11-05 19:04:57,056 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.8550 | Iter Mean Loss 46.0609
2020-11-05 19:04:57,064 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.4024 | Iter Mean Loss 46.8963
2020-11-05 19:04:57,072 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.7445 | Iter Mean Loss 46.6659
2020-11-05 19:04:57,074 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.5117
2020-11-05 19:04:57,084 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9842 | Iter Mean Loss 35.9842
2020-11-05 19:04:57,093 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.3828 | Iter Mean Loss 32.1835
2020-11-05 19:04:57,103 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.7854 | Iter Mean Loss 44.0508
2020-11-05 19:04:57,111 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.4234 | Iter Mean Loss 44.8940
2020-11-05 19:04:57,121 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 44.3515 | Iter Mean Loss 44.7855
2020-11-05 19:04:57,123 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.5098
2020-11-05 19:04:57,132 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.3389 | Iter Mean Loss 34.3389
2020-11-05 19:04:57,141 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.6056 | Iter Mean Loss 30.4722
2020-11-05 19:04:57,150 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0123 | Iter Mean Loss 42.3189
2020-11-05 19:04:57,159 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.7268 | Iter Mean Loss 43.1709
2020-11-05 19:04:57,169 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 43.1727 | Iter Mean Loss 43.1712
2020-11-05 19:04:57,171 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.5081
2020-11-05 19:04:57,180 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.9560 | Iter Mean Loss 32.9560
2020-11-05 19:04:57,189 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.0850 | Iter Mean Loss 29.0205
2020-11-05 19:04:57,197 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.5169 | Iter Mean Loss 40.8526
2020-11-05 19:04:57,204 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.2964 | Iter Mean Loss 41.7136
2020-11-05 19:04:57,212 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 42.1911 | Iter Mean Loss 41.8091
2020-11-05 19:04:57,214 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.5066
2020-11-05 19:04:57,223 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.8164 | Iter Mean Loss 31.8164
2020-11-05 19:04:57,231 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.8048 | Iter Mean Loss 27.8106
2020-11-05 19:04:57,238 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2742 | Iter Mean Loss 39.6318
2020-11-05 19:04:57,246 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.1094 | Iter Mean Loss 40.5012
2020-11-05 19:04:57,254 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 41.3853 | Iter Mean Loss 40.6780
2020-11-05 19:04:57,256 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.5052
2020-11-05 19:04:57,264 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.8940 | Iter Mean Loss 30.8940
2020-11-05 19:04:57,273 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7426 | Iter Mean Loss 26.8183
2020-11-05 19:04:57,283 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.2539 | Iter Mean Loss 38.6302
2020-11-05 19:04:57,292 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1375 | Iter Mean Loss 39.5070
2020-11-05 19:04:57,300 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.7305 | Iter Mean Loss 39.7517
2020-11-05 19:04:57,303 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.5041
2020-11-05 19:04:57,313 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1582 | Iter Mean Loss 30.1582
2020-11-05 19:04:57,324 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.8714 | Iter Mean Loss 26.0148
2020-11-05 19:04:57,339 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.4230 | Iter Mean Loss 37.8175
2020-11-05 19:04:57,350 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3496 | Iter Mean Loss 38.7006
2020-11-05 19:04:57,358 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.2007 | Iter Mean Loss 39.0006
2020-11-05 19:04:57,362 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.2817 | MSE 0.5031
2020-11-05 19:04:57,372 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.5766 | Iter Mean Loss 29.5766
2020-11-05 19:04:57,381 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.1624 | Iter Mean Loss 25.3695
2020-11-05 19:04:57,390 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.7478 | Iter Mean Loss 37.1623
2020-11-05 19:04:57,399 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.7138 | Iter Mean Loss 38.0501
2020-11-05 19:04:57,407 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.7704 | Iter Mean Loss 38.3942
2020-11-05 19:04:57,410 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.2817 | MSE 0.5022
2020-11-05 19:04:57,419 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.1174 | Iter Mean Loss 29.1174
2020-11-05 19:04:57,427 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5868 | Iter Mean Loss 24.8521
2020-11-05 19:04:57,435 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.1961 | Iter Mean Loss 36.6334
2020-11-05 19:04:57,443 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1997 | Iter Mean Loss 37.5250
2020-11-05 19:04:57,451 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.4166 | Iter Mean Loss 37.9033
2020-11-05 19:04:57,453 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.2817 | MSE 0.5015
2020-11-05 19:04:57,462 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.7520 | Iter Mean Loss 28.7520
2020-11-05 19:04:57,470 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1178 | Iter Mean Loss 24.4349
2020-11-05 19:04:57,478 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.7387 | Iter Mean Loss 36.2028
2020-11-05 19:04:57,486 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7799 | Iter Mean Loss 37.0971
2020-11-05 19:04:57,495 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.1192 | Iter Mean Loss 37.5015
2020-11-05 19:04:57,498 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.2817 | MSE 0.5009
2020-11-05 19:04:57,507 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4556 | Iter Mean Loss 28.4556
2020-11-05 19:04:57,517 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7321 | Iter Mean Loss 24.0938
2020-11-05 19:04:57,526 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3507 | Iter Mean Loss 35.8461
2020-11-05 19:04:57,535 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4309 | Iter Mean Loss 36.7423
2020-11-05 19:04:57,544 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.8614 | Iter Mean Loss 37.1661
2020-11-05 19:04:57,548 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.2817 | MSE 0.5003
2020-11-05 19:04:57,557 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2086 | Iter Mean Loss 28.2086
2020-11-05 19:04:57,566 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.4101 | Iter Mean Loss 23.8093
2020-11-05 19:04:57,574 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0119 | Iter Mean Loss 35.5435
2020-11-05 19:04:57,583 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1339 | Iter Mean Loss 36.4411
2020-11-05 19:04:57,592 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.6306 | Iter Mean Loss 36.8790
2020-11-05 19:04:57,595 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.2817 | MSE 0.4999
2020-11-05 19:04:57,604 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.9961 | Iter Mean Loss 27.9961
2020-11-05 19:04:57,612 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1364 | Iter Mean Loss 23.5663
2020-11-05 19:04:57,620 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7064 | Iter Mean Loss 35.2796
2020-11-05 19:04:57,627 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8739 | Iter Mean Loss 36.1782
2020-11-05 19:04:57,635 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.4172 | Iter Mean Loss 36.6260
2020-11-05 19:04:57,637 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.2817 | MSE 0.4996
2020-11-05 19:04:57,646 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8074 | Iter Mean Loss 27.8074
2020-11-05 19:04:57,654 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8993 | Iter Mean Loss 23.3534
2020-11-05 19:04:57,662 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.4225 | Iter Mean Loss 35.0431
2020-11-05 19:04:57,669 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6401 | Iter Mean Loss 35.9423
2020-11-05 19:04:57,677 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.2145 | Iter Mean Loss 36.3967
2020-11-05 19:04:57,679 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.2817 | MSE 0.4993
2020-11-05 19:04:57,689 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.6351 | Iter Mean Loss 27.6351
2020-11-05 19:04:57,698 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6900 | Iter Mean Loss 23.1625
2020-11-05 19:04:57,708 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.1517 | Iter Mean Loss 34.8256
2020-11-05 19:04:57,716 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.4241 | Iter Mean Loss 35.7252
2020-11-05 19:04:57,724 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.0179 | Iter Mean Loss 36.1837
2020-11-05 19:04:57,727 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.2817 | MSE 0.4991
2020-11-05 19:04:57,735 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.4741 | Iter Mean Loss 27.4741
2020-11-05 19:04:57,745 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.5017 | Iter Mean Loss 22.9879
2020-11-05 19:04:57,753 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.8881 | Iter Mean Loss 34.6213
2020-11-05 19:04:57,762 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2203 | Iter Mean Loss 35.5210
2020-11-05 19:04:57,770 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.8245 | Iter Mean Loss 35.9817
2020-11-05 19:04:57,773 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.2817 | MSE 0.4989
2020-11-05 19:04:57,784 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3210 | Iter Mean Loss 27.3210
2020-11-05 19:04:57,794 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3295 | Iter Mean Loss 22.8252
2020-11-05 19:04:57,803 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.6279 | Iter Mean Loss 34.4261
2020-11-05 19:04:57,812 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0246 | Iter Mean Loss 35.3257
2020-11-05 19:04:57,821 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.6324 | Iter Mean Loss 35.7871
2020-11-05 19:04:57,823 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.2817 | MSE 0.4988
2020-11-05 19:04:57,832 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.1733 | Iter Mean Loss 27.1733
2020-11-05 19:04:57,840 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.1695 | Iter Mean Loss 22.6714
2020-11-05 19:04:57,849 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3683 | Iter Mean Loss 34.2370
2020-11-05 19:04:57,857 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8340 | Iter Mean Loss 35.1363
2020-11-05 19:04:57,865 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.4404 | Iter Mean Loss 35.5971
2020-11-05 19:04:57,867 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.2817 | MSE 0.4987
2020-11-05 19:04:57,876 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0294 | Iter Mean Loss 27.0294
2020-11-05 19:04:57,884 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0186 | Iter Mean Loss 22.5240
2020-11-05 19:04:57,892 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.1077 | Iter Mean Loss 34.0519
2020-11-05 19:04:57,901 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.6466 | Iter Mean Loss 34.9506
2020-11-05 19:04:57,910 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.2477 | Iter Mean Loss 35.4100
2020-11-05 19:04:57,913 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.2817 | MSE 0.4986
2020-11-05 19:04:57,923 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.8878 | Iter Mean Loss 26.8878
2020-11-05 19:04:57,932 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.8743 | Iter Mean Loss 22.3811
2020-11-05 19:04:57,941 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.8452 | Iter Mean Loss 33.8691
2020-11-05 19:04:57,949 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.4607 | Iter Mean Loss 34.7670
2020-11-05 19:04:57,959 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.0539 | Iter Mean Loss 35.2244
2020-11-05 19:04:57,961 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.2817 | MSE 0.4986
2020-11-05 19:04:57,971 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7473 | Iter Mean Loss 26.7473
2020-11-05 19:04:57,980 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7345 | Iter Mean Loss 22.2409
2020-11-05 19:04:57,989 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.5801 | Iter Mean Loss 33.6873
2020-11-05 19:04:57,998 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2753 | Iter Mean Loss 34.5843
2020-11-05 19:04:58,008 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.8584 | Iter Mean Loss 35.0391
2020-11-05 19:04:58,011 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.2817 | MSE 0.4985
2020-11-05 19:04:58,019 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6069 | Iter Mean Loss 26.6069
2020-11-05 19:04:58,027 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5973 | Iter Mean Loss 22.1021
2020-11-05 19:04:58,036 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.3121 | Iter Mean Loss 33.5054
2020-11-05 19:04:58,043 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0895 | Iter Mean Loss 34.4015
2020-11-05 19:04:58,051 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6610 | Iter Mean Loss 34.8534
2020-11-05 19:04:58,054 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.2817 | MSE 0.4985
2020-11-05 19:04:58,062 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.4657 | Iter Mean Loss 26.4657
2020-11-05 19:04:58,070 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4612 | Iter Mean Loss 21.9635
2020-11-05 19:04:58,078 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.0410 | Iter Mean Loss 33.3226
2020-11-05 19:04:58,086 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.9027 | Iter Mean Loss 34.2176
2020-11-05 19:04:58,094 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.4613 | Iter Mean Loss 34.6664
2020-11-05 19:04:58,097 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.2817 | MSE 0.4985
2020-11-05 19:04:58,106 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3228 | Iter Mean Loss 26.3228
2020-11-05 19:04:58,115 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.3249 | Iter Mean Loss 21.8239
2020-11-05 19:04:58,124 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.7666 | Iter Mean Loss 33.1381
2020-11-05 19:04:58,132 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.7143 | Iter Mean Loss 34.0322
2020-11-05 19:04:58,142 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.2590 | Iter Mean Loss 34.4775
2020-11-05 19:04:58,144 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.2817 | MSE 0.4985
2020-11-05 19:04:58,154 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1776 | Iter Mean Loss 26.1776
2020-11-05 19:04:58,163 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.1874 | Iter Mean Loss 21.6825
2020-11-05 19:04:58,172 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.4889 | Iter Mean Loss 32.9513
2020-11-05 19:04:58,181 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.5238 | Iter Mean Loss 33.8444
2020-11-05 19:04:58,190 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.0538 | Iter Mean Loss 34.2863
2020-11-05 19:04:58,192 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.2817 | MSE 0.4985
2020-11-05 19:04:58,201 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.0292 | Iter Mean Loss 26.0292
2020-11-05 19:04:58,210 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0477 | Iter Mean Loss 21.5385
2020-11-05 19:04:58,218 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.2077 | Iter Mean Loss 32.7616
2020-11-05 19:04:58,226 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.3308 | Iter Mean Loss 33.6539
2020-11-05 19:04:58,235 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.8454 | Iter Mean Loss 34.0922
2020-11-05 19:04:58,237 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,246 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8773 | Iter Mean Loss 25.8773
2020-11-05 19:04:58,253 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.9051 | Iter Mean Loss 21.3912
2020-11-05 19:04:58,261 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.9228 | Iter Mean Loss 32.5684
2020-11-05 19:04:58,269 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.1349 | Iter Mean Loss 33.4600
2020-11-05 19:04:58,278 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.6332 | Iter Mean Loss 33.8947
2020-11-05 19:04:58,281 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,289 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7211 | Iter Mean Loss 25.7211
2020-11-05 19:04:58,297 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7588 | Iter Mean Loss 21.2400
2020-11-05 19:04:58,306 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.6339 | Iter Mean Loss 32.3713
2020-11-05 19:04:58,316 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.9358 | Iter Mean Loss 33.2624
2020-11-05 19:04:58,326 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.4170 | Iter Mean Loss 33.6933
2020-11-05 19:04:58,328 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,337 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.5602 | Iter Mean Loss 25.5602
2020-11-05 19:04:58,347 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.6084 | Iter Mean Loss 21.0843
2020-11-05 19:04:58,355 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.3408 | Iter Mean Loss 32.1698
2020-11-05 19:04:58,363 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.7330 | Iter Mean Loss 33.0606
2020-11-05 19:04:58,372 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.1963 | Iter Mean Loss 33.4877
2020-11-05 19:04:58,375 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,385 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3942 | Iter Mean Loss 25.3942
2020-11-05 19:04:58,394 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.4533 | Iter Mean Loss 20.9238
2020-11-05 19:04:58,403 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0431 | Iter Mean Loss 31.9635
2020-11-05 19:04:58,411 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.5263 | Iter Mean Loss 32.8542
2020-11-05 19:04:58,419 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.9707 | Iter Mean Loss 33.2775
2020-11-05 19:04:58,421 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,429 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2227 | Iter Mean Loss 25.2227
2020-11-05 19:04:58,437 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.2930 | Iter Mean Loss 20.7579
2020-11-05 19:04:58,446 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.7405 | Iter Mean Loss 31.7521
2020-11-05 19:04:58,454 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.3152 | Iter Mean Loss 32.6429
2020-11-05 19:04:58,462 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.7399 | Iter Mean Loss 33.0623
2020-11-05 19:04:58,464 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,473 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0453 | Iter Mean Loss 25.0453
2020-11-05 19:04:58,481 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1273 | Iter Mean Loss 20.5863
2020-11-05 19:04:58,489 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.4327 | Iter Mean Loss 31.5351
2020-11-05 19:04:58,497 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0995 | Iter Mean Loss 32.4262
2020-11-05 19:04:58,506 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.5034 | Iter Mean Loss 32.8417
2020-11-05 19:04:58,508 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,516 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8616 | Iter Mean Loss 24.8616
2020-11-05 19:04:58,524 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9557 | Iter Mean Loss 20.4086
2020-11-05 19:04:58,532 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.1193 | Iter Mean Loss 31.3122
2020-11-05 19:04:58,540 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.8789 | Iter Mean Loss 32.2039
2020-11-05 19:04:58,549 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.2609 | Iter Mean Loss 32.6153
2020-11-05 19:04:58,551 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,560 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6712 | Iter Mean Loss 24.6712
2020-11-05 19:04:58,569 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.7779 | Iter Mean Loss 20.2245
2020-11-05 19:04:58,576 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.7999 | Iter Mean Loss 31.0830
2020-11-05 19:04:58,585 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.6530 | Iter Mean Loss 31.9755
2020-11-05 19:04:58,593 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.0120 | Iter Mean Loss 32.3828
2020-11-05 19:04:58,596 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,606 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4738 | Iter Mean Loss 24.4738
2020-11-05 19:04:58,613 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.5936 | Iter Mean Loss 20.0337
2020-11-05 19:04:58,621 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.4743 | Iter Mean Loss 30.8472
2020-11-05 19:04:58,628 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.4216 | Iter Mean Loss 31.7408
2020-11-05 19:04:58,636 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.7564 | Iter Mean Loss 32.1439
2020-11-05 19:04:58,638 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.2817 | MSE 0.4984
2020-11-05 19:04:58,647 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2691 | Iter Mean Loss 24.2691
2020-11-05 19:04:58,655 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4025 | Iter Mean Loss 19.8358
2020-11-05 19:04:58,663 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.1423 | Iter Mean Loss 30.6046
2020-11-05 19:04:58,670 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1844 | Iter Mean Loss 31.4996
2020-11-05 19:04:58,678 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.4938 | Iter Mean Loss 31.8984
2020-11-05 19:04:58,681 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,689 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0568 | Iter Mean Loss 24.0568
2020-11-05 19:04:58,698 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2046 | Iter Mean Loss 19.6307
2020-11-05 19:04:58,710 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.8035 | Iter Mean Loss 30.3549
2020-11-05 19:04:58,719 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.9413 | Iter Mean Loss 31.2515
2020-11-05 19:04:58,728 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.2241 | Iter Mean Loss 31.6460
2020-11-05 19:04:58,731 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,741 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8366 | Iter Mean Loss 23.8366
2020-11-05 19:04:58,750 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.9995 | Iter Mean Loss 19.4181
2020-11-05 19:04:58,759 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.4578 | Iter Mean Loss 30.0980
2020-11-05 19:04:58,768 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6920 | Iter Mean Loss 30.9965
2020-11-05 19:04:58,777 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9471 | Iter Mean Loss 31.3866
2020-11-05 19:04:58,780 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,789 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6084 | Iter Mean Loss 23.6084
2020-11-05 19:04:58,799 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7872 | Iter Mean Loss 19.1978
2020-11-05 19:04:58,808 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1051 | Iter Mean Loss 29.8336
2020-11-05 19:04:58,818 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4366 | Iter Mean Loss 30.7343
2020-11-05 19:04:58,827 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.6626 | Iter Mean Loss 31.1200
2020-11-05 19:04:58,829 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,838 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3720 | Iter Mean Loss 23.3720
2020-11-05 19:04:58,847 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5678 | Iter Mean Loss 18.9699
2020-11-05 19:04:58,855 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7455 | Iter Mean Loss 29.5618
2020-11-05 19:04:58,863 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1749 | Iter Mean Loss 30.4650
2020-11-05 19:04:58,871 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.3708 | Iter Mean Loss 30.8462
2020-11-05 19:04:58,874 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,882 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1274 | Iter Mean Loss 23.1274
2020-11-05 19:04:58,890 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.3412 | Iter Mean Loss 18.7343
2020-11-05 19:04:58,898 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3788 | Iter Mean Loss 29.2825
2020-11-05 19:04:58,906 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9071 | Iter Mean Loss 30.1886
2020-11-05 19:04:58,915 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.0718 | Iter Mean Loss 30.5653
2020-11-05 19:04:58,917 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,927 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8747 | Iter Mean Loss 22.8747
2020-11-05 19:04:58,935 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.1076 | Iter Mean Loss 18.4912
2020-11-05 19:04:58,944 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.0055 | Iter Mean Loss 28.9959
2020-11-05 19:04:58,953 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6333 | Iter Mean Loss 29.9053
2020-11-05 19:04:58,963 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.7657 | Iter Mean Loss 30.2774
2020-11-05 19:04:58,965 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:58,975 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6140 | Iter Mean Loss 22.6140
2020-11-05 19:04:58,983 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.8674 | Iter Mean Loss 18.2407
2020-11-05 19:04:58,993 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.6256 | Iter Mean Loss 28.7023
2020-11-05 19:04:59,001 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.3538 | Iter Mean Loss 29.6152
2020-11-05 19:04:59,010 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.4529 | Iter Mean Loss 29.9827
2020-11-05 19:04:59,013 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:59,022 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3457 | Iter Mean Loss 22.3457
2020-11-05 19:04:59,031 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.6209 | Iter Mean Loss 17.9833
2020-11-05 19:04:59,039 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.2396 | Iter Mean Loss 28.4020
2020-11-05 19:04:59,046 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.0689 | Iter Mean Loss 29.3188
2020-11-05 19:04:59,054 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.1339 | Iter Mean Loss 29.6818
2020-11-05 19:04:59,057 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.2817 | MSE 0.4983
2020-11-05 19:04:59,065 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0700 | Iter Mean Loss 22.0700
2020-11-05 19:04:59,074 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.3688 | Iter Mean Loss 17.7194
2020-11-05 19:04:59,083 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.8480 | Iter Mean Loss 28.0956
2020-11-05 19:04:59,091 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7791 | Iter Mean Loss 29.0165
2020-11-05 19:04:59,099 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 29.3751
2020-11-05 19:04:59,101 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.2817 | MSE 0.4982
2020-11-05 19:04:59,111 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7878 | Iter Mean Loss 21.7878
2020-11-05 19:04:59,120 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.1117 | Iter Mean Loss 17.4497
2020-11-05 19:04:59,128 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.4515 | Iter Mean Loss 27.7837
2020-11-05 19:04:59,135 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.4851 | Iter Mean Loss 28.7090
2020-11-05 19:04:59,144 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.4802 | Iter Mean Loss 29.0633
2020-11-05 19:04:59,147 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.2817 | MSE 0.4982
2020-11-05 19:04:59,156 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4996 | Iter Mean Loss 21.4996
2020-11-05 19:04:59,164 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.8505 | Iter Mean Loss 17.1750
2020-11-05 19:04:59,172 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.0509 | Iter Mean Loss 27.4670
2020-11-05 19:04:59,180 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.1877 | Iter Mean Loss 28.3972
2020-11-05 19:04:59,188 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.1473 | Iter Mean Loss 28.7472
2020-11-05 19:04:59,190 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.2817 | MSE 0.4982
2020-11-05 19:04:59,199 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2065 | Iter Mean Loss 21.2065
2020-11-05 19:04:59,208 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5862 | Iter Mean Loss 16.8963
2020-11-05 19:04:59,216 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.6471 | Iter Mean Loss 27.1466
2020-11-05 19:04:59,223 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8876 | Iter Mean Loss 28.0818
2020-11-05 19:04:59,231 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.8117 | Iter Mean Loss 28.4278
2020-11-05 19:04:59,234 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.2817 | MSE 0.4982
2020-11-05 19:04:59,243 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9094 | Iter Mean Loss 20.9094
2020-11-05 19:04:59,251 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.3201 | Iter Mean Loss 16.6147
2020-11-05 19:04:59,259 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.2411 | Iter Mean Loss 26.8235
2020-11-05 19:04:59,268 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5859 | Iter Mean Loss 27.7641
2020-11-05 19:04:59,278 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4748 | Iter Mean Loss 28.1063
2020-11-05 19:04:59,280 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.2817 | MSE 0.4981
2020-11-05 19:04:59,289 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6096 | Iter Mean Loss 20.6096
2020-11-05 19:04:59,296 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.0533 | Iter Mean Loss 16.3314
2020-11-05 19:04:59,304 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.8343 | Iter Mean Loss 26.4990
2020-11-05 19:04:59,312 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.2837 | Iter Mean Loss 27.4452
2020-11-05 19:04:59,323 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.1379 | Iter Mean Loss 27.7837
2020-11-05 19:04:59,325 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.2817 | MSE 0.4981
2020-11-05 19:04:59,334 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3084 | Iter Mean Loss 20.3084
2020-11-05 19:04:59,343 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7873 | Iter Mean Loss 16.0478
2020-11-05 19:04:59,351 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.4277 | Iter Mean Loss 26.1744
2020-11-05 19:04:59,360 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9821 | Iter Mean Loss 27.1264
2020-11-05 19:04:59,368 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.8025 | Iter Mean Loss 27.4616
2020-11-05 19:04:59,370 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.2817 | MSE 0.4980
2020-11-05 19:04:59,380 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0072 | Iter Mean Loss 20.0072
2020-11-05 19:04:59,389 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.5235 | Iter Mean Loss 15.7653
2020-11-05 19:04:59,397 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.0226 | Iter Mean Loss 25.8511
2020-11-05 19:04:59,406 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6824 | Iter Mean Loss 26.8089
2020-11-05 19:04:59,415 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.4702 | Iter Mean Loss 27.1412
2020-11-05 19:04:59,417 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.2817 | MSE 0.4980
2020-11-05 19:04:59,427 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7075 | Iter Mean Loss 19.7075
2020-11-05 19:04:59,436 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2634 | Iter Mean Loss 15.4854
2020-11-05 19:04:59,444 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.6204 | Iter Mean Loss 25.5304
2020-11-05 19:04:59,452 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.3856 | Iter Mean Loss 26.4942
2020-11-05 19:04:59,460 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.1424 | Iter Mean Loss 26.8239
2020-11-05 19:04:59,462 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.2817 | MSE 0.4979
2020-11-05 19:04:59,470 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4107 | Iter Mean Loss 19.4107
2020-11-05 19:04:59,478 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.0085 | Iter Mean Loss 15.2096
2020-11-05 19:04:59,486 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.2223 | Iter Mean Loss 25.2138
2020-11-05 19:04:59,494 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0930 | Iter Mean Loss 26.1836
2020-11-05 19:04:59,502 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.8205 | Iter Mean Loss 26.5110
2020-11-05 19:04:59,504 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.2817 | MSE 0.4978
2020-11-05 19:04:59,513 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1182 | Iter Mean Loss 19.1182
2020-11-05 19:04:59,521 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7601 | Iter Mean Loss 14.9391
2020-11-05 19:04:59,529 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.8294 | Iter Mean Loss 24.9026
2020-11-05 19:04:59,537 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8055 | Iter Mean Loss 25.8783
2020-11-05 19:04:59,545 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.5060 | Iter Mean Loss 26.2038
2020-11-05 19:04:59,549 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.2817 | MSE 0.4978
2020-11-05 19:04:59,558 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8312 | Iter Mean Loss 18.8312
2020-11-05 19:04:59,566 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5194 | Iter Mean Loss 14.6753
2020-11-05 19:04:59,575 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.4427 | Iter Mean Loss 24.5978
2020-11-05 19:04:59,584 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.5241 | Iter Mean Loss 25.5794
2020-11-05 19:04:59,592 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.1998 | Iter Mean Loss 25.9034
2020-11-05 19:04:59,594 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.2817 | MSE 0.4977
2020-11-05 19:04:59,604 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5509 | Iter Mean Loss 18.5509
2020-11-05 19:04:59,612 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.2874 | Iter Mean Loss 14.4192
2020-11-05 19:04:59,620 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0630 | Iter Mean Loss 24.3004
2020-11-05 19:04:59,630 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.2495 | Iter Mean Loss 25.2877
2020-11-05 19:04:59,638 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.9029 | Iter Mean Loss 25.6107
2020-11-05 19:04:59,640 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.2817 | MSE 0.4975
2020-11-05 19:04:59,649 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2782 | Iter Mean Loss 18.2782
2020-11-05 19:04:59,656 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0649 | Iter Mean Loss 14.1715
2020-11-05 19:04:59,664 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6909 | Iter Mean Loss 24.0113
2020-11-05 19:04:59,671 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9822 | Iter Mean Loss 25.0040
2020-11-05 19:04:59,679 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.6160 | Iter Mean Loss 25.3264
2020-11-05 19:04:59,681 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.2817 | MSE 0.4974
2020-11-05 19:04:59,690 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0136 | Iter Mean Loss 18.0136
2020-11-05 19:04:59,698 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8524 | Iter Mean Loss 13.9330
2020-11-05 19:04:59,706 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3267 | Iter Mean Loss 23.7309
2020-11-05 19:04:59,713 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7225 | Iter Mean Loss 24.7288
2020-11-05 19:04:59,721 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.3393 | Iter Mean Loss 25.0509
2020-11-05 19:04:59,723 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.2817 | MSE 0.4972
2020-11-05 19:04:59,732 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7576 | Iter Mean Loss 17.7576
2020-11-05 19:04:59,740 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6501 | Iter Mean Loss 13.7039
2020-11-05 19:04:59,748 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.9706 | Iter Mean Loss 23.4594
2020-11-05 19:04:59,755 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.4706 | Iter Mean Loss 24.4622
2020-11-05 19:04:59,764 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.0730 | Iter Mean Loss 24.7844
2020-11-05 19:04:59,766 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.2817 | MSE 0.4971
2020-11-05 19:04:59,774 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5104 | Iter Mean Loss 17.5104
2020-11-05 19:04:59,783 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4581 | Iter Mean Loss 13.4843
2020-11-05 19:04:59,791 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6225 | Iter Mean Loss 23.1970
2020-11-05 19:04:59,801 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.2264 | Iter Mean Loss 24.2044
2020-11-05 19:04:59,808 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.8169 | Iter Mean Loss 24.5269
2020-11-05 19:04:59,810 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.2817 | MSE 0.4969
2020-11-05 19:04:59,819 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2718 | Iter Mean Loss 17.2718
2020-11-05 19:04:59,826 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2762 | Iter Mean Loss 13.2740
2020-11-05 19:04:59,835 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.2822 | Iter Mean Loss 22.9434
2020-11-05 19:04:59,842 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9895 | Iter Mean Loss 23.9549
2020-11-05 19:04:59,850 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.5706 | Iter Mean Loss 24.2781
2020-11-05 19:04:59,852 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.2817 | MSE 0.4966
2020-11-05 19:04:59,861 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0416 | Iter Mean Loss 17.0416
2020-11-05 19:04:59,869 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.1037 | Iter Mean Loss 13.0727
2020-11-05 19:04:59,876 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.9491 | Iter Mean Loss 22.6982
2020-11-05 19:04:59,884 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7597 | Iter Mean Loss 23.7136
2020-11-05 19:04:59,891 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.3335 | Iter Mean Loss 24.0375
2020-11-05 19:04:59,893 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.2817 | MSE 0.4964
2020-11-05 19:04:59,905 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8193 | Iter Mean Loss 16.8193
2020-11-05 19:04:59,925 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.9402 | Iter Mean Loss 12.8798
2020-11-05 19:04:59,936 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.6228 | Iter Mean Loss 22.4608
2020-11-05 19:04:59,945 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.5364 | Iter Mean Loss 23.4797
2020-11-05 19:04:59,954 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.1048 | Iter Mean Loss 23.8047
2020-11-05 19:04:59,961 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.2817 | MSE 0.4961
2020-11-05 19:04:59,974 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6043 | Iter Mean Loss 16.6043
2020-11-05 19:04:59,984 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.7848 | Iter Mean Loss 12.6946
2020-11-05 19:04:59,993 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3025 | Iter Mean Loss 22.2305
2020-11-05 19:05:00,001 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.3189 | Iter Mean Loss 23.2526
2020-11-05 19:05:00,011 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.8837 | Iter Mean Loss 23.5788
2020-11-05 19:05:00,013 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.2817 | MSE 0.4958
2020-11-05 19:05:00,022 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3959 | Iter Mean Loss 16.3959
2020-11-05 19:05:00,031 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 12.5163
2020-11-05 19:05:00,040 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.9874 | Iter Mean Loss 22.0067
2020-11-05 19:05:00,049 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.1066 | Iter Mean Loss 23.0316
2020-11-05 19:05:00,057 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.6691 | Iter Mean Loss 23.3591
2020-11-05 19:05:00,059 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.2817 | MSE 0.4955
2020-11-05 19:05:00,067 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1933 | Iter Mean Loss 16.1933
2020-11-05 19:05:00,076 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 12.3441
2020-11-05 19:05:00,083 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.6769 | Iter Mean Loss 21.7883
2020-11-05 19:05:00,091 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8988 | Iter Mean Loss 22.8159
2020-11-05 19:05:00,099 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.4602 | Iter Mean Loss 23.1448
2020-11-05 19:05:00,101 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.2817 | MSE 0.4952
2020-11-05 19:05:00,109 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9957 | Iter Mean Loss 15.9957
2020-11-05 19:05:00,117 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3584 | Iter Mean Loss 12.1771
2020-11-05 19:05:00,125 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.3700 | Iter Mean Loss 21.5747
2020-11-05 19:05:00,133 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6948 | Iter Mean Loss 22.6047
2020-11-05 19:05:00,141 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.2559 | Iter Mean Loss 22.9350
2020-11-05 19:05:00,143 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.2817 | MSE 0.4948
2020-11-05 19:05:00,152 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8024 | Iter Mean Loss 15.8024
2020-11-05 19:05:00,161 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 12.0144
2020-11-05 19:05:00,168 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.0662 | Iter Mean Loss 21.3650
2020-11-05 19:05:00,176 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4940 | Iter Mean Loss 22.3973
2020-11-05 19:05:00,184 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.0553 | Iter Mean Loss 22.7289
2020-11-05 19:05:00,186 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.2817 | MSE 0.4944
2020-11-05 19:05:00,195 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6127 | Iter Mean Loss 15.6127
2020-11-05 19:05:00,204 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.0982 | Iter Mean Loss 11.8555
2020-11-05 19:05:00,211 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.7648 | Iter Mean Loss 21.1586
2020-11-05 19:05:00,219 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2957 | Iter Mean Loss 22.1929
2020-11-05 19:05:00,228 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.8577 | Iter Mean Loss 22.5259
2020-11-05 19:05:00,230 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.2817 | MSE 0.4940
2020-11-05 19:05:00,239 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4260 | Iter Mean Loss 15.4260
2020-11-05 19:05:00,247 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9730 | Iter Mean Loss 11.6995
2020-11-05 19:05:00,255 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.4652 | Iter Mean Loss 20.9547
2020-11-05 19:05:00,263 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0996 | Iter Mean Loss 21.9909
2020-11-05 19:05:00,271 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.6624 | Iter Mean Loss 22.3252
2020-11-05 19:05:00,273 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.2817 | MSE 0.4936
2020-11-05 19:05:00,281 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2417 | Iter Mean Loss 15.2417
2020-11-05 19:05:00,289 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.8501 | Iter Mean Loss 11.5459
2020-11-05 19:05:00,297 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.1670 | Iter Mean Loss 20.7529
2020-11-05 19:05:00,305 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.9051 | Iter Mean Loss 21.7910
2020-11-05 19:05:00,314 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.4687 | Iter Mean Loss 22.1265
2020-11-05 19:05:00,316 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.2817 | MSE 0.4932
2020-11-05 19:05:00,328 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0594 | Iter Mean Loss 15.0594
2020-11-05 19:05:00,336 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7290 | Iter Mean Loss 11.3942
2020-11-05 19:05:00,344 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.8697 | Iter Mean Loss 20.5527
2020-11-05 19:05:00,352 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7120 | Iter Mean Loss 21.5925
2020-11-05 19:05:00,361 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.2761 | Iter Mean Loss 21.9292
2020-11-05 19:05:00,363 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.2817 | MSE 0.4927
2020-11-05 19:05:00,372 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8789 | Iter Mean Loss 14.8789
2020-11-05 19:05:00,380 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 11.2441
2020-11-05 19:05:00,390 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.5732 | Iter Mean Loss 20.3538
2020-11-05 19:05:00,398 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5200 | Iter Mean Loss 21.3953
2020-11-05 19:05:00,406 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.0843 | Iter Mean Loss 21.7331
2020-11-05 19:05:00,410 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.2817 | MSE 0.4922
2020-11-05 19:05:00,420 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6999 | Iter Mean Loss 14.6999
2020-11-05 19:05:00,428 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4908 | Iter Mean Loss 11.0953
2020-11-05 19:05:00,437 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.2772 | Iter Mean Loss 20.1560
2020-11-05 19:05:00,446 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3290 | Iter Mean Loss 21.1992
2020-11-05 19:05:00,453 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.8930 | Iter Mean Loss 21.5380
2020-11-05 19:05:00,456 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.2817 | MSE 0.4917
2020-11-05 19:05:00,464 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5223 | Iter Mean Loss 14.5223
2020-11-05 19:05:00,472 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.3731 | Iter Mean Loss 10.9477
2020-11-05 19:05:00,480 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.9818 | Iter Mean Loss 19.9591
2020-11-05 19:05:00,487 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1389 | Iter Mean Loss 21.0040
2020-11-05 19:05:00,495 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.7019 | Iter Mean Loss 21.3436
2020-11-05 19:05:00,497 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.2817 | MSE 0.4912
2020-11-05 19:05:00,505 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3462 | Iter Mean Loss 14.3462
2020-11-05 19:05:00,513 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2563 | Iter Mean Loss 10.8012
2020-11-05 19:05:00,521 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.6868 | Iter Mean Loss 19.7631
2020-11-05 19:05:00,528 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9496 | Iter Mean Loss 20.8097
2020-11-05 19:05:00,536 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.5111 | Iter Mean Loss 21.1500
2020-11-05 19:05:00,538 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.2817 | MSE 0.4907
2020-11-05 19:05:00,546 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1715 | Iter Mean Loss 14.1715
2020-11-05 19:05:00,554 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1402 | Iter Mean Loss 10.6558
2020-11-05 19:05:00,562 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.3925 | Iter Mean Loss 19.5681
2020-11-05 19:05:00,570 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.7613 | Iter Mean Loss 20.6164
2020-11-05 19:05:00,578 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.3204 | Iter Mean Loss 20.9572
2020-11-05 19:05:00,581 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.2817 | MSE 0.4902
2020-11-05 19:05:00,589 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9984 | Iter Mean Loss 13.9984
2020-11-05 19:05:00,597 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.0249 | Iter Mean Loss 10.5117
2020-11-05 19:05:00,605 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.0988 | Iter Mean Loss 19.3741
2020-11-05 19:05:00,613 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5741 | Iter Mean Loss 20.4241
2020-11-05 19:05:00,621 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.1299 | Iter Mean Loss 20.7652
2020-11-05 19:05:00,623 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.2817 | MSE 0.4896
2020-11-05 19:05:00,633 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8272 | Iter Mean Loss 13.8272
2020-11-05 19:05:00,641 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9105 | Iter Mean Loss 10.3689
2020-11-05 19:05:00,649 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.8061 | Iter Mean Loss 19.1813
2020-11-05 19:05:00,657 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3881 | Iter Mean Loss 20.2330
2020-11-05 19:05:00,664 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.9397 | Iter Mean Loss 20.5743
2020-11-05 19:05:00,666 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.2817 | MSE 0.4890
2020-11-05 19:05:00,674 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6581 | Iter Mean Loss 13.6581
2020-11-05 19:05:00,683 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7971 | Iter Mean Loss 10.2276
2020-11-05 19:05:00,691 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.5145 | Iter Mean Loss 18.9899
2020-11-05 19:05:00,699 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2034 | Iter Mean Loss 20.0433
2020-11-05 19:05:00,707 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.7500 | Iter Mean Loss 20.3846
2020-11-05 19:05:00,709 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.2817 | MSE 0.4885
2020-11-05 19:05:00,717 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4913 | Iter Mean Loss 13.4913
2020-11-05 19:05:00,725 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6850 | Iter Mean Loss 10.0881
2020-11-05 19:05:00,732 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2243 | Iter Mean Loss 18.8002
2020-11-05 19:05:00,740 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0204 | Iter Mean Loss 19.8553
2020-11-05 19:05:00,748 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 20.1964
2020-11-05 19:05:00,750 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.2817 | MSE 0.4879
2020-11-05 19:05:00,758 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3273 | Iter Mean Loss 13.3273
2020-11-05 19:05:00,766 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.5742 | Iter Mean Loss 9.9508
2020-11-05 19:05:00,774 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9359 | Iter Mean Loss 18.6125
2020-11-05 19:05:00,782 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8393 | Iter Mean Loss 19.6692
2020-11-05 19:05:00,790 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.3726 | Iter Mean Loss 20.0099
2020-11-05 19:05:00,792 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.2817 | MSE 0.4873
2020-11-05 19:05:00,800 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1664 | Iter Mean Loss 13.1664
2020-11-05 19:05:00,809 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4650 | Iter Mean Loss 9.8157
2020-11-05 19:05:00,816 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.6495 | Iter Mean Loss 18.4270
2020-11-05 19:05:00,825 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6602 | Iter Mean Loss 19.4853
2020-11-05 19:05:00,833 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.1854 | Iter Mean Loss 19.8253
2020-11-05 19:05:00,835 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.2817 | MSE 0.4867
2020-11-05 19:05:00,843 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0090 | Iter Mean Loss 13.0090
2020-11-05 19:05:00,852 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3577 | Iter Mean Loss 9.6834
2020-11-05 19:05:00,859 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.3655 | Iter Mean Loss 18.2441
2020-11-05 19:05:00,867 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4836 | Iter Mean Loss 19.3040
2020-11-05 19:05:00,874 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.9996 | Iter Mean Loss 19.6431
2020-11-05 19:05:00,876 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.2817 | MSE 0.4860
2020-11-05 19:05:00,884 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8554 | Iter Mean Loss 12.8554
2020-11-05 19:05:00,892 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.2525 | Iter Mean Loss 9.5540
2020-11-05 19:05:00,899 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0843 | Iter Mean Loss 18.0641
2020-11-05 19:05:00,907 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3097 | Iter Mean Loss 19.1255
2020-11-05 19:05:00,916 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.8154 | Iter Mean Loss 19.4635
2020-11-05 19:05:00,918 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.2817 | MSE 0.4854
2020-11-05 19:05:00,926 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7061 | Iter Mean Loss 12.7061
2020-11-05 19:05:00,933 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 9.4279
2020-11-05 19:05:00,941 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.8062 | Iter Mean Loss 17.8873
2020-11-05 19:05:00,949 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1387 | Iter Mean Loss 18.9502
2020-11-05 19:05:00,956 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.6330 | Iter Mean Loss 19.2867
2020-11-05 19:05:00,958 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.2817 | MSE 0.4848
2020-11-05 19:05:00,967 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5615 | Iter Mean Loss 12.5615
2020-11-05 19:05:00,974 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.0494 | Iter Mean Loss 9.3055
2020-11-05 19:05:00,983 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5314 | Iter Mean Loss 17.7141
2020-11-05 19:05:00,991 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9709 | Iter Mean Loss 18.7783
2020-11-05 19:05:00,999 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.4529 | Iter Mean Loss 19.1132
2020-11-05 19:05:01,001 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.2817 | MSE 0.4841
2020-11-05 19:05:01,010 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4218 | Iter Mean Loss 12.4218
2020-11-05 19:05:01,017 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9520 | Iter Mean Loss 9.1869
2020-11-05 19:05:01,025 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.2604 | Iter Mean Loss 17.5448
2020-11-05 19:05:01,034 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8066 | Iter Mean Loss 18.6102
2020-11-05 19:05:01,041 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.2752 | Iter Mean Loss 18.9432
2020-11-05 19:05:01,043 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.2817 | MSE 0.4835
2020-11-05 19:05:01,053 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2876 | Iter Mean Loss 12.2876
2020-11-05 19:05:01,060 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8576 | Iter Mean Loss 9.0726
2020-11-05 19:05:01,068 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9935 | Iter Mean Loss 17.3795
2020-11-05 19:05:01,075 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6460 | Iter Mean Loss 18.4462
2020-11-05 19:05:01,083 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.1002 | Iter Mean Loss 18.7770
2020-11-05 19:05:01,085 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.2817 | MSE 0.4828
2020-11-05 19:05:01,093 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1589 | Iter Mean Loss 12.1589
2020-11-05 19:05:01,100 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.7664 | Iter Mean Loss 8.9627
2020-11-05 19:05:01,108 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7308 | Iter Mean Loss 17.2187
2020-11-05 19:05:01,115 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4892 | Iter Mean Loss 18.2863
2020-11-05 19:05:01,122 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.9281 | Iter Mean Loss 18.6147
2020-11-05 19:05:01,124 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.2817 | MSE 0.4821
2020-11-05 19:05:01,132 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0362 | Iter Mean Loss 12.0362
2020-11-05 19:05:01,140 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6785 | Iter Mean Loss 8.8574
2020-11-05 19:05:01,148 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4727 | Iter Mean Loss 17.0625
2020-11-05 19:05:01,155 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3365 | Iter Mean Loss 18.1310
2020-11-05 19:05:01,162 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.7593 | Iter Mean Loss 18.4567
2020-11-05 19:05:01,164 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.2817 | MSE 0.4815
2020-11-05 19:05:01,172 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9197 | Iter Mean Loss 11.9197
2020-11-05 19:05:01,180 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5942 | Iter Mean Loss 8.7570
2020-11-05 19:05:01,188 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2193 | Iter Mean Loss 16.9111
2020-11-05 19:05:01,196 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1879 | Iter Mean Loss 17.9803
2020-11-05 19:05:01,204 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5939 | Iter Mean Loss 18.3030
2020-11-05 19:05:01,207 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.2817 | MSE 0.4808
2020-11-05 19:05:01,215 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8095 | Iter Mean Loss 11.8095
2020-11-05 19:05:01,224 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5136 | Iter Mean Loss 8.6615
2020-11-05 19:05:01,231 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9707 | Iter Mean Loss 16.7646
2020-11-05 19:05:01,239 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0436 | Iter Mean Loss 17.8343
2020-11-05 19:05:01,246 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.4321 | Iter Mean Loss 18.1539
2020-11-05 19:05:01,250 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.2817 | MSE 0.4801
2020-11-05 19:05:01,260 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7057 | Iter Mean Loss 11.7057
2020-11-05 19:05:01,269 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4366 | Iter Mean Loss 8.5711
2020-11-05 19:05:01,276 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7271 | Iter Mean Loss 16.6231
2020-11-05 19:05:01,287 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9036 | Iter Mean Loss 17.6932
2020-11-05 19:05:01,296 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.2740 | Iter Mean Loss 18.0094
2020-11-05 19:05:01,299 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.2817 | MSE 0.4794
2020-11-05 19:05:01,308 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6085 | Iter Mean Loss 11.6085
2020-11-05 19:05:01,317 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.3634 | Iter Mean Loss 8.4859
2020-11-05 19:05:01,327 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4886 | Iter Mean Loss 16.4868
2020-11-05 19:05:01,334 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7679 | Iter Mean Loss 17.5571
2020-11-05 19:05:01,342 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.1197 | Iter Mean Loss 17.8696
2020-11-05 19:05:01,344 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.2817 | MSE 0.4786
2020-11-05 19:05:01,353 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5178 | Iter Mean Loss 11.5178
2020-11-05 19:05:01,361 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2939 | Iter Mean Loss 8.4058
2020-11-05 19:05:01,369 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2551 | Iter Mean Loss 16.3556
2020-11-05 19:05:01,376 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6366 | Iter Mean Loss 17.4258
2020-11-05 19:05:01,385 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.9694 | Iter Mean Loss 17.7345
2020-11-05 19:05:01,388 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.2817 | MSE 0.4779
2020-11-05 19:05:01,399 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4336 | Iter Mean Loss 11.4336
2020-11-05 19:05:01,408 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2283 | Iter Mean Loss 8.3309
2020-11-05 19:05:01,415 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0266 | Iter Mean Loss 16.2295
2020-11-05 19:05:01,424 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5095 | Iter Mean Loss 17.2995
2020-11-05 19:05:01,431 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.8231 | Iter Mean Loss 17.6042
2020-11-05 19:05:01,433 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.2817 | MSE 0.4772
2020-11-05 19:05:01,441 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3558 | Iter Mean Loss 11.3558
2020-11-05 19:05:01,450 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1663 | Iter Mean Loss 8.2611
2020-11-05 19:05:01,458 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8031 | Iter Mean Loss 16.1084
2020-11-05 19:05:01,465 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3867 | Iter Mean Loss 17.1780
2020-11-05 19:05:01,472 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.6807 | Iter Mean Loss 17.4785
2020-11-05 19:05:01,474 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.2817 | MSE 0.4764
2020-11-05 19:05:01,482 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2844 | Iter Mean Loss 11.2844
2020-11-05 19:05:01,490 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 8.1962
2020-11-05 19:05:01,497 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.5845 | Iter Mean Loss 15.9923
2020-11-05 19:05:01,504 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2679 | Iter Mean Loss 17.0612
2020-11-05 19:05:01,511 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.5423 | Iter Mean Loss 17.3574
2020-11-05 19:05:01,513 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.2817 | MSE 0.4757
2020-11-05 19:05:01,521 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2192 | Iter Mean Loss 11.2192
2020-11-05 19:05:01,529 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0534 | Iter Mean Loss 8.1363
2020-11-05 19:05:01,536 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3707 | Iter Mean Loss 15.8811
2020-11-05 19:05:01,543 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1531 | Iter Mean Loss 16.9491
2020-11-05 19:05:01,550 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.4078 | Iter Mean Loss 17.2409
2020-11-05 19:05:01,552 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.2817 | MSE 0.4749
2020-11-05 19:05:01,560 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1600 | Iter Mean Loss 11.1600
2020-11-05 19:05:01,568 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0022 | Iter Mean Loss 8.0811
2020-11-05 19:05:01,575 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1615 | Iter Mean Loss 15.7746
2020-11-05 19:05:01,583 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0422 | Iter Mean Loss 16.8415
2020-11-05 19:05:01,591 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.2772 | Iter Mean Loss 17.1286
2020-11-05 19:05:01,593 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.2817 | MSE 0.4741
2020-11-05 19:05:01,601 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1065 | Iter Mean Loss 11.1065
2020-11-05 19:05:01,610 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9544 | Iter Mean Loss 8.0304
2020-11-05 19:05:01,617 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.9567 | Iter Mean Loss 15.6725
2020-11-05 19:05:01,625 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9349 | Iter Mean Loss 16.7381
2020-11-05 19:05:01,633 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.1504 | Iter Mean Loss 17.0206
2020-11-05 19:05:01,635 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.2817 | MSE 0.4734
2020-11-05 19:05:01,643 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0586 | Iter Mean Loss 11.0586
2020-11-05 19:05:01,651 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9098 | Iter Mean Loss 7.9842
2020-11-05 19:05:01,659 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7562 | Iter Mean Loss 15.5749
2020-11-05 19:05:01,666 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8310 | Iter Mean Loss 16.6389
2020-11-05 19:05:01,673 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.0272 | Iter Mean Loss 16.9166
2020-11-05 19:05:01,675 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.2817 | MSE 0.4726
2020-11-05 19:05:01,684 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0159 | Iter Mean Loss 11.0159
2020-11-05 19:05:01,691 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8683 | Iter Mean Loss 7.9421
2020-11-05 19:05:01,699 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5597 | Iter Mean Loss 15.4813
2020-11-05 19:05:01,706 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7305 | Iter Mean Loss 16.5436
2020-11-05 19:05:01,714 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9075 | Iter Mean Loss 16.8164
2020-11-05 19:05:01,716 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.2817 | MSE 0.4718
2020-11-05 19:05:01,723 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9782 | Iter Mean Loss 10.9782
2020-11-05 19:05:01,731 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8298 | Iter Mean Loss 7.9040
2020-11-05 19:05:01,738 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3670 | Iter Mean Loss 15.3917
2020-11-05 19:05:01,745 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6330 | Iter Mean Loss 16.4520
2020-11-05 19:05:01,752 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.7911 | Iter Mean Loss 16.7198
2020-11-05 19:05:01,754 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.2817 | MSE 0.4710
2020-11-05 19:05:01,762 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9452 | Iter Mean Loss 10.9452
2020-11-05 19:05:01,769 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7940 | Iter Mean Loss 7.8696
2020-11-05 19:05:01,777 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1779 | Iter Mean Loss 15.3057
2020-11-05 19:05:01,786 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5384 | Iter Mean Loss 16.3639
2020-11-05 19:05:01,794 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.6780 | Iter Mean Loss 16.6267
2020-11-05 19:05:01,796 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.2817 | MSE 0.4702
2020-11-05 19:05:01,803 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9165 | Iter Mean Loss 10.9165
2020-11-05 19:05:01,812 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7609 | Iter Mean Loss 7.8387
2020-11-05 19:05:01,821 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9922 | Iter Mean Loss 15.2232
2020-11-05 19:05:01,829 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4465 | Iter Mean Loss 16.2790
2020-11-05 19:05:01,837 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.5679 | Iter Mean Loss 16.5368
2020-11-05 19:05:01,840 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.2817 | MSE 0.4694
2020-11-05 19:05:01,849 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8920 | Iter Mean Loss 10.8920
2020-11-05 19:05:01,856 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7302 | Iter Mean Loss 7.8111
2020-11-05 19:05:01,864 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8097 | Iter Mean Loss 15.1440
2020-11-05 19:05:01,872 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3571 | Iter Mean Loss 16.1972
2020-11-05 19:05:01,880 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.4607 | Iter Mean Loss 16.4499
2020-11-05 19:05:01,882 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.2817 | MSE 0.4685
2020-11-05 19:05:01,890 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 19:05:01,897 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7018 | Iter Mean Loss 7.7865
2020-11-05 19:05:01,904 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6301 | Iter Mean Loss 15.0677
2020-11-05 19:05:01,911 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2699 | Iter Mean Loss 16.1183
2020-11-05 19:05:01,919 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.3562 | Iter Mean Loss 16.3659
2020-11-05 19:05:01,921 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.2817 | MSE 0.4677
2020-11-05 19:05:01,928 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8540 | Iter Mean Loss 10.8540
2020-11-05 19:05:01,936 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 7.7648
2020-11-05 19:05:01,943 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4533 | Iter Mean Loss 14.9943
2020-11-05 19:05:01,950 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1848 | Iter Mean Loss 16.0419
2020-11-05 19:05:01,957 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.2542 | Iter Mean Loss 16.2844
2020-11-05 19:05:01,959 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.2817 | MSE 0.4668
2020-11-05 19:05:01,967 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8400 | Iter Mean Loss 10.8400
2020-11-05 19:05:01,974 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6512 | Iter Mean Loss 7.7456
2020-11-05 19:05:01,982 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2789 | Iter Mean Loss 14.9234
2020-11-05 19:05:01,989 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1017 | Iter Mean Loss 15.9679
2020-11-05 19:05:01,996 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.1545 | Iter Mean Loss 16.2053
2020-11-05 19:05:01,998 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.2817 | MSE 0.4660
2020-11-05 19:05:02,007 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8289 | Iter Mean Loss 10.8289
2020-11-05 19:05:02,015 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6287 | Iter Mean Loss 7.7288
2020-11-05 19:05:02,022 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1069 | Iter Mean Loss 14.8548
2020-11-05 19:05:02,029 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0203 | Iter Mean Loss 15.8962
2020-11-05 19:05:02,038 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.0571 | Iter Mean Loss 16.1284
2020-11-05 19:05:02,040 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.2817 | MSE 0.4651
2020-11-05 19:05:02,048 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8205 | Iter Mean Loss 10.8205
2020-11-05 19:05:02,056 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6078 | Iter Mean Loss 7.7142
2020-11-05 19:05:02,064 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9371 | Iter Mean Loss 14.7885
2020-11-05 19:05:02,072 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9405 | Iter Mean Loss 15.8265
2020-11-05 19:05:02,079 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.9616 | Iter Mean Loss 16.0535
2020-11-05 19:05:02,081 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.2817 | MSE 0.4643
2020-11-05 19:05:02,089 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8146 | Iter Mean Loss 10.8146
2020-11-05 19:05:02,096 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5885 | Iter Mean Loss 7.7015
2020-11-05 19:05:02,104 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7693 | Iter Mean Loss 14.7241
2020-11-05 19:05:02,112 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8621 | Iter Mean Loss 15.7586
2020-11-05 19:05:02,119 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.8681 | Iter Mean Loss 15.9805
2020-11-05 19:05:02,121 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.2817 | MSE 0.4634
2020-11-05 19:05:02,129 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 19:05:02,136 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5705 | Iter Mean Loss 7.6907
2020-11-05 19:05:02,143 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6033 | Iter Mean Loss 14.6616
2020-11-05 19:05:02,151 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7850 | Iter Mean Loss 15.6924
2020-11-05 19:05:02,158 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.7762 | Iter Mean Loss 15.9092
2020-11-05 19:05:02,160 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.2817 | MSE 0.4625
2020-11-05 19:05:02,168 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8091 | Iter Mean Loss 10.8091
2020-11-05 19:05:02,175 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5538 | Iter Mean Loss 7.6815
2020-11-05 19:05:02,182 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4390 | Iter Mean Loss 14.6007
2020-11-05 19:05:02,189 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7092 | Iter Mean Loss 15.6278
2020-11-05 19:05:02,197 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6860 | Iter Mean Loss 15.8394
2020-11-05 19:05:02,199 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.2817 | MSE 0.4617
2020-11-05 19:05:02,207 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8092 | Iter Mean Loss 10.8092
2020-11-05 19:05:02,215 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5383 | Iter Mean Loss 7.6738
2020-11-05 19:05:02,223 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2763 | Iter Mean Loss 14.5413
2020-11-05 19:05:02,231 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6344 | Iter Mean Loss 15.5646
2020-11-05 19:05:02,239 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5972 | Iter Mean Loss 15.7711
2020-11-05 19:05:02,241 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.2817 | MSE 0.4608
2020-11-05 19:05:02,249 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 19:05:02,257 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5238 | Iter Mean Loss 7.6673
2020-11-05 19:05:02,265 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1151 | Iter Mean Loss 14.4833
2020-11-05 19:05:02,272 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5606 | Iter Mean Loss 15.5026
2020-11-05 19:05:02,279 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5098 | Iter Mean Loss 15.7040
2020-11-05 19:05:02,281 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.2817 | MSE 0.4599
2020-11-05 19:05:02,289 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8140 | Iter Mean Loss 10.8140
2020-11-05 19:05:02,297 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 7.6621
2020-11-05 19:05:02,304 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9552 | Iter Mean Loss 14.4265
2020-11-05 19:05:02,311 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4877 | Iter Mean Loss 15.4418
2020-11-05 19:05:02,319 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.4236 | Iter Mean Loss 15.6382
2020-11-05 19:05:02,322 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.2817 | MSE 0.4590
2020-11-05 19:05:02,330 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8184 | Iter Mean Loss 10.8184
2020-11-05 19:05:02,338 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4975 | Iter Mean Loss 7.6580
2020-11-05 19:05:02,345 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7967 | Iter Mean Loss 14.3709
2020-11-05 19:05:02,352 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4156 | Iter Mean Loss 15.3820
2020-11-05 19:05:02,359 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.3386 | Iter Mean Loss 15.5734
2020-11-05 19:05:02,361 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.2817 | MSE 0.4581
2020-11-05 19:05:02,369 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8240 | Iter Mean Loss 10.8240
2020-11-05 19:05:02,376 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4856 | Iter Mean Loss 7.6548
2020-11-05 19:05:02,384 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6393 | Iter Mean Loss 14.3163
2020-11-05 19:05:02,391 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3442 | Iter Mean Loss 15.3233
2020-11-05 19:05:02,399 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.2546 | Iter Mean Loss 15.5095
2020-11-05 19:05:02,401 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.2817 | MSE 0.4572
2020-11-05 19:05:02,409 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8305 | Iter Mean Loss 10.8305
2020-11-05 19:05:02,416 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4743 | Iter Mean Loss 7.6524
2020-11-05 19:05:02,424 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4831 | Iter Mean Loss 14.2626
2020-11-05 19:05:02,432 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2736 | Iter Mean Loss 15.2654
2020-11-05 19:05:02,439 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.1716 | Iter Mean Loss 15.4466
2020-11-05 19:05:02,441 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.2817 | MSE 0.4563
2020-11-05 19:05:02,448 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8379 | Iter Mean Loss 10.8379
2020-11-05 19:05:02,456 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4637 | Iter Mean Loss 7.6508
2020-11-05 19:05:02,464 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3279 | Iter Mean Loss 14.2098
2020-11-05 19:05:02,471 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2035 | Iter Mean Loss 15.2083
2020-11-05 19:05:02,480 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0894 | Iter Mean Loss 15.3845
2020-11-05 19:05:02,482 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.2817 | MSE 0.4554
2020-11-05 19:05:02,490 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 10.8461
2020-11-05 19:05:02,497 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4536 | Iter Mean Loss 7.6499
2020-11-05 19:05:02,504 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1738 | Iter Mean Loss 14.1579
2020-11-05 19:05:02,511 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1341 | Iter Mean Loss 15.1519
2020-11-05 19:05:02,518 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0081 | Iter Mean Loss 15.3232
2020-11-05 19:05:02,520 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.2817 | MSE 0.4544
2020-11-05 19:05:02,528 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8550 | Iter Mean Loss 10.8550
2020-11-05 19:05:02,535 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4440 | Iter Mean Loss 7.6495
2020-11-05 19:05:02,542 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0207 | Iter Mean Loss 14.1066
2020-11-05 19:05:02,549 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 15.0962
2020-11-05 19:05:02,556 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.9276 | Iter Mean Loss 15.2625
2020-11-05 19:05:02,558 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.2817 | MSE 0.4535
2020-11-05 19:05:02,566 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8645 | Iter Mean Loss 10.8645
2020-11-05 19:05:02,573 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4349 | Iter Mean Loss 7.6497
2020-11-05 19:05:02,581 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8685 | Iter Mean Loss 14.0560
2020-11-05 19:05:02,588 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9969 | Iter Mean Loss 15.0412
2020-11-05 19:05:02,595 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.8477 | Iter Mean Loss 15.2025
2020-11-05 19:05:02,597 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.2817 | MSE 0.4526
2020-11-05 19:05:02,606 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8745 | Iter Mean Loss 10.8745
2020-11-05 19:05:02,613 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4262 | Iter Mean Loss 7.6504
2020-11-05 19:05:02,621 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7173 | Iter Mean Loss 14.0060
2020-11-05 19:05:02,628 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9290 | Iter Mean Loss 14.9868
2020-11-05 19:05:02,636 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.7685 | Iter Mean Loss 15.1431
2020-11-05 19:05:02,638 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.2817 | MSE 0.4517
2020-11-05 19:05:02,646 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8849 | Iter Mean Loss 10.8849
2020-11-05 19:05:02,654 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 7.6514
2020-11-05 19:05:02,662 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5669 | Iter Mean Loss 13.9566
2020-11-05 19:05:02,669 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8617 | Iter Mean Loss 14.9329
2020-11-05 19:05:02,676 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6900 | Iter Mean Loss 15.0843
2020-11-05 19:05:02,678 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.2817 | MSE 0.4508
2020-11-05 19:05:02,687 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8957 | Iter Mean Loss 10.8957
2020-11-05 19:05:02,695 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4099 | Iter Mean Loss 7.6528
2020-11-05 19:05:02,703 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4174 | Iter Mean Loss 13.9077
2020-11-05 19:05:02,710 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7948 | Iter Mean Loss 14.8795
2020-11-05 19:05:02,717 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6120 | Iter Mean Loss 15.0260
2020-11-05 19:05:02,719 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.2817 | MSE 0.4498
2020-11-05 19:05:02,727 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9069 | Iter Mean Loss 10.9069
2020-11-05 19:05:02,734 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4022 | Iter Mean Loss 7.6545
2020-11-05 19:05:02,741 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2688 | Iter Mean Loss 13.8593
2020-11-05 19:05:02,749 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7283 | Iter Mean Loss 14.8265
2020-11-05 19:05:02,756 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5345 | Iter Mean Loss 14.9681
2020-11-05 19:05:02,758 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.2817 | MSE 0.4489
2020-11-05 19:05:02,765 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9183 | Iter Mean Loss 10.9183
2020-11-05 19:05:02,773 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3948 | Iter Mean Loss 7.6565
2020-11-05 19:05:02,780 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1211 | Iter Mean Loss 13.8114
2020-11-05 19:05:02,787 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6622 | Iter Mean Loss 14.7741
2020-11-05 19:05:02,795 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.4576 | Iter Mean Loss 14.9108
2020-11-05 19:05:02,797 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.2817 | MSE 0.4480
2020-11-05 19:05:02,805 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9299 | Iter Mean Loss 10.9299
2020-11-05 19:05:02,814 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3876 | Iter Mean Loss 7.6587
2020-11-05 19:05:02,821 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9742 | Iter Mean Loss 13.7639
2020-11-05 19:05:02,829 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5966 | Iter Mean Loss 14.7221
2020-11-05 19:05:02,836 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3811 | Iter Mean Loss 14.8539
2020-11-05 19:05:02,839 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.2817 | MSE 0.4471
2020-11-05 19:05:02,847 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9416 | Iter Mean Loss 10.9416
2020-11-05 19:05:02,855 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3807 | Iter Mean Loss 7.6612
2020-11-05 19:05:02,863 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8281 | Iter Mean Loss 13.7168
2020-11-05 19:05:02,870 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5314 | Iter Mean Loss 14.6705
2020-11-05 19:05:02,878 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3051 | Iter Mean Loss 14.7974
2020-11-05 19:05:02,880 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.2817 | MSE 0.4461
2020-11-05 19:05:02,887 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9536 | Iter Mean Loss 10.9536
2020-11-05 19:05:02,895 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3739 | Iter Mean Loss 7.6638
2020-11-05 19:05:02,902 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6829 | Iter Mean Loss 13.6701
2020-11-05 19:05:02,909 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4666 | Iter Mean Loss 14.6192
2020-11-05 19:05:02,916 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.2295 | Iter Mean Loss 14.7413
2020-11-05 19:05:02,918 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.2817 | MSE 0.4452
2020-11-05 19:05:02,926 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9656 | Iter Mean Loss 10.9656
2020-11-05 19:05:02,933 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3674 | Iter Mean Loss 7.6665
2020-11-05 19:05:02,941 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5385 | Iter Mean Loss 13.6238
2020-11-05 19:05:02,948 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4022 | Iter Mean Loss 14.5684
2020-11-05 19:05:02,955 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.1544 | Iter Mean Loss 14.6856
2020-11-05 19:05:02,957 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.2817 | MSE 0.4443
2020-11-05 19:05:02,965 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9776 | Iter Mean Loss 10.9776
2020-11-05 19:05:02,972 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3610 | Iter Mean Loss 7.6693
2020-11-05 19:05:02,979 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3949 | Iter Mean Loss 13.5779
2020-11-05 19:05:02,987 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3382 | Iter Mean Loss 14.5179
2020-11-05 19:05:02,994 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0796 | Iter Mean Loss 14.6303
2020-11-05 19:05:02,996 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.2817 | MSE 0.4433
2020-11-05 19:05:03,005 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9897 | Iter Mean Loss 10.9897
2020-11-05 19:05:03,012 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3548 | Iter Mean Loss 7.6723
2020-11-05 19:05:03,019 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2522 | Iter Mean Loss 13.5322
2020-11-05 19:05:03,027 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2746 | Iter Mean Loss 14.4678
2020-11-05 19:05:03,035 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0053 | Iter Mean Loss 14.5753
2020-11-05 19:05:03,037 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.2817 | MSE 0.4424
2020-11-05 19:05:03,045 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0019 | Iter Mean Loss 11.0019
2020-11-05 19:05:03,053 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3487 | Iter Mean Loss 7.6753
2020-11-05 19:05:03,061 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1103 | Iter Mean Loss 13.4870
2020-11-05 19:05:03,068 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2114 | Iter Mean Loss 14.4181
2020-11-05 19:05:03,075 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.9313 | Iter Mean Loss 14.5207
2020-11-05 19:05:03,077 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.2817 | MSE 0.4415
2020-11-05 19:05:03,085 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 11.0139
2020-11-05 19:05:03,094 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3428 | Iter Mean Loss 7.6784
2020-11-05 19:05:03,101 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9693 | Iter Mean Loss 13.4420
2020-11-05 19:05:03,109 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1485 | Iter Mean Loss 14.3686
2020-11-05 19:05:03,116 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.8577 | Iter Mean Loss 14.4664
2020-11-05 19:05:03,118 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.2817 | MSE 0.4406
2020-11-05 19:05:03,126 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0260 | Iter Mean Loss 11.0260
2020-11-05 19:05:03,133 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3370 | Iter Mean Loss 7.6815
2020-11-05 19:05:03,141 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8291 | Iter Mean Loss 13.3974
2020-11-05 19:05:03,148 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0861 | Iter Mean Loss 14.3195
2020-11-05 19:05:03,155 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7844 | Iter Mean Loss 14.4125
2020-11-05 19:05:03,157 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.2817 | MSE 0.4396
2020-11-05 19:05:03,164 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0380 | Iter Mean Loss 11.0380
2020-11-05 19:05:03,172 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3312 | Iter Mean Loss 7.6846
2020-11-05 19:05:03,179 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6898 | Iter Mean Loss 13.3530
2020-11-05 19:05:03,186 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0241 | Iter Mean Loss 14.2708
2020-11-05 19:05:03,193 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7115 | Iter Mean Loss 14.3589
2020-11-05 19:05:03,195 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.2817 | MSE 0.4387
2020-11-05 19:05:03,203 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0499 | Iter Mean Loss 11.0499
2020-11-05 19:05:03,211 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3256 | Iter Mean Loss 7.6878
2020-11-05 19:05:03,218 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5513 | Iter Mean Loss 13.3090
2020-11-05 19:05:03,225 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9624 | Iter Mean Loss 14.2223
2020-11-05 19:05:03,232 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.6390 | Iter Mean Loss 14.3057
2020-11-05 19:05:03,234 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.2817 | MSE 0.4378
2020-11-05 19:05:03,243 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0617 | Iter Mean Loss 11.0617
2020-11-05 19:05:03,250 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 7.6909
2020-11-05 19:05:03,259 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4137 | Iter Mean Loss 13.2652
2020-11-05 19:05:03,266 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9011 | Iter Mean Loss 14.1742
2020-11-05 19:05:03,273 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5668 | Iter Mean Loss 14.2527
2020-11-05 19:05:03,275 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.2817 | MSE 0.4369
2020-11-05 19:05:03,283 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0734 | Iter Mean Loss 11.0734
2020-11-05 19:05:03,292 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3147 | Iter Mean Loss 7.6941
2020-11-05 19:05:03,299 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2770 | Iter Mean Loss 13.2217
2020-11-05 19:05:03,306 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8403 | Iter Mean Loss 14.1263
2020-11-05 19:05:03,315 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4949 | Iter Mean Loss 14.2001
2020-11-05 19:05:03,317 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.2817 | MSE 0.4360
2020-11-05 19:05:03,326 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0850 | Iter Mean Loss 11.0850
2020-11-05 19:05:03,334 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3094 | Iter Mean Loss 7.6972
2020-11-05 19:05:03,341 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1411 | Iter Mean Loss 13.1785
2020-11-05 19:05:03,348 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7798 | Iter Mean Loss 14.0788
2020-11-05 19:05:03,355 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4233 | Iter Mean Loss 14.1477
2020-11-05 19:05:03,357 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.2817 | MSE 0.4350
2020-11-05 19:05:03,365 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0964 | Iter Mean Loss 11.0964
2020-11-05 19:05:03,372 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3041 | Iter Mean Loss 7.7003
2020-11-05 19:05:03,379 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0062 | Iter Mean Loss 13.1356
2020-11-05 19:05:03,386 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7197 | Iter Mean Loss 14.0316
2020-11-05 19:05:03,393 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.3521 | Iter Mean Loss 14.0957
2020-11-05 19:05:03,395 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.2817 | MSE 0.4341
2020-11-05 19:05:03,403 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.1076
2020-11-05 19:05:03,411 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 7.7033
2020-11-05 19:05:03,418 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8721 | Iter Mean Loss 13.0929
2020-11-05 19:05:03,425 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6600 | Iter Mean Loss 13.9846
2020-11-05 19:05:03,433 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2812 | Iter Mean Loss 14.0440
2020-11-05 19:05:03,435 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.2817 | MSE 0.4332
2020-11-05 19:05:03,443 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1187 | Iter Mean Loss 11.1187
2020-11-05 19:05:03,451 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2938 | Iter Mean Loss 7.7063
2020-11-05 19:05:03,459 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7389 | Iter Mean Loss 13.0505
2020-11-05 19:05:03,466 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6006 | Iter Mean Loss 13.9380
2020-11-05 19:05:03,474 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2106 | Iter Mean Loss 13.9925
2020-11-05 19:05:03,477 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.2817 | MSE 0.4323
2020-11-05 19:05:03,485 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1296 | Iter Mean Loss 11.1296
2020-11-05 19:05:03,492 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2888 | Iter Mean Loss 7.7092
2020-11-05 19:05:03,499 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6065 | Iter Mean Loss 13.0083
2020-11-05 19:05:03,506 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5417 | Iter Mean Loss 13.8917
2020-11-05 19:05:03,514 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.1404 | Iter Mean Loss 13.9414
2020-11-05 19:05:03,516 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.2817 | MSE 0.4314
2020-11-05 19:05:03,523 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1403 | Iter Mean Loss 11.1403
2020-11-05 19:05:03,530 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2838 | Iter Mean Loss 7.7120
2020-11-05 19:05:03,538 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4751 | Iter Mean Loss 12.9664
2020-11-05 19:05:03,545 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4831 | Iter Mean Loss 13.8456
2020-11-05 19:05:03,552 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0704 | Iter Mean Loss 13.8906
2020-11-05 19:05:03,554 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.2817 | MSE 0.4305
2020-11-05 19:05:03,562 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1508 | Iter Mean Loss 11.1508
2020-11-05 19:05:03,569 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 7.7148
2020-11-05 19:05:03,576 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3446 | Iter Mean Loss 12.9247
2020-11-05 19:05:03,583 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4250 | Iter Mean Loss 13.7998
2020-11-05 19:05:03,590 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0008 | Iter Mean Loss 13.8400
2020-11-05 19:05:03,592 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.2817 | MSE 0.4296
2020-11-05 19:05:03,600 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1611 | Iter Mean Loss 11.1611
2020-11-05 19:05:03,608 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2739 | Iter Mean Loss 7.7175
2020-11-05 19:05:03,616 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2150 | Iter Mean Loss 12.8833
2020-11-05 19:05:03,623 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3672 | Iter Mean Loss 13.7543
2020-11-05 19:05:03,630 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.9315 | Iter Mean Loss 13.7897
2020-11-05 19:05:03,632 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.2817 | MSE 0.4287
2020-11-05 19:05:03,640 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1711 | Iter Mean Loss 11.1711
2020-11-05 19:05:03,648 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2691 | Iter Mean Loss 7.7201
2020-11-05 19:05:03,656 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0863 | Iter Mean Loss 12.8422
2020-11-05 19:05:03,663 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3098 | Iter Mean Loss 13.7091
2020-11-05 19:05:03,671 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.8625 | Iter Mean Loss 13.7398
2020-11-05 19:05:03,674 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.2817 | MSE 0.4278
2020-11-05 19:05:03,682 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1809 | Iter Mean Loss 11.1809
2020-11-05 19:05:03,690 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2643 | Iter Mean Loss 7.7226
2020-11-05 19:05:03,698 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9586 | Iter Mean Loss 12.8013
2020-11-05 19:05:03,706 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2528 | Iter Mean Loss 13.6641
2020-11-05 19:05:03,714 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.6901
2020-11-05 19:05:03,716 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.2817 | MSE 0.4270
2020-11-05 19:05:03,724 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1905 | Iter Mean Loss 11.1905
2020-11-05 19:05:03,732 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 7.7250
2020-11-05 19:05:03,739 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8317 | Iter Mean Loss 12.7606
2020-11-05 19:05:03,746 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1962 | Iter Mean Loss 13.6195
2020-11-05 19:05:03,753 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7255 | Iter Mean Loss 13.6407
2020-11-05 19:05:03,755 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.2817 | MSE 0.4261
2020-11-05 19:05:03,763 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1998 | Iter Mean Loss 11.1998
2020-11-05 19:05:03,770 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 7.7273
2020-11-05 19:05:03,777 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7058 | Iter Mean Loss 12.7201
2020-11-05 19:05:03,784 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1399 | Iter Mean Loss 13.5751
2020-11-05 19:05:03,792 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.6575 | Iter Mean Loss 13.5916
2020-11-05 19:05:03,793 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.2817 | MSE 0.4252
2020-11-05 19:05:03,801 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2088 | Iter Mean Loss 11.2088
2020-11-05 19:05:03,808 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2502 | Iter Mean Loss 7.7295
2020-11-05 19:05:03,816 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5808 | Iter Mean Loss 12.6799
2020-11-05 19:05:03,823 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0841 | Iter Mean Loss 13.5310
2020-11-05 19:05:03,830 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5898 | Iter Mean Loss 13.5427
2020-11-05 19:05:03,833 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.2817 | MSE 0.4243
2020-11-05 19:05:03,841 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2176 | Iter Mean Loss 11.2176
2020-11-05 19:05:03,848 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2456 | Iter Mean Loss 7.7316
2020-11-05 19:05:03,856 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4567 | Iter Mean Loss 12.6400
2020-11-05 19:05:03,864 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0286 | Iter Mean Loss 13.4871
2020-11-05 19:05:03,871 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5224 | Iter Mean Loss 13.4942
2020-11-05 19:05:03,874 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.2817 | MSE 0.4235
2020-11-05 19:05:03,882 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2261 | Iter Mean Loss 11.2261
2020-11-05 19:05:03,889 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2410 | Iter Mean Loss 7.7336
2020-11-05 19:05:03,896 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3335 | Iter Mean Loss 12.6002
2020-11-05 19:05:03,904 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9735 | Iter Mean Loss 13.4435
2020-11-05 19:05:03,912 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.4554 | Iter Mean Loss 13.4459
2020-11-05 19:05:03,914 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.2817 | MSE 0.4226
2020-11-05 19:05:03,922 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2343 | Iter Mean Loss 11.2343
2020-11-05 19:05:03,929 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 7.7354
2020-11-05 19:05:03,937 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2113 | Iter Mean Loss 12.5607
2020-11-05 19:05:03,944 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9187 | Iter Mean Loss 13.4002
2020-11-05 19:05:03,951 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3886 | Iter Mean Loss 13.3979
2020-11-05 19:05:03,953 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.2817 | MSE 0.4217
2020-11-05 19:05:03,961 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2423 | Iter Mean Loss 11.2423
2020-11-05 19:05:03,968 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2319 | Iter Mean Loss 7.7371
2020-11-05 19:05:03,975 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0900 | Iter Mean Loss 12.5214
2020-11-05 19:05:03,982 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8644 | Iter Mean Loss 13.3571
2020-11-05 19:05:03,989 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3222 | Iter Mean Loss 13.3502
2020-11-05 19:05:03,991 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.2817 | MSE 0.4209
2020-11-05 19:05:03,999 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2499 | Iter Mean Loss 11.2499
2020-11-05 19:05:04,006 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2274 | Iter Mean Loss 7.7387
2020-11-05 19:05:04,013 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9697 | Iter Mean Loss 12.4823
2020-11-05 19:05:04,020 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8104 | Iter Mean Loss 13.3143
2020-11-05 19:05:04,028 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.2561 | Iter Mean Loss 13.3027
2020-11-05 19:05:04,030 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.2817 | MSE 0.4200
2020-11-05 19:05:04,038 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2573 | Iter Mean Loss 11.2573
2020-11-05 19:05:04,046 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2229 | Iter Mean Loss 7.7401
2020-11-05 19:05:04,054 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8502 | Iter Mean Loss 12.4435
2020-11-05 19:05:04,062 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7568 | Iter Mean Loss 13.2718
2020-11-05 19:05:04,069 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1904 | Iter Mean Loss 13.2555
2020-11-05 19:05:04,072 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.2817 | MSE 0.4192
2020-11-05 19:05:04,079 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2643 | Iter Mean Loss 11.2643
2020-11-05 19:05:04,087 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2185 | Iter Mean Loss 7.7414
2020-11-05 19:05:04,095 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7318 | Iter Mean Loss 12.4049
2020-11-05 19:05:04,103 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7035 | Iter Mean Loss 13.2295
2020-11-05 19:05:04,110 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1250 | Iter Mean Loss 13.2086
2020-11-05 19:05:04,113 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.2817 | MSE 0.4184
2020-11-05 19:05:04,122 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2711 | Iter Mean Loss 11.2711
2020-11-05 19:05:04,129 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2141 | Iter Mean Loss 7.7426
2020-11-05 19:05:04,136 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6142 | Iter Mean Loss 12.3665
2020-11-05 19:05:04,143 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6507 | Iter Mean Loss 13.1875
2020-11-05 19:05:04,150 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.0599 | Iter Mean Loss 13.1620
2020-11-05 19:05:04,152 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.2817 | MSE 0.4175
2020-11-05 19:05:04,160 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2775 | Iter Mean Loss 11.2775
2020-11-05 19:05:04,167 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2097 | Iter Mean Loss 7.7436
2020-11-05 19:05:04,175 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4976 | Iter Mean Loss 12.3283
2020-11-05 19:05:04,182 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5982 | Iter Mean Loss 13.1457
2020-11-05 19:05:04,189 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9951 | Iter Mean Loss 13.1156
2020-11-05 19:05:04,191 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.2817 | MSE 0.4167
2020-11-05 19:05:04,199 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2837 | Iter Mean Loss 11.2837
2020-11-05 19:05:04,206 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2053 | Iter Mean Loss 7.7445
2020-11-05 19:05:04,213 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3819 | Iter Mean Loss 12.2903
2020-11-05 19:05:04,220 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5460 | Iter Mean Loss 13.1042
2020-11-05 19:05:04,228 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9307 | Iter Mean Loss 13.0695
2020-11-05 19:05:04,230 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.2817 | MSE 0.4159
2020-11-05 19:05:04,237 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2895 | Iter Mean Loss 11.2895
2020-11-05 19:05:04,245 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2009 | Iter Mean Loss 7.7452
2020-11-05 19:05:04,253 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2671 | Iter Mean Loss 12.2525
2020-11-05 19:05:04,260 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4942 | Iter Mean Loss 13.0629
2020-11-05 19:05:04,268 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8666 | Iter Mean Loss 13.0237
2020-11-05 19:05:04,271 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.2817 | MSE 0.4150
2020-11-05 19:05:04,279 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2950 | Iter Mean Loss 11.2950
2020-11-05 19:05:04,287 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1966 | Iter Mean Loss 7.7458
2020-11-05 19:05:04,294 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1533 | Iter Mean Loss 12.2150
2020-11-05 19:05:04,302 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4428 | Iter Mean Loss 13.0219
2020-11-05 19:05:04,309 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8028 | Iter Mean Loss 12.9781
2020-11-05 19:05:04,311 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.2817 | MSE 0.4142
2020-11-05 19:05:04,320 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3002 | Iter Mean Loss 11.3002
2020-11-05 19:05:04,329 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1923 | Iter Mean Loss 7.7462
2020-11-05 19:05:04,336 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0404 | Iter Mean Loss 12.1776
2020-11-05 19:05:04,343 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3918 | Iter Mean Loss 12.9811
2020-11-05 19:05:04,350 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.7394 | Iter Mean Loss 12.9328
2020-11-05 19:05:04,353 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.2817 | MSE 0.4134
2020-11-05 19:05:04,360 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3050 | Iter Mean Loss 11.3050
2020-11-05 19:05:04,368 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1880 | Iter Mean Loss 7.7465
2020-11-05 19:05:04,375 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9284 | Iter Mean Loss 12.1405
2020-11-05 19:05:04,382 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3411 | Iter Mean Loss 12.9406
2020-11-05 19:05:04,389 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6763 | Iter Mean Loss 12.8878
2020-11-05 19:05:04,391 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.2817 | MSE 0.4126
2020-11-05 19:05:04,399 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3096 | Iter Mean Loss 11.3096
2020-11-05 19:05:04,406 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 7.7466
2020-11-05 19:05:04,418 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8174 | Iter Mean Loss 12.1035
2020-11-05 19:05:04,430 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2907 | Iter Mean Loss 12.9003
2020-11-05 19:05:04,441 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6136 | Iter Mean Loss 12.8430
2020-11-05 19:05:04,444 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.2817 | MSE 0.4118
2020-11-05 19:05:04,454 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3138 | Iter Mean Loss 11.3138
2020-11-05 19:05:04,462 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1794 | Iter Mean Loss 7.7466
2020-11-05 19:05:04,472 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7072 | Iter Mean Loss 12.0668
2020-11-05 19:05:04,480 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2407 | Iter Mean Loss 12.8603
2020-11-05 19:05:04,489 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.5512 | Iter Mean Loss 12.7985
2020-11-05 19:05:04,492 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.2817 | MSE 0.4110
2020-11-05 19:05:04,500 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3177 | Iter Mean Loss 11.3177
2020-11-05 19:05:04,509 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1751 | Iter Mean Loss 7.7464
2020-11-05 19:05:04,517 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5980 | Iter Mean Loss 12.0303
2020-11-05 19:05:04,527 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1911 | Iter Mean Loss 12.8205
2020-11-05 19:05:04,537 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4891 | Iter Mean Loss 12.7542
2020-11-05 19:05:04,539 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.2817 | MSE 0.4102
2020-11-05 19:05:04,549 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3212 | Iter Mean Loss 11.3212
2020-11-05 19:05:04,558 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1709 | Iter Mean Loss 7.7460
2020-11-05 19:05:04,566 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4897 | Iter Mean Loss 11.9939
2020-11-05 19:05:04,573 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1418 | Iter Mean Loss 12.7809
2020-11-05 19:05:04,581 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4274 | Iter Mean Loss 12.7102
2020-11-05 19:05:04,583 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.2817 | MSE 0.4095
2020-11-05 19:05:04,590 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3244 | Iter Mean Loss 11.3244
2020-11-05 19:05:04,598 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1666 | Iter Mean Loss 7.7455
2020-11-05 19:05:04,605 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3824 | Iter Mean Loss 11.9578
2020-11-05 19:05:04,613 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0928 | Iter Mean Loss 12.7416
2020-11-05 19:05:04,620 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3661 | Iter Mean Loss 12.6665
2020-11-05 19:05:04,622 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.2817 | MSE 0.4087
2020-11-05 19:05:04,630 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3273 | Iter Mean Loss 11.3273
2020-11-05 19:05:04,638 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1624 | Iter Mean Loss 7.7449
2020-11-05 19:05:04,645 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2759 | Iter Mean Loss 11.9219
2020-11-05 19:05:04,653 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0442 | Iter Mean Loss 12.7025
2020-11-05 19:05:04,660 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3051 | Iter Mean Loss 12.6230
2020-11-05 19:05:04,662 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.2817 | MSE 0.4079
2020-11-05 19:05:04,670 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3299 | Iter Mean Loss 11.3299
2020-11-05 19:05:04,679 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1582 | Iter Mean Loss 7.7440
2020-11-05 19:05:04,687 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1703 | Iter Mean Loss 11.8861
2020-11-05 19:05:04,696 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9960 | Iter Mean Loss 12.6636
2020-11-05 19:05:04,704 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.2444 | Iter Mean Loss 12.5798
2020-11-05 19:05:04,706 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.2817 | MSE 0.4072
2020-11-05 19:05:04,716 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3321 | Iter Mean Loss 11.3321
2020-11-05 19:05:04,724 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1540 | Iter Mean Loss 7.7431
2020-11-05 19:05:04,733 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0657 | Iter Mean Loss 11.8506
2020-11-05 19:05:04,742 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9480 | Iter Mean Loss 12.6250
2020-11-05 19:05:04,751 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1841 | Iter Mean Loss 12.5368
2020-11-05 19:05:04,754 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.2817 | MSE 0.4064
2020-11-05 19:05:04,762 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3340 | Iter Mean Loss 11.3340
2020-11-05 19:05:04,771 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1498 | Iter Mean Loss 7.7419
2020-11-05 19:05:04,779 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9620 | Iter Mean Loss 11.8153
2020-11-05 19:05:04,786 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9004 | Iter Mean Loss 12.5866
2020-11-05 19:05:04,794 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1242 | Iter Mean Loss 12.4941
2020-11-05 19:05:04,796 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.2817 | MSE 0.4056
2020-11-05 19:05:04,804 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3356 | Iter Mean Loss 11.3356
2020-11-05 19:05:04,812 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1456 | Iter Mean Loss 7.7406
2020-11-05 19:05:04,820 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8591 | Iter Mean Loss 11.7801
2020-11-05 19:05:04,828 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8532 | Iter Mean Loss 12.5484
2020-11-05 19:05:04,837 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0646 | Iter Mean Loss 12.4516
2020-11-05 19:05:04,839 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.2817 | MSE 0.4049
2020-11-05 19:05:04,847 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3368 | Iter Mean Loss 11.3368
2020-11-05 19:05:04,857 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1414 | Iter Mean Loss 7.7391
2020-11-05 19:05:04,865 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7571 | Iter Mean Loss 11.7451
2020-11-05 19:05:04,874 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8063 | Iter Mean Loss 12.5104
2020-11-05 19:05:04,883 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0053 | Iter Mean Loss 12.4094
2020-11-05 19:05:04,885 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.2817 | MSE 0.4042
2020-11-05 19:05:04,893 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3378 | Iter Mean Loss 11.3378
2020-11-05 19:05:04,902 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1372 | Iter Mean Loss 7.7375
2020-11-05 19:05:04,910 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6561 | Iter Mean Loss 11.7103
2020-11-05 19:05:04,917 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7597 | Iter Mean Loss 12.4727
2020-11-05 19:05:04,925 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.9465 | Iter Mean Loss 12.3674
2020-11-05 19:05:04,927 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.2817 | MSE 0.4034
2020-11-05 19:05:04,936 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3383 | Iter Mean Loss 11.3383
2020-11-05 19:05:04,944 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1330 | Iter Mean Loss 7.7357
2020-11-05 19:05:04,951 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5559 | Iter Mean Loss 11.6757
2020-11-05 19:05:04,959 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7135 | Iter Mean Loss 12.4352
2020-11-05 19:05:04,967 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8880 | Iter Mean Loss 12.3257
2020-11-05 19:05:04,969 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.2817 | MSE 0.4027
2020-11-05 19:05:04,977 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3386 | Iter Mean Loss 11.3386
2020-11-05 19:05:04,985 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 7.7337
2020-11-05 19:05:04,992 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4566 | Iter Mean Loss 11.6413
2020-11-05 19:05:04,999 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6676 | Iter Mean Loss 12.3979
2020-11-05 19:05:05,007 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8298 | Iter Mean Loss 12.2843
2020-11-05 19:05:05,009 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.2817 | MSE 0.4020
2020-11-05 19:05:05,018 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3385 | Iter Mean Loss 11.3385
2020-11-05 19:05:05,025 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1246 | Iter Mean Loss 7.7316
2020-11-05 19:05:05,033 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3582 | Iter Mean Loss 11.6071
2020-11-05 19:05:05,041 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6220 | Iter Mean Loss 12.3608
2020-11-05 19:05:05,048 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7720 | Iter Mean Loss 12.2431
2020-11-05 19:05:05,050 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.2817 | MSE 0.4012
2020-11-05 19:05:05,059 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3381 | Iter Mean Loss 11.3381
2020-11-05 19:05:05,067 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1204 | Iter Mean Loss 7.7293
2020-11-05 19:05:05,076 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2606 | Iter Mean Loss 11.5731
2020-11-05 19:05:05,084 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5767 | Iter Mean Loss 12.3240
2020-11-05 19:05:05,092 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7146 | Iter Mean Loss 12.2021
2020-11-05 19:05:05,095 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.2817 | MSE 0.4005
2020-11-05 19:05:05,105 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3374 | Iter Mean Loss 11.3374
2020-11-05 19:05:05,114 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1163 | Iter Mean Loss 7.7268
2020-11-05 19:05:05,123 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1639 | Iter Mean Loss 11.5392
2020-11-05 19:05:05,134 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5317 | Iter Mean Loss 12.2873
2020-11-05 19:05:05,142 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6576 | Iter Mean Loss 12.1614
2020-11-05 19:05:05,146 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.2817 | MSE 0.3998
2020-11-05 19:05:05,155 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3364 | Iter Mean Loss 11.3364
2020-11-05 19:05:05,165 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1121 | Iter Mean Loss 7.7242
2020-11-05 19:05:05,174 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0681 | Iter Mean Loss 11.5055
2020-11-05 19:05:05,183 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4871 | Iter Mean Loss 12.2509
2020-11-05 19:05:05,192 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6009 | Iter Mean Loss 12.1209
2020-11-05 19:05:05,196 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.2817 | MSE 0.3991
2020-11-05 19:05:05,205 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3350 | Iter Mean Loss 11.3350
2020-11-05 19:05:05,215 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1079 | Iter Mean Loss 7.7215
2020-11-05 19:05:05,224 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9731 | Iter Mean Loss 11.4720
2020-11-05 19:05:05,234 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4428 | Iter Mean Loss 12.2147
2020-11-05 19:05:05,244 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.5446 | Iter Mean Loss 12.0807
2020-11-05 19:05:05,248 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.2817 | MSE 0.3984
2020-11-05 19:05:05,257 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3334 | Iter Mean Loss 11.3334
2020-11-05 19:05:05,267 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1037 | Iter Mean Loss 7.7185
2020-11-05 19:05:05,277 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8790 | Iter Mean Loss 11.4387
2020-11-05 19:05:05,287 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3988 | Iter Mean Loss 12.1787
2020-11-05 19:05:05,297 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4887 | Iter Mean Loss 12.0407
2020-11-05 19:05:05,300 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.2817 | MSE 0.3977
2020-11-05 19:05:05,309 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3314 | Iter Mean Loss 11.3314
2020-11-05 19:05:05,320 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0995 | Iter Mean Loss 7.7154
2020-11-05 19:05:05,329 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7857 | Iter Mean Loss 11.4055
2020-11-05 19:05:05,338 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3551 | Iter Mean Loss 12.1429
2020-11-05 19:05:05,348 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4331 | Iter Mean Loss 12.0010
2020-11-05 19:05:05,350 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.2817 | MSE 0.3970
2020-11-05 19:05:05,359 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3290 | Iter Mean Loss 11.3290
2020-11-05 19:05:05,368 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0953 | Iter Mean Loss 7.7122
2020-11-05 19:05:05,376 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6933 | Iter Mean Loss 11.3726
2020-11-05 19:05:05,385 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3118 | Iter Mean Loss 12.1074
2020-11-05 19:05:05,393 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3779 | Iter Mean Loss 11.9615
2020-11-05 19:05:05,397 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.2817 | MSE 0.3963
2020-11-05 19:05:05,406 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3264 | Iter Mean Loss 11.3264
2020-11-05 19:05:05,415 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0911 | Iter Mean Loss 7.7088
2020-11-05 19:05:05,424 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6017 | Iter Mean Loss 11.3397
2020-11-05 19:05:05,433 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2687 | Iter Mean Loss 12.0720
2020-11-05 19:05:05,441 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3231 | Iter Mean Loss 11.9222
2020-11-05 19:05:05,444 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.2817 | MSE 0.3956
2020-11-05 19:05:05,454 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3235 | Iter Mean Loss 11.3235
2020-11-05 19:05:05,463 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0869 | Iter Mean Loss 7.7052
2020-11-05 19:05:05,472 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5109 | Iter Mean Loss 11.3071
2020-11-05 19:05:05,480 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2260 | Iter Mean Loss 12.0368
2020-11-05 19:05:05,489 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2687 | Iter Mean Loss 11.8832
2020-11-05 19:05:05,491 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.2817 | MSE 0.3950
2020-11-05 19:05:05,500 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3203 | Iter Mean Loss 11.3203
2020-11-05 19:05:05,507 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0827 | Iter Mean Loss 7.7015
2020-11-05 19:05:05,515 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4210 | Iter Mean Loss 11.2746
2020-11-05 19:05:05,522 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1835 | Iter Mean Loss 12.0019
2020-11-05 19:05:05,530 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2146 | Iter Mean Loss 11.8444
2020-11-05 19:05:05,532 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.2817 | MSE 0.3943
2020-11-05 19:05:05,540 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3167 | Iter Mean Loss 11.3167
2020-11-05 19:05:05,548 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0785 | Iter Mean Loss 7.6976
2020-11-05 19:05:05,556 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3319 | Iter Mean Loss 11.2424
2020-11-05 19:05:05,564 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1414 | Iter Mean Loss 11.9671
2020-11-05 19:05:05,571 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1609 | Iter Mean Loss 11.8059
2020-11-05 19:05:05,573 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.2817 | MSE 0.3936
2020-11-05 19:05:05,581 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3129 | Iter Mean Loss 11.3129
2020-11-05 19:05:05,588 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0743 | Iter Mean Loss 7.6936
2020-11-05 19:05:05,595 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.2102
2020-11-05 19:05:05,603 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0995 | Iter Mean Loss 11.9325
2020-11-05 19:05:05,611 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.7676
2020-11-05 19:05:05,613 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.2817 | MSE 0.3930
2020-11-05 19:05:05,621 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3087 | Iter Mean Loss 11.3087
2020-11-05 19:05:05,628 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0700 | Iter Mean Loss 7.6894
2020-11-05 19:05:05,635 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1560 | Iter Mean Loss 11.1783
2020-11-05 19:05:05,642 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0579 | Iter Mean Loss 11.8982
2020-11-05 19:05:05,650 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0547 | Iter Mean Loss 11.7295
2020-11-05 19:05:05,653 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.2817 | MSE 0.3923
2020-11-05 19:05:05,662 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 11.3043
2020-11-05 19:05:05,671 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 7.6850
2020-11-05 19:05:05,679 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0693 | Iter Mean Loss 11.1465
2020-11-05 19:05:05,687 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0167 | Iter Mean Loss 11.8640
2020-11-05 19:05:05,695 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0022 | Iter Mean Loss 11.6917
2020-11-05 19:05:05,697 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.2817 | MSE 0.3917
2020-11-05 19:05:05,705 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2995 | Iter Mean Loss 11.2995
2020-11-05 19:05:05,714 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0615 | Iter Mean Loss 7.6805
2020-11-05 19:05:05,722 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9834 | Iter Mean Loss 11.1148
2020-11-05 19:05:05,730 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9757 | Iter Mean Loss 11.8301
2020-11-05 19:05:05,739 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.9500 | Iter Mean Loss 11.6540
2020-11-05 19:05:05,741 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.2817 | MSE 0.3910
2020-11-05 19:05:05,750 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 11.2945
2020-11-05 19:05:05,758 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0573 | Iter Mean Loss 7.6759
2020-11-05 19:05:05,766 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8983 | Iter Mean Loss 11.0834
2020-11-05 19:05:05,773 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9350 | Iter Mean Loss 11.7963
2020-11-05 19:05:05,781 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8983 | Iter Mean Loss 11.6167
2020-11-05 19:05:05,783 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.2817 | MSE 0.3904
2020-11-05 19:05:05,792 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2892 | Iter Mean Loss 11.2892
2020-11-05 19:05:05,800 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0530 | Iter Mean Loss 7.6711
2020-11-05 19:05:05,808 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8140 | Iter Mean Loss 11.0521
2020-11-05 19:05:05,817 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8946 | Iter Mean Loss 11.7627
2020-11-05 19:05:05,828 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8469 | Iter Mean Loss 11.5795
2020-11-05 19:05:05,830 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.2817 | MSE 0.3898
2020-11-05 19:05:05,843 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2836 | Iter Mean Loss 11.2836
2020-11-05 19:05:05,853 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0487 | Iter Mean Loss 7.6661
2020-11-05 19:05:05,864 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7304 | Iter Mean Loss 11.0209
2020-11-05 19:05:05,876 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8545 | Iter Mean Loss 11.7293
2020-11-05 19:05:05,885 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7959 | Iter Mean Loss 11.5426
2020-11-05 19:05:05,890 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.2817 | MSE 0.3891
2020-11-05 19:05:05,900 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2777 | Iter Mean Loss 11.2777
2020-11-05 19:05:05,912 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0445 | Iter Mean Loss 7.6611
2020-11-05 19:05:05,922 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6476 | Iter Mean Loss 10.9899
2020-11-05 19:05:05,932 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8146 | Iter Mean Loss 11.6961
2020-11-05 19:05:05,943 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7453 | Iter Mean Loss 11.5059
2020-11-05 19:05:05,946 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.2817 | MSE 0.3885
2020-11-05 19:05:05,958 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2715 | Iter Mean Loss 11.2715
2020-11-05 19:05:05,968 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0402 | Iter Mean Loss 7.6558
2020-11-05 19:05:05,980 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5656 | Iter Mean Loss 10.9591
2020-11-05 19:05:05,991 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7750 | Iter Mean Loss 11.6631
2020-11-05 19:05:06,001 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6950 | Iter Mean Loss 11.4695
2020-11-05 19:05:06,005 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.2817 | MSE 0.3879
2020-11-05 19:05:06,015 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2650 | Iter Mean Loss 11.2650
2020-11-05 19:05:06,027 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0358 | Iter Mean Loss 7.6504
2020-11-05 19:05:06,037 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4844 | Iter Mean Loss 10.9284
2020-11-05 19:05:06,046 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7357 | Iter Mean Loss 11.6302
2020-11-05 19:05:06,056 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6452 | Iter Mean Loss 11.4332
2020-11-05 19:05:06,059 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.2817 | MSE 0.3873
2020-11-05 19:05:06,069 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2583 | Iter Mean Loss 11.2583
2020-11-05 19:05:06,078 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0315 | Iter Mean Loss 7.6449
2020-11-05 19:05:06,088 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4038 | Iter Mean Loss 10.8979
2020-11-05 19:05:06,096 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6967 | Iter Mean Loss 11.5976
2020-11-05 19:05:06,103 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5957 | Iter Mean Loss 11.3972
2020-11-05 19:05:06,106 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.2817 | MSE 0.3867
2020-11-05 19:05:06,116 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2513 | Iter Mean Loss 11.2513
2020-11-05 19:05:06,124 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 7.6392
2020-11-05 19:05:06,134 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3241 | Iter Mean Loss 10.8675
2020-11-05 19:05:06,144 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6579 | Iter Mean Loss 11.5651
2020-11-05 19:05:06,155 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5466 | Iter Mean Loss 11.3614
2020-11-05 19:05:06,158 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.2817 | MSE 0.3860
2020-11-05 19:05:06,169 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2440 | Iter Mean Loss 11.2440
2020-11-05 19:05:06,178 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0228 | Iter Mean Loss 7.6334
2020-11-05 19:05:06,189 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2451 | Iter Mean Loss 10.8373
2020-11-05 19:05:06,198 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6194 | Iter Mean Loss 11.5328
2020-11-05 19:05:06,209 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4979 | Iter Mean Loss 11.3258
2020-11-05 19:05:06,211 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.2817 | MSE 0.3854
2020-11-05 19:05:06,222 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2365 | Iter Mean Loss 11.2365
2020-11-05 19:05:06,231 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0185 | Iter Mean Loss 7.6275
2020-11-05 19:05:06,242 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1668 | Iter Mean Loss 10.8072
2020-11-05 19:05:06,252 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5811 | Iter Mean Loss 11.5007
2020-11-05 19:05:06,262 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4496 | Iter Mean Loss 11.2905
2020-11-05 19:05:06,264 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.2817 | MSE 0.3848
2020-11-05 19:05:06,276 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2287 | Iter Mean Loss 11.2287
2020-11-05 19:05:06,286 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 7.6214
2020-11-05 19:05:06,296 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0892 | Iter Mean Loss 10.7773
2020-11-05 19:05:06,305 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5431 | Iter Mean Loss 11.4688
2020-11-05 19:05:06,314 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4017 | Iter Mean Loss 11.2553
2020-11-05 19:05:06,318 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.2817 | MSE 0.3843
2020-11-05 19:05:06,327 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2206 | Iter Mean Loss 11.2206
2020-11-05 19:05:06,335 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0097 | Iter Mean Loss 7.6152
2020-11-05 19:05:06,344 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0124 | Iter Mean Loss 10.7476
2020-11-05 19:05:06,351 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5053 | Iter Mean Loss 11.4370
2020-11-05 19:05:06,360 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3541 | Iter Mean Loss 11.2204
2020-11-05 19:05:06,363 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.2817 | MSE 0.3837
2020-11-05 19:05:06,372 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2123 | Iter Mean Loss 11.2123
2020-11-05 19:05:06,383 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0053 | Iter Mean Loss 7.6088
2020-11-05 19:05:06,395 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9363 | Iter Mean Loss 10.7179
2020-11-05 19:05:06,403 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4678 | Iter Mean Loss 11.4054
2020-11-05 19:05:06,413 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3070 | Iter Mean Loss 11.1857
2020-11-05 19:05:06,416 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.2817 | MSE 0.3831
2020-11-05 19:05:06,424 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2037 | Iter Mean Loss 11.2037
2020-11-05 19:05:06,431 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0009 | Iter Mean Loss 7.6023
2020-11-05 19:05:06,439 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8608 | Iter Mean Loss 10.6885
2020-11-05 19:05:06,446 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4305 | Iter Mean Loss 11.3740
2020-11-05 19:05:06,454 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2602 | Iter Mean Loss 11.1512
2020-11-05 19:05:06,456 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.2817 | MSE 0.3825
2020-11-05 19:05:06,464 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1949 | Iter Mean Loss 11.1949
2020-11-05 19:05:06,471 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9964 | Iter Mean Loss 7.5957
2020-11-05 19:05:06,479 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7861 | Iter Mean Loss 10.6591
2020-11-05 19:05:06,487 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3934 | Iter Mean Loss 11.3427
2020-11-05 19:05:06,494 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2138 | Iter Mean Loss 11.1169
2020-11-05 19:05:06,496 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.2817 | MSE 0.3819
2020-11-05 19:05:06,504 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1858 | Iter Mean Loss 11.1858
2020-11-05 19:05:06,513 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9920 | Iter Mean Loss 7.5889
2020-11-05 19:05:06,521 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7121 | Iter Mean Loss 10.6300
2020-11-05 19:05:06,530 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3566 | Iter Mean Loss 11.3116
2020-11-05 19:05:06,538 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1677 | Iter Mean Loss 11.0829
2020-11-05 19:05:06,540 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.2817 | MSE 0.3813
2020-11-05 19:05:06,548 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1765 | Iter Mean Loss 11.1765
2020-11-05 19:05:06,559 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9875 | Iter Mean Loss 7.5820
2020-11-05 19:05:06,567 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6388 | Iter Mean Loss 10.6009
2020-11-05 19:05:06,576 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3200 | Iter Mean Loss 11.2807
2020-11-05 19:05:06,585 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1221 | Iter Mean Loss 11.0490
2020-11-05 19:05:06,589 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.2817 | MSE 0.3808
2020-11-05 19:05:06,598 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1669 | Iter Mean Loss 11.1669
2020-11-05 19:05:06,608 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9830 | Iter Mean Loss 7.5750
2020-11-05 19:05:06,616 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5662 | Iter Mean Loss 10.5720
2020-11-05 19:05:06,625 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2837 | Iter Mean Loss 11.2499
2020-11-05 19:05:06,633 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0768 | Iter Mean Loss 11.0153
2020-11-05 19:05:06,635 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.2817 | MSE 0.3802
2020-11-05 19:05:06,643 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1571 | Iter Mean Loss 11.1571
2020-11-05 19:05:06,650 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 7.5678
2020-11-05 19:05:06,658 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4942 | Iter Mean Loss 10.5433
2020-11-05 19:05:06,666 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2475 | Iter Mean Loss 11.2193
2020-11-05 19:05:06,673 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0319 | Iter Mean Loss 10.9818
2020-11-05 19:05:06,675 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.2817 | MSE 0.3797
2020-11-05 19:05:06,684 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1471 | Iter Mean Loss 11.1471
2020-11-05 19:05:06,697 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9740 | Iter Mean Loss 7.5605
2020-11-05 19:05:06,709 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4229 | Iter Mean Loss 10.5146
2020-11-05 19:05:06,720 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2116 | Iter Mean Loss 11.1889
2020-11-05 19:05:06,732 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9874 | Iter Mean Loss 10.9486
2020-11-05 19:05:06,735 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.2817 | MSE 0.3791
2020-11-05 19:05:06,747 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1368 | Iter Mean Loss 11.1368
2020-11-05 19:05:06,760 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9694 | Iter Mean Loss 7.5531
2020-11-05 19:05:06,769 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3523 | Iter Mean Loss 10.4861
2020-11-05 19:05:06,777 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1758 | Iter Mean Loss 11.1586
2020-11-05 19:05:06,787 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9432 | Iter Mean Loss 10.9155
2020-11-05 19:05:06,791 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.2817 | MSE 0.3786
2020-11-05 19:05:06,799 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1263 | Iter Mean Loss 11.1263
2020-11-05 19:05:06,807 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9648 | Iter Mean Loss 7.5456
2020-11-05 19:05:06,815 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2823 | Iter Mean Loss 10.4578
2020-11-05 19:05:06,823 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1403 | Iter Mean Loss 11.1284
2020-11-05 19:05:06,833 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8995 | Iter Mean Loss 10.8826
2020-11-05 19:05:06,835 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.2817 | MSE 0.3780
2020-11-05 19:05:06,844 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1155 | Iter Mean Loss 11.1155
2020-11-05 19:05:06,854 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9603 | Iter Mean Loss 7.5379
2020-11-05 19:05:06,861 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2130 | Iter Mean Loss 10.4296
2020-11-05 19:05:06,869 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1050 | Iter Mean Loss 11.0984
2020-11-05 19:05:06,876 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8560 | Iter Mean Loss 10.8499
2020-11-05 19:05:06,878 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.2817 | MSE 0.3775
2020-11-05 19:05:06,887 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1045 | Iter Mean Loss 11.1045
2020-11-05 19:05:06,896 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9556 | Iter Mean Loss 7.5301
2020-11-05 19:05:06,905 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1443 | Iter Mean Loss 10.4015
2020-11-05 19:05:06,913 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0698 | Iter Mean Loss 11.0686
2020-11-05 19:05:06,922 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8130 | Iter Mean Loss 10.8175
2020-11-05 19:05:06,924 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.2817 | MSE 0.3769
2020-11-05 19:05:06,932 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0934 | Iter Mean Loss 11.0934
2020-11-05 19:05:06,939 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9510 | Iter Mean Loss 7.5222
2020-11-05 19:05:06,948 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0763 | Iter Mean Loss 10.3735
2020-11-05 19:05:06,955 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0349 | Iter Mean Loss 11.0389
2020-11-05 19:05:06,963 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7703 | Iter Mean Loss 10.7852
2020-11-05 19:05:06,966 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.2817 | MSE 0.3764
2020-11-05 19:05:06,974 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0819 | Iter Mean Loss 11.0819
2020-11-05 19:05:06,981 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9464 | Iter Mean Loss 7.5141
2020-11-05 19:05:06,989 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0088 | Iter Mean Loss 10.3457
2020-11-05 19:05:06,996 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0002 | Iter Mean Loss 11.0093
2020-11-05 19:05:07,003 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7280 | Iter Mean Loss 10.7531
2020-11-05 19:05:07,005 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.2817 | MSE 0.3759
2020-11-05 19:05:07,013 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0703 | Iter Mean Loss 11.0703
2020-11-05 19:05:07,021 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9417 | Iter Mean Loss 7.5060
2020-11-05 19:05:07,029 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9421 | Iter Mean Loss 10.3180
2020-11-05 19:05:07,037 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9656 | Iter Mean Loss 10.9799
2020-11-05 19:05:07,044 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 10.7211
2020-11-05 19:05:07,046 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.2817 | MSE 0.3753
2020-11-05 19:05:07,054 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0585 | Iter Mean Loss 11.0585
2020-11-05 19:05:07,062 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 7.4977
2020-11-05 19:05:07,069 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8759 | Iter Mean Loss 10.2904
2020-11-05 19:05:07,076 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9312 | Iter Mean Loss 10.9506
2020-11-05 19:05:07,083 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6444 | Iter Mean Loss 10.6894
2020-11-05 19:05:07,085 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.2817 | MSE 0.3748
2020-11-05 19:05:07,093 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0464 | Iter Mean Loss 11.0464
2020-11-05 19:05:07,101 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9323 | Iter Mean Loss 7.4893
2020-11-05 19:05:07,109 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.2630
2020-11-05 19:05:07,116 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8970 | Iter Mean Loss 10.9215
2020-11-05 19:05:07,124 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6031 | Iter Mean Loss 10.6578
2020-11-05 19:05:07,126 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.2817 | MSE 0.3743
2020-11-05 19:05:07,135 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0341 | Iter Mean Loss 11.0341
2020-11-05 19:05:07,143 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9275 | Iter Mean Loss 7.4808
2020-11-05 19:05:07,151 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7454 | Iter Mean Loss 10.2357
2020-11-05 19:05:07,160 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8630 | Iter Mean Loss 10.8925
2020-11-05 19:05:07,168 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5622 | Iter Mean Loss 10.6264
2020-11-05 19:05:07,170 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.2817 | MSE 0.3738
2020-11-05 19:05:07,179 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0216 | Iter Mean Loss 11.0216
2020-11-05 19:05:07,187 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9228 | Iter Mean Loss 7.4722
2020-11-05 19:05:07,195 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6810 | Iter Mean Loss 10.2085
2020-11-05 19:05:07,203 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8291 | Iter Mean Loss 10.8636
2020-11-05 19:05:07,210 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5216 | Iter Mean Loss 10.5952
2020-11-05 19:05:07,212 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.2817 | MSE 0.3733
2020-11-05 19:05:07,219 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0089 | Iter Mean Loss 11.0089
2020-11-05 19:05:07,227 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9180 | Iter Mean Loss 7.4635
2020-11-05 19:05:07,234 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6173 | Iter Mean Loss 10.1814
2020-11-05 19:05:07,241 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7954 | Iter Mean Loss 10.8349
2020-11-05 19:05:07,249 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4813 | Iter Mean Loss 10.5642
2020-11-05 19:05:07,250 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.2817 | MSE 0.3727
2020-11-05 19:05:07,258 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9961 | Iter Mean Loss 10.9961
2020-11-05 19:05:07,265 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9132 | Iter Mean Loss 7.4546
2020-11-05 19:05:07,273 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5541 | Iter Mean Loss 10.1544
2020-11-05 19:05:07,280 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7618 | Iter Mean Loss 10.8063
2020-11-05 19:05:07,287 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4415 | Iter Mean Loss 10.5333
2020-11-05 19:05:07,289 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.2817 | MSE 0.3722
2020-11-05 19:05:07,297 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9830 | Iter Mean Loss 10.9830
2020-11-05 19:05:07,304 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9083 | Iter Mean Loss 7.4456
2020-11-05 19:05:07,312 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4915 | Iter Mean Loss 10.1276
2020-11-05 19:05:07,321 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7284 | Iter Mean Loss 10.7778
2020-11-05 19:05:07,329 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4019 | Iter Mean Loss 10.5026
2020-11-05 19:05:07,332 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.2817 | MSE 0.3717
2020-11-05 19:05:07,342 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9697 | Iter Mean Loss 10.9697
2020-11-05 19:05:07,350 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 7.4366
2020-11-05 19:05:07,359 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4295 | Iter Mean Loss 10.1009
2020-11-05 19:05:07,367 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6952 | Iter Mean Loss 10.7494
2020-11-05 19:05:07,376 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3627 | Iter Mean Loss 10.4721
2020-11-05 19:05:07,378 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.2817 | MSE 0.3712
2020-11-05 19:05:07,387 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9562 | Iter Mean Loss 10.9562
2020-11-05 19:05:07,395 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8986 | Iter Mean Loss 7.4274
2020-11-05 19:05:07,404 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3680 | Iter Mean Loss 10.0742
2020-11-05 19:05:07,415 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6621 | Iter Mean Loss 10.7212
2020-11-05 19:05:07,424 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3238 | Iter Mean Loss 10.4417
2020-11-05 19:05:07,427 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.2817 | MSE 0.3708
2020-11-05 19:05:07,437 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9425 | Iter Mean Loss 10.9425
2020-11-05 19:05:07,447 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8936 | Iter Mean Loss 7.4181
2020-11-05 19:05:07,456 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3071 | Iter Mean Loss 10.0477
2020-11-05 19:05:07,464 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6291 | Iter Mean Loss 10.6931
2020-11-05 19:05:07,474 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2852 | Iter Mean Loss 10.4115
2020-11-05 19:05:07,477 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.2817 | MSE 0.3703
2020-11-05 19:05:07,488 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9286 | Iter Mean Loss 10.9286
2020-11-05 19:05:07,498 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8887 | Iter Mean Loss 7.4086
2020-11-05 19:05:07,508 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2467 | Iter Mean Loss 10.0213
2020-11-05 19:05:07,517 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5963 | Iter Mean Loss 10.6651
2020-11-05 19:05:07,527 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2470 | Iter Mean Loss 10.3815
2020-11-05 19:05:07,529 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.2817 | MSE 0.3698
2020-11-05 19:05:07,541 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9145 | Iter Mean Loss 10.9145
2020-11-05 19:05:07,552 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8837 | Iter Mean Loss 7.3991
2020-11-05 19:05:07,564 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1869 | Iter Mean Loss 9.9951
2020-11-05 19:05:07,575 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5636 | Iter Mean Loss 10.6372
2020-11-05 19:05:07,583 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2090 | Iter Mean Loss 10.3516
2020-11-05 19:05:07,586 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.2817 | MSE 0.3693
2020-11-05 19:05:07,595 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9003 | Iter Mean Loss 10.9003
2020-11-05 19:05:07,604 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8787 | Iter Mean Loss 7.3895
2020-11-05 19:05:07,612 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1276 | Iter Mean Loss 9.9689
2020-11-05 19:05:07,620 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5310 | Iter Mean Loss 10.6094
2020-11-05 19:05:07,627 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1714 | Iter Mean Loss 10.3218
2020-11-05 19:05:07,630 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.2817 | MSE 0.3688
2020-11-05 19:05:07,638 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8858 | Iter Mean Loss 10.8858
2020-11-05 19:05:07,645 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 7.3798
2020-11-05 19:05:07,653 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0689 | Iter Mean Loss 9.9428
2020-11-05 19:05:07,661 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4986 | Iter Mean Loss 10.5818
2020-11-05 19:05:07,668 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1341 | Iter Mean Loss 10.2922
2020-11-05 19:05:07,670 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.2817 | MSE 0.3683
2020-11-05 19:05:07,678 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 19:05:07,686 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8686 | Iter Mean Loss 7.3699
2020-11-05 19:05:07,694 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0107 | Iter Mean Loss 9.9168
2020-11-05 19:05:07,703 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4663 | Iter Mean Loss 10.5542
2020-11-05 19:05:07,710 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0971 | Iter Mean Loss 10.2628
2020-11-05 19:05:07,713 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.2817 | MSE 0.3679
2020-11-05 19:05:07,722 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8564 | Iter Mean Loss 10.8564
2020-11-05 19:05:07,730 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8635 | Iter Mean Loss 7.3600
2020-11-05 19:05:07,738 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9530 | Iter Mean Loss 9.8910
2020-11-05 19:05:07,747 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4341 | Iter Mean Loss 10.5268
2020-11-05 19:05:07,754 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0604 | Iter Mean Loss 10.2335
2020-11-05 19:05:07,756 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.2817 | MSE 0.3674
2020-11-05 19:05:07,765 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8414 | Iter Mean Loss 10.8414
2020-11-05 19:05:07,774 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8584 | Iter Mean Loss 7.3499
2020-11-05 19:05:07,782 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8958 | Iter Mean Loss 9.8652
2020-11-05 19:05:07,789 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4020 | Iter Mean Loss 10.4994
2020-11-05 19:05:07,797 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0240 | Iter Mean Loss 10.2043
2020-11-05 19:05:07,800 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.2817 | MSE 0.3669
2020-11-05 19:05:07,809 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8262 | Iter Mean Loss 10.8262
2020-11-05 19:05:07,817 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8533 | Iter Mean Loss 7.3398
2020-11-05 19:05:07,825 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8391 | Iter Mean Loss 9.8395
2020-11-05 19:05:07,832 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3701 | Iter Mean Loss 10.4722
2020-11-05 19:05:07,839 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9879 | Iter Mean Loss 10.1753
2020-11-05 19:05:07,841 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.2817 | MSE 0.3665
2020-11-05 19:05:07,849 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 19:05:07,857 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8481 | Iter Mean Loss 7.3295
2020-11-05 19:05:07,865 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7829 | Iter Mean Loss 9.8140
2020-11-05 19:05:07,873 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3383 | Iter Mean Loss 10.4450
2020-11-05 19:05:07,881 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9521 | Iter Mean Loss 10.1464
2020-11-05 19:05:07,883 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.2817 | MSE 0.3660
2020-11-05 19:05:07,891 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7954 | Iter Mean Loss 10.7954
2020-11-05 19:05:07,898 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8429 | Iter Mean Loss 7.3191
2020-11-05 19:05:07,906 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7272 | Iter Mean Loss 9.7885
2020-11-05 19:05:07,914 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3065 | Iter Mean Loss 10.4180
2020-11-05 19:05:07,921 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9165 | Iter Mean Loss 10.1177
2020-11-05 19:05:07,923 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.2817 | MSE 0.3655
2020-11-05 19:05:07,931 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7797 | Iter Mean Loss 10.7797
2020-11-05 19:05:07,939 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8377 | Iter Mean Loss 7.3087
2020-11-05 19:05:07,946 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6720 | Iter Mean Loss 9.7631
2020-11-05 19:05:07,955 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2749 | Iter Mean Loss 10.3911
2020-11-05 19:05:07,962 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8813 | Iter Mean Loss 10.0891
2020-11-05 19:05:07,965 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.2817 | MSE 0.3651
2020-11-05 19:05:07,974 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7638 | Iter Mean Loss 10.7638
2020-11-05 19:05:07,982 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8324 | Iter Mean Loss 7.2981
2020-11-05 19:05:07,991 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6173 | Iter Mean Loss 9.7378
2020-11-05 19:05:07,998 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2434 | Iter Mean Loss 10.3642
2020-11-05 19:05:08,006 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8463 | Iter Mean Loss 10.0606
2020-11-05 19:05:08,008 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.2817 | MSE 0.3646
2020-11-05 19:05:08,016 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7478 | Iter Mean Loss 10.7478
2020-11-05 19:05:08,024 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8271 | Iter Mean Loss 7.2874
2020-11-05 19:05:08,031 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5630 | Iter Mean Loss 9.7126
2020-11-05 19:05:08,038 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2119 | Iter Mean Loss 10.3374
2020-11-05 19:05:08,046 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8116 | Iter Mean Loss 10.0323
2020-11-05 19:05:08,048 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.2817 | MSE 0.3642
2020-11-05 19:05:08,056 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7316 | Iter Mean Loss 10.7316
2020-11-05 19:05:08,065 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8218 | Iter Mean Loss 7.2767
2020-11-05 19:05:08,077 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5092 | Iter Mean Loss 9.6875
2020-11-05 19:05:08,088 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1806 | Iter Mean Loss 10.3108
2020-11-05 19:05:08,099 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7772 | Iter Mean Loss 10.0041
2020-11-05 19:05:08,103 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.2817 | MSE 0.3638
2020-11-05 19:05:08,113 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7152 | Iter Mean Loss 10.7152
2020-11-05 19:05:08,123 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8164 | Iter Mean Loss 7.2658
2020-11-05 19:05:08,133 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4559 | Iter Mean Loss 9.6625
2020-11-05 19:05:08,143 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1494 | Iter Mean Loss 10.2842
2020-11-05 19:05:08,152 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7431 | Iter Mean Loss 9.9760
2020-11-05 19:05:08,155 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.2817 | MSE 0.3633
2020-11-05 19:05:08,165 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6986 | Iter Mean Loss 10.6986
2020-11-05 19:05:08,174 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8110 | Iter Mean Loss 7.2548
2020-11-05 19:05:08,182 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4030 | Iter Mean Loss 9.6375
2020-11-05 19:05:08,190 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1182 | Iter Mean Loss 10.2577
2020-11-05 19:05:08,199 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7092 | Iter Mean Loss 9.9480
2020-11-05 19:05:08,202 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.2817 | MSE 0.3629
2020-11-05 19:05:08,211 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6819 | Iter Mean Loss 10.6819
2020-11-05 19:05:08,219 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8056 | Iter Mean Loss 7.2438
2020-11-05 19:05:08,227 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3506 | Iter Mean Loss 9.6127
2020-11-05 19:05:08,234 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0872 | Iter Mean Loss 10.2313
2020-11-05 19:05:08,242 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6755 | Iter Mean Loss 9.9202
2020-11-05 19:05:08,244 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.2817 | MSE 0.3624
2020-11-05 19:05:08,252 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6651 | Iter Mean Loss 10.6651
2020-11-05 19:05:08,260 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8001 | Iter Mean Loss 7.2326
2020-11-05 19:05:08,268 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2986 | Iter Mean Loss 9.5879
2020-11-05 19:05:08,277 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0562 | Iter Mean Loss 10.2050
2020-11-05 19:05:08,285 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6422 | Iter Mean Loss 9.8924
2020-11-05 19:05:08,287 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.2817 | MSE 0.3620
2020-11-05 19:05:08,295 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6480 | Iter Mean Loss 10.6480
2020-11-05 19:05:08,303 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7946 | Iter Mean Loss 7.2213
2020-11-05 19:05:08,311 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2470 | Iter Mean Loss 9.5632
2020-11-05 19:05:08,320 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0253 | Iter Mean Loss 10.1787
2020-11-05 19:05:08,329 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6090 | Iter Mean Loss 9.8648
2020-11-05 19:05:08,331 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.2817 | MSE 0.3616
2020-11-05 19:05:08,340 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6309 | Iter Mean Loss 10.6309
2020-11-05 19:05:08,347 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7891 | Iter Mean Loss 7.2100
2020-11-05 19:05:08,356 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1959 | Iter Mean Loss 9.5386
2020-11-05 19:05:08,365 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9945 | Iter Mean Loss 10.1526
2020-11-05 19:05:08,373 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5762 | Iter Mean Loss 9.8373
2020-11-05 19:05:08,375 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.2817 | MSE 0.3612
2020-11-05 19:05:08,385 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6135 | Iter Mean Loss 10.6135
2020-11-05 19:05:08,393 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7835 | Iter Mean Loss 7.1985
2020-11-05 19:05:08,403 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1451 | Iter Mean Loss 9.5141
2020-11-05 19:05:08,411 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9638 | Iter Mean Loss 10.1265
2020-11-05 19:05:08,420 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 9.8099
2020-11-05 19:05:08,422 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.2817 | MSE 0.3607
2020-11-05 19:05:08,431 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5960 | Iter Mean Loss 10.5960
2020-11-05 19:05:08,438 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7779 | Iter Mean Loss 7.1869
2020-11-05 19:05:08,446 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0949 | Iter Mean Loss 9.4896
2020-11-05 19:05:08,453 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9331 | Iter Mean Loss 10.1005
2020-11-05 19:05:08,461 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5111 | Iter Mean Loss 9.7826
2020-11-05 19:05:08,463 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.2817 | MSE 0.3603
2020-11-05 19:05:08,471 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5783 | Iter Mean Loss 10.5783
2020-11-05 19:05:08,479 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 7.1753
2020-11-05 19:05:08,487 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0450 | Iter Mean Loss 9.4652
2020-11-05 19:05:08,496 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9026 | Iter Mean Loss 10.0745
2020-11-05 19:05:08,508 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4790 | Iter Mean Loss 9.7554
2020-11-05 19:05:08,510 - root - INFO - Evaluate: Epoch 0285 | NDCG 1.0000 | MSE 0.3599
2020-11-05 19:05:08,518 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5605 | Iter Mean Loss 10.5605
2020-11-05 19:05:08,527 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7666 | Iter Mean Loss 7.1636
2020-11-05 19:05:08,535 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9955 | Iter Mean Loss 9.4409
2020-11-05 19:05:08,543 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8721 | Iter Mean Loss 10.0487
2020-11-05 19:05:08,551 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4471 | Iter Mean Loss 9.7283
2020-11-05 19:05:08,554 - root - INFO - Evaluate: Epoch 0286 | NDCG 1.0000 | MSE 0.3595
2020-11-05 19:05:08,562 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5426 | Iter Mean Loss 10.5426
2020-11-05 19:05:08,571 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7609 | Iter Mean Loss 7.1517
2020-11-05 19:05:08,580 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9464 | Iter Mean Loss 9.4166
2020-11-05 19:05:08,588 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8416 | Iter Mean Loss 10.0229
2020-11-05 19:05:08,596 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 9.7014
2020-11-05 19:05:08,598 - root - INFO - Evaluate: Epoch 0287 | NDCG 1.0000 | MSE 0.3591
2020-11-05 19:05:08,608 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5244 | Iter Mean Loss 10.5244
2020-11-05 19:05:08,616 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7551 | Iter Mean Loss 7.1398
2020-11-05 19:05:08,626 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8977 | Iter Mean Loss 9.3924
2020-11-05 19:05:08,634 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8113 | Iter Mean Loss 9.9971
2020-11-05 19:05:08,641 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3839 | Iter Mean Loss 9.6745
2020-11-05 19:05:08,644 - root - INFO - Evaluate: Epoch 0288 | NDCG 1.0000 | MSE 0.3587
2020-11-05 19:05:08,652 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5062 | Iter Mean Loss 10.5062
2020-11-05 19:05:08,660 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7493 | Iter Mean Loss 7.1278
2020-11-05 19:05:08,667 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8494 | Iter Mean Loss 9.3683
2020-11-05 19:05:08,675 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7810 | Iter Mean Loss 9.9715
2020-11-05 19:05:08,684 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3526 | Iter Mean Loss 9.6477
2020-11-05 19:05:08,686 - root - INFO - Evaluate: Epoch 0289 | NDCG 1.0000 | MSE 0.3583
2020-11-05 19:05:08,696 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4878 | Iter Mean Loss 10.4878
2020-11-05 19:05:08,704 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7435 | Iter Mean Loss 7.1156
2020-11-05 19:05:08,712 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8015 | Iter Mean Loss 9.3442
2020-11-05 19:05:08,720 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7508 | Iter Mean Loss 9.9459
2020-11-05 19:05:08,728 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3216 | Iter Mean Loss 9.6210
2020-11-05 19:05:08,730 - root - INFO - Evaluate: Epoch 0290 | NDCG 1.0000 | MSE 0.3579
2020-11-05 19:05:08,738 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4692 | Iter Mean Loss 10.4692
2020-11-05 19:05:08,746 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7376 | Iter Mean Loss 7.1034
2020-11-05 19:05:08,755 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7539 | Iter Mean Loss 9.3203
2020-11-05 19:05:08,763 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7206 | Iter Mean Loss 9.9203
2020-11-05 19:05:08,771 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2908 | Iter Mean Loss 9.5944
2020-11-05 19:05:08,773 - root - INFO - Evaluate: Epoch 0291 | NDCG 1.0000 | MSE 0.3575
2020-11-05 19:05:08,782 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4505 | Iter Mean Loss 10.4505
2020-11-05 19:05:08,791 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7318 | Iter Mean Loss 7.0911
2020-11-05 19:05:08,799 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7068 | Iter Mean Loss 9.2963
2020-11-05 19:05:08,809 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6905 | Iter Mean Loss 9.8949
2020-11-05 19:05:08,817 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2602 | Iter Mean Loss 9.5679
2020-11-05 19:05:08,819 - root - INFO - Evaluate: Epoch 0292 | NDCG 1.0000 | MSE 0.3571
2020-11-05 19:05:08,827 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4316 | Iter Mean Loss 10.4316
2020-11-05 19:05:08,836 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7258 | Iter Mean Loss 7.0787
2020-11-05 19:05:08,844 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6599 | Iter Mean Loss 9.2725
2020-11-05 19:05:08,852 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6605 | Iter Mean Loss 9.8695
2020-11-05 19:05:08,860 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2298 | Iter Mean Loss 9.5415
2020-11-05 19:05:08,862 - root - INFO - Evaluate: Epoch 0293 | NDCG 1.0000 | MSE 0.3567
2020-11-05 19:05:08,870 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4126 | Iter Mean Loss 10.4126
2020-11-05 19:05:08,878 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7198 | Iter Mean Loss 7.0662
2020-11-05 19:05:08,886 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6135 | Iter Mean Loss 9.2486
2020-11-05 19:05:08,893 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6305 | Iter Mean Loss 9.8441
2020-11-05 19:05:08,901 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1996 | Iter Mean Loss 9.5152
2020-11-05 19:05:08,903 - root - INFO - Evaluate: Epoch 0294 | NDCG 1.0000 | MSE 0.3563
2020-11-05 19:05:08,912 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3934 | Iter Mean Loss 10.3934
2020-11-05 19:05:08,919 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7138 | Iter Mean Loss 7.0536
2020-11-05 19:05:08,927 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5674 | Iter Mean Loss 9.2249
2020-11-05 19:05:08,934 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6006 | Iter Mean Loss 9.8188
2020-11-05 19:05:08,942 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1696 | Iter Mean Loss 9.4890
2020-11-05 19:05:08,944 - root - INFO - Evaluate: Epoch 0295 | NDCG 1.0000 | MSE 0.3559
2020-11-05 19:05:08,952 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3741 | Iter Mean Loss 10.3741
2020-11-05 19:05:08,960 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7078 | Iter Mean Loss 7.0410
2020-11-05 19:05:08,969 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5216 | Iter Mean Loss 9.2012
2020-11-05 19:05:08,977 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 9.7936
2020-11-05 19:05:08,986 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1398 | Iter Mean Loss 9.4628
2020-11-05 19:05:08,988 - root - INFO - Evaluate: Epoch 0296 | NDCG 1.0000 | MSE 0.3555
2020-11-05 19:05:08,998 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3547 | Iter Mean Loss 10.3547
2020-11-05 19:05:09,009 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7017 | Iter Mean Loss 7.0282
2020-11-05 19:05:09,017 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4762 | Iter Mean Loss 9.1775
2020-11-05 19:05:09,026 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5410 | Iter Mean Loss 9.7684
2020-11-05 19:05:09,033 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1102 | Iter Mean Loss 9.4368
2020-11-05 19:05:09,036 - root - INFO - Evaluate: Epoch 0297 | NDCG 1.0000 | MSE 0.3552
2020-11-05 19:05:09,044 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3351 | Iter Mean Loss 10.3351
2020-11-05 19:05:09,051 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6956 | Iter Mean Loss 7.0153
2020-11-05 19:05:09,059 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4311 | Iter Mean Loss 9.1539
2020-11-05 19:05:09,066 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5113 | Iter Mean Loss 9.7433
2020-11-05 19:05:09,073 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0808 | Iter Mean Loss 9.4108
2020-11-05 19:05:09,075 - root - INFO - Evaluate: Epoch 0298 | NDCG 1.0000 | MSE 0.3548
2020-11-05 19:05:09,084 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3154 | Iter Mean Loss 10.3154
2020-11-05 19:05:09,095 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6894 | Iter Mean Loss 7.0024
2020-11-05 19:05:09,107 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3864 | Iter Mean Loss 9.1304
2020-11-05 19:05:09,118 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4816 | Iter Mean Loss 9.7182
2020-11-05 19:05:09,131 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0516 | Iter Mean Loss 9.3849
2020-11-05 19:05:09,133 - root - INFO - Evaluate: Epoch 0299 | NDCG 1.0000 | MSE 0.3544
2020-11-05 19:05:09,145 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2955 | Iter Mean Loss 10.2955
2020-11-05 19:05:09,155 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6832 | Iter Mean Loss 6.9894
2020-11-05 19:05:09,166 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3420 | Iter Mean Loss 9.1069
2020-11-05 19:05:09,177 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4520 | Iter Mean Loss 9.6932
2020-11-05 19:05:09,186 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0226 | Iter Mean Loss 9.3591
2020-11-05 19:05:09,190 - root - INFO - Evaluate: Epoch 0300 | NDCG 1.0000 | MSE 0.3540
2020-11-05 19:05:09,201 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2755 | Iter Mean Loss 10.2755
2020-11-05 19:05:09,212 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6770 | Iter Mean Loss 6.9762
2020-11-05 19:05:09,221 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2979 | Iter Mean Loss 9.0835
2020-11-05 19:05:09,231 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4224 | Iter Mean Loss 9.6682
2020-11-05 19:05:09,240 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9937 | Iter Mean Loss 9.3333
2020-11-05 19:05:09,243 - root - INFO - Evaluate: Epoch 0301 | NDCG 1.0000 | MSE 0.3537
2020-11-05 19:05:09,252 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2554 | Iter Mean Loss 10.2554
2020-11-05 19:05:09,262 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6707 | Iter Mean Loss 6.9630
2020-11-05 19:05:09,270 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2541 | Iter Mean Loss 9.0601
2020-11-05 19:05:09,280 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3929 | Iter Mean Loss 9.6433
2020-11-05 19:05:09,290 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 9.3076
2020-11-05 19:05:09,292 - root - INFO - Evaluate: Epoch 0302 | NDCG 1.0000 | MSE 0.3533
2020-11-05 19:05:09,301 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2351 | Iter Mean Loss 10.2351
2020-11-05 19:05:09,312 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6644 | Iter Mean Loss 6.9497
2020-11-05 19:05:09,323 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2107 | Iter Mean Loss 9.0367
2020-11-05 19:05:09,331 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3635 | Iter Mean Loss 9.6184
2020-11-05 19:05:09,341 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9366 | Iter Mean Loss 9.2821
2020-11-05 19:05:09,343 - root - INFO - Evaluate: Epoch 0303 | NDCG 1.0000 | MSE 0.3529
2020-11-05 19:05:09,353 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2147 | Iter Mean Loss 10.2147
2020-11-05 19:05:09,362 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6580 | Iter Mean Loss 6.9364
2020-11-05 19:05:09,373 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1675 | Iter Mean Loss 9.0134
2020-11-05 19:05:09,381 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3341 | Iter Mean Loss 9.5936
2020-11-05 19:05:09,390 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9083 | Iter Mean Loss 9.2565
2020-11-05 19:05:09,393 - root - INFO - Evaluate: Epoch 0304 | NDCG 1.0000 | MSE 0.3526
2020-11-05 19:05:09,401 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1942 | Iter Mean Loss 10.1942
2020-11-05 19:05:09,411 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6516 | Iter Mean Loss 6.9229
2020-11-05 19:05:09,421 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1247 | Iter Mean Loss 8.9902
2020-11-05 19:05:09,432 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3047 | Iter Mean Loss 9.5688
2020-11-05 19:05:09,441 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8802 | Iter Mean Loss 9.2311
2020-11-05 19:05:09,443 - root - INFO - Evaluate: Epoch 0305 | NDCG 1.0000 | MSE 0.3522
2020-11-05 19:05:09,453 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1735 | Iter Mean Loss 10.1735
2020-11-05 19:05:09,461 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6452 | Iter Mean Loss 6.9093
2020-11-05 19:05:09,470 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0822 | Iter Mean Loss 8.9670
2020-11-05 19:05:09,479 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2754 | Iter Mean Loss 9.5441
2020-11-05 19:05:09,490 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8522 | Iter Mean Loss 9.2057
2020-11-05 19:05:09,492 - root - INFO - Evaluate: Epoch 0306 | NDCG 1.0000 | MSE 0.3519
2020-11-05 19:05:09,502 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1527 | Iter Mean Loss 10.1527
2020-11-05 19:05:09,510 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6387 | Iter Mean Loss 6.8957
2020-11-05 19:05:09,520 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0399 | Iter Mean Loss 8.9438
2020-11-05 19:05:09,529 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2462 | Iter Mean Loss 9.5194
2020-11-05 19:05:09,537 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8245 | Iter Mean Loss 9.1804
2020-11-05 19:05:09,539 - root - INFO - Evaluate: Epoch 0307 | NDCG 1.0000 | MSE 0.3515
2020-11-05 19:05:09,548 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1318 | Iter Mean Loss 10.1318
2020-11-05 19:05:09,557 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 6.8820
2020-11-05 19:05:09,566 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9980 | Iter Mean Loss 8.9207
2020-11-05 19:05:09,574 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2170 | Iter Mean Loss 9.4947
2020-11-05 19:05:09,584 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7968 | Iter Mean Loss 9.1552
2020-11-05 19:05:09,588 - root - INFO - Evaluate: Epoch 0308 | NDCG 1.0000 | MSE 0.3512
2020-11-05 19:05:09,597 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1107 | Iter Mean Loss 10.1107
2020-11-05 19:05:09,605 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 6.8682
2020-11-05 19:05:09,616 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9563 | Iter Mean Loss 8.8976
2020-11-05 19:05:09,624 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1878 | Iter Mean Loss 9.4701
2020-11-05 19:05:09,632 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7694 | Iter Mean Loss 9.1300
2020-11-05 19:05:09,635 - root - INFO - Evaluate: Epoch 0309 | NDCG 1.0000 | MSE 0.3508
2020-11-05 19:05:09,645 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0895 | Iter Mean Loss 10.0895
2020-11-05 19:05:09,655 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6191 | Iter Mean Loss 6.8543
2020-11-05 19:05:09,663 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9149 | Iter Mean Loss 8.8745
2020-11-05 19:05:09,672 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1587 | Iter Mean Loss 9.4456
2020-11-05 19:05:09,681 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7421 | Iter Mean Loss 9.1049
2020-11-05 19:05:09,683 - root - INFO - Evaluate: Epoch 0310 | NDCG 1.0000 | MSE 0.3505
2020-11-05 19:05:09,692 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0682 | Iter Mean Loss 10.0682
2020-11-05 19:05:09,701 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6124 | Iter Mean Loss 6.8403
2020-11-05 19:05:09,710 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8738 | Iter Mean Loss 8.8515
2020-11-05 19:05:09,719 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1297 | Iter Mean Loss 9.4210
2020-11-05 19:05:09,727 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7150 | Iter Mean Loss 9.0798
2020-11-05 19:05:09,730 - root - INFO - Evaluate: Epoch 0311 | NDCG 1.0000 | MSE 0.3501
2020-11-05 19:05:09,741 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0468 | Iter Mean Loss 10.0468
2020-11-05 19:05:09,749 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6058 | Iter Mean Loss 6.8263
2020-11-05 19:05:09,757 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8330 | Iter Mean Loss 8.8285
2020-11-05 19:05:09,764 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1007 | Iter Mean Loss 9.3966
2020-11-05 19:05:09,774 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6881 | Iter Mean Loss 9.0549
2020-11-05 19:05:09,777 - root - INFO - Evaluate: Epoch 0312 | NDCG 1.0000 | MSE 0.3498
2020-11-05 19:05:09,786 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0253 | Iter Mean Loss 10.0253
2020-11-05 19:05:09,796 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5991 | Iter Mean Loss 6.8122
2020-11-05 19:05:09,806 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7925 | Iter Mean Loss 8.8056
2020-11-05 19:05:09,814 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0717 | Iter Mean Loss 9.3721
2020-11-05 19:05:09,823 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6613 | Iter Mean Loss 9.0300
2020-11-05 19:05:09,825 - root - INFO - Evaluate: Epoch 0313 | NDCG 1.0000 | MSE 0.3494
2020-11-05 19:05:09,833 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0036 | Iter Mean Loss 10.0036
2020-11-05 19:05:09,844 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 6.7980
2020-11-05 19:05:09,853 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7522 | Iter Mean Loss 8.7827
2020-11-05 19:05:09,864 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0428 | Iter Mean Loss 9.3477
2020-11-05 19:05:09,873 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6347 | Iter Mean Loss 9.0051
2020-11-05 19:05:09,875 - root - INFO - Evaluate: Epoch 0314 | NDCG 1.0000 | MSE 0.3491
2020-11-05 19:05:09,884 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9818 | Iter Mean Loss 9.9818
2020-11-05 19:05:09,895 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5856 | Iter Mean Loss 6.7837
2020-11-05 19:05:09,903 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7122 | Iter Mean Loss 8.7599
2020-11-05 19:05:09,910 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 9.3234
2020-11-05 19:05:09,918 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6082 | Iter Mean Loss 8.9803
2020-11-05 19:05:09,920 - root - INFO - Evaluate: Epoch 0315 | NDCG 1.0000 | MSE 0.3488
2020-11-05 19:05:09,930 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9599 | Iter Mean Loss 9.9599
2020-11-05 19:05:09,938 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5788 | Iter Mean Loss 6.7693
2020-11-05 19:05:09,947 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6724 | Iter Mean Loss 8.7370
2020-11-05 19:05:09,956 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9851 | Iter Mean Loss 9.2991
2020-11-05 19:05:09,964 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5819 | Iter Mean Loss 8.9556
2020-11-05 19:05:09,966 - root - INFO - Evaluate: Epoch 0316 | NDCG 1.0000 | MSE 0.3484
2020-11-05 19:05:09,974 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9379 | Iter Mean Loss 9.9379
2020-11-05 19:05:09,982 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5719 | Iter Mean Loss 6.7549
2020-11-05 19:05:09,990 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6329 | Iter Mean Loss 8.7143
2020-11-05 19:05:09,999 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9564 | Iter Mean Loss 9.2748
2020-11-05 19:05:10,008 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5558 | Iter Mean Loss 8.9310
2020-11-05 19:05:10,010 - root - INFO - Evaluate: Epoch 0317 | NDCG 1.0000 | MSE 0.3481
2020-11-05 19:05:10,020 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9158 | Iter Mean Loss 9.9158
2020-11-05 19:05:10,028 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5651 | Iter Mean Loss 6.7404
2020-11-05 19:05:10,038 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5937 | Iter Mean Loss 8.6915
2020-11-05 19:05:10,046 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9277 | Iter Mean Loss 9.2505
2020-11-05 19:05:10,057 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5298 | Iter Mean Loss 8.9064
2020-11-05 19:05:10,060 - root - INFO - Evaluate: Epoch 0318 | NDCG 1.0000 | MSE 0.3478
2020-11-05 19:05:10,075 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8935 | Iter Mean Loss 9.8935
2020-11-05 19:05:10,086 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5581 | Iter Mean Loss 6.7258
2020-11-05 19:05:10,094 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5547 | Iter Mean Loss 8.6688
2020-11-05 19:05:10,102 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8990 | Iter Mean Loss 9.2264
2020-11-05 19:05:10,112 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5039 | Iter Mean Loss 8.8819
2020-11-05 19:05:10,115 - root - INFO - Evaluate: Epoch 0319 | NDCG 1.0000 | MSE 0.3475
2020-11-05 19:05:10,125 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8712 | Iter Mean Loss 9.8712
2020-11-05 19:05:10,135 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5512 | Iter Mean Loss 6.7112
2020-11-05 19:05:10,145 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5160 | Iter Mean Loss 8.6461
2020-11-05 19:05:10,153 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8704 | Iter Mean Loss 9.2022
2020-11-05 19:05:10,161 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4783 | Iter Mean Loss 8.8574
2020-11-05 19:05:10,163 - root - INFO - Evaluate: Epoch 0320 | NDCG 1.0000 | MSE 0.3472
2020-11-05 19:05:10,172 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8487 | Iter Mean Loss 9.8487
2020-11-05 19:05:10,184 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5442 | Iter Mean Loss 6.6965
2020-11-05 19:05:10,197 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4775 | Iter Mean Loss 8.6235
2020-11-05 19:05:10,207 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8418 | Iter Mean Loss 9.1781
2020-11-05 19:05:10,218 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4527 | Iter Mean Loss 8.8330
2020-11-05 19:05:10,221 - root - INFO - Evaluate: Epoch 0321 | NDCG 1.0000 | MSE 0.3468
2020-11-05 19:05:10,231 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8262 | Iter Mean Loss 9.8262
2020-11-05 19:05:10,239 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5372 | Iter Mean Loss 6.6817
2020-11-05 19:05:10,248 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4393 | Iter Mean Loss 8.6009
2020-11-05 19:05:10,258 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8133 | Iter Mean Loss 9.1540
2020-11-05 19:05:10,269 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4274 | Iter Mean Loss 8.8087
2020-11-05 19:05:10,272 - root - INFO - Evaluate: Epoch 0322 | NDCG 1.0000 | MSE 0.3465
2020-11-05 19:05:10,284 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8036 | Iter Mean Loss 9.8036
2020-11-05 19:05:10,296 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5302 | Iter Mean Loss 6.6669
2020-11-05 19:05:10,305 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4013 | Iter Mean Loss 8.5784
2020-11-05 19:05:10,316 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7848 | Iter Mean Loss 9.1300
2020-11-05 19:05:10,331 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4022 | Iter Mean Loss 8.7844
2020-11-05 19:05:10,333 - root - INFO - Evaluate: Epoch 0323 | NDCG 1.0000 | MSE 0.3462
2020-11-05 19:05:10,344 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7808 | Iter Mean Loss 9.7808
2020-11-05 19:05:10,353 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5231 | Iter Mean Loss 6.6520
2020-11-05 19:05:10,364 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3635 | Iter Mean Loss 8.5558
2020-11-05 19:05:10,373 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7564 | Iter Mean Loss 9.1060
2020-11-05 19:05:10,383 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 8.7602
2020-11-05 19:05:10,386 - root - INFO - Evaluate: Epoch 0324 | NDCG 1.0000 | MSE 0.3459
2020-11-05 19:05:10,398 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7580 | Iter Mean Loss 9.7580
2020-11-05 19:05:10,407 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5160 | Iter Mean Loss 6.6370
2020-11-05 19:05:10,418 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 8.5334
2020-11-05 19:05:10,427 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7281 | Iter Mean Loss 9.0820
2020-11-05 19:05:10,437 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3522 | Iter Mean Loss 8.7361
2020-11-05 19:05:10,440 - root - INFO - Evaluate: Epoch 0325 | NDCG 1.0000 | MSE 0.3456
2020-11-05 19:05:10,451 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7351 | Iter Mean Loss 9.7351
2020-11-05 19:05:10,461 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5089 | Iter Mean Loss 6.6220
2020-11-05 19:05:10,471 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2888 | Iter Mean Loss 8.5109
2020-11-05 19:05:10,480 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6998 | Iter Mean Loss 9.0581
2020-11-05 19:05:10,489 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3274 | Iter Mean Loss 8.7120
2020-11-05 19:05:10,491 - root - INFO - Evaluate: Epoch 0326 | NDCG 1.0000 | MSE 0.3453
2020-11-05 19:05:10,500 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7120 | Iter Mean Loss 9.7120
2020-11-05 19:05:10,508 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5018 | Iter Mean Loss 6.6069
2020-11-05 19:05:10,518 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2517 | Iter Mean Loss 8.4885
2020-11-05 19:05:10,527 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6715 | Iter Mean Loss 9.0343
2020-11-05 19:05:10,537 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3028 | Iter Mean Loss 8.6880
2020-11-05 19:05:10,540 - root - INFO - Evaluate: Epoch 0327 | NDCG 1.0000 | MSE 0.3450
2020-11-05 19:05:10,550 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6890 | Iter Mean Loss 9.6890
2020-11-05 19:05:10,559 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4946 | Iter Mean Loss 6.5918
2020-11-05 19:05:10,570 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2149 | Iter Mean Loss 8.4662
2020-11-05 19:05:10,578 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6433 | Iter Mean Loss 9.0104
2020-11-05 19:05:10,588 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2784 | Iter Mean Loss 8.6640
2020-11-05 19:05:10,590 - root - INFO - Evaluate: Epoch 0328 | NDCG 1.0000 | MSE 0.3447
2020-11-05 19:05:10,601 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6658 | Iter Mean Loss 9.6658
2020-11-05 19:05:10,609 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4874 | Iter Mean Loss 6.5766
2020-11-05 19:05:10,618 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1783 | Iter Mean Loss 8.4438
2020-11-05 19:05:10,627 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6152 | Iter Mean Loss 8.9867
2020-11-05 19:05:10,636 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2541 | Iter Mean Loss 8.6402
2020-11-05 19:05:10,638 - root - INFO - Evaluate: Epoch 0329 | NDCG 1.0000 | MSE 0.3444
2020-11-05 19:05:10,646 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6425 | Iter Mean Loss 9.6425
2020-11-05 19:05:10,656 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4802 | Iter Mean Loss 6.5614
2020-11-05 19:05:10,664 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1420 | Iter Mean Loss 8.4216
2020-11-05 19:05:10,674 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5871 | Iter Mean Loss 8.9629
2020-11-05 19:05:10,682 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2300 | Iter Mean Loss 8.6164
2020-11-05 19:05:10,685 - root - INFO - Evaluate: Epoch 0330 | NDCG 1.0000 | MSE 0.3441
2020-11-05 19:05:10,695 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6192 | Iter Mean Loss 9.6192
2020-11-05 19:05:10,703 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4730 | Iter Mean Loss 6.5461
2020-11-05 19:05:10,711 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1058 | Iter Mean Loss 8.3993
2020-11-05 19:05:10,718 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5591 | Iter Mean Loss 8.9393
2020-11-05 19:05:10,726 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2060 | Iter Mean Loss 8.5926
2020-11-05 19:05:10,730 - root - INFO - Evaluate: Epoch 0331 | NDCG 1.0000 | MSE 0.3438
2020-11-05 19:05:10,739 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.5958
2020-11-05 19:05:10,749 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4657 | Iter Mean Loss 6.5308
2020-11-05 19:05:10,756 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0699 | Iter Mean Loss 8.3772
2020-11-05 19:05:10,764 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5311 | Iter Mean Loss 8.9156
2020-11-05 19:05:10,771 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1822 | Iter Mean Loss 8.5689
2020-11-05 19:05:10,774 - root - INFO - Evaluate: Epoch 0332 | NDCG 1.0000 | MSE 0.3435
2020-11-05 19:05:10,783 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5724 | Iter Mean Loss 9.5724
2020-11-05 19:05:10,791 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4584 | Iter Mean Loss 6.5154
2020-11-05 19:05:10,798 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0343 | Iter Mean Loss 8.3550
2020-11-05 19:05:10,807 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5032 | Iter Mean Loss 8.8921
2020-11-05 19:05:10,817 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1585 | Iter Mean Loss 8.5454
2020-11-05 19:05:10,819 - root - INFO - Evaluate: Epoch 0333 | NDCG 1.0000 | MSE 0.3433
2020-11-05 19:05:10,828 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5489 | Iter Mean Loss 9.5489
2020-11-05 19:05:10,836 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4511 | Iter Mean Loss 6.5000
2020-11-05 19:05:10,847 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9988 | Iter Mean Loss 8.3329
2020-11-05 19:05:10,855 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4754 | Iter Mean Loss 8.8685
2020-11-05 19:05:10,864 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1350 | Iter Mean Loss 8.5218
2020-11-05 19:05:10,866 - root - INFO - Evaluate: Epoch 0334 | NDCG 1.0000 | MSE 0.3430
2020-11-05 19:05:10,876 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5253 | Iter Mean Loss 9.5253
2020-11-05 19:05:10,885 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4438 | Iter Mean Loss 6.4846
2020-11-05 19:05:10,892 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 8.3109
2020-11-05 19:05:10,899 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4476 | Iter Mean Loss 8.8451
2020-11-05 19:05:10,907 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1116 | Iter Mean Loss 8.4984
2020-11-05 19:05:10,909 - root - INFO - Evaluate: Epoch 0335 | NDCG 1.0000 | MSE 0.3427
2020-11-05 19:05:10,919 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5017 | Iter Mean Loss 9.5017
2020-11-05 19:05:10,927 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4365 | Iter Mean Loss 6.4691
2020-11-05 19:05:10,937 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9286 | Iter Mean Loss 8.2889
2020-11-05 19:05:10,944 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4199 | Iter Mean Loss 8.8217
2020-11-05 19:05:10,951 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0884 | Iter Mean Loss 8.4750
2020-11-05 19:05:10,953 - root - INFO - Evaluate: Epoch 0336 | NDCG 1.0000 | MSE 0.3424
2020-11-05 19:05:10,963 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4780 | Iter Mean Loss 9.4780
2020-11-05 19:05:10,972 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4292 | Iter Mean Loss 6.4536
2020-11-05 19:05:10,979 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8938 | Iter Mean Loss 8.2670
2020-11-05 19:05:10,987 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3922 | Iter Mean Loss 8.7983
2020-11-05 19:05:10,996 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0654 | Iter Mean Loss 8.4517
2020-11-05 19:05:10,999 - root - INFO - Evaluate: Epoch 0337 | NDCG 1.0000 | MSE 0.3421
2020-11-05 19:05:11,007 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4543 | Iter Mean Loss 9.4543
2020-11-05 19:05:11,017 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4218 | Iter Mean Loss 6.4381
2020-11-05 19:05:11,026 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8592 | Iter Mean Loss 8.2451
2020-11-05 19:05:11,035 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3647 | Iter Mean Loss 8.7750
2020-11-05 19:05:11,042 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0425 | Iter Mean Loss 8.4285
2020-11-05 19:05:11,045 - root - INFO - Evaluate: Epoch 0338 | NDCG 1.0000 | MSE 0.3419
2020-11-05 19:05:11,054 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4306 | Iter Mean Loss 9.4306
2020-11-05 19:05:11,063 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.4225
2020-11-05 19:05:11,072 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8248 | Iter Mean Loss 8.2233
2020-11-05 19:05:11,083 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3371 | Iter Mean Loss 8.7518
2020-11-05 19:05:11,091 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0198 | Iter Mean Loss 8.4054
2020-11-05 19:05:11,093 - root - INFO - Evaluate: Epoch 0339 | NDCG 1.0000 | MSE 0.3416
2020-11-05 19:05:11,101 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 9.4068
2020-11-05 19:05:11,110 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4071 | Iter Mean Loss 6.4070
2020-11-05 19:05:11,119 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7907 | Iter Mean Loss 8.2015
2020-11-05 19:05:11,126 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3097 | Iter Mean Loss 8.7286
2020-11-05 19:05:11,135 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9972 | Iter Mean Loss 8.3823
2020-11-05 19:05:11,137 - root - INFO - Evaluate: Epoch 0340 | NDCG 1.0000 | MSE 0.3413
2020-11-05 19:05:11,146 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3830 | Iter Mean Loss 9.3830
2020-11-05 19:05:11,155 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3998 | Iter Mean Loss 6.3914
2020-11-05 19:05:11,162 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7568 | Iter Mean Loss 8.1798
2020-11-05 19:05:11,170 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2824 | Iter Mean Loss 8.7055
2020-11-05 19:05:11,180 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9748 | Iter Mean Loss 8.3593
2020-11-05 19:05:11,182 - root - INFO - Evaluate: Epoch 0341 | NDCG 1.0000 | MSE 0.3411
2020-11-05 19:05:11,191 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3592 | Iter Mean Loss 9.3592
2020-11-05 19:05:11,199 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3924 | Iter Mean Loss 6.3758
2020-11-05 19:05:11,209 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7231 | Iter Mean Loss 8.1582
2020-11-05 19:05:11,217 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2551 | Iter Mean Loss 8.6824
2020-11-05 19:05:11,225 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9526 | Iter Mean Loss 8.3365
2020-11-05 19:05:11,227 - root - INFO - Evaluate: Epoch 0342 | NDCG 1.0000 | MSE 0.3408
2020-11-05 19:05:11,236 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3354 | Iter Mean Loss 9.3354
2020-11-05 19:05:11,244 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3850 | Iter Mean Loss 6.3602
2020-11-05 19:05:11,254 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6896 | Iter Mean Loss 8.1367
2020-11-05 19:05:11,263 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2279 | Iter Mean Loss 8.6595
2020-11-05 19:05:11,272 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9305 | Iter Mean Loss 8.3137
2020-11-05 19:05:11,274 - root - INFO - Evaluate: Epoch 0343 | NDCG 1.0000 | MSE 0.3406
2020-11-05 19:05:11,282 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3115 | Iter Mean Loss 9.3115
2020-11-05 19:05:11,290 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3777 | Iter Mean Loss 6.3446
2020-11-05 19:05:11,298 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6563 | Iter Mean Loss 8.1152
2020-11-05 19:05:11,305 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2007 | Iter Mean Loss 8.6366
2020-11-05 19:05:11,316 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 8.2910
2020-11-05 19:05:11,318 - root - INFO - Evaluate: Epoch 0344 | NDCG 1.0000 | MSE 0.3403
2020-11-05 19:05:11,328 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2877 | Iter Mean Loss 9.2877
2020-11-05 19:05:11,337 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3703 | Iter Mean Loss 6.3290
2020-11-05 19:05:11,344 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6232 | Iter Mean Loss 8.0937
2020-11-05 19:05:11,352 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1737 | Iter Mean Loss 8.6137
2020-11-05 19:05:11,361 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 8.2683
2020-11-05 19:05:11,363 - root - INFO - Evaluate: Epoch 0345 | NDCG 1.0000 | MSE 0.3401
2020-11-05 19:05:11,371 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2638 | Iter Mean Loss 9.2638
2020-11-05 19:05:11,379 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3629 | Iter Mean Loss 6.3134
2020-11-05 19:05:11,387 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5904 | Iter Mean Loss 8.0724
2020-11-05 19:05:11,397 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1467 | Iter Mean Loss 8.5910
2020-11-05 19:05:11,405 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8652 | Iter Mean Loss 8.2458
2020-11-05 19:05:11,407 - root - INFO - Evaluate: Epoch 0346 | NDCG 1.0000 | MSE 0.3398
2020-11-05 19:05:11,420 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2400 | Iter Mean Loss 9.2400
2020-11-05 19:05:11,431 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.2978
2020-11-05 19:05:11,439 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5577 | Iter Mean Loss 8.0511
2020-11-05 19:05:11,448 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1199 | Iter Mean Loss 8.5683
2020-11-05 19:05:11,457 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8438 | Iter Mean Loss 8.2234
2020-11-05 19:05:11,460 - root - INFO - Evaluate: Epoch 0347 | NDCG 1.0000 | MSE 0.3396
2020-11-05 19:05:11,471 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2162 | Iter Mean Loss 9.2162
2020-11-05 19:05:11,483 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3482 | Iter Mean Loss 6.2822
2020-11-05 19:05:11,491 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5253 | Iter Mean Loss 8.0299
2020-11-05 19:05:11,502 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0931 | Iter Mean Loss 8.5457
2020-11-05 19:05:11,513 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8226 | Iter Mean Loss 8.2011
2020-11-05 19:05:11,516 - root - INFO - Evaluate: Epoch 0348 | NDCG 1.0000 | MSE 0.3393
2020-11-05 19:05:11,526 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1924 | Iter Mean Loss 9.1924
2020-11-05 19:05:11,535 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3409 | Iter Mean Loss 6.2666
2020-11-05 19:05:11,543 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4931 | Iter Mean Loss 8.0088
2020-11-05 19:05:11,553 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 8.5232
2020-11-05 19:05:11,562 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8015 | Iter Mean Loss 8.1788
2020-11-05 19:05:11,565 - root - INFO - Evaluate: Epoch 0349 | NDCG 1.0000 | MSE 0.3391
2020-11-05 19:05:11,577 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1686 | Iter Mean Loss 9.1686
2020-11-05 19:05:11,584 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3336 | Iter Mean Loss 6.2511
2020-11-05 19:05:11,592 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4611 | Iter Mean Loss 7.9878
2020-11-05 19:05:11,599 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0398 | Iter Mean Loss 8.5008
2020-11-05 19:05:11,607 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7806 | Iter Mean Loss 8.1567
2020-11-05 19:05:11,609 - root - INFO - Evaluate: Epoch 0350 | NDCG 1.0000 | MSE 0.3389
2020-11-05 19:05:11,619 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1448 | Iter Mean Loss 9.1448
2020-11-05 19:05:11,628 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3263 | Iter Mean Loss 6.2355
2020-11-05 19:05:11,638 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4293 | Iter Mean Loss 7.9668
2020-11-05 19:05:11,645 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0133 | Iter Mean Loss 8.4784
2020-11-05 19:05:11,653 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 8.1347
2020-11-05 19:05:11,656 - root - INFO - Evaluate: Epoch 0351 | NDCG 1.0000 | MSE 0.3386
2020-11-05 19:05:11,664 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1211 | Iter Mean Loss 9.1211
2020-11-05 19:05:11,673 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3190 | Iter Mean Loss 6.2200
2020-11-05 19:05:11,682 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3978 | Iter Mean Loss 7.9460
2020-11-05 19:05:11,691 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9869 | Iter Mean Loss 8.4562
2020-11-05 19:05:11,700 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7392 | Iter Mean Loss 8.1128
2020-11-05 19:05:11,702 - root - INFO - Evaluate: Epoch 0352 | NDCG 1.0000 | MSE 0.3384
2020-11-05 19:05:11,711 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0974 | Iter Mean Loss 9.0974
2020-11-05 19:05:11,720 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3117 | Iter Mean Loss 6.2046
2020-11-05 19:05:11,728 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3664 | Iter Mean Loss 7.9252
2020-11-05 19:05:11,736 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9606 | Iter Mean Loss 8.4340
2020-11-05 19:05:11,744 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7188 | Iter Mean Loss 8.0910
2020-11-05 19:05:11,746 - root - INFO - Evaluate: Epoch 0353 | NDCG 1.0000 | MSE 0.3382
2020-11-05 19:05:11,754 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0738 | Iter Mean Loss 9.0738
2020-11-05 19:05:11,763 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3045 | Iter Mean Loss 6.1891
2020-11-05 19:05:11,771 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3353 | Iter Mean Loss 7.9045
2020-11-05 19:05:11,780 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9343 | Iter Mean Loss 8.4120
2020-11-05 19:05:11,789 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6986 | Iter Mean Loss 8.0693
2020-11-05 19:05:11,791 - root - INFO - Evaluate: Epoch 0354 | NDCG 1.0000 | MSE 0.3380
2020-11-05 19:05:11,799 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0502 | Iter Mean Loss 9.0502
2020-11-05 19:05:11,807 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2973 | Iter Mean Loss 6.1737
2020-11-05 19:05:11,815 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 7.8839
2020-11-05 19:05:11,824 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9082 | Iter Mean Loss 8.3900
2020-11-05 19:05:11,833 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6785 | Iter Mean Loss 8.0477
2020-11-05 19:05:11,835 - root - INFO - Evaluate: Epoch 0355 | NDCG 1.0000 | MSE 0.3377
2020-11-05 19:05:11,846 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0267 | Iter Mean Loss 9.0267
2020-11-05 19:05:11,854 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2901 | Iter Mean Loss 6.1584
2020-11-05 19:05:11,862 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2736 | Iter Mean Loss 7.8635
2020-11-05 19:05:11,872 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8822 | Iter Mean Loss 8.3681
2020-11-05 19:05:11,881 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6586 | Iter Mean Loss 8.0262
2020-11-05 19:05:11,883 - root - INFO - Evaluate: Epoch 0356 | NDCG 1.0000 | MSE 0.3375
2020-11-05 19:05:11,891 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0032 | Iter Mean Loss 9.0032
2020-11-05 19:05:11,900 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2829 | Iter Mean Loss 6.1431
2020-11-05 19:05:11,909 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2431 | Iter Mean Loss 7.8431
2020-11-05 19:05:11,917 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8563 | Iter Mean Loss 8.3464
2020-11-05 19:05:11,925 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6389 | Iter Mean Loss 8.0049
2020-11-05 19:05:11,927 - root - INFO - Evaluate: Epoch 0357 | NDCG 1.0000 | MSE 0.3373
2020-11-05 19:05:11,936 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9799 | Iter Mean Loss 8.9799
2020-11-05 19:05:11,945 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2758 | Iter Mean Loss 6.1278
2020-11-05 19:05:11,953 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2128 | Iter Mean Loss 7.8228
2020-11-05 19:05:11,960 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8306 | Iter Mean Loss 8.3247
2020-11-05 19:05:11,967 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6193 | Iter Mean Loss 7.9837
2020-11-05 19:05:11,970 - root - INFO - Evaluate: Epoch 0358 | NDCG 1.0000 | MSE 0.3371
2020-11-05 19:05:11,980 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9565 | Iter Mean Loss 8.9565
2020-11-05 19:05:11,988 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2687 | Iter Mean Loss 6.1126
2020-11-05 19:05:11,998 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1827 | Iter Mean Loss 7.8026
2020-11-05 19:05:12,006 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8049 | Iter Mean Loss 8.3032
2020-11-05 19:05:12,013 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5999 | Iter Mean Loss 7.9625
2020-11-05 19:05:12,016 - root - INFO - Evaluate: Epoch 0359 | NDCG 1.0000 | MSE 0.3369
2020-11-05 19:05:12,024 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9333 | Iter Mean Loss 8.9333
2020-11-05 19:05:12,032 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2616 | Iter Mean Loss 6.0975
2020-11-05 19:05:12,041 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1528 | Iter Mean Loss 7.7826
2020-11-05 19:05:12,050 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7793 | Iter Mean Loss 8.2818
2020-11-05 19:05:12,059 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5807 | Iter Mean Loss 7.9416
2020-11-05 19:05:12,061 - root - INFO - Evaluate: Epoch 0360 | NDCG 1.0000 | MSE 0.3367
2020-11-05 19:05:12,070 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9102 | Iter Mean Loss 8.9102
2020-11-05 19:05:12,078 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 6.0824
2020-11-05 19:05:12,088 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1232 | Iter Mean Loss 7.7626
2020-11-05 19:05:12,096 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7539 | Iter Mean Loss 8.2604
2020-11-05 19:05:12,105 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5616 | Iter Mean Loss 7.9207
2020-11-05 19:05:12,107 - root - INFO - Evaluate: Epoch 0361 | NDCG 1.0000 | MSE 0.3365
2020-11-05 19:05:12,115 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8871 | Iter Mean Loss 8.8871
2020-11-05 19:05:12,124 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2475 | Iter Mean Loss 6.0673
2020-11-05 19:05:12,133 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0937 | Iter Mean Loss 7.7428
2020-11-05 19:05:12,141 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7285 | Iter Mean Loss 8.2392
2020-11-05 19:05:12,152 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5428 | Iter Mean Loss 7.8999
2020-11-05 19:05:12,154 - root - INFO - Evaluate: Epoch 0362 | NDCG 1.0000 | MSE 0.3363
2020-11-05 19:05:12,162 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8642 | Iter Mean Loss 8.8642
2020-11-05 19:05:12,169 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2406 | Iter Mean Loss 6.0524
2020-11-05 19:05:12,177 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0645 | Iter Mean Loss 7.7231
2020-11-05 19:05:12,184 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7033 | Iter Mean Loss 8.2181
2020-11-05 19:05:12,192 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5241 | Iter Mean Loss 7.8793
2020-11-05 19:05:12,196 - root - INFO - Evaluate: Epoch 0363 | NDCG 1.0000 | MSE 0.3361
2020-11-05 19:05:12,205 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8413 | Iter Mean Loss 8.8413
2020-11-05 19:05:12,214 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2337 | Iter Mean Loss 6.0375
2020-11-05 19:05:12,222 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0355 | Iter Mean Loss 7.7035
2020-11-05 19:05:12,229 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6783 | Iter Mean Loss 8.1972
2020-11-05 19:05:12,237 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5055 | Iter Mean Loss 7.8588
2020-11-05 19:05:12,240 - root - INFO - Evaluate: Epoch 0364 | NDCG 1.0000 | MSE 0.3359
2020-11-05 19:05:12,249 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8186 | Iter Mean Loss 8.8186
2020-11-05 19:05:12,257 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2268 | Iter Mean Loss 6.0227
2020-11-05 19:05:12,266 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0066 | Iter Mean Loss 7.6840
2020-11-05 19:05:12,275 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6533 | Iter Mean Loss 8.1763
2020-11-05 19:05:12,284 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4871 | Iter Mean Loss 7.8385
2020-11-05 19:05:12,286 - root - INFO - Evaluate: Epoch 0365 | NDCG 1.0000 | MSE 0.3357
2020-11-05 19:05:12,296 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7960 | Iter Mean Loss 8.7960
2020-11-05 19:05:12,304 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2199 | Iter Mean Loss 6.0079
2020-11-05 19:05:12,314 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9780 | Iter Mean Loss 7.6646
2020-11-05 19:05:12,322 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6285 | Iter Mean Loss 8.1556
2020-11-05 19:05:12,330 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4689 | Iter Mean Loss 7.8183
2020-11-05 19:05:12,332 - root - INFO - Evaluate: Epoch 0366 | NDCG 1.0000 | MSE 0.3355
2020-11-05 19:05:12,341 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7734 | Iter Mean Loss 8.7734
2020-11-05 19:05:12,350 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2131 | Iter Mean Loss 5.9933
2020-11-05 19:05:12,358 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9496 | Iter Mean Loss 7.6454
2020-11-05 19:05:12,367 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6037 | Iter Mean Loss 8.1350
2020-11-05 19:05:12,375 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4509 | Iter Mean Loss 7.7982
2020-11-05 19:05:12,377 - root - INFO - Evaluate: Epoch 0367 | NDCG 1.0000 | MSE 0.3353
2020-11-05 19:05:12,385 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7510 | Iter Mean Loss 8.7510
2020-11-05 19:05:12,393 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2064 | Iter Mean Loss 5.9787
2020-11-05 19:05:12,402 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9214 | Iter Mean Loss 7.6263
2020-11-05 19:05:12,409 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5792 | Iter Mean Loss 8.1145
2020-11-05 19:05:12,417 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4330 | Iter Mean Loss 7.7782
2020-11-05 19:05:12,420 - root - INFO - Evaluate: Epoch 0368 | NDCG 1.0000 | MSE 0.3351
2020-11-05 19:05:12,429 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7288 | Iter Mean Loss 8.7288
2020-11-05 19:05:12,436 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1997 | Iter Mean Loss 5.9642
2020-11-05 19:05:12,444 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8934 | Iter Mean Loss 7.6073
2020-11-05 19:05:12,451 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5547 | Iter Mean Loss 8.0941
2020-11-05 19:05:12,460 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4153 | Iter Mean Loss 7.7584
2020-11-05 19:05:12,463 - root - INFO - Evaluate: Epoch 0369 | NDCG 1.0000 | MSE 0.3350
2020-11-05 19:05:12,471 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7066 | Iter Mean Loss 8.7066
2020-11-05 19:05:12,480 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1930 | Iter Mean Loss 5.9498
2020-11-05 19:05:12,489 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8657 | Iter Mean Loss 7.5884
2020-11-05 19:05:12,497 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5304 | Iter Mean Loss 8.0739
2020-11-05 19:05:12,505 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3977 | Iter Mean Loss 7.7387
2020-11-05 19:05:12,507 - root - INFO - Evaluate: Epoch 0370 | NDCG 1.0000 | MSE 0.3348
2020-11-05 19:05:12,515 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6846 | Iter Mean Loss 8.6846
2020-11-05 19:05:12,523 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1864 | Iter Mean Loss 5.9355
2020-11-05 19:05:12,533 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8381 | Iter Mean Loss 7.5697
2020-11-05 19:05:12,540 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5062 | Iter Mean Loss 8.0538
2020-11-05 19:05:12,550 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3803 | Iter Mean Loss 7.7191
2020-11-05 19:05:12,552 - root - INFO - Evaluate: Epoch 0371 | NDCG 1.0000 | MSE 0.3346
2020-11-05 19:05:12,560 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6628 | Iter Mean Loss 8.6628
2020-11-05 19:05:12,568 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1799 | Iter Mean Loss 5.9213
2020-11-05 19:05:12,576 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 7.5511
2020-11-05 19:05:12,585 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 8.0339
2020-11-05 19:05:12,593 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3631 | Iter Mean Loss 7.6997
2020-11-05 19:05:12,595 - root - INFO - Evaluate: Epoch 0372 | NDCG 1.0000 | MSE 0.3344
2020-11-05 19:05:12,603 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6410 | Iter Mean Loss 8.6410
2020-11-05 19:05:12,612 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.9072
2020-11-05 19:05:12,620 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7835 | Iter Mean Loss 7.5326
2020-11-05 19:05:12,629 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4582 | Iter Mean Loss 8.0140
2020-11-05 19:05:12,637 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3460 | Iter Mean Loss 7.6804
2020-11-05 19:05:12,639 - root - INFO - Evaluate: Epoch 0373 | NDCG 1.0000 | MSE 0.3343
2020-11-05 19:05:12,650 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6194 | Iter Mean Loss 8.6194
2020-11-05 19:05:12,658 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1669 | Iter Mean Loss 5.8932
2020-11-05 19:05:12,666 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7566 | Iter Mean Loss 7.5143
2020-11-05 19:05:12,675 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4344 | Iter Mean Loss 7.9943
2020-11-05 19:05:12,682 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3291 | Iter Mean Loss 7.6613
2020-11-05 19:05:12,685 - root - INFO - Evaluate: Epoch 0374 | NDCG 1.0000 | MSE 0.3341
2020-11-05 19:05:12,694 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5980 | Iter Mean Loss 8.5980
2020-11-05 19:05:12,702 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1605 | Iter Mean Loss 5.8792
2020-11-05 19:05:12,712 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7298 | Iter Mean Loss 7.4961
2020-11-05 19:05:12,720 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4108 | Iter Mean Loss 7.9748
2020-11-05 19:05:12,730 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3124 | Iter Mean Loss 7.6423
2020-11-05 19:05:12,732 - root - INFO - Evaluate: Epoch 0375 | NDCG 1.0000 | MSE 0.3339
2020-11-05 19:05:12,741 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5767
2020-11-05 19:05:12,748 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 5.8654
2020-11-05 19:05:12,756 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7033 | Iter Mean Loss 7.4780
2020-11-05 19:05:12,765 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3873 | Iter Mean Loss 7.9553
2020-11-05 19:05:12,772 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2958 | Iter Mean Loss 7.6234
2020-11-05 19:05:12,774 - root - INFO - Evaluate: Epoch 0376 | NDCG 1.0000 | MSE 0.3338
2020-11-05 19:05:12,782 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5555 | Iter Mean Loss 8.5555
2020-11-05 19:05:12,790 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1479 | Iter Mean Loss 5.8517
2020-11-05 19:05:12,799 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6769 | Iter Mean Loss 7.4601
2020-11-05 19:05:12,806 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3639 | Iter Mean Loss 7.9360
2020-11-05 19:05:12,814 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2793 | Iter Mean Loss 7.6047
2020-11-05 19:05:12,816 - root - INFO - Evaluate: Epoch 0377 | NDCG 1.0000 | MSE 0.3336
2020-11-05 19:05:12,827 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5346 | Iter Mean Loss 8.5346
2020-11-05 19:05:12,835 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1416 | Iter Mean Loss 5.8381
2020-11-05 19:05:12,844 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6507 | Iter Mean Loss 7.4423
2020-11-05 19:05:12,852 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3407 | Iter Mean Loss 7.9169
2020-11-05 19:05:12,861 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2630 | Iter Mean Loss 7.5861
2020-11-05 19:05:12,865 - root - INFO - Evaluate: Epoch 0378 | NDCG 1.0000 | MSE 0.3335
2020-11-05 19:05:12,875 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5137 | Iter Mean Loss 8.5137
2020-11-05 19:05:12,885 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1355 | Iter Mean Loss 5.8246
2020-11-05 19:05:12,893 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6248 | Iter Mean Loss 7.4246
2020-11-05 19:05:12,901 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3176 | Iter Mean Loss 7.8979
2020-11-05 19:05:12,910 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2468 | Iter Mean Loss 7.5677
2020-11-05 19:05:12,913 - root - INFO - Evaluate: Epoch 0379 | NDCG 1.0000 | MSE 0.3333
2020-11-05 19:05:12,923 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4930 | Iter Mean Loss 8.4930
2020-11-05 19:05:12,931 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1293 | Iter Mean Loss 5.8112
2020-11-05 19:05:12,940 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5990 | Iter Mean Loss 7.4071
2020-11-05 19:05:12,948 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2946 | Iter Mean Loss 7.8790
2020-11-05 19:05:12,956 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2308 | Iter Mean Loss 7.5494
2020-11-05 19:05:12,958 - root - INFO - Evaluate: Epoch 0380 | NDCG 1.0000 | MSE 0.3332
2020-11-05 19:05:12,965 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4725 | Iter Mean Loss 8.4725
2020-11-05 19:05:12,973 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1233 | Iter Mean Loss 5.7979
2020-11-05 19:05:12,982 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 7.3897
2020-11-05 19:05:12,990 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2718 | Iter Mean Loss 7.8602
2020-11-05 19:05:12,997 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2150 | Iter Mean Loss 7.5312
2020-11-05 19:05:13,000 - root - INFO - Evaluate: Epoch 0381 | NDCG 1.0000 | MSE 0.3330
2020-11-05 19:05:13,009 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 19:05:13,016 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1172 | Iter Mean Loss 5.7847
2020-11-05 19:05:13,024 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5480 | Iter Mean Loss 7.3725
2020-11-05 19:05:13,032 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2491 | Iter Mean Loss 7.8416
2020-11-05 19:05:13,040 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 7.5132
2020-11-05 19:05:13,043 - root - INFO - Evaluate: Epoch 0382 | NDCG 1.0000 | MSE 0.3329
2020-11-05 19:05:13,052 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4320 | Iter Mean Loss 8.4320
2020-11-05 19:05:13,061 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1113 | Iter Mean Loss 5.7716
2020-11-05 19:05:13,071 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5228 | Iter Mean Loss 7.3554
2020-11-05 19:05:13,079 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2266 | Iter Mean Loss 7.8232
2020-11-05 19:05:13,090 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1836 | Iter Mean Loss 7.4953
2020-11-05 19:05:13,092 - root - INFO - Evaluate: Epoch 0383 | NDCG 1.0000 | MSE 0.3327
2020-11-05 19:05:13,103 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4119 | Iter Mean Loss 8.4119
2020-11-05 19:05:13,111 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1054 | Iter Mean Loss 5.7587
2020-11-05 19:05:13,121 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4978 | Iter Mean Loss 7.3384
2020-11-05 19:05:13,131 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2042 | Iter Mean Loss 7.8048
2020-11-05 19:05:13,140 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1682 | Iter Mean Loss 7.4775
2020-11-05 19:05:13,142 - root - INFO - Evaluate: Epoch 0384 | NDCG 1.0000 | MSE 0.3326
2020-11-05 19:05:13,151 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3921 | Iter Mean Loss 8.3921
2020-11-05 19:05:13,161 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0996 | Iter Mean Loss 5.7458
2020-11-05 19:05:13,169 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4730 | Iter Mean Loss 7.3215
2020-11-05 19:05:13,176 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1820 | Iter Mean Loss 7.7867
2020-11-05 19:05:13,184 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1529 | Iter Mean Loss 7.4599
2020-11-05 19:05:13,186 - root - INFO - Evaluate: Epoch 0385 | NDCG 1.0000 | MSE 0.3324
2020-11-05 19:05:13,196 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3724 | Iter Mean Loss 8.3724
2020-11-05 19:05:13,205 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0938 | Iter Mean Loss 5.7331
2020-11-05 19:05:13,213 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4483 | Iter Mean Loss 7.3048
2020-11-05 19:05:13,223 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1599 | Iter Mean Loss 7.7686
2020-11-05 19:05:13,230 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1377 | Iter Mean Loss 7.4424
2020-11-05 19:05:13,233 - root - INFO - Evaluate: Epoch 0386 | NDCG 1.0000 | MSE 0.3323
2020-11-05 19:05:13,242 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3528 | Iter Mean Loss 8.3528
2020-11-05 19:05:13,250 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0880 | Iter Mean Loss 5.7204
2020-11-05 19:05:13,262 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4239 | Iter Mean Loss 7.2883
2020-11-05 19:05:13,270 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1379 | Iter Mean Loss 7.7507
2020-11-05 19:05:13,279 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1227 | Iter Mean Loss 7.4251
2020-11-05 19:05:13,283 - root - INFO - Evaluate: Epoch 0387 | NDCG 1.0000 | MSE 0.3322
2020-11-05 19:05:13,292 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.3335
2020-11-05 19:05:13,299 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0824 | Iter Mean Loss 5.7079
2020-11-05 19:05:13,308 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3996 | Iter Mean Loss 7.2718
2020-11-05 19:05:13,317 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1161 | Iter Mean Loss 7.7329
2020-11-05 19:05:13,326 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1077 | Iter Mean Loss 7.4079
2020-11-05 19:05:13,328 - root - INFO - Evaluate: Epoch 0388 | NDCG 1.0000 | MSE 0.3320
2020-11-05 19:05:13,337 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3143 | Iter Mean Loss 8.3143
2020-11-05 19:05:13,346 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0768 | Iter Mean Loss 5.6955
2020-11-05 19:05:13,354 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3755 | Iter Mean Loss 7.2555
2020-11-05 19:05:13,362 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0945 | Iter Mean Loss 7.7153
2020-11-05 19:05:13,370 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0929 | Iter Mean Loss 7.3908
2020-11-05 19:05:13,374 - root - INFO - Evaluate: Epoch 0389 | NDCG 1.0000 | MSE 0.3319
2020-11-05 19:05:13,382 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2953 | Iter Mean Loss 8.2953
2020-11-05 19:05:13,389 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0712 | Iter Mean Loss 5.6832
2020-11-05 19:05:13,397 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3516 | Iter Mean Loss 7.2393
2020-11-05 19:05:13,404 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0729 | Iter Mean Loss 7.6977
2020-11-05 19:05:13,413 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0783 | Iter Mean Loss 7.3738
2020-11-05 19:05:13,415 - root - INFO - Evaluate: Epoch 0390 | NDCG 1.0000 | MSE 0.3318
2020-11-05 19:05:13,424 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2764 | Iter Mean Loss 8.2764
2020-11-05 19:05:13,434 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0657 | Iter Mean Loss 5.6711
2020-11-05 19:05:13,441 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3278 | Iter Mean Loss 7.2233
2020-11-05 19:05:13,448 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0516 | Iter Mean Loss 7.6804
2020-11-05 19:05:13,456 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0637 | Iter Mean Loss 7.3570
2020-11-05 19:05:13,458 - root - INFO - Evaluate: Epoch 0391 | NDCG 1.0000 | MSE 0.3317
2020-11-05 19:05:13,465 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2577 | Iter Mean Loss 8.2577
2020-11-05 19:05:13,474 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0603 | Iter Mean Loss 5.6590
2020-11-05 19:05:13,483 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3042 | Iter Mean Loss 7.2074
2020-11-05 19:05:13,491 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0303 | Iter Mean Loss 7.6631
2020-11-05 19:05:13,500 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0493 | Iter Mean Loss 7.3404
2020-11-05 19:05:13,502 - root - INFO - Evaluate: Epoch 0392 | NDCG 1.0000 | MSE 0.3315
2020-11-05 19:05:13,510 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2392 | Iter Mean Loss 8.2392
2020-11-05 19:05:13,520 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0549 | Iter Mean Loss 5.6470
2020-11-05 19:05:13,528 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2808 | Iter Mean Loss 7.1916
2020-11-05 19:05:13,536 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0092 | Iter Mean Loss 7.6460
2020-11-05 19:05:13,544 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0350 | Iter Mean Loss 7.3238
2020-11-05 19:05:13,547 - root - INFO - Evaluate: Epoch 0393 | NDCG 1.0000 | MSE 0.3314
2020-11-05 19:05:13,556 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2208 | Iter Mean Loss 8.2208
2020-11-05 19:05:13,565 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0495 | Iter Mean Loss 5.6352
2020-11-05 19:05:13,572 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2576 | Iter Mean Loss 7.1760
2020-11-05 19:05:13,580 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9883 | Iter Mean Loss 7.6291
2020-11-05 19:05:13,589 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0208 | Iter Mean Loss 7.3074
2020-11-05 19:05:13,592 - root - INFO - Evaluate: Epoch 0394 | NDCG 1.0000 | MSE 0.3313
2020-11-05 19:05:13,599 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2026 | Iter Mean Loss 8.2026
2020-11-05 19:05:13,607 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0443 | Iter Mean Loss 5.6234
2020-11-05 19:05:13,614 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2345 | Iter Mean Loss 7.1605
2020-11-05 19:05:13,622 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9675 | Iter Mean Loss 7.6122
2020-11-05 19:05:13,631 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0067 | Iter Mean Loss 7.2911
2020-11-05 19:05:13,634 - root - INFO - Evaluate: Epoch 0395 | NDCG 1.0000 | MSE 0.3312
2020-11-05 19:05:13,643 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1846 | Iter Mean Loss 8.1846
2020-11-05 19:05:13,652 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0390 | Iter Mean Loss 5.6118
2020-11-05 19:05:13,659 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2116 | Iter Mean Loss 7.1451
2020-11-05 19:05:13,667 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 7.5955
2020-11-05 19:05:13,674 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9927 | Iter Mean Loss 7.2749
2020-11-05 19:05:13,676 - root - INFO - Evaluate: Epoch 0396 | NDCG 1.0000 | MSE 0.3310
2020-11-05 19:05:13,685 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1667 | Iter Mean Loss 8.1667
2020-11-05 19:05:13,694 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0339 | Iter Mean Loss 5.6003
2020-11-05 19:05:13,704 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1889 | Iter Mean Loss 7.1298
2020-11-05 19:05:13,713 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9263 | Iter Mean Loss 7.5789
2020-11-05 19:05:13,721 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9788 | Iter Mean Loss 7.2589
2020-11-05 19:05:13,723 - root - INFO - Evaluate: Epoch 0397 | NDCG 1.0000 | MSE 0.3309
2020-11-05 19:05:13,733 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1490 | Iter Mean Loss 8.1490
2020-11-05 19:05:13,741 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0287 | Iter Mean Loss 5.5889
2020-11-05 19:05:13,750 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1663 | Iter Mean Loss 7.1147
2020-11-05 19:05:13,758 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9059 | Iter Mean Loss 7.5625
2020-11-05 19:05:13,765 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9650 | Iter Mean Loss 7.2430
2020-11-05 19:05:13,767 - root - INFO - Evaluate: Epoch 0398 | NDCG 1.0000 | MSE 0.3308
2020-11-05 19:05:13,776 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1315 | Iter Mean Loss 8.1315
2020-11-05 19:05:13,785 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0237 | Iter Mean Loss 5.5776
2020-11-05 19:05:13,792 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1439 | Iter Mean Loss 7.0997
2020-11-05 19:05:13,801 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8856 | Iter Mean Loss 7.5462
2020-11-05 19:05:13,810 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 7.2272
2020-11-05 19:05:13,812 - root - INFO - Evaluate: Epoch 0399 | NDCG 1.0000 | MSE 0.3307
2020-11-05 19:05:13,820 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1141 | Iter Mean Loss 8.1141
2020-11-05 19:05:13,827 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0187 | Iter Mean Loss 5.5664
2020-11-05 19:05:13,834 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1216 | Iter Mean Loss 7.0848
2020-11-05 19:05:13,842 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8655 | Iter Mean Loss 7.5300
2020-11-05 19:05:13,851 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9378 | Iter Mean Loss 7.2115
2020-11-05 19:05:13,853 - root - INFO - Evaluate: Epoch 0400 | NDCG 1.0000 | MSE 0.3306
2020-11-05 19:05:13,866 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0969 | Iter Mean Loss 8.0969
2020-11-05 19:05:13,873 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0137 | Iter Mean Loss 5.5553
2020-11-05 19:05:13,882 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0995 | Iter Mean Loss 7.0700
2020-11-05 19:05:13,890 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8455 | Iter Mean Loss 7.5139
2020-11-05 19:05:13,899 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9243 | Iter Mean Loss 7.1960
2020-11-05 19:05:13,902 - root - INFO - Evaluate: Epoch 0401 | NDCG 1.0000 | MSE 0.3305
2020-11-05 19:05:13,910 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0799 | Iter Mean Loss 8.0799
2020-11-05 19:05:13,919 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0088 | Iter Mean Loss 5.5443
2020-11-05 19:05:13,927 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0775 | Iter Mean Loss 7.0554
2020-11-05 19:05:13,936 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8257 | Iter Mean Loss 7.4979
2020-11-05 19:05:13,944 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9110 | Iter Mean Loss 7.1806
2020-11-05 19:05:13,948 - root - INFO - Evaluate: Epoch 0402 | NDCG 1.0000 | MSE 0.3304
2020-11-05 19:05:13,957 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0630 | Iter Mean Loss 8.0630
2020-11-05 19:05:13,965 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0039 | Iter Mean Loss 5.5334
2020-11-05 19:05:13,973 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0557 | Iter Mean Loss 7.0409
2020-11-05 19:05:13,980 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8059 | Iter Mean Loss 7.4821
2020-11-05 19:05:13,988 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8977 | Iter Mean Loss 7.1652
2020-11-05 19:05:13,990 - root - INFO - Evaluate: Epoch 0403 | NDCG 1.0000 | MSE 0.3303
2020-11-05 19:05:14,000 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0462 | Iter Mean Loss 8.0462
2020-11-05 19:05:14,008 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9991 | Iter Mean Loss 5.5227
2020-11-05 19:05:14,018 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0340 | Iter Mean Loss 7.0264
2020-11-05 19:05:14,025 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7864 | Iter Mean Loss 7.4664
2020-11-05 19:05:14,032 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8845 | Iter Mean Loss 7.1500
2020-11-05 19:05:14,035 - root - INFO - Evaluate: Epoch 0404 | NDCG 1.0000 | MSE 0.3302
2020-11-05 19:05:14,042 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0297 | Iter Mean Loss 8.0297
2020-11-05 19:05:14,050 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9943 | Iter Mean Loss 5.5120
2020-11-05 19:05:14,058 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0125 | Iter Mean Loss 7.0122
2020-11-05 19:05:14,067 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7669 | Iter Mean Loss 7.4508
2020-11-05 19:05:14,076 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8714 | Iter Mean Loss 7.1350
2020-11-05 19:05:14,079 - root - INFO - Evaluate: Epoch 0405 | NDCG 1.0000 | MSE 0.3301
2020-11-05 19:05:14,088 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0132 | Iter Mean Loss 8.0132
2020-11-05 19:05:14,096 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9896 | Iter Mean Loss 5.5014
2020-11-05 19:05:14,105 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9911 | Iter Mean Loss 6.9980
2020-11-05 19:05:14,114 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7476 | Iter Mean Loss 7.4354
2020-11-05 19:05:14,122 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8584 | Iter Mean Loss 7.1200
2020-11-05 19:05:14,124 - root - INFO - Evaluate: Epoch 0406 | NDCG 1.0000 | MSE 0.3300
2020-11-05 19:05:14,133 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9970 | Iter Mean Loss 7.9970
2020-11-05 19:05:14,141 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9849 | Iter Mean Loss 5.4909
2020-11-05 19:05:14,151 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9699 | Iter Mean Loss 6.9839
2020-11-05 19:05:14,158 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7284 | Iter Mean Loss 7.4200
2020-11-05 19:05:14,168 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8454 | Iter Mean Loss 7.1051
2020-11-05 19:05:14,170 - root - INFO - Evaluate: Epoch 0407 | NDCG 1.0000 | MSE 0.3299
2020-11-05 19:05:14,180 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9808 | Iter Mean Loss 7.9808
2020-11-05 19:05:14,187 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9803 | Iter Mean Loss 5.4806
2020-11-05 19:05:14,195 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9488 | Iter Mean Loss 6.9700
2020-11-05 19:05:14,202 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7094 | Iter Mean Loss 7.4048
2020-11-05 19:05:14,211 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8326 | Iter Mean Loss 7.0904
2020-11-05 19:05:14,214 - root - INFO - Evaluate: Epoch 0408 | NDCG 1.0000 | MSE 0.3298
2020-11-05 19:05:14,222 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9649 | Iter Mean Loss 7.9649
2020-11-05 19:05:14,232 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9757 | Iter Mean Loss 5.4703
2020-11-05 19:05:14,240 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9278 | Iter Mean Loss 6.9561
2020-11-05 19:05:14,247 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6904 | Iter Mean Loss 7.3897
2020-11-05 19:05:14,255 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8198 | Iter Mean Loss 7.0757
2020-11-05 19:05:14,257 - root - INFO - Evaluate: Epoch 0409 | NDCG 1.0000 | MSE 0.3297
2020-11-05 19:05:14,266 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9490 | Iter Mean Loss 7.9490
2020-11-05 19:05:14,274 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9712 | Iter Mean Loss 5.4601
2020-11-05 19:05:14,282 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9070 | Iter Mean Loss 6.9424
2020-11-05 19:05:14,290 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6716 | Iter Mean Loss 7.3747
2020-11-05 19:05:14,300 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8072 | Iter Mean Loss 7.0612
2020-11-05 19:05:14,302 - root - INFO - Evaluate: Epoch 0410 | NDCG 1.0000 | MSE 0.3296
2020-11-05 19:05:14,311 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9334 | Iter Mean Loss 7.9334
2020-11-05 19:05:14,320 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9667 | Iter Mean Loss 5.4500
2020-11-05 19:05:14,330 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 6.9288
2020-11-05 19:05:14,337 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6530 | Iter Mean Loss 7.3598
2020-11-05 19:05:14,346 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7945 | Iter Mean Loss 7.0468
2020-11-05 19:05:14,349 - root - INFO - Evaluate: Epoch 0411 | NDCG 1.0000 | MSE 0.3295
2020-11-05 19:05:14,358 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9178 | Iter Mean Loss 7.9178
2020-11-05 19:05:14,367 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9622 | Iter Mean Loss 5.4400
2020-11-05 19:05:14,374 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8657 | Iter Mean Loss 6.9153
2020-11-05 19:05:14,381 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6344 | Iter Mean Loss 7.3450
2020-11-05 19:05:14,389 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7820 | Iter Mean Loss 7.0324
2020-11-05 19:05:14,391 - root - INFO - Evaluate: Epoch 0412 | NDCG 1.0000 | MSE 0.3294
2020-11-05 19:05:14,400 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9025 | Iter Mean Loss 7.9025
2020-11-05 19:05:14,408 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9578 | Iter Mean Loss 5.4301
2020-11-05 19:05:14,419 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8453 | Iter Mean Loss 6.9018
2020-11-05 19:05:14,426 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6160 | Iter Mean Loss 7.3304
2020-11-05 19:05:14,433 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7696 | Iter Mean Loss 7.0182
2020-11-05 19:05:14,435 - root - INFO - Evaluate: Epoch 0413 | NDCG 1.0000 | MSE 0.3293
2020-11-05 19:05:14,443 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8872 | Iter Mean Loss 7.8872
2020-11-05 19:05:14,450 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 5.4203
2020-11-05 19:05:14,458 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8250 | Iter Mean Loss 6.8885
2020-11-05 19:05:14,467 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5977 | Iter Mean Loss 7.3158
2020-11-05 19:05:14,477 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7572 | Iter Mean Loss 7.0041
2020-11-05 19:05:14,480 - root - INFO - Evaluate: Epoch 0414 | NDCG 1.0000 | MSE 0.3292
2020-11-05 19:05:14,489 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8721 | Iter Mean Loss 7.8721
2020-11-05 19:05:14,497 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9491 | Iter Mean Loss 5.4106
2020-11-05 19:05:14,505 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8048 | Iter Mean Loss 6.8753
2020-11-05 19:05:14,514 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5795 | Iter Mean Loss 7.3014
2020-11-05 19:05:14,521 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7449 | Iter Mean Loss 6.9901
2020-11-05 19:05:14,524 - root - INFO - Evaluate: Epoch 0415 | NDCG 1.0000 | MSE 0.3291
2020-11-05 19:05:14,533 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8571 | Iter Mean Loss 7.8571
2020-11-05 19:05:14,541 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9448 | Iter Mean Loss 5.4010
2020-11-05 19:05:14,551 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7847 | Iter Mean Loss 6.8622
2020-11-05 19:05:14,559 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5615 | Iter Mean Loss 7.2870
2020-11-05 19:05:14,568 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7326 | Iter Mean Loss 6.9761
2020-11-05 19:05:14,571 - root - INFO - Evaluate: Epoch 0416 | NDCG 1.0000 | MSE 0.3290
2020-11-05 19:05:14,580 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8423 | Iter Mean Loss 7.8423
2020-11-05 19:05:14,588 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9405 | Iter Mean Loss 5.3914
2020-11-05 19:05:14,596 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7648 | Iter Mean Loss 6.8492
2020-11-05 19:05:14,603 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 7.2728
2020-11-05 19:05:14,612 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7205 | Iter Mean Loss 6.9623
2020-11-05 19:05:14,614 - root - INFO - Evaluate: Epoch 0417 | NDCG 1.0000 | MSE 0.3289
2020-11-05 19:05:14,623 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 7.8276
2020-11-05 19:05:14,632 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 5.3820
2020-11-05 19:05:14,640 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7449 | Iter Mean Loss 6.8363
2020-11-05 19:05:14,647 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5257 | Iter Mean Loss 7.2586
2020-11-05 19:05:14,655 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7083 | Iter Mean Loss 6.9486
2020-11-05 19:05:14,657 - root - INFO - Evaluate: Epoch 0418 | NDCG 1.0000 | MSE 0.3288
2020-11-05 19:05:14,666 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8131 | Iter Mean Loss 7.8131
2020-11-05 19:05:14,674 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9321 | Iter Mean Loss 5.3726
2020-11-05 19:05:14,682 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7252 | Iter Mean Loss 6.8235
2020-11-05 19:05:14,691 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5080 | Iter Mean Loss 7.2446
2020-11-05 19:05:14,700 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6963 | Iter Mean Loss 6.9349
2020-11-05 19:05:14,703 - root - INFO - Evaluate: Epoch 0419 | NDCG 1.0000 | MSE 0.3287
2020-11-05 19:05:14,711 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7986 | Iter Mean Loss 7.7986
2020-11-05 19:05:14,721 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9279 | Iter Mean Loss 5.3633
2020-11-05 19:05:14,729 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7056 | Iter Mean Loss 6.8107
2020-11-05 19:05:14,738 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4904 | Iter Mean Loss 7.2307
2020-11-05 19:05:14,746 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6843 | Iter Mean Loss 6.9214
2020-11-05 19:05:14,748 - root - INFO - Evaluate: Epoch 0420 | NDCG 1.0000 | MSE 0.3286
2020-11-05 19:05:14,757 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7843 | Iter Mean Loss 7.7843
2020-11-05 19:05:14,767 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9238 | Iter Mean Loss 5.3541
2020-11-05 19:05:14,775 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6862 | Iter Mean Loss 6.7981
2020-11-05 19:05:14,785 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4729 | Iter Mean Loss 7.2168
2020-11-05 19:05:14,793 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6724 | Iter Mean Loss 6.9079
2020-11-05 19:05:14,795 - root - INFO - Evaluate: Epoch 0421 | NDCG 1.0000 | MSE 0.3285
2020-11-05 19:05:14,803 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7701 | Iter Mean Loss 7.7701
2020-11-05 19:05:14,810 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9197 | Iter Mean Loss 5.3449
2020-11-05 19:05:14,817 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6668 | Iter Mean Loss 6.7856
2020-11-05 19:05:14,825 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4555 | Iter Mean Loss 7.2031
2020-11-05 19:05:14,834 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6605 | Iter Mean Loss 6.8946
2020-11-05 19:05:14,836 - root - INFO - Evaluate: Epoch 0422 | NDCG 1.0000 | MSE 0.3284
2020-11-05 19:05:14,845 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7561 | Iter Mean Loss 7.7561
2020-11-05 19:05:14,854 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9157 | Iter Mean Loss 5.3359
2020-11-05 19:05:14,862 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6476 | Iter Mean Loss 6.7731
2020-11-05 19:05:14,870 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4383 | Iter Mean Loss 7.1894
2020-11-05 19:05:14,878 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6488 | Iter Mean Loss 6.8813
2020-11-05 19:05:14,880 - root - INFO - Evaluate: Epoch 0423 | NDCG 1.0000 | MSE 0.3284
2020-11-05 19:05:14,888 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7422 | Iter Mean Loss 7.7422
2020-11-05 19:05:14,897 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9117 | Iter Mean Loss 5.3269
2020-11-05 19:05:14,905 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6284 | Iter Mean Loss 6.7608
2020-11-05 19:05:14,915 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4211 | Iter Mean Loss 7.1758
2020-11-05 19:05:14,922 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6370 | Iter Mean Loss 6.8681
2020-11-05 19:05:14,925 - root - INFO - Evaluate: Epoch 0424 | NDCG 1.0000 | MSE 0.3283
2020-11-05 19:05:14,934 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7284 | Iter Mean Loss 7.7284
2020-11-05 19:05:14,942 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9077 | Iter Mean Loss 5.3180
2020-11-05 19:05:14,951 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6094 | Iter Mean Loss 6.7485
2020-11-05 19:05:14,958 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4041 | Iter Mean Loss 7.1624
2020-11-05 19:05:14,965 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6253 | Iter Mean Loss 6.8550
2020-11-05 19:05:14,967 - root - INFO - Evaluate: Epoch 0425 | NDCG 1.0000 | MSE 0.3282
2020-11-05 19:05:14,978 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7147 | Iter Mean Loss 7.7147
2020-11-05 19:05:14,986 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9037 | Iter Mean Loss 5.3092
2020-11-05 19:05:14,994 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5905 | Iter Mean Loss 6.7363
2020-11-05 19:05:15,002 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3871 | Iter Mean Loss 7.1490
2020-11-05 19:05:15,010 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6137 | Iter Mean Loss 6.8419
2020-11-05 19:05:15,012 - root - INFO - Evaluate: Epoch 0426 | NDCG 1.0000 | MSE 0.3281
2020-11-05 19:05:15,020 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7011 | Iter Mean Loss 7.7011
2020-11-05 19:05:15,028 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8998 | Iter Mean Loss 5.3005
2020-11-05 19:05:15,037 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5716 | Iter Mean Loss 6.7242
2020-11-05 19:05:15,044 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3703 | Iter Mean Loss 7.1357
2020-11-05 19:05:15,052 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6021 | Iter Mean Loss 6.8290
2020-11-05 19:05:15,054 - root - INFO - Evaluate: Epoch 0427 | NDCG 1.0000 | MSE 0.3280
2020-11-05 19:05:15,063 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6877 | Iter Mean Loss 7.6877
2020-11-05 19:05:15,071 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8959 | Iter Mean Loss 5.2918
2020-11-05 19:05:15,078 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5529 | Iter Mean Loss 6.7122
2020-11-05 19:05:15,086 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3536 | Iter Mean Loss 7.1225
2020-11-05 19:05:15,095 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5906 | Iter Mean Loss 6.8161
2020-11-05 19:05:15,098 - root - INFO - Evaluate: Epoch 0428 | NDCG 1.0000 | MSE 0.3279
2020-11-05 19:05:15,106 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6743 | Iter Mean Loss 7.6743
2020-11-05 19:05:15,114 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8920 | Iter Mean Loss 5.2832
2020-11-05 19:05:15,123 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5343 | Iter Mean Loss 6.7002
2020-11-05 19:05:15,131 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3370 | Iter Mean Loss 7.1094
2020-11-05 19:05:15,140 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5791 | Iter Mean Loss 6.8034
2020-11-05 19:05:15,142 - root - INFO - Evaluate: Epoch 0429 | NDCG 1.0000 | MSE 0.3278
2020-11-05 19:05:15,150 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6611 | Iter Mean Loss 7.6611
2020-11-05 19:05:15,161 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8882 | Iter Mean Loss 5.2747
2020-11-05 19:05:15,168 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 6.6884
2020-11-05 19:05:15,177 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3204 | Iter Mean Loss 7.0964
2020-11-05 19:05:15,186 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5677 | Iter Mean Loss 6.7907
2020-11-05 19:05:15,188 - root - INFO - Evaluate: Epoch 0430 | NDCG 1.0000 | MSE 0.3278
2020-11-05 19:05:15,197 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6480 | Iter Mean Loss 7.6480
2020-11-05 19:05:15,205 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8844 | Iter Mean Loss 5.2662
2020-11-05 19:05:15,212 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4974 | Iter Mean Loss 6.6766
2020-11-05 19:05:15,219 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3040 | Iter Mean Loss 7.0834
2020-11-05 19:05:15,227 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5564 | Iter Mean Loss 6.7780
2020-11-05 19:05:15,231 - root - INFO - Evaluate: Epoch 0431 | NDCG 1.0000 | MSE 0.3277
2020-11-05 19:05:15,239 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6350 | Iter Mean Loss 7.6350
2020-11-05 19:05:15,248 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8806 | Iter Mean Loss 5.2578
2020-11-05 19:05:15,256 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4791 | Iter Mean Loss 6.6649
2020-11-05 19:05:15,263 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 7.0706
2020-11-05 19:05:15,272 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5451 | Iter Mean Loss 6.7655
2020-11-05 19:05:15,276 - root - INFO - Evaluate: Epoch 0432 | NDCG 1.0000 | MSE 0.3276
2020-11-05 19:05:15,284 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6221 | Iter Mean Loss 7.6221
2020-11-05 19:05:15,291 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8768 | Iter Mean Loss 5.2495
2020-11-05 19:05:15,299 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4609 | Iter Mean Loss 6.6533
2020-11-05 19:05:15,307 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2714 | Iter Mean Loss 7.0578
2020-11-05 19:05:15,317 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5338 | Iter Mean Loss 6.7530
2020-11-05 19:05:15,320 - root - INFO - Evaluate: Epoch 0433 | NDCG 1.0000 | MSE 0.3275
2020-11-05 19:05:15,328 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 7.6093
2020-11-05 19:05:15,339 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8731 | Iter Mean Loss 5.2412
2020-11-05 19:05:15,347 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4427 | Iter Mean Loss 6.6417
2020-11-05 19:05:15,355 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2553 | Iter Mean Loss 7.0451
2020-11-05 19:05:15,363 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5226 | Iter Mean Loss 6.7406
2020-11-05 19:05:15,365 - root - INFO - Evaluate: Epoch 0434 | NDCG 1.0000 | MSE 0.3274
2020-11-05 19:05:15,374 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5966 | Iter Mean Loss 7.5966
2020-11-05 19:05:15,383 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8694 | Iter Mean Loss 5.2330
2020-11-05 19:05:15,392 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4247 | Iter Mean Loss 6.6302
2020-11-05 19:05:15,401 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2393 | Iter Mean Loss 7.0325
2020-11-05 19:05:15,408 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5114 | Iter Mean Loss 6.7283
2020-11-05 19:05:15,410 - root - INFO - Evaluate: Epoch 0435 | NDCG 1.0000 | MSE 0.3274
2020-11-05 19:05:15,418 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5840 | Iter Mean Loss 7.5840
2020-11-05 19:05:15,426 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8657 | Iter Mean Loss 5.2249
2020-11-05 19:05:15,435 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 6.6188
2020-11-05 19:05:15,442 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2233 | Iter Mean Loss 7.0200
2020-11-05 19:05:15,449 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5003 | Iter Mean Loss 6.7160
2020-11-05 19:05:15,451 - root - INFO - Evaluate: Epoch 0436 | NDCG 1.0000 | MSE 0.3273
2020-11-05 19:05:15,460 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5716 | Iter Mean Loss 7.5716
2020-11-05 19:05:15,469 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8620 | Iter Mean Loss 5.2168
2020-11-05 19:05:15,477 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3889 | Iter Mean Loss 6.6075
2020-11-05 19:05:15,484 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2075 | Iter Mean Loss 7.0075
2020-11-05 19:05:15,493 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4892 | Iter Mean Loss 6.7038
2020-11-05 19:05:15,495 - root - INFO - Evaluate: Epoch 0437 | NDCG 1.0000 | MSE 0.3272
2020-11-05 19:05:15,504 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5592 | Iter Mean Loss 7.5592
2020-11-05 19:05:15,512 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8584 | Iter Mean Loss 5.2088
2020-11-05 19:05:15,520 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3712 | Iter Mean Loss 6.5962
2020-11-05 19:05:15,528 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1917 | Iter Mean Loss 6.9951
2020-11-05 19:05:15,537 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4782 | Iter Mean Loss 6.6917
2020-11-05 19:05:15,539 - root - INFO - Evaluate: Epoch 0438 | NDCG 1.0000 | MSE 0.3271
2020-11-05 19:05:15,550 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5469 | Iter Mean Loss 7.5469
2020-11-05 19:05:15,558 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8548 | Iter Mean Loss 5.2008
2020-11-05 19:05:15,566 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3535 | Iter Mean Loss 6.5851
2020-11-05 19:05:15,574 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1760 | Iter Mean Loss 6.9828
2020-11-05 19:05:15,581 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4672 | Iter Mean Loss 6.6797
2020-11-05 19:05:15,583 - root - INFO - Evaluate: Epoch 0439 | NDCG 1.0000 | MSE 0.3270
2020-11-05 19:05:15,592 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5347 | Iter Mean Loss 7.5347
2020-11-05 19:05:15,601 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8512 | Iter Mean Loss 5.1930
2020-11-05 19:05:15,609 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3359 | Iter Mean Loss 6.5739
2020-11-05 19:05:15,618 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 6.9706
2020-11-05 19:05:15,625 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4562 | Iter Mean Loss 6.6677
2020-11-05 19:05:15,628 - root - INFO - Evaluate: Epoch 0440 | NDCG 1.0000 | MSE 0.3270
2020-11-05 19:05:15,637 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5227 | Iter Mean Loss 7.5227
2020-11-05 19:05:15,645 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8476 | Iter Mean Loss 5.1851
2020-11-05 19:05:15,654 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3184 | Iter Mean Loss 6.5629
2020-11-05 19:05:15,661 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1449 | Iter Mean Loss 6.9584
2020-11-05 19:05:15,668 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4453 | Iter Mean Loss 6.6558
2020-11-05 19:05:15,671 - root - INFO - Evaluate: Epoch 0441 | NDCG 1.0000 | MSE 0.3269
2020-11-05 19:05:15,681 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5107 | Iter Mean Loss 7.5107
2020-11-05 19:05:15,688 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8440 | Iter Mean Loss 5.1773
2020-11-05 19:05:15,696 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3010 | Iter Mean Loss 6.5519
2020-11-05 19:05:15,705 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1295 | Iter Mean Loss 6.9463
2020-11-05 19:05:15,713 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4344 | Iter Mean Loss 6.6439
2020-11-05 19:05:15,715 - root - INFO - Evaluate: Epoch 0442 | NDCG 1.0000 | MSE 0.3268
2020-11-05 19:05:15,723 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4988 | Iter Mean Loss 7.4988
2020-11-05 19:05:15,730 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8405 | Iter Mean Loss 5.1696
2020-11-05 19:05:15,738 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2837 | Iter Mean Loss 6.5410
2020-11-05 19:05:15,747 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1142 | Iter Mean Loss 6.9343
2020-11-05 19:05:15,755 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4236 | Iter Mean Loss 6.6321
2020-11-05 19:05:15,758 - root - INFO - Evaluate: Epoch 0443 | NDCG 1.0000 | MSE 0.3267
2020-11-05 19:05:15,767 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4870 | Iter Mean Loss 7.4870
2020-11-05 19:05:15,775 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8370 | Iter Mean Loss 5.1620
2020-11-05 19:05:15,783 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 6.5301
2020-11-05 19:05:15,791 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0989 | Iter Mean Loss 6.9223
2020-11-05 19:05:15,800 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4128 | Iter Mean Loss 6.6204
2020-11-05 19:05:15,802 - root - INFO - Evaluate: Epoch 0444 | NDCG 1.0000 | MSE 0.3267
2020-11-05 19:05:15,810 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4752 | Iter Mean Loss 7.4752
2020-11-05 19:05:15,819 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8334 | Iter Mean Loss 5.1543
2020-11-05 19:05:15,827 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2493 | Iter Mean Loss 6.5193
2020-11-05 19:05:15,835 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0837 | Iter Mean Loss 6.9104
2020-11-05 19:05:15,842 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4021 | Iter Mean Loss 6.6088
2020-11-05 19:05:15,844 - root - INFO - Evaluate: Epoch 0445 | NDCG 1.0000 | MSE 0.3266
2020-11-05 19:05:15,852 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4636 | Iter Mean Loss 7.4636
2020-11-05 19:05:15,860 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8300 | Iter Mean Loss 5.1468
2020-11-05 19:05:15,869 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2322 | Iter Mean Loss 6.5086
2020-11-05 19:05:15,877 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0686 | Iter Mean Loss 6.8986
2020-11-05 19:05:15,885 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3914 | Iter Mean Loss 6.5972
2020-11-05 19:05:15,888 - root - INFO - Evaluate: Epoch 0446 | NDCG 1.0000 | MSE 0.3265
2020-11-05 19:05:15,897 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4521 | Iter Mean Loss 7.4521
2020-11-05 19:05:15,904 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8265 | Iter Mean Loss 5.1393
2020-11-05 19:05:15,912 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2152 | Iter Mean Loss 6.4979
2020-11-05 19:05:15,919 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0536 | Iter Mean Loss 6.8868
2020-11-05 19:05:15,928 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3807 | Iter Mean Loss 6.5856
2020-11-05 19:05:15,931 - root - INFO - Evaluate: Epoch 0447 | NDCG 1.0000 | MSE 0.3264
2020-11-05 19:05:15,939 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4406 | Iter Mean Loss 7.4406
2020-11-05 19:05:15,949 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8230 | Iter Mean Loss 5.1318
2020-11-05 19:05:15,957 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1983 | Iter Mean Loss 6.4873
2020-11-05 19:05:15,965 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0387 | Iter Mean Loss 6.8752
2020-11-05 19:05:15,973 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3701 | Iter Mean Loss 6.5741
2020-11-05 19:05:15,975 - root - INFO - Evaluate: Epoch 0448 | NDCG 1.0000 | MSE 0.3264
2020-11-05 19:05:15,985 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4293 | Iter Mean Loss 7.4293
2020-11-05 19:05:15,992 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 5.1244
2020-11-05 19:05:16,000 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1815 | Iter Mean Loss 6.4768
2020-11-05 19:05:16,009 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0238 | Iter Mean Loss 6.8635
2020-11-05 19:05:16,017 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 6.5627
2020-11-05 19:05:16,019 - root - INFO - Evaluate: Epoch 0449 | NDCG 1.0000 | MSE 0.3263
2020-11-05 19:05:16,027 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 7.4180
2020-11-05 19:05:16,034 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8162 | Iter Mean Loss 5.1171
2020-11-05 19:05:16,043 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1647 | Iter Mean Loss 6.4663
2020-11-05 19:05:16,052 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0090 | Iter Mean Loss 6.8520
2020-11-05 19:05:16,059 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3489 | Iter Mean Loss 6.5514
2020-11-05 19:05:16,061 - root - INFO - Evaluate: Epoch 0450 | NDCG 1.0000 | MSE 0.3262
2020-11-05 19:05:16,070 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4068 | Iter Mean Loss 7.4068
2020-11-05 19:05:16,079 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8128 | Iter Mean Loss 5.1098
2020-11-05 19:05:16,087 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1480 | Iter Mean Loss 6.4558
2020-11-05 19:05:16,094 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9943 | Iter Mean Loss 6.8405
2020-11-05 19:05:16,102 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3384 | Iter Mean Loss 6.5401
2020-11-05 19:05:16,104 - root - INFO - Evaluate: Epoch 0451 | NDCG 1.0000 | MSE 0.3261
2020-11-05 19:05:16,114 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3956 | Iter Mean Loss 7.3956
2020-11-05 19:05:16,122 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8094 | Iter Mean Loss 5.1025
2020-11-05 19:05:16,132 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1314 | Iter Mean Loss 6.4455
2020-11-05 19:05:16,140 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9797 | Iter Mean Loss 6.8290
2020-11-05 19:05:16,148 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3279 | Iter Mean Loss 6.5288
2020-11-05 19:05:16,150 - root - INFO - Evaluate: Epoch 0452 | NDCG 1.0000 | MSE 0.3261
2020-11-05 19:05:16,158 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3846 | Iter Mean Loss 7.3846
2020-11-05 19:05:16,165 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8060 | Iter Mean Loss 5.0953
2020-11-05 19:05:16,176 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1149 | Iter Mean Loss 6.4351
2020-11-05 19:05:16,185 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 6.8176
2020-11-05 19:05:16,196 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3175 | Iter Mean Loss 6.5176
2020-11-05 19:05:16,201 - root - INFO - Evaluate: Epoch 0453 | NDCG 1.0000 | MSE 0.3260
2020-11-05 19:05:16,215 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3736 | Iter Mean Loss 7.3736
2020-11-05 19:05:16,231 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8026 | Iter Mean Loss 5.0881
2020-11-05 19:05:16,247 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 6.4249
2020-11-05 19:05:16,263 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9506 | Iter Mean Loss 6.8063
2020-11-05 19:05:16,279 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3071 | Iter Mean Loss 6.5065
2020-11-05 19:05:16,282 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.2817 | MSE 0.3259
2020-11-05 19:05:16,298 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3627 | Iter Mean Loss 7.3627
2020-11-05 19:05:16,315 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7992 | Iter Mean Loss 5.0810
2020-11-05 19:05:16,331 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0820 | Iter Mean Loss 6.4147
2020-11-05 19:05:16,343 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9362 | Iter Mean Loss 6.7951
2020-11-05 19:05:16,356 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2967 | Iter Mean Loss 6.4954
2020-11-05 19:05:16,358 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.2817 | MSE 0.3258
2020-11-05 19:05:16,370 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3519 | Iter Mean Loss 7.3519
2020-11-05 19:05:16,380 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7959 | Iter Mean Loss 5.0739
2020-11-05 19:05:16,393 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0657 | Iter Mean Loss 6.4045
2020-11-05 19:05:16,406 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9219 | Iter Mean Loss 6.7838
2020-11-05 19:05:16,416 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2863 | Iter Mean Loss 6.4843
2020-11-05 19:05:16,420 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.2817 | MSE 0.3258
2020-11-05 19:05:16,431 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3412 | Iter Mean Loss 7.3412
2020-11-05 19:05:16,445 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7926 | Iter Mean Loss 5.0669
2020-11-05 19:05:16,456 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0495 | Iter Mean Loss 6.3944
2020-11-05 19:05:16,466 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9076 | Iter Mean Loss 6.7727
2020-11-05 19:05:16,477 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2760 | Iter Mean Loss 6.4734
2020-11-05 19:05:16,480 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.2817 | MSE 0.3257
2020-11-05 19:05:16,490 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3305 | Iter Mean Loss 7.3305
2020-11-05 19:05:16,499 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7892 | Iter Mean Loss 5.0599
2020-11-05 19:05:16,509 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0333 | Iter Mean Loss 6.3844
2020-11-05 19:05:16,517 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8934 | Iter Mean Loss 6.7616
2020-11-05 19:05:16,528 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2657 | Iter Mean Loss 6.4624
2020-11-05 19:05:16,531 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.2817 | MSE 0.3256
2020-11-05 19:05:16,541 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3199 | Iter Mean Loss 7.3199
2020-11-05 19:05:16,549 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7859 | Iter Mean Loss 5.0529
2020-11-05 19:05:16,559 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0172 | Iter Mean Loss 6.3743
2020-11-05 19:05:16,568 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8792 | Iter Mean Loss 6.7506
2020-11-05 19:05:16,576 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2555 | Iter Mean Loss 6.4515
2020-11-05 19:05:16,579 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.2817 | MSE 0.3256
2020-11-05 19:05:16,587 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3094 | Iter Mean Loss 7.3094
2020-11-05 19:05:16,594 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7826 | Iter Mean Loss 5.0460
2020-11-05 19:05:16,603 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0011 | Iter Mean Loss 6.3644
2020-11-05 19:05:16,610 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8651 | Iter Mean Loss 6.7396
2020-11-05 19:05:16,618 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 6.4407
2020-11-05 19:05:16,620 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.2817 | MSE 0.3255
2020-11-05 19:05:16,629 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2990 | Iter Mean Loss 7.2990
2020-11-05 19:05:16,640 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7793 | Iter Mean Loss 5.0391
2020-11-05 19:05:16,647 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9852 | Iter Mean Loss 6.3545
2020-11-05 19:05:16,656 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8511 | Iter Mean Loss 6.7286
2020-11-05 19:05:16,663 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2351 | Iter Mean Loss 6.4299
2020-11-05 19:05:16,665 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.2817 | MSE 0.3254
2020-11-05 19:05:16,673 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2886 | Iter Mean Loss 7.2886
2020-11-05 19:05:16,680 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7760 | Iter Mean Loss 5.0323
2020-11-05 19:05:16,688 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9693 | Iter Mean Loss 6.3446
2020-11-05 19:05:16,695 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8371 | Iter Mean Loss 6.7178
2020-11-05 19:05:16,703 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2249 | Iter Mean Loss 6.4192
2020-11-05 19:05:16,705 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.2817 | MSE 0.3253
2020-11-05 19:05:16,713 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2783 | Iter Mean Loss 7.2783
2020-11-05 19:05:16,721 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7728 | Iter Mean Loss 5.0255
2020-11-05 19:05:16,728 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9534 | Iter Mean Loss 6.3348
2020-11-05 19:05:16,735 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8232 | Iter Mean Loss 6.7069
2020-11-05 19:05:16,743 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2148 | Iter Mean Loss 6.4085
2020-11-05 19:05:16,745 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.2817 | MSE 0.3253
2020-11-05 19:05:16,752 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2680 | Iter Mean Loss 7.2680
2020-11-05 19:05:16,760 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7695 | Iter Mean Loss 5.0188
2020-11-05 19:05:16,768 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9377 | Iter Mean Loss 6.3251
2020-11-05 19:05:16,776 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8094 | Iter Mean Loss 6.6961
2020-11-05 19:05:16,784 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2047 | Iter Mean Loss 6.3979
2020-11-05 19:05:16,786 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.2817 | MSE 0.3252
2020-11-05 19:05:16,795 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2578 | Iter Mean Loss 7.2578
2020-11-05 19:05:16,803 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7662 | Iter Mean Loss 5.0120
2020-11-05 19:05:16,811 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9220 | Iter Mean Loss 6.3153
2020-11-05 19:05:16,819 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7956 | Iter Mean Loss 6.6854
2020-11-05 19:05:16,826 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1947 | Iter Mean Loss 6.3873
2020-11-05 19:05:16,828 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.2817 | MSE 0.3251
2020-11-05 19:05:16,836 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2477 | Iter Mean Loss 7.2477
2020-11-05 19:05:16,843 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7630 | Iter Mean Loss 5.0054
2020-11-05 19:05:16,850 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9063 | Iter Mean Loss 6.3057
2020-11-05 19:05:16,858 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7819 | Iter Mean Loss 6.6747
2020-11-05 19:05:16,865 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1846 | Iter Mean Loss 6.3767
2020-11-05 19:05:16,867 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.2817 | MSE 0.3251
2020-11-05 19:05:16,874 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2377 | Iter Mean Loss 7.2377
2020-11-05 19:05:16,882 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7597 | Iter Mean Loss 4.9987
2020-11-05 19:05:16,889 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8907 | Iter Mean Loss 6.2961
2020-11-05 19:05:16,896 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7682 | Iter Mean Loss 6.6641
2020-11-05 19:05:16,903 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1746 | Iter Mean Loss 6.3662
2020-11-05 19:05:16,905 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.2817 | MSE 0.3250
2020-11-05 19:05:16,913 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2277 | Iter Mean Loss 7.2277
2020-11-05 19:05:16,920 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7565 | Iter Mean Loss 4.9921
2020-11-05 19:05:16,928 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8752 | Iter Mean Loss 6.2865
2020-11-05 19:05:16,935 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7546 | Iter Mean Loss 6.6535
2020-11-05 19:05:16,942 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 6.3557
2020-11-05 19:05:16,944 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.2817 | MSE 0.3249
2020-11-05 19:05:16,953 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2178 | Iter Mean Loss 7.2178
2020-11-05 19:05:16,961 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7533 | Iter Mean Loss 4.9855
2020-11-05 19:05:16,968 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8597 | Iter Mean Loss 6.2769
2020-11-05 19:05:16,976 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7411 | Iter Mean Loss 6.6430
2020-11-05 19:05:16,985 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1547 | Iter Mean Loss 6.3453
2020-11-05 19:05:16,987 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.2817 | MSE 0.3249
2020-11-05 19:05:16,995 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2079 | Iter Mean Loss 7.2079
2020-11-05 19:05:17,004 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7501 | Iter Mean Loss 4.9790
2020-11-05 19:05:17,011 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8443 | Iter Mean Loss 6.2674
2020-11-05 19:05:17,018 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7276 | Iter Mean Loss 6.6325
2020-11-05 19:05:17,026 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1448 | Iter Mean Loss 6.3349
2020-11-05 19:05:17,028 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.2817 | MSE 0.3248
2020-11-05 19:05:17,036 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1981 | Iter Mean Loss 7.1981
2020-11-05 19:05:17,043 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7468 | Iter Mean Loss 4.9725
2020-11-05 19:05:17,050 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8290 | Iter Mean Loss 6.2580
2020-11-05 19:05:17,057 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7141 | Iter Mean Loss 6.6220
2020-11-05 19:05:17,064 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1349 | Iter Mean Loss 6.3246
2020-11-05 19:05:17,066 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.2817 | MSE 0.3247
2020-11-05 19:05:17,074 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1884 | Iter Mean Loss 7.1884
2020-11-05 19:05:17,081 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7436 | Iter Mean Loss 4.9660
2020-11-05 19:05:17,089 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8137 | Iter Mean Loss 6.2486
2020-11-05 19:05:17,096 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7007 | Iter Mean Loss 6.6116
2020-11-05 19:05:17,103 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1250 | Iter Mean Loss 6.3143
2020-11-05 19:05:17,105 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.2817 | MSE 0.3247
2020-11-05 19:05:17,113 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1787 | Iter Mean Loss 7.1787
2020-11-05 19:05:17,120 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7404 | Iter Mean Loss 4.9595
2020-11-05 19:05:17,128 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7985 | Iter Mean Loss 6.2392
2020-11-05 19:05:17,136 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6874 | Iter Mean Loss 6.6012
2020-11-05 19:05:17,144 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1152 | Iter Mean Loss 6.3040
2020-11-05 19:05:17,146 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.2817 | MSE 0.3246
2020-11-05 19:05:17,153 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1690 | Iter Mean Loss 7.1690
2020-11-05 19:05:17,161 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7372 | Iter Mean Loss 4.9531
2020-11-05 19:05:17,168 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7833 | Iter Mean Loss 6.2299
2020-11-05 19:05:17,177 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6741 | Iter Mean Loss 6.5909
2020-11-05 19:05:17,185 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1054 | Iter Mean Loss 6.2938
2020-11-05 19:05:17,187 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.2817 | MSE 0.3245
2020-11-05 19:05:17,195 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1595 | Iter Mean Loss 7.1595
2020-11-05 19:05:17,204 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7340 | Iter Mean Loss 4.9467
2020-11-05 19:05:17,212 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7682 | Iter Mean Loss 6.2206
2020-11-05 19:05:17,219 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6609 | Iter Mean Loss 6.5806
2020-11-05 19:05:17,228 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0956 | Iter Mean Loss 6.2836
2020-11-05 19:05:17,230 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.2817 | MSE 0.3245
2020-11-05 19:05:17,238 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1500 | Iter Mean Loss 7.1500
2020-11-05 19:05:17,245 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7308 | Iter Mean Loss 4.9404
2020-11-05 19:05:17,252 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7532 | Iter Mean Loss 6.2113
2020-11-05 19:05:17,259 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6477 | Iter Mean Loss 6.5704
2020-11-05 19:05:17,266 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0858 | Iter Mean Loss 6.2735
2020-11-05 19:05:17,268 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.2817 | MSE 0.3244
2020-11-05 19:05:17,276 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1405 | Iter Mean Loss 7.1405
2020-11-05 19:05:17,284 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7276 | Iter Mean Loss 4.9340
2020-11-05 19:05:17,291 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7382 | Iter Mean Loss 6.2021
2020-11-05 19:05:17,299 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6345 | Iter Mean Loss 6.5602
2020-11-05 19:05:17,306 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0761 | Iter Mean Loss 6.2634
2020-11-05 19:05:17,308 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.2817 | MSE 0.3243
2020-11-05 19:05:17,317 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1311 | Iter Mean Loss 7.1311
2020-11-05 19:05:17,327 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7244 | Iter Mean Loss 4.9277
2020-11-05 19:05:17,335 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7232 | Iter Mean Loss 6.1929
2020-11-05 19:05:17,342 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6215 | Iter Mean Loss 6.5501
2020-11-05 19:05:17,351 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0664 | Iter Mean Loss 6.2533
2020-11-05 19:05:17,353 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.2817 | MSE 0.3243
2020-11-05 19:05:17,361 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1218 | Iter Mean Loss 7.1218
2020-11-05 19:05:17,369 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7212 | Iter Mean Loss 4.9215
2020-11-05 19:05:17,379 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7084 | Iter Mean Loss 6.1838
2020-11-05 19:05:17,386 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6084 | Iter Mean Loss 6.5399
2020-11-05 19:05:17,396 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0567 | Iter Mean Loss 6.2433
2020-11-05 19:05:17,398 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.2817 | MSE 0.3242
2020-11-05 19:05:17,407 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1125 | Iter Mean Loss 7.1125
2020-11-05 19:05:17,416 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7180 | Iter Mean Loss 4.9152
2020-11-05 19:05:17,424 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6935 | Iter Mean Loss 6.1747
2020-11-05 19:05:17,434 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5954 | Iter Mean Loss 6.5299
2020-11-05 19:05:17,442 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0470 | Iter Mean Loss 6.2333
2020-11-05 19:05:17,445 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.2817 | MSE 0.3241
2020-11-05 19:05:17,455 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1032 | Iter Mean Loss 7.1032
2020-11-05 19:05:17,464 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7148 | Iter Mean Loss 4.9090
2020-11-05 19:05:17,473 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6787 | Iter Mean Loss 6.1656
2020-11-05 19:05:17,481 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5825 | Iter Mean Loss 6.5198
2020-11-05 19:05:17,489 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0374 | Iter Mean Loss 6.2233
2020-11-05 19:05:17,491 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.2817 | MSE 0.3241
2020-11-05 19:05:17,500 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0940 | Iter Mean Loss 7.0940
2020-11-05 19:05:17,507 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7116 | Iter Mean Loss 4.9028
2020-11-05 19:05:17,515 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6640 | Iter Mean Loss 6.1566
2020-11-05 19:05:17,523 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5696 | Iter Mean Loss 6.5098
2020-11-05 19:05:17,531 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0278 | Iter Mean Loss 6.2134
2020-11-05 19:05:17,533 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.2817 | MSE 0.3240
2020-11-05 19:05:17,541 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0849 | Iter Mean Loss 7.0849
2020-11-05 19:05:17,549 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7084 | Iter Mean Loss 4.8967
2020-11-05 19:05:17,558 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6493 | Iter Mean Loss 6.1476
2020-11-05 19:05:17,566 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5567 | Iter Mean Loss 6.4998
2020-11-05 19:05:17,575 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0182 | Iter Mean Loss 6.2035
2020-11-05 19:05:17,578 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.2817 | MSE 0.3239
2020-11-05 19:05:17,586 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0758 | Iter Mean Loss 7.0758
2020-11-05 19:05:17,594 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7053 | Iter Mean Loss 4.8905
2020-11-05 19:05:17,603 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6347 | Iter Mean Loss 6.1386
2020-11-05 19:05:17,611 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5439 | Iter Mean Loss 6.4899
2020-11-05 19:05:17,619 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0086 | Iter Mean Loss 6.1936
2020-11-05 19:05:17,621 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.2817 | MSE 0.3239
2020-11-05 19:05:17,629 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0667 | Iter Mean Loss 7.0667
2020-11-05 19:05:17,638 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7021 | Iter Mean Loss 4.8844
2020-11-05 19:05:17,646 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1296
2020-11-05 19:05:17,654 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5311 | Iter Mean Loss 6.4800
2020-11-05 19:05:17,662 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9991 | Iter Mean Loss 6.1838
2020-11-05 19:05:17,664 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.2817 | MSE 0.3238
2020-11-05 19:05:17,672 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0577 | Iter Mean Loss 7.0577
2020-11-05 19:05:17,680 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6989 | Iter Mean Loss 4.8783
2020-11-05 19:05:17,687 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6056 | Iter Mean Loss 6.1207
2020-11-05 19:05:17,695 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5184 | Iter Mean Loss 6.4702
2020-11-05 19:05:17,703 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9895 | Iter Mean Loss 6.1740
2020-11-05 19:05:17,706 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.2817 | MSE 0.3237
2020-11-05 19:05:17,714 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0488 | Iter Mean Loss 7.0488
2020-11-05 19:05:17,722 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 4.8722
2020-11-05 19:05:17,730 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5911 | Iter Mean Loss 6.1119
2020-11-05 19:05:17,737 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 6.4603
2020-11-05 19:05:17,745 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9800 | Iter Mean Loss 6.1643
2020-11-05 19:05:17,747 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.2817 | MSE 0.3237
2020-11-05 19:05:17,755 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0399 | Iter Mean Loss 7.0399
2020-11-05 19:05:17,763 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 4.8662
2020-11-05 19:05:17,770 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 6.1030
2020-11-05 19:05:17,778 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4931 | Iter Mean Loss 6.4505
2020-11-05 19:05:17,787 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9706 | Iter Mean Loss 6.1545
2020-11-05 19:05:17,789 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.2817 | MSE 0.3236
2020-11-05 19:05:17,797 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0310 | Iter Mean Loss 7.0310
2020-11-05 19:05:17,805 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 4.8602
2020-11-05 19:05:17,814 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5623 | Iter Mean Loss 6.0942
2020-11-05 19:05:17,822 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4804 | Iter Mean Loss 6.4408
2020-11-05 19:05:17,832 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9611 | Iter Mean Loss 6.1448
2020-11-05 19:05:17,834 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.2817 | MSE 0.3236
2020-11-05 19:05:17,842 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0222 | Iter Mean Loss 7.0222
2020-11-05 19:05:17,850 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6861 | Iter Mean Loss 4.8542
2020-11-05 19:05:17,857 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5479 | Iter Mean Loss 6.0854
2020-11-05 19:05:17,865 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4679 | Iter Mean Loss 6.4310
2020-11-05 19:05:17,872 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9517 | Iter Mean Loss 6.1352
2020-11-05 19:05:17,874 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.2817 | MSE 0.3235
2020-11-05 19:05:17,882 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 7.0135
2020-11-05 19:05:17,890 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6829 | Iter Mean Loss 4.8482
2020-11-05 19:05:17,897 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5337 | Iter Mean Loss 6.0767
2020-11-05 19:05:17,905 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4553 | Iter Mean Loss 6.4213
2020-11-05 19:05:17,912 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9422 | Iter Mean Loss 6.1255
2020-11-05 19:05:17,914 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.2817 | MSE 0.3234
2020-11-05 19:05:17,922 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0047 | Iter Mean Loss 7.0047
2020-11-05 19:05:17,930 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6797 | Iter Mean Loss 4.8422
2020-11-05 19:05:17,937 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5194 | Iter Mean Loss 6.0679
2020-11-05 19:05:17,945 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4428 | Iter Mean Loss 6.4117
2020-11-05 19:05:17,952 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9328 | Iter Mean Loss 6.1159
2020-11-05 19:05:17,954 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.2817 | MSE 0.3234
2020-11-05 19:05:17,962 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9961 | Iter Mean Loss 6.9961
2020-11-05 19:05:17,971 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6765 | Iter Mean Loss 4.8363
2020-11-05 19:05:17,979 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5052 | Iter Mean Loss 6.0592
2020-11-05 19:05:17,986 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4304 | Iter Mean Loss 6.4020
2020-11-05 19:05:17,993 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9235 | Iter Mean Loss 6.1063
2020-11-05 19:05:17,995 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.2817 | MSE 0.3233
2020-11-05 19:05:18,005 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9874 | Iter Mean Loss 6.9874
2020-11-05 19:05:18,013 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6733 | Iter Mean Loss 4.8304
2020-11-05 19:05:18,020 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4910 | Iter Mean Loss 6.0506
2020-11-05 19:05:18,028 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 6.3924
2020-11-05 19:05:18,037 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9141 | Iter Mean Loss 6.0968
2020-11-05 19:05:18,039 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.2817 | MSE 0.3232
2020-11-05 19:05:18,047 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9788 | Iter Mean Loss 6.9788
2020-11-05 19:05:18,055 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6701 | Iter Mean Loss 4.8244
2020-11-05 19:05:18,064 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4769 | Iter Mean Loss 6.0419
2020-11-05 19:05:18,072 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4056 | Iter Mean Loss 6.3828
2020-11-05 19:05:18,079 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9048 | Iter Mean Loss 6.0872
2020-11-05 19:05:18,081 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.2817 | MSE 0.3232
2020-11-05 19:05:18,089 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9703 | Iter Mean Loss 6.9703
2020-11-05 19:05:18,097 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6668 | Iter Mean Loss 4.8186
2020-11-05 19:05:18,104 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4628 | Iter Mean Loss 6.0333
2020-11-05 19:05:18,111 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3932 | Iter Mean Loss 6.3733
2020-11-05 19:05:18,119 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8955 | Iter Mean Loss 6.0777
2020-11-05 19:05:18,121 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.2817 | MSE 0.3231
2020-11-05 19:05:18,129 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9618 | Iter Mean Loss 6.9618
2020-11-05 19:05:18,137 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6636 | Iter Mean Loss 4.8127
2020-11-05 19:05:18,145 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4488 | Iter Mean Loss 6.0247
2020-11-05 19:05:18,152 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3809 | Iter Mean Loss 6.3638
2020-11-05 19:05:18,160 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8861 | Iter Mean Loss 6.0682
2020-11-05 19:05:18,162 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.2817 | MSE 0.3231
2020-11-05 19:05:18,170 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9533 | Iter Mean Loss 6.9533
2020-11-05 19:05:18,178 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6604 | Iter Mean Loss 4.8068
2020-11-05 19:05:18,185 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4348 | Iter Mean Loss 6.0162
2020-11-05 19:05:18,192 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3686 | Iter Mean Loss 6.3543
2020-11-05 19:05:18,200 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8769 | Iter Mean Loss 6.0588
2020-11-05 19:05:18,202 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.2817 | MSE 0.3230
2020-11-05 19:05:18,211 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9449 | Iter Mean Loss 6.9449
2020-11-05 19:05:18,219 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6571 | Iter Mean Loss 4.8010
2020-11-05 19:05:18,228 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4209 | Iter Mean Loss 6.0076
2020-11-05 19:05:18,235 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3564 | Iter Mean Loss 6.3448
2020-11-05 19:05:18,243 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8676 | Iter Mean Loss 6.0494
2020-11-05 19:05:18,245 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.2817 | MSE 0.3229
2020-11-05 19:05:18,254 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9365 | Iter Mean Loss 6.9365
2020-11-05 19:05:18,262 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6539 | Iter Mean Loss 4.7952
2020-11-05 19:05:18,270 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4069 | Iter Mean Loss 5.9991
2020-11-05 19:05:18,277 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.3354
2020-11-05 19:05:18,285 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 6.0400
2020-11-05 19:05:18,287 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.2817 | MSE 0.3229
2020-11-05 19:05:18,294 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9281 | Iter Mean Loss 6.9281
2020-11-05 19:05:18,302 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6507 | Iter Mean Loss 4.7894
2020-11-05 19:05:18,309 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3931 | Iter Mean Loss 5.9906
2020-11-05 19:05:18,323 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3320 | Iter Mean Loss 6.3260
2020-11-05 19:05:18,334 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8491 | Iter Mean Loss 6.0306
2020-11-05 19:05:18,336 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.2817 | MSE 0.3228
2020-11-05 19:05:18,344 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9198 | Iter Mean Loss 6.9198
2020-11-05 19:05:18,352 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6474 | Iter Mean Loss 4.7836
2020-11-05 19:05:18,360 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 5.9821
2020-11-05 19:05:18,368 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3198 | Iter Mean Loss 6.3166
2020-11-05 19:05:18,376 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8399 | Iter Mean Loss 6.0212
2020-11-05 19:05:18,378 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.2817 | MSE 0.3228
2020-11-05 19:05:18,386 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9115 | Iter Mean Loss 6.9115
2020-11-05 19:05:18,394 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6441 | Iter Mean Loss 4.7778
2020-11-05 19:05:18,402 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3654 | Iter Mean Loss 5.9737
2020-11-05 19:05:18,413 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3077 | Iter Mean Loss 6.3072
2020-11-05 19:05:18,425 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8307 | Iter Mean Loss 6.0119
2020-11-05 19:05:18,431 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.2817 | MSE 0.3227
2020-11-05 19:05:18,441 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9033 | Iter Mean Loss 6.9033
2020-11-05 19:05:18,450 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6409 | Iter Mean Loss 4.7721
2020-11-05 19:05:18,459 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3517 | Iter Mean Loss 5.9653
2020-11-05 19:05:18,469 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2956 | Iter Mean Loss 6.2978
2020-11-05 19:05:18,477 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8215 | Iter Mean Loss 6.0026
2020-11-05 19:05:18,480 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.2817 | MSE 0.3227
2020-11-05 19:05:18,489 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8951 | Iter Mean Loss 6.8951
2020-11-05 19:05:18,497 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6376 | Iter Mean Loss 4.7663
2020-11-05 19:05:18,505 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3379 | Iter Mean Loss 5.9569
2020-11-05 19:05:18,513 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2835 | Iter Mean Loss 6.2885
2020-11-05 19:05:18,521 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8124 | Iter Mean Loss 5.9933
2020-11-05 19:05:18,523 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.2817 | MSE 0.3226
2020-11-05 19:05:18,532 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8869 | Iter Mean Loss 6.8869
2020-11-05 19:05:18,540 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6343 | Iter Mean Loss 4.7606
2020-11-05 19:05:18,549 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3242 | Iter Mean Loss 5.9485
2020-11-05 19:05:18,558 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2715 | Iter Mean Loss 6.2792
2020-11-05 19:05:18,568 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8032 | Iter Mean Loss 5.9840
2020-11-05 19:05:18,570 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.2817 | MSE 0.3225
2020-11-05 19:05:18,580 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8788 | Iter Mean Loss 6.8788
2020-11-05 19:05:18,591 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6310 | Iter Mean Loss 4.7549
2020-11-05 19:05:18,600 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3106 | Iter Mean Loss 5.9401
2020-11-05 19:05:18,607 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2594 | Iter Mean Loss 6.2700
2020-11-05 19:05:18,615 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7941 | Iter Mean Loss 5.9748
2020-11-05 19:05:18,617 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.2817 | MSE 0.3225
2020-11-05 19:05:18,627 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8707 | Iter Mean Loss 6.8707
2020-11-05 19:05:18,635 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6277 | Iter Mean Loss 4.7492
2020-11-05 19:05:18,644 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9318
2020-11-05 19:05:18,651 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2475 | Iter Mean Loss 6.2607
2020-11-05 19:05:18,659 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7849 | Iter Mean Loss 5.9655
2020-11-05 19:05:18,661 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.2817 | MSE 0.3224
2020-11-05 19:05:18,671 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8626 | Iter Mean Loss 6.8626
2020-11-05 19:05:18,679 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6244 | Iter Mean Loss 4.7435
2020-11-05 19:05:18,687 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2834 | Iter Mean Loss 5.9235
2020-11-05 19:05:18,695 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2355 | Iter Mean Loss 6.2515
2020-11-05 19:05:18,703 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7758 | Iter Mean Loss 5.9563
2020-11-05 19:05:18,706 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.2817 | MSE 0.3224
2020-11-05 19:05:18,715 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8546 | Iter Mean Loss 6.8546
2020-11-05 19:05:18,723 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6211 | Iter Mean Loss 4.7378
2020-11-05 19:05:18,731 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2698 | Iter Mean Loss 5.9152
2020-11-05 19:05:18,738 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2236 | Iter Mean Loss 6.2423
2020-11-05 19:05:18,746 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7667 | Iter Mean Loss 5.9471
2020-11-05 19:05:18,748 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.2817 | MSE 0.3223
2020-11-05 19:05:18,756 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 6.8466
2020-11-05 19:05:18,764 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6177 | Iter Mean Loss 4.7321
2020-11-05 19:05:18,772 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2563 | Iter Mean Loss 5.9069
2020-11-05 19:05:18,780 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2116 | Iter Mean Loss 6.2331
2020-11-05 19:05:18,788 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7576 | Iter Mean Loss 5.9380
2020-11-05 19:05:18,790 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.2817 | MSE 0.3223
2020-11-05 19:05:18,800 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8386 | Iter Mean Loss 6.8386
2020-11-05 19:05:18,807 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6144 | Iter Mean Loss 4.7265
2020-11-05 19:05:18,815 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2428 | Iter Mean Loss 5.8986
2020-11-05 19:05:18,823 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1998 | Iter Mean Loss 6.2239
2020-11-05 19:05:18,832 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7486 | Iter Mean Loss 5.9288
2020-11-05 19:05:18,834 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.2817 | MSE 0.3222
2020-11-05 19:05:18,843 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8307 | Iter Mean Loss 6.8307
2020-11-05 19:05:18,852 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6110 | Iter Mean Loss 4.7208
2020-11-05 19:05:18,860 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2293 | Iter Mean Loss 5.8903
2020-11-05 19:05:18,869 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1879 | Iter Mean Loss 6.2147
2020-11-05 19:05:18,877 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 5.9197
2020-11-05 19:05:18,879 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.2817 | MSE 0.3221
2020-11-05 19:05:18,888 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8228 | Iter Mean Loss 6.8228
2020-11-05 19:05:18,895 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6076 | Iter Mean Loss 4.7152
2020-11-05 19:05:18,903 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2159 | Iter Mean Loss 5.8821
2020-11-05 19:05:18,911 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1761 | Iter Mean Loss 6.2056
2020-11-05 19:05:18,918 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7305 | Iter Mean Loss 5.9106
2020-11-05 19:05:18,920 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.2817 | MSE 0.3221
2020-11-05 19:05:18,929 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8149 | Iter Mean Loss 6.8149
2020-11-05 19:05:18,938 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6042 | Iter Mean Loss 4.7096
2020-11-05 19:05:18,946 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2025 | Iter Mean Loss 5.8739
2020-11-05 19:05:18,954 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1642 | Iter Mean Loss 6.1965
2020-11-05 19:05:18,962 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7214 | Iter Mean Loss 5.9015
2020-11-05 19:05:18,964 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.2817 | MSE 0.3220
2020-11-05 19:05:18,973 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8070 | Iter Mean Loss 6.8070
2020-11-05 19:05:18,981 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6008 | Iter Mean Loss 4.7039
2020-11-05 19:05:18,989 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1891 | Iter Mean Loss 5.8657
2020-11-05 19:05:18,997 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1524 | Iter Mean Loss 6.1874
2020-11-05 19:05:19,005 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7124 | Iter Mean Loss 5.8924
2020-11-05 19:05:19,007 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.2817 | MSE 0.3220
2020-11-05 19:05:19,016 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7992 | Iter Mean Loss 6.7992
2020-11-05 19:05:19,026 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5974 | Iter Mean Loss 4.6983
2020-11-05 19:05:19,034 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1758 | Iter Mean Loss 5.8575
2020-11-05 19:05:19,045 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1407 | Iter Mean Loss 6.1783
2020-11-05 19:05:19,053 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7034 | Iter Mean Loss 5.8833
2020-11-05 19:05:19,055 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.2817 | MSE 0.3219
2020-11-05 19:05:19,064 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7914 | Iter Mean Loss 6.7914
2020-11-05 19:05:19,075 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5940 | Iter Mean Loss 4.6927
2020-11-05 19:05:19,083 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1625 | Iter Mean Loss 5.8493
2020-11-05 19:05:19,091 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1289 | Iter Mean Loss 6.1692
2020-11-05 19:05:19,100 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6944 | Iter Mean Loss 5.8742
2020-11-05 19:05:19,102 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.2817 | MSE 0.3219
2020-11-05 19:05:19,111 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7837 | Iter Mean Loss 6.7837
2020-11-05 19:05:19,119 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5906 | Iter Mean Loss 4.6871
2020-11-05 19:05:19,127 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1492 | Iter Mean Loss 5.8411
2020-11-05 19:05:19,135 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1172 | Iter Mean Loss 6.1602
2020-11-05 19:05:19,145 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6854 | Iter Mean Loss 5.8652
2020-11-05 19:05:19,147 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.2817 | MSE 0.3218
2020-11-05 19:05:19,155 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7759 | Iter Mean Loss 6.7759
2020-11-05 19:05:19,164 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5871 | Iter Mean Loss 4.6815
2020-11-05 19:05:19,171 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1359 | Iter Mean Loss 5.8330
2020-11-05 19:05:19,179 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1054 | Iter Mean Loss 6.1511
2020-11-05 19:05:19,187 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6764 | Iter Mean Loss 5.8562
2020-11-05 19:05:19,189 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.2817 | MSE 0.3218
2020-11-05 19:05:19,198 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7682 | Iter Mean Loss 6.7682
2020-11-05 19:05:19,206 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5837 | Iter Mean Loss 4.6759
2020-11-05 19:05:19,214 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1227 | Iter Mean Loss 5.8249
2020-11-05 19:05:19,222 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0937 | Iter Mean Loss 6.1421
2020-11-05 19:05:19,230 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6674 | Iter Mean Loss 5.8472
2020-11-05 19:05:19,232 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.2817 | MSE 0.3217
2020-11-05 19:05:19,241 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7605 | Iter Mean Loss 6.7605
2020-11-05 19:05:19,251 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5802 | Iter Mean Loss 4.6704
2020-11-05 19:05:19,259 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 5.8167
2020-11-05 19:05:19,269 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0821 | Iter Mean Loss 6.1331
2020-11-05 19:05:19,277 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6585 | Iter Mean Loss 5.8381
2020-11-05 19:05:19,280 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.2817 | MSE 0.3217
2020-11-05 19:05:19,290 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7529 | Iter Mean Loss 6.7529
2020-11-05 19:05:19,299 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5767 | Iter Mean Loss 4.6648
2020-11-05 19:05:19,307 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0963 | Iter Mean Loss 5.8086
2020-11-05 19:05:19,318 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0704 | Iter Mean Loss 6.1241
2020-11-05 19:05:19,330 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6495 | Iter Mean Loss 5.8292
2020-11-05 19:05:19,332 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.2817 | MSE 0.3216
2020-11-05 19:05:19,341 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7453 | Iter Mean Loss 6.7453
2020-11-05 19:05:19,349 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 4.6592
2020-11-05 19:05:19,357 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0831 | Iter Mean Loss 5.8005
2020-11-05 19:05:19,364 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0588 | Iter Mean Loss 6.1151
2020-11-05 19:05:19,372 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6406 | Iter Mean Loss 5.8202
2020-11-05 19:05:19,374 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.2817 | MSE 0.3216
2020-11-05 19:05:19,382 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7377 | Iter Mean Loss 6.7377
2020-11-05 19:05:19,390 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5696 | Iter Mean Loss 4.6536
2020-11-05 19:05:19,399 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0700 | Iter Mean Loss 5.7924
2020-11-05 19:05:19,406 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0471 | Iter Mean Loss 6.1061
2020-11-05 19:05:19,414 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6316 | Iter Mean Loss 5.8112
2020-11-05 19:05:19,416 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.2817 | MSE 0.3215
2020-11-05 19:05:19,425 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7301 | Iter Mean Loss 6.7301
2020-11-05 19:05:19,435 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5661 | Iter Mean Loss 4.6481
2020-11-05 19:05:19,443 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0569 | Iter Mean Loss 5.7843
2020-11-05 19:05:19,453 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0355 | Iter Mean Loss 6.0971
2020-11-05 19:05:19,461 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6227 | Iter Mean Loss 5.8022
2020-11-05 19:05:19,463 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.2817 | MSE 0.3215
2020-11-05 19:05:19,472 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7225 | Iter Mean Loss 6.7225
2020-11-05 19:05:19,482 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5625 | Iter Mean Loss 4.6425
2020-11-05 19:05:19,491 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0438 | Iter Mean Loss 5.7763
2020-11-05 19:05:19,498 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0239 | Iter Mean Loss 6.0882
2020-11-05 19:05:19,506 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6137 | Iter Mean Loss 5.7933
2020-11-05 19:05:19,508 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.2817 | MSE 0.3214
2020-11-05 19:05:19,517 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7150 | Iter Mean Loss 6.7150
2020-11-05 19:05:19,525 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5589 | Iter Mean Loss 4.6370
2020-11-05 19:05:19,532 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0307 | Iter Mean Loss 5.7682
2020-11-05 19:05:19,540 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0123 | Iter Mean Loss 6.0792
2020-11-05 19:05:19,548 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6048 | Iter Mean Loss 5.7844
2020-11-05 19:05:19,550 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.2817 | MSE 0.3214
2020-11-05 19:05:19,558 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7075 | Iter Mean Loss 6.7075
2020-11-05 19:05:19,566 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5553 | Iter Mean Loss 4.6314
2020-11-05 19:05:19,574 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0176 | Iter Mean Loss 5.7601
2020-11-05 19:05:19,582 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0008 | Iter Mean Loss 6.0703
2020-11-05 19:05:19,590 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5959 | Iter Mean Loss 5.7754
2020-11-05 19:05:19,592 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.2817 | MSE 0.3213
2020-11-05 19:05:19,600 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7000 | Iter Mean Loss 6.7000
2020-11-05 19:05:19,608 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5517 | Iter Mean Loss 4.6258
2020-11-05 19:05:19,618 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0046 | Iter Mean Loss 5.7521
2020-11-05 19:05:19,626 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9892 | Iter Mean Loss 6.0614
2020-11-05 19:05:19,633 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5870 | Iter Mean Loss 5.7665
2020-11-05 19:05:19,636 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.2817 | MSE 0.3213
2020-11-05 19:05:19,645 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6925 | Iter Mean Loss 6.6925
2020-11-05 19:05:19,653 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5480 | Iter Mean Loss 4.6203
2020-11-05 19:05:19,661 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9916 | Iter Mean Loss 5.7441
2020-11-05 19:05:19,669 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9776 | Iter Mean Loss 6.0525
2020-11-05 19:05:19,677 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5781 | Iter Mean Loss 5.7576
2020-11-05 19:05:19,679 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.2817 | MSE 0.3212
2020-11-05 19:05:19,689 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6851 | Iter Mean Loss 6.6851
2020-11-05 19:05:19,697 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5444 | Iter Mean Loss 4.6147
2020-11-05 19:05:19,706 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9786 | Iter Mean Loss 5.7360
2020-11-05 19:05:19,714 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9661 | Iter Mean Loss 6.0435
2020-11-05 19:05:19,722 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5692 | Iter Mean Loss 5.7487
2020-11-05 19:05:19,724 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.2817 | MSE 0.3212
2020-11-05 19:05:19,732 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6777 | Iter Mean Loss 6.6777
2020-11-05 19:05:19,740 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5407 | Iter Mean Loss 4.6092
2020-11-05 19:05:19,748 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9656 | Iter Mean Loss 5.7280
2020-11-05 19:05:19,756 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9546 | Iter Mean Loss 6.0346
2020-11-05 19:05:19,763 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5603 | Iter Mean Loss 5.7398
2020-11-05 19:05:19,765 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.2817 | MSE 0.3211
2020-11-05 19:05:19,773 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6703 | Iter Mean Loss 6.6703
2020-11-05 19:05:19,781 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5370 | Iter Mean Loss 4.6036
2020-11-05 19:05:19,789 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9526 | Iter Mean Loss 5.7200
2020-11-05 19:05:19,796 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9431 | Iter Mean Loss 6.0257
2020-11-05 19:05:19,804 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5514 | Iter Mean Loss 5.7309
2020-11-05 19:05:19,806 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.2817 | MSE 0.3211
2020-11-05 19:05:19,814 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6629 | Iter Mean Loss 6.6629
2020-11-05 19:05:19,822 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5333 | Iter Mean Loss 4.5981
2020-11-05 19:05:19,830 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9397 | Iter Mean Loss 5.7119
2020-11-05 19:05:19,839 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9316 | Iter Mean Loss 6.0169
2020-11-05 19:05:19,847 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5425 | Iter Mean Loss 5.7220
2020-11-05 19:05:19,850 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.2817 | MSE 0.3210
2020-11-05 19:05:19,860 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6556 | Iter Mean Loss 6.6556
2020-11-05 19:05:19,869 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5295 | Iter Mean Loss 4.5925
2020-11-05 19:05:19,877 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9267 | Iter Mean Loss 5.7039
2020-11-05 19:05:19,886 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9201 | Iter Mean Loss 6.0080
2020-11-05 19:05:19,893 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5336 | Iter Mean Loss 5.7131
2020-11-05 19:05:19,895 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.2817 | MSE 0.3210
2020-11-05 19:05:19,903 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6482 | Iter Mean Loss 6.6482
2020-11-05 19:05:19,911 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5257 | Iter Mean Loss 4.5870
2020-11-05 19:05:19,919 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9138 | Iter Mean Loss 5.6959
2020-11-05 19:05:19,926 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 5.9991
2020-11-05 19:05:19,933 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5247 | Iter Mean Loss 5.7042
2020-11-05 19:05:19,935 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.2817 | MSE 0.3209
2020-11-05 19:05:19,943 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6409 | Iter Mean Loss 6.6409
2020-11-05 19:05:19,950 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5219 | Iter Mean Loss 4.5814
2020-11-05 19:05:19,959 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 5.6879
2020-11-05 19:05:19,971 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8971 | Iter Mean Loss 5.9902
2020-11-05 19:05:19,985 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5158 | Iter Mean Loss 5.6953
2020-11-05 19:05:19,991 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.2817 | MSE 0.3209
2020-11-05 19:05:20,010 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6336 | Iter Mean Loss 6.6336
2020-11-05 19:05:20,024 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5181 | Iter Mean Loss 4.5759
2020-11-05 19:05:20,042 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8880 | Iter Mean Loss 5.6799
2020-11-05 19:05:20,060 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8856 | Iter Mean Loss 5.9813
2020-11-05 19:05:20,076 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 5.6865
2020-11-05 19:05:20,081 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.2817 | MSE 0.3208
2020-11-05 19:05:20,098 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6263 | Iter Mean Loss 6.6263
2020-11-05 19:05:20,111 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5143 | Iter Mean Loss 4.5703
2020-11-05 19:05:20,120 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8751 | Iter Mean Loss 5.6719
2020-11-05 19:05:20,132 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8742 | Iter Mean Loss 5.9725
2020-11-05 19:05:20,145 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4980 | Iter Mean Loss 5.6776
2020-11-05 19:05:20,148 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.2817 | MSE 0.3208
2020-11-05 19:05:20,160 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6191 | Iter Mean Loss 6.6191
2020-11-05 19:05:20,170 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5104 | Iter Mean Loss 4.5647
2020-11-05 19:05:20,182 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8623 | Iter Mean Loss 5.6639
2020-11-05 19:05:20,194 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8627 | Iter Mean Loss 5.9636
2020-11-05 19:05:20,203 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4891 | Iter Mean Loss 5.6687
2020-11-05 19:05:20,208 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.2817 | MSE 0.3207
2020-11-05 19:05:20,220 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6118 | Iter Mean Loss 6.6118
2020-11-05 19:05:20,232 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5065 | Iter Mean Loss 4.5592
2020-11-05 19:05:20,244 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 5.6559
2020-11-05 19:05:20,253 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8513 | Iter Mean Loss 5.9547
2020-11-05 19:05:20,265 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4802 | Iter Mean Loss 5.6598
2020-11-05 19:05:20,268 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.2817 | MSE 0.3207
2020-11-05 19:05:20,281 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.6046
2020-11-05 19:05:20,291 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5026 | Iter Mean Loss 4.5536
2020-11-05 19:05:20,301 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8365 | Iter Mean Loss 5.6479
2020-11-05 19:05:20,313 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8398 | Iter Mean Loss 5.9459
2020-11-05 19:05:20,323 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4713 | Iter Mean Loss 5.6510
2020-11-05 19:05:20,327 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:20,336 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5974 | Iter Mean Loss 6.5974
2020-11-05 19:05:20,344 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4986 | Iter Mean Loss 4.5480
2020-11-05 19:05:20,351 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8237 | Iter Mean Loss 5.6399
2020-11-05 19:05:20,358 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8284 | Iter Mean Loss 5.9370
2020-11-05 19:05:20,366 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4624 | Iter Mean Loss 5.6421
2020-11-05 19:05:20,368 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:20,376 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5902 | Iter Mean Loss 6.5902
2020-11-05 19:05:20,383 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4947 | Iter Mean Loss 4.5424
2020-11-05 19:05:20,391 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8109 | Iter Mean Loss 5.6319
2020-11-05 19:05:20,398 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8169 | Iter Mean Loss 5.9282
2020-11-05 19:05:20,406 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 5.6332
2020-11-05 19:05:20,408 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:20,418 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5830 | Iter Mean Loss 6.5830
2020-11-05 19:05:20,431 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4907 | Iter Mean Loss 4.5368
2020-11-05 19:05:20,441 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7981 | Iter Mean Loss 5.6239
2020-11-05 19:05:20,450 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8055 | Iter Mean Loss 5.9193
2020-11-05 19:05:20,461 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4446 | Iter Mean Loss 5.6244
2020-11-05 19:05:20,463 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:20,473 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5758 | Iter Mean Loss 6.5758
2020-11-05 19:05:20,482 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4866 | Iter Mean Loss 4.5312
2020-11-05 19:05:20,492 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7852 | Iter Mean Loss 5.6159
2020-11-05 19:05:20,503 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7941 | Iter Mean Loss 5.9104
2020-11-05 19:05:20,513 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4357 | Iter Mean Loss 5.6155
2020-11-05 19:05:20,515 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:20,525 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5687 | Iter Mean Loss 6.5687
2020-11-05 19:05:20,534 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4826 | Iter Mean Loss 4.5256
2020-11-05 19:05:20,541 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7724 | Iter Mean Loss 5.6079
2020-11-05 19:05:20,549 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7826 | Iter Mean Loss 5.9016
2020-11-05 19:05:20,556 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4268 | Iter Mean Loss 5.6066
2020-11-05 19:05:20,558 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.2817 | MSE 0.3204
2020-11-05 19:05:20,569 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5615 | Iter Mean Loss 6.5615
2020-11-05 19:05:20,579 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4785 | Iter Mean Loss 4.5200
2020-11-05 19:05:20,588 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7596 | Iter Mean Loss 5.5999
2020-11-05 19:05:20,597 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7712 | Iter Mean Loss 5.8927
2020-11-05 19:05:20,607 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 5.5978
2020-11-05 19:05:20,609 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.2817 | MSE 0.3204
2020-11-05 19:05:20,618 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5544 | Iter Mean Loss 6.5544
2020-11-05 19:05:20,628 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4744 | Iter Mean Loss 4.5144
2020-11-05 19:05:20,639 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7468 | Iter Mean Loss 5.5919
2020-11-05 19:05:20,646 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 5.8839
2020-11-05 19:05:20,656 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4090 | Iter Mean Loss 5.5889
2020-11-05 19:05:20,658 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:20,667 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5473 | Iter Mean Loss 6.5473
2020-11-05 19:05:20,676 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4703 | Iter Mean Loss 4.5088
2020-11-05 19:05:20,685 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7340 | Iter Mean Loss 5.5839
2020-11-05 19:05:20,694 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7484 | Iter Mean Loss 5.8750
2020-11-05 19:05:20,703 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 5.5800
2020-11-05 19:05:20,706 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:20,715 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5402 | Iter Mean Loss 6.5402
2020-11-05 19:05:20,724 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4661 | Iter Mean Loss 4.5031
2020-11-05 19:05:20,732 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7212 | Iter Mean Loss 5.5758
2020-11-05 19:05:20,741 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7369 | Iter Mean Loss 5.8661
2020-11-05 19:05:20,749 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3911 | Iter Mean Loss 5.5711
2020-11-05 19:05:20,751 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:20,761 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5331 | Iter Mean Loss 6.5331
2020-11-05 19:05:20,770 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4619 | Iter Mean Loss 4.4975
2020-11-05 19:05:20,779 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7085 | Iter Mean Loss 5.5678
2020-11-05 19:05:20,788 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7255 | Iter Mean Loss 5.8572
2020-11-05 19:05:20,797 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3822 | Iter Mean Loss 5.5622
2020-11-05 19:05:20,799 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:20,808 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5260 | Iter Mean Loss 6.5260
2020-11-05 19:05:20,825 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4576 | Iter Mean Loss 4.4918
2020-11-05 19:05:20,837 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6957 | Iter Mean Loss 5.5598
2020-11-05 19:05:20,853 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7141 | Iter Mean Loss 5.8484
2020-11-05 19:05:20,867 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3733 | Iter Mean Loss 5.5533
2020-11-05 19:05:20,869 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:20,884 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5190 | Iter Mean Loss 6.5190
2020-11-05 19:05:20,898 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 4.4862
2020-11-05 19:05:20,910 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6829 | Iter Mean Loss 5.5518
2020-11-05 19:05:20,922 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7026 | Iter Mean Loss 5.8395
2020-11-05 19:05:20,936 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3643 | Iter Mean Loss 5.5444
2020-11-05 19:05:20,942 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.2817 | MSE 0.3201
2020-11-05 19:05:20,958 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5119 | Iter Mean Loss 6.5119
2020-11-05 19:05:20,969 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4491 | Iter Mean Loss 4.4805
2020-11-05 19:05:20,982 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6701 | Iter Mean Loss 5.5437
2020-11-05 19:05:20,993 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6912 | Iter Mean Loss 5.8306
2020-11-05 19:05:21,002 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3553 | Iter Mean Loss 5.5355
2020-11-05 19:05:21,006 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.2817 | MSE 0.3201
2020-11-05 19:05:21,016 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5049 | Iter Mean Loss 6.5049
2020-11-05 19:05:21,025 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4447 | Iter Mean Loss 4.4748
2020-11-05 19:05:21,033 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6573 | Iter Mean Loss 5.5357
2020-11-05 19:05:21,043 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6798 | Iter Mean Loss 5.8217
2020-11-05 19:05:21,051 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3464 | Iter Mean Loss 5.5266
2020-11-05 19:05:21,053 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:21,065 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4979 | Iter Mean Loss 6.4979
2020-11-05 19:05:21,076 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4404 | Iter Mean Loss 4.4691
2020-11-05 19:05:21,085 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6445 | Iter Mean Loss 5.5276
2020-11-05 19:05:21,094 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6683 | Iter Mean Loss 5.8128
2020-11-05 19:05:21,103 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3374 | Iter Mean Loss 5.5177
2020-11-05 19:05:21,107 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:21,117 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4909 | Iter Mean Loss 6.4909
2020-11-05 19:05:21,128 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4360 | Iter Mean Loss 4.4634
2020-11-05 19:05:21,138 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5195
2020-11-05 19:05:21,147 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6569 | Iter Mean Loss 5.8039
2020-11-05 19:05:21,156 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3284 | Iter Mean Loss 5.5088
2020-11-05 19:05:21,161 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:21,171 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4839 | Iter Mean Loss 6.4839
2020-11-05 19:05:21,182 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4315 | Iter Mean Loss 4.4577
2020-11-05 19:05:21,193 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6190 | Iter Mean Loss 5.5115
2020-11-05 19:05:21,203 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6454 | Iter Mean Loss 5.7949
2020-11-05 19:05:21,214 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3194 | Iter Mean Loss 5.4998
2020-11-05 19:05:21,216 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:21,224 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4769 | Iter Mean Loss 6.4769
2020-11-05 19:05:21,231 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4271 | Iter Mean Loss 4.4520
2020-11-05 19:05:21,239 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6062 | Iter Mean Loss 5.5034
2020-11-05 19:05:21,246 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6339 | Iter Mean Loss 5.7860
2020-11-05 19:05:21,253 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3104 | Iter Mean Loss 5.4909
2020-11-05 19:05:21,255 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:21,263 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4699 | Iter Mean Loss 6.4699
2020-11-05 19:05:21,270 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4226 | Iter Mean Loss 4.4462
2020-11-05 19:05:21,277 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5934 | Iter Mean Loss 5.4953
2020-11-05 19:05:21,285 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6225 | Iter Mean Loss 5.7771
2020-11-05 19:05:21,293 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3014 | Iter Mean Loss 5.4819
2020-11-05 19:05:21,295 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:21,303 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4629 | Iter Mean Loss 6.4629
2020-11-05 19:05:21,311 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4180 | Iter Mean Loss 4.4405
2020-11-05 19:05:21,319 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5806 | Iter Mean Loss 5.4872
2020-11-05 19:05:21,329 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6110 | Iter Mean Loss 5.7681
2020-11-05 19:05:21,336 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2924 | Iter Mean Loss 5.4730
2020-11-05 19:05:21,338 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:21,347 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4560 | Iter Mean Loss 6.4560
2020-11-05 19:05:21,355 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4134 | Iter Mean Loss 4.4347
2020-11-05 19:05:21,362 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5678 | Iter Mean Loss 5.4791
2020-11-05 19:05:21,371 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5995 | Iter Mean Loss 5.7592
2020-11-05 19:05:21,378 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2833 | Iter Mean Loss 5.4640
2020-11-05 19:05:21,380 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:21,388 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4490 | Iter Mean Loss 6.4490
2020-11-05 19:05:21,396 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4088 | Iter Mean Loss 4.4289
2020-11-05 19:05:21,403 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5550 | Iter Mean Loss 5.4709
2020-11-05 19:05:21,412 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5880 | Iter Mean Loss 5.7502
2020-11-05 19:05:21,422 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2743 | Iter Mean Loss 5.4550
2020-11-05 19:05:21,425 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:21,434 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4421 | Iter Mean Loss 6.4421
2020-11-05 19:05:21,442 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4042 | Iter Mean Loss 4.4231
2020-11-05 19:05:21,450 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5422 | Iter Mean Loss 5.4628
2020-11-05 19:05:21,457 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5765 | Iter Mean Loss 5.7412
2020-11-05 19:05:21,466 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2652 | Iter Mean Loss 5.4460
2020-11-05 19:05:21,469 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:21,479 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4351 | Iter Mean Loss 6.4351
2020-11-05 19:05:21,489 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3995 | Iter Mean Loss 4.4173
2020-11-05 19:05:21,498 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5294 | Iter Mean Loss 5.4547
2020-11-05 19:05:21,507 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5650 | Iter Mean Loss 5.7323
2020-11-05 19:05:21,515 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2561 | Iter Mean Loss 5.4370
2020-11-05 19:05:21,519 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:21,528 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4282 | Iter Mean Loss 6.4282
2020-11-05 19:05:21,539 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3948 | Iter Mean Loss 4.4115
2020-11-05 19:05:21,548 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5166 | Iter Mean Loss 5.4465
2020-11-05 19:05:21,557 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5535 | Iter Mean Loss 5.7233
2020-11-05 19:05:21,566 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2470 | Iter Mean Loss 5.4280
2020-11-05 19:05:21,569 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:21,578 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4213 | Iter Mean Loss 6.4213
2020-11-05 19:05:21,587 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3900 | Iter Mean Loss 4.4056
2020-11-05 19:05:21,594 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5037 | Iter Mean Loss 5.4383
2020-11-05 19:05:21,601 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5419 | Iter Mean Loss 5.7142
2020-11-05 19:05:21,609 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2379 | Iter Mean Loss 5.4190
2020-11-05 19:05:21,611 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:21,619 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4144 | Iter Mean Loss 6.4144
2020-11-05 19:05:21,627 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3852 | Iter Mean Loss 4.3998
2020-11-05 19:05:21,635 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4909 | Iter Mean Loss 5.4302
2020-11-05 19:05:21,644 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5304 | Iter Mean Loss 5.7052
2020-11-05 19:05:21,652 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2288 | Iter Mean Loss 5.4099
2020-11-05 19:05:21,654 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:21,663 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4075 | Iter Mean Loss 6.4075
2020-11-05 19:05:21,671 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3803 | Iter Mean Loss 4.3939
2020-11-05 19:05:21,679 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4781 | Iter Mean Loss 5.4220
2020-11-05 19:05:21,688 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5188 | Iter Mean Loss 5.6962
2020-11-05 19:05:21,698 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2197 | Iter Mean Loss 5.4009
2020-11-05 19:05:21,700 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:21,711 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4006 | Iter Mean Loss 6.4006
2020-11-05 19:05:21,721 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3755 | Iter Mean Loss 4.3880
2020-11-05 19:05:21,732 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4652 | Iter Mean Loss 5.4137
2020-11-05 19:05:21,741 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5073 | Iter Mean Loss 5.6871
2020-11-05 19:05:21,751 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2105 | Iter Mean Loss 5.3918
2020-11-05 19:05:21,753 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:21,763 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3937 | Iter Mean Loss 6.3937
2020-11-05 19:05:21,772 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3705 | Iter Mean Loss 4.3821
2020-11-05 19:05:21,779 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4524 | Iter Mean Loss 5.4055
2020-11-05 19:05:21,791 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4957 | Iter Mean Loss 5.6781
2020-11-05 19:05:21,803 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2013 | Iter Mean Loss 5.3827
2020-11-05 19:05:21,806 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:21,815 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3868 | Iter Mean Loss 6.3868
2020-11-05 19:05:21,825 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3656 | Iter Mean Loss 4.3762
2020-11-05 19:05:21,834 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4395 | Iter Mean Loss 5.3973
2020-11-05 19:05:21,844 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4841 | Iter Mean Loss 5.6690
2020-11-05 19:05:21,853 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1922 | Iter Mean Loss 5.3736
2020-11-05 19:05:21,856 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:21,866 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3799 | Iter Mean Loss 6.3799
2020-11-05 19:05:21,877 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3606 | Iter Mean Loss 4.3702
2020-11-05 19:05:21,890 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4266 | Iter Mean Loss 5.3890
2020-11-05 19:05:21,903 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4725 | Iter Mean Loss 5.6599
2020-11-05 19:05:21,913 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1830 | Iter Mean Loss 5.3645
2020-11-05 19:05:21,918 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:21,930 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3730 | Iter Mean Loss 6.3730
2020-11-05 19:05:21,940 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3555 | Iter Mean Loss 4.3643
2020-11-05 19:05:21,951 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4137 | Iter Mean Loss 5.3807
2020-11-05 19:05:21,963 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4609 | Iter Mean Loss 5.6508
2020-11-05 19:05:21,974 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1737 | Iter Mean Loss 5.3554
2020-11-05 19:05:21,976 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:21,988 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 6.3662
2020-11-05 19:05:21,999 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3504 | Iter Mean Loss 4.3583
2020-11-05 19:05:22,010 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4008 | Iter Mean Loss 5.3725
2020-11-05 19:05:22,023 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4493 | Iter Mean Loss 5.6417
2020-11-05 19:05:22,035 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1645 | Iter Mean Loss 5.3462
2020-11-05 19:05:22,039 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:22,052 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3593 | Iter Mean Loss 6.3593
2020-11-05 19:05:22,062 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3453 | Iter Mean Loss 4.3523
2020-11-05 19:05:22,072 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3879 | Iter Mean Loss 5.3642
2020-11-05 19:05:22,080 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4376 | Iter Mean Loss 5.6325
2020-11-05 19:05:22,092 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1552 | Iter Mean Loss 5.3371
2020-11-05 19:05:22,095 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:22,109 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3524 | Iter Mean Loss 6.3524
2020-11-05 19:05:22,122 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3401 | Iter Mean Loss 4.3463
2020-11-05 19:05:22,136 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3750 | Iter Mean Loss 5.3558
2020-11-05 19:05:22,149 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4259 | Iter Mean Loss 5.6234
2020-11-05 19:05:22,162 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1460 | Iter Mean Loss 5.3279
2020-11-05 19:05:22,166 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:22,181 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3456 | Iter Mean Loss 6.3456
2020-11-05 19:05:22,195 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3349 | Iter Mean Loss 4.3403
2020-11-05 19:05:22,208 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3620 | Iter Mean Loss 5.3475
2020-11-05 19:05:22,221 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4143 | Iter Mean Loss 5.6142
2020-11-05 19:05:22,233 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1367 | Iter Mean Loss 5.3187
2020-11-05 19:05:22,238 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:22,250 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3388 | Iter Mean Loss 6.3388
2020-11-05 19:05:22,263 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3297 | Iter Mean Loss 4.3342
2020-11-05 19:05:22,276 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3491 | Iter Mean Loss 5.3392
2020-11-05 19:05:22,288 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4026 | Iter Mean Loss 5.6050
2020-11-05 19:05:22,300 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1274 | Iter Mean Loss 5.3095
2020-11-05 19:05:22,305 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:22,322 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3319 | Iter Mean Loss 6.3319
2020-11-05 19:05:22,336 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3244 | Iter Mean Loss 4.3281
2020-11-05 19:05:22,349 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3361 | Iter Mean Loss 5.3308
2020-11-05 19:05:22,363 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3909 | Iter Mean Loss 5.5958
2020-11-05 19:05:22,376 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1180 | Iter Mean Loss 5.3002
2020-11-05 19:05:22,380 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:22,394 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3251 | Iter Mean Loss 6.3251
2020-11-05 19:05:22,406 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3190 | Iter Mean Loss 4.3220
2020-11-05 19:05:22,418 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3231 | Iter Mean Loss 5.3224
2020-11-05 19:05:22,430 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3791 | Iter Mean Loss 5.5866
2020-11-05 19:05:22,442 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1087 | Iter Mean Loss 5.2910
2020-11-05 19:05:22,445 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:22,455 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3183 | Iter Mean Loss 6.3183
2020-11-05 19:05:22,464 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3136 | Iter Mean Loss 4.3159
2020-11-05 19:05:22,478 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3101 | Iter Mean Loss 5.3140
2020-11-05 19:05:22,491 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3674 | Iter Mean Loss 5.5773
2020-11-05 19:05:22,503 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0993 | Iter Mean Loss 5.2817
2020-11-05 19:05:22,506 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:22,519 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3114 | Iter Mean Loss 6.3114
2020-11-05 19:05:22,532 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3082 | Iter Mean Loss 4.3098
2020-11-05 19:05:22,544 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2971 | Iter Mean Loss 5.3056
2020-11-05 19:05:22,556 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3556 | Iter Mean Loss 5.5681
2020-11-05 19:05:22,566 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 5.2725
2020-11-05 19:05:22,568 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:22,578 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3046 | Iter Mean Loss 6.3046
2020-11-05 19:05:22,587 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3027 | Iter Mean Loss 4.3037
2020-11-05 19:05:22,595 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2841 | Iter Mean Loss 5.2971
2020-11-05 19:05:22,604 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3438 | Iter Mean Loss 5.5588
2020-11-05 19:05:22,617 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0805 | Iter Mean Loss 5.2632
2020-11-05 19:05:22,619 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:22,632 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2978 | Iter Mean Loss 6.2978
2020-11-05 19:05:22,643 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2972 | Iter Mean Loss 4.2975
2020-11-05 19:05:22,653 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2710 | Iter Mean Loss 5.2887
2020-11-05 19:05:22,664 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3320 | Iter Mean Loss 5.5495
2020-11-05 19:05:22,673 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 5.2538
2020-11-05 19:05:22,676 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:22,690 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2910 | Iter Mean Loss 6.2910
2020-11-05 19:05:22,702 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 4.2913
2020-11-05 19:05:22,714 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2580 | Iter Mean Loss 5.2802
2020-11-05 19:05:22,724 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3202 | Iter Mean Loss 5.5402
2020-11-05 19:05:22,739 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0616 | Iter Mean Loss 5.2445
2020-11-05 19:05:22,743 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:22,760 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2842 | Iter Mean Loss 6.2842
2020-11-05 19:05:22,777 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2860 | Iter Mean Loss 4.2851
2020-11-05 19:05:22,792 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2449 | Iter Mean Loss 5.2717
2020-11-05 19:05:22,804 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3084 | Iter Mean Loss 5.5309
2020-11-05 19:05:22,814 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0522 | Iter Mean Loss 5.2351
2020-11-05 19:05:22,818 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:22,828 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2774 | Iter Mean Loss 6.2774
2020-11-05 19:05:22,841 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2804 | Iter Mean Loss 4.2789
2020-11-05 19:05:22,853 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2318 | Iter Mean Loss 5.2632
2020-11-05 19:05:22,865 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2966 | Iter Mean Loss 5.5215
2020-11-05 19:05:22,878 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0427 | Iter Mean Loss 5.2258
2020-11-05 19:05:22,884 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:22,897 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 6.2706
2020-11-05 19:05:22,908 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2747 | Iter Mean Loss 4.2727
2020-11-05 19:05:22,921 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2187 | Iter Mean Loss 5.2547
2020-11-05 19:05:22,932 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2847 | Iter Mean Loss 5.5122
2020-11-05 19:05:22,945 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0332 | Iter Mean Loss 5.2164
2020-11-05 19:05:22,950 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:22,963 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2639 | Iter Mean Loss 6.2639
2020-11-05 19:05:22,976 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2690 | Iter Mean Loss 4.2664
2020-11-05 19:05:22,989 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2056 | Iter Mean Loss 5.2461
2020-11-05 19:05:23,003 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2728 | Iter Mean Loss 5.5028
2020-11-05 19:05:23,013 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0236 | Iter Mean Loss 5.2070
2020-11-05 19:05:23,016 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:23,028 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2571 | Iter Mean Loss 6.2571
2020-11-05 19:05:23,040 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2632 | Iter Mean Loss 4.2601
2020-11-05 19:05:23,051 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1925 | Iter Mean Loss 5.2376
2020-11-05 19:05:23,062 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2609 | Iter Mean Loss 5.4934
2020-11-05 19:05:23,074 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 5.1975
2020-11-05 19:05:23,077 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:23,089 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2503 | Iter Mean Loss 6.2503
2020-11-05 19:05:23,099 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2574 | Iter Mean Loss 4.2538
2020-11-05 19:05:23,112 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1793 | Iter Mean Loss 5.2290
2020-11-05 19:05:23,123 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2490 | Iter Mean Loss 5.4840
2020-11-05 19:05:23,135 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0045 | Iter Mean Loss 5.1881
2020-11-05 19:05:23,138 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:23,150 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2436 | Iter Mean Loss 6.2436
2020-11-05 19:05:23,162 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2515 | Iter Mean Loss 4.2475
2020-11-05 19:05:23,174 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1661 | Iter Mean Loss 5.2204
2020-11-05 19:05:23,185 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2370 | Iter Mean Loss 5.4746
2020-11-05 19:05:23,196 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9949 | Iter Mean Loss 5.1786
2020-11-05 19:05:23,200 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:23,212 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2368 | Iter Mean Loss 6.2368
2020-11-05 19:05:23,224 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2456 | Iter Mean Loss 4.2412
2020-11-05 19:05:23,233 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1530 | Iter Mean Loss 5.2118
2020-11-05 19:05:23,245 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2251 | Iter Mean Loss 5.4651
2020-11-05 19:05:23,256 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9853 | Iter Mean Loss 5.1691
2020-11-05 19:05:23,259 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:23,269 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2300 | Iter Mean Loss 6.2300
2020-11-05 19:05:23,281 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2397 | Iter Mean Loss 4.2349
2020-11-05 19:05:23,293 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1398 | Iter Mean Loss 5.2032
2020-11-05 19:05:23,304 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.4556
2020-11-05 19:05:23,316 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9757 | Iter Mean Loss 5.1596
2020-11-05 19:05:23,319 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:23,333 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2233 | Iter Mean Loss 6.2233
2020-11-05 19:05:23,347 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2337 | Iter Mean Loss 4.2285
2020-11-05 19:05:23,360 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1266 | Iter Mean Loss 5.1945
2020-11-05 19:05:23,369 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2011 | Iter Mean Loss 5.4462
2020-11-05 19:05:23,381 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9660 | Iter Mean Loss 5.1501
2020-11-05 19:05:23,384 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:23,398 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2166 | Iter Mean Loss 6.2166
2020-11-05 19:05:23,412 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2276 | Iter Mean Loss 4.2221
2020-11-05 19:05:23,428 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1133 | Iter Mean Loss 5.1859
2020-11-05 19:05:23,440 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1891 | Iter Mean Loss 5.4367
2020-11-05 19:05:23,452 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9563 | Iter Mean Loss 5.1406
2020-11-05 19:05:23,454 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:23,468 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2098 | Iter Mean Loss 6.2098
2020-11-05 19:05:23,480 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2216 | Iter Mean Loss 4.2157
2020-11-05 19:05:23,492 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1001 | Iter Mean Loss 5.1772
2020-11-05 19:05:23,503 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1771 | Iter Mean Loss 5.4271
2020-11-05 19:05:23,515 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9466 | Iter Mean Loss 5.1310
2020-11-05 19:05:23,518 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:23,530 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2031 | Iter Mean Loss 6.2031
2020-11-05 19:05:23,541 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2155 | Iter Mean Loss 4.2093
2020-11-05 19:05:23,554 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0869 | Iter Mean Loss 5.1685
2020-11-05 19:05:23,565 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1650 | Iter Mean Loss 5.4176
2020-11-05 19:05:23,576 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9369 | Iter Mean Loss 5.1215
2020-11-05 19:05:23,579 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:23,591 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1964 | Iter Mean Loss 6.1964
2020-11-05 19:05:23,606 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2093 | Iter Mean Loss 4.2029
2020-11-05 19:05:23,618 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0736 | Iter Mean Loss 5.1598
2020-11-05 19:05:23,630 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1530 | Iter Mean Loss 5.4081
2020-11-05 19:05:23,647 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9272 | Iter Mean Loss 5.1119
2020-11-05 19:05:23,649 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:23,662 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1897 | Iter Mean Loss 6.1897
2020-11-05 19:05:23,672 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2031 | Iter Mean Loss 4.1964
2020-11-05 19:05:23,683 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0603 | Iter Mean Loss 5.1510
2020-11-05 19:05:23,694 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1409 | Iter Mean Loss 5.3985
2020-11-05 19:05:23,705 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9175 | Iter Mean Loss 5.1023
2020-11-05 19:05:23,710 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:23,721 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 6.1830
2020-11-05 19:05:23,733 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1969 | Iter Mean Loss 4.1899
2020-11-05 19:05:23,744 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0470 | Iter Mean Loss 5.1423
2020-11-05 19:05:23,756 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1288 | Iter Mean Loss 5.3889
2020-11-05 19:05:23,769 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9077 | Iter Mean Loss 5.0927
2020-11-05 19:05:23,771 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:23,785 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1763 | Iter Mean Loss 6.1763
2020-11-05 19:05:23,798 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 4.1835
2020-11-05 19:05:23,807 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0337 | Iter Mean Loss 5.1336
2020-11-05 19:05:23,819 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1167 | Iter Mean Loss 5.3793
2020-11-05 19:05:23,832 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8979 | Iter Mean Loss 5.0830
2020-11-05 19:05:23,834 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:23,846 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1696 | Iter Mean Loss 6.1696
2020-11-05 19:05:23,855 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1843 | Iter Mean Loss 4.1770
2020-11-05 19:05:23,865 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0204 | Iter Mean Loss 5.1248
2020-11-05 19:05:23,878 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1045 | Iter Mean Loss 5.3697
2020-11-05 19:05:23,890 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8881 | Iter Mean Loss 5.0734
2020-11-05 19:05:23,894 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:23,914 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1630 | Iter Mean Loss 6.1630
2020-11-05 19:05:23,927 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1780 | Iter Mean Loss 4.1705
2020-11-05 19:05:23,935 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0071 | Iter Mean Loss 5.1160
2020-11-05 19:05:23,947 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0924 | Iter Mean Loss 5.3601
2020-11-05 19:05:23,958 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8783 | Iter Mean Loss 5.0637
2020-11-05 19:05:23,961 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:23,971 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1563 | Iter Mean Loss 6.1563
2020-11-05 19:05:23,981 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1716 | Iter Mean Loss 4.1640
2020-11-05 19:05:23,993 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9937 | Iter Mean Loss 5.1072
2020-11-05 19:05:24,003 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0803 | Iter Mean Loss 5.3505
2020-11-05 19:05:24,013 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8685 | Iter Mean Loss 5.0541
2020-11-05 19:05:24,015 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:24,027 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 6.1497
2020-11-05 19:05:24,036 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1652 | Iter Mean Loss 4.1574
2020-11-05 19:05:24,046 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9804 | Iter Mean Loss 5.0984
2020-11-05 19:05:24,057 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0681 | Iter Mean Loss 5.3408
2020-11-05 19:05:24,067 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8586 | Iter Mean Loss 5.0444
2020-11-05 19:05:24,071 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:24,081 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1430 | Iter Mean Loss 6.1430
2020-11-05 19:05:24,092 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1588 | Iter Mean Loss 4.1509
2020-11-05 19:05:24,101 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9670 | Iter Mean Loss 5.0896
2020-11-05 19:05:24,112 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0559 | Iter Mean Loss 5.3312
2020-11-05 19:05:24,123 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8488 | Iter Mean Loss 5.0347
2020-11-05 19:05:24,127 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:24,136 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1364 | Iter Mean Loss 6.1364
2020-11-05 19:05:24,146 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1523 | Iter Mean Loss 4.1443
2020-11-05 19:05:24,155 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9537 | Iter Mean Loss 5.0808
2020-11-05 19:05:24,164 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0437 | Iter Mean Loss 5.3215
2020-11-05 19:05:24,173 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8389 | Iter Mean Loss 5.0250
2020-11-05 19:05:24,175 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:24,183 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1298 | Iter Mean Loss 6.1298
2020-11-05 19:05:24,192 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1458 | Iter Mean Loss 4.1378
2020-11-05 19:05:24,200 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9403 | Iter Mean Loss 5.0719
2020-11-05 19:05:24,207 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0315 | Iter Mean Loss 5.3118
2020-11-05 19:05:24,215 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8290 | Iter Mean Loss 5.0153
2020-11-05 19:05:24,218 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:24,226 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1232 | Iter Mean Loss 6.1232
2020-11-05 19:05:24,235 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1392 | Iter Mean Loss 4.1312
2020-11-05 19:05:24,243 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9269 | Iter Mean Loss 5.0631
2020-11-05 19:05:24,250 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0193 | Iter Mean Loss 5.3022
2020-11-05 19:05:24,258 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8191 | Iter Mean Loss 5.0055
2020-11-05 19:05:24,260 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:24,268 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1166 | Iter Mean Loss 6.1166
2020-11-05 19:05:24,275 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1327 | Iter Mean Loss 4.1246
2020-11-05 19:05:24,283 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9135 | Iter Mean Loss 5.0543
2020-11-05 19:05:24,291 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0071 | Iter Mean Loss 5.2925
2020-11-05 19:05:24,298 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8092 | Iter Mean Loss 4.9958
2020-11-05 19:05:24,301 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:24,309 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1100 | Iter Mean Loss 6.1100
2020-11-05 19:05:24,317 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1261 | Iter Mean Loss 4.1180
2020-11-05 19:05:24,326 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9002 | Iter Mean Loss 5.0454
2020-11-05 19:05:24,335 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9949 | Iter Mean Loss 5.2828
2020-11-05 19:05:24,342 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7993 | Iter Mean Loss 4.9861
2020-11-05 19:05:24,344 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:24,352 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1034 | Iter Mean Loss 6.1034
2020-11-05 19:05:24,360 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1195 | Iter Mean Loss 4.1114
2020-11-05 19:05:24,368 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 5.0366
2020-11-05 19:05:24,376 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9827 | Iter Mean Loss 5.2731
2020-11-05 19:05:24,386 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7893 | Iter Mean Loss 4.9763
2020-11-05 19:05:24,388 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:24,401 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0969 | Iter Mean Loss 6.0969
2020-11-05 19:05:24,414 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1128 | Iter Mean Loss 4.1048
2020-11-05 19:05:24,424 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8734 | Iter Mean Loss 5.0277
2020-11-05 19:05:24,435 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9704 | Iter Mean Loss 5.2634
2020-11-05 19:05:24,447 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7794 | Iter Mean Loss 4.9666
2020-11-05 19:05:24,450 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:24,462 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0903 | Iter Mean Loss 6.0903
2020-11-05 19:05:24,474 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1062 | Iter Mean Loss 4.0982
2020-11-05 19:05:24,483 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8600 | Iter Mean Loss 5.0188
2020-11-05 19:05:24,495 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9582 | Iter Mean Loss 5.2537
2020-11-05 19:05:24,503 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7695 | Iter Mean Loss 4.9568
2020-11-05 19:05:24,506 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:24,516 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0838 | Iter Mean Loss 6.0838
2020-11-05 19:05:24,524 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0995 | Iter Mean Loss 4.0916
2020-11-05 19:05:24,533 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 5.0100
2020-11-05 19:05:24,541 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9459 | Iter Mean Loss 5.2440
2020-11-05 19:05:24,550 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7595 | Iter Mean Loss 4.9471
2020-11-05 19:05:24,552 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:24,563 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0773 | Iter Mean Loss 6.0773
2020-11-05 19:05:24,575 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0928 | Iter Mean Loss 4.0850
2020-11-05 19:05:24,585 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8332 | Iter Mean Loss 5.0011
2020-11-05 19:05:24,594 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9337 | Iter Mean Loss 5.2342
2020-11-05 19:05:24,603 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7495 | Iter Mean Loss 4.9373
2020-11-05 19:05:24,606 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:24,617 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0708 | Iter Mean Loss 6.0708
2020-11-05 19:05:24,625 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0860 | Iter Mean Loss 4.0784
2020-11-05 19:05:24,635 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8198 | Iter Mean Loss 4.9922
2020-11-05 19:05:24,650 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9215 | Iter Mean Loss 5.2245
2020-11-05 19:05:24,665 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7396 | Iter Mean Loss 4.9275
2020-11-05 19:05:24,668 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:24,684 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0643 | Iter Mean Loss 6.0643
2020-11-05 19:05:24,700 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0793 | Iter Mean Loss 4.0718
2020-11-05 19:05:24,713 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8064 | Iter Mean Loss 4.9834
2020-11-05 19:05:24,727 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9092 | Iter Mean Loss 5.2148
2020-11-05 19:05:24,738 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7296 | Iter Mean Loss 4.9178
2020-11-05 19:05:24,741 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:24,752 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0579 | Iter Mean Loss 6.0579
2020-11-05 19:05:24,761 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0725 | Iter Mean Loss 4.0652
2020-11-05 19:05:24,777 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7931 | Iter Mean Loss 4.9745
2020-11-05 19:05:24,787 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8970 | Iter Mean Loss 5.2051
2020-11-05 19:05:24,797 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7197 | Iter Mean Loss 4.9080
2020-11-05 19:05:24,801 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:24,811 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0514 | Iter Mean Loss 6.0514
2020-11-05 19:05:24,820 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0657 | Iter Mean Loss 4.0586
2020-11-05 19:05:24,829 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7797 | Iter Mean Loss 4.9656
2020-11-05 19:05:24,839 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8847 | Iter Mean Loss 5.1954
2020-11-05 19:05:24,847 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7097 | Iter Mean Loss 4.8983
2020-11-05 19:05:24,851 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:24,861 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0450 | Iter Mean Loss 6.0450
2020-11-05 19:05:24,870 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0589 | Iter Mean Loss 4.0520
2020-11-05 19:05:24,879 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7664 | Iter Mean Loss 4.9568
2020-11-05 19:05:24,889 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8725 | Iter Mean Loss 5.1857
2020-11-05 19:05:24,898 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6998 | Iter Mean Loss 4.8885
2020-11-05 19:05:24,902 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:24,911 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0386 | Iter Mean Loss 6.0386
2020-11-05 19:05:24,921 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0521 | Iter Mean Loss 4.0454
2020-11-05 19:05:24,930 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7530 | Iter Mean Loss 4.9479
2020-11-05 19:05:24,940 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8603 | Iter Mean Loss 5.1760
2020-11-05 19:05:24,948 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6898 | Iter Mean Loss 4.8788
2020-11-05 19:05:24,951 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:24,960 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0322 | Iter Mean Loss 6.0322
2020-11-05 19:05:24,969 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0453 | Iter Mean Loss 4.0388
2020-11-05 19:05:24,978 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7397 | Iter Mean Loss 4.9391
2020-11-05 19:05:24,987 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8481 | Iter Mean Loss 5.1663
2020-11-05 19:05:24,995 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6799 | Iter Mean Loss 4.8690
2020-11-05 19:05:24,998 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:25,008 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0259 | Iter Mean Loss 6.0259
2020-11-05 19:05:25,016 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0385 | Iter Mean Loss 4.0322
2020-11-05 19:05:25,024 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7264 | Iter Mean Loss 4.9303
2020-11-05 19:05:25,032 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.1567
2020-11-05 19:05:25,040 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6699 | Iter Mean Loss 4.8593
2020-11-05 19:05:25,042 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:25,051 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0195 | Iter Mean Loss 6.0195
2020-11-05 19:05:25,059 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0317 | Iter Mean Loss 4.0256
2020-11-05 19:05:25,067 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7131 | Iter Mean Loss 4.9214
2020-11-05 19:05:25,075 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8237 | Iter Mean Loss 5.1470
2020-11-05 19:05:25,083 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6600 | Iter Mean Loss 4.8496
2020-11-05 19:05:25,085 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,093 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0132 | Iter Mean Loss 6.0132
2020-11-05 19:05:25,100 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0249 | Iter Mean Loss 4.0191
2020-11-05 19:05:25,107 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6998 | Iter Mean Loss 4.9126
2020-11-05 19:05:25,114 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8115 | Iter Mean Loss 5.1373
2020-11-05 19:05:25,122 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6501 | Iter Mean Loss 4.8399
2020-11-05 19:05:25,124 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,132 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0069 | Iter Mean Loss 6.0069
2020-11-05 19:05:25,139 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0181 | Iter Mean Loss 4.0125
2020-11-05 19:05:25,148 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6865 | Iter Mean Loss 4.9038
2020-11-05 19:05:25,155 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7993 | Iter Mean Loss 5.1277
2020-11-05 19:05:25,162 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6401 | Iter Mean Loss 4.8302
2020-11-05 19:05:25,164 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,173 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0007 | Iter Mean Loss 6.0007
2020-11-05 19:05:25,181 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0112 | Iter Mean Loss 4.0059
2020-11-05 19:05:25,188 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6733 | Iter Mean Loss 4.8950
2020-11-05 19:05:25,195 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7872 | Iter Mean Loss 5.1181
2020-11-05 19:05:25,203 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6302 | Iter Mean Loss 4.8205
2020-11-05 19:05:25,205 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,212 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9944 | Iter Mean Loss 5.9944
2020-11-05 19:05:25,220 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0044 | Iter Mean Loss 3.9994
2020-11-05 19:05:25,227 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 4.8863
2020-11-05 19:05:25,235 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7751 | Iter Mean Loss 5.1085
2020-11-05 19:05:25,243 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6204 | Iter Mean Loss 4.8109
2020-11-05 19:05:25,245 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,254 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9882 | Iter Mean Loss 5.9882
2020-11-05 19:05:25,263 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9976 | Iter Mean Loss 3.9929
2020-11-05 19:05:25,271 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6468 | Iter Mean Loss 4.8775
2020-11-05 19:05:25,279 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7629 | Iter Mean Loss 5.0989
2020-11-05 19:05:25,287 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6105 | Iter Mean Loss 4.8012
2020-11-05 19:05:25,289 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,297 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9820 | Iter Mean Loss 5.9820
2020-11-05 19:05:25,305 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9908 | Iter Mean Loss 3.9864
2020-11-05 19:05:25,322 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6337 | Iter Mean Loss 4.8688
2020-11-05 19:05:25,333 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7509 | Iter Mean Loss 5.0893
2020-11-05 19:05:25,345 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6006 | Iter Mean Loss 4.7916
2020-11-05 19:05:25,348 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,360 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9758 | Iter Mean Loss 5.9758
2020-11-05 19:05:25,372 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9840 | Iter Mean Loss 3.9799
2020-11-05 19:05:25,382 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6205 | Iter Mean Loss 4.8601
2020-11-05 19:05:25,393 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7388 | Iter Mean Loss 5.0798
2020-11-05 19:05:25,403 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5908 | Iter Mean Loss 4.7820
2020-11-05 19:05:25,406 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:25,415 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9696 | Iter Mean Loss 5.9696
2020-11-05 19:05:25,426 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9772 | Iter Mean Loss 3.9734
2020-11-05 19:05:25,436 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6074 | Iter Mean Loss 4.8514
2020-11-05 19:05:25,445 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7268 | Iter Mean Loss 5.0702
2020-11-05 19:05:25,455 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5810 | Iter Mean Loss 4.7724
2020-11-05 19:05:25,458 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,468 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9635 | Iter Mean Loss 5.9635
2020-11-05 19:05:25,478 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9704 | Iter Mean Loss 3.9670
2020-11-05 19:05:25,487 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5943 | Iter Mean Loss 4.8427
2020-11-05 19:05:25,496 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7148 | Iter Mean Loss 5.0607
2020-11-05 19:05:25,507 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5712 | Iter Mean Loss 4.7628
2020-11-05 19:05:25,509 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,519 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9574 | Iter Mean Loss 5.9574
2020-11-05 19:05:25,529 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9637 | Iter Mean Loss 3.9605
2020-11-05 19:05:25,539 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5813 | Iter Mean Loss 4.8341
2020-11-05 19:05:25,547 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7028 | Iter Mean Loss 5.0513
2020-11-05 19:05:25,557 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5615 | Iter Mean Loss 4.7533
2020-11-05 19:05:25,560 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,575 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9513 | Iter Mean Loss 5.9513
2020-11-05 19:05:25,586 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9569 | Iter Mean Loss 3.9541
2020-11-05 19:05:25,601 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5683 | Iter Mean Loss 4.8255
2020-11-05 19:05:25,614 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6908 | Iter Mean Loss 5.0418
2020-11-05 19:05:25,628 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5517 | Iter Mean Loss 4.7438
2020-11-05 19:05:25,631 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,644 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9453 | Iter Mean Loss 5.9453
2020-11-05 19:05:25,655 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9502 | Iter Mean Loss 3.9477
2020-11-05 19:05:25,664 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5553 | Iter Mean Loss 4.8169
2020-11-05 19:05:25,674 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6789 | Iter Mean Loss 5.0324
2020-11-05 19:05:25,683 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5420 | Iter Mean Loss 4.7343
2020-11-05 19:05:25,687 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,697 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9393 | Iter Mean Loss 5.9393
2020-11-05 19:05:25,707 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9435 | Iter Mean Loss 3.9414
2020-11-05 19:05:25,715 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5423 | Iter Mean Loss 4.8084
2020-11-05 19:05:25,725 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6670 | Iter Mean Loss 5.0230
2020-11-05 19:05:25,734 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5323 | Iter Mean Loss 4.7249
2020-11-05 19:05:25,738 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,747 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9333 | Iter Mean Loss 5.9333
2020-11-05 19:05:25,756 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9368 | Iter Mean Loss 3.9350
2020-11-05 19:05:25,765 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5294 | Iter Mean Loss 4.7998
2020-11-05 19:05:25,775 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6552 | Iter Mean Loss 5.0137
2020-11-05 19:05:25,786 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5227 | Iter Mean Loss 4.7155
2020-11-05 19:05:25,790 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,799 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9273 | Iter Mean Loss 5.9273
2020-11-05 19:05:25,809 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9301 | Iter Mean Loss 3.9287
2020-11-05 19:05:25,817 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5166 | Iter Mean Loss 4.7913
2020-11-05 19:05:25,827 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6434 | Iter Mean Loss 5.0043
2020-11-05 19:05:25,836 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5131 | Iter Mean Loss 4.7061
2020-11-05 19:05:25,839 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,852 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9214 | Iter Mean Loss 5.9214
2020-11-05 19:05:25,868 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9235 | Iter Mean Loss 3.9224
2020-11-05 19:05:25,882 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5038 | Iter Mean Loss 4.7829
2020-11-05 19:05:25,894 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6316 | Iter Mean Loss 4.9951
2020-11-05 19:05:25,910 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 4.6967
2020-11-05 19:05:25,914 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,929 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9154 | Iter Mean Loss 5.9154
2020-11-05 19:05:25,941 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9169 | Iter Mean Loss 3.9162
2020-11-05 19:05:25,954 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4910 | Iter Mean Loss 4.7745
2020-11-05 19:05:25,966 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6199 | Iter Mean Loss 4.9858
2020-11-05 19:05:25,977 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4939 | Iter Mean Loss 4.6874
2020-11-05 19:05:25,980 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:25,992 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9096 | Iter Mean Loss 5.9096
2020-11-05 19:05:26,001 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9103 | Iter Mean Loss 3.9100
2020-11-05 19:05:26,012 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4783 | Iter Mean Loss 4.7661
2020-11-05 19:05:26,022 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 4.9766
2020-11-05 19:05:26,032 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4844 | Iter Mean Loss 4.6782
2020-11-05 19:05:26,034 - root - INFO - Evaluate: Epoch 0647 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,046 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9037 | Iter Mean Loss 5.9037
2020-11-05 19:05:26,056 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9038 | Iter Mean Loss 3.9038
2020-11-05 19:05:26,067 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4656 | Iter Mean Loss 4.7577
2020-11-05 19:05:26,078 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5966 | Iter Mean Loss 4.9674
2020-11-05 19:05:26,089 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4749 | Iter Mean Loss 4.6689
2020-11-05 19:05:26,094 - root - INFO - Evaluate: Epoch 0648 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,104 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8979 | Iter Mean Loss 5.8979
2020-11-05 19:05:26,115 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8973 | Iter Mean Loss 3.8976
2020-11-05 19:05:26,123 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4530 | Iter Mean Loss 4.7494
2020-11-05 19:05:26,133 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5850 | Iter Mean Loss 4.9583
2020-11-05 19:05:26,143 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4655 | Iter Mean Loss 4.6597
2020-11-05 19:05:26,145 - root - INFO - Evaluate: Epoch 0649 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,163 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8921 | Iter Mean Loss 5.8921
2020-11-05 19:05:26,179 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8908 | Iter Mean Loss 3.8915
2020-11-05 19:05:26,195 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4404 | Iter Mean Loss 4.7411
2020-11-05 19:05:26,209 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5734 | Iter Mean Loss 4.9492
2020-11-05 19:05:26,222 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4561 | Iter Mean Loss 4.6506
2020-11-05 19:05:26,226 - root - INFO - Evaluate: Epoch 0650 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,242 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8864 | Iter Mean Loss 5.8864
2020-11-05 19:05:26,253 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8844 | Iter Mean Loss 3.8854
2020-11-05 19:05:26,263 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4279 | Iter Mean Loss 4.7329
2020-11-05 19:05:26,274 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5619 | Iter Mean Loss 4.9402
2020-11-05 19:05:26,283 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4468 | Iter Mean Loss 4.6415
2020-11-05 19:05:26,288 - root - INFO - Evaluate: Epoch 0651 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,297 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8806 | Iter Mean Loss 5.8806
2020-11-05 19:05:26,308 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8780 | Iter Mean Loss 3.8793
2020-11-05 19:05:26,317 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4154 | Iter Mean Loss 4.7247
2020-11-05 19:05:26,328 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5505 | Iter Mean Loss 4.9311
2020-11-05 19:05:26,336 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4375 | Iter Mean Loss 4.6324
2020-11-05 19:05:26,340 - root - INFO - Evaluate: Epoch 0652 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,349 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8749 | Iter Mean Loss 5.8749
2020-11-05 19:05:26,359 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8717 | Iter Mean Loss 3.8733
2020-11-05 19:05:26,368 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4030 | Iter Mean Loss 4.7165
2020-11-05 19:05:26,378 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5391 | Iter Mean Loss 4.9222
2020-11-05 19:05:26,388 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4282 | Iter Mean Loss 4.6234
2020-11-05 19:05:26,391 - root - INFO - Evaluate: Epoch 0653 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,401 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8693 | Iter Mean Loss 5.8693
2020-11-05 19:05:26,412 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8654 | Iter Mean Loss 3.8673
2020-11-05 19:05:26,430 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3907 | Iter Mean Loss 4.7084
2020-11-05 19:05:26,448 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5278 | Iter Mean Loss 4.9133
2020-11-05 19:05:26,464 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4190 | Iter Mean Loss 4.6144
2020-11-05 19:05:26,467 - root - INFO - Evaluate: Epoch 0654 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,487 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8636 | Iter Mean Loss 5.8636
2020-11-05 19:05:26,506 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8591 | Iter Mean Loss 3.8614
2020-11-05 19:05:26,526 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3784 | Iter Mean Loss 4.7004
2020-11-05 19:05:26,545 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5165 | Iter Mean Loss 4.9044
2020-11-05 19:05:26,560 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4099 | Iter Mean Loss 4.6055
2020-11-05 19:05:26,563 - root - INFO - Evaluate: Epoch 0655 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,576 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 5.8580
2020-11-05 19:05:26,585 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 3.8555
2020-11-05 19:05:26,597 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 4.6924
2020-11-05 19:05:26,608 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5053 | Iter Mean Loss 4.8956
2020-11-05 19:05:26,620 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4008 | Iter Mean Loss 4.5966
2020-11-05 19:05:26,626 - root - INFO - Evaluate: Epoch 0656 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,640 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8525 | Iter Mean Loss 5.8525
2020-11-05 19:05:26,652 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8467 | Iter Mean Loss 3.8496
2020-11-05 19:05:26,665 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3540 | Iter Mean Loss 4.6844
2020-11-05 19:05:26,678 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4941 | Iter Mean Loss 4.8868
2020-11-05 19:05:26,691 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 4.5878
2020-11-05 19:05:26,694 - root - INFO - Evaluate: Epoch 0657 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,707 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 5.8469
2020-11-05 19:05:26,718 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8406 | Iter Mean Loss 3.8438
2020-11-05 19:05:26,730 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3419 | Iter Mean Loss 4.6765
2020-11-05 19:05:26,740 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4830 | Iter Mean Loss 4.8781
2020-11-05 19:05:26,749 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3827 | Iter Mean Loss 4.5790
2020-11-05 19:05:26,751 - root - INFO - Evaluate: Epoch 0658 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,762 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8414 | Iter Mean Loss 5.8414
2020-11-05 19:05:26,770 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8346 | Iter Mean Loss 3.8380
2020-11-05 19:05:26,780 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3298 | Iter Mean Loss 4.6686
2020-11-05 19:05:26,790 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4719 | Iter Mean Loss 4.8694
2020-11-05 19:05:26,798 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3737 | Iter Mean Loss 4.5703
2020-11-05 19:05:26,800 - root - INFO - Evaluate: Epoch 0659 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,810 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.8359
2020-11-05 19:05:26,818 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8285 | Iter Mean Loss 3.8322
2020-11-05 19:05:26,825 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3179 | Iter Mean Loss 4.6608
2020-11-05 19:05:26,832 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4610 | Iter Mean Loss 4.8608
2020-11-05 19:05:26,840 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 4.5616
2020-11-05 19:05:26,842 - root - INFO - Evaluate: Epoch 0660 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,851 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8305 | Iter Mean Loss 5.8305
2020-11-05 19:05:26,859 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8226 | Iter Mean Loss 3.8265
2020-11-05 19:05:26,867 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3060 | Iter Mean Loss 4.6530
2020-11-05 19:05:26,874 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4500 | Iter Mean Loss 4.8523
2020-11-05 19:05:26,883 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3560 | Iter Mean Loss 4.5530
2020-11-05 19:05:26,885 - root - INFO - Evaluate: Epoch 0661 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,893 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8251 | Iter Mean Loss 5.8251
2020-11-05 19:05:26,902 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8167 | Iter Mean Loss 3.8209
2020-11-05 19:05:26,910 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 4.6453
2020-11-05 19:05:26,918 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4392 | Iter Mean Loss 4.8438
2020-11-05 19:05:26,927 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3472 | Iter Mean Loss 4.5444
2020-11-05 19:05:26,929 - root - INFO - Evaluate: Epoch 0662 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,937 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8197 | Iter Mean Loss 5.8197
2020-11-05 19:05:26,945 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8108 | Iter Mean Loss 3.8153
2020-11-05 19:05:26,952 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2823 | Iter Mean Loss 4.6376
2020-11-05 19:05:26,961 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4284 | Iter Mean Loss 4.8353
2020-11-05 19:05:26,970 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3385 | Iter Mean Loss 4.5359
2020-11-05 19:05:26,972 - root - INFO - Evaluate: Epoch 0663 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:26,980 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8144 | Iter Mean Loss 5.8144
2020-11-05 19:05:26,987 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8050 | Iter Mean Loss 3.8097
2020-11-05 19:05:26,995 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 4.6300
2020-11-05 19:05:27,002 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4176 | Iter Mean Loss 4.8269
2020-11-05 19:05:27,009 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 4.5275
2020-11-05 19:05:27,011 - root - INFO - Evaluate: Epoch 0664 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,019 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8090 | Iter Mean Loss 5.8090
2020-11-05 19:05:27,026 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7993 | Iter Mean Loss 3.8042
2020-11-05 19:05:27,033 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2590 | Iter Mean Loss 4.6224
2020-11-05 19:05:27,041 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4070 | Iter Mean Loss 4.8186
2020-11-05 19:05:27,049 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3212 | Iter Mean Loss 4.5191
2020-11-05 19:05:27,051 - root - INFO - Evaluate: Epoch 0665 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,061 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8038 | Iter Mean Loss 5.8038
2020-11-05 19:05:27,069 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7936 | Iter Mean Loss 3.7987
2020-11-05 19:05:27,076 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2474 | Iter Mean Loss 4.6149
2020-11-05 19:05:27,084 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3964 | Iter Mean Loss 4.8103
2020-11-05 19:05:27,093 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3126 | Iter Mean Loss 4.5107
2020-11-05 19:05:27,095 - root - INFO - Evaluate: Epoch 0666 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,103 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7985 | Iter Mean Loss 5.7985
2020-11-05 19:05:27,111 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7880 | Iter Mean Loss 3.7932
2020-11-05 19:05:27,122 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2359 | Iter Mean Loss 4.6074
2020-11-05 19:05:27,130 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3858 | Iter Mean Loss 4.8020
2020-11-05 19:05:27,138 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3041 | Iter Mean Loss 4.5025
2020-11-05 19:05:27,140 - root - INFO - Evaluate: Epoch 0667 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,150 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7933 | Iter Mean Loss 5.7933
2020-11-05 19:05:27,159 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7824 | Iter Mean Loss 3.7878
2020-11-05 19:05:27,166 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2244 | Iter Mean Loss 4.6000
2020-11-05 19:05:27,174 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 4.7939
2020-11-05 19:05:27,182 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2957 | Iter Mean Loss 4.4942
2020-11-05 19:05:27,184 - root - INFO - Evaluate: Epoch 0668 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,192 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7881 | Iter Mean Loss 5.7881
2020-11-05 19:05:27,200 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7769 | Iter Mean Loss 3.7825
2020-11-05 19:05:27,208 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 4.5927
2020-11-05 19:05:27,215 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3649 | Iter Mean Loss 4.7857
2020-11-05 19:05:27,223 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2873 | Iter Mean Loss 4.4861
2020-11-05 19:05:27,225 - root - INFO - Evaluate: Epoch 0669 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,233 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7829 | Iter Mean Loss 5.7829
2020-11-05 19:05:27,241 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7714 | Iter Mean Loss 3.7772
2020-11-05 19:05:27,249 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2018 | Iter Mean Loss 4.5854
2020-11-05 19:05:27,257 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3546 | Iter Mean Loss 4.7777
2020-11-05 19:05:27,265 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2790 | Iter Mean Loss 4.4779
2020-11-05 19:05:27,267 - root - INFO - Evaluate: Epoch 0670 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,276 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7778 | Iter Mean Loss 5.7778
2020-11-05 19:05:27,284 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7660 | Iter Mean Loss 3.7719
2020-11-05 19:05:27,292 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1905 | Iter Mean Loss 4.5781
2020-11-05 19:05:27,300 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3443 | Iter Mean Loss 4.7697
2020-11-05 19:05:27,309 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2708 | Iter Mean Loss 4.4699
2020-11-05 19:05:27,311 - root - INFO - Evaluate: Epoch 0671 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,320 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7727 | Iter Mean Loss 5.7727
2020-11-05 19:05:27,329 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7607 | Iter Mean Loss 3.7667
2020-11-05 19:05:27,337 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1794 | Iter Mean Loss 4.5709
2020-11-05 19:05:27,345 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3341 | Iter Mean Loss 4.7617
2020-11-05 19:05:27,353 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2626 | Iter Mean Loss 4.4619
2020-11-05 19:05:27,355 - root - INFO - Evaluate: Epoch 0672 | NDCG 0.2817 | MSE 0.3179
2020-11-05 19:05:27,363 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7677 | Iter Mean Loss 5.7677
2020-11-05 19:05:27,370 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7554 | Iter Mean Loss 3.7615
2020-11-05 19:05:27,378 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1683 | Iter Mean Loss 4.5638
2020-11-05 19:05:27,385 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3240 | Iter Mean Loss 4.7538
2020-11-05 19:05:27,393 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2544 | Iter Mean Loss 4.4540
2020-11-05 19:05:27,395 - root - INFO - Evaluate: Epoch 0673 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,403 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7626 | Iter Mean Loss 5.7626
2020-11-05 19:05:27,411 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7502 | Iter Mean Loss 3.7564
2020-11-05 19:05:27,418 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1573 | Iter Mean Loss 4.5567
2020-11-05 19:05:27,425 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3139 | Iter Mean Loss 4.7460
2020-11-05 19:05:27,433 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2464 | Iter Mean Loss 4.4461
2020-11-05 19:05:27,435 - root - INFO - Evaluate: Epoch 0674 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,443 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7576 | Iter Mean Loss 5.7576
2020-11-05 19:05:27,451 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7450 | Iter Mean Loss 3.7513
2020-11-05 19:05:27,458 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1463 | Iter Mean Loss 4.5497
2020-11-05 19:05:27,466 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3039 | Iter Mean Loss 4.7382
2020-11-05 19:05:27,474 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2384 | Iter Mean Loss 4.4382
2020-11-05 19:05:27,476 - root - INFO - Evaluate: Epoch 0675 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,485 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7527 | Iter Mean Loss 5.7527
2020-11-05 19:05:27,493 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7399 | Iter Mean Loss 3.7463
2020-11-05 19:05:27,500 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1354 | Iter Mean Loss 4.5427
2020-11-05 19:05:27,508 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2940 | Iter Mean Loss 4.7305
2020-11-05 19:05:27,515 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2304 | Iter Mean Loss 4.4305
2020-11-05 19:05:27,518 - root - INFO - Evaluate: Epoch 0676 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,527 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7477 | Iter Mean Loss 5.7477
2020-11-05 19:05:27,536 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7349 | Iter Mean Loss 3.7413
2020-11-05 19:05:27,546 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1246 | Iter Mean Loss 4.5358
2020-11-05 19:05:27,555 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2841 | Iter Mean Loss 4.7228
2020-11-05 19:05:27,562 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 4.4228
2020-11-05 19:05:27,564 - root - INFO - Evaluate: Epoch 0677 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,572 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7428 | Iter Mean Loss 5.7428
2020-11-05 19:05:27,580 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7299 | Iter Mean Loss 3.7364
2020-11-05 19:05:27,587 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1139 | Iter Mean Loss 4.5289
2020-11-05 19:05:27,594 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2743 | Iter Mean Loss 4.7152
2020-11-05 19:05:27,602 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2147 | Iter Mean Loss 4.4151
2020-11-05 19:05:27,604 - root - INFO - Evaluate: Epoch 0678 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,612 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7379 | Iter Mean Loss 5.7379
2020-11-05 19:05:27,619 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7250 | Iter Mean Loss 3.7315
2020-11-05 19:05:27,626 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1032 | Iter Mean Loss 4.5221
2020-11-05 19:05:27,634 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2646 | Iter Mean Loss 4.7077
2020-11-05 19:05:27,641 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 4.4075
2020-11-05 19:05:27,643 - root - INFO - Evaluate: Epoch 0679 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,652 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7331 | Iter Mean Loss 5.7331
2020-11-05 19:05:27,660 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7201 | Iter Mean Loss 3.7266
2020-11-05 19:05:27,667 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0926 | Iter Mean Loss 4.5153
2020-11-05 19:05:27,675 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2549 | Iter Mean Loss 4.7002
2020-11-05 19:05:27,682 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1992 | Iter Mean Loss 4.4000
2020-11-05 19:05:27,684 - root - INFO - Evaluate: Epoch 0680 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,692 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7283 | Iter Mean Loss 5.7283
2020-11-05 19:05:27,701 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7153 | Iter Mean Loss 3.7218
2020-11-05 19:05:27,708 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0821 | Iter Mean Loss 4.5086
2020-11-05 19:05:27,718 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.6928
2020-11-05 19:05:27,726 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1916 | Iter Mean Loss 4.3925
2020-11-05 19:05:27,728 - root - INFO - Evaluate: Epoch 0681 | NDCG 0.2817 | MSE 0.3180
2020-11-05 19:05:27,738 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7235 | Iter Mean Loss 5.7235
2020-11-05 19:05:27,746 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7106 | Iter Mean Loss 3.7170
2020-11-05 19:05:27,754 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0717 | Iter Mean Loss 4.5019
2020-11-05 19:05:27,762 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2358 | Iter Mean Loss 4.6854
2020-11-05 19:05:27,769 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1840 | Iter Mean Loss 4.3851
2020-11-05 19:05:27,771 - root - INFO - Evaluate: Epoch 0682 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,780 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7187 | Iter Mean Loss 5.7187
2020-11-05 19:05:27,787 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7059 | Iter Mean Loss 3.7123
2020-11-05 19:05:27,795 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0613 | Iter Mean Loss 4.4953
2020-11-05 19:05:27,802 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2263 | Iter Mean Loss 4.6781
2020-11-05 19:05:27,809 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1765 | Iter Mean Loss 4.3778
2020-11-05 19:05:27,811 - root - INFO - Evaluate: Epoch 0683 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,820 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7140 | Iter Mean Loss 5.7140
2020-11-05 19:05:27,827 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7013 | Iter Mean Loss 3.7077
2020-11-05 19:05:27,835 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0510 | Iter Mean Loss 4.4888
2020-11-05 19:05:27,842 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2169 | Iter Mean Loss 4.6708
2020-11-05 19:05:27,849 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1690 | Iter Mean Loss 4.3705
2020-11-05 19:05:27,851 - root - INFO - Evaluate: Epoch 0684 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,859 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7093 | Iter Mean Loss 5.7093
2020-11-05 19:05:27,867 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6968 | Iter Mean Loss 3.7030
2020-11-05 19:05:27,874 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0407 | Iter Mean Loss 4.4823
2020-11-05 19:05:27,882 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2076 | Iter Mean Loss 4.6636
2020-11-05 19:05:27,890 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1616 | Iter Mean Loss 4.3632
2020-11-05 19:05:27,892 - root - INFO - Evaluate: Epoch 0685 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,901 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7046 | Iter Mean Loss 5.7046
2020-11-05 19:05:27,909 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6923 | Iter Mean Loss 3.6984
2020-11-05 19:05:27,916 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0305 | Iter Mean Loss 4.4758
2020-11-05 19:05:27,923 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1984 | Iter Mean Loss 4.6564
2020-11-05 19:05:27,931 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1543 | Iter Mean Loss 4.3560
2020-11-05 19:05:27,934 - root - INFO - Evaluate: Epoch 0686 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,942 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7000 | Iter Mean Loss 5.7000
2020-11-05 19:05:27,950 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6878 | Iter Mean Loss 3.6939
2020-11-05 19:05:27,959 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0204 | Iter Mean Loss 4.4694
2020-11-05 19:05:27,967 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1891 | Iter Mean Loss 4.6493
2020-11-05 19:05:27,975 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1470 | Iter Mean Loss 4.3489
2020-11-05 19:05:27,977 - root - INFO - Evaluate: Epoch 0687 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:27,985 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6953 | Iter Mean Loss 5.6953
2020-11-05 19:05:27,992 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6834 | Iter Mean Loss 3.6894
2020-11-05 19:05:28,000 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0104 | Iter Mean Loss 4.4630
2020-11-05 19:05:28,007 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1800 | Iter Mean Loss 4.6423
2020-11-05 19:05:28,015 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1398 | Iter Mean Loss 4.3418
2020-11-05 19:05:28,017 - root - INFO - Evaluate: Epoch 0688 | NDCG 0.2817 | MSE 0.3181
2020-11-05 19:05:28,025 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6907 | Iter Mean Loss 5.6907
2020-11-05 19:05:28,033 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6791 | Iter Mean Loss 3.6849
2020-11-05 19:05:28,041 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0004 | Iter Mean Loss 4.4567
2020-11-05 19:05:28,048 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1709 | Iter Mean Loss 4.6353
2020-11-05 19:05:28,056 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1326 | Iter Mean Loss 4.3348
2020-11-05 19:05:28,058 - root - INFO - Evaluate: Epoch 0689 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,065 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6862 | Iter Mean Loss 5.6862
2020-11-05 19:05:28,073 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6748 | Iter Mean Loss 3.6805
2020-11-05 19:05:28,080 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9905 | Iter Mean Loss 4.4505
2020-11-05 19:05:28,088 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1619 | Iter Mean Loss 4.6283
2020-11-05 19:05:28,096 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1255 | Iter Mean Loss 4.3278
2020-11-05 19:05:28,098 - root - INFO - Evaluate: Epoch 0690 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,106 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6816 | Iter Mean Loss 5.6816
2020-11-05 19:05:28,113 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6706 | Iter Mean Loss 3.6761
2020-11-05 19:05:28,122 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9806 | Iter Mean Loss 4.4443
2020-11-05 19:05:28,129 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1530 | Iter Mean Loss 4.6215
2020-11-05 19:05:28,137 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1185 | Iter Mean Loss 4.3209
2020-11-05 19:05:28,140 - root - INFO - Evaluate: Epoch 0691 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,148 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6771 | Iter Mean Loss 5.6771
2020-11-05 19:05:28,156 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6664 | Iter Mean Loss 3.6718
2020-11-05 19:05:28,164 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9708 | Iter Mean Loss 4.4381
2020-11-05 19:05:28,171 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1441 | Iter Mean Loss 4.6146
2020-11-05 19:05:28,179 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1115 | Iter Mean Loss 4.3140
2020-11-05 19:05:28,182 - root - INFO - Evaluate: Epoch 0692 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,192 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6726 | Iter Mean Loss 5.6726
2020-11-05 19:05:28,200 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6623 | Iter Mean Loss 3.6675
2020-11-05 19:05:28,207 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9611 | Iter Mean Loss 4.4320
2020-11-05 19:05:28,214 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1352 | Iter Mean Loss 4.6078
2020-11-05 19:05:28,221 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1046 | Iter Mean Loss 4.3072
2020-11-05 19:05:28,223 - root - INFO - Evaluate: Epoch 0693 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,231 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6682 | Iter Mean Loss 5.6682
2020-11-05 19:05:28,239 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6583 | Iter Mean Loss 3.6632
2020-11-05 19:05:28,246 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 4.4260
2020-11-05 19:05:28,253 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1265 | Iter Mean Loss 4.6011
2020-11-05 19:05:28,260 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0977 | Iter Mean Loss 4.3004
2020-11-05 19:05:28,262 - root - INFO - Evaluate: Epoch 0694 | NDCG 0.2817 | MSE 0.3182
2020-11-05 19:05:28,271 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6637 | Iter Mean Loss 5.6637
2020-11-05 19:05:28,279 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 3.6590
2020-11-05 19:05:28,287 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9418 | Iter Mean Loss 4.4199
2020-11-05 19:05:28,295 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1178 | Iter Mean Loss 4.5944
2020-11-05 19:05:28,304 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0909 | Iter Mean Loss 4.2937
2020-11-05 19:05:28,306 - root - INFO - Evaluate: Epoch 0695 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,315 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6593 | Iter Mean Loss 5.6593
2020-11-05 19:05:28,324 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6503 | Iter Mean Loss 3.6548
2020-11-05 19:05:28,332 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9323 | Iter Mean Loss 4.4140
2020-11-05 19:05:28,340 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1091 | Iter Mean Loss 4.5878
2020-11-05 19:05:28,348 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0841 | Iter Mean Loss 4.2870
2020-11-05 19:05:28,350 - root - INFO - Evaluate: Epoch 0696 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,359 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6549 | Iter Mean Loss 5.6549
2020-11-05 19:05:28,366 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6464 | Iter Mean Loss 3.6507
2020-11-05 19:05:28,374 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9228 | Iter Mean Loss 4.4081
2020-11-05 19:05:28,381 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1005 | Iter Mean Loss 4.5812
2020-11-05 19:05:28,388 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0774 | Iter Mean Loss 4.2804
2020-11-05 19:05:28,390 - root - INFO - Evaluate: Epoch 0697 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,398 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6506 | Iter Mean Loss 5.6506
2020-11-05 19:05:28,405 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6426 | Iter Mean Loss 3.6466
2020-11-05 19:05:28,413 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9134 | Iter Mean Loss 4.4022
2020-11-05 19:05:28,420 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0920 | Iter Mean Loss 4.5746
2020-11-05 19:05:28,427 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0707 | Iter Mean Loss 4.2738
2020-11-05 19:05:28,429 - root - INFO - Evaluate: Epoch 0698 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,437 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6462 | Iter Mean Loss 5.6462
2020-11-05 19:05:28,444 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6388 | Iter Mean Loss 3.6425
2020-11-05 19:05:28,451 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9040 | Iter Mean Loss 4.3963
2020-11-05 19:05:28,458 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0835 | Iter Mean Loss 4.5681
2020-11-05 19:05:28,466 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0641 | Iter Mean Loss 4.2673
2020-11-05 19:05:28,468 - root - INFO - Evaluate: Epoch 0699 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,475 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6419 | Iter Mean Loss 5.6419
2020-11-05 19:05:28,484 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6350 | Iter Mean Loss 3.6385
2020-11-05 19:05:28,491 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8947 | Iter Mean Loss 4.3906
2020-11-05 19:05:28,499 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0751 | Iter Mean Loss 4.5617
2020-11-05 19:05:28,507 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0576 | Iter Mean Loss 4.2609
2020-11-05 19:05:28,509 - root - INFO - Evaluate: Epoch 0700 | NDCG 0.2817 | MSE 0.3183
2020-11-05 19:05:28,518 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6376 | Iter Mean Loss 5.6376
2020-11-05 19:05:28,526 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6313 | Iter Mean Loss 3.6345
2020-11-05 19:05:28,534 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8855 | Iter Mean Loss 4.3848
2020-11-05 19:05:28,543 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0667 | Iter Mean Loss 4.5553
2020-11-05 19:05:28,551 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0511 | Iter Mean Loss 4.2544
2020-11-05 19:05:28,554 - root - INFO - Evaluate: Epoch 0701 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:28,563 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6334 | Iter Mean Loss 5.6334
2020-11-05 19:05:28,572 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6277 | Iter Mean Loss 3.6305
2020-11-05 19:05:28,580 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8763 | Iter Mean Loss 4.3791
2020-11-05 19:05:28,587 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0584 | Iter Mean Loss 4.5489
2020-11-05 19:05:28,596 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0446 | Iter Mean Loss 4.2481
2020-11-05 19:05:28,598 - root - INFO - Evaluate: Epoch 0702 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:28,606 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6291 | Iter Mean Loss 5.6291
2020-11-05 19:05:28,614 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6240 | Iter Mean Loss 3.6266
2020-11-05 19:05:28,622 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8671 | Iter Mean Loss 4.3734
2020-11-05 19:05:28,629 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0501 | Iter Mean Loss 4.5426
2020-11-05 19:05:28,637 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0382 | Iter Mean Loss 4.2417
2020-11-05 19:05:28,639 - root - INFO - Evaluate: Epoch 0703 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:28,649 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6249 | Iter Mean Loss 5.6249
2020-11-05 19:05:28,658 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6205 | Iter Mean Loss 3.6227
2020-11-05 19:05:28,666 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 4.3678
2020-11-05 19:05:28,673 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0419 | Iter Mean Loss 4.5363
2020-11-05 19:05:28,681 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0319 | Iter Mean Loss 4.2354
2020-11-05 19:05:28,683 - root - INFO - Evaluate: Epoch 0704 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:28,691 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6207 | Iter Mean Loss 5.6207
2020-11-05 19:05:28,699 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6170 | Iter Mean Loss 3.6188
2020-11-05 19:05:28,708 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8490 | Iter Mean Loss 4.3622
2020-11-05 19:05:28,716 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0337 | Iter Mean Loss 4.5301
2020-11-05 19:05:28,725 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0255 | Iter Mean Loss 4.2292
2020-11-05 19:05:28,727 - root - INFO - Evaluate: Epoch 0705 | NDCG 0.2817 | MSE 0.3184
2020-11-05 19:05:28,735 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6165 | Iter Mean Loss 5.6165
2020-11-05 19:05:28,743 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6135 | Iter Mean Loss 3.6150
2020-11-05 19:05:28,753 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8400 | Iter Mean Loss 4.3567
2020-11-05 19:05:28,761 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0256 | Iter Mean Loss 4.5239
2020-11-05 19:05:28,770 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0193 | Iter Mean Loss 4.2230
2020-11-05 19:05:28,772 - root - INFO - Evaluate: Epoch 0706 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:28,780 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6124 | Iter Mean Loss 5.6124
2020-11-05 19:05:28,788 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6101 | Iter Mean Loss 3.6112
2020-11-05 19:05:28,796 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8311 | Iter Mean Loss 4.3512
2020-11-05 19:05:28,804 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0176 | Iter Mean Loss 4.5178
2020-11-05 19:05:28,811 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0131 | Iter Mean Loss 4.2168
2020-11-05 19:05:28,813 - root - INFO - Evaluate: Epoch 0707 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:28,821 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 5.6082
2020-11-05 19:05:28,829 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6067 | Iter Mean Loss 3.6075
2020-11-05 19:05:28,836 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8222 | Iter Mean Loss 4.3457
2020-11-05 19:05:28,844 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0096 | Iter Mean Loss 4.5117
2020-11-05 19:05:28,852 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0069 | Iter Mean Loss 4.2107
2020-11-05 19:05:28,854 - root - INFO - Evaluate: Epoch 0708 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:28,862 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6041 | Iter Mean Loss 5.6041
2020-11-05 19:05:28,869 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6033 | Iter Mean Loss 3.6037
2020-11-05 19:05:28,876 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8134 | Iter Mean Loss 4.3403
2020-11-05 19:05:28,884 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0016 | Iter Mean Loss 4.5056
2020-11-05 19:05:28,892 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0008 | Iter Mean Loss 4.2047
2020-11-05 19:05:28,894 - root - INFO - Evaluate: Epoch 0709 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:28,903 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6000 | Iter Mean Loss 5.6000
2020-11-05 19:05:28,914 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6000 | Iter Mean Loss 3.6000
2020-11-05 19:05:28,924 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8047 | Iter Mean Loss 4.3349
2020-11-05 19:05:28,935 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9937 | Iter Mean Loss 4.4996
2020-11-05 19:05:28,946 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9947 | Iter Mean Loss 4.1986
2020-11-05 19:05:28,949 - root - INFO - Evaluate: Epoch 0710 | NDCG 0.2817 | MSE 0.3185
2020-11-05 19:05:28,959 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5959 | Iter Mean Loss 5.5959
2020-11-05 19:05:28,970 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5968 | Iter Mean Loss 3.5964
2020-11-05 19:05:28,981 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7959 | Iter Mean Loss 4.3295
2020-11-05 19:05:28,990 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9858 | Iter Mean Loss 4.4936
2020-11-05 19:05:29,001 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9887 | Iter Mean Loss 4.1926
2020-11-05 19:05:29,004 - root - INFO - Evaluate: Epoch 0711 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:29,015 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5919 | Iter Mean Loss 5.5919
2020-11-05 19:05:29,024 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5935 | Iter Mean Loss 3.5927
2020-11-05 19:05:29,034 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7873 | Iter Mean Loss 4.3242
2020-11-05 19:05:29,045 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9780 | Iter Mean Loss 4.4877
2020-11-05 19:05:29,055 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9827 | Iter Mean Loss 4.1867
2020-11-05 19:05:29,058 - root - INFO - Evaluate: Epoch 0712 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:29,068 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5879 | Iter Mean Loss 5.5879
2020-11-05 19:05:29,079 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5904 | Iter Mean Loss 3.5891
2020-11-05 19:05:29,089 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7786 | Iter Mean Loss 4.3189
2020-11-05 19:05:29,101 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9702 | Iter Mean Loss 4.4818
2020-11-05 19:05:29,111 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9768 | Iter Mean Loss 4.1808
2020-11-05 19:05:29,116 - root - INFO - Evaluate: Epoch 0713 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:29,126 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5838 | Iter Mean Loss 5.5838
2020-11-05 19:05:29,137 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 3.5855
2020-11-05 19:05:29,147 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7701 | Iter Mean Loss 4.3137
2020-11-05 19:05:29,157 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9625 | Iter Mean Loss 4.4759
2020-11-05 19:05:29,167 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9709 | Iter Mean Loss 4.1749
2020-11-05 19:05:29,169 - root - INFO - Evaluate: Epoch 0714 | NDCG 0.2817 | MSE 0.3186
2020-11-05 19:05:29,179 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5798 | Iter Mean Loss 5.5798
2020-11-05 19:05:29,190 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5841 | Iter Mean Loss 3.5820
2020-11-05 19:05:29,201 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7615 | Iter Mean Loss 4.3085
2020-11-05 19:05:29,210 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9548 | Iter Mean Loss 4.4701
2020-11-05 19:05:29,219 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9650 | Iter Mean Loss 4.1691
2020-11-05 19:05:29,221 - root - INFO - Evaluate: Epoch 0715 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:29,231 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5759 | Iter Mean Loss 5.5759
2020-11-05 19:05:29,241 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5810 | Iter Mean Loss 3.5784
2020-11-05 19:05:29,252 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7530 | Iter Mean Loss 4.3033
2020-11-05 19:05:29,261 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9472 | Iter Mean Loss 4.4643
2020-11-05 19:05:29,270 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9592 | Iter Mean Loss 4.1633
2020-11-05 19:05:29,273 - root - INFO - Evaluate: Epoch 0716 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:29,284 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5719 | Iter Mean Loss 5.5719
2020-11-05 19:05:29,293 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5780 | Iter Mean Loss 3.5749
2020-11-05 19:05:29,303 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7446 | Iter Mean Loss 4.2982
2020-11-05 19:05:29,311 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9396 | Iter Mean Loss 4.4585
2020-11-05 19:05:29,322 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 4.1575
2020-11-05 19:05:29,324 - root - INFO - Evaluate: Epoch 0717 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:29,333 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5680 | Iter Mean Loss 5.5680
2020-11-05 19:05:29,342 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5750 | Iter Mean Loss 3.5715
2020-11-05 19:05:29,352 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7362 | Iter Mean Loss 4.2931
2020-11-05 19:05:29,359 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9320 | Iter Mean Loss 4.4528
2020-11-05 19:05:29,367 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9477 | Iter Mean Loss 4.1518
2020-11-05 19:05:29,369 - root - INFO - Evaluate: Epoch 0718 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:29,378 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5640 | Iter Mean Loss 5.5640
2020-11-05 19:05:29,386 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5720 | Iter Mean Loss 3.5680
2020-11-05 19:05:29,395 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7278 | Iter Mean Loss 4.2880
2020-11-05 19:05:29,402 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9245 | Iter Mean Loss 4.4471
2020-11-05 19:05:29,409 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 4.1461
2020-11-05 19:05:29,411 - root - INFO - Evaluate: Epoch 0719 | NDCG 0.2817 | MSE 0.3187
2020-11-05 19:05:29,419 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5601 | Iter Mean Loss 5.5601
2020-11-05 19:05:29,427 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5691 | Iter Mean Loss 3.5646
2020-11-05 19:05:29,434 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7195 | Iter Mean Loss 4.2829
2020-11-05 19:05:29,441 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9170 | Iter Mean Loss 4.4414
2020-11-05 19:05:29,449 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 4.1404
2020-11-05 19:05:29,451 - root - INFO - Evaluate: Epoch 0720 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:29,459 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5562 | Iter Mean Loss 5.5562
2020-11-05 19:05:29,467 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5662 | Iter Mean Loss 3.5612
2020-11-05 19:05:29,474 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7113 | Iter Mean Loss 4.2779
2020-11-05 19:05:29,481 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9095 | Iter Mean Loss 4.4358
2020-11-05 19:05:29,488 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9307 | Iter Mean Loss 4.1348
2020-11-05 19:05:29,490 - root - INFO - Evaluate: Epoch 0721 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:29,498 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5524 | Iter Mean Loss 5.5524
2020-11-05 19:05:29,505 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 3.5578
2020-11-05 19:05:29,513 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7030 | Iter Mean Loss 4.2729
2020-11-05 19:05:29,520 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9021 | Iter Mean Loss 4.4302
2020-11-05 19:05:29,527 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9251 | Iter Mean Loss 4.1292
2020-11-05 19:05:29,529 - root - INFO - Evaluate: Epoch 0722 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:29,540 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5485 | Iter Mean Loss 5.5485
2020-11-05 19:05:29,549 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5605 | Iter Mean Loss 3.5545
2020-11-05 19:05:29,559 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6949 | Iter Mean Loss 4.2679
2020-11-05 19:05:29,567 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8948 | Iter Mean Loss 4.4247
2020-11-05 19:05:29,577 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9195 | Iter Mean Loss 4.1236
2020-11-05 19:05:29,579 - root - INFO - Evaluate: Epoch 0723 | NDCG 0.2817 | MSE 0.3188
2020-11-05 19:05:29,589 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5447 | Iter Mean Loss 5.5447
2020-11-05 19:05:29,599 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5577 | Iter Mean Loss 3.5512
2020-11-05 19:05:29,609 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6867 | Iter Mean Loss 4.2630
2020-11-05 19:05:29,617 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8875 | Iter Mean Loss 4.4191
2020-11-05 19:05:29,626 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9140 | Iter Mean Loss 4.1181
2020-11-05 19:05:29,628 - root - INFO - Evaluate: Epoch 0724 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:29,638 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5408 | Iter Mean Loss 5.5408
2020-11-05 19:05:29,647 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5549 | Iter Mean Loss 3.5479
2020-11-05 19:05:29,656 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6786 | Iter Mean Loss 4.2581
2020-11-05 19:05:29,666 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8802 | Iter Mean Loss 4.4136
2020-11-05 19:05:29,675 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9085 | Iter Mean Loss 4.1126
2020-11-05 19:05:29,677 - root - INFO - Evaluate: Epoch 0725 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:29,686 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5370 | Iter Mean Loss 5.5370
2020-11-05 19:05:29,694 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5522 | Iter Mean Loss 3.5446
2020-11-05 19:05:29,703 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6705 | Iter Mean Loss 4.2532
2020-11-05 19:05:29,713 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8729 | Iter Mean Loss 4.4082
2020-11-05 19:05:29,722 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9031 | Iter Mean Loss 4.1071
2020-11-05 19:05:29,724 - root - INFO - Evaluate: Epoch 0726 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:29,734 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5332 | Iter Mean Loss 5.5332
2020-11-05 19:05:29,743 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5495 | Iter Mean Loss 3.5413
2020-11-05 19:05:29,753 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6625 | Iter Mean Loss 4.2484
2020-11-05 19:05:29,762 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8657 | Iter Mean Loss 4.4027
2020-11-05 19:05:29,771 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8977 | Iter Mean Loss 4.1017
2020-11-05 19:05:29,773 - root - INFO - Evaluate: Epoch 0727 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:29,783 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5294 | Iter Mean Loss 5.5294
2020-11-05 19:05:29,793 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5468 | Iter Mean Loss 3.5381
2020-11-05 19:05:29,802 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6545 | Iter Mean Loss 4.2436
2020-11-05 19:05:29,812 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8585 | Iter Mean Loss 4.3973
2020-11-05 19:05:29,820 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8923 | Iter Mean Loss 4.0963
2020-11-05 19:05:29,823 - root - INFO - Evaluate: Epoch 0728 | NDCG 0.2817 | MSE 0.3189
2020-11-05 19:05:29,832 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5257 | Iter Mean Loss 5.5257
2020-11-05 19:05:29,840 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5441 | Iter Mean Loss 3.5349
2020-11-05 19:05:29,850 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6465 | Iter Mean Loss 4.2388
2020-11-05 19:05:29,859 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8514 | Iter Mean Loss 4.3919
2020-11-05 19:05:29,868 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 4.0909
2020-11-05 19:05:29,870 - root - INFO - Evaluate: Epoch 0729 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:29,879 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5219 | Iter Mean Loss 5.5219
2020-11-05 19:05:29,887 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5415 | Iter Mean Loss 3.5317
2020-11-05 19:05:29,895 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6386 | Iter Mean Loss 4.2340
2020-11-05 19:05:29,905 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8443 | Iter Mean Loss 4.3866
2020-11-05 19:05:29,915 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8817 | Iter Mean Loss 4.0856
2020-11-05 19:05:29,917 - root - INFO - Evaluate: Epoch 0730 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:29,927 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5182 | Iter Mean Loss 5.5182
2020-11-05 19:05:29,935 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5389 | Iter Mean Loss 3.5286
2020-11-05 19:05:29,945 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6307 | Iter Mean Loss 4.2293
2020-11-05 19:05:29,953 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8372 | Iter Mean Loss 4.3813
2020-11-05 19:05:29,963 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8764 | Iter Mean Loss 4.0803
2020-11-05 19:05:29,965 - root - INFO - Evaluate: Epoch 0731 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:29,974 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5145 | Iter Mean Loss 5.5145
2020-11-05 19:05:29,984 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5363 | Iter Mean Loss 3.5254
2020-11-05 19:05:29,993 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6229 | Iter Mean Loss 4.2246
2020-11-05 19:05:30,002 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8302 | Iter Mean Loss 4.3760
2020-11-05 19:05:30,011 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8711 | Iter Mean Loss 4.0750
2020-11-05 19:05:30,014 - root - INFO - Evaluate: Epoch 0732 | NDCG 0.2817 | MSE 0.3190
2020-11-05 19:05:30,022 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5108 | Iter Mean Loss 5.5108
2020-11-05 19:05:30,032 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5338 | Iter Mean Loss 3.5223
2020-11-05 19:05:30,040 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6151 | Iter Mean Loss 4.2199
2020-11-05 19:05:30,050 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8231 | Iter Mean Loss 4.3707
2020-11-05 19:05:30,058 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8659 | Iter Mean Loss 4.0697
2020-11-05 19:05:30,061 - root - INFO - Evaluate: Epoch 0733 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:30,069 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5071 | Iter Mean Loss 5.5071
2020-11-05 19:05:30,078 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5313 | Iter Mean Loss 3.5192
2020-11-05 19:05:30,086 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6073 | Iter Mean Loss 4.2152
2020-11-05 19:05:30,094 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8162 | Iter Mean Loss 4.3654
2020-11-05 19:05:30,102 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8608 | Iter Mean Loss 4.0645
2020-11-05 19:05:30,104 - root - INFO - Evaluate: Epoch 0734 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:30,114 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5034 | Iter Mean Loss 5.5034
2020-11-05 19:05:30,123 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5288 | Iter Mean Loss 3.5161
2020-11-05 19:05:30,132 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5995 | Iter Mean Loss 4.2106
2020-11-05 19:05:30,141 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8092 | Iter Mean Loss 4.3602
2020-11-05 19:05:30,156 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8556 | Iter Mean Loss 4.0593
2020-11-05 19:05:30,160 - root - INFO - Evaluate: Epoch 0735 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:30,176 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4997 | Iter Mean Loss 5.4997
2020-11-05 19:05:30,194 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5263 | Iter Mean Loss 3.5130
2020-11-05 19:05:30,211 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5918 | Iter Mean Loss 4.2059
2020-11-05 19:05:30,223 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8023 | Iter Mean Loss 4.3550
2020-11-05 19:05:30,240 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8505 | Iter Mean Loss 4.0541
2020-11-05 19:05:30,244 - root - INFO - Evaluate: Epoch 0736 | NDCG 0.2817 | MSE 0.3191
2020-11-05 19:05:30,256 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4961 | Iter Mean Loss 5.4961
2020-11-05 19:05:30,270 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5239 | Iter Mean Loss 3.5100
2020-11-05 19:05:30,283 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5841 | Iter Mean Loss 4.2013
2020-11-05 19:05:30,294 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7954 | Iter Mean Loss 4.3499
2020-11-05 19:05:30,313 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8454 | Iter Mean Loss 4.0490
2020-11-05 19:05:30,326 - root - INFO - Evaluate: Epoch 0737 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:30,339 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4924 | Iter Mean Loss 5.4924
2020-11-05 19:05:30,356 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5214 | Iter Mean Loss 3.5069
2020-11-05 19:05:30,377 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5765 | Iter Mean Loss 4.1968
2020-11-05 19:05:30,393 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7886 | Iter Mean Loss 4.3447
2020-11-05 19:05:30,410 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8403 | Iter Mean Loss 4.0438
2020-11-05 19:05:30,413 - root - INFO - Evaluate: Epoch 0738 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:30,432 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4888 | Iter Mean Loss 5.4888
2020-11-05 19:05:30,455 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5190 | Iter Mean Loss 3.5039
2020-11-05 19:05:30,467 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5688 | Iter Mean Loss 4.1922
2020-11-05 19:05:30,482 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7817 | Iter Mean Loss 4.3396
2020-11-05 19:05:30,499 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8353 | Iter Mean Loss 4.0387
2020-11-05 19:05:30,504 - root - INFO - Evaluate: Epoch 0739 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:30,519 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4852 | Iter Mean Loss 5.4852
2020-11-05 19:05:30,534 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5166 | Iter Mean Loss 3.5009
2020-11-05 19:05:30,547 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5612 | Iter Mean Loss 4.1877
2020-11-05 19:05:30,563 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7749 | Iter Mean Loss 4.3345
2020-11-05 19:05:30,577 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 4.0337
2020-11-05 19:05:30,582 - root - INFO - Evaluate: Epoch 0740 | NDCG 0.2817 | MSE 0.3192
2020-11-05 19:05:30,600 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4816 | Iter Mean Loss 5.4816
2020-11-05 19:05:30,615 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5143 | Iter Mean Loss 3.4979
2020-11-05 19:05:30,628 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5537 | Iter Mean Loss 4.1832
2020-11-05 19:05:30,645 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7682 | Iter Mean Loss 4.3294
2020-11-05 19:05:30,660 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8253 | Iter Mean Loss 4.0286
2020-11-05 19:05:30,663 - root - INFO - Evaluate: Epoch 0741 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:30,676 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4780 | Iter Mean Loss 5.4780
2020-11-05 19:05:30,706 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5120 | Iter Mean Loss 3.4950
2020-11-05 19:05:30,718 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5462 | Iter Mean Loss 4.1787
2020-11-05 19:05:30,735 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7614 | Iter Mean Loss 4.3244
2020-11-05 19:05:30,757 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8203 | Iter Mean Loss 4.0236
2020-11-05 19:05:30,761 - root - INFO - Evaluate: Epoch 0742 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:30,780 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4744 | Iter Mean Loss 5.4744
2020-11-05 19:05:30,801 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5096 | Iter Mean Loss 3.4920
2020-11-05 19:05:30,816 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5386 | Iter Mean Loss 4.1742
2020-11-05 19:05:30,835 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7547 | Iter Mean Loss 4.3194
2020-11-05 19:05:30,850 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8154 | Iter Mean Loss 4.0186
2020-11-05 19:05:30,854 - root - INFO - Evaluate: Epoch 0743 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:30,868 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4709 | Iter Mean Loss 5.4709
2020-11-05 19:05:30,885 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5073 | Iter Mean Loss 3.4891
2020-11-05 19:05:30,898 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5312 | Iter Mean Loss 4.1698
2020-11-05 19:05:30,915 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7480 | Iter Mean Loss 4.3144
2020-11-05 19:05:30,931 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8105 | Iter Mean Loss 4.0136
2020-11-05 19:05:30,934 - root - INFO - Evaluate: Epoch 0744 | NDCG 0.2817 | MSE 0.3193
2020-11-05 19:05:30,949 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4673 | Iter Mean Loss 5.4673
2020-11-05 19:05:30,967 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5051 | Iter Mean Loss 3.4862
2020-11-05 19:05:30,983 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5237 | Iter Mean Loss 4.1654
2020-11-05 19:05:31,001 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 4.3094
2020-11-05 19:05:31,020 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8056 | Iter Mean Loss 4.0086
2020-11-05 19:05:31,023 - root - INFO - Evaluate: Epoch 0745 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:31,042 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4638 | Iter Mean Loss 5.4638
2020-11-05 19:05:31,059 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5028 | Iter Mean Loss 3.4833
2020-11-05 19:05:31,071 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5163 | Iter Mean Loss 4.1610
2020-11-05 19:05:31,093 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7348 | Iter Mean Loss 4.3044
2020-11-05 19:05:31,106 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8008 | Iter Mean Loss 4.0037
2020-11-05 19:05:31,110 - root - INFO - Evaluate: Epoch 0746 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:31,126 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4602 | Iter Mean Loss 5.4602
2020-11-05 19:05:31,139 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5006 | Iter Mean Loss 3.4804
2020-11-05 19:05:31,153 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5089 | Iter Mean Loss 4.1566
2020-11-05 19:05:31,168 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7281 | Iter Mean Loss 4.2995
2020-11-05 19:05:31,182 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7960 | Iter Mean Loss 3.9988
2020-11-05 19:05:31,186 - root - INFO - Evaluate: Epoch 0747 | NDCG 0.2817 | MSE 0.3194
2020-11-05 19:05:31,204 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4567 | Iter Mean Loss 5.4567
2020-11-05 19:05:31,219 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4984 | Iter Mean Loss 3.4776
2020-11-05 19:05:31,238 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5016 | Iter Mean Loss 4.1522
2020-11-05 19:05:31,252 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7216 | Iter Mean Loss 4.2946
2020-11-05 19:05:31,268 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7912 | Iter Mean Loss 3.9939
2020-11-05 19:05:31,275 - root - INFO - Evaluate: Epoch 0748 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:31,295 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4532 | Iter Mean Loss 5.4532
2020-11-05 19:05:31,308 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4962 | Iter Mean Loss 3.4747
2020-11-05 19:05:31,323 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4942 | Iter Mean Loss 4.1479
2020-11-05 19:05:31,334 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7150 | Iter Mean Loss 4.2897
2020-11-05 19:05:31,344 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7864 | Iter Mean Loss 3.9890
2020-11-05 19:05:31,347 - root - INFO - Evaluate: Epoch 0749 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:31,358 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4497 | Iter Mean Loss 5.4497
2020-11-05 19:05:31,368 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4940 | Iter Mean Loss 3.4719
2020-11-05 19:05:31,377 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4869 | Iter Mean Loss 4.1435
2020-11-05 19:05:31,388 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7085 | Iter Mean Loss 4.2848
2020-11-05 19:05:31,396 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7817 | Iter Mean Loss 3.9842
2020-11-05 19:05:31,400 - root - INFO - Evaluate: Epoch 0750 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:31,410 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4462 | Iter Mean Loss 5.4462
2020-11-05 19:05:31,421 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4918 | Iter Mean Loss 3.4690
2020-11-05 19:05:31,431 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4796 | Iter Mean Loss 4.1392
2020-11-05 19:05:31,443 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7020 | Iter Mean Loss 4.2799
2020-11-05 19:05:31,454 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7769 | Iter Mean Loss 3.9793
2020-11-05 19:05:31,458 - root - INFO - Evaluate: Epoch 0751 | NDCG 0.2817 | MSE 0.3195
2020-11-05 19:05:31,467 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4428 | Iter Mean Loss 5.4428
2020-11-05 19:05:31,478 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4897 | Iter Mean Loss 3.4662
2020-11-05 19:05:31,486 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4724 | Iter Mean Loss 4.1349
2020-11-05 19:05:31,493 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6955 | Iter Mean Loss 4.2751
2020-11-05 19:05:31,501 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7722 | Iter Mean Loss 3.9745
2020-11-05 19:05:31,503 - root - INFO - Evaluate: Epoch 0752 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:31,511 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4393 | Iter Mean Loss 5.4393
2020-11-05 19:05:31,518 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4876 | Iter Mean Loss 3.4634
2020-11-05 19:05:31,525 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4651 | Iter Mean Loss 4.1307
2020-11-05 19:05:31,533 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6891 | Iter Mean Loss 4.2703
2020-11-05 19:05:31,542 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7676 | Iter Mean Loss 3.9697
2020-11-05 19:05:31,546 - root - INFO - Evaluate: Epoch 0753 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:31,555 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4358 | Iter Mean Loss 5.4358
2020-11-05 19:05:31,564 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 3.4607
2020-11-05 19:05:31,573 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4579 | Iter Mean Loss 4.1264
2020-11-05 19:05:31,581 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6826 | Iter Mean Loss 4.2655
2020-11-05 19:05:31,590 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7629 | Iter Mean Loss 3.9650
2020-11-05 19:05:31,592 - root - INFO - Evaluate: Epoch 0754 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:31,602 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4324 | Iter Mean Loss 5.4324
2020-11-05 19:05:31,611 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4834 | Iter Mean Loss 3.4579
2020-11-05 19:05:31,620 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4507 | Iter Mean Loss 4.1222
2020-11-05 19:05:31,628 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6762 | Iter Mean Loss 4.2607
2020-11-05 19:05:31,637 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7583 | Iter Mean Loss 3.9602
2020-11-05 19:05:31,639 - root - INFO - Evaluate: Epoch 0755 | NDCG 0.2817 | MSE 0.3196
2020-11-05 19:05:31,648 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4290 | Iter Mean Loss 5.4290
2020-11-05 19:05:31,656 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4813 | Iter Mean Loss 3.4551
2020-11-05 19:05:31,665 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4436 | Iter Mean Loss 4.1180
2020-11-05 19:05:31,673 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6698 | Iter Mean Loss 4.2559
2020-11-05 19:05:31,682 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7537 | Iter Mean Loss 3.9555
2020-11-05 19:05:31,684 - root - INFO - Evaluate: Epoch 0756 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:31,693 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4255 | Iter Mean Loss 5.4255
2020-11-05 19:05:31,701 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4793 | Iter Mean Loss 3.4524
2020-11-05 19:05:31,709 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4365 | Iter Mean Loss 4.1137
2020-11-05 19:05:31,718 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6635 | Iter Mean Loss 4.2512
2020-11-05 19:05:31,726 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7491 | Iter Mean Loss 3.9508
2020-11-05 19:05:31,729 - root - INFO - Evaluate: Epoch 0757 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:31,738 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4221 | Iter Mean Loss 5.4221
2020-11-05 19:05:31,746 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4772 | Iter Mean Loss 3.4497
2020-11-05 19:05:31,754 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4293 | Iter Mean Loss 4.1096
2020-11-05 19:05:31,761 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6572 | Iter Mean Loss 4.2465
2020-11-05 19:05:31,770 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7445 | Iter Mean Loss 3.9461
2020-11-05 19:05:31,772 - root - INFO - Evaluate: Epoch 0758 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:31,782 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4187 | Iter Mean Loss 5.4187
2020-11-05 19:05:31,790 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4752 | Iter Mean Loss 3.4469
2020-11-05 19:05:31,799 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4223 | Iter Mean Loss 4.1054
2020-11-05 19:05:31,807 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6508 | Iter Mean Loss 4.2417
2020-11-05 19:05:31,816 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7400 | Iter Mean Loss 3.9414
2020-11-05 19:05:31,818 - root - INFO - Evaluate: Epoch 0759 | NDCG 0.2817 | MSE 0.3197
2020-11-05 19:05:31,827 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4153 | Iter Mean Loss 5.4153
2020-11-05 19:05:31,836 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4732 | Iter Mean Loss 3.4442
2020-11-05 19:05:31,844 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4152 | Iter Mean Loss 4.1012
2020-11-05 19:05:31,853 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6445 | Iter Mean Loss 4.2371
2020-11-05 19:05:31,861 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7354 | Iter Mean Loss 3.9367
2020-11-05 19:05:31,864 - root - INFO - Evaluate: Epoch 0760 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:31,873 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4119 | Iter Mean Loss 5.4119
2020-11-05 19:05:31,882 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4712 | Iter Mean Loss 3.4416
2020-11-05 19:05:31,890 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4081 | Iter Mean Loss 4.0971
2020-11-05 19:05:31,898 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6383 | Iter Mean Loss 4.2324
2020-11-05 19:05:31,905 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7309 | Iter Mean Loss 3.9321
2020-11-05 19:05:31,907 - root - INFO - Evaluate: Epoch 0761 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:31,916 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4086 | Iter Mean Loss 5.4086
2020-11-05 19:05:31,923 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4692 | Iter Mean Loss 3.4389
2020-11-05 19:05:31,931 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4011 | Iter Mean Loss 4.0930
2020-11-05 19:05:31,938 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6320 | Iter Mean Loss 4.2277
2020-11-05 19:05:31,947 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7265 | Iter Mean Loss 3.9275
2020-11-05 19:05:31,949 - root - INFO - Evaluate: Epoch 0762 | NDCG 0.2817 | MSE 0.3198
2020-11-05 19:05:31,957 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4052 | Iter Mean Loss 5.4052
2020-11-05 19:05:31,965 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4672 | Iter Mean Loss 3.4362
2020-11-05 19:05:31,973 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3941 | Iter Mean Loss 4.0888
2020-11-05 19:05:31,981 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6258 | Iter Mean Loss 4.2231
2020-11-05 19:05:31,990 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7220 | Iter Mean Loss 3.9229
2020-11-05 19:05:31,992 - root - INFO - Evaluate: Epoch 0763 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:32,003 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4018 | Iter Mean Loss 5.4018
2020-11-05 19:05:32,011 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4653 | Iter Mean Loss 3.4336
2020-11-05 19:05:32,021 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3872 | Iter Mean Loss 4.0848
2020-11-05 19:05:32,029 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6196 | Iter Mean Loss 4.2185
2020-11-05 19:05:32,037 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7176 | Iter Mean Loss 3.9183
2020-11-05 19:05:32,040 - root - INFO - Evaluate: Epoch 0764 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:32,048 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3985 | Iter Mean Loss 5.3985
2020-11-05 19:05:32,057 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4633 | Iter Mean Loss 3.4309
2020-11-05 19:05:32,065 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3802 | Iter Mean Loss 4.0807
2020-11-05 19:05:32,074 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6134 | Iter Mean Loss 4.2139
2020-11-05 19:05:32,082 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7131 | Iter Mean Loss 3.9137
2020-11-05 19:05:32,084 - root - INFO - Evaluate: Epoch 0765 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:32,093 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3951 | Iter Mean Loss 5.3951
2020-11-05 19:05:32,101 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4614 | Iter Mean Loss 3.4283
2020-11-05 19:05:32,109 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3733 | Iter Mean Loss 4.0766
2020-11-05 19:05:32,116 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6072 | Iter Mean Loss 4.2093
2020-11-05 19:05:32,124 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7087 | Iter Mean Loss 3.9092
2020-11-05 19:05:32,126 - root - INFO - Evaluate: Epoch 0766 | NDCG 0.2817 | MSE 0.3199
2020-11-05 19:05:32,134 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3918 | Iter Mean Loss 5.3918
2020-11-05 19:05:32,142 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4595 | Iter Mean Loss 3.4257
2020-11-05 19:05:32,149 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3664 | Iter Mean Loss 4.0726
2020-11-05 19:05:32,157 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6011 | Iter Mean Loss 4.2047
2020-11-05 19:05:32,164 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7044 | Iter Mean Loss 3.9046
2020-11-05 19:05:32,166 - root - INFO - Evaluate: Epoch 0767 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:32,174 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3885 | Iter Mean Loss 5.3885
2020-11-05 19:05:32,182 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 3.4230
2020-11-05 19:05:32,191 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 4.0685
2020-11-05 19:05:32,198 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5950 | Iter Mean Loss 4.2001
2020-11-05 19:05:32,207 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7000 | Iter Mean Loss 3.9001
2020-11-05 19:05:32,210 - root - INFO - Evaluate: Epoch 0768 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:32,218 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3852 | Iter Mean Loss 5.3852
2020-11-05 19:05:32,227 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4557 | Iter Mean Loss 3.4204
2020-11-05 19:05:32,235 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3526 | Iter Mean Loss 4.0645
2020-11-05 19:05:32,243 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5889 | Iter Mean Loss 4.1956
2020-11-05 19:05:32,251 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 3.8956
2020-11-05 19:05:32,255 - root - INFO - Evaluate: Epoch 0769 | NDCG 0.2817 | MSE 0.3200
2020-11-05 19:05:32,264 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3818 | Iter Mean Loss 5.3818
2020-11-05 19:05:32,272 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4538 | Iter Mean Loss 3.4178
2020-11-05 19:05:32,281 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3457 | Iter Mean Loss 4.0605
2020-11-05 19:05:32,289 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5828 | Iter Mean Loss 4.1911
2020-11-05 19:05:32,297 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6913 | Iter Mean Loss 3.8911
2020-11-05 19:05:32,299 - root - INFO - Evaluate: Epoch 0770 | NDCG 0.2817 | MSE 0.3201
2020-11-05 19:05:32,308 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3785 | Iter Mean Loss 5.3785
2020-11-05 19:05:32,316 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4520 | Iter Mean Loss 3.4153
2020-11-05 19:05:32,325 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3389 | Iter Mean Loss 4.0565
2020-11-05 19:05:32,332 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5767 | Iter Mean Loss 4.1865
2020-11-05 19:05:32,340 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6870 | Iter Mean Loss 3.8866
2020-11-05 19:05:32,342 - root - INFO - Evaluate: Epoch 0771 | NDCG 0.2817 | MSE 0.3201
2020-11-05 19:05:32,350 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 5.3753
2020-11-05 19:05:32,357 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4501 | Iter Mean Loss 3.4127
2020-11-05 19:05:32,365 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3321 | Iter Mean Loss 4.0525
2020-11-05 19:05:32,372 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5707 | Iter Mean Loss 4.1820
2020-11-05 19:05:32,380 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 3.8822
2020-11-05 19:05:32,382 - root - INFO - Evaluate: Epoch 0772 | NDCG 0.2817 | MSE 0.3201
2020-11-05 19:05:32,391 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3720 | Iter Mean Loss 5.3720
2020-11-05 19:05:32,398 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4483 | Iter Mean Loss 3.4101
2020-11-05 19:05:32,409 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3253 | Iter Mean Loss 4.0485
2020-11-05 19:05:32,418 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5647 | Iter Mean Loss 4.1776
2020-11-05 19:05:32,428 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6785 | Iter Mean Loss 3.8777
2020-11-05 19:05:32,431 - root - INFO - Evaluate: Epoch 0773 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:32,442 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3687 | Iter Mean Loss 5.3687
2020-11-05 19:05:32,451 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4465 | Iter Mean Loss 3.4076
2020-11-05 19:05:32,460 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3185 | Iter Mean Loss 4.0446
2020-11-05 19:05:32,469 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5586 | Iter Mean Loss 4.1731
2020-11-05 19:05:32,479 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6742 | Iter Mean Loss 3.8733
2020-11-05 19:05:32,482 - root - INFO - Evaluate: Epoch 0774 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:32,492 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3654 | Iter Mean Loss 5.3654
2020-11-05 19:05:32,501 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4447 | Iter Mean Loss 3.4050
2020-11-05 19:05:32,510 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3118 | Iter Mean Loss 4.0406
2020-11-05 19:05:32,518 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5527 | Iter Mean Loss 4.1686
2020-11-05 19:05:32,527 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6700 | Iter Mean Loss 3.8689
2020-11-05 19:05:32,530 - root - INFO - Evaluate: Epoch 0775 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:32,540 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3622 | Iter Mean Loss 5.3622
2020-11-05 19:05:32,549 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4429 | Iter Mean Loss 3.4025
2020-11-05 19:05:32,557 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3050 | Iter Mean Loss 4.0367
2020-11-05 19:05:32,566 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5467 | Iter Mean Loss 4.1642
2020-11-05 19:05:32,575 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6658 | Iter Mean Loss 3.8645
2020-11-05 19:05:32,577 - root - INFO - Evaluate: Epoch 0776 | NDCG 0.2817 | MSE 0.3202
2020-11-05 19:05:32,585 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3589 | Iter Mean Loss 5.3589
2020-11-05 19:05:32,593 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4411 | Iter Mean Loss 3.4000
2020-11-05 19:05:32,601 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 4.0328
2020-11-05 19:05:32,609 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5407 | Iter Mean Loss 4.1598
2020-11-05 19:05:32,617 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6616 | Iter Mean Loss 3.8601
2020-11-05 19:05:32,619 - root - INFO - Evaluate: Epoch 0777 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:32,628 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3557 | Iter Mean Loss 5.3557
2020-11-05 19:05:32,636 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4393 | Iter Mean Loss 3.3975
2020-11-05 19:05:32,644 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2916 | Iter Mean Loss 4.0289
2020-11-05 19:05:32,652 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5348 | Iter Mean Loss 4.1553
2020-11-05 19:05:32,659 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6574 | Iter Mean Loss 3.8558
2020-11-05 19:05:32,662 - root - INFO - Evaluate: Epoch 0778 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:32,670 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3524 | Iter Mean Loss 5.3524
2020-11-05 19:05:32,679 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4375 | Iter Mean Loss 3.3950
2020-11-05 19:05:32,686 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2850 | Iter Mean Loss 4.0250
2020-11-05 19:05:32,694 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5289 | Iter Mean Loss 4.1509
2020-11-05 19:05:32,702 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6532 | Iter Mean Loss 3.8514
2020-11-05 19:05:32,704 - root - INFO - Evaluate: Epoch 0779 | NDCG 0.2817 | MSE 0.3203
2020-11-05 19:05:32,713 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3492 | Iter Mean Loss 5.3492
2020-11-05 19:05:32,720 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 3.3925
2020-11-05 19:05:32,728 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2783 | Iter Mean Loss 4.0211
2020-11-05 19:05:32,735 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5230 | Iter Mean Loss 4.1466
2020-11-05 19:05:32,742 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6491 | Iter Mean Loss 3.8471
2020-11-05 19:05:32,744 - root - INFO - Evaluate: Epoch 0780 | NDCG 0.2817 | MSE 0.3204
2020-11-05 19:05:32,752 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3460 | Iter Mean Loss 5.3460
2020-11-05 19:05:32,760 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4340 | Iter Mean Loss 3.3900
2020-11-05 19:05:32,767 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2717 | Iter Mean Loss 4.0172
2020-11-05 19:05:32,774 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 4.1422
2020-11-05 19:05:32,781 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6449 | Iter Mean Loss 3.8427
2020-11-05 19:05:32,783 - root - INFO - Evaluate: Epoch 0781 | NDCG 0.2817 | MSE 0.3204
2020-11-05 19:05:32,792 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3427 | Iter Mean Loss 5.3427
2020-11-05 19:05:32,800 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4323 | Iter Mean Loss 3.3875
2020-11-05 19:05:32,807 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2650 | Iter Mean Loss 4.0133
2020-11-05 19:05:32,815 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5112 | Iter Mean Loss 4.1378
2020-11-05 19:05:32,823 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6408 | Iter Mean Loss 3.8384
2020-11-05 19:05:32,825 - root - INFO - Evaluate: Epoch 0782 | NDCG 0.2817 | MSE 0.3204
2020-11-05 19:05:32,833 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3395 | Iter Mean Loss 5.3395
2020-11-05 19:05:32,841 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4305 | Iter Mean Loss 3.3850
2020-11-05 19:05:32,848 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2584 | Iter Mean Loss 4.0095
2020-11-05 19:05:32,856 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5054 | Iter Mean Loss 4.1335
2020-11-05 19:05:32,864 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6367 | Iter Mean Loss 3.8341
2020-11-05 19:05:32,866 - root - INFO - Evaluate: Epoch 0783 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:32,875 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3363 | Iter Mean Loss 5.3363
2020-11-05 19:05:32,882 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4288 | Iter Mean Loss 3.3826
2020-11-05 19:05:32,889 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2518 | Iter Mean Loss 4.0057
2020-11-05 19:05:32,897 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4996 | Iter Mean Loss 4.1291
2020-11-05 19:05:32,905 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6326 | Iter Mean Loss 3.8298
2020-11-05 19:05:32,907 - root - INFO - Evaluate: Epoch 0784 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:32,915 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3331 | Iter Mean Loss 5.3331
2020-11-05 19:05:32,922 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4271 | Iter Mean Loss 3.3801
2020-11-05 19:05:32,929 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.0018
2020-11-05 19:05:32,937 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4938 | Iter Mean Loss 4.1248
2020-11-05 19:05:32,944 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6286 | Iter Mean Loss 3.8256
2020-11-05 19:05:32,946 - root - INFO - Evaluate: Epoch 0785 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:32,953 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3299 | Iter Mean Loss 5.3299
2020-11-05 19:05:32,961 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4254 | Iter Mean Loss 3.3777
2020-11-05 19:05:32,968 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2387 | Iter Mean Loss 3.9980
2020-11-05 19:05:32,975 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4880 | Iter Mean Loss 4.1205
2020-11-05 19:05:32,983 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6245 | Iter Mean Loss 3.8213
2020-11-05 19:05:32,985 - root - INFO - Evaluate: Epoch 0786 | NDCG 0.2817 | MSE 0.3205
2020-11-05 19:05:32,993 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3267 | Iter Mean Loss 5.3267
2020-11-05 19:05:33,000 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4237 | Iter Mean Loss 3.3752
2020-11-05 19:05:33,008 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2322 | Iter Mean Loss 3.9942
2020-11-05 19:05:33,015 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4822 | Iter Mean Loss 4.1162
2020-11-05 19:05:33,023 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6205 | Iter Mean Loss 3.8171
2020-11-05 19:05:33,026 - root - INFO - Evaluate: Epoch 0787 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:33,034 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3236 | Iter Mean Loss 5.3236
2020-11-05 19:05:33,042 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4220 | Iter Mean Loss 3.3728
2020-11-05 19:05:33,050 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2256 | Iter Mean Loss 3.9904
2020-11-05 19:05:33,058 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4764 | Iter Mean Loss 4.1119
2020-11-05 19:05:33,066 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6165 | Iter Mean Loss 3.8128
2020-11-05 19:05:33,068 - root - INFO - Evaluate: Epoch 0788 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:33,076 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3204 | Iter Mean Loss 5.3204
2020-11-05 19:05:33,084 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4204 | Iter Mean Loss 3.3704
2020-11-05 19:05:33,091 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2191 | Iter Mean Loss 3.9866
2020-11-05 19:05:33,100 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4707 | Iter Mean Loss 4.1076
2020-11-05 19:05:33,107 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6125 | Iter Mean Loss 3.8086
2020-11-05 19:05:33,109 - root - INFO - Evaluate: Epoch 0789 | NDCG 0.2817 | MSE 0.3206
2020-11-05 19:05:33,118 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3172 | Iter Mean Loss 5.3172
2020-11-05 19:05:33,125 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4187 | Iter Mean Loss 3.3680
2020-11-05 19:05:33,132 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2126 | Iter Mean Loss 3.9829
2020-11-05 19:05:33,139 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4649 | Iter Mean Loss 4.1034
2020-11-05 19:05:33,146 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6085 | Iter Mean Loss 3.8044
2020-11-05 19:05:33,148 - root - INFO - Evaluate: Epoch 0790 | NDCG 0.2817 | MSE 0.3207
2020-11-05 19:05:33,156 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3141 | Iter Mean Loss 5.3141
2020-11-05 19:05:33,163 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4171 | Iter Mean Loss 3.3656
2020-11-05 19:05:33,171 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2062 | Iter Mean Loss 3.9791
2020-11-05 19:05:33,178 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4592 | Iter Mean Loss 4.0991
2020-11-05 19:05:33,185 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6045 | Iter Mean Loss 3.8002
2020-11-05 19:05:33,187 - root - INFO - Evaluate: Epoch 0791 | NDCG 0.2817 | MSE 0.3207
2020-11-05 19:05:33,195 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3109 | Iter Mean Loss 5.3109
2020-11-05 19:05:33,202 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 3.3632
2020-11-05 19:05:33,210 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1997 | Iter Mean Loss 3.9753
2020-11-05 19:05:33,217 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 4.0949
2020-11-05 19:05:33,225 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6005 | Iter Mean Loss 3.7960
2020-11-05 19:05:33,227 - root - INFO - Evaluate: Epoch 0792 | NDCG 0.2817 | MSE 0.3207
2020-11-05 19:05:33,236 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3078 | Iter Mean Loss 5.3078
2020-11-05 19:05:33,244 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4138 | Iter Mean Loss 3.3608
2020-11-05 19:05:33,252 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1933 | Iter Mean Loss 3.9716
2020-11-05 19:05:33,260 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 4.0907
2020-11-05 19:05:33,268 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5966 | Iter Mean Loss 3.7918
2020-11-05 19:05:33,270 - root - INFO - Evaluate: Epoch 0793 | NDCG 0.2817 | MSE 0.3208
2020-11-05 19:05:33,279 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3046 | Iter Mean Loss 5.3046
2020-11-05 19:05:33,287 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4122 | Iter Mean Loss 3.3584
2020-11-05 19:05:33,294 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1868 | Iter Mean Loss 3.9679
2020-11-05 19:05:33,303 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4422 | Iter Mean Loss 4.0864
2020-11-05 19:05:33,310 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5927 | Iter Mean Loss 3.7877
2020-11-05 19:05:33,314 - root - INFO - Evaluate: Epoch 0794 | NDCG 0.2817 | MSE 0.3208
2020-11-05 19:05:33,322 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3015 | Iter Mean Loss 5.3015
2020-11-05 19:05:33,330 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4105 | Iter Mean Loss 3.3560
2020-11-05 19:05:33,338 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1804 | Iter Mean Loss 3.9641
2020-11-05 19:05:33,345 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4365 | Iter Mean Loss 4.0822
2020-11-05 19:05:33,352 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5887 | Iter Mean Loss 3.7835
2020-11-05 19:05:33,354 - root - INFO - Evaluate: Epoch 0795 | NDCG 0.2817 | MSE 0.3208
2020-11-05 19:05:33,362 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 5.2983
2020-11-05 19:05:33,369 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4089 | Iter Mean Loss 3.3536
2020-11-05 19:05:33,377 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1740 | Iter Mean Loss 3.9604
2020-11-05 19:05:33,384 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4309 | Iter Mean Loss 4.0780
2020-11-05 19:05:33,391 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5848 | Iter Mean Loss 3.7794
2020-11-05 19:05:33,393 - root - INFO - Evaluate: Epoch 0796 | NDCG 0.2817 | MSE 0.3209
2020-11-05 19:05:33,401 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2952 | Iter Mean Loss 5.2952
2020-11-05 19:05:33,409 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4073 | Iter Mean Loss 3.3513
2020-11-05 19:05:33,416 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1677 | Iter Mean Loss 3.9567
2020-11-05 19:05:33,424 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4253 | Iter Mean Loss 4.0739
2020-11-05 19:05:33,432 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5809 | Iter Mean Loss 3.7753
2020-11-05 19:05:33,434 - root - INFO - Evaluate: Epoch 0797 | NDCG 0.2817 | MSE 0.3209
2020-11-05 19:05:33,442 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2921 | Iter Mean Loss 5.2921
2020-11-05 19:05:33,450 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4057 | Iter Mean Loss 3.3489
2020-11-05 19:05:33,457 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1613 | Iter Mean Loss 3.9530
2020-11-05 19:05:33,465 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4197 | Iter Mean Loss 4.0697
2020-11-05 19:05:33,473 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5771 | Iter Mean Loss 3.7712
2020-11-05 19:05:33,475 - root - INFO - Evaluate: Epoch 0798 | NDCG 0.2817 | MSE 0.3209
2020-11-05 19:05:33,484 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2890 | Iter Mean Loss 5.2890
2020-11-05 19:05:33,491 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4041 | Iter Mean Loss 3.3466
2020-11-05 19:05:33,499 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1549 | Iter Mean Loss 3.9494
2020-11-05 19:05:33,507 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4141 | Iter Mean Loss 4.0655
2020-11-05 19:05:33,515 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 3.7671
2020-11-05 19:05:33,517 - root - INFO - Evaluate: Epoch 0799 | NDCG 0.2817 | MSE 0.3210
2020-11-05 19:05:33,525 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2859 | Iter Mean Loss 5.2859
2020-11-05 19:05:33,532 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4025 | Iter Mean Loss 3.3442
2020-11-05 19:05:33,540 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1486 | Iter Mean Loss 3.9457
2020-11-05 19:05:33,547 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4085 | Iter Mean Loss 4.0614
2020-11-05 19:05:33,554 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5694 | Iter Mean Loss 3.7630
2020-11-05 19:05:33,556 - root - INFO - Evaluate: Epoch 0800 | NDCG 0.2817 | MSE 0.3210
2020-11-05 19:05:33,564 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2828 | Iter Mean Loss 5.2828
2020-11-05 19:05:33,572 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4010 | Iter Mean Loss 3.3419
2020-11-05 19:05:33,579 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1423 | Iter Mean Loss 3.9420
2020-11-05 19:05:33,586 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4029 | Iter Mean Loss 4.0572
2020-11-05 19:05:33,593 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5655 | Iter Mean Loss 3.7589
2020-11-05 19:05:33,595 - root - INFO - Evaluate: Epoch 0801 | NDCG 0.2817 | MSE 0.3210
2020-11-05 19:05:33,603 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2797 | Iter Mean Loss 5.2797
2020-11-05 19:05:33,611 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3994 | Iter Mean Loss 3.3395
2020-11-05 19:05:33,619 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1360 | Iter Mean Loss 3.9383
2020-11-05 19:05:33,626 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3974 | Iter Mean Loss 4.0531
2020-11-05 19:05:33,634 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5617 | Iter Mean Loss 3.7548
2020-11-05 19:05:33,636 - root - INFO - Evaluate: Epoch 0802 | NDCG 0.2817 | MSE 0.3211
2020-11-05 19:05:33,645 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2766 | Iter Mean Loss 5.2766
2020-11-05 19:05:33,653 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3978 | Iter Mean Loss 3.3372
2020-11-05 19:05:33,661 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1297 | Iter Mean Loss 3.9347
2020-11-05 19:05:33,669 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3918 | Iter Mean Loss 4.0490
2020-11-05 19:05:33,676 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5579 | Iter Mean Loss 3.7508
2020-11-05 19:05:33,678 - root - INFO - Evaluate: Epoch 0803 | NDCG 0.2817 | MSE 0.3211
2020-11-05 19:05:33,687 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2735 | Iter Mean Loss 5.2735
2020-11-05 19:05:33,694 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3963 | Iter Mean Loss 3.3349
2020-11-05 19:05:33,702 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1234 | Iter Mean Loss 3.9311
2020-11-05 19:05:33,710 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3863 | Iter Mean Loss 4.0449
2020-11-05 19:05:33,718 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5541 | Iter Mean Loss 3.7467
2020-11-05 19:05:33,721 - root - INFO - Evaluate: Epoch 0804 | NDCG 0.2817 | MSE 0.3211
2020-11-05 19:05:33,729 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2704 | Iter Mean Loss 5.2704
2020-11-05 19:05:33,736 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3947 | Iter Mean Loss 3.3326
2020-11-05 19:05:33,743 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1172 | Iter Mean Loss 3.9274
2020-11-05 19:05:33,751 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3808 | Iter Mean Loss 4.0408
2020-11-05 19:05:33,758 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5503 | Iter Mean Loss 3.7427
2020-11-05 19:05:33,760 - root - INFO - Evaluate: Epoch 0805 | NDCG 0.2817 | MSE 0.3212
2020-11-05 19:05:33,767 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2673 | Iter Mean Loss 5.2673
2020-11-05 19:05:33,776 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3932 | Iter Mean Loss 3.3303
2020-11-05 19:05:33,783 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1109 | Iter Mean Loss 3.9238
2020-11-05 19:05:33,790 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3753 | Iter Mean Loss 4.0367
2020-11-05 19:05:33,797 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5465 | Iter Mean Loss 3.7387
2020-11-05 19:05:33,799 - root - INFO - Evaluate: Epoch 0806 | NDCG 0.2817 | MSE 0.3212
2020-11-05 19:05:33,807 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2642 | Iter Mean Loss 5.2642
2020-11-05 19:05:33,815 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3917 | Iter Mean Loss 3.3279
2020-11-05 19:05:33,823 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1047 | Iter Mean Loss 3.9202
2020-11-05 19:05:33,830 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3698 | Iter Mean Loss 4.0326
2020-11-05 19:05:33,839 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5428 | Iter Mean Loss 3.7346
2020-11-05 19:05:33,841 - root - INFO - Evaluate: Epoch 0807 | NDCG 0.2817 | MSE 0.3212
2020-11-05 19:05:33,849 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2612 | Iter Mean Loss 5.2612
2020-11-05 19:05:33,857 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3901 | Iter Mean Loss 3.3256
2020-11-05 19:05:33,865 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0985 | Iter Mean Loss 3.9166
2020-11-05 19:05:33,873 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3644 | Iter Mean Loss 4.0285
2020-11-05 19:05:33,881 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5390 | Iter Mean Loss 3.7306
2020-11-05 19:05:33,883 - root - INFO - Evaluate: Epoch 0808 | NDCG 0.2817 | MSE 0.3213
2020-11-05 19:05:33,892 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2581 | Iter Mean Loss 5.2581
2020-11-05 19:05:33,899 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3886 | Iter Mean Loss 3.3234
2020-11-05 19:05:33,907 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0922 | Iter Mean Loss 3.9130
2020-11-05 19:05:33,915 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 4.0245
2020-11-05 19:05:33,923 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5353 | Iter Mean Loss 3.7266
2020-11-05 19:05:33,925 - root - INFO - Evaluate: Epoch 0809 | NDCG 0.2817 | MSE 0.3213
2020-11-05 19:05:33,933 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2550 | Iter Mean Loss 5.2550
2020-11-05 19:05:33,940 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3871 | Iter Mean Loss 3.3211
2020-11-05 19:05:33,947 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0861 | Iter Mean Loss 3.9094
2020-11-05 19:05:33,954 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3535 | Iter Mean Loss 4.0204
2020-11-05 19:05:33,962 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5316 | Iter Mean Loss 3.7227
2020-11-05 19:05:33,964 - root - INFO - Evaluate: Epoch 0810 | NDCG 0.2817 | MSE 0.3213
2020-11-05 19:05:33,972 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2520 | Iter Mean Loss 5.2520
2020-11-05 19:05:33,980 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3856 | Iter Mean Loss 3.3188
2020-11-05 19:05:33,988 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0799 | Iter Mean Loss 3.9058
2020-11-05 19:05:33,995 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3481 | Iter Mean Loss 4.0164
2020-11-05 19:05:34,002 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5279 | Iter Mean Loss 3.7187
2020-11-05 19:05:34,004 - root - INFO - Evaluate: Epoch 0811 | NDCG 0.2817 | MSE 0.3214
2020-11-05 19:05:34,012 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2489 | Iter Mean Loss 5.2489
2020-11-05 19:05:34,020 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3841 | Iter Mean Loss 3.3165
2020-11-05 19:05:34,028 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0737 | Iter Mean Loss 3.9022
2020-11-05 19:05:34,036 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3427 | Iter Mean Loss 4.0123
2020-11-05 19:05:34,045 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5242 | Iter Mean Loss 3.7147
2020-11-05 19:05:34,047 - root - INFO - Evaluate: Epoch 0812 | NDCG 0.2817 | MSE 0.3214
2020-11-05 19:05:34,057 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2458 | Iter Mean Loss 5.2458
2020-11-05 19:05:34,065 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3826 | Iter Mean Loss 3.3142
2020-11-05 19:05:34,074 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0676 | Iter Mean Loss 3.8987
2020-11-05 19:05:34,082 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3373 | Iter Mean Loss 4.0083
2020-11-05 19:05:34,091 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5205 | Iter Mean Loss 3.7108
2020-11-05 19:05:34,093 - root - INFO - Evaluate: Epoch 0813 | NDCG 0.2817 | MSE 0.3214
2020-11-05 19:05:34,102 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2428 | Iter Mean Loss 5.2428
2020-11-05 19:05:34,110 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3811 | Iter Mean Loss 3.3120
2020-11-05 19:05:34,119 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0614 | Iter Mean Loss 3.8951
2020-11-05 19:05:34,127 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3319 | Iter Mean Loss 4.0043
2020-11-05 19:05:34,135 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5168 | Iter Mean Loss 3.7068
2020-11-05 19:05:34,137 - root - INFO - Evaluate: Epoch 0814 | NDCG 0.2817 | MSE 0.3215
2020-11-05 19:05:34,145 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2398 | Iter Mean Loss 5.2398
2020-11-05 19:05:34,153 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3796 | Iter Mean Loss 3.3097
2020-11-05 19:05:34,161 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0553 | Iter Mean Loss 3.8916
2020-11-05 19:05:34,168 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3265 | Iter Mean Loss 4.0003
2020-11-05 19:05:34,176 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5132 | Iter Mean Loss 3.7029
2020-11-05 19:05:34,179 - root - INFO - Evaluate: Epoch 0815 | NDCG 0.2817 | MSE 0.3215
2020-11-05 19:05:34,188 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2367 | Iter Mean Loss 5.2367
2020-11-05 19:05:34,197 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 3.3074
2020-11-05 19:05:34,204 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0492 | Iter Mean Loss 3.8880
2020-11-05 19:05:34,212 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3212 | Iter Mean Loss 3.9963
2020-11-05 19:05:34,220 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5095 | Iter Mean Loss 3.6989
2020-11-05 19:05:34,223 - root - INFO - Evaluate: Epoch 0816 | NDCG 0.2817 | MSE 0.3215
2020-11-05 19:05:34,232 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2337 | Iter Mean Loss 5.2337
2020-11-05 19:05:34,240 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3767 | Iter Mean Loss 3.3052
2020-11-05 19:05:34,249 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0431 | Iter Mean Loss 3.8845
2020-11-05 19:05:34,257 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3158 | Iter Mean Loss 3.9923
2020-11-05 19:05:34,266 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5059 | Iter Mean Loss 3.6950
2020-11-05 19:05:34,268 - root - INFO - Evaluate: Epoch 0817 | NDCG 0.2817 | MSE 0.3216
2020-11-05 19:05:34,277 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2306 | Iter Mean Loss 5.2306
2020-11-05 19:05:34,286 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3752 | Iter Mean Loss 3.3029
2020-11-05 19:05:34,294 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0370 | Iter Mean Loss 3.8809
2020-11-05 19:05:34,302 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3105 | Iter Mean Loss 3.9883
2020-11-05 19:05:34,312 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5023 | Iter Mean Loss 3.6911
2020-11-05 19:05:34,315 - root - INFO - Evaluate: Epoch 0818 | NDCG 0.2817 | MSE 0.3216
2020-11-05 19:05:34,324 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2276 | Iter Mean Loss 5.2276
2020-11-05 19:05:34,334 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3737 | Iter Mean Loss 3.3007
2020-11-05 19:05:34,341 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0309 | Iter Mean Loss 3.8774
2020-11-05 19:05:34,349 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3052 | Iter Mean Loss 3.9844
2020-11-05 19:05:34,357 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4987 | Iter Mean Loss 3.6872
2020-11-05 19:05:34,359 - root - INFO - Evaluate: Epoch 0819 | NDCG 0.2817 | MSE 0.3217
2020-11-05 19:05:34,367 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2246 | Iter Mean Loss 5.2246
2020-11-05 19:05:34,376 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3723 | Iter Mean Loss 3.2984
2020-11-05 19:05:34,384 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0248 | Iter Mean Loss 3.8739
2020-11-05 19:05:34,392 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.9804
2020-11-05 19:05:34,400 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4951 | Iter Mean Loss 3.6833
2020-11-05 19:05:34,402 - root - INFO - Evaluate: Epoch 0820 | NDCG 0.2817 | MSE 0.3217
2020-11-05 19:05:34,410 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2216 | Iter Mean Loss 5.2216
2020-11-05 19:05:34,418 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3708 | Iter Mean Loss 3.2962
2020-11-05 19:05:34,426 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0188 | Iter Mean Loss 3.8704
2020-11-05 19:05:34,434 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 3.9764
2020-11-05 19:05:34,442 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4915 | Iter Mean Loss 3.6794
2020-11-05 19:05:34,444 - root - INFO - Evaluate: Epoch 0821 | NDCG 0.2817 | MSE 0.3217
2020-11-05 19:05:34,453 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2185 | Iter Mean Loss 5.2185
2020-11-05 19:05:34,461 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3694 | Iter Mean Loss 3.2940
2020-11-05 19:05:34,470 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0128 | Iter Mean Loss 3.8669
2020-11-05 19:05:34,477 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2893 | Iter Mean Loss 3.9725
2020-11-05 19:05:34,486 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4879 | Iter Mean Loss 3.6756
2020-11-05 19:05:34,488 - root - INFO - Evaluate: Epoch 0822 | NDCG 0.2817 | MSE 0.3218
2020-11-05 19:05:34,497 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2155 | Iter Mean Loss 5.2155
2020-11-05 19:05:34,505 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3679 | Iter Mean Loss 3.2917
2020-11-05 19:05:34,513 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0067 | Iter Mean Loss 3.8634
2020-11-05 19:05:34,521 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2840 | Iter Mean Loss 3.9686
2020-11-05 19:05:34,530 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4843 | Iter Mean Loss 3.6717
2020-11-05 19:05:34,532 - root - INFO - Evaluate: Epoch 0823 | NDCG 0.2817 | MSE 0.3218
2020-11-05 19:05:34,541 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2125 | Iter Mean Loss 5.2125
2020-11-05 19:05:34,549 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3665 | Iter Mean Loss 3.2895
2020-11-05 19:05:34,557 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0007 | Iter Mean Loss 3.8599
2020-11-05 19:05:34,564 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 3.9646
2020-11-05 19:05:34,572 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4808 | Iter Mean Loss 3.6679
2020-11-05 19:05:34,574 - root - INFO - Evaluate: Epoch 0824 | NDCG 0.2817 | MSE 0.3218
2020-11-05 19:05:34,582 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2095 | Iter Mean Loss 5.2095
2020-11-05 19:05:34,589 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3651 | Iter Mean Loss 3.2873
2020-11-05 19:05:34,597 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9947 | Iter Mean Loss 3.8564
2020-11-05 19:05:34,604 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2735 | Iter Mean Loss 3.9607
2020-11-05 19:05:34,612 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4772 | Iter Mean Loss 3.6640
2020-11-05 19:05:34,614 - root - INFO - Evaluate: Epoch 0825 | NDCG 0.2817 | MSE 0.3219
2020-11-05 19:05:34,622 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2065 | Iter Mean Loss 5.2065
2020-11-05 19:05:34,631 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3636 | Iter Mean Loss 3.2851
2020-11-05 19:05:34,640 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9887 | Iter Mean Loss 3.8529
2020-11-05 19:05:34,648 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2683 | Iter Mean Loss 3.9568
2020-11-05 19:05:34,657 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4737 | Iter Mean Loss 3.6602
2020-11-05 19:05:34,660 - root - INFO - Evaluate: Epoch 0826 | NDCG 0.2817 | MSE 0.3219
2020-11-05 19:05:34,670 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2035 | Iter Mean Loss 5.2035
2020-11-05 19:05:34,680 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3622 | Iter Mean Loss 3.2828
2020-11-05 19:05:34,688 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9827 | Iter Mean Loss 3.8495
2020-11-05 19:05:34,697 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 3.9529
2020-11-05 19:05:34,706 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4701 | Iter Mean Loss 3.6563
2020-11-05 19:05:34,708 - root - INFO - Evaluate: Epoch 0827 | NDCG 0.2817 | MSE 0.3219
2020-11-05 19:05:34,718 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2005 | Iter Mean Loss 5.2005
2020-11-05 19:05:34,727 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3608 | Iter Mean Loss 3.2806
2020-11-05 19:05:34,736 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9768 | Iter Mean Loss 3.8460
2020-11-05 19:05:34,744 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2579 | Iter Mean Loss 3.9490
2020-11-05 19:05:34,753 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4666 | Iter Mean Loss 3.6525
2020-11-05 19:05:34,755 - root - INFO - Evaluate: Epoch 0828 | NDCG 0.2817 | MSE 0.3220
2020-11-05 19:05:34,763 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1975 | Iter Mean Loss 5.1975
2020-11-05 19:05:34,771 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 3.2784
2020-11-05 19:05:34,779 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9708 | Iter Mean Loss 3.8426
2020-11-05 19:05:34,787 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2527 | Iter Mean Loss 3.9451
2020-11-05 19:05:34,794 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4631 | Iter Mean Loss 3.6487
2020-11-05 19:05:34,797 - root - INFO - Evaluate: Epoch 0829 | NDCG 0.2817 | MSE 0.3220
2020-11-05 19:05:34,805 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1945 | Iter Mean Loss 5.1945
2020-11-05 19:05:34,813 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3580 | Iter Mean Loss 3.2762
2020-11-05 19:05:34,821 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9649 | Iter Mean Loss 3.8391
2020-11-05 19:05:34,829 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2475 | Iter Mean Loss 3.9412
2020-11-05 19:05:34,837 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4596 | Iter Mean Loss 3.6449
2020-11-05 19:05:34,839 - root - INFO - Evaluate: Epoch 0830 | NDCG 0.2817 | MSE 0.3221
2020-11-05 19:05:34,849 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1915 | Iter Mean Loss 5.1915
2020-11-05 19:05:34,857 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3566 | Iter Mean Loss 3.2740
2020-11-05 19:05:34,865 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 3.8357
2020-11-05 19:05:34,874 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2423 | Iter Mean Loss 3.9373
2020-11-05 19:05:34,884 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4561 | Iter Mean Loss 3.6411
2020-11-05 19:05:34,886 - root - INFO - Evaluate: Epoch 0831 | NDCG 0.2817 | MSE 0.3221
2020-11-05 19:05:34,895 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1885 | Iter Mean Loss 5.1885
2020-11-05 19:05:34,905 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3552 | Iter Mean Loss 3.2718
2020-11-05 19:05:34,913 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9530 | Iter Mean Loss 3.8322
2020-11-05 19:05:34,922 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2372 | Iter Mean Loss 3.9335
2020-11-05 19:05:34,930 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4527 | Iter Mean Loss 3.6373
2020-11-05 19:05:34,933 - root - INFO - Evaluate: Epoch 0832 | NDCG 0.2817 | MSE 0.3221
2020-11-05 19:05:34,942 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1855 | Iter Mean Loss 5.1855
2020-11-05 19:05:34,950 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3538 | Iter Mean Loss 3.2696
2020-11-05 19:05:34,958 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9471 | Iter Mean Loss 3.8288
2020-11-05 19:05:34,965 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2320 | Iter Mean Loss 3.9296
2020-11-05 19:05:34,973 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4492 | Iter Mean Loss 3.6335
2020-11-05 19:05:34,975 - root - INFO - Evaluate: Epoch 0833 | NDCG 0.2817 | MSE 0.3222
2020-11-05 19:05:34,983 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1825 | Iter Mean Loss 5.1825
2020-11-05 19:05:34,991 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3524 | Iter Mean Loss 3.2674
2020-11-05 19:05:34,999 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9412 | Iter Mean Loss 3.8254
2020-11-05 19:05:35,007 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2269 | Iter Mean Loss 3.9257
2020-11-05 19:05:35,015 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4457 | Iter Mean Loss 3.6297
2020-11-05 19:05:35,017 - root - INFO - Evaluate: Epoch 0834 | NDCG 0.2817 | MSE 0.3222
2020-11-05 19:05:35,025 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1795 | Iter Mean Loss 5.1795
2020-11-05 19:05:35,033 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3510 | Iter Mean Loss 3.2652
2020-11-05 19:05:35,041 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9353 | Iter Mean Loss 3.8219
2020-11-05 19:05:35,049 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 3.9219
2020-11-05 19:05:35,058 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4423 | Iter Mean Loss 3.6260
2020-11-05 19:05:35,060 - root - INFO - Evaluate: Epoch 0835 | NDCG 0.2817 | MSE 0.3222
2020-11-05 19:05:35,070 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1765 | Iter Mean Loss 5.1765
2020-11-05 19:05:35,078 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3496 | Iter Mean Loss 3.2631
2020-11-05 19:05:35,087 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9295 | Iter Mean Loss 3.8185
2020-11-05 19:05:35,095 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2166 | Iter Mean Loss 3.9181
2020-11-05 19:05:35,104 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4389 | Iter Mean Loss 3.6222
2020-11-05 19:05:35,107 - root - INFO - Evaluate: Epoch 0836 | NDCG 0.2817 | MSE 0.3223
2020-11-05 19:05:35,116 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1735 | Iter Mean Loss 5.1735
2020-11-05 19:05:35,125 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3482 | Iter Mean Loss 3.2609
2020-11-05 19:05:35,133 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 3.8151
2020-11-05 19:05:35,142 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2115 | Iter Mean Loss 3.9142
2020-11-05 19:05:35,150 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4354 | Iter Mean Loss 3.6185
2020-11-05 19:05:35,152 - root - INFO - Evaluate: Epoch 0837 | NDCG 0.2817 | MSE 0.3223
2020-11-05 19:05:35,161 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1706 | Iter Mean Loss 5.1706
2020-11-05 19:05:35,169 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3468 | Iter Mean Loss 3.2587
2020-11-05 19:05:35,178 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9178 | Iter Mean Loss 3.8117
2020-11-05 19:05:35,185 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2065 | Iter Mean Loss 3.9104
2020-11-05 19:05:35,193 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4320 | Iter Mean Loss 3.6147
2020-11-05 19:05:35,195 - root - INFO - Evaluate: Epoch 0838 | NDCG 0.2817 | MSE 0.3224
2020-11-05 19:05:35,204 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1676 | Iter Mean Loss 5.1676
2020-11-05 19:05:35,212 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3454 | Iter Mean Loss 3.2565
2020-11-05 19:05:35,220 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9119 | Iter Mean Loss 3.8083
2020-11-05 19:05:35,227 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2014 | Iter Mean Loss 3.9066
2020-11-05 19:05:35,235 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4286 | Iter Mean Loss 3.6110
2020-11-05 19:05:35,237 - root - INFO - Evaluate: Epoch 0839 | NDCG 0.2817 | MSE 0.3224
2020-11-05 19:05:35,245 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 5.1646
2020-11-05 19:05:35,254 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3441 | Iter Mean Loss 3.2543
2020-11-05 19:05:35,262 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9061 | Iter Mean Loss 3.8049
2020-11-05 19:05:35,271 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1963 | Iter Mean Loss 3.9028
2020-11-05 19:05:35,279 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4252 | Iter Mean Loss 3.6073
2020-11-05 19:05:35,281 - root - INFO - Evaluate: Epoch 0840 | NDCG 0.2817 | MSE 0.3224
2020-11-05 19:05:35,290 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1616 | Iter Mean Loss 5.1616
2020-11-05 19:05:35,298 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 3.2522
2020-11-05 19:05:35,307 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9003 | Iter Mean Loss 3.8015
2020-11-05 19:05:35,316 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1913 | Iter Mean Loss 3.8990
2020-11-05 19:05:35,326 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4218 | Iter Mean Loss 3.6035
2020-11-05 19:05:35,328 - root - INFO - Evaluate: Epoch 0841 | NDCG 0.2817 | MSE 0.3225
2020-11-05 19:05:35,338 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1586 | Iter Mean Loss 5.1586
2020-11-05 19:05:35,347 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 3.2500
2020-11-05 19:05:35,356 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8945 | Iter Mean Loss 3.7981
2020-11-05 19:05:35,365 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1862 | Iter Mean Loss 3.8952
2020-11-05 19:05:35,373 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4184 | Iter Mean Loss 3.5998
2020-11-05 19:05:35,375 - root - INFO - Evaluate: Epoch 0842 | NDCG 0.2817 | MSE 0.3225
2020-11-05 19:05:35,384 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1557 | Iter Mean Loss 5.1557
2020-11-05 19:05:35,391 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3400 | Iter Mean Loss 3.2478
2020-11-05 19:05:35,399 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8887 | Iter Mean Loss 3.7948
2020-11-05 19:05:35,406 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1812 | Iter Mean Loss 3.8914
2020-11-05 19:05:35,416 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4151 | Iter Mean Loss 3.5961
2020-11-05 19:05:35,419 - root - INFO - Evaluate: Epoch 0843 | NDCG 0.2817 | MSE 0.3225
2020-11-05 19:05:35,430 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1527 | Iter Mean Loss 5.1527
2020-11-05 19:05:35,439 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3386 | Iter Mean Loss 3.2456
2020-11-05 19:05:35,449 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8829 | Iter Mean Loss 3.7914
2020-11-05 19:05:35,459 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1761 | Iter Mean Loss 3.8876
2020-11-05 19:05:35,469 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4117 | Iter Mean Loss 3.5924
2020-11-05 19:05:35,471 - root - INFO - Evaluate: Epoch 0844 | NDCG 0.2817 | MSE 0.3226
2020-11-05 19:05:35,483 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1497 | Iter Mean Loss 5.1497
2020-11-05 19:05:35,493 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3372 | Iter Mean Loss 3.2435
2020-11-05 19:05:35,502 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8771 | Iter Mean Loss 3.7880
2020-11-05 19:05:35,511 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1711 | Iter Mean Loss 3.8838
2020-11-05 19:05:35,519 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4084 | Iter Mean Loss 3.5887
2020-11-05 19:05:35,522 - root - INFO - Evaluate: Epoch 0845 | NDCG 0.2817 | MSE 0.3226
2020-11-05 19:05:35,532 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1467 | Iter Mean Loss 5.1467
2020-11-05 19:05:35,545 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3359 | Iter Mean Loss 3.2413
2020-11-05 19:05:35,554 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8713 | Iter Mean Loss 3.7846
2020-11-05 19:05:35,563 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1661 | Iter Mean Loss 3.8800
2020-11-05 19:05:35,572 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4050 | Iter Mean Loss 3.5850
2020-11-05 19:05:35,575 - root - INFO - Evaluate: Epoch 0846 | NDCG 0.2817 | MSE 0.3227
2020-11-05 19:05:35,583 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1438 | Iter Mean Loss 5.1438
2020-11-05 19:05:35,592 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3345 | Iter Mean Loss 3.2391
2020-11-05 19:05:35,601 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8656 | Iter Mean Loss 3.7813
2020-11-05 19:05:35,609 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1611 | Iter Mean Loss 3.8762
2020-11-05 19:05:35,617 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4017 | Iter Mean Loss 3.5813
2020-11-05 19:05:35,619 - root - INFO - Evaluate: Epoch 0847 | NDCG 0.2817 | MSE 0.3227
2020-11-05 19:05:35,627 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1408 | Iter Mean Loss 5.1408
2020-11-05 19:05:35,636 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3332 | Iter Mean Loss 3.2370
2020-11-05 19:05:35,644 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8598 | Iter Mean Loss 3.7779
2020-11-05 19:05:35,652 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1561 | Iter Mean Loss 3.8725
2020-11-05 19:05:35,660 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3983 | Iter Mean Loss 3.5777
2020-11-05 19:05:35,663 - root - INFO - Evaluate: Epoch 0848 | NDCG 0.2817 | MSE 0.3227
2020-11-05 19:05:35,672 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1378 | Iter Mean Loss 5.1378
2020-11-05 19:05:35,681 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3318 | Iter Mean Loss 3.2348
2020-11-05 19:05:35,690 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8541 | Iter Mean Loss 3.7746
2020-11-05 19:05:35,699 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1512 | Iter Mean Loss 3.8687
2020-11-05 19:05:35,707 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3950 | Iter Mean Loss 3.5740
2020-11-05 19:05:35,710 - root - INFO - Evaluate: Epoch 0849 | NDCG 0.2817 | MSE 0.3228
2020-11-05 19:05:35,720 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1348 | Iter Mean Loss 5.1348
2020-11-05 19:05:35,728 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3305 | Iter Mean Loss 3.2327
2020-11-05 19:05:35,737 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8484 | Iter Mean Loss 3.7712
2020-11-05 19:05:35,744 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1462 | Iter Mean Loss 3.8650
2020-11-05 19:05:35,753 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3917 | Iter Mean Loss 3.5703
2020-11-05 19:05:35,756 - root - INFO - Evaluate: Epoch 0850 | NDCG 0.2817 | MSE 0.3228
2020-11-05 19:05:35,764 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1319 | Iter Mean Loss 5.1319
2020-11-05 19:05:35,772 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3292 | Iter Mean Loss 3.2305
2020-11-05 19:05:35,779 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8426 | Iter Mean Loss 3.7679
2020-11-05 19:05:35,787 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1413 | Iter Mean Loss 3.8612
2020-11-05 19:05:35,795 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3884 | Iter Mean Loss 3.5667
2020-11-05 19:05:35,797 - root - INFO - Evaluate: Epoch 0851 | NDCG 0.2817 | MSE 0.3229
2020-11-05 19:05:35,806 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1289 | Iter Mean Loss 5.1289
2020-11-05 19:05:35,815 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3278 | Iter Mean Loss 3.2284
2020-11-05 19:05:35,823 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8369 | Iter Mean Loss 3.7645
2020-11-05 19:05:35,831 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1363 | Iter Mean Loss 3.8575
2020-11-05 19:05:35,838 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3851 | Iter Mean Loss 3.5630
2020-11-05 19:05:35,841 - root - INFO - Evaluate: Epoch 0852 | NDCG 0.2817 | MSE 0.3229
2020-11-05 19:05:35,849 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1259 | Iter Mean Loss 5.1259
2020-11-05 19:05:35,857 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 3.2262
2020-11-05 19:05:35,865 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 3.7612
2020-11-05 19:05:35,873 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1314 | Iter Mean Loss 3.8538
2020-11-05 19:05:35,881 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3818 | Iter Mean Loss 3.5594
2020-11-05 19:05:35,883 - root - INFO - Evaluate: Epoch 0853 | NDCG 0.2817 | MSE 0.3229
2020-11-05 19:05:35,892 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1230 | Iter Mean Loss 5.1230
2020-11-05 19:05:35,901 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 3.2240
2020-11-05 19:05:35,909 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8255 | Iter Mean Loss 3.7579
2020-11-05 19:05:35,918 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1265 | Iter Mean Loss 3.8500
2020-11-05 19:05:35,926 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3786 | Iter Mean Loss 3.5557
2020-11-05 19:05:35,928 - root - INFO - Evaluate: Epoch 0854 | NDCG 0.2817 | MSE 0.3230
2020-11-05 19:05:35,937 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1200 | Iter Mean Loss 5.1200
2020-11-05 19:05:35,945 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3238 | Iter Mean Loss 3.2219
2020-11-05 19:05:35,953 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8199 | Iter Mean Loss 3.7546
2020-11-05 19:05:35,961 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1216 | Iter Mean Loss 3.8463
2020-11-05 19:05:35,970 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3753 | Iter Mean Loss 3.5521
2020-11-05 19:05:35,972 - root - INFO - Evaluate: Epoch 0855 | NDCG 0.2817 | MSE 0.3230
2020-11-05 19:05:35,980 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1170 | Iter Mean Loss 5.1170
2020-11-05 19:05:35,989 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3225 | Iter Mean Loss 3.2197
2020-11-05 19:05:35,996 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8142 | Iter Mean Loss 3.7512
2020-11-05 19:05:36,004 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1166 | Iter Mean Loss 3.8426
2020-11-05 19:05:36,012 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3720 | Iter Mean Loss 3.5485
2020-11-05 19:05:36,014 - root - INFO - Evaluate: Epoch 0856 | NDCG 0.2817 | MSE 0.3230
2020-11-05 19:05:36,022 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1140 | Iter Mean Loss 5.1140
2020-11-05 19:05:36,030 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3211 | Iter Mean Loss 3.2176
2020-11-05 19:05:36,037 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8085 | Iter Mean Loss 3.7479
2020-11-05 19:05:36,045 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1118 | Iter Mean Loss 3.8389
2020-11-05 19:05:36,052 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3688 | Iter Mean Loss 3.5448
2020-11-05 19:05:36,054 - root - INFO - Evaluate: Epoch 0857 | NDCG 0.2817 | MSE 0.3231
2020-11-05 19:05:36,063 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1111 | Iter Mean Loss 5.1111
2020-11-05 19:05:36,072 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3198 | Iter Mean Loss 3.2154
2020-11-05 19:05:36,080 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8029 | Iter Mean Loss 3.7446
2020-11-05 19:05:36,089 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1069 | Iter Mean Loss 3.8352
2020-11-05 19:05:36,098 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3655 | Iter Mean Loss 3.5412
2020-11-05 19:05:36,100 - root - INFO - Evaluate: Epoch 0858 | NDCG 0.2817 | MSE 0.3231
2020-11-05 19:05:36,110 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 5.1081
2020-11-05 19:05:36,118 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3185 | Iter Mean Loss 3.2133
2020-11-05 19:05:36,127 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7973 | Iter Mean Loss 3.7413
2020-11-05 19:05:36,136 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1020 | Iter Mean Loss 3.8315
2020-11-05 19:05:36,145 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3623 | Iter Mean Loss 3.5376
2020-11-05 19:05:36,147 - root - INFO - Evaluate: Epoch 0859 | NDCG 0.2817 | MSE 0.3232
2020-11-05 19:05:36,155 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1051 | Iter Mean Loss 5.1051
2020-11-05 19:05:36,164 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3172 | Iter Mean Loss 3.2111
2020-11-05 19:05:36,172 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7916 | Iter Mean Loss 3.7380
2020-11-05 19:05:36,180 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0971 | Iter Mean Loss 3.8278
2020-11-05 19:05:36,188 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3591 | Iter Mean Loss 3.5340
2020-11-05 19:05:36,190 - root - INFO - Evaluate: Epoch 0860 | NDCG 0.2817 | MSE 0.3232
2020-11-05 19:05:36,198 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1021 | Iter Mean Loss 5.1021
2020-11-05 19:05:36,206 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3158 | Iter Mean Loss 3.2090
2020-11-05 19:05:36,214 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7860 | Iter Mean Loss 3.7347
2020-11-05 19:05:36,222 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0923 | Iter Mean Loss 3.8241
2020-11-05 19:05:36,229 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3558 | Iter Mean Loss 3.5304
2020-11-05 19:05:36,231 - root - INFO - Evaluate: Epoch 0861 | NDCG 0.2817 | MSE 0.3232
2020-11-05 19:05:36,240 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0992 | Iter Mean Loss 5.0992
2020-11-05 19:05:36,247 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3145 | Iter Mean Loss 3.2068
2020-11-05 19:05:36,255 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7804 | Iter Mean Loss 3.7314
2020-11-05 19:05:36,263 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0874 | Iter Mean Loss 3.8204
2020-11-05 19:05:36,271 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3526 | Iter Mean Loss 3.5268
2020-11-05 19:05:36,274 - root - INFO - Evaluate: Epoch 0862 | NDCG 0.2817 | MSE 0.3233
2020-11-05 19:05:36,282 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0962 | Iter Mean Loss 5.0962
2020-11-05 19:05:36,290 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3132 | Iter Mean Loss 3.2047
2020-11-05 19:05:36,299 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7748 | Iter Mean Loss 3.7281
2020-11-05 19:05:36,307 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0826 | Iter Mean Loss 3.8167
2020-11-05 19:05:36,317 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3494 | Iter Mean Loss 3.5232
2020-11-05 19:05:36,319 - root - INFO - Evaluate: Epoch 0863 | NDCG 0.2817 | MSE 0.3233
2020-11-05 19:05:36,328 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0932 | Iter Mean Loss 5.0932
2020-11-05 19:05:36,337 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 3.2025
2020-11-05 19:05:36,345 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7692 | Iter Mean Loss 3.7248
2020-11-05 19:05:36,354 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0778 | Iter Mean Loss 3.8130
2020-11-05 19:05:36,362 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3462 | Iter Mean Loss 3.5197
2020-11-05 19:05:36,365 - root - INFO - Evaluate: Epoch 0864 | NDCG 0.2817 | MSE 0.3234
2020-11-05 19:05:36,374 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0902 | Iter Mean Loss 5.0902
2020-11-05 19:05:36,382 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3106 | Iter Mean Loss 3.2004
2020-11-05 19:05:36,390 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7636 | Iter Mean Loss 3.7215
2020-11-05 19:05:36,398 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0730 | Iter Mean Loss 3.8093
2020-11-05 19:05:36,406 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3430 | Iter Mean Loss 3.5161
2020-11-05 19:05:36,408 - root - INFO - Evaluate: Epoch 0865 | NDCG 0.2817 | MSE 0.3234
2020-11-05 19:05:36,417 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0872 | Iter Mean Loss 5.0872
2020-11-05 19:05:36,425 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3093 | Iter Mean Loss 3.1982
2020-11-05 19:05:36,433 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7580 | Iter Mean Loss 3.7182
2020-11-05 19:05:36,440 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0682 | Iter Mean Loss 3.8057
2020-11-05 19:05:36,448 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3398 | Iter Mean Loss 3.5125
2020-11-05 19:05:36,450 - root - INFO - Evaluate: Epoch 0866 | NDCG 0.2817 | MSE 0.3235
2020-11-05 19:05:36,458 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0843 | Iter Mean Loss 5.0843
2020-11-05 19:05:36,466 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3079 | Iter Mean Loss 3.1961
2020-11-05 19:05:36,473 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7525 | Iter Mean Loss 3.7149
2020-11-05 19:05:36,481 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0634 | Iter Mean Loss 3.8020
2020-11-05 19:05:36,489 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3366 | Iter Mean Loss 3.5089
2020-11-05 19:05:36,492 - root - INFO - Evaluate: Epoch 0867 | NDCG 0.2817 | MSE 0.3235
2020-11-05 19:05:36,501 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0813 | Iter Mean Loss 5.0813
2020-11-05 19:05:36,509 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3066 | Iter Mean Loss 3.1939
2020-11-05 19:05:36,517 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7469 | Iter Mean Loss 3.7116
2020-11-05 19:05:36,526 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0586 | Iter Mean Loss 3.7983
2020-11-05 19:05:36,534 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 3.5054
2020-11-05 19:05:36,537 - root - INFO - Evaluate: Epoch 0868 | NDCG 0.2817 | MSE 0.3235
2020-11-05 19:05:36,546 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0783 | Iter Mean Loss 5.0783
2020-11-05 19:05:36,555 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3053 | Iter Mean Loss 3.1918
2020-11-05 19:05:36,563 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 3.7083
2020-11-05 19:05:36,571 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0538 | Iter Mean Loss 3.7947
2020-11-05 19:05:36,580 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3303 | Iter Mean Loss 3.5018
2020-11-05 19:05:36,582 - root - INFO - Evaluate: Epoch 0869 | NDCG 0.2817 | MSE 0.3236
2020-11-05 19:05:36,591 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0753 | Iter Mean Loss 5.0753
2020-11-05 19:05:36,599 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3040 | Iter Mean Loss 3.1896
2020-11-05 19:05:36,607 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7358 | Iter Mean Loss 3.7050
2020-11-05 19:05:36,614 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0490 | Iter Mean Loss 3.7910
2020-11-05 19:05:36,622 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3271 | Iter Mean Loss 3.4983
2020-11-05 19:05:36,624 - root - INFO - Evaluate: Epoch 0870 | NDCG 0.2817 | MSE 0.3236
2020-11-05 19:05:36,633 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0723 | Iter Mean Loss 5.0723
2020-11-05 19:05:36,640 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3027 | Iter Mean Loss 3.1875
2020-11-05 19:05:36,648 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7303 | Iter Mean Loss 3.7018
2020-11-05 19:05:36,656 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0443 | Iter Mean Loss 3.7874
2020-11-05 19:05:36,664 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3240 | Iter Mean Loss 3.4947
2020-11-05 19:05:36,666 - root - INFO - Evaluate: Epoch 0871 | NDCG 0.2817 | MSE 0.3237
2020-11-05 19:05:36,674 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0693 | Iter Mean Loss 5.0693
2020-11-05 19:05:36,682 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3014 | Iter Mean Loss 3.1853
2020-11-05 19:05:36,691 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7248 | Iter Mean Loss 3.6985
2020-11-05 19:05:36,699 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0395 | Iter Mean Loss 3.7837
2020-11-05 19:05:36,708 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3208 | Iter Mean Loss 3.4912
2020-11-05 19:05:36,710 - root - INFO - Evaluate: Epoch 0872 | NDCG 0.2817 | MSE 0.3237
2020-11-05 19:05:36,721 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0663 | Iter Mean Loss 5.0663
2020-11-05 19:05:36,729 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3001 | Iter Mean Loss 3.1832
2020-11-05 19:05:36,738 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7193 | Iter Mean Loss 3.6952
2020-11-05 19:05:36,746 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 3.7801
2020-11-05 19:05:36,755 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3177 | Iter Mean Loss 3.4876
2020-11-05 19:05:36,757 - root - INFO - Evaluate: Epoch 0873 | NDCG 0.2817 | MSE 0.3237
2020-11-05 19:05:36,766 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0633 | Iter Mean Loss 5.0633
2020-11-05 19:05:36,774 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 3.1810
2020-11-05 19:05:36,783 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7138 | Iter Mean Loss 3.6919
2020-11-05 19:05:36,791 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0300 | Iter Mean Loss 3.7765
2020-11-05 19:05:36,799 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3146 | Iter Mean Loss 3.4841
2020-11-05 19:05:36,801 - root - INFO - Evaluate: Epoch 0874 | NDCG 0.2817 | MSE 0.3238
2020-11-05 19:05:36,811 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0603 | Iter Mean Loss 5.0603
2020-11-05 19:05:36,819 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2975 | Iter Mean Loss 3.1789
2020-11-05 19:05:36,826 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7083 | Iter Mean Loss 3.6887
2020-11-05 19:05:36,834 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0253 | Iter Mean Loss 3.7728
2020-11-05 19:05:36,841 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3114 | Iter Mean Loss 3.4806
2020-11-05 19:05:36,843 - root - INFO - Evaluate: Epoch 0875 | NDCG 0.2817 | MSE 0.3238
2020-11-05 19:05:36,852 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0573 | Iter Mean Loss 5.0573
2020-11-05 19:05:36,859 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2961 | Iter Mean Loss 3.1767
2020-11-05 19:05:36,867 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7028 | Iter Mean Loss 3.6854
2020-11-05 19:05:36,875 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0206 | Iter Mean Loss 3.7692
2020-11-05 19:05:36,882 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3083 | Iter Mean Loss 3.4770
2020-11-05 19:05:36,885 - root - INFO - Evaluate: Epoch 0876 | NDCG 0.2817 | MSE 0.3239
2020-11-05 19:05:36,894 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0543 | Iter Mean Loss 5.0543
2020-11-05 19:05:36,902 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2948 | Iter Mean Loss 3.1746
2020-11-05 19:05:36,911 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6973 | Iter Mean Loss 3.6821
2020-11-05 19:05:36,919 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0159 | Iter Mean Loss 3.7656
2020-11-05 19:05:36,927 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3052 | Iter Mean Loss 3.4735
2020-11-05 19:05:36,929 - root - INFO - Evaluate: Epoch 0877 | NDCG 0.2817 | MSE 0.3239
2020-11-05 19:05:36,939 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0513 | Iter Mean Loss 5.0513
2020-11-05 19:05:36,947 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2935 | Iter Mean Loss 3.1724
2020-11-05 19:05:36,955 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6918 | Iter Mean Loss 3.6789
2020-11-05 19:05:36,963 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0112 | Iter Mean Loss 3.7620
2020-11-05 19:05:36,972 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3021 | Iter Mean Loss 3.4700
2020-11-05 19:05:36,974 - root - INFO - Evaluate: Epoch 0878 | NDCG 0.2817 | MSE 0.3239
2020-11-05 19:05:36,982 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0483 | Iter Mean Loss 5.0483
2020-11-05 19:05:36,991 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2922 | Iter Mean Loss 3.1703
2020-11-05 19:05:36,999 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6864 | Iter Mean Loss 3.6756
2020-11-05 19:05:37,006 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0065 | Iter Mean Loss 3.7583
2020-11-05 19:05:37,014 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2990 | Iter Mean Loss 3.4665
2020-11-05 19:05:37,016 - root - INFO - Evaluate: Epoch 0879 | NDCG 0.2817 | MSE 0.3240
2020-11-05 19:05:37,024 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0453 | Iter Mean Loss 5.0453
2020-11-05 19:05:37,032 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2909 | Iter Mean Loss 3.1681
2020-11-05 19:05:37,041 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6809 | Iter Mean Loss 3.6724
2020-11-05 19:05:37,048 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0018 | Iter Mean Loss 3.7547
2020-11-05 19:05:37,056 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2959 | Iter Mean Loss 3.4630
2020-11-05 19:05:37,058 - root - INFO - Evaluate: Epoch 0880 | NDCG 0.2817 | MSE 0.3240
2020-11-05 19:05:37,066 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0423 | Iter Mean Loss 5.0423
2020-11-05 19:05:37,074 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2896 | Iter Mean Loss 3.1659
2020-11-05 19:05:37,082 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 3.6691
2020-11-05 19:05:37,090 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9971 | Iter Mean Loss 3.7511
2020-11-05 19:05:37,098 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2928 | Iter Mean Loss 3.4594
2020-11-05 19:05:37,101 - root - INFO - Evaluate: Epoch 0881 | NDCG 0.2817 | MSE 0.3241
2020-11-05 19:05:37,110 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0392 | Iter Mean Loss 5.0392
2020-11-05 19:05:37,119 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2883 | Iter Mean Loss 3.1638
2020-11-05 19:05:37,128 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6700 | Iter Mean Loss 3.6659
2020-11-05 19:05:37,136 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9924 | Iter Mean Loss 3.7475
2020-11-05 19:05:37,145 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2897 | Iter Mean Loss 3.4559
2020-11-05 19:05:37,147 - root - INFO - Evaluate: Epoch 0882 | NDCG 0.2817 | MSE 0.3241
2020-11-05 19:05:37,156 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0362 | Iter Mean Loss 5.0362
2020-11-05 19:05:37,165 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 3.1616
2020-11-05 19:05:37,173 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6646 | Iter Mean Loss 3.6626
2020-11-05 19:05:37,182 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9878 | Iter Mean Loss 3.7439
2020-11-05 19:05:37,190 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2866 | Iter Mean Loss 3.4524
2020-11-05 19:05:37,192 - root - INFO - Evaluate: Epoch 0883 | NDCG 0.2817 | MSE 0.3242
2020-11-05 19:05:37,201 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0332 | Iter Mean Loss 5.0332
2020-11-05 19:05:37,209 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2857 | Iter Mean Loss 3.1594
2020-11-05 19:05:37,217 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6592 | Iter Mean Loss 3.6593
2020-11-05 19:05:37,224 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9831 | Iter Mean Loss 3.7403
2020-11-05 19:05:37,232 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2836 | Iter Mean Loss 3.4489
2020-11-05 19:05:37,234 - root - INFO - Evaluate: Epoch 0884 | NDCG 0.2817 | MSE 0.3242
2020-11-05 19:05:37,242 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0301 | Iter Mean Loss 5.0301
2020-11-05 19:05:37,250 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2844 | Iter Mean Loss 3.1573
2020-11-05 19:05:37,258 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 3.6561
2020-11-05 19:05:37,266 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 3.7367
2020-11-05 19:05:37,273 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2805 | Iter Mean Loss 3.4455
2020-11-05 19:05:37,275 - root - INFO - Evaluate: Epoch 0885 | NDCG 0.2817 | MSE 0.3242
2020-11-05 19:05:37,284 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0271 | Iter Mean Loss 5.0271
2020-11-05 19:05:37,292 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2831 | Iter Mean Loss 3.1551
2020-11-05 19:05:37,300 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6483 | Iter Mean Loss 3.6528
2020-11-05 19:05:37,308 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9738 | Iter Mean Loss 3.7331
2020-11-05 19:05:37,318 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2774 | Iter Mean Loss 3.4420
2020-11-05 19:05:37,320 - root - INFO - Evaluate: Epoch 0886 | NDCG 0.2817 | MSE 0.3243
2020-11-05 19:05:37,330 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0241 | Iter Mean Loss 5.0241
2020-11-05 19:05:37,339 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2818 | Iter Mean Loss 3.1529
2020-11-05 19:05:37,347 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6429 | Iter Mean Loss 3.6496
2020-11-05 19:05:37,355 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 3.7295
2020-11-05 19:05:37,364 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2744 | Iter Mean Loss 3.4385
2020-11-05 19:05:37,366 - root - INFO - Evaluate: Epoch 0887 | NDCG 0.2817 | MSE 0.3243
2020-11-05 19:05:37,375 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0210 | Iter Mean Loss 5.0210
2020-11-05 19:05:37,384 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2805 | Iter Mean Loss 3.1507
2020-11-05 19:05:37,392 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6375 | Iter Mean Loss 3.6463
2020-11-05 19:05:37,400 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 3.7259
2020-11-05 19:05:37,408 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2713 | Iter Mean Loss 3.4350
2020-11-05 19:05:37,410 - root - INFO - Evaluate: Epoch 0888 | NDCG 0.2817 | MSE 0.3244
2020-11-05 19:05:37,418 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0180 | Iter Mean Loss 5.0180
2020-11-05 19:05:37,426 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2791 | Iter Mean Loss 3.1486
2020-11-05 19:05:37,434 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6322 | Iter Mean Loss 3.6431
2020-11-05 19:05:37,441 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9600 | Iter Mean Loss 3.7223
2020-11-05 19:05:37,449 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2683 | Iter Mean Loss 3.4315
2020-11-05 19:05:37,451 - root - INFO - Evaluate: Epoch 0889 | NDCG 0.2817 | MSE 0.3244
2020-11-05 19:05:37,459 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0149 | Iter Mean Loss 5.0149
2020-11-05 19:05:37,467 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2778 | Iter Mean Loss 3.1464
2020-11-05 19:05:37,474 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6268 | Iter Mean Loss 3.6398
2020-11-05 19:05:37,482 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9554 | Iter Mean Loss 3.7187
2020-11-05 19:05:37,489 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2652 | Iter Mean Loss 3.4280
2020-11-05 19:05:37,492 - root - INFO - Evaluate: Epoch 0890 | NDCG 0.2817 | MSE 0.3244
2020-11-05 19:05:37,501 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0119 | Iter Mean Loss 5.0119
2020-11-05 19:05:37,509 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2765 | Iter Mean Loss 3.1442
2020-11-05 19:05:37,517 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6214 | Iter Mean Loss 3.6366
2020-11-05 19:05:37,525 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9508 | Iter Mean Loss 3.7151
2020-11-05 19:05:37,533 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2622 | Iter Mean Loss 3.4246
2020-11-05 19:05:37,537 - root - INFO - Evaluate: Epoch 0891 | NDCG 0.2817 | MSE 0.3245
2020-11-05 19:05:37,545 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0088 | Iter Mean Loss 5.0088
2020-11-05 19:05:37,555 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2752 | Iter Mean Loss 3.1420
2020-11-05 19:05:37,563 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6160 | Iter Mean Loss 3.6334
2020-11-05 19:05:37,571 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9462 | Iter Mean Loss 3.7116
2020-11-05 19:05:37,580 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2592 | Iter Mean Loss 3.4211
2020-11-05 19:05:37,582 - root - INFO - Evaluate: Epoch 0892 | NDCG 0.2817 | MSE 0.3245
2020-11-05 19:05:37,592 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0057 | Iter Mean Loss 5.0057
2020-11-05 19:05:37,600 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2739 | Iter Mean Loss 3.1398
2020-11-05 19:05:37,609 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6107 | Iter Mean Loss 3.6301
2020-11-05 19:05:37,617 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 3.7080
2020-11-05 19:05:37,625 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2561 | Iter Mean Loss 3.4176
2020-11-05 19:05:37,628 - root - INFO - Evaluate: Epoch 0893 | NDCG 0.2817 | MSE 0.3246
2020-11-05 19:05:37,636 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0027 | Iter Mean Loss 5.0027
2020-11-05 19:05:37,644 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2726 | Iter Mean Loss 3.1376
2020-11-05 19:05:37,652 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6053 | Iter Mean Loss 3.6269
2020-11-05 19:05:37,660 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 3.7044
2020-11-05 19:05:37,668 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2531 | Iter Mean Loss 3.4141
2020-11-05 19:05:37,670 - root - INFO - Evaluate: Epoch 0894 | NDCG 0.2817 | MSE 0.3246
2020-11-05 19:05:37,678 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9996 | Iter Mean Loss 4.9996
2020-11-05 19:05:37,686 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2713 | Iter Mean Loss 3.1354
2020-11-05 19:05:37,694 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6000 | Iter Mean Loss 3.6236
2020-11-05 19:05:37,702 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9324 | Iter Mean Loss 3.7008
2020-11-05 19:05:37,711 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2501 | Iter Mean Loss 3.4107
2020-11-05 19:05:37,713 - root - INFO - Evaluate: Epoch 0895 | NDCG 0.2817 | MSE 0.3247
2020-11-05 19:05:37,723 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9965 | Iter Mean Loss 4.9965
2020-11-05 19:05:37,732 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2700 | Iter Mean Loss 3.1332
2020-11-05 19:05:37,741 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5947 | Iter Mean Loss 3.6204
2020-11-05 19:05:37,750 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9279 | Iter Mean Loss 3.6972
2020-11-05 19:05:37,758 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2471 | Iter Mean Loss 3.4072
2020-11-05 19:05:37,762 - root - INFO - Evaluate: Epoch 0896 | NDCG 0.2817 | MSE 0.3247
2020-11-05 19:05:37,770 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9934 | Iter Mean Loss 4.9934
2020-11-05 19:05:37,779 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2686 | Iter Mean Loss 3.1310
2020-11-05 19:05:37,789 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5893 | Iter Mean Loss 3.6171
2020-11-05 19:05:37,798 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9233 | Iter Mean Loss 3.6937
2020-11-05 19:05:37,806 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2441 | Iter Mean Loss 3.4038
2020-11-05 19:05:37,809 - root - INFO - Evaluate: Epoch 0897 | NDCG 0.2817 | MSE 0.3247
2020-11-05 19:05:37,818 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9903 | Iter Mean Loss 4.9903
2020-11-05 19:05:37,826 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2673 | Iter Mean Loss 3.1288
2020-11-05 19:05:37,834 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5840 | Iter Mean Loss 3.6139
2020-11-05 19:05:37,841 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9188 | Iter Mean Loss 3.6901
2020-11-05 19:05:37,849 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2411 | Iter Mean Loss 3.4003
2020-11-05 19:05:37,851 - root - INFO - Evaluate: Epoch 0898 | NDCG 0.2817 | MSE 0.3248
2020-11-05 19:05:37,860 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9872 | Iter Mean Loss 4.9872
2020-11-05 19:05:37,868 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 3.1266
2020-11-05 19:05:37,876 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5787 | Iter Mean Loss 3.6106
2020-11-05 19:05:37,883 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9142 | Iter Mean Loss 3.6865
2020-11-05 19:05:37,891 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2381 | Iter Mean Loss 3.3968
2020-11-05 19:05:37,893 - root - INFO - Evaluate: Epoch 0899 | NDCG 0.2817 | MSE 0.3248
2020-11-05 19:05:37,901 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9841 | Iter Mean Loss 4.9841
2020-11-05 19:05:37,910 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2647 | Iter Mean Loss 3.1244
2020-11-05 19:05:37,918 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5734 | Iter Mean Loss 3.6074
2020-11-05 19:05:37,926 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9097 | Iter Mean Loss 3.6830
2020-11-05 19:05:37,935 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2351 | Iter Mean Loss 3.3934
2020-11-05 19:05:37,937 - root - INFO - Evaluate: Epoch 0900 | NDCG 0.2817 | MSE 0.3249
2020-11-05 19:05:37,947 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9810 | Iter Mean Loss 4.9810
2020-11-05 19:05:37,955 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2634 | Iter Mean Loss 3.1222
2020-11-05 19:05:37,963 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5681 | Iter Mean Loss 3.6041
2020-11-05 19:05:37,971 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9052 | Iter Mean Loss 3.6794
2020-11-05 19:05:37,980 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2321 | Iter Mean Loss 3.3899
2020-11-05 19:05:37,982 - root - INFO - Evaluate: Epoch 0901 | NDCG 0.2817 | MSE 0.3249
2020-11-05 19:05:37,991 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9778 | Iter Mean Loss 4.9778
2020-11-05 19:05:38,000 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2620 | Iter Mean Loss 3.1199
2020-11-05 19:05:38,008 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5628 | Iter Mean Loss 3.6009
2020-11-05 19:05:38,016 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9007 | Iter Mean Loss 3.6758
2020-11-05 19:05:38,024 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2291 | Iter Mean Loss 3.3865
2020-11-05 19:05:38,026 - root - INFO - Evaluate: Epoch 0902 | NDCG 0.2817 | MSE 0.3250
2020-11-05 19:05:38,035 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9747 | Iter Mean Loss 4.9747
2020-11-05 19:05:38,042 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2607 | Iter Mean Loss 3.1177
2020-11-05 19:05:38,050 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5575 | Iter Mean Loss 3.5976
2020-11-05 19:05:38,059 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8961 | Iter Mean Loss 3.6723
2020-11-05 19:05:38,072 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 3.3830
2020-11-05 19:05:38,075 - root - INFO - Evaluate: Epoch 0903 | NDCG 0.2817 | MSE 0.3250
2020-11-05 19:05:38,086 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9716 | Iter Mean Loss 4.9716
2020-11-05 19:05:38,097 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2594 | Iter Mean Loss 3.1155
2020-11-05 19:05:38,107 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5522 | Iter Mean Loss 3.5944
2020-11-05 19:05:38,118 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8916 | Iter Mean Loss 3.6687
2020-11-05 19:05:38,127 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2231 | Iter Mean Loss 3.3796
2020-11-05 19:05:38,130 - root - INFO - Evaluate: Epoch 0904 | NDCG 0.2817 | MSE 0.3250
2020-11-05 19:05:38,141 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9684 | Iter Mean Loss 4.9684
2020-11-05 19:05:38,151 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2581 | Iter Mean Loss 3.1132
2020-11-05 19:05:38,162 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5469 | Iter Mean Loss 3.5911
2020-11-05 19:05:38,171 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8871 | Iter Mean Loss 3.6651
2020-11-05 19:05:38,180 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2202 | Iter Mean Loss 3.3761
2020-11-05 19:05:38,182 - root - INFO - Evaluate: Epoch 0905 | NDCG 0.2817 | MSE 0.3251
2020-11-05 19:05:38,192 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9653 | Iter Mean Loss 4.9653
2020-11-05 19:05:38,200 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2567 | Iter Mean Loss 3.1110
2020-11-05 19:05:38,211 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5417 | Iter Mean Loss 3.5879
2020-11-05 19:05:38,221 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8826 | Iter Mean Loss 3.6616
2020-11-05 19:05:38,230 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2172 | Iter Mean Loss 3.3727
2020-11-05 19:05:38,232 - root - INFO - Evaluate: Epoch 0906 | NDCG 0.2817 | MSE 0.3251
2020-11-05 19:05:38,241 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9621 | Iter Mean Loss 4.9621
2020-11-05 19:05:38,249 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2554 | Iter Mean Loss 3.1088
2020-11-05 19:05:38,257 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5364 | Iter Mean Loss 3.5846
2020-11-05 19:05:38,265 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8782 | Iter Mean Loss 3.6580
2020-11-05 19:05:38,272 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2142 | Iter Mean Loss 3.3693
2020-11-05 19:05:38,274 - root - INFO - Evaluate: Epoch 0907 | NDCG 0.2817 | MSE 0.3252
2020-11-05 19:05:38,282 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 4.9590
2020-11-05 19:05:38,290 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2541 | Iter Mean Loss 3.1065
2020-11-05 19:05:38,298 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5311 | Iter Mean Loss 3.5814
2020-11-05 19:05:38,306 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 3.6545
2020-11-05 19:05:38,315 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2113 | Iter Mean Loss 3.3658
2020-11-05 19:05:38,318 - root - INFO - Evaluate: Epoch 0908 | NDCG 0.2817 | MSE 0.3252
2020-11-05 19:05:38,327 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9558 | Iter Mean Loss 4.9558
2020-11-05 19:05:38,336 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2527 | Iter Mean Loss 3.1043
2020-11-05 19:05:38,344 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5259 | Iter Mean Loss 3.5781
2020-11-05 19:05:38,353 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8692 | Iter Mean Loss 3.6509
2020-11-05 19:05:38,361 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2083 | Iter Mean Loss 3.3624
2020-11-05 19:05:38,364 - root - INFO - Evaluate: Epoch 0909 | NDCG 0.2817 | MSE 0.3253
2020-11-05 19:05:38,374 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9526 | Iter Mean Loss 4.9526
2020-11-05 19:05:38,383 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2514 | Iter Mean Loss 3.1020
2020-11-05 19:05:38,391 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5207 | Iter Mean Loss 3.5749
2020-11-05 19:05:38,399 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8647 | Iter Mean Loss 3.6473
2020-11-05 19:05:38,407 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2054 | Iter Mean Loss 3.3589
2020-11-05 19:05:38,410 - root - INFO - Evaluate: Epoch 0910 | NDCG 0.2817 | MSE 0.3253
2020-11-05 19:05:38,419 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9494 | Iter Mean Loss 4.9494
2020-11-05 19:05:38,428 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2500 | Iter Mean Loss 3.0997
2020-11-05 19:05:38,436 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5154 | Iter Mean Loss 3.5716
2020-11-05 19:05:38,444 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8603 | Iter Mean Loss 3.6438
2020-11-05 19:05:38,451 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2024 | Iter Mean Loss 3.3555
2020-11-05 19:05:38,454 - root - INFO - Evaluate: Epoch 0911 | NDCG 0.2817 | MSE 0.3254
2020-11-05 19:05:38,462 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9462 | Iter Mean Loss 4.9462
2020-11-05 19:05:38,470 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2487 | Iter Mean Loss 3.0975
2020-11-05 19:05:38,478 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 3.5684
2020-11-05 19:05:38,485 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8558 | Iter Mean Loss 3.6402
2020-11-05 19:05:38,493 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1995 | Iter Mean Loss 3.3521
2020-11-05 19:05:38,495 - root - INFO - Evaluate: Epoch 0912 | NDCG 0.2817 | MSE 0.3254
2020-11-05 19:05:38,504 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9430 | Iter Mean Loss 4.9430
2020-11-05 19:05:38,511 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2473 | Iter Mean Loss 3.0952
2020-11-05 19:05:38,519 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 3.5651
2020-11-05 19:05:38,528 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8514 | Iter Mean Loss 3.6367
2020-11-05 19:05:38,536 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1965 | Iter Mean Loss 3.3486
2020-11-05 19:05:38,538 - root - INFO - Evaluate: Epoch 0913 | NDCG 0.2817 | MSE 0.3254
2020-11-05 19:05:38,547 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9398 | Iter Mean Loss 4.9398
2020-11-05 19:05:38,556 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2460 | Iter Mean Loss 3.0929
2020-11-05 19:05:38,563 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4997 | Iter Mean Loss 3.5618
2020-11-05 19:05:38,572 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8469 | Iter Mean Loss 3.6331
2020-11-05 19:05:38,580 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1936 | Iter Mean Loss 3.3452
2020-11-05 19:05:38,584 - root - INFO - Evaluate: Epoch 0914 | NDCG 0.2817 | MSE 0.3255
2020-11-05 19:05:38,592 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9366 | Iter Mean Loss 4.9366
2020-11-05 19:05:38,601 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2446 | Iter Mean Loss 3.0906
2020-11-05 19:05:38,609 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4945 | Iter Mean Loss 3.5586
2020-11-05 19:05:38,618 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8425 | Iter Mean Loss 3.6296
2020-11-05 19:05:38,626 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 3.3418
2020-11-05 19:05:38,628 - root - INFO - Evaluate: Epoch 0915 | NDCG 0.2817 | MSE 0.3255
2020-11-05 19:05:38,637 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9334 | Iter Mean Loss 4.9334
2020-11-05 19:05:38,645 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2433 | Iter Mean Loss 3.0883
2020-11-05 19:05:38,653 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4893 | Iter Mean Loss 3.5553
2020-11-05 19:05:38,660 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8380 | Iter Mean Loss 3.6260
2020-11-05 19:05:38,668 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1877 | Iter Mean Loss 3.3383
2020-11-05 19:05:38,670 - root - INFO - Evaluate: Epoch 0916 | NDCG 0.2817 | MSE 0.3256
2020-11-05 19:05:38,679 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9301 | Iter Mean Loss 4.9301
2020-11-05 19:05:38,686 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2419 | Iter Mean Loss 3.0860
2020-11-05 19:05:38,694 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4841 | Iter Mean Loss 3.5520
2020-11-05 19:05:38,702 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8336 | Iter Mean Loss 3.6224
2020-11-05 19:05:38,709 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1848 | Iter Mean Loss 3.3349
2020-11-05 19:05:38,711 - root - INFO - Evaluate: Epoch 0917 | NDCG 0.2817 | MSE 0.3256
2020-11-05 19:05:38,720 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9269 | Iter Mean Loss 4.9269
2020-11-05 19:05:38,728 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2406 | Iter Mean Loss 3.0837
2020-11-05 19:05:38,736 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4789 | Iter Mean Loss 3.5488
2020-11-05 19:05:38,744 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8292 | Iter Mean Loss 3.6189
2020-11-05 19:05:38,753 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1818 | Iter Mean Loss 3.3315
2020-11-05 19:05:38,755 - root - INFO - Evaluate: Epoch 0918 | NDCG 0.2817 | MSE 0.3257
2020-11-05 19:05:38,764 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 4.9236
2020-11-05 19:05:38,772 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2392 | Iter Mean Loss 3.0814
2020-11-05 19:05:38,782 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4737 | Iter Mean Loss 3.5455
2020-11-05 19:05:38,790 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8248 | Iter Mean Loss 3.6153
2020-11-05 19:05:38,799 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1789 | Iter Mean Loss 3.3280
2020-11-05 19:05:38,801 - root - INFO - Evaluate: Epoch 0919 | NDCG 0.2817 | MSE 0.3257
2020-11-05 19:05:38,809 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9203 | Iter Mean Loss 4.9203
2020-11-05 19:05:38,817 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2378 | Iter Mean Loss 3.0791
2020-11-05 19:05:38,827 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4685 | Iter Mean Loss 3.5422
2020-11-05 19:05:38,835 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8204 | Iter Mean Loss 3.6118
2020-11-05 19:05:38,843 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1760 | Iter Mean Loss 3.3246
2020-11-05 19:05:38,845 - root - INFO - Evaluate: Epoch 0920 | NDCG 0.2817 | MSE 0.3257
2020-11-05 19:05:38,853 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9171 | Iter Mean Loss 4.9171
2020-11-05 19:05:38,861 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2364 | Iter Mean Loss 3.0767
2020-11-05 19:05:38,869 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4633 | Iter Mean Loss 3.5389
2020-11-05 19:05:38,876 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8160 | Iter Mean Loss 3.6082
2020-11-05 19:05:38,884 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1730 | Iter Mean Loss 3.3212
2020-11-05 19:05:38,886 - root - INFO - Evaluate: Epoch 0921 | NDCG 0.2817 | MSE 0.3258
2020-11-05 19:05:38,894 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9138 | Iter Mean Loss 4.9138
2020-11-05 19:05:38,901 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2351 | Iter Mean Loss 3.0744
2020-11-05 19:05:38,909 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4582 | Iter Mean Loss 3.5357
2020-11-05 19:05:38,916 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8116 | Iter Mean Loss 3.6046
2020-11-05 19:05:38,925 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1701 | Iter Mean Loss 3.3177
2020-11-05 19:05:38,927 - root - INFO - Evaluate: Epoch 0922 | NDCG 0.2817 | MSE 0.3258
2020-11-05 19:05:38,936 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9105 | Iter Mean Loss 4.9105
2020-11-05 19:05:38,944 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2337 | Iter Mean Loss 3.0721
2020-11-05 19:05:38,952 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4530 | Iter Mean Loss 3.5324
2020-11-05 19:05:38,961 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8072 | Iter Mean Loss 3.6011
2020-11-05 19:05:38,969 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1672 | Iter Mean Loss 3.3143
2020-11-05 19:05:38,972 - root - INFO - Evaluate: Epoch 0923 | NDCG 0.2817 | MSE 0.3259
2020-11-05 19:05:38,981 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9072 | Iter Mean Loss 4.9072
2020-11-05 19:05:38,990 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2323 | Iter Mean Loss 3.0697
2020-11-05 19:05:38,998 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 3.5291
2020-11-05 19:05:39,006 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8028 | Iter Mean Loss 3.5975
2020-11-05 19:05:39,014 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1643 | Iter Mean Loss 3.3109
2020-11-05 19:05:39,017 - root - INFO - Evaluate: Epoch 0924 | NDCG 0.2817 | MSE 0.3259
2020-11-05 19:05:39,027 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9038 | Iter Mean Loss 4.9038
2020-11-05 19:05:39,035 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2309 | Iter Mean Loss 3.0674
2020-11-05 19:05:39,043 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4427 | Iter Mean Loss 3.5258
2020-11-05 19:05:39,050 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7984 | Iter Mean Loss 3.5940
2020-11-05 19:05:39,058 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1614 | Iter Mean Loss 3.3074
2020-11-05 19:05:39,060 - root - INFO - Evaluate: Epoch 0925 | NDCG 0.2817 | MSE 0.3260
2020-11-05 19:05:39,068 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9005 | Iter Mean Loss 4.9005
2020-11-05 19:05:39,076 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2295 | Iter Mean Loss 3.0650
2020-11-05 19:05:39,083 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4375 | Iter Mean Loss 3.5225
2020-11-05 19:05:39,091 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7940 | Iter Mean Loss 3.5904
2020-11-05 19:05:39,099 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1585 | Iter Mean Loss 3.3040
2020-11-05 19:05:39,101 - root - INFO - Evaluate: Epoch 0926 | NDCG 0.2817 | MSE 0.3260
2020-11-05 19:05:39,108 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8972 | Iter Mean Loss 4.8972
2020-11-05 19:05:39,116 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2281 | Iter Mean Loss 3.0626
2020-11-05 19:05:39,124 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4324 | Iter Mean Loss 3.5192
2020-11-05 19:05:39,132 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7896 | Iter Mean Loss 3.5868
2020-11-05 19:05:39,141 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1556 | Iter Mean Loss 3.3006
2020-11-05 19:05:39,143 - root - INFO - Evaluate: Epoch 0927 | NDCG 0.2817 | MSE 0.3261
2020-11-05 19:05:39,151 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8938 | Iter Mean Loss 4.8938
2020-11-05 19:05:39,159 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2267 | Iter Mean Loss 3.0603
2020-11-05 19:05:39,168 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4272 | Iter Mean Loss 3.5159
2020-11-05 19:05:39,177 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7853 | Iter Mean Loss 3.5833
2020-11-05 19:05:39,185 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1526 | Iter Mean Loss 3.2971
2020-11-05 19:05:39,187 - root - INFO - Evaluate: Epoch 0928 | NDCG 0.2817 | MSE 0.3261
2020-11-05 19:05:39,196 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8904 | Iter Mean Loss 4.8904
2020-11-05 19:05:39,204 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2253 | Iter Mean Loss 3.0579
2020-11-05 19:05:39,213 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4221 | Iter Mean Loss 3.5126
2020-11-05 19:05:39,221 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7809 | Iter Mean Loss 3.5797
2020-11-05 19:05:39,230 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1497 | Iter Mean Loss 3.2937
2020-11-05 19:05:39,232 - root - INFO - Evaluate: Epoch 0929 | NDCG 0.2817 | MSE 0.3261
2020-11-05 19:05:39,240 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8871 | Iter Mean Loss 4.8871
2020-11-05 19:05:39,249 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2239 | Iter Mean Loss 3.0555
2020-11-05 19:05:39,257 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4169 | Iter Mean Loss 3.5093
2020-11-05 19:05:39,265 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7765 | Iter Mean Loss 3.5761
2020-11-05 19:05:39,272 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1468 | Iter Mean Loss 3.2903
2020-11-05 19:05:39,274 - root - INFO - Evaluate: Epoch 0930 | NDCG 0.2817 | MSE 0.3262
2020-11-05 19:05:39,282 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8837 | Iter Mean Loss 4.8837
2020-11-05 19:05:39,290 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2225 | Iter Mean Loss 3.0531
2020-11-05 19:05:39,298 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4118 | Iter Mean Loss 3.5060
2020-11-05 19:05:39,305 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 3.5725
2020-11-05 19:05:39,312 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1439 | Iter Mean Loss 3.2868
2020-11-05 19:05:39,315 - root - INFO - Evaluate: Epoch 0931 | NDCG 0.2817 | MSE 0.3262
2020-11-05 19:05:39,325 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8803 | Iter Mean Loss 4.8803
2020-11-05 19:05:39,333 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2211 | Iter Mean Loss 3.0507
2020-11-05 19:05:39,342 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4067 | Iter Mean Loss 3.5027
2020-11-05 19:05:39,351 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7678 | Iter Mean Loss 3.5690
2020-11-05 19:05:39,359 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1410 | Iter Mean Loss 3.2834
2020-11-05 19:05:39,363 - root - INFO - Evaluate: Epoch 0932 | NDCG 0.2817 | MSE 0.3263
2020-11-05 19:05:39,372 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8768 | Iter Mean Loss 4.8768
2020-11-05 19:05:39,382 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2197 | Iter Mean Loss 3.0483
2020-11-05 19:05:39,390 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4016 | Iter Mean Loss 3.4994
2020-11-05 19:05:39,400 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7635 | Iter Mean Loss 3.5654
2020-11-05 19:05:39,408 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1381 | Iter Mean Loss 3.2799
2020-11-05 19:05:39,411 - root - INFO - Evaluate: Epoch 0933 | NDCG 0.2817 | MSE 0.3263
2020-11-05 19:05:39,425 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8734 | Iter Mean Loss 4.8734
2020-11-05 19:05:39,436 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 3.0458
2020-11-05 19:05:39,445 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3964 | Iter Mean Loss 3.4960
2020-11-05 19:05:39,455 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7591 | Iter Mean Loss 3.5618
2020-11-05 19:05:39,464 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1352 | Iter Mean Loss 3.2765
2020-11-05 19:05:39,466 - root - INFO - Evaluate: Epoch 0934 | NDCG 0.2817 | MSE 0.3264
2020-11-05 19:05:39,477 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8700 | Iter Mean Loss 4.8700
2020-11-05 19:05:39,488 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2168 | Iter Mean Loss 3.0434
2020-11-05 19:05:39,498 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 3.4927
2020-11-05 19:05:39,508 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7548 | Iter Mean Loss 3.5582
2020-11-05 19:05:39,518 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1323 | Iter Mean Loss 3.2731
2020-11-05 19:05:39,521 - root - INFO - Evaluate: Epoch 0935 | NDCG 0.2817 | MSE 0.3264
2020-11-05 19:05:39,530 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8665 | Iter Mean Loss 4.8665
2020-11-05 19:05:39,539 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2154 | Iter Mean Loss 3.0410
2020-11-05 19:05:39,551 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3862 | Iter Mean Loss 3.4894
2020-11-05 19:05:39,561 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7505 | Iter Mean Loss 3.5546
2020-11-05 19:05:39,570 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1294 | Iter Mean Loss 3.2696
2020-11-05 19:05:39,573 - root - INFO - Evaluate: Epoch 0936 | NDCG 0.2817 | MSE 0.3264
2020-11-05 19:05:39,584 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8631 | Iter Mean Loss 4.8631
2020-11-05 19:05:39,593 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2140 | Iter Mean Loss 3.0385
2020-11-05 19:05:39,603 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3811 | Iter Mean Loss 3.4860
2020-11-05 19:05:39,611 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7461 | Iter Mean Loss 3.5511
2020-11-05 19:05:39,620 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1265 | Iter Mean Loss 3.2662
2020-11-05 19:05:39,622 - root - INFO - Evaluate: Epoch 0937 | NDCG 0.2817 | MSE 0.3265
2020-11-05 19:05:39,630 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8596 | Iter Mean Loss 4.8596
2020-11-05 19:05:39,639 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2125 | Iter Mean Loss 3.0360
2020-11-05 19:05:39,647 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3760 | Iter Mean Loss 3.4827
2020-11-05 19:05:39,655 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7418 | Iter Mean Loss 3.5475
2020-11-05 19:05:39,663 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1237 | Iter Mean Loss 3.2627
2020-11-05 19:05:39,665 - root - INFO - Evaluate: Epoch 0938 | NDCG 0.2817 | MSE 0.3265
2020-11-05 19:05:39,673 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8561 | Iter Mean Loss 4.8561
2020-11-05 19:05:39,681 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2111 | Iter Mean Loss 3.0336
2020-11-05 19:05:39,688 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3709 | Iter Mean Loss 3.4793
2020-11-05 19:05:39,696 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7375 | Iter Mean Loss 3.5439
2020-11-05 19:05:39,703 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1208 | Iter Mean Loss 3.2593
2020-11-05 19:05:39,706 - root - INFO - Evaluate: Epoch 0939 | NDCG 0.2817 | MSE 0.3266
2020-11-05 19:05:39,714 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8526 | Iter Mean Loss 4.8526
2020-11-05 19:05:39,722 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2096 | Iter Mean Loss 3.0311
2020-11-05 19:05:39,730 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3658 | Iter Mean Loss 3.4760
2020-11-05 19:05:39,738 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7332 | Iter Mean Loss 3.5403
2020-11-05 19:05:39,746 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1179 | Iter Mean Loss 3.2558
2020-11-05 19:05:39,749 - root - INFO - Evaluate: Epoch 0940 | NDCG 0.2817 | MSE 0.3266
2020-11-05 19:05:39,757 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8490 | Iter Mean Loss 4.8490
2020-11-05 19:05:39,765 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 3.0286
2020-11-05 19:05:39,773 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3607 | Iter Mean Loss 3.4726
2020-11-05 19:05:39,781 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7288 | Iter Mean Loss 3.5367
2020-11-05 19:05:39,789 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1150 | Iter Mean Loss 3.2523
2020-11-05 19:05:39,792 - root - INFO - Evaluate: Epoch 0941 | NDCG 0.2817 | MSE 0.3267
2020-11-05 19:05:39,801 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8455 | Iter Mean Loss 4.8455
2020-11-05 19:05:39,809 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2067 | Iter Mean Loss 3.0261
2020-11-05 19:05:39,818 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3556 | Iter Mean Loss 3.4693
2020-11-05 19:05:39,826 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7245 | Iter Mean Loss 3.5331
2020-11-05 19:05:39,834 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1121 | Iter Mean Loss 3.2489
2020-11-05 19:05:39,836 - root - INFO - Evaluate: Epoch 0942 | NDCG 0.2817 | MSE 0.3267
2020-11-05 19:05:39,845 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8420 | Iter Mean Loss 4.8420
2020-11-05 19:05:39,853 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2052 | Iter Mean Loss 3.0236
2020-11-05 19:05:39,861 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3505 | Iter Mean Loss 3.4659
2020-11-05 19:05:39,869 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7202 | Iter Mean Loss 3.5295
2020-11-05 19:05:39,877 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1092 | Iter Mean Loss 3.2454
2020-11-05 19:05:39,879 - root - INFO - Evaluate: Epoch 0943 | NDCG 0.2817 | MSE 0.3268
2020-11-05 19:05:39,887 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8384 | Iter Mean Loss 4.8384
2020-11-05 19:05:39,894 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2038 | Iter Mean Loss 3.0211
2020-11-05 19:05:39,902 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3455 | Iter Mean Loss 3.4625
2020-11-05 19:05:39,909 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7159 | Iter Mean Loss 3.5259
2020-11-05 19:05:39,917 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1063 | Iter Mean Loss 3.2420
2020-11-05 19:05:39,919 - root - INFO - Evaluate: Epoch 0944 | NDCG 0.2817 | MSE 0.3268
2020-11-05 19:05:39,927 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8348 | Iter Mean Loss 4.8348
2020-11-05 19:05:39,934 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2023 | Iter Mean Loss 3.0185
2020-11-05 19:05:39,942 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3404 | Iter Mean Loss 3.4592
2020-11-05 19:05:39,949 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7116 | Iter Mean Loss 3.5223
2020-11-05 19:05:39,958 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1034 | Iter Mean Loss 3.2385
2020-11-05 19:05:39,960 - root - INFO - Evaluate: Epoch 0945 | NDCG 0.2817 | MSE 0.3268
2020-11-05 19:05:39,968 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 4.8312
2020-11-05 19:05:39,977 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2008 | Iter Mean Loss 3.0160
2020-11-05 19:05:39,985 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3353 | Iter Mean Loss 3.4558
2020-11-05 19:05:39,993 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7073 | Iter Mean Loss 3.5187
2020-11-05 19:05:40,001 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1005 | Iter Mean Loss 3.2350
2020-11-05 19:05:40,003 - root - INFO - Evaluate: Epoch 0946 | NDCG 0.2817 | MSE 0.3269
2020-11-05 19:05:40,012 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8276 | Iter Mean Loss 4.8276
2020-11-05 19:05:40,020 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1993 | Iter Mean Loss 3.0134
2020-11-05 19:05:40,029 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3302 | Iter Mean Loss 3.4524
2020-11-05 19:05:40,036 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7030 | Iter Mean Loss 3.5150
2020-11-05 19:05:40,045 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0976 | Iter Mean Loss 3.2316
2020-11-05 19:05:40,047 - root - INFO - Evaluate: Epoch 0947 | NDCG 0.2817 | MSE 0.3269
2020-11-05 19:05:40,055 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8240 | Iter Mean Loss 4.8240
2020-11-05 19:05:40,064 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1978 | Iter Mean Loss 3.0109
2020-11-05 19:05:40,071 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3252 | Iter Mean Loss 3.4490
2020-11-05 19:05:40,079 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6987 | Iter Mean Loss 3.5114
2020-11-05 19:05:40,086 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0948 | Iter Mean Loss 3.2281
2020-11-05 19:05:40,088 - root - INFO - Evaluate: Epoch 0948 | NDCG 0.2817 | MSE 0.3270
2020-11-05 19:05:40,096 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8203 | Iter Mean Loss 4.8203
2020-11-05 19:05:40,104 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1963 | Iter Mean Loss 3.0083
2020-11-05 19:05:40,111 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 3.4456
2020-11-05 19:05:40,119 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6945 | Iter Mean Loss 3.5078
2020-11-05 19:05:40,126 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0919 | Iter Mean Loss 3.2246
2020-11-05 19:05:40,128 - root - INFO - Evaluate: Epoch 0949 | NDCG 0.2817 | MSE 0.3270
2020-11-05 19:05:40,136 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8166 | Iter Mean Loss 4.8166
2020-11-05 19:05:40,144 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1948 | Iter Mean Loss 3.0057
2020-11-05 19:05:40,151 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 3.4422
2020-11-05 19:05:40,159 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6902 | Iter Mean Loss 3.5042
2020-11-05 19:05:40,167 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0890 | Iter Mean Loss 3.2211
2020-11-05 19:05:40,169 - root - INFO - Evaluate: Epoch 0950 | NDCG 0.2817 | MSE 0.3271
2020-11-05 19:05:40,178 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8130 | Iter Mean Loss 4.8130
2020-11-05 19:05:40,186 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1933 | Iter Mean Loss 3.0031
2020-11-05 19:05:40,194 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3100 | Iter Mean Loss 3.4387
2020-11-05 19:05:40,202 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6859 | Iter Mean Loss 3.5005
2020-11-05 19:05:40,209 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0861 | Iter Mean Loss 3.2176
2020-11-05 19:05:40,212 - root - INFO - Evaluate: Epoch 0951 | NDCG 0.2817 | MSE 0.3271
2020-11-05 19:05:40,221 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8093 | Iter Mean Loss 4.8093
2020-11-05 19:05:40,229 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1918 | Iter Mean Loss 3.0005
2020-11-05 19:05:40,237 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3049 | Iter Mean Loss 3.4353
2020-11-05 19:05:40,244 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6816 | Iter Mean Loss 3.4969
2020-11-05 19:05:40,253 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0832 | Iter Mean Loss 3.2142
2020-11-05 19:05:40,255 - root - INFO - Evaluate: Epoch 0952 | NDCG 0.2817 | MSE 0.3272
2020-11-05 19:05:40,264 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8055 | Iter Mean Loss 4.8055
2020-11-05 19:05:40,272 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1902 | Iter Mean Loss 2.9979
2020-11-05 19:05:40,279 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.4319
2020-11-05 19:05:40,286 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6773 | Iter Mean Loss 3.4933
2020-11-05 19:05:40,294 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0803 | Iter Mean Loss 3.2107
2020-11-05 19:05:40,296 - root - INFO - Evaluate: Epoch 0953 | NDCG 0.2817 | MSE 0.3272
2020-11-05 19:05:40,303 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8018 | Iter Mean Loss 4.8018
2020-11-05 19:05:40,311 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1887 | Iter Mean Loss 2.9953
2020-11-05 19:05:40,319 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2948 | Iter Mean Loss 3.4285
2020-11-05 19:05:40,328 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6731 | Iter Mean Loss 3.4896
2020-11-05 19:05:40,335 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0774 | Iter Mean Loss 3.2072
2020-11-05 19:05:40,337 - root - INFO - Evaluate: Epoch 0954 | NDCG 0.2817 | MSE 0.3272
2020-11-05 19:05:40,345 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7981 | Iter Mean Loss 4.7981
2020-11-05 19:05:40,353 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1872 | Iter Mean Loss 2.9926
2020-11-05 19:05:40,360 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2898 | Iter Mean Loss 3.4250
2020-11-05 19:05:40,369 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6688 | Iter Mean Loss 3.4860
2020-11-05 19:05:40,377 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0745 | Iter Mean Loss 3.2037
2020-11-05 19:05:40,380 - root - INFO - Evaluate: Epoch 0955 | NDCG 0.2817 | MSE 0.3273
2020-11-05 19:05:40,389 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7943 | Iter Mean Loss 4.7943
2020-11-05 19:05:40,397 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1856 | Iter Mean Loss 2.9900
2020-11-05 19:05:40,406 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 3.4216
2020-11-05 19:05:40,414 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6645 | Iter Mean Loss 3.4823
2020-11-05 19:05:40,422 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0716 | Iter Mean Loss 3.2002
2020-11-05 19:05:40,424 - root - INFO - Evaluate: Epoch 0956 | NDCG 0.2817 | MSE 0.3273
2020-11-05 19:05:40,434 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7905 | Iter Mean Loss 4.7905
2020-11-05 19:05:40,441 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1841 | Iter Mean Loss 2.9873
2020-11-05 19:05:40,450 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2797 | Iter Mean Loss 3.4181
2020-11-05 19:05:40,458 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6603 | Iter Mean Loss 3.4786
2020-11-05 19:05:40,466 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0687 | Iter Mean Loss 3.1967
2020-11-05 19:05:40,468 - root - INFO - Evaluate: Epoch 0957 | NDCG 0.2817 | MSE 0.3274
2020-11-05 19:05:40,476 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7867 | Iter Mean Loss 4.7867
2020-11-05 19:05:40,484 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1825 | Iter Mean Loss 2.9846
2020-11-05 19:05:40,491 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2747 | Iter Mean Loss 3.4146
2020-11-05 19:05:40,498 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6560 | Iter Mean Loss 3.4750
2020-11-05 19:05:40,505 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0659 | Iter Mean Loss 3.1931
2020-11-05 19:05:40,507 - root - INFO - Evaluate: Epoch 0958 | NDCG 0.2817 | MSE 0.3274
2020-11-05 19:05:40,515 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7829 | Iter Mean Loss 4.7829
2020-11-05 19:05:40,522 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1809 | Iter Mean Loss 2.9819
2020-11-05 19:05:40,530 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2696 | Iter Mean Loss 3.4112
2020-11-05 19:05:40,537 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6517 | Iter Mean Loss 3.4713
2020-11-05 19:05:40,544 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0630 | Iter Mean Loss 3.1896
2020-11-05 19:05:40,546 - root - INFO - Evaluate: Epoch 0959 | NDCG 0.2817 | MSE 0.3275
2020-11-05 19:05:40,554 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7790 | Iter Mean Loss 4.7790
2020-11-05 19:05:40,562 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1794 | Iter Mean Loss 2.9792
2020-11-05 19:05:40,570 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2646 | Iter Mean Loss 3.4077
2020-11-05 19:05:40,577 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6475 | Iter Mean Loss 3.4676
2020-11-05 19:05:40,585 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0601 | Iter Mean Loss 3.1861
2020-11-05 19:05:40,588 - root - INFO - Evaluate: Epoch 0960 | NDCG 0.2817 | MSE 0.3275
2020-11-05 19:05:40,596 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7752 | Iter Mean Loss 4.7752
2020-11-05 19:05:40,605 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1778 | Iter Mean Loss 2.9765
2020-11-05 19:05:40,613 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 3.4042
2020-11-05 19:05:40,621 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 3.4639
2020-11-05 19:05:40,629 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0572 | Iter Mean Loss 3.1826
2020-11-05 19:05:40,631 - root - INFO - Evaluate: Epoch 0961 | NDCG 0.2817 | MSE 0.3275
2020-11-05 19:05:40,640 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7713 | Iter Mean Loss 4.7713
2020-11-05 19:05:40,648 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1762 | Iter Mean Loss 2.9738
2020-11-05 19:05:40,657 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2545 | Iter Mean Loss 3.4007
2020-11-05 19:05:40,665 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6390 | Iter Mean Loss 3.4603
2020-11-05 19:05:40,673 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0543 | Iter Mean Loss 3.1791
2020-11-05 19:05:40,675 - root - INFO - Evaluate: Epoch 0962 | NDCG 0.2817 | MSE 0.3276
2020-11-05 19:05:40,683 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7674 | Iter Mean Loss 4.7674
2020-11-05 19:05:40,690 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1746 | Iter Mean Loss 2.9710
2020-11-05 19:05:40,698 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2495 | Iter Mean Loss 3.3972
2020-11-05 19:05:40,705 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6347 | Iter Mean Loss 3.4566
2020-11-05 19:05:40,712 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0514 | Iter Mean Loss 3.1755
2020-11-05 19:05:40,714 - root - INFO - Evaluate: Epoch 0963 | NDCG 0.2817 | MSE 0.3276
2020-11-05 19:05:40,722 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7635 | Iter Mean Loss 4.7635
2020-11-05 19:05:40,731 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1730 | Iter Mean Loss 2.9682
2020-11-05 19:05:40,738 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2445 | Iter Mean Loss 3.3937
2020-11-05 19:05:40,745 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6305 | Iter Mean Loss 3.4529
2020-11-05 19:05:40,753 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0485 | Iter Mean Loss 3.1720
2020-11-05 19:05:40,755 - root - INFO - Evaluate: Epoch 0964 | NDCG 0.2817 | MSE 0.3277
2020-11-05 19:05:40,763 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7595 | Iter Mean Loss 4.7595
2020-11-05 19:05:40,771 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 2.9655
2020-11-05 19:05:40,778 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2395 | Iter Mean Loss 3.3901
2020-11-05 19:05:40,786 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6262 | Iter Mean Loss 3.4492
2020-11-05 19:05:40,794 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0456 | Iter Mean Loss 3.1684
2020-11-05 19:05:40,797 - root - INFO - Evaluate: Epoch 0965 | NDCG 0.2817 | MSE 0.3277
2020-11-05 19:05:40,805 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7556 | Iter Mean Loss 4.7556
2020-11-05 19:05:40,813 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1698 | Iter Mean Loss 2.9627
2020-11-05 19:05:40,821 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2344 | Iter Mean Loss 3.3866
2020-11-05 19:05:40,829 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6220 | Iter Mean Loss 3.4454
2020-11-05 19:05:40,837 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0427 | Iter Mean Loss 3.1649
2020-11-05 19:05:40,839 - root - INFO - Evaluate: Epoch 0966 | NDCG 0.2817 | MSE 0.3278
2020-11-05 19:05:40,848 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7516 | Iter Mean Loss 4.7516
2020-11-05 19:05:40,855 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1682 | Iter Mean Loss 2.9599
2020-11-05 19:05:40,864 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2294 | Iter Mean Loss 3.3831
2020-11-05 19:05:40,871 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6177 | Iter Mean Loss 3.4417
2020-11-05 19:05:40,879 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0398 | Iter Mean Loss 3.1613
2020-11-05 19:05:40,881 - root - INFO - Evaluate: Epoch 0967 | NDCG 0.2817 | MSE 0.3278
2020-11-05 19:05:40,889 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7476 | Iter Mean Loss 4.7476
2020-11-05 19:05:40,896 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1665 | Iter Mean Loss 2.9571
2020-11-05 19:05:40,904 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2244 | Iter Mean Loss 3.3795
2020-11-05 19:05:40,911 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6135 | Iter Mean Loss 3.4380
2020-11-05 19:05:40,918 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0369 | Iter Mean Loss 3.1578
2020-11-05 19:05:40,920 - root - INFO - Evaluate: Epoch 0968 | NDCG 0.2817 | MSE 0.3278
2020-11-05 19:05:40,928 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7436 | Iter Mean Loss 4.7436
2020-11-05 19:05:40,935 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1649 | Iter Mean Loss 2.9542
2020-11-05 19:05:40,943 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2194 | Iter Mean Loss 3.3760
2020-11-05 19:05:40,950 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6092 | Iter Mean Loss 3.4343
2020-11-05 19:05:40,957 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0339 | Iter Mean Loss 3.1542
2020-11-05 19:05:40,959 - root - INFO - Evaluate: Epoch 0969 | NDCG 0.2817 | MSE 0.3279
2020-11-05 19:05:40,968 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 4.7395
2020-11-05 19:05:40,975 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1633 | Iter Mean Loss 2.9514
2020-11-05 19:05:40,983 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2144 | Iter Mean Loss 3.3724
2020-11-05 19:05:40,991 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6050 | Iter Mean Loss 3.4305
2020-11-05 19:05:40,998 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0310 | Iter Mean Loss 3.1506
2020-11-05 19:05:41,000 - root - INFO - Evaluate: Epoch 0970 | NDCG 0.2817 | MSE 0.3279
2020-11-05 19:05:41,009 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7354 | Iter Mean Loss 4.7354
2020-11-05 19:05:41,017 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1616 | Iter Mean Loss 2.9485
2020-11-05 19:05:41,025 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2094 | Iter Mean Loss 3.3688
2020-11-05 19:05:41,032 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6008 | Iter Mean Loss 3.4268
2020-11-05 19:05:41,040 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0281 | Iter Mean Loss 3.1471
2020-11-05 19:05:41,042 - root - INFO - Evaluate: Epoch 0971 | NDCG 0.2817 | MSE 0.3280
2020-11-05 19:05:41,051 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7313 | Iter Mean Loss 4.7313
2020-11-05 19:05:41,059 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1600 | Iter Mean Loss 2.9457
2020-11-05 19:05:41,066 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2043 | Iter Mean Loss 3.3652
2020-11-05 19:05:41,074 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5965 | Iter Mean Loss 3.4230
2020-11-05 19:05:41,082 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0252 | Iter Mean Loss 3.1435
2020-11-05 19:05:41,084 - root - INFO - Evaluate: Epoch 0972 | NDCG 0.2817 | MSE 0.3280
2020-11-05 19:05:41,092 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7272 | Iter Mean Loss 4.7272
2020-11-05 19:05:41,099 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1583 | Iter Mean Loss 2.9428
2020-11-05 19:05:41,106 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1993 | Iter Mean Loss 3.3616
2020-11-05 19:05:41,113 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 3.4193
2020-11-05 19:05:41,121 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0223 | Iter Mean Loss 3.1399
2020-11-05 19:05:41,123 - root - INFO - Evaluate: Epoch 0973 | NDCG 0.2817 | MSE 0.3281
2020-11-05 19:05:41,131 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7231 | Iter Mean Loss 4.7231
2020-11-05 19:05:41,138 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1566 | Iter Mean Loss 2.9399
2020-11-05 19:05:41,145 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1943 | Iter Mean Loss 3.3580
2020-11-05 19:05:41,152 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5881 | Iter Mean Loss 3.4155
2020-11-05 19:05:41,159 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0194 | Iter Mean Loss 3.1363
2020-11-05 19:05:41,161 - root - INFO - Evaluate: Epoch 0974 | NDCG 0.2817 | MSE 0.3281
2020-11-05 19:05:41,170 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7189 | Iter Mean Loss 4.7189
2020-11-05 19:05:41,177 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1549 | Iter Mean Loss 2.9369
2020-11-05 19:05:41,185 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1893 | Iter Mean Loss 3.3544
2020-11-05 19:05:41,193 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5838 | Iter Mean Loss 3.4118
2020-11-05 19:05:41,200 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0164 | Iter Mean Loss 3.1327
2020-11-05 19:05:41,202 - root - INFO - Evaluate: Epoch 0975 | NDCG 0.2817 | MSE 0.3282
2020-11-05 19:05:41,211 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7148 | Iter Mean Loss 4.7148
2020-11-05 19:05:41,219 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1533 | Iter Mean Loss 2.9340
2020-11-05 19:05:41,227 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1843 | Iter Mean Loss 3.3508
2020-11-05 19:05:41,234 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5796 | Iter Mean Loss 3.4080
2020-11-05 19:05:41,242 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0135 | Iter Mean Loss 3.1291
2020-11-05 19:05:41,244 - root - INFO - Evaluate: Epoch 0976 | NDCG 0.2817 | MSE 0.3282
2020-11-05 19:05:41,253 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7106 | Iter Mean Loss 4.7106
2020-11-05 19:05:41,261 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 2.9311
2020-11-05 19:05:41,269 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1793 | Iter Mean Loss 3.3471
2020-11-05 19:05:41,276 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5754 | Iter Mean Loss 3.4042
2020-11-05 19:05:41,284 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0106 | Iter Mean Loss 3.1255
2020-11-05 19:05:41,286 - root - INFO - Evaluate: Epoch 0977 | NDCG 0.2817 | MSE 0.3282
2020-11-05 19:05:41,293 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7063 | Iter Mean Loss 4.7063
2020-11-05 19:05:41,301 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1499 | Iter Mean Loss 2.9281
2020-11-05 19:05:41,308 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1743 | Iter Mean Loss 3.3435
2020-11-05 19:05:41,315 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5711 | Iter Mean Loss 3.4004
2020-11-05 19:05:41,324 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0076 | Iter Mean Loss 3.1218
2020-11-05 19:05:41,326 - root - INFO - Evaluate: Epoch 0978 | NDCG 0.2817 | MSE 0.3283
2020-11-05 19:05:41,334 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7021 | Iter Mean Loss 4.7021
2020-11-05 19:05:41,341 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1481 | Iter Mean Loss 2.9251
2020-11-05 19:05:41,348 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1693 | Iter Mean Loss 3.3398
2020-11-05 19:05:41,355 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5669 | Iter Mean Loss 3.3966
2020-11-05 19:05:41,363 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0047 | Iter Mean Loss 3.1182
2020-11-05 19:05:41,365 - root - INFO - Evaluate: Epoch 0979 | NDCG 0.2817 | MSE 0.3283
2020-11-05 19:05:41,374 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6978 | Iter Mean Loss 4.6978
2020-11-05 19:05:41,381 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1464 | Iter Mean Loss 2.9221
2020-11-05 19:05:41,390 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1643 | Iter Mean Loss 3.3362
2020-11-05 19:05:41,397 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5627 | Iter Mean Loss 3.3928
2020-11-05 19:05:41,405 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0018 | Iter Mean Loss 3.1146
2020-11-05 19:05:41,408 - root - INFO - Evaluate: Epoch 0980 | NDCG 0.2817 | MSE 0.3284
2020-11-05 19:05:41,416 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6935 | Iter Mean Loss 4.6935
2020-11-05 19:05:41,424 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1447 | Iter Mean Loss 2.9191
2020-11-05 19:05:41,432 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1592 | Iter Mean Loss 3.3325
2020-11-05 19:05:41,440 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5584 | Iter Mean Loss 3.3890
2020-11-05 19:05:41,448 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9988 | Iter Mean Loss 3.1109
2020-11-05 19:05:41,450 - root - INFO - Evaluate: Epoch 0981 | NDCG 0.2817 | MSE 0.3284
2020-11-05 19:05:41,459 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6892 | Iter Mean Loss 4.6892
2020-11-05 19:05:41,467 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1430 | Iter Mean Loss 2.9161
2020-11-05 19:05:41,474 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1542 | Iter Mean Loss 3.3288
2020-11-05 19:05:41,482 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5542 | Iter Mean Loss 3.3851
2020-11-05 19:05:41,490 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9959 | Iter Mean Loss 3.1073
2020-11-05 19:05:41,492 - root - INFO - Evaluate: Epoch 0982 | NDCG 0.2817 | MSE 0.3284
2020-11-05 19:05:41,499 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6848 | Iter Mean Loss 4.6848
2020-11-05 19:05:41,507 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1412 | Iter Mean Loss 2.9130
2020-11-05 19:05:41,514 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1492 | Iter Mean Loss 3.3251
2020-11-05 19:05:41,521 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5500 | Iter Mean Loss 3.3813
2020-11-05 19:05:41,528 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9929 | Iter Mean Loss 3.1036
2020-11-05 19:05:41,530 - root - INFO - Evaluate: Epoch 0983 | NDCG 0.2817 | MSE 0.3285
2020-11-05 19:05:41,538 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6805 | Iter Mean Loss 4.6805
2020-11-05 19:05:41,545 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1395 | Iter Mean Loss 2.9100
2020-11-05 19:05:41,552 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1442 | Iter Mean Loss 3.3214
2020-11-05 19:05:41,560 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5458 | Iter Mean Loss 3.3775
2020-11-05 19:05:41,567 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9900 | Iter Mean Loss 3.1000
2020-11-05 19:05:41,569 - root - INFO - Evaluate: Epoch 0984 | NDCG 0.2817 | MSE 0.3285
2020-11-05 19:05:41,578 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6761 | Iter Mean Loss 4.6761
2020-11-05 19:05:41,586 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1377 | Iter Mean Loss 2.9069
2020-11-05 19:05:41,593 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1392 | Iter Mean Loss 3.3177
2020-11-05 19:05:41,602 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5415 | Iter Mean Loss 3.3736
2020-11-05 19:05:41,609 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9870 | Iter Mean Loss 3.0963
2020-11-05 19:05:41,611 - root - INFO - Evaluate: Epoch 0985 | NDCG 0.2817 | MSE 0.3286
2020-11-05 19:05:41,620 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6716 | Iter Mean Loss 4.6716
2020-11-05 19:05:41,628 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1359 | Iter Mean Loss 2.9038
2020-11-05 19:05:41,636 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1342 | Iter Mean Loss 3.3139
2020-11-05 19:05:41,644 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5373 | Iter Mean Loss 3.3698
2020-11-05 19:05:41,652 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9841 | Iter Mean Loss 3.0926
2020-11-05 19:05:41,654 - root - INFO - Evaluate: Epoch 0986 | NDCG 0.2817 | MSE 0.3286
2020-11-05 19:05:41,662 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6672 | Iter Mean Loss 4.6672
2020-11-05 19:05:41,671 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1342 | Iter Mean Loss 2.9007
2020-11-05 19:05:41,678 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1292 | Iter Mean Loss 3.3102
2020-11-05 19:05:41,686 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5331 | Iter Mean Loss 3.3659
2020-11-05 19:05:41,693 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9811 | Iter Mean Loss 3.0889
2020-11-05 19:05:41,695 - root - INFO - Evaluate: Epoch 0987 | NDCG 0.2817 | MSE 0.3287
2020-11-05 19:05:41,703 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6627 | Iter Mean Loss 4.6627
2020-11-05 19:05:41,711 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1324 | Iter Mean Loss 2.8975
2020-11-05 19:05:41,718 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1242 | Iter Mean Loss 3.3064
2020-11-05 19:05:41,725 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5289 | Iter Mean Loss 3.3620
2020-11-05 19:05:41,733 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9781 | Iter Mean Loss 3.0853
2020-11-05 19:05:41,735 - root - INFO - Evaluate: Epoch 0988 | NDCG 0.2817 | MSE 0.3287
2020-11-05 19:05:41,743 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6582 | Iter Mean Loss 4.6582
2020-11-05 19:05:41,750 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1306 | Iter Mean Loss 2.8944
2020-11-05 19:05:41,757 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1192 | Iter Mean Loss 3.3027
2020-11-05 19:05:41,765 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5246 | Iter Mean Loss 3.3582
2020-11-05 19:05:41,773 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9752 | Iter Mean Loss 3.0816
2020-11-05 19:05:41,775 - root - INFO - Evaluate: Epoch 0989 | NDCG 0.2817 | MSE 0.3287
2020-11-05 19:05:41,783 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 4.6537
2020-11-05 19:05:41,791 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1288 | Iter Mean Loss 2.8912
2020-11-05 19:05:41,798 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1142 | Iter Mean Loss 3.2989
2020-11-05 19:05:41,806 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5204 | Iter Mean Loss 3.3543
2020-11-05 19:05:41,814 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9722 | Iter Mean Loss 3.0779
2020-11-05 19:05:41,816 - root - INFO - Evaluate: Epoch 0990 | NDCG 0.2817 | MSE 0.3288
2020-11-05 19:05:41,824 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6491 | Iter Mean Loss 4.6491
2020-11-05 19:05:41,832 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1270 | Iter Mean Loss 2.8881
2020-11-05 19:05:41,840 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 3.2951
2020-11-05 19:05:41,848 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5162 | Iter Mean Loss 3.3504
2020-11-05 19:05:41,855 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9692 | Iter Mean Loss 3.0741
2020-11-05 19:05:41,858 - root - INFO - Evaluate: Epoch 0991 | NDCG 0.2817 | MSE 0.3288
2020-11-05 19:05:41,866 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6446 | Iter Mean Loss 4.6446
2020-11-05 19:05:41,874 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1252 | Iter Mean Loss 2.8849
2020-11-05 19:05:41,881 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1042 | Iter Mean Loss 3.2913
2020-11-05 19:05:41,888 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5120 | Iter Mean Loss 3.3465
2020-11-05 19:05:41,896 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9662 | Iter Mean Loss 3.0704
2020-11-05 19:05:41,898 - root - INFO - Evaluate: Epoch 0992 | NDCG 0.2817 | MSE 0.3289
2020-11-05 19:05:41,905 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6400 | Iter Mean Loss 4.6400
2020-11-05 19:05:41,913 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1234 | Iter Mean Loss 2.8817
2020-11-05 19:05:41,920 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0991 | Iter Mean Loss 3.2875
2020-11-05 19:05:41,927 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5077 | Iter Mean Loss 3.3425
2020-11-05 19:05:41,934 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9633 | Iter Mean Loss 3.0667
2020-11-05 19:05:41,936 - root - INFO - Evaluate: Epoch 0993 | NDCG 0.2817 | MSE 0.3289
2020-11-05 19:05:41,944 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6353 | Iter Mean Loss 4.6353
2020-11-05 19:05:41,952 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1215 | Iter Mean Loss 2.8784
2020-11-05 19:05:41,959 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0941 | Iter Mean Loss 3.2837
2020-11-05 19:05:41,966 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 3.3386
2020-11-05 19:05:41,973 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9603 | Iter Mean Loss 3.0629
2020-11-05 19:05:41,975 - root - INFO - Evaluate: Epoch 0994 | NDCG 0.2817 | MSE 0.3289
2020-11-05 19:05:41,983 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6307 | Iter Mean Loss 4.6307
2020-11-05 19:05:41,991 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1197 | Iter Mean Loss 2.8752
2020-11-05 19:05:41,998 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0891 | Iter Mean Loss 3.2798
2020-11-05 19:05:42,006 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4993 | Iter Mean Loss 3.3347
2020-11-05 19:05:42,014 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9573 | Iter Mean Loss 3.0592
2020-11-05 19:05:42,016 - root - INFO - Evaluate: Epoch 0995 | NDCG 0.2817 | MSE 0.3290
2020-11-05 19:05:42,025 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6260 | Iter Mean Loss 4.6260
2020-11-05 19:05:42,032 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1178 | Iter Mean Loss 2.8719
2020-11-05 19:05:42,040 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0841 | Iter Mean Loss 3.2760
2020-11-05 19:05:42,048 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4950 | Iter Mean Loss 3.3307
2020-11-05 19:05:42,055 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9543 | Iter Mean Loss 3.0555
2020-11-05 19:05:42,058 - root - INFO - Evaluate: Epoch 0996 | NDCG 0.2817 | MSE 0.3290
2020-11-05 19:05:42,066 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6213 | Iter Mean Loss 4.6213
2020-11-05 19:05:42,074 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1160 | Iter Mean Loss 2.8686
2020-11-05 19:05:42,082 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 3.2721
2020-11-05 19:05:42,089 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4908 | Iter Mean Loss 3.3268
2020-11-05 19:05:42,097 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9513 | Iter Mean Loss 3.0517
2020-11-05 19:05:42,100 - root - INFO - Evaluate: Epoch 0997 | NDCG 0.2817 | MSE 0.3291
2020-11-05 19:05:42,107 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6166 | Iter Mean Loss 4.6166
2020-11-05 19:05:42,115 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1141 | Iter Mean Loss 2.8653
2020-11-05 19:05:42,122 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0741 | Iter Mean Loss 3.2683
2020-11-05 19:05:42,129 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4866 | Iter Mean Loss 3.3228
2020-11-05 19:05:42,136 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9483 | Iter Mean Loss 3.0479
2020-11-05 19:05:42,138 - root - INFO - Evaluate: Epoch 0998 | NDCG 0.2817 | MSE 0.3291
2020-11-05 19:05:42,146 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6118 | Iter Mean Loss 4.6118
2020-11-05 19:05:42,153 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1123 | Iter Mean Loss 2.8620
2020-11-05 19:05:42,161 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0691 | Iter Mean Loss 3.2644
2020-11-05 19:05:42,168 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4824 | Iter Mean Loss 3.3189
2020-11-05 19:05:42,175 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9452 | Iter Mean Loss 3.0441
2020-11-05 19:05:42,177 - root - INFO - Evaluate: Epoch 0999 | NDCG 0.2817 | MSE 0.3291
2020-11-05 19:05:42,177 - root - INFO - [!]-----------training done.
2020-11-05 19:05:42,307 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 19:05:42,308 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,308 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,309 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,310 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,310 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,310 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,310 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 19:05:42,310 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,311 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,312 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 19:05:42,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 19:05:42,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 19:05:42,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 19:05:42,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 19:05:42,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 19:05:42,389 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 19:05:42,589 - root - INFO - [!]-----------start testing.
2020-11-05 19:05:42,591 - root - INFO - Real Rank:
2020-11-05 19:05:42,591 - root - INFO - [116 142]
2020-11-05 19:05:42,591 - root - INFO - Pred Rank:
2020-11-05 19:05:42,591 - root - INFO - [142  91 116 135]
2020-11-05 19:08:02,932 - root - INFO - Test Result: NDCG 0.2817 | MSE 0.3291
