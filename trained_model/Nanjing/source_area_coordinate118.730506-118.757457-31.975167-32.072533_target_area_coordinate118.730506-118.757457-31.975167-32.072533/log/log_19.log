2020-11-05 21:00:32,136 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.730506-118.757457-31.975167-32.072533_target_area_coordinate118.730506-118.757457-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], target_enterprise='大众书局')
2020-11-05 21:00:32,136 - root - INFO - --------------parse args and init done.
2020-11-05 21:00:35,127 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 21:00:36,170 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 21:00:36,170 - root - INFO - n_source_grid: 95, n_target_grid: 152
2020-11-05 21:00:36,170 - root - INFO - [3 /10]       split grid done.
2020-11-05 21:00:37,399 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 21:04:36,905 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 21:04:37,012 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 21:04:37,156 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 21:04:37,190 - root - INFO - [8 /10]       combine features done.
2020-11-05 21:04:37,819 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 21:04:37,819 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 21:04:37,853 - root - INFO - --------------load data done.
2020-11-05 21:04:37,904 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 21:04:37,905 - root - INFO - --------------construct model and optimizer done.
2020-11-05 21:04:37,905 - root - INFO - --------------initialize metrics done.
2020-11-05 21:04:37,905 - root - INFO - [!]-----------start training.
2020-11-05 21:04:38,142 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.2s | Iter Loss 599.9505 | Iter Mean Loss 599.9505
2020-11-05 21:04:38,152 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 563.8873 | Iter Mean Loss 581.9189
2020-11-05 21:04:38,162 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 584.5262 | Iter Mean Loss 582.7880
2020-11-05 21:04:38,172 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 507.9936 | Iter Mean Loss 564.0894
2020-11-05 21:04:38,181 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 458.8430 | Iter Mean Loss 543.0401
2020-11-05 21:04:38,186 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.6699
2020-11-05 21:04:38,196 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 471.0423 | Iter Mean Loss 471.0423
2020-11-05 21:04:38,206 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 438.9006 | Iter Mean Loss 454.9715
2020-11-05 21:04:38,216 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 467.8340 | Iter Mean Loss 459.2590
2020-11-05 21:04:38,225 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 403.4666 | Iter Mean Loss 445.3109
2020-11-05 21:04:38,235 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 363.2046 | Iter Mean Loss 428.8896
2020-11-05 21:04:38,237 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.6592
2020-11-05 21:04:38,247 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 370.4881 | Iter Mean Loss 370.4881
2020-11-05 21:04:38,257 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 342.5330 | Iter Mean Loss 356.5105
2020-11-05 21:04:38,267 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 377.8442 | Iter Mean Loss 363.6218
2020-11-05 21:04:38,276 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 323.3188 | Iter Mean Loss 353.5460
2020-11-05 21:04:38,284 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 289.7713 | Iter Mean Loss 340.7911
2020-11-05 21:04:38,288 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.6435
2020-11-05 21:04:38,297 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 293.7136 | Iter Mean Loss 293.7136
2020-11-05 21:04:38,305 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 270.0704 | Iter Mean Loss 281.8920
2020-11-05 21:04:38,313 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 310.1771 | Iter Mean Loss 291.3204
2020-11-05 21:04:38,322 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 263.4282 | Iter Mean Loss 284.3473
2020-11-05 21:04:38,330 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 234.8489 | Iter Mean Loss 274.4476
2020-11-05 21:04:38,332 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.6286
2020-11-05 21:04:38,342 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 236.6264 | Iter Mean Loss 236.6264
2020-11-05 21:04:38,350 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 217.0520 | Iter Mean Loss 226.8392
2020-11-05 21:04:38,357 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.5522 | Iter Mean Loss 238.0769
2020-11-05 21:04:38,365 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 219.7862 | Iter Mean Loss 233.5042
2020-11-05 21:04:38,373 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 194.8294 | Iter Mean Loss 225.7692
2020-11-05 21:04:38,375 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.6161
2020-11-05 21:04:38,383 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 195.2402 | Iter Mean Loss 195.2402
2020-11-05 21:04:38,391 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 179.2348 | Iter Mean Loss 187.2375
2020-11-05 21:04:38,398 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 224.8896 | Iter Mean Loss 199.7882
2020-11-05 21:04:38,406 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 188.5862 | Iter Mean Loss 196.9877
2020-11-05 21:04:38,414 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 166.2150 | Iter Mean Loss 190.8331
2020-11-05 21:04:38,416 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6060
2020-11-05 21:04:38,424 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7128 | Iter Mean Loss 165.7128
2020-11-05 21:04:38,431 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 152.6226 | Iter Mean Loss 159.1677
2020-11-05 21:04:38,439 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 199.3787 | Iter Mean Loss 172.5714
2020-11-05 21:04:38,446 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 166.3069 | Iter Mean Loss 171.0053
2020-11-05 21:04:38,454 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 145.7488 | Iter Mean Loss 165.9540
2020-11-05 21:04:38,456 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.5978
2020-11-05 21:04:38,465 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 144.5331 | Iter Mean Loss 144.5331
2020-11-05 21:04:38,473 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 133.6582 | Iter Mean Loss 139.0957
2020-11-05 21:04:38,481 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 180.6999 | Iter Mean Loss 152.9638
2020-11-05 21:04:38,489 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 149.9379 | Iter Mean Loss 152.2073
2020-11-05 21:04:38,497 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 130.6678 | Iter Mean Loss 147.8994
2020-11-05 21:04:38,499 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5912
2020-11-05 21:04:38,508 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 128.7950 | Iter Mean Loss 128.7950
2020-11-05 21:04:38,515 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 119.4939 | Iter Mean Loss 124.1445
2020-11-05 21:04:38,523 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 166.2718 | Iter Mean Loss 138.1869
2020-11-05 21:04:38,532 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 137.1909 | Iter Mean Loss 137.9379
2020-11-05 21:04:38,540 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 118.9059 | Iter Mean Loss 134.1315
2020-11-05 21:04:38,542 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5858
2020-11-05 21:04:38,550 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 116.3777 | Iter Mean Loss 116.3777
2020-11-05 21:04:38,559 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.1299 | Iter Mean Loss 112.2538
2020-11-05 21:04:38,567 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 154.3308 | Iter Mean Loss 126.2795
2020-11-05 21:04:38,575 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 126.5405 | Iter Mean Loss 126.3447
2020-11-05 21:04:38,583 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 109.1168 | Iter Mean Loss 122.8991
2020-11-05 21:04:38,585 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.5813
2020-11-05 21:04:38,594 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 105.9358 | Iter Mean Loss 105.9358
2020-11-05 21:04:38,602 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 98.3574 | Iter Mean Loss 102.1466
2020-11-05 21:04:38,609 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 143.8448 | Iter Mean Loss 116.0460
2020-11-05 21:04:38,617 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 117.1201 | Iter Mean Loss 116.3145
2020-11-05 21:04:38,625 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 100.5567 | Iter Mean Loss 113.1630
2020-11-05 21:04:38,627 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.5768
2020-11-05 21:04:38,636 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 96.7500 | Iter Mean Loss 96.7500
2020-11-05 21:04:38,644 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 89.5796 | Iter Mean Loss 93.1648
2020-11-05 21:04:38,651 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.3275 | Iter Mean Loss 106.8857
2020-11-05 21:04:38,659 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 108.5400 | Iter Mean Loss 107.2993
2020-11-05 21:04:38,667 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 92.8969 | Iter Mean Loss 104.4188
2020-11-05 21:04:38,669 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.5719
2020-11-05 21:04:38,678 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 88.5143 | Iter Mean Loss 88.5143
2020-11-05 21:04:38,685 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 81.5814 | Iter Mean Loss 85.0478
2020-11-05 21:04:38,693 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 125.6180 | Iter Mean Loss 98.5712
2020-11-05 21:04:38,701 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.6804 | Iter Mean Loss 99.0985
2020-11-05 21:04:38,709 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 86.0280 | Iter Mean Loss 96.4844
2020-11-05 21:04:38,711 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.5662
2020-11-05 21:04:38,719 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 81.1286 | Iter Mean Loss 81.1286
2020-11-05 21:04:38,728 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 74.3207 | Iter Mean Loss 77.7246
2020-11-05 21:04:38,736 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 117.6934 | Iter Mean Loss 91.0476
2020-11-05 21:04:38,744 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.5280 | Iter Mean Loss 91.6677
2020-11-05 21:04:38,752 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 79.9200 | Iter Mean Loss 89.3181
2020-11-05 21:04:38,754 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.5598
2020-11-05 21:04:38,763 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.5577 | Iter Mean Loss 74.5577
2020-11-05 21:04:38,771 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 67.7987 | Iter Mean Loss 71.1782
2020-11-05 21:04:38,779 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 110.5582 | Iter Mean Loss 84.3049
2020-11-05 21:04:38,787 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.0850 | Iter Mean Loss 84.9999
2020-11-05 21:04:38,795 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 74.5488 | Iter Mean Loss 82.9097
2020-11-05 21:04:38,797 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.5531
2020-11-05 21:04:38,805 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.7612 | Iter Mean Loss 68.7612
2020-11-05 21:04:38,813 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 61.9997 | Iter Mean Loss 65.3805
2020-11-05 21:04:38,821 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 104.1932 | Iter Mean Loss 78.3180
2020-11-05 21:04:38,828 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.3271 | Iter Mean Loss 79.0703
2020-11-05 21:04:38,836 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 69.8635 | Iter Mean Loss 77.2289
2020-11-05 21:04:38,838 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.5464
2020-11-05 21:04:38,847 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.6676 | Iter Mean Loss 63.6676
2020-11-05 21:04:38,855 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 56.8697 | Iter Mean Loss 60.2687
2020-11-05 21:04:38,863 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 98.5402 | Iter Mean Loss 73.0259
2020-11-05 21:04:38,870 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.1936 | Iter Mean Loss 73.8178
2020-11-05 21:04:38,878 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 65.7818 | Iter Mean Loss 72.2106
2020-11-05 21:04:38,880 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.5403
2020-11-05 21:04:38,888 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.1769 | Iter Mean Loss 59.1769
2020-11-05 21:04:38,896 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 52.3209 | Iter Mean Loss 55.7489
2020-11-05 21:04:38,903 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 93.5118 | Iter Mean Loss 68.3365
2020-11-05 21:04:38,911 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 71.5985 | Iter Mean Loss 69.1520
2020-11-05 21:04:38,919 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 62.2030 | Iter Mean Loss 67.7622
2020-11-05 21:04:38,921 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.5349
2020-11-05 21:04:38,929 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.1791 | Iter Mean Loss 55.1791
2020-11-05 21:04:38,936 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 48.2524 | Iter Mean Loss 51.7158
2020-11-05 21:04:38,944 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 89.0110 | Iter Mean Loss 64.1475
2020-11-05 21:04:38,952 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 67.4521 | Iter Mean Loss 64.9737
2020-11-05 21:04:38,960 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 59.0294 | Iter Mean Loss 63.7848
2020-11-05 21:04:38,962 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.5301
2020-11-05 21:04:38,970 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.5756 | Iter Mean Loss 51.5756
2020-11-05 21:04:38,978 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.5715 | Iter Mean Loss 48.0735
2020-11-05 21:04:38,986 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 84.9521 | Iter Mean Loss 60.3664
2020-11-05 21:04:38,993 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 63.6805 | Iter Mean Loss 61.1949
2020-11-05 21:04:39,001 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 56.1838 | Iter Mean Loss 60.1927
2020-11-05 21:04:39,003 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.5260
2020-11-05 21:04:39,011 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2950 | Iter Mean Loss 48.2950
2020-11-05 21:04:39,019 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2096 | Iter Mean Loss 44.7523
2020-11-05 21:04:39,028 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 81.2730 | Iter Mean Loss 56.9259
2020-11-05 21:04:39,035 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 60.2347 | Iter Mean Loss 57.7531
2020-11-05 21:04:39,043 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 53.6153 | Iter Mean Loss 56.9255
2020-11-05 21:04:39,045 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.5224
2020-11-05 21:04:39,054 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.2965 | Iter Mean Loss 45.2965
2020-11-05 21:04:39,061 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.1255 | Iter Mean Loss 41.7110
2020-11-05 21:04:39,069 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.9367 | Iter Mean Loss 53.7862
2020-11-05 21:04:39,077 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 57.0892 | Iter Mean Loss 54.6120
2020-11-05 21:04:39,085 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 51.2955 | Iter Mean Loss 53.9487
2020-11-05 21:04:39,087 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.5192
2020-11-05 21:04:39,095 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.5641 | Iter Mean Loss 42.5641
2020-11-05 21:04:39,103 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.3007 | Iter Mean Loss 38.9324
2020-11-05 21:04:39,111 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 74.9256 | Iter Mean Loss 50.9301
2020-11-05 21:04:39,118 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 54.2351 | Iter Mean Loss 51.7564
2020-11-05 21:04:39,126 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 49.2126 | Iter Mean Loss 51.2476
2020-11-05 21:04:39,128 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.5164
2020-11-05 21:04:39,136 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.0977 | Iter Mean Loss 40.0977
2020-11-05 21:04:39,144 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 32.7323 | Iter Mean Loss 36.4150
2020-11-05 21:04:39,151 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.2329 | Iter Mean Loss 48.3543
2020-11-05 21:04:39,159 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.6722 | Iter Mean Loss 49.1838
2020-11-05 21:04:39,167 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 47.3629 | Iter Mean Loss 48.8196
2020-11-05 21:04:39,169 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.5139
2020-11-05 21:04:39,177 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.9030 | Iter Mean Loss 37.9030
2020-11-05 21:04:39,185 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 30.4248 | Iter Mean Loss 34.1639
2020-11-05 21:04:39,192 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.8550 | Iter Mean Loss 46.0609
2020-11-05 21:04:39,200 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.4024 | Iter Mean Loss 46.8963
2020-11-05 21:04:39,207 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.7445 | Iter Mean Loss 46.6659
2020-11-05 21:04:39,209 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.5117
2020-11-05 21:04:39,217 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9842 | Iter Mean Loss 35.9842
2020-11-05 21:04:39,225 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.3828 | Iter Mean Loss 32.1835
2020-11-05 21:04:39,233 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.7854 | Iter Mean Loss 44.0508
2020-11-05 21:04:39,240 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.4234 | Iter Mean Loss 44.8940
2020-11-05 21:04:39,248 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 44.3515 | Iter Mean Loss 44.7855
2020-11-05 21:04:39,250 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.5098
2020-11-05 21:04:39,258 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.3389 | Iter Mean Loss 34.3389
2020-11-05 21:04:39,265 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.6056 | Iter Mean Loss 30.4722
2020-11-05 21:04:39,274 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0123 | Iter Mean Loss 42.3189
2020-11-05 21:04:39,281 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.7268 | Iter Mean Loss 43.1709
2020-11-05 21:04:39,289 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 43.1727 | Iter Mean Loss 43.1712
2020-11-05 21:04:39,291 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.5081
2020-11-05 21:04:39,299 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.9560 | Iter Mean Loss 32.9560
2020-11-05 21:04:39,307 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.0850 | Iter Mean Loss 29.0205
2020-11-05 21:04:39,315 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.5169 | Iter Mean Loss 40.8526
2020-11-05 21:04:39,323 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.2964 | Iter Mean Loss 41.7136
2020-11-05 21:04:39,331 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 42.1911 | Iter Mean Loss 41.8091
2020-11-05 21:04:39,333 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.5066
2020-11-05 21:04:39,342 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.8164 | Iter Mean Loss 31.8164
2020-11-05 21:04:39,349 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.8048 | Iter Mean Loss 27.8106
2020-11-05 21:04:39,357 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2742 | Iter Mean Loss 39.6318
2020-11-05 21:04:39,365 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.1094 | Iter Mean Loss 40.5012
2020-11-05 21:04:39,373 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 41.3853 | Iter Mean Loss 40.6780
2020-11-05 21:04:39,375 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.5052
2020-11-05 21:04:39,383 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.8940 | Iter Mean Loss 30.8940
2020-11-05 21:04:39,391 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7426 | Iter Mean Loss 26.8183
2020-11-05 21:04:39,399 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.2539 | Iter Mean Loss 38.6302
2020-11-05 21:04:39,406 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1375 | Iter Mean Loss 39.5070
2020-11-05 21:04:39,417 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.7305 | Iter Mean Loss 39.7517
2020-11-05 21:04:39,420 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.5041
2020-11-05 21:04:39,430 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1582 | Iter Mean Loss 30.1582
2020-11-05 21:04:39,441 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.8714 | Iter Mean Loss 26.0148
2020-11-05 21:04:39,452 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.4230 | Iter Mean Loss 37.8175
2020-11-05 21:04:39,462 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3496 | Iter Mean Loss 38.7006
2020-11-05 21:04:39,473 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.2007 | Iter Mean Loss 39.0006
2020-11-05 21:04:39,476 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.2817 | MSE 0.5031
2020-11-05 21:04:39,488 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.5766 | Iter Mean Loss 29.5766
2020-11-05 21:04:39,498 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.1624 | Iter Mean Loss 25.3695
2020-11-05 21:04:39,507 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.7478 | Iter Mean Loss 37.1623
2020-11-05 21:04:39,516 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.7138 | Iter Mean Loss 38.0501
2020-11-05 21:04:39,524 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.7704 | Iter Mean Loss 38.3942
2020-11-05 21:04:39,526 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.2817 | MSE 0.5022
2020-11-05 21:04:39,536 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.1174 | Iter Mean Loss 29.1174
2020-11-05 21:04:39,545 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5868 | Iter Mean Loss 24.8521
2020-11-05 21:04:39,555 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.1961 | Iter Mean Loss 36.6334
2020-11-05 21:04:39,564 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1997 | Iter Mean Loss 37.5250
2020-11-05 21:04:39,573 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.4166 | Iter Mean Loss 37.9033
2020-11-05 21:04:39,576 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.2817 | MSE 0.5015
2020-11-05 21:04:39,586 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.7520 | Iter Mean Loss 28.7520
2020-11-05 21:04:39,594 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1178 | Iter Mean Loss 24.4349
2020-11-05 21:04:39,603 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.7387 | Iter Mean Loss 36.2028
2020-11-05 21:04:39,611 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7799 | Iter Mean Loss 37.0971
2020-11-05 21:04:39,618 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.1192 | Iter Mean Loss 37.5015
2020-11-05 21:04:39,620 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.2817 | MSE 0.5009
2020-11-05 21:04:39,628 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4556 | Iter Mean Loss 28.4556
2020-11-05 21:04:39,636 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7321 | Iter Mean Loss 24.0938
2020-11-05 21:04:39,643 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3507 | Iter Mean Loss 35.8461
2020-11-05 21:04:39,651 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4309 | Iter Mean Loss 36.7423
2020-11-05 21:04:39,658 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.8614 | Iter Mean Loss 37.1661
2020-11-05 21:04:39,660 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.2817 | MSE 0.5003
2020-11-05 21:04:39,669 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2086 | Iter Mean Loss 28.2086
2020-11-05 21:04:39,676 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.4101 | Iter Mean Loss 23.8093
2020-11-05 21:04:39,684 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0119 | Iter Mean Loss 35.5435
2020-11-05 21:04:39,691 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1339 | Iter Mean Loss 36.4411
2020-11-05 21:04:39,699 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.6306 | Iter Mean Loss 36.8790
2020-11-05 21:04:39,701 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.2817 | MSE 0.4999
2020-11-05 21:04:39,709 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.9961 | Iter Mean Loss 27.9961
2020-11-05 21:04:39,716 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1364 | Iter Mean Loss 23.5663
2020-11-05 21:04:39,724 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7064 | Iter Mean Loss 35.2796
2020-11-05 21:04:39,731 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8739 | Iter Mean Loss 36.1782
2020-11-05 21:04:39,739 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.4172 | Iter Mean Loss 36.6260
2020-11-05 21:04:39,741 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.2817 | MSE 0.4996
2020-11-05 21:04:39,749 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8074 | Iter Mean Loss 27.8074
2020-11-05 21:04:39,756 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8993 | Iter Mean Loss 23.3534
2020-11-05 21:04:39,764 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.4225 | Iter Mean Loss 35.0431
2020-11-05 21:04:39,771 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6401 | Iter Mean Loss 35.9423
2020-11-05 21:04:39,779 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.2145 | Iter Mean Loss 36.3967
2020-11-05 21:04:39,781 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.2817 | MSE 0.4993
2020-11-05 21:04:39,790 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.6351 | Iter Mean Loss 27.6351
2020-11-05 21:04:39,797 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6900 | Iter Mean Loss 23.1625
2020-11-05 21:04:39,805 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.1517 | Iter Mean Loss 34.8256
2020-11-05 21:04:39,812 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.4241 | Iter Mean Loss 35.7252
2020-11-05 21:04:39,820 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.0179 | Iter Mean Loss 36.1837
2020-11-05 21:04:39,822 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.2817 | MSE 0.4991
2020-11-05 21:04:39,829 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.4741 | Iter Mean Loss 27.4741
2020-11-05 21:04:39,837 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.5017 | Iter Mean Loss 22.9879
2020-11-05 21:04:39,844 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.8881 | Iter Mean Loss 34.6213
2020-11-05 21:04:39,852 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2203 | Iter Mean Loss 35.5210
2020-11-05 21:04:39,859 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.8245 | Iter Mean Loss 35.9817
2020-11-05 21:04:39,861 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.2817 | MSE 0.4989
2020-11-05 21:04:39,869 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3210 | Iter Mean Loss 27.3210
2020-11-05 21:04:39,877 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3295 | Iter Mean Loss 22.8252
2020-11-05 21:04:39,884 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.6279 | Iter Mean Loss 34.4261
2020-11-05 21:04:39,891 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0246 | Iter Mean Loss 35.3257
2020-11-05 21:04:39,899 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.6324 | Iter Mean Loss 35.7871
2020-11-05 21:04:39,901 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.2817 | MSE 0.4988
2020-11-05 21:04:39,909 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.1733 | Iter Mean Loss 27.1733
2020-11-05 21:04:39,916 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.1695 | Iter Mean Loss 22.6714
2020-11-05 21:04:39,923 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3683 | Iter Mean Loss 34.2370
2020-11-05 21:04:39,930 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8340 | Iter Mean Loss 35.1363
2020-11-05 21:04:39,938 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.4404 | Iter Mean Loss 35.5971
2020-11-05 21:04:39,940 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.2817 | MSE 0.4987
2020-11-05 21:04:39,948 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0294 | Iter Mean Loss 27.0294
2020-11-05 21:04:39,956 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0186 | Iter Mean Loss 22.5240
2020-11-05 21:04:39,964 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.1077 | Iter Mean Loss 34.0519
2020-11-05 21:04:39,971 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.6466 | Iter Mean Loss 34.9506
2020-11-05 21:04:39,979 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.2477 | Iter Mean Loss 35.4100
2020-11-05 21:04:39,981 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.2817 | MSE 0.4986
2020-11-05 21:04:39,990 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.8878 | Iter Mean Loss 26.8878
2020-11-05 21:04:39,998 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.8743 | Iter Mean Loss 22.3811
2020-11-05 21:04:40,005 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.8452 | Iter Mean Loss 33.8691
2020-11-05 21:04:40,013 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.4607 | Iter Mean Loss 34.7670
2020-11-05 21:04:40,020 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.0539 | Iter Mean Loss 35.2244
2020-11-05 21:04:40,022 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.2817 | MSE 0.4986
2020-11-05 21:04:40,030 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7473 | Iter Mean Loss 26.7473
2020-11-05 21:04:40,037 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7345 | Iter Mean Loss 22.2409
2020-11-05 21:04:40,045 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.5801 | Iter Mean Loss 33.6873
2020-11-05 21:04:40,052 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2753 | Iter Mean Loss 34.5843
2020-11-05 21:04:40,059 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.8584 | Iter Mean Loss 35.0391
2020-11-05 21:04:40,061 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.2817 | MSE 0.4985
2020-11-05 21:04:40,069 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6069 | Iter Mean Loss 26.6069
2020-11-05 21:04:40,077 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5973 | Iter Mean Loss 22.1021
2020-11-05 21:04:40,085 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.3121 | Iter Mean Loss 33.5054
2020-11-05 21:04:40,092 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0895 | Iter Mean Loss 34.4015
2020-11-05 21:04:40,100 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6610 | Iter Mean Loss 34.8534
2020-11-05 21:04:40,102 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.2817 | MSE 0.4985
2020-11-05 21:04:40,110 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.4657 | Iter Mean Loss 26.4657
2020-11-05 21:04:40,118 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4612 | Iter Mean Loss 21.9635
2020-11-05 21:04:40,126 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.0410 | Iter Mean Loss 33.3226
2020-11-05 21:04:40,134 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.9027 | Iter Mean Loss 34.2176
2020-11-05 21:04:40,141 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.4613 | Iter Mean Loss 34.6664
2020-11-05 21:04:40,143 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.2817 | MSE 0.4985
2020-11-05 21:04:40,152 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3228 | Iter Mean Loss 26.3228
2020-11-05 21:04:40,160 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.3249 | Iter Mean Loss 21.8239
2020-11-05 21:04:40,167 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.7666 | Iter Mean Loss 33.1381
2020-11-05 21:04:40,176 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.7143 | Iter Mean Loss 34.0322
2020-11-05 21:04:40,185 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.2590 | Iter Mean Loss 34.4775
2020-11-05 21:04:40,187 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.2817 | MSE 0.4985
2020-11-05 21:04:40,196 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1776 | Iter Mean Loss 26.1776
2020-11-05 21:04:40,206 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.1874 | Iter Mean Loss 21.6825
2020-11-05 21:04:40,214 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.4889 | Iter Mean Loss 32.9513
2020-11-05 21:04:40,224 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.5238 | Iter Mean Loss 33.8444
2020-11-05 21:04:40,232 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.0538 | Iter Mean Loss 34.2863
2020-11-05 21:04:40,235 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.2817 | MSE 0.4985
2020-11-05 21:04:40,244 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.0292 | Iter Mean Loss 26.0292
2020-11-05 21:04:40,253 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0477 | Iter Mean Loss 21.5385
2020-11-05 21:04:40,261 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.2077 | Iter Mean Loss 32.7616
2020-11-05 21:04:40,269 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.3308 | Iter Mean Loss 33.6539
2020-11-05 21:04:40,278 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.8454 | Iter Mean Loss 34.0922
2020-11-05 21:04:40,280 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,289 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8773 | Iter Mean Loss 25.8773
2020-11-05 21:04:40,297 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.9051 | Iter Mean Loss 21.3912
2020-11-05 21:04:40,305 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.9228 | Iter Mean Loss 32.5684
2020-11-05 21:04:40,313 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.1349 | Iter Mean Loss 33.4600
2020-11-05 21:04:40,323 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.6332 | Iter Mean Loss 33.8947
2020-11-05 21:04:40,326 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,335 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7211 | Iter Mean Loss 25.7211
2020-11-05 21:04:40,344 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7588 | Iter Mean Loss 21.2400
2020-11-05 21:04:40,352 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.6339 | Iter Mean Loss 32.3713
2020-11-05 21:04:40,360 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.9358 | Iter Mean Loss 33.2624
2020-11-05 21:04:40,369 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.4170 | Iter Mean Loss 33.6933
2020-11-05 21:04:40,371 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,380 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.5602 | Iter Mean Loss 25.5602
2020-11-05 21:04:40,388 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.6084 | Iter Mean Loss 21.0843
2020-11-05 21:04:40,396 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.3408 | Iter Mean Loss 32.1698
2020-11-05 21:04:40,404 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.7330 | Iter Mean Loss 33.0606
2020-11-05 21:04:40,412 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.1963 | Iter Mean Loss 33.4877
2020-11-05 21:04:40,415 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,423 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3942 | Iter Mean Loss 25.3942
2020-11-05 21:04:40,431 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.4533 | Iter Mean Loss 20.9238
2020-11-05 21:04:40,439 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0431 | Iter Mean Loss 31.9635
2020-11-05 21:04:40,448 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.5263 | Iter Mean Loss 32.8542
2020-11-05 21:04:40,456 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.9707 | Iter Mean Loss 33.2775
2020-11-05 21:04:40,458 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,468 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2227 | Iter Mean Loss 25.2227
2020-11-05 21:04:40,476 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.2930 | Iter Mean Loss 20.7579
2020-11-05 21:04:40,485 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.7405 | Iter Mean Loss 31.7521
2020-11-05 21:04:40,494 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.3152 | Iter Mean Loss 32.6429
2020-11-05 21:04:40,502 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.7399 | Iter Mean Loss 33.0623
2020-11-05 21:04:40,504 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,515 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0453 | Iter Mean Loss 25.0453
2020-11-05 21:04:40,524 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1273 | Iter Mean Loss 20.5863
2020-11-05 21:04:40,532 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.4327 | Iter Mean Loss 31.5351
2020-11-05 21:04:40,540 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0995 | Iter Mean Loss 32.4262
2020-11-05 21:04:40,548 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.5034 | Iter Mean Loss 32.8417
2020-11-05 21:04:40,551 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,560 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8616 | Iter Mean Loss 24.8616
2020-11-05 21:04:40,568 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9557 | Iter Mean Loss 20.4086
2020-11-05 21:04:40,576 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.1193 | Iter Mean Loss 31.3122
2020-11-05 21:04:40,584 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.8789 | Iter Mean Loss 32.2039
2020-11-05 21:04:40,592 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.2609 | Iter Mean Loss 32.6153
2020-11-05 21:04:40,594 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,603 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6712 | Iter Mean Loss 24.6712
2020-11-05 21:04:40,610 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.7779 | Iter Mean Loss 20.2245
2020-11-05 21:04:40,618 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.7999 | Iter Mean Loss 31.0830
2020-11-05 21:04:40,626 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.6530 | Iter Mean Loss 31.9755
2020-11-05 21:04:40,634 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.0120 | Iter Mean Loss 32.3828
2020-11-05 21:04:40,636 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,644 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4738 | Iter Mean Loss 24.4738
2020-11-05 21:04:40,652 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.5936 | Iter Mean Loss 20.0337
2020-11-05 21:04:40,659 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.4743 | Iter Mean Loss 30.8472
2020-11-05 21:04:40,667 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.4216 | Iter Mean Loss 31.7408
2020-11-05 21:04:40,674 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.7564 | Iter Mean Loss 32.1439
2020-11-05 21:04:40,677 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.2817 | MSE 0.4984
2020-11-05 21:04:40,685 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2691 | Iter Mean Loss 24.2691
2020-11-05 21:04:40,692 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4025 | Iter Mean Loss 19.8358
2020-11-05 21:04:40,700 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.1423 | Iter Mean Loss 30.6046
2020-11-05 21:04:40,707 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1844 | Iter Mean Loss 31.4996
2020-11-05 21:04:40,715 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.4938 | Iter Mean Loss 31.8984
2020-11-05 21:04:40,717 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,725 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0568 | Iter Mean Loss 24.0568
2020-11-05 21:04:40,733 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2046 | Iter Mean Loss 19.6307
2020-11-05 21:04:40,741 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.8035 | Iter Mean Loss 30.3549
2020-11-05 21:04:40,749 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.9413 | Iter Mean Loss 31.2515
2020-11-05 21:04:40,757 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.2241 | Iter Mean Loss 31.6460
2020-11-05 21:04:40,759 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,771 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8366 | Iter Mean Loss 23.8366
2020-11-05 21:04:40,781 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.9995 | Iter Mean Loss 19.4181
2020-11-05 21:04:40,788 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.4578 | Iter Mean Loss 30.0980
2020-11-05 21:04:40,796 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6920 | Iter Mean Loss 30.9965
2020-11-05 21:04:40,804 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9471 | Iter Mean Loss 31.3866
2020-11-05 21:04:40,806 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,815 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6084 | Iter Mean Loss 23.6084
2020-11-05 21:04:40,823 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7872 | Iter Mean Loss 19.1978
2020-11-05 21:04:40,831 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1051 | Iter Mean Loss 29.8336
2020-11-05 21:04:40,840 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4366 | Iter Mean Loss 30.7343
2020-11-05 21:04:40,849 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.6626 | Iter Mean Loss 31.1200
2020-11-05 21:04:40,851 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,860 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3720 | Iter Mean Loss 23.3720
2020-11-05 21:04:40,870 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5678 | Iter Mean Loss 18.9699
2020-11-05 21:04:40,879 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7455 | Iter Mean Loss 29.5618
2020-11-05 21:04:40,887 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1749 | Iter Mean Loss 30.4650
2020-11-05 21:04:40,896 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.3708 | Iter Mean Loss 30.8462
2020-11-05 21:04:40,899 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,908 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1274 | Iter Mean Loss 23.1274
2020-11-05 21:04:40,917 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.3412 | Iter Mean Loss 18.7343
2020-11-05 21:04:40,925 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3788 | Iter Mean Loss 29.2825
2020-11-05 21:04:40,934 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9071 | Iter Mean Loss 30.1886
2020-11-05 21:04:40,941 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.0718 | Iter Mean Loss 30.5653
2020-11-05 21:04:40,944 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,953 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8747 | Iter Mean Loss 22.8747
2020-11-05 21:04:40,962 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.1076 | Iter Mean Loss 18.4912
2020-11-05 21:04:40,970 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.0055 | Iter Mean Loss 28.9959
2020-11-05 21:04:40,977 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6333 | Iter Mean Loss 29.9053
2020-11-05 21:04:40,985 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.7657 | Iter Mean Loss 30.2774
2020-11-05 21:04:40,987 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:40,995 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6140 | Iter Mean Loss 22.6140
2020-11-05 21:04:41,003 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.8674 | Iter Mean Loss 18.2407
2020-11-05 21:04:41,012 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.6256 | Iter Mean Loss 28.7023
2020-11-05 21:04:41,021 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.3538 | Iter Mean Loss 29.6152
2020-11-05 21:04:41,029 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.4529 | Iter Mean Loss 29.9827
2020-11-05 21:04:41,032 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:41,040 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3457 | Iter Mean Loss 22.3457
2020-11-05 21:04:41,049 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.6209 | Iter Mean Loss 17.9833
2020-11-05 21:04:41,059 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.2396 | Iter Mean Loss 28.4020
2020-11-05 21:04:41,067 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.0689 | Iter Mean Loss 29.3188
2020-11-05 21:04:41,076 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.1339 | Iter Mean Loss 29.6818
2020-11-05 21:04:41,079 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.2817 | MSE 0.4983
2020-11-05 21:04:41,087 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0700 | Iter Mean Loss 22.0700
2020-11-05 21:04:41,096 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.3688 | Iter Mean Loss 17.7194
2020-11-05 21:04:41,104 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.8480 | Iter Mean Loss 28.0956
2020-11-05 21:04:41,114 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7791 | Iter Mean Loss 29.0165
2020-11-05 21:04:41,122 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 29.3751
2020-11-05 21:04:41,124 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.2817 | MSE 0.4982
2020-11-05 21:04:41,133 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7878 | Iter Mean Loss 21.7878
2020-11-05 21:04:41,141 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.1117 | Iter Mean Loss 17.4497
2020-11-05 21:04:41,148 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.4515 | Iter Mean Loss 27.7837
2020-11-05 21:04:41,156 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.4851 | Iter Mean Loss 28.7090
2020-11-05 21:04:41,164 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.4802 | Iter Mean Loss 29.0633
2020-11-05 21:04:41,166 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.2817 | MSE 0.4982
2020-11-05 21:04:41,174 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4996 | Iter Mean Loss 21.4996
2020-11-05 21:04:41,182 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.8505 | Iter Mean Loss 17.1750
2020-11-05 21:04:41,189 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.0509 | Iter Mean Loss 27.4670
2020-11-05 21:04:41,197 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.1877 | Iter Mean Loss 28.3972
2020-11-05 21:04:41,204 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.1473 | Iter Mean Loss 28.7472
2020-11-05 21:04:41,206 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.2817 | MSE 0.4982
2020-11-05 21:04:41,215 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2065 | Iter Mean Loss 21.2065
2020-11-05 21:04:41,223 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5862 | Iter Mean Loss 16.8963
2020-11-05 21:04:41,231 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.6471 | Iter Mean Loss 27.1466
2020-11-05 21:04:41,238 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8876 | Iter Mean Loss 28.0818
2020-11-05 21:04:41,247 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.8117 | Iter Mean Loss 28.4278
2020-11-05 21:04:41,250 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.2817 | MSE 0.4982
2020-11-05 21:04:41,258 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9094 | Iter Mean Loss 20.9094
2020-11-05 21:04:41,267 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.3201 | Iter Mean Loss 16.6147
2020-11-05 21:04:41,275 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.2411 | Iter Mean Loss 26.8235
2020-11-05 21:04:41,284 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5859 | Iter Mean Loss 27.7641
2020-11-05 21:04:41,291 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4748 | Iter Mean Loss 28.1063
2020-11-05 21:04:41,295 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.2817 | MSE 0.4981
2020-11-05 21:04:41,303 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6096 | Iter Mean Loss 20.6096
2020-11-05 21:04:41,312 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.0533 | Iter Mean Loss 16.3314
2020-11-05 21:04:41,321 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.8343 | Iter Mean Loss 26.4990
2020-11-05 21:04:41,330 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.2837 | Iter Mean Loss 27.4452
2020-11-05 21:04:41,337 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.1379 | Iter Mean Loss 27.7837
2020-11-05 21:04:41,340 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.2817 | MSE 0.4981
2020-11-05 21:04:41,348 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3084 | Iter Mean Loss 20.3084
2020-11-05 21:04:41,355 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7873 | Iter Mean Loss 16.0478
2020-11-05 21:04:41,363 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.4277 | Iter Mean Loss 26.1744
2020-11-05 21:04:41,371 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9821 | Iter Mean Loss 27.1264
2020-11-05 21:04:41,378 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.8025 | Iter Mean Loss 27.4616
2020-11-05 21:04:41,380 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.2817 | MSE 0.4980
2020-11-05 21:04:41,388 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0072 | Iter Mean Loss 20.0072
2020-11-05 21:04:41,396 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.5235 | Iter Mean Loss 15.7653
2020-11-05 21:04:41,403 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.0226 | Iter Mean Loss 25.8511
2020-11-05 21:04:41,411 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6824 | Iter Mean Loss 26.8089
2020-11-05 21:04:41,418 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.4702 | Iter Mean Loss 27.1412
2020-11-05 21:04:41,420 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.2817 | MSE 0.4980
2020-11-05 21:04:41,429 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7075 | Iter Mean Loss 19.7075
2020-11-05 21:04:41,437 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2634 | Iter Mean Loss 15.4854
2020-11-05 21:04:41,445 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.6204 | Iter Mean Loss 25.5304
2020-11-05 21:04:41,453 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.3856 | Iter Mean Loss 26.4942
2020-11-05 21:04:41,462 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.1424 | Iter Mean Loss 26.8239
2020-11-05 21:04:41,464 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.2817 | MSE 0.4979
2020-11-05 21:04:41,472 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4107 | Iter Mean Loss 19.4107
2020-11-05 21:04:41,481 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.0085 | Iter Mean Loss 15.2096
2020-11-05 21:04:41,489 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.2223 | Iter Mean Loss 25.2138
2020-11-05 21:04:41,497 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0930 | Iter Mean Loss 26.1836
2020-11-05 21:04:41,504 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.8205 | Iter Mean Loss 26.5110
2020-11-05 21:04:41,507 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.2817 | MSE 0.4978
2020-11-05 21:04:41,515 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1182 | Iter Mean Loss 19.1182
2020-11-05 21:04:41,523 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7601 | Iter Mean Loss 14.9391
2020-11-05 21:04:41,531 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.8294 | Iter Mean Loss 24.9026
2020-11-05 21:04:41,539 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8055 | Iter Mean Loss 25.8783
2020-11-05 21:04:41,546 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.5060 | Iter Mean Loss 26.2038
2020-11-05 21:04:41,548 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.2817 | MSE 0.4978
2020-11-05 21:04:41,556 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8312 | Iter Mean Loss 18.8312
2020-11-05 21:04:41,564 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5194 | Iter Mean Loss 14.6753
2020-11-05 21:04:41,571 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.4427 | Iter Mean Loss 24.5978
2020-11-05 21:04:41,578 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.5241 | Iter Mean Loss 25.5794
2020-11-05 21:04:41,586 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.1998 | Iter Mean Loss 25.9034
2020-11-05 21:04:41,587 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.2817 | MSE 0.4977
2020-11-05 21:04:41,595 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5509 | Iter Mean Loss 18.5509
2020-11-05 21:04:41,603 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.2874 | Iter Mean Loss 14.4192
2020-11-05 21:04:41,610 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0630 | Iter Mean Loss 24.3004
2020-11-05 21:04:41,618 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.2495 | Iter Mean Loss 25.2877
2020-11-05 21:04:41,626 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.9029 | Iter Mean Loss 25.6107
2020-11-05 21:04:41,628 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.2817 | MSE 0.4975
2020-11-05 21:04:41,637 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2782 | Iter Mean Loss 18.2782
2020-11-05 21:04:41,644 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0649 | Iter Mean Loss 14.1715
2020-11-05 21:04:41,652 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6909 | Iter Mean Loss 24.0113
2020-11-05 21:04:41,660 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9822 | Iter Mean Loss 25.0040
2020-11-05 21:04:41,668 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.6160 | Iter Mean Loss 25.3264
2020-11-05 21:04:41,671 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.2817 | MSE 0.4974
2020-11-05 21:04:41,680 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0136 | Iter Mean Loss 18.0136
2020-11-05 21:04:41,688 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8524 | Iter Mean Loss 13.9330
2020-11-05 21:04:41,696 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3267 | Iter Mean Loss 23.7309
2020-11-05 21:04:41,704 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7225 | Iter Mean Loss 24.7288
2020-11-05 21:04:41,712 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.3393 | Iter Mean Loss 25.0509
2020-11-05 21:04:41,714 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.2817 | MSE 0.4972
2020-11-05 21:04:41,723 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7576 | Iter Mean Loss 17.7576
2020-11-05 21:04:41,730 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6501 | Iter Mean Loss 13.7039
2020-11-05 21:04:41,739 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.9706 | Iter Mean Loss 23.4594
2020-11-05 21:04:41,746 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.4706 | Iter Mean Loss 24.4622
2020-11-05 21:04:41,753 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.0730 | Iter Mean Loss 24.7844
2020-11-05 21:04:41,755 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.2817 | MSE 0.4971
2020-11-05 21:04:41,764 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5104 | Iter Mean Loss 17.5104
2020-11-05 21:04:41,771 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4581 | Iter Mean Loss 13.4843
2020-11-05 21:04:41,778 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6225 | Iter Mean Loss 23.1970
2020-11-05 21:04:41,786 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.2264 | Iter Mean Loss 24.2044
2020-11-05 21:04:41,793 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.8169 | Iter Mean Loss 24.5269
2020-11-05 21:04:41,795 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.2817 | MSE 0.4969
2020-11-05 21:04:41,803 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2718 | Iter Mean Loss 17.2718
2020-11-05 21:04:41,810 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2762 | Iter Mean Loss 13.2740
2020-11-05 21:04:41,818 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.2822 | Iter Mean Loss 22.9434
2020-11-05 21:04:41,825 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9895 | Iter Mean Loss 23.9549
2020-11-05 21:04:41,833 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.5706 | Iter Mean Loss 24.2781
2020-11-05 21:04:41,835 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.2817 | MSE 0.4966
2020-11-05 21:04:41,844 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0416 | Iter Mean Loss 17.0416
2020-11-05 21:04:41,852 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.1037 | Iter Mean Loss 13.0727
2020-11-05 21:04:41,859 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.9491 | Iter Mean Loss 22.6982
2020-11-05 21:04:41,868 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7597 | Iter Mean Loss 23.7136
2020-11-05 21:04:41,875 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.3335 | Iter Mean Loss 24.0375
2020-11-05 21:04:41,878 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.2817 | MSE 0.4964
2020-11-05 21:04:41,887 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8193 | Iter Mean Loss 16.8193
2020-11-05 21:04:41,896 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.9402 | Iter Mean Loss 12.8798
2020-11-05 21:04:41,903 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.6228 | Iter Mean Loss 22.4608
2020-11-05 21:04:41,911 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.5364 | Iter Mean Loss 23.4797
2020-11-05 21:04:41,919 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.1048 | Iter Mean Loss 23.8047
2020-11-05 21:04:41,921 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.2817 | MSE 0.4961
2020-11-05 21:04:41,930 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6043 | Iter Mean Loss 16.6043
2020-11-05 21:04:41,938 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.7848 | Iter Mean Loss 12.6946
2020-11-05 21:04:41,945 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3025 | Iter Mean Loss 22.2305
2020-11-05 21:04:41,955 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.3189 | Iter Mean Loss 23.2526
2020-11-05 21:04:41,962 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.8837 | Iter Mean Loss 23.5788
2020-11-05 21:04:41,965 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.2817 | MSE 0.4958
2020-11-05 21:04:41,973 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3959 | Iter Mean Loss 16.3959
2020-11-05 21:04:41,980 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 12.5163
2020-11-05 21:04:41,988 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.9874 | Iter Mean Loss 22.0067
2020-11-05 21:04:41,995 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.1066 | Iter Mean Loss 23.0316
2020-11-05 21:04:42,002 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.6691 | Iter Mean Loss 23.3591
2020-11-05 21:04:42,004 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.2817 | MSE 0.4955
2020-11-05 21:04:42,012 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1933 | Iter Mean Loss 16.1933
2020-11-05 21:04:42,019 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 12.3441
2020-11-05 21:04:42,027 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.6769 | Iter Mean Loss 21.7883
2020-11-05 21:04:42,035 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8988 | Iter Mean Loss 22.8159
2020-11-05 21:04:42,042 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.4602 | Iter Mean Loss 23.1448
2020-11-05 21:04:42,045 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.2817 | MSE 0.4952
2020-11-05 21:04:42,053 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9957 | Iter Mean Loss 15.9957
2020-11-05 21:04:42,061 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3584 | Iter Mean Loss 12.1771
2020-11-05 21:04:42,069 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.3700 | Iter Mean Loss 21.5747
2020-11-05 21:04:42,076 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6948 | Iter Mean Loss 22.6047
2020-11-05 21:04:42,085 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.2559 | Iter Mean Loss 22.9350
2020-11-05 21:04:42,087 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.2817 | MSE 0.4948
2020-11-05 21:04:42,095 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8024 | Iter Mean Loss 15.8024
2020-11-05 21:04:42,103 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 12.0144
2020-11-05 21:04:42,111 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.0662 | Iter Mean Loss 21.3650
2020-11-05 21:04:42,119 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4940 | Iter Mean Loss 22.3973
2020-11-05 21:04:42,127 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.0553 | Iter Mean Loss 22.7289
2020-11-05 21:04:42,129 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.2817 | MSE 0.4944
2020-11-05 21:04:42,138 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6127 | Iter Mean Loss 15.6127
2020-11-05 21:04:42,145 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.0982 | Iter Mean Loss 11.8555
2020-11-05 21:04:42,153 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.7648 | Iter Mean Loss 21.1586
2020-11-05 21:04:42,160 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2957 | Iter Mean Loss 22.1929
2020-11-05 21:04:42,167 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.8577 | Iter Mean Loss 22.5259
2020-11-05 21:04:42,170 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.2817 | MSE 0.4940
2020-11-05 21:04:42,177 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4260 | Iter Mean Loss 15.4260
2020-11-05 21:04:42,185 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9730 | Iter Mean Loss 11.6995
2020-11-05 21:04:42,192 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.4652 | Iter Mean Loss 20.9547
2020-11-05 21:04:42,199 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0996 | Iter Mean Loss 21.9909
2020-11-05 21:04:42,206 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.6624 | Iter Mean Loss 22.3252
2020-11-05 21:04:42,208 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.2817 | MSE 0.4936
2020-11-05 21:04:42,216 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2417 | Iter Mean Loss 15.2417
2020-11-05 21:04:42,223 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.8501 | Iter Mean Loss 11.5459
2020-11-05 21:04:42,230 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.1670 | Iter Mean Loss 20.7529
2020-11-05 21:04:42,238 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.9051 | Iter Mean Loss 21.7910
2020-11-05 21:04:42,246 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.4687 | Iter Mean Loss 22.1265
2020-11-05 21:04:42,248 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.2817 | MSE 0.4932
2020-11-05 21:04:42,256 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0594 | Iter Mean Loss 15.0594
2020-11-05 21:04:42,265 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7290 | Iter Mean Loss 11.3942
2020-11-05 21:04:42,272 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.8697 | Iter Mean Loss 20.5527
2020-11-05 21:04:42,280 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7120 | Iter Mean Loss 21.5925
2020-11-05 21:04:42,288 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.2761 | Iter Mean Loss 21.9292
2020-11-05 21:04:42,290 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.2817 | MSE 0.4927
2020-11-05 21:04:42,299 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8789 | Iter Mean Loss 14.8789
2020-11-05 21:04:42,307 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 11.2441
2020-11-05 21:04:42,316 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.5732 | Iter Mean Loss 20.3538
2020-11-05 21:04:42,324 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5200 | Iter Mean Loss 21.3953
2020-11-05 21:04:42,333 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.0843 | Iter Mean Loss 21.7331
2020-11-05 21:04:42,335 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.2817 | MSE 0.4922
2020-11-05 21:04:42,343 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6999 | Iter Mean Loss 14.6999
2020-11-05 21:04:42,351 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4908 | Iter Mean Loss 11.0953
2020-11-05 21:04:42,359 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.2772 | Iter Mean Loss 20.1560
2020-11-05 21:04:42,366 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3290 | Iter Mean Loss 21.1992
2020-11-05 21:04:42,373 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.8930 | Iter Mean Loss 21.5380
2020-11-05 21:04:42,375 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.2817 | MSE 0.4917
2020-11-05 21:04:42,383 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5223 | Iter Mean Loss 14.5223
2020-11-05 21:04:42,390 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.3731 | Iter Mean Loss 10.9477
2020-11-05 21:04:42,397 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.9818 | Iter Mean Loss 19.9591
2020-11-05 21:04:42,404 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1389 | Iter Mean Loss 21.0040
2020-11-05 21:04:42,412 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.7019 | Iter Mean Loss 21.3436
2020-11-05 21:04:42,415 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.2817 | MSE 0.4912
2020-11-05 21:04:42,424 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3462 | Iter Mean Loss 14.3462
2020-11-05 21:04:42,432 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2563 | Iter Mean Loss 10.8012
2020-11-05 21:04:42,443 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.6868 | Iter Mean Loss 19.7631
2020-11-05 21:04:42,454 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9496 | Iter Mean Loss 20.8097
2020-11-05 21:04:42,465 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.5111 | Iter Mean Loss 21.1500
2020-11-05 21:04:42,467 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.2817 | MSE 0.4907
2020-11-05 21:04:42,479 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1715 | Iter Mean Loss 14.1715
2020-11-05 21:04:42,489 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1402 | Iter Mean Loss 10.6558
2020-11-05 21:04:42,503 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.3925 | Iter Mean Loss 19.5681
2020-11-05 21:04:42,513 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.7613 | Iter Mean Loss 20.6164
2020-11-05 21:04:42,523 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.3204 | Iter Mean Loss 20.9572
2020-11-05 21:04:42,526 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.2817 | MSE 0.4902
2020-11-05 21:04:42,537 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9984 | Iter Mean Loss 13.9984
2020-11-05 21:04:42,547 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.0249 | Iter Mean Loss 10.5117
2020-11-05 21:04:42,555 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.0988 | Iter Mean Loss 19.3741
2020-11-05 21:04:42,564 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5741 | Iter Mean Loss 20.4241
2020-11-05 21:04:42,572 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.1299 | Iter Mean Loss 20.7652
2020-11-05 21:04:42,574 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.2817 | MSE 0.4896
2020-11-05 21:04:42,583 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8272 | Iter Mean Loss 13.8272
2020-11-05 21:04:42,591 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9105 | Iter Mean Loss 10.3689
2020-11-05 21:04:42,599 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.8061 | Iter Mean Loss 19.1813
2020-11-05 21:04:42,607 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3881 | Iter Mean Loss 20.2330
2020-11-05 21:04:42,615 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.9397 | Iter Mean Loss 20.5743
2020-11-05 21:04:42,617 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.2817 | MSE 0.4890
2020-11-05 21:04:42,625 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6581 | Iter Mean Loss 13.6581
2020-11-05 21:04:42,632 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7971 | Iter Mean Loss 10.2276
2020-11-05 21:04:42,640 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.5145 | Iter Mean Loss 18.9899
2020-11-05 21:04:42,647 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2034 | Iter Mean Loss 20.0433
2020-11-05 21:04:42,654 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.7500 | Iter Mean Loss 20.3846
2020-11-05 21:04:42,656 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.2817 | MSE 0.4885
2020-11-05 21:04:42,664 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4913 | Iter Mean Loss 13.4913
2020-11-05 21:04:42,672 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6850 | Iter Mean Loss 10.0881
2020-11-05 21:04:42,680 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2243 | Iter Mean Loss 18.8002
2020-11-05 21:04:42,687 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0204 | Iter Mean Loss 19.8553
2020-11-05 21:04:42,695 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 20.1964
2020-11-05 21:04:42,697 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.2817 | MSE 0.4879
2020-11-05 21:04:42,705 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3273 | Iter Mean Loss 13.3273
2020-11-05 21:04:42,713 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.5742 | Iter Mean Loss 9.9508
2020-11-05 21:04:42,720 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9359 | Iter Mean Loss 18.6125
2020-11-05 21:04:42,728 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8393 | Iter Mean Loss 19.6692
2020-11-05 21:04:42,735 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.3726 | Iter Mean Loss 20.0099
2020-11-05 21:04:42,737 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.2817 | MSE 0.4873
2020-11-05 21:04:42,745 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1664 | Iter Mean Loss 13.1664
2020-11-05 21:04:42,753 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4650 | Iter Mean Loss 9.8157
2020-11-05 21:04:42,760 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.6495 | Iter Mean Loss 18.4270
2020-11-05 21:04:42,768 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6602 | Iter Mean Loss 19.4853
2020-11-05 21:04:42,775 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.1854 | Iter Mean Loss 19.8253
2020-11-05 21:04:42,777 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.2817 | MSE 0.4867
2020-11-05 21:04:42,784 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0090 | Iter Mean Loss 13.0090
2020-11-05 21:04:42,792 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3577 | Iter Mean Loss 9.6834
2020-11-05 21:04:42,799 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.3655 | Iter Mean Loss 18.2441
2020-11-05 21:04:42,806 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4836 | Iter Mean Loss 19.3040
2020-11-05 21:04:42,813 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.9996 | Iter Mean Loss 19.6431
2020-11-05 21:04:42,815 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.2817 | MSE 0.4860
2020-11-05 21:04:42,823 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8554 | Iter Mean Loss 12.8554
2020-11-05 21:04:42,830 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.2525 | Iter Mean Loss 9.5540
2020-11-05 21:04:42,837 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0843 | Iter Mean Loss 18.0641
2020-11-05 21:04:42,844 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3097 | Iter Mean Loss 19.1255
2020-11-05 21:04:42,851 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.8154 | Iter Mean Loss 19.4635
2020-11-05 21:04:42,853 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.2817 | MSE 0.4854
2020-11-05 21:04:42,862 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7061 | Iter Mean Loss 12.7061
2020-11-05 21:04:42,869 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 9.4279
2020-11-05 21:04:42,877 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.8062 | Iter Mean Loss 17.8873
2020-11-05 21:04:42,884 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1387 | Iter Mean Loss 18.9502
2020-11-05 21:04:42,892 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.6330 | Iter Mean Loss 19.2867
2020-11-05 21:04:42,894 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.2817 | MSE 0.4848
2020-11-05 21:04:42,902 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5615 | Iter Mean Loss 12.5615
2020-11-05 21:04:42,910 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.0494 | Iter Mean Loss 9.3055
2020-11-05 21:04:42,918 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5314 | Iter Mean Loss 17.7141
2020-11-05 21:04:42,925 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9709 | Iter Mean Loss 18.7783
2020-11-05 21:04:42,933 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.4529 | Iter Mean Loss 19.1132
2020-11-05 21:04:42,935 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.2817 | MSE 0.4841
2020-11-05 21:04:42,943 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4218 | Iter Mean Loss 12.4218
2020-11-05 21:04:42,951 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9520 | Iter Mean Loss 9.1869
2020-11-05 21:04:42,959 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.2604 | Iter Mean Loss 17.5448
2020-11-05 21:04:42,967 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8066 | Iter Mean Loss 18.6102
2020-11-05 21:04:42,974 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.2752 | Iter Mean Loss 18.9432
2020-11-05 21:04:42,976 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.2817 | MSE 0.4835
2020-11-05 21:04:42,984 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2876 | Iter Mean Loss 12.2876
2020-11-05 21:04:42,991 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8576 | Iter Mean Loss 9.0726
2020-11-05 21:04:42,999 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9935 | Iter Mean Loss 17.3795
2020-11-05 21:04:43,006 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6460 | Iter Mean Loss 18.4462
2020-11-05 21:04:43,013 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.1002 | Iter Mean Loss 18.7770
2020-11-05 21:04:43,015 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.2817 | MSE 0.4828
2020-11-05 21:04:43,023 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1589 | Iter Mean Loss 12.1589
2020-11-05 21:04:43,030 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.7664 | Iter Mean Loss 8.9627
2020-11-05 21:04:43,038 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7308 | Iter Mean Loss 17.2187
2020-11-05 21:04:43,045 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4892 | Iter Mean Loss 18.2863
2020-11-05 21:04:43,052 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.9281 | Iter Mean Loss 18.6147
2020-11-05 21:04:43,055 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.2817 | MSE 0.4821
2020-11-05 21:04:43,063 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0362 | Iter Mean Loss 12.0362
2020-11-05 21:04:43,071 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6785 | Iter Mean Loss 8.8574
2020-11-05 21:04:43,080 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4727 | Iter Mean Loss 17.0625
2020-11-05 21:04:43,088 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3365 | Iter Mean Loss 18.1310
2020-11-05 21:04:43,095 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.7593 | Iter Mean Loss 18.4567
2020-11-05 21:04:43,098 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.2817 | MSE 0.4815
2020-11-05 21:04:43,106 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9197 | Iter Mean Loss 11.9197
2020-11-05 21:04:43,115 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5942 | Iter Mean Loss 8.7570
2020-11-05 21:04:43,123 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2193 | Iter Mean Loss 16.9111
2020-11-05 21:04:43,131 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1879 | Iter Mean Loss 17.9803
2020-11-05 21:04:43,140 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5939 | Iter Mean Loss 18.3030
2020-11-05 21:04:43,142 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.2817 | MSE 0.4808
2020-11-05 21:04:43,151 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8095 | Iter Mean Loss 11.8095
2020-11-05 21:04:43,158 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5136 | Iter Mean Loss 8.6615
2020-11-05 21:04:43,167 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9707 | Iter Mean Loss 16.7646
2020-11-05 21:04:43,174 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0436 | Iter Mean Loss 17.8343
2020-11-05 21:04:43,182 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.4321 | Iter Mean Loss 18.1539
2020-11-05 21:04:43,184 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.2817 | MSE 0.4801
2020-11-05 21:04:43,192 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7057 | Iter Mean Loss 11.7057
2020-11-05 21:04:43,199 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4366 | Iter Mean Loss 8.5711
2020-11-05 21:04:43,207 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7271 | Iter Mean Loss 16.6231
2020-11-05 21:04:43,214 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9036 | Iter Mean Loss 17.6932
2020-11-05 21:04:43,221 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.2740 | Iter Mean Loss 18.0094
2020-11-05 21:04:43,223 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.2817 | MSE 0.4794
2020-11-05 21:04:43,231 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6085 | Iter Mean Loss 11.6085
2020-11-05 21:04:43,239 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.3634 | Iter Mean Loss 8.4859
2020-11-05 21:04:43,246 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4886 | Iter Mean Loss 16.4868
2020-11-05 21:04:43,254 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7679 | Iter Mean Loss 17.5571
2020-11-05 21:04:43,261 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.1197 | Iter Mean Loss 17.8696
2020-11-05 21:04:43,264 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.2817 | MSE 0.4786
2020-11-05 21:04:43,273 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5178 | Iter Mean Loss 11.5178
2020-11-05 21:04:43,281 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2939 | Iter Mean Loss 8.4058
2020-11-05 21:04:43,289 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2551 | Iter Mean Loss 16.3556
2020-11-05 21:04:43,297 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6366 | Iter Mean Loss 17.4258
2020-11-05 21:04:43,306 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.9694 | Iter Mean Loss 17.7345
2020-11-05 21:04:43,308 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.2817 | MSE 0.4779
2020-11-05 21:04:43,317 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4336 | Iter Mean Loss 11.4336
2020-11-05 21:04:43,326 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2283 | Iter Mean Loss 8.3309
2020-11-05 21:04:43,334 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0266 | Iter Mean Loss 16.2295
2020-11-05 21:04:43,342 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5095 | Iter Mean Loss 17.2995
2020-11-05 21:04:43,351 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.8231 | Iter Mean Loss 17.6042
2020-11-05 21:04:43,353 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.2817 | MSE 0.4772
2020-11-05 21:04:43,361 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3558 | Iter Mean Loss 11.3558
2020-11-05 21:04:43,370 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1663 | Iter Mean Loss 8.2611
2020-11-05 21:04:43,377 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8031 | Iter Mean Loss 16.1084
2020-11-05 21:04:43,385 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3867 | Iter Mean Loss 17.1780
2020-11-05 21:04:43,392 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.6807 | Iter Mean Loss 17.4785
2020-11-05 21:04:43,394 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.2817 | MSE 0.4764
2020-11-05 21:04:43,402 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2844 | Iter Mean Loss 11.2844
2020-11-05 21:04:43,409 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 8.1962
2020-11-05 21:04:43,417 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.5845 | Iter Mean Loss 15.9923
2020-11-05 21:04:43,424 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2679 | Iter Mean Loss 17.0612
2020-11-05 21:04:43,431 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.5423 | Iter Mean Loss 17.3574
2020-11-05 21:04:43,433 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.2817 | MSE 0.4757
2020-11-05 21:04:43,441 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2192 | Iter Mean Loss 11.2192
2020-11-05 21:04:43,449 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0534 | Iter Mean Loss 8.1363
2020-11-05 21:04:43,457 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3707 | Iter Mean Loss 15.8811
2020-11-05 21:04:43,466 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1531 | Iter Mean Loss 16.9491
2020-11-05 21:04:43,475 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.4078 | Iter Mean Loss 17.2409
2020-11-05 21:04:43,478 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.2817 | MSE 0.4749
2020-11-05 21:04:43,488 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1600 | Iter Mean Loss 11.1600
2020-11-05 21:04:43,497 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0022 | Iter Mean Loss 8.0811
2020-11-05 21:04:43,505 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1615 | Iter Mean Loss 15.7746
2020-11-05 21:04:43,516 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0422 | Iter Mean Loss 16.8415
2020-11-05 21:04:43,526 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.2772 | Iter Mean Loss 17.1286
2020-11-05 21:04:43,528 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.2817 | MSE 0.4741
2020-11-05 21:04:43,538 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1065 | Iter Mean Loss 11.1065
2020-11-05 21:04:43,547 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9544 | Iter Mean Loss 8.0304
2020-11-05 21:04:43,556 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.9567 | Iter Mean Loss 15.6725
2020-11-05 21:04:43,564 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9349 | Iter Mean Loss 16.7381
2020-11-05 21:04:43,574 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.1504 | Iter Mean Loss 17.0206
2020-11-05 21:04:43,576 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.2817 | MSE 0.4734
2020-11-05 21:04:43,585 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0586 | Iter Mean Loss 11.0586
2020-11-05 21:04:43,594 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9098 | Iter Mean Loss 7.9842
2020-11-05 21:04:43,602 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7562 | Iter Mean Loss 15.5749
2020-11-05 21:04:43,610 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8310 | Iter Mean Loss 16.6389
2020-11-05 21:04:43,617 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.0272 | Iter Mean Loss 16.9166
2020-11-05 21:04:43,620 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.2817 | MSE 0.4726
2020-11-05 21:04:43,628 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0159 | Iter Mean Loss 11.0159
2020-11-05 21:04:43,638 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8683 | Iter Mean Loss 7.9421
2020-11-05 21:04:43,646 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5597 | Iter Mean Loss 15.4813
2020-11-05 21:04:43,655 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7305 | Iter Mean Loss 16.5436
2020-11-05 21:04:43,663 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9075 | Iter Mean Loss 16.8164
2020-11-05 21:04:43,665 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.2817 | MSE 0.4718
2020-11-05 21:04:43,675 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9782 | Iter Mean Loss 10.9782
2020-11-05 21:04:43,684 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8298 | Iter Mean Loss 7.9040
2020-11-05 21:04:43,693 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3670 | Iter Mean Loss 15.3917
2020-11-05 21:04:43,701 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6330 | Iter Mean Loss 16.4520
2020-11-05 21:04:43,709 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.7911 | Iter Mean Loss 16.7198
2020-11-05 21:04:43,711 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.2817 | MSE 0.4710
2020-11-05 21:04:43,721 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9452 | Iter Mean Loss 10.9452
2020-11-05 21:04:43,729 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7940 | Iter Mean Loss 7.8696
2020-11-05 21:04:43,737 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1779 | Iter Mean Loss 15.3057
2020-11-05 21:04:43,746 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5384 | Iter Mean Loss 16.3639
2020-11-05 21:04:43,755 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.6780 | Iter Mean Loss 16.6267
2020-11-05 21:04:43,757 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.2817 | MSE 0.4702
2020-11-05 21:04:43,766 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9165 | Iter Mean Loss 10.9165
2020-11-05 21:04:43,776 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7609 | Iter Mean Loss 7.8387
2020-11-05 21:04:43,783 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9922 | Iter Mean Loss 15.2232
2020-11-05 21:04:43,791 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4465 | Iter Mean Loss 16.2790
2020-11-05 21:04:43,799 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.5679 | Iter Mean Loss 16.5368
2020-11-05 21:04:43,801 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.2817 | MSE 0.4694
2020-11-05 21:04:43,809 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8920 | Iter Mean Loss 10.8920
2020-11-05 21:04:43,817 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7302 | Iter Mean Loss 7.8111
2020-11-05 21:04:43,824 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8097 | Iter Mean Loss 15.1440
2020-11-05 21:04:43,832 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3571 | Iter Mean Loss 16.1972
2020-11-05 21:04:43,839 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.4607 | Iter Mean Loss 16.4499
2020-11-05 21:04:43,841 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.2817 | MSE 0.4685
2020-11-05 21:04:43,850 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 21:04:43,858 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7018 | Iter Mean Loss 7.7865
2020-11-05 21:04:43,865 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6301 | Iter Mean Loss 15.0677
2020-11-05 21:04:43,873 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2699 | Iter Mean Loss 16.1183
2020-11-05 21:04:43,881 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.3562 | Iter Mean Loss 16.3659
2020-11-05 21:04:43,883 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.2817 | MSE 0.4677
2020-11-05 21:04:43,892 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8540 | Iter Mean Loss 10.8540
2020-11-05 21:04:43,901 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 7.7648
2020-11-05 21:04:43,908 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4533 | Iter Mean Loss 14.9943
2020-11-05 21:04:43,917 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1848 | Iter Mean Loss 16.0419
2020-11-05 21:04:43,925 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.2542 | Iter Mean Loss 16.2844
2020-11-05 21:04:43,928 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.2817 | MSE 0.4668
2020-11-05 21:04:43,936 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8400 | Iter Mean Loss 10.8400
2020-11-05 21:04:43,945 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6512 | Iter Mean Loss 7.7456
2020-11-05 21:04:43,953 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2789 | Iter Mean Loss 14.9234
2020-11-05 21:04:43,961 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1017 | Iter Mean Loss 15.9679
2020-11-05 21:04:43,969 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.1545 | Iter Mean Loss 16.2053
2020-11-05 21:04:43,972 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.2817 | MSE 0.4660
2020-11-05 21:04:43,981 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8289 | Iter Mean Loss 10.8289
2020-11-05 21:04:43,988 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6287 | Iter Mean Loss 7.7288
2020-11-05 21:04:43,996 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1069 | Iter Mean Loss 14.8548
2020-11-05 21:04:44,004 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0203 | Iter Mean Loss 15.8962
2020-11-05 21:04:44,012 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.0571 | Iter Mean Loss 16.1284
2020-11-05 21:04:44,014 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.2817 | MSE 0.4651
2020-11-05 21:04:44,022 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8205 | Iter Mean Loss 10.8205
2020-11-05 21:04:44,030 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6078 | Iter Mean Loss 7.7142
2020-11-05 21:04:44,037 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9371 | Iter Mean Loss 14.7885
2020-11-05 21:04:44,045 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9405 | Iter Mean Loss 15.8265
2020-11-05 21:04:44,052 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.9616 | Iter Mean Loss 16.0535
2020-11-05 21:04:44,054 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.2817 | MSE 0.4643
2020-11-05 21:04:44,062 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8146 | Iter Mean Loss 10.8146
2020-11-05 21:04:44,070 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5885 | Iter Mean Loss 7.7015
2020-11-05 21:04:44,079 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7693 | Iter Mean Loss 14.7241
2020-11-05 21:04:44,086 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8621 | Iter Mean Loss 15.7586
2020-11-05 21:04:44,094 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.8681 | Iter Mean Loss 15.9805
2020-11-05 21:04:44,097 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.2817 | MSE 0.4634
2020-11-05 21:04:44,106 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 21:04:44,114 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5705 | Iter Mean Loss 7.6907
2020-11-05 21:04:44,123 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6033 | Iter Mean Loss 14.6616
2020-11-05 21:04:44,131 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7850 | Iter Mean Loss 15.6924
2020-11-05 21:04:44,140 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.7762 | Iter Mean Loss 15.9092
2020-11-05 21:04:44,142 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.2817 | MSE 0.4625
2020-11-05 21:04:44,151 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8091 | Iter Mean Loss 10.8091
2020-11-05 21:04:44,160 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5538 | Iter Mean Loss 7.6815
2020-11-05 21:04:44,168 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4390 | Iter Mean Loss 14.6007
2020-11-05 21:04:44,177 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7092 | Iter Mean Loss 15.6278
2020-11-05 21:04:44,185 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6860 | Iter Mean Loss 15.8394
2020-11-05 21:04:44,187 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.2817 | MSE 0.4617
2020-11-05 21:04:44,196 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8092 | Iter Mean Loss 10.8092
2020-11-05 21:04:44,204 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5383 | Iter Mean Loss 7.6738
2020-11-05 21:04:44,211 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2763 | Iter Mean Loss 14.5413
2020-11-05 21:04:44,219 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6344 | Iter Mean Loss 15.5646
2020-11-05 21:04:44,226 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5972 | Iter Mean Loss 15.7711
2020-11-05 21:04:44,228 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.2817 | MSE 0.4608
2020-11-05 21:04:44,237 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 21:04:44,244 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5238 | Iter Mean Loss 7.6673
2020-11-05 21:04:44,252 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1151 | Iter Mean Loss 14.4833
2020-11-05 21:04:44,260 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5606 | Iter Mean Loss 15.5026
2020-11-05 21:04:44,268 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5098 | Iter Mean Loss 15.7040
2020-11-05 21:04:44,270 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.2817 | MSE 0.4599
2020-11-05 21:04:44,279 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8140 | Iter Mean Loss 10.8140
2020-11-05 21:04:44,288 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 7.6621
2020-11-05 21:04:44,295 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9552 | Iter Mean Loss 14.4265
2020-11-05 21:04:44,304 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4877 | Iter Mean Loss 15.4418
2020-11-05 21:04:44,313 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.4236 | Iter Mean Loss 15.6382
2020-11-05 21:04:44,315 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.2817 | MSE 0.4590
2020-11-05 21:04:44,326 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8184 | Iter Mean Loss 10.8184
2020-11-05 21:04:44,334 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4975 | Iter Mean Loss 7.6580
2020-11-05 21:04:44,343 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7967 | Iter Mean Loss 14.3709
2020-11-05 21:04:44,351 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4156 | Iter Mean Loss 15.3820
2020-11-05 21:04:44,359 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.3386 | Iter Mean Loss 15.5734
2020-11-05 21:04:44,361 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.2817 | MSE 0.4581
2020-11-05 21:04:44,371 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8240 | Iter Mean Loss 10.8240
2020-11-05 21:04:44,379 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4856 | Iter Mean Loss 7.6548
2020-11-05 21:04:44,388 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6393 | Iter Mean Loss 14.3163
2020-11-05 21:04:44,397 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3442 | Iter Mean Loss 15.3233
2020-11-05 21:04:44,405 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.2546 | Iter Mean Loss 15.5095
2020-11-05 21:04:44,407 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.2817 | MSE 0.4572
2020-11-05 21:04:44,415 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8305 | Iter Mean Loss 10.8305
2020-11-05 21:04:44,423 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4743 | Iter Mean Loss 7.6524
2020-11-05 21:04:44,431 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4831 | Iter Mean Loss 14.2626
2020-11-05 21:04:44,439 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2736 | Iter Mean Loss 15.2654
2020-11-05 21:04:44,447 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.1716 | Iter Mean Loss 15.4466
2020-11-05 21:04:44,449 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.2817 | MSE 0.4563
2020-11-05 21:04:44,457 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8379 | Iter Mean Loss 10.8379
2020-11-05 21:04:44,465 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4637 | Iter Mean Loss 7.6508
2020-11-05 21:04:44,473 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3279 | Iter Mean Loss 14.2098
2020-11-05 21:04:44,481 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2035 | Iter Mean Loss 15.2083
2020-11-05 21:04:44,490 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0894 | Iter Mean Loss 15.3845
2020-11-05 21:04:44,493 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.2817 | MSE 0.4554
2020-11-05 21:04:44,501 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 10.8461
2020-11-05 21:04:44,510 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4536 | Iter Mean Loss 7.6499
2020-11-05 21:04:44,520 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1738 | Iter Mean Loss 14.1579
2020-11-05 21:04:44,529 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1341 | Iter Mean Loss 15.1519
2020-11-05 21:04:44,537 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0081 | Iter Mean Loss 15.3232
2020-11-05 21:04:44,539 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.2817 | MSE 0.4544
2020-11-05 21:04:44,548 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8550 | Iter Mean Loss 10.8550
2020-11-05 21:04:44,557 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4440 | Iter Mean Loss 7.6495
2020-11-05 21:04:44,565 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0207 | Iter Mean Loss 14.1066
2020-11-05 21:04:44,573 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 15.0962
2020-11-05 21:04:44,583 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.9276 | Iter Mean Loss 15.2625
2020-11-05 21:04:44,585 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.2817 | MSE 0.4535
2020-11-05 21:04:44,594 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8645 | Iter Mean Loss 10.8645
2020-11-05 21:04:44,603 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4349 | Iter Mean Loss 7.6497
2020-11-05 21:04:44,611 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8685 | Iter Mean Loss 14.0560
2020-11-05 21:04:44,620 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9969 | Iter Mean Loss 15.0412
2020-11-05 21:04:44,628 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.8477 | Iter Mean Loss 15.2025
2020-11-05 21:04:44,630 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.2817 | MSE 0.4526
2020-11-05 21:04:44,638 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8745 | Iter Mean Loss 10.8745
2020-11-05 21:04:44,646 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4262 | Iter Mean Loss 7.6504
2020-11-05 21:04:44,654 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7173 | Iter Mean Loss 14.0060
2020-11-05 21:04:44,662 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9290 | Iter Mean Loss 14.9868
2020-11-05 21:04:44,670 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.7685 | Iter Mean Loss 15.1431
2020-11-05 21:04:44,672 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.2817 | MSE 0.4517
2020-11-05 21:04:44,681 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8849 | Iter Mean Loss 10.8849
2020-11-05 21:04:44,689 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 7.6514
2020-11-05 21:04:44,698 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5669 | Iter Mean Loss 13.9566
2020-11-05 21:04:44,706 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8617 | Iter Mean Loss 14.9329
2020-11-05 21:04:44,716 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6900 | Iter Mean Loss 15.0843
2020-11-05 21:04:44,718 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.2817 | MSE 0.4508
2020-11-05 21:04:44,727 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8957 | Iter Mean Loss 10.8957
2020-11-05 21:04:44,737 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4099 | Iter Mean Loss 7.6528
2020-11-05 21:04:44,746 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4174 | Iter Mean Loss 13.9077
2020-11-05 21:04:44,755 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7948 | Iter Mean Loss 14.8795
2020-11-05 21:04:44,764 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6120 | Iter Mean Loss 15.0260
2020-11-05 21:04:44,767 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.2817 | MSE 0.4498
2020-11-05 21:04:44,776 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9069 | Iter Mean Loss 10.9069
2020-11-05 21:04:44,786 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4022 | Iter Mean Loss 7.6545
2020-11-05 21:04:44,795 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2688 | Iter Mean Loss 13.8593
2020-11-05 21:04:44,803 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7283 | Iter Mean Loss 14.8265
2020-11-05 21:04:44,811 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5345 | Iter Mean Loss 14.9681
2020-11-05 21:04:44,813 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.2817 | MSE 0.4489
2020-11-05 21:04:44,822 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9183 | Iter Mean Loss 10.9183
2020-11-05 21:04:44,830 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3948 | Iter Mean Loss 7.6565
2020-11-05 21:04:44,837 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1211 | Iter Mean Loss 13.8114
2020-11-05 21:04:44,845 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6622 | Iter Mean Loss 14.7741
2020-11-05 21:04:44,853 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.4576 | Iter Mean Loss 14.9108
2020-11-05 21:04:44,855 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.2817 | MSE 0.4480
2020-11-05 21:04:44,864 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9299 | Iter Mean Loss 10.9299
2020-11-05 21:04:44,872 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3876 | Iter Mean Loss 7.6587
2020-11-05 21:04:44,880 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9742 | Iter Mean Loss 13.7639
2020-11-05 21:04:44,888 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5966 | Iter Mean Loss 14.7221
2020-11-05 21:04:44,896 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3811 | Iter Mean Loss 14.8539
2020-11-05 21:04:44,898 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.2817 | MSE 0.4471
2020-11-05 21:04:44,907 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9416 | Iter Mean Loss 10.9416
2020-11-05 21:04:44,916 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3807 | Iter Mean Loss 7.6612
2020-11-05 21:04:44,926 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8281 | Iter Mean Loss 13.7168
2020-11-05 21:04:44,934 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5314 | Iter Mean Loss 14.6705
2020-11-05 21:04:44,943 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3051 | Iter Mean Loss 14.7974
2020-11-05 21:04:44,946 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.2817 | MSE 0.4461
2020-11-05 21:04:44,956 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9536 | Iter Mean Loss 10.9536
2020-11-05 21:04:44,965 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3739 | Iter Mean Loss 7.6638
2020-11-05 21:04:44,975 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6829 | Iter Mean Loss 13.6701
2020-11-05 21:04:44,982 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4666 | Iter Mean Loss 14.6192
2020-11-05 21:04:44,992 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.2295 | Iter Mean Loss 14.7413
2020-11-05 21:04:44,994 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.2817 | MSE 0.4452
2020-11-05 21:04:45,002 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9656 | Iter Mean Loss 10.9656
2020-11-05 21:04:45,011 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3674 | Iter Mean Loss 7.6665
2020-11-05 21:04:45,021 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5385 | Iter Mean Loss 13.6238
2020-11-05 21:04:45,029 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4022 | Iter Mean Loss 14.5684
2020-11-05 21:04:45,038 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.1544 | Iter Mean Loss 14.6856
2020-11-05 21:04:45,040 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.2817 | MSE 0.4443
2020-11-05 21:04:45,048 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9776 | Iter Mean Loss 10.9776
2020-11-05 21:04:45,057 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3610 | Iter Mean Loss 7.6693
2020-11-05 21:04:45,065 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3949 | Iter Mean Loss 13.5779
2020-11-05 21:04:45,073 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3382 | Iter Mean Loss 14.5179
2020-11-05 21:04:45,081 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0796 | Iter Mean Loss 14.6303
2020-11-05 21:04:45,083 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.2817 | MSE 0.4433
2020-11-05 21:04:45,091 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9897 | Iter Mean Loss 10.9897
2020-11-05 21:04:45,100 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3548 | Iter Mean Loss 7.6723
2020-11-05 21:04:45,108 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2522 | Iter Mean Loss 13.5322
2020-11-05 21:04:45,117 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2746 | Iter Mean Loss 14.4678
2020-11-05 21:04:45,127 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0053 | Iter Mean Loss 14.5753
2020-11-05 21:04:45,129 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.2817 | MSE 0.4424
2020-11-05 21:04:45,139 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0019 | Iter Mean Loss 11.0019
2020-11-05 21:04:45,148 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3487 | Iter Mean Loss 7.6753
2020-11-05 21:04:45,156 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1103 | Iter Mean Loss 13.4870
2020-11-05 21:04:45,166 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2114 | Iter Mean Loss 14.4181
2020-11-05 21:04:45,175 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.9313 | Iter Mean Loss 14.5207
2020-11-05 21:04:45,178 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.2817 | MSE 0.4415
2020-11-05 21:04:45,187 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 11.0139
2020-11-05 21:04:45,196 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3428 | Iter Mean Loss 7.6784
2020-11-05 21:04:45,205 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9693 | Iter Mean Loss 13.4420
2020-11-05 21:04:45,214 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1485 | Iter Mean Loss 14.3686
2020-11-05 21:04:45,221 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.8577 | Iter Mean Loss 14.4664
2020-11-05 21:04:45,224 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.2817 | MSE 0.4406
2020-11-05 21:04:45,232 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0260 | Iter Mean Loss 11.0260
2020-11-05 21:04:45,240 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3370 | Iter Mean Loss 7.6815
2020-11-05 21:04:45,248 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8291 | Iter Mean Loss 13.3974
2020-11-05 21:04:45,256 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0861 | Iter Mean Loss 14.3195
2020-11-05 21:04:45,264 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7844 | Iter Mean Loss 14.4125
2020-11-05 21:04:45,266 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.2817 | MSE 0.4396
2020-11-05 21:04:45,275 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0380 | Iter Mean Loss 11.0380
2020-11-05 21:04:45,283 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3312 | Iter Mean Loss 7.6846
2020-11-05 21:04:45,291 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6898 | Iter Mean Loss 13.3530
2020-11-05 21:04:45,299 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0241 | Iter Mean Loss 14.2708
2020-11-05 21:04:45,307 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7115 | Iter Mean Loss 14.3589
2020-11-05 21:04:45,310 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.2817 | MSE 0.4387
2020-11-05 21:04:45,321 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0499 | Iter Mean Loss 11.0499
2020-11-05 21:04:45,331 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3256 | Iter Mean Loss 7.6878
2020-11-05 21:04:45,339 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5513 | Iter Mean Loss 13.3090
2020-11-05 21:04:45,347 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9624 | Iter Mean Loss 14.2223
2020-11-05 21:04:45,355 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.6390 | Iter Mean Loss 14.3057
2020-11-05 21:04:45,358 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.2817 | MSE 0.4378
2020-11-05 21:04:45,367 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0617 | Iter Mean Loss 11.0617
2020-11-05 21:04:45,375 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 7.6909
2020-11-05 21:04:45,385 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4137 | Iter Mean Loss 13.2652
2020-11-05 21:04:45,393 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9011 | Iter Mean Loss 14.1742
2020-11-05 21:04:45,402 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5668 | Iter Mean Loss 14.2527
2020-11-05 21:04:45,405 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.2817 | MSE 0.4369
2020-11-05 21:04:45,417 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0734 | Iter Mean Loss 11.0734
2020-11-05 21:04:45,425 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3147 | Iter Mean Loss 7.6941
2020-11-05 21:04:45,433 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2770 | Iter Mean Loss 13.2217
2020-11-05 21:04:45,440 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8403 | Iter Mean Loss 14.1263
2020-11-05 21:04:45,448 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4949 | Iter Mean Loss 14.2001
2020-11-05 21:04:45,450 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.2817 | MSE 0.4360
2020-11-05 21:04:45,459 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0850 | Iter Mean Loss 11.0850
2020-11-05 21:04:45,466 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3094 | Iter Mean Loss 7.6972
2020-11-05 21:04:45,474 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1411 | Iter Mean Loss 13.1785
2020-11-05 21:04:45,482 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7798 | Iter Mean Loss 14.0788
2020-11-05 21:04:45,490 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4233 | Iter Mean Loss 14.1477
2020-11-05 21:04:45,492 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.2817 | MSE 0.4350
2020-11-05 21:04:45,500 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0964 | Iter Mean Loss 11.0964
2020-11-05 21:04:45,509 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3041 | Iter Mean Loss 7.7003
2020-11-05 21:04:45,521 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0062 | Iter Mean Loss 13.1356
2020-11-05 21:04:45,530 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7197 | Iter Mean Loss 14.0316
2020-11-05 21:04:45,539 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.3521 | Iter Mean Loss 14.0957
2020-11-05 21:04:45,542 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.2817 | MSE 0.4341
2020-11-05 21:04:45,553 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.1076
2020-11-05 21:04:45,562 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 7.7033
2020-11-05 21:04:45,571 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8721 | Iter Mean Loss 13.0929
2020-11-05 21:04:45,580 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6600 | Iter Mean Loss 13.9846
2020-11-05 21:04:45,590 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2812 | Iter Mean Loss 14.0440
2020-11-05 21:04:45,592 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.2817 | MSE 0.4332
2020-11-05 21:04:45,602 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1187 | Iter Mean Loss 11.1187
2020-11-05 21:04:45,611 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2938 | Iter Mean Loss 7.7063
2020-11-05 21:04:45,620 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7389 | Iter Mean Loss 13.0505
2020-11-05 21:04:45,627 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6006 | Iter Mean Loss 13.9380
2020-11-05 21:04:45,636 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2106 | Iter Mean Loss 13.9925
2020-11-05 21:04:45,638 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.2817 | MSE 0.4323
2020-11-05 21:04:45,646 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1296 | Iter Mean Loss 11.1296
2020-11-05 21:04:45,654 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2888 | Iter Mean Loss 7.7092
2020-11-05 21:04:45,662 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6065 | Iter Mean Loss 13.0083
2020-11-05 21:04:45,669 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5417 | Iter Mean Loss 13.8917
2020-11-05 21:04:45,677 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.1404 | Iter Mean Loss 13.9414
2020-11-05 21:04:45,679 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.2817 | MSE 0.4314
2020-11-05 21:04:45,687 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1403 | Iter Mean Loss 11.1403
2020-11-05 21:04:45,695 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2838 | Iter Mean Loss 7.7120
2020-11-05 21:04:45,703 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4751 | Iter Mean Loss 12.9664
2020-11-05 21:04:45,710 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4831 | Iter Mean Loss 13.8456
2020-11-05 21:04:45,718 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0704 | Iter Mean Loss 13.8906
2020-11-05 21:04:45,721 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.2817 | MSE 0.4305
2020-11-05 21:04:45,730 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1508 | Iter Mean Loss 11.1508
2020-11-05 21:04:45,739 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 7.7148
2020-11-05 21:04:45,747 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3446 | Iter Mean Loss 12.9247
2020-11-05 21:04:45,756 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4250 | Iter Mean Loss 13.7998
2020-11-05 21:04:45,764 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0008 | Iter Mean Loss 13.8400
2020-11-05 21:04:45,766 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.2817 | MSE 0.4296
2020-11-05 21:04:45,776 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1611 | Iter Mean Loss 11.1611
2020-11-05 21:04:45,784 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2739 | Iter Mean Loss 7.7175
2020-11-05 21:04:45,793 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2150 | Iter Mean Loss 12.8833
2020-11-05 21:04:45,801 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3672 | Iter Mean Loss 13.7543
2020-11-05 21:04:45,810 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.9315 | Iter Mean Loss 13.7897
2020-11-05 21:04:45,812 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.2817 | MSE 0.4287
2020-11-05 21:04:45,821 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1711 | Iter Mean Loss 11.1711
2020-11-05 21:04:45,830 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2691 | Iter Mean Loss 7.7201
2020-11-05 21:04:45,838 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0863 | Iter Mean Loss 12.8422
2020-11-05 21:04:45,846 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3098 | Iter Mean Loss 13.7091
2020-11-05 21:04:45,856 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.8625 | Iter Mean Loss 13.7398
2020-11-05 21:04:45,859 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.2817 | MSE 0.4278
2020-11-05 21:04:45,870 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1809 | Iter Mean Loss 11.1809
2020-11-05 21:04:45,880 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2643 | Iter Mean Loss 7.7226
2020-11-05 21:04:45,889 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9586 | Iter Mean Loss 12.8013
2020-11-05 21:04:45,897 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2528 | Iter Mean Loss 13.6641
2020-11-05 21:04:45,905 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.6901
2020-11-05 21:04:45,907 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.2817 | MSE 0.4270
2020-11-05 21:04:45,917 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1905 | Iter Mean Loss 11.1905
2020-11-05 21:04:45,927 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 7.7250
2020-11-05 21:04:45,936 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8317 | Iter Mean Loss 12.7606
2020-11-05 21:04:45,945 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1962 | Iter Mean Loss 13.6195
2020-11-05 21:04:45,954 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7255 | Iter Mean Loss 13.6407
2020-11-05 21:04:45,958 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.2817 | MSE 0.4261
2020-11-05 21:04:45,967 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1998 | Iter Mean Loss 11.1998
2020-11-05 21:04:45,977 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 7.7273
2020-11-05 21:04:45,985 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7058 | Iter Mean Loss 12.7201
2020-11-05 21:04:45,995 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1399 | Iter Mean Loss 13.5751
2020-11-05 21:04:46,003 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.6575 | Iter Mean Loss 13.5916
2020-11-05 21:04:46,006 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.2817 | MSE 0.4252
2020-11-05 21:04:46,016 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2088 | Iter Mean Loss 11.2088
2020-11-05 21:04:46,026 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2502 | Iter Mean Loss 7.7295
2020-11-05 21:04:46,034 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5808 | Iter Mean Loss 12.6799
2020-11-05 21:04:46,043 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0841 | Iter Mean Loss 13.5310
2020-11-05 21:04:46,051 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5898 | Iter Mean Loss 13.5427
2020-11-05 21:04:46,053 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.2817 | MSE 0.4243
2020-11-05 21:04:46,062 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2176 | Iter Mean Loss 11.2176
2020-11-05 21:04:46,070 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2456 | Iter Mean Loss 7.7316
2020-11-05 21:04:46,078 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4567 | Iter Mean Loss 12.6400
2020-11-05 21:04:46,086 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0286 | Iter Mean Loss 13.4871
2020-11-05 21:04:46,094 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5224 | Iter Mean Loss 13.4942
2020-11-05 21:04:46,096 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.2817 | MSE 0.4235
2020-11-05 21:04:46,106 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2261 | Iter Mean Loss 11.2261
2020-11-05 21:04:46,115 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2410 | Iter Mean Loss 7.7336
2020-11-05 21:04:46,124 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3335 | Iter Mean Loss 12.6002
2020-11-05 21:04:46,132 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9735 | Iter Mean Loss 13.4435
2020-11-05 21:04:46,141 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.4554 | Iter Mean Loss 13.4459
2020-11-05 21:04:46,144 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.2817 | MSE 0.4226
2020-11-05 21:04:46,153 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2343 | Iter Mean Loss 11.2343
2020-11-05 21:04:46,164 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 7.7354
2020-11-05 21:04:46,179 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2113 | Iter Mean Loss 12.5607
2020-11-05 21:04:46,195 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9187 | Iter Mean Loss 13.4002
2020-11-05 21:04:46,210 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3886 | Iter Mean Loss 13.3979
2020-11-05 21:04:46,214 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.2817 | MSE 0.4217
2020-11-05 21:04:46,231 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2423 | Iter Mean Loss 11.2423
2020-11-05 21:04:46,241 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2319 | Iter Mean Loss 7.7371
2020-11-05 21:04:46,250 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0900 | Iter Mean Loss 12.5214
2020-11-05 21:04:46,262 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8644 | Iter Mean Loss 13.3571
2020-11-05 21:04:46,275 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3222 | Iter Mean Loss 13.3502
2020-11-05 21:04:46,279 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.2817 | MSE 0.4209
2020-11-05 21:04:46,294 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2499 | Iter Mean Loss 11.2499
2020-11-05 21:04:46,306 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2274 | Iter Mean Loss 7.7387
2020-11-05 21:04:46,321 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9697 | Iter Mean Loss 12.4823
2020-11-05 21:04:46,335 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8104 | Iter Mean Loss 13.3143
2020-11-05 21:04:46,350 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.2561 | Iter Mean Loss 13.3027
2020-11-05 21:04:46,356 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.2817 | MSE 0.4200
2020-11-05 21:04:46,372 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2573 | Iter Mean Loss 11.2573
2020-11-05 21:04:46,387 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2229 | Iter Mean Loss 7.7401
2020-11-05 21:04:46,402 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8502 | Iter Mean Loss 12.4435
2020-11-05 21:04:46,415 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7568 | Iter Mean Loss 13.2718
2020-11-05 21:04:46,426 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1904 | Iter Mean Loss 13.2555
2020-11-05 21:04:46,428 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.2817 | MSE 0.4192
2020-11-05 21:04:46,437 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2643 | Iter Mean Loss 11.2643
2020-11-05 21:04:46,447 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2185 | Iter Mean Loss 7.7414
2020-11-05 21:04:46,455 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7318 | Iter Mean Loss 12.4049
2020-11-05 21:04:46,463 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7035 | Iter Mean Loss 13.2295
2020-11-05 21:04:46,471 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1250 | Iter Mean Loss 13.2086
2020-11-05 21:04:46,473 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.2817 | MSE 0.4184
2020-11-05 21:04:46,481 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2711 | Iter Mean Loss 11.2711
2020-11-05 21:04:46,489 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2141 | Iter Mean Loss 7.7426
2020-11-05 21:04:46,496 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6142 | Iter Mean Loss 12.3665
2020-11-05 21:04:46,503 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6507 | Iter Mean Loss 13.1875
2020-11-05 21:04:46,513 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.0599 | Iter Mean Loss 13.1620
2020-11-05 21:04:46,515 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.2817 | MSE 0.4175
2020-11-05 21:04:46,523 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2775 | Iter Mean Loss 11.2775
2020-11-05 21:04:46,532 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2097 | Iter Mean Loss 7.7436
2020-11-05 21:04:46,541 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4976 | Iter Mean Loss 12.3283
2020-11-05 21:04:46,550 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5982 | Iter Mean Loss 13.1457
2020-11-05 21:04:46,559 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9951 | Iter Mean Loss 13.1156
2020-11-05 21:04:46,561 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.2817 | MSE 0.4167
2020-11-05 21:04:46,570 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2837 | Iter Mean Loss 11.2837
2020-11-05 21:04:46,579 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2053 | Iter Mean Loss 7.7445
2020-11-05 21:04:46,588 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3819 | Iter Mean Loss 12.2903
2020-11-05 21:04:46,597 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5460 | Iter Mean Loss 13.1042
2020-11-05 21:04:46,606 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9307 | Iter Mean Loss 13.0695
2020-11-05 21:04:46,609 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.2817 | MSE 0.4159
2020-11-05 21:04:46,618 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2895 | Iter Mean Loss 11.2895
2020-11-05 21:04:46,627 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2009 | Iter Mean Loss 7.7452
2020-11-05 21:04:46,636 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2671 | Iter Mean Loss 12.2525
2020-11-05 21:04:46,645 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4942 | Iter Mean Loss 13.0629
2020-11-05 21:04:46,654 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8666 | Iter Mean Loss 13.0237
2020-11-05 21:04:46,657 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.2817 | MSE 0.4150
2020-11-05 21:04:46,666 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2950 | Iter Mean Loss 11.2950
2020-11-05 21:04:46,674 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1966 | Iter Mean Loss 7.7458
2020-11-05 21:04:46,682 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1533 | Iter Mean Loss 12.2150
2020-11-05 21:04:46,690 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4428 | Iter Mean Loss 13.0219
2020-11-05 21:04:46,698 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8028 | Iter Mean Loss 12.9781
2020-11-05 21:04:46,700 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.2817 | MSE 0.4142
2020-11-05 21:04:46,708 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3002 | Iter Mean Loss 11.3002
2020-11-05 21:04:46,716 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1923 | Iter Mean Loss 7.7462
2020-11-05 21:04:46,724 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0404 | Iter Mean Loss 12.1776
2020-11-05 21:04:46,732 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3918 | Iter Mean Loss 12.9811
2020-11-05 21:04:46,739 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.7394 | Iter Mean Loss 12.9328
2020-11-05 21:04:46,741 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.2817 | MSE 0.4134
2020-11-05 21:04:46,750 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3050 | Iter Mean Loss 11.3050
2020-11-05 21:04:46,759 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1880 | Iter Mean Loss 7.7465
2020-11-05 21:04:46,767 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9284 | Iter Mean Loss 12.1405
2020-11-05 21:04:46,777 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3411 | Iter Mean Loss 12.9406
2020-11-05 21:04:46,786 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6763 | Iter Mean Loss 12.8878
2020-11-05 21:04:46,790 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.2817 | MSE 0.4126
2020-11-05 21:04:46,799 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3096 | Iter Mean Loss 11.3096
2020-11-05 21:04:46,808 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 7.7466
2020-11-05 21:04:46,816 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8174 | Iter Mean Loss 12.1035
2020-11-05 21:04:46,825 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2907 | Iter Mean Loss 12.9003
2020-11-05 21:04:46,833 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6136 | Iter Mean Loss 12.8430
2020-11-05 21:04:46,835 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.2817 | MSE 0.4118
2020-11-05 21:04:46,845 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3138 | Iter Mean Loss 11.3138
2020-11-05 21:04:46,853 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1794 | Iter Mean Loss 7.7466
2020-11-05 21:04:46,862 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7072 | Iter Mean Loss 12.0668
2020-11-05 21:04:46,870 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2407 | Iter Mean Loss 12.8603
2020-11-05 21:04:46,878 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.5512 | Iter Mean Loss 12.7985
2020-11-05 21:04:46,880 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.2817 | MSE 0.4110
2020-11-05 21:04:46,890 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3177 | Iter Mean Loss 11.3177
2020-11-05 21:04:46,897 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1751 | Iter Mean Loss 7.7464
2020-11-05 21:04:46,905 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5980 | Iter Mean Loss 12.0303
2020-11-05 21:04:46,912 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1911 | Iter Mean Loss 12.8205
2020-11-05 21:04:46,920 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4891 | Iter Mean Loss 12.7542
2020-11-05 21:04:46,922 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.2817 | MSE 0.4102
2020-11-05 21:04:46,930 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3212 | Iter Mean Loss 11.3212
2020-11-05 21:04:46,937 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1709 | Iter Mean Loss 7.7460
2020-11-05 21:04:46,945 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4897 | Iter Mean Loss 11.9939
2020-11-05 21:04:46,953 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1418 | Iter Mean Loss 12.7809
2020-11-05 21:04:46,961 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4274 | Iter Mean Loss 12.7102
2020-11-05 21:04:46,964 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.2817 | MSE 0.4095
2020-11-05 21:04:46,972 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3244 | Iter Mean Loss 11.3244
2020-11-05 21:04:46,981 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1666 | Iter Mean Loss 7.7455
2020-11-05 21:04:46,989 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3824 | Iter Mean Loss 11.9578
2020-11-05 21:04:46,997 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0928 | Iter Mean Loss 12.7416
2020-11-05 21:04:47,005 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3661 | Iter Mean Loss 12.6665
2020-11-05 21:04:47,007 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.2817 | MSE 0.4087
2020-11-05 21:04:47,016 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3273 | Iter Mean Loss 11.3273
2020-11-05 21:04:47,025 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1624 | Iter Mean Loss 7.7449
2020-11-05 21:04:47,033 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2759 | Iter Mean Loss 11.9219
2020-11-05 21:04:47,041 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0442 | Iter Mean Loss 12.7025
2020-11-05 21:04:47,049 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3051 | Iter Mean Loss 12.6230
2020-11-05 21:04:47,052 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.2817 | MSE 0.4079
2020-11-05 21:04:47,060 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3299 | Iter Mean Loss 11.3299
2020-11-05 21:04:47,068 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1582 | Iter Mean Loss 7.7440
2020-11-05 21:04:47,076 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1703 | Iter Mean Loss 11.8861
2020-11-05 21:04:47,084 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9960 | Iter Mean Loss 12.6636
2020-11-05 21:04:47,092 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.2444 | Iter Mean Loss 12.5798
2020-11-05 21:04:47,094 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.2817 | MSE 0.4072
2020-11-05 21:04:47,103 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3321 | Iter Mean Loss 11.3321
2020-11-05 21:04:47,111 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1540 | Iter Mean Loss 7.7431
2020-11-05 21:04:47,118 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0657 | Iter Mean Loss 11.8506
2020-11-05 21:04:47,126 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9480 | Iter Mean Loss 12.6250
2020-11-05 21:04:47,134 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1841 | Iter Mean Loss 12.5368
2020-11-05 21:04:47,136 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.2817 | MSE 0.4064
2020-11-05 21:04:47,144 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3340 | Iter Mean Loss 11.3340
2020-11-05 21:04:47,153 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1498 | Iter Mean Loss 7.7419
2020-11-05 21:04:47,161 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9620 | Iter Mean Loss 11.8153
2020-11-05 21:04:47,171 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9004 | Iter Mean Loss 12.5866
2020-11-05 21:04:47,179 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1242 | Iter Mean Loss 12.4941
2020-11-05 21:04:47,182 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.2817 | MSE 0.4056
2020-11-05 21:04:47,192 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3356 | Iter Mean Loss 11.3356
2020-11-05 21:04:47,200 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1456 | Iter Mean Loss 7.7406
2020-11-05 21:04:47,209 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8591 | Iter Mean Loss 11.7801
2020-11-05 21:04:47,219 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8532 | Iter Mean Loss 12.5484
2020-11-05 21:04:47,227 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0646 | Iter Mean Loss 12.4516
2020-11-05 21:04:47,229 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.2817 | MSE 0.4049
2020-11-05 21:04:47,239 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3368 | Iter Mean Loss 11.3368
2020-11-05 21:04:47,248 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1414 | Iter Mean Loss 7.7391
2020-11-05 21:04:47,260 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7571 | Iter Mean Loss 11.7451
2020-11-05 21:04:47,271 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8063 | Iter Mean Loss 12.5104
2020-11-05 21:04:47,282 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0053 | Iter Mean Loss 12.4094
2020-11-05 21:04:47,285 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.2817 | MSE 0.4042
2020-11-05 21:04:47,297 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3378 | Iter Mean Loss 11.3378
2020-11-05 21:04:47,307 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1372 | Iter Mean Loss 7.7375
2020-11-05 21:04:47,316 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6561 | Iter Mean Loss 11.7103
2020-11-05 21:04:47,326 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7597 | Iter Mean Loss 12.4727
2020-11-05 21:04:47,334 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.9465 | Iter Mean Loss 12.3674
2020-11-05 21:04:47,337 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.2817 | MSE 0.4034
2020-11-05 21:04:47,345 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3383 | Iter Mean Loss 11.3383
2020-11-05 21:04:47,354 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1330 | Iter Mean Loss 7.7357
2020-11-05 21:04:47,364 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5559 | Iter Mean Loss 11.6757
2020-11-05 21:04:47,375 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7135 | Iter Mean Loss 12.4352
2020-11-05 21:04:47,385 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8880 | Iter Mean Loss 12.3257
2020-11-05 21:04:47,389 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.2817 | MSE 0.4027
2020-11-05 21:04:47,399 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3386 | Iter Mean Loss 11.3386
2020-11-05 21:04:47,410 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 7.7337
2020-11-05 21:04:47,421 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4566 | Iter Mean Loss 11.6413
2020-11-05 21:04:47,430 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6676 | Iter Mean Loss 12.3979
2020-11-05 21:04:47,440 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8298 | Iter Mean Loss 12.2843
2020-11-05 21:04:47,442 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.2817 | MSE 0.4020
2020-11-05 21:04:47,452 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3385 | Iter Mean Loss 11.3385
2020-11-05 21:04:47,465 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1246 | Iter Mean Loss 7.7316
2020-11-05 21:04:47,477 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3582 | Iter Mean Loss 11.6071
2020-11-05 21:04:47,485 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6220 | Iter Mean Loss 12.3608
2020-11-05 21:04:47,494 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7720 | Iter Mean Loss 12.2431
2020-11-05 21:04:47,496 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.2817 | MSE 0.4012
2020-11-05 21:04:47,504 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3381 | Iter Mean Loss 11.3381
2020-11-05 21:04:47,514 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1204 | Iter Mean Loss 7.7293
2020-11-05 21:04:47,526 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2606 | Iter Mean Loss 11.5731
2020-11-05 21:04:47,540 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5767 | Iter Mean Loss 12.3240
2020-11-05 21:04:47,554 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7146 | Iter Mean Loss 12.2021
2020-11-05 21:04:47,557 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.2817 | MSE 0.4005
2020-11-05 21:04:47,568 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3374 | Iter Mean Loss 11.3374
2020-11-05 21:04:47,578 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1163 | Iter Mean Loss 7.7268
2020-11-05 21:04:47,587 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1639 | Iter Mean Loss 11.5392
2020-11-05 21:04:47,596 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5317 | Iter Mean Loss 12.2873
2020-11-05 21:04:47,604 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6576 | Iter Mean Loss 12.1614
2020-11-05 21:04:47,607 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.2817 | MSE 0.3998
2020-11-05 21:04:47,617 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3364 | Iter Mean Loss 11.3364
2020-11-05 21:04:47,625 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1121 | Iter Mean Loss 7.7242
2020-11-05 21:04:47,633 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0681 | Iter Mean Loss 11.5055
2020-11-05 21:04:47,641 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4871 | Iter Mean Loss 12.2509
2020-11-05 21:04:47,650 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6009 | Iter Mean Loss 12.1209
2020-11-05 21:04:47,652 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.2817 | MSE 0.3991
2020-11-05 21:04:47,663 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3350 | Iter Mean Loss 11.3350
2020-11-05 21:04:47,673 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1079 | Iter Mean Loss 7.7215
2020-11-05 21:04:47,681 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9731 | Iter Mean Loss 11.4720
2020-11-05 21:04:47,692 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4428 | Iter Mean Loss 12.2147
2020-11-05 21:04:47,702 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.5446 | Iter Mean Loss 12.0807
2020-11-05 21:04:47,704 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.2817 | MSE 0.3984
2020-11-05 21:04:47,714 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3334 | Iter Mean Loss 11.3334
2020-11-05 21:04:47,724 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1037 | Iter Mean Loss 7.7185
2020-11-05 21:04:47,733 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8790 | Iter Mean Loss 11.4387
2020-11-05 21:04:47,744 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3988 | Iter Mean Loss 12.1787
2020-11-05 21:04:47,755 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4887 | Iter Mean Loss 12.0407
2020-11-05 21:04:47,757 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.2817 | MSE 0.3977
2020-11-05 21:04:47,767 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3314 | Iter Mean Loss 11.3314
2020-11-05 21:04:47,778 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0995 | Iter Mean Loss 7.7154
2020-11-05 21:04:47,786 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7857 | Iter Mean Loss 11.4055
2020-11-05 21:04:47,797 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3551 | Iter Mean Loss 12.1429
2020-11-05 21:04:47,806 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4331 | Iter Mean Loss 12.0010
2020-11-05 21:04:47,808 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.2817 | MSE 0.3970
2020-11-05 21:04:47,823 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3290 | Iter Mean Loss 11.3290
2020-11-05 21:04:47,836 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0953 | Iter Mean Loss 7.7122
2020-11-05 21:04:47,849 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6933 | Iter Mean Loss 11.3726
2020-11-05 21:04:47,858 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3118 | Iter Mean Loss 12.1074
2020-11-05 21:04:47,869 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3779 | Iter Mean Loss 11.9615
2020-11-05 21:04:47,873 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.2817 | MSE 0.3963
2020-11-05 21:04:47,885 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3264 | Iter Mean Loss 11.3264
2020-11-05 21:04:47,894 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0911 | Iter Mean Loss 7.7088
2020-11-05 21:04:47,905 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6017 | Iter Mean Loss 11.3397
2020-11-05 21:04:47,914 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2687 | Iter Mean Loss 12.0720
2020-11-05 21:04:47,926 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3231 | Iter Mean Loss 11.9222
2020-11-05 21:04:47,929 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.2817 | MSE 0.3956
2020-11-05 21:04:47,945 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3235 | Iter Mean Loss 11.3235
2020-11-05 21:04:47,958 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0869 | Iter Mean Loss 7.7052
2020-11-05 21:04:47,967 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5109 | Iter Mean Loss 11.3071
2020-11-05 21:04:47,978 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2260 | Iter Mean Loss 12.0368
2020-11-05 21:04:47,990 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2687 | Iter Mean Loss 11.8832
2020-11-05 21:04:47,993 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.2817 | MSE 0.3950
2020-11-05 21:04:48,004 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3203 | Iter Mean Loss 11.3203
2020-11-05 21:04:48,016 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0827 | Iter Mean Loss 7.7015
2020-11-05 21:04:48,028 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4210 | Iter Mean Loss 11.2746
2020-11-05 21:04:48,038 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1835 | Iter Mean Loss 12.0019
2020-11-05 21:04:48,051 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2146 | Iter Mean Loss 11.8444
2020-11-05 21:04:48,053 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.2817 | MSE 0.3943
2020-11-05 21:04:48,065 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3167 | Iter Mean Loss 11.3167
2020-11-05 21:04:48,077 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0785 | Iter Mean Loss 7.6976
2020-11-05 21:04:48,088 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3319 | Iter Mean Loss 11.2424
2020-11-05 21:04:48,099 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1414 | Iter Mean Loss 11.9671
2020-11-05 21:04:48,109 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1609 | Iter Mean Loss 11.8059
2020-11-05 21:04:48,112 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.2817 | MSE 0.3936
2020-11-05 21:04:48,125 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3129 | Iter Mean Loss 11.3129
2020-11-05 21:04:48,136 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0743 | Iter Mean Loss 7.6936
2020-11-05 21:04:48,144 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.2102
2020-11-05 21:04:48,153 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0995 | Iter Mean Loss 11.9325
2020-11-05 21:04:48,162 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.7676
2020-11-05 21:04:48,165 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.2817 | MSE 0.3930
2020-11-05 21:04:48,175 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3087 | Iter Mean Loss 11.3087
2020-11-05 21:04:48,183 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0700 | Iter Mean Loss 7.6894
2020-11-05 21:04:48,191 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1560 | Iter Mean Loss 11.1783
2020-11-05 21:04:48,200 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0579 | Iter Mean Loss 11.8982
2020-11-05 21:04:48,209 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0547 | Iter Mean Loss 11.7295
2020-11-05 21:04:48,211 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.2817 | MSE 0.3923
2020-11-05 21:04:48,221 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 11.3043
2020-11-05 21:04:48,230 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 7.6850
2020-11-05 21:04:48,240 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0693 | Iter Mean Loss 11.1465
2020-11-05 21:04:48,248 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0167 | Iter Mean Loss 11.8640
2020-11-05 21:04:48,258 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0022 | Iter Mean Loss 11.6917
2020-11-05 21:04:48,261 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.2817 | MSE 0.3917
2020-11-05 21:04:48,271 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2995 | Iter Mean Loss 11.2995
2020-11-05 21:04:48,280 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0615 | Iter Mean Loss 7.6805
2020-11-05 21:04:48,290 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9834 | Iter Mean Loss 11.1148
2020-11-05 21:04:48,298 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9757 | Iter Mean Loss 11.8301
2020-11-05 21:04:48,308 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.9500 | Iter Mean Loss 11.6540
2020-11-05 21:04:48,311 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.2817 | MSE 0.3910
2020-11-05 21:04:48,322 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 11.2945
2020-11-05 21:04:48,330 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0573 | Iter Mean Loss 7.6759
2020-11-05 21:04:48,339 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8983 | Iter Mean Loss 11.0834
2020-11-05 21:04:48,347 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9350 | Iter Mean Loss 11.7963
2020-11-05 21:04:48,355 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8983 | Iter Mean Loss 11.6167
2020-11-05 21:04:48,357 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.2817 | MSE 0.3904
2020-11-05 21:04:48,366 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2892 | Iter Mean Loss 11.2892
2020-11-05 21:04:48,376 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0530 | Iter Mean Loss 7.6711
2020-11-05 21:04:48,385 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8140 | Iter Mean Loss 11.0521
2020-11-05 21:04:48,393 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8946 | Iter Mean Loss 11.7627
2020-11-05 21:04:48,402 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8469 | Iter Mean Loss 11.5795
2020-11-05 21:04:48,406 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.2817 | MSE 0.3898
2020-11-05 21:04:48,419 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2836 | Iter Mean Loss 11.2836
2020-11-05 21:04:48,432 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0487 | Iter Mean Loss 7.6661
2020-11-05 21:04:48,444 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7304 | Iter Mean Loss 11.0209
2020-11-05 21:04:48,453 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8545 | Iter Mean Loss 11.7293
2020-11-05 21:04:48,465 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7959 | Iter Mean Loss 11.5426
2020-11-05 21:04:48,467 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.2817 | MSE 0.3891
2020-11-05 21:04:48,479 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2777 | Iter Mean Loss 11.2777
2020-11-05 21:04:48,493 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0445 | Iter Mean Loss 7.6611
2020-11-05 21:04:48,503 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6476 | Iter Mean Loss 10.9899
2020-11-05 21:04:48,511 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8146 | Iter Mean Loss 11.6961
2020-11-05 21:04:48,520 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7453 | Iter Mean Loss 11.5059
2020-11-05 21:04:48,523 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.2817 | MSE 0.3885
2020-11-05 21:04:48,533 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2715 | Iter Mean Loss 11.2715
2020-11-05 21:04:48,542 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0402 | Iter Mean Loss 7.6558
2020-11-05 21:04:48,550 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5656 | Iter Mean Loss 10.9591
2020-11-05 21:04:48,559 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7750 | Iter Mean Loss 11.6631
2020-11-05 21:04:48,567 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6950 | Iter Mean Loss 11.4695
2020-11-05 21:04:48,570 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.2817 | MSE 0.3879
2020-11-05 21:04:48,580 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2650 | Iter Mean Loss 11.2650
2020-11-05 21:04:48,589 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0358 | Iter Mean Loss 7.6504
2020-11-05 21:04:48,598 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4844 | Iter Mean Loss 10.9284
2020-11-05 21:04:48,607 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7357 | Iter Mean Loss 11.6302
2020-11-05 21:04:48,615 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6452 | Iter Mean Loss 11.4332
2020-11-05 21:04:48,619 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.2817 | MSE 0.3873
2020-11-05 21:04:48,628 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2583 | Iter Mean Loss 11.2583
2020-11-05 21:04:48,637 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0315 | Iter Mean Loss 7.6449
2020-11-05 21:04:48,646 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4038 | Iter Mean Loss 10.8979
2020-11-05 21:04:48,655 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6967 | Iter Mean Loss 11.5976
2020-11-05 21:04:48,663 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5957 | Iter Mean Loss 11.3972
2020-11-05 21:04:48,666 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.2817 | MSE 0.3867
2020-11-05 21:04:48,675 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2513 | Iter Mean Loss 11.2513
2020-11-05 21:04:48,683 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 7.6392
2020-11-05 21:04:48,693 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3241 | Iter Mean Loss 10.8675
2020-11-05 21:04:48,700 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6579 | Iter Mean Loss 11.5651
2020-11-05 21:04:48,709 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5466 | Iter Mean Loss 11.3614
2020-11-05 21:04:48,711 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.2817 | MSE 0.3860
2020-11-05 21:04:48,721 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2440 | Iter Mean Loss 11.2440
2020-11-05 21:04:48,729 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0228 | Iter Mean Loss 7.6334
2020-11-05 21:04:48,738 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2451 | Iter Mean Loss 10.8373
2020-11-05 21:04:48,747 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6194 | Iter Mean Loss 11.5328
2020-11-05 21:04:48,755 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4979 | Iter Mean Loss 11.3258
2020-11-05 21:04:48,757 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.2817 | MSE 0.3854
2020-11-05 21:04:48,766 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2365 | Iter Mean Loss 11.2365
2020-11-05 21:04:48,775 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0185 | Iter Mean Loss 7.6275
2020-11-05 21:04:48,784 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1668 | Iter Mean Loss 10.8072
2020-11-05 21:04:48,792 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5811 | Iter Mean Loss 11.5007
2020-11-05 21:04:48,800 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4496 | Iter Mean Loss 11.2905
2020-11-05 21:04:48,803 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.2817 | MSE 0.3848
2020-11-05 21:04:48,813 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2287 | Iter Mean Loss 11.2287
2020-11-05 21:04:48,822 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 7.6214
2020-11-05 21:04:48,830 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0892 | Iter Mean Loss 10.7773
2020-11-05 21:04:48,838 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5431 | Iter Mean Loss 11.4688
2020-11-05 21:04:48,847 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4017 | Iter Mean Loss 11.2553
2020-11-05 21:04:48,849 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.2817 | MSE 0.3843
2020-11-05 21:04:48,859 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2206 | Iter Mean Loss 11.2206
2020-11-05 21:04:48,869 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0097 | Iter Mean Loss 7.6152
2020-11-05 21:04:48,878 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0124 | Iter Mean Loss 10.7476
2020-11-05 21:04:48,887 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5053 | Iter Mean Loss 11.4370
2020-11-05 21:04:48,897 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3541 | Iter Mean Loss 11.2204
2020-11-05 21:04:48,899 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.2817 | MSE 0.3837
2020-11-05 21:04:48,908 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2123 | Iter Mean Loss 11.2123
2020-11-05 21:04:48,918 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0053 | Iter Mean Loss 7.6088
2020-11-05 21:04:48,926 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9363 | Iter Mean Loss 10.7179
2020-11-05 21:04:48,934 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4678 | Iter Mean Loss 11.4054
2020-11-05 21:04:48,943 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3070 | Iter Mean Loss 11.1857
2020-11-05 21:04:48,945 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.2817 | MSE 0.3831
2020-11-05 21:04:48,954 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2037 | Iter Mean Loss 11.2037
2020-11-05 21:04:48,963 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0009 | Iter Mean Loss 7.6023
2020-11-05 21:04:48,973 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8608 | Iter Mean Loss 10.6885
2020-11-05 21:04:48,982 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4305 | Iter Mean Loss 11.3740
2020-11-05 21:04:48,990 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2602 | Iter Mean Loss 11.1512
2020-11-05 21:04:48,993 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.2817 | MSE 0.3825
2020-11-05 21:04:49,001 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1949 | Iter Mean Loss 11.1949
2020-11-05 21:04:49,010 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9964 | Iter Mean Loss 7.5957
2020-11-05 21:04:49,020 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7861 | Iter Mean Loss 10.6591
2020-11-05 21:04:49,032 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3934 | Iter Mean Loss 11.3427
2020-11-05 21:04:49,041 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2138 | Iter Mean Loss 11.1169
2020-11-05 21:04:49,043 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.2817 | MSE 0.3819
2020-11-05 21:04:49,053 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1858 | Iter Mean Loss 11.1858
2020-11-05 21:04:49,062 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9920 | Iter Mean Loss 7.5889
2020-11-05 21:04:49,072 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7121 | Iter Mean Loss 10.6300
2020-11-05 21:04:49,080 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3566 | Iter Mean Loss 11.3116
2020-11-05 21:04:49,089 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1677 | Iter Mean Loss 11.0829
2020-11-05 21:04:49,091 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.2817 | MSE 0.3813
2020-11-05 21:04:49,100 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1765 | Iter Mean Loss 11.1765
2020-11-05 21:04:49,109 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9875 | Iter Mean Loss 7.5820
2020-11-05 21:04:49,117 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6388 | Iter Mean Loss 10.6009
2020-11-05 21:04:49,125 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3200 | Iter Mean Loss 11.2807
2020-11-05 21:04:49,133 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1221 | Iter Mean Loss 11.0490
2020-11-05 21:04:49,135 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.2817 | MSE 0.3808
2020-11-05 21:04:49,144 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1669 | Iter Mean Loss 11.1669
2020-11-05 21:04:49,152 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9830 | Iter Mean Loss 7.5750
2020-11-05 21:04:49,160 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5662 | Iter Mean Loss 10.5720
2020-11-05 21:04:49,168 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2837 | Iter Mean Loss 11.2499
2020-11-05 21:04:49,176 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0768 | Iter Mean Loss 11.0153
2020-11-05 21:04:49,178 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.2817 | MSE 0.3802
2020-11-05 21:04:49,187 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1571 | Iter Mean Loss 11.1571
2020-11-05 21:04:49,195 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 7.5678
2020-11-05 21:04:49,203 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4942 | Iter Mean Loss 10.5433
2020-11-05 21:04:49,211 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2475 | Iter Mean Loss 11.2193
2020-11-05 21:04:49,220 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0319 | Iter Mean Loss 10.9818
2020-11-05 21:04:49,222 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.2817 | MSE 0.3797
2020-11-05 21:04:49,231 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1471 | Iter Mean Loss 11.1471
2020-11-05 21:04:49,239 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9740 | Iter Mean Loss 7.5605
2020-11-05 21:04:49,248 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4229 | Iter Mean Loss 10.5146
2020-11-05 21:04:49,257 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2116 | Iter Mean Loss 11.1889
2020-11-05 21:04:49,266 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9874 | Iter Mean Loss 10.9486
2020-11-05 21:04:49,269 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.2817 | MSE 0.3791
2020-11-05 21:04:49,279 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1368 | Iter Mean Loss 11.1368
2020-11-05 21:04:49,287 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9694 | Iter Mean Loss 7.5531
2020-11-05 21:04:49,296 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3523 | Iter Mean Loss 10.4861
2020-11-05 21:04:49,306 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1758 | Iter Mean Loss 11.1586
2020-11-05 21:04:49,315 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9432 | Iter Mean Loss 10.9155
2020-11-05 21:04:49,318 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.2817 | MSE 0.3786
2020-11-05 21:04:49,327 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1263 | Iter Mean Loss 11.1263
2020-11-05 21:04:49,336 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9648 | Iter Mean Loss 7.5456
2020-11-05 21:04:49,346 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2823 | Iter Mean Loss 10.4578
2020-11-05 21:04:49,356 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1403 | Iter Mean Loss 11.1284
2020-11-05 21:04:49,364 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8995 | Iter Mean Loss 10.8826
2020-11-05 21:04:49,366 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.2817 | MSE 0.3780
2020-11-05 21:04:49,374 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1155 | Iter Mean Loss 11.1155
2020-11-05 21:04:49,382 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9603 | Iter Mean Loss 7.5379
2020-11-05 21:04:49,390 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2130 | Iter Mean Loss 10.4296
2020-11-05 21:04:49,399 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1050 | Iter Mean Loss 11.0984
2020-11-05 21:04:49,408 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8560 | Iter Mean Loss 10.8499
2020-11-05 21:04:49,411 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.2817 | MSE 0.3775
2020-11-05 21:04:49,421 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1045 | Iter Mean Loss 11.1045
2020-11-05 21:04:49,430 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9556 | Iter Mean Loss 7.5301
2020-11-05 21:04:49,440 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1443 | Iter Mean Loss 10.4015
2020-11-05 21:04:49,448 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0698 | Iter Mean Loss 11.0686
2020-11-05 21:04:49,458 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8130 | Iter Mean Loss 10.8175
2020-11-05 21:04:49,460 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.2817 | MSE 0.3769
2020-11-05 21:04:49,470 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0934 | Iter Mean Loss 11.0934
2020-11-05 21:04:49,479 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9510 | Iter Mean Loss 7.5222
2020-11-05 21:04:49,488 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0763 | Iter Mean Loss 10.3735
2020-11-05 21:04:49,496 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0349 | Iter Mean Loss 11.0389
2020-11-05 21:04:49,507 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7703 | Iter Mean Loss 10.7852
2020-11-05 21:04:49,509 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.2817 | MSE 0.3764
2020-11-05 21:04:49,519 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0819 | Iter Mean Loss 11.0819
2020-11-05 21:04:49,528 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9464 | Iter Mean Loss 7.5141
2020-11-05 21:04:49,536 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0088 | Iter Mean Loss 10.3457
2020-11-05 21:04:49,544 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0002 | Iter Mean Loss 11.0093
2020-11-05 21:04:49,554 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7280 | Iter Mean Loss 10.7531
2020-11-05 21:04:49,556 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.2817 | MSE 0.3759
2020-11-05 21:04:49,565 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0703 | Iter Mean Loss 11.0703
2020-11-05 21:04:49,574 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9417 | Iter Mean Loss 7.5060
2020-11-05 21:04:49,582 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9421 | Iter Mean Loss 10.3180
2020-11-05 21:04:49,590 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9656 | Iter Mean Loss 10.9799
2020-11-05 21:04:49,602 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 10.7211
2020-11-05 21:04:49,606 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.2817 | MSE 0.3753
2020-11-05 21:04:49,619 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0585 | Iter Mean Loss 11.0585
2020-11-05 21:04:49,633 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 7.4977
2020-11-05 21:04:49,648 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8759 | Iter Mean Loss 10.2904
2020-11-05 21:04:49,662 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9312 | Iter Mean Loss 10.9506
2020-11-05 21:04:49,675 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6444 | Iter Mean Loss 10.6894
2020-11-05 21:04:49,679 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.2817 | MSE 0.3748
2020-11-05 21:04:49,691 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0464 | Iter Mean Loss 11.0464
2020-11-05 21:04:49,700 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9323 | Iter Mean Loss 7.4893
2020-11-05 21:04:49,710 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.2630
2020-11-05 21:04:49,719 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8970 | Iter Mean Loss 10.9215
2020-11-05 21:04:49,728 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6031 | Iter Mean Loss 10.6578
2020-11-05 21:04:49,730 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.2817 | MSE 0.3743
2020-11-05 21:04:49,739 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0341 | Iter Mean Loss 11.0341
2020-11-05 21:04:49,747 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9275 | Iter Mean Loss 7.4808
2020-11-05 21:04:49,758 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7454 | Iter Mean Loss 10.2357
2020-11-05 21:04:49,768 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8630 | Iter Mean Loss 10.8925
2020-11-05 21:04:49,780 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5622 | Iter Mean Loss 10.6264
2020-11-05 21:04:49,782 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.2817 | MSE 0.3738
2020-11-05 21:04:49,793 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0216 | Iter Mean Loss 11.0216
2020-11-05 21:04:49,802 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9228 | Iter Mean Loss 7.4722
2020-11-05 21:04:49,814 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6810 | Iter Mean Loss 10.2085
2020-11-05 21:04:49,824 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8291 | Iter Mean Loss 10.8636
2020-11-05 21:04:49,834 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5216 | Iter Mean Loss 10.5952
2020-11-05 21:04:49,837 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.2817 | MSE 0.3733
2020-11-05 21:04:49,847 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0089 | Iter Mean Loss 11.0089
2020-11-05 21:04:49,856 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9180 | Iter Mean Loss 7.4635
2020-11-05 21:04:49,866 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6173 | Iter Mean Loss 10.1814
2020-11-05 21:04:49,874 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7954 | Iter Mean Loss 10.8349
2020-11-05 21:04:49,885 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4813 | Iter Mean Loss 10.5642
2020-11-05 21:04:49,888 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.2817 | MSE 0.3727
2020-11-05 21:04:49,898 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9961 | Iter Mean Loss 10.9961
2020-11-05 21:04:49,909 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9132 | Iter Mean Loss 7.4546
2020-11-05 21:04:49,922 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5541 | Iter Mean Loss 10.1544
2020-11-05 21:04:49,931 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7618 | Iter Mean Loss 10.8063
2020-11-05 21:04:49,942 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4415 | Iter Mean Loss 10.5333
2020-11-05 21:04:49,945 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.2817 | MSE 0.3722
2020-11-05 21:04:49,957 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9830 | Iter Mean Loss 10.9830
2020-11-05 21:04:49,967 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9083 | Iter Mean Loss 7.4456
2020-11-05 21:04:49,977 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4915 | Iter Mean Loss 10.1276
2020-11-05 21:04:49,986 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7284 | Iter Mean Loss 10.7778
2020-11-05 21:04:49,996 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4019 | Iter Mean Loss 10.5026
2020-11-05 21:04:49,998 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.2817 | MSE 0.3717
2020-11-05 21:04:50,007 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9697 | Iter Mean Loss 10.9697
2020-11-05 21:04:50,016 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 7.4366
2020-11-05 21:04:50,025 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4295 | Iter Mean Loss 10.1009
2020-11-05 21:04:50,035 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6952 | Iter Mean Loss 10.7494
2020-11-05 21:04:50,043 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3627 | Iter Mean Loss 10.4721
2020-11-05 21:04:50,045 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.2817 | MSE 0.3712
2020-11-05 21:04:50,055 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9562 | Iter Mean Loss 10.9562
2020-11-05 21:04:50,064 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8986 | Iter Mean Loss 7.4274
2020-11-05 21:04:50,074 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3680 | Iter Mean Loss 10.0742
2020-11-05 21:04:50,081 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6621 | Iter Mean Loss 10.7212
2020-11-05 21:04:50,091 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3238 | Iter Mean Loss 10.4417
2020-11-05 21:04:50,093 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.2817 | MSE 0.3708
2020-11-05 21:04:50,103 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9425 | Iter Mean Loss 10.9425
2020-11-05 21:04:50,112 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8936 | Iter Mean Loss 7.4181
2020-11-05 21:04:50,122 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3071 | Iter Mean Loss 10.0477
2020-11-05 21:04:50,130 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6291 | Iter Mean Loss 10.6931
2020-11-05 21:04:50,139 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2852 | Iter Mean Loss 10.4115
2020-11-05 21:04:50,141 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.2817 | MSE 0.3703
2020-11-05 21:04:50,150 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9286 | Iter Mean Loss 10.9286
2020-11-05 21:04:50,158 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8887 | Iter Mean Loss 7.4086
2020-11-05 21:04:50,166 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2467 | Iter Mean Loss 10.0213
2020-11-05 21:04:50,175 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5963 | Iter Mean Loss 10.6651
2020-11-05 21:04:50,183 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2470 | Iter Mean Loss 10.3815
2020-11-05 21:04:50,185 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.2817 | MSE 0.3698
2020-11-05 21:04:50,193 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9145 | Iter Mean Loss 10.9145
2020-11-05 21:04:50,201 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8837 | Iter Mean Loss 7.3991
2020-11-05 21:04:50,209 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1869 | Iter Mean Loss 9.9951
2020-11-05 21:04:50,218 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5636 | Iter Mean Loss 10.6372
2020-11-05 21:04:50,227 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2090 | Iter Mean Loss 10.3516
2020-11-05 21:04:50,230 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.2817 | MSE 0.3693
2020-11-05 21:04:50,239 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9003 | Iter Mean Loss 10.9003
2020-11-05 21:04:50,248 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8787 | Iter Mean Loss 7.3895
2020-11-05 21:04:50,256 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1276 | Iter Mean Loss 9.9689
2020-11-05 21:04:50,266 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5310 | Iter Mean Loss 10.6094
2020-11-05 21:04:50,274 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1714 | Iter Mean Loss 10.3218
2020-11-05 21:04:50,277 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.2817 | MSE 0.3688
2020-11-05 21:04:50,287 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8858 | Iter Mean Loss 10.8858
2020-11-05 21:04:50,296 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 7.3798
2020-11-05 21:04:50,305 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0689 | Iter Mean Loss 9.9428
2020-11-05 21:04:50,315 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4986 | Iter Mean Loss 10.5818
2020-11-05 21:04:50,324 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1341 | Iter Mean Loss 10.2922
2020-11-05 21:04:50,328 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.2817 | MSE 0.3683
2020-11-05 21:04:50,336 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 21:04:50,344 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8686 | Iter Mean Loss 7.3699
2020-11-05 21:04:50,352 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0107 | Iter Mean Loss 9.9168
2020-11-05 21:04:50,360 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4663 | Iter Mean Loss 10.5542
2020-11-05 21:04:50,368 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0971 | Iter Mean Loss 10.2628
2020-11-05 21:04:50,371 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.2817 | MSE 0.3679
2020-11-05 21:04:50,380 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8564 | Iter Mean Loss 10.8564
2020-11-05 21:04:50,389 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8635 | Iter Mean Loss 7.3600
2020-11-05 21:04:50,396 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9530 | Iter Mean Loss 9.8910
2020-11-05 21:04:50,404 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4341 | Iter Mean Loss 10.5268
2020-11-05 21:04:50,412 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0604 | Iter Mean Loss 10.2335
2020-11-05 21:04:50,415 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.2817 | MSE 0.3674
2020-11-05 21:04:50,424 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8414 | Iter Mean Loss 10.8414
2020-11-05 21:04:50,433 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8584 | Iter Mean Loss 7.3499
2020-11-05 21:04:50,442 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8958 | Iter Mean Loss 9.8652
2020-11-05 21:04:50,450 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4020 | Iter Mean Loss 10.4994
2020-11-05 21:04:50,459 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0240 | Iter Mean Loss 10.2043
2020-11-05 21:04:50,461 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.2817 | MSE 0.3669
2020-11-05 21:04:50,469 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8262 | Iter Mean Loss 10.8262
2020-11-05 21:04:50,478 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8533 | Iter Mean Loss 7.3398
2020-11-05 21:04:50,486 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8391 | Iter Mean Loss 9.8395
2020-11-05 21:04:50,494 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3701 | Iter Mean Loss 10.4722
2020-11-05 21:04:50,502 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9879 | Iter Mean Loss 10.1753
2020-11-05 21:04:50,504 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.2817 | MSE 0.3665
2020-11-05 21:04:50,514 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 21:04:50,522 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8481 | Iter Mean Loss 7.3295
2020-11-05 21:04:50,532 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7829 | Iter Mean Loss 9.8140
2020-11-05 21:04:50,540 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3383 | Iter Mean Loss 10.4450
2020-11-05 21:04:50,550 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9521 | Iter Mean Loss 10.1464
2020-11-05 21:04:50,552 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.2817 | MSE 0.3660
2020-11-05 21:04:50,561 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7954 | Iter Mean Loss 10.7954
2020-11-05 21:04:50,569 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8429 | Iter Mean Loss 7.3191
2020-11-05 21:04:50,579 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7272 | Iter Mean Loss 9.7885
2020-11-05 21:04:50,587 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3065 | Iter Mean Loss 10.4180
2020-11-05 21:04:50,595 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9165 | Iter Mean Loss 10.1177
2020-11-05 21:04:50,597 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.2817 | MSE 0.3655
2020-11-05 21:04:50,606 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7797 | Iter Mean Loss 10.7797
2020-11-05 21:04:50,614 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8377 | Iter Mean Loss 7.3087
2020-11-05 21:04:50,622 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6720 | Iter Mean Loss 9.7631
2020-11-05 21:04:50,631 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2749 | Iter Mean Loss 10.3911
2020-11-05 21:04:50,639 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8813 | Iter Mean Loss 10.0891
2020-11-05 21:04:50,642 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.2817 | MSE 0.3651
2020-11-05 21:04:50,652 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7638 | Iter Mean Loss 10.7638
2020-11-05 21:04:50,661 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8324 | Iter Mean Loss 7.2981
2020-11-05 21:04:50,672 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6173 | Iter Mean Loss 9.7378
2020-11-05 21:04:50,684 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2434 | Iter Mean Loss 10.3642
2020-11-05 21:04:50,692 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8463 | Iter Mean Loss 10.0606
2020-11-05 21:04:50,695 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.2817 | MSE 0.3646
2020-11-05 21:04:50,705 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7478 | Iter Mean Loss 10.7478
2020-11-05 21:04:50,714 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8271 | Iter Mean Loss 7.2874
2020-11-05 21:04:50,724 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5630 | Iter Mean Loss 9.7126
2020-11-05 21:04:50,732 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2119 | Iter Mean Loss 10.3374
2020-11-05 21:04:50,742 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8116 | Iter Mean Loss 10.0323
2020-11-05 21:04:50,744 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.2817 | MSE 0.3642
2020-11-05 21:04:50,755 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7316 | Iter Mean Loss 10.7316
2020-11-05 21:04:50,763 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8218 | Iter Mean Loss 7.2767
2020-11-05 21:04:50,773 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5092 | Iter Mean Loss 9.6875
2020-11-05 21:04:50,781 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1806 | Iter Mean Loss 10.3108
2020-11-05 21:04:50,790 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7772 | Iter Mean Loss 10.0041
2020-11-05 21:04:50,793 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.2817 | MSE 0.3638
2020-11-05 21:04:50,802 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7152 | Iter Mean Loss 10.7152
2020-11-05 21:04:50,811 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8164 | Iter Mean Loss 7.2658
2020-11-05 21:04:50,820 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4559 | Iter Mean Loss 9.6625
2020-11-05 21:04:50,829 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1494 | Iter Mean Loss 10.2842
2020-11-05 21:04:50,838 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7431 | Iter Mean Loss 9.9760
2020-11-05 21:04:50,840 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.2817 | MSE 0.3633
2020-11-05 21:04:50,850 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6986 | Iter Mean Loss 10.6986
2020-11-05 21:04:50,858 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8110 | Iter Mean Loss 7.2548
2020-11-05 21:04:50,868 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4030 | Iter Mean Loss 9.6375
2020-11-05 21:04:50,876 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1182 | Iter Mean Loss 10.2577
2020-11-05 21:04:50,885 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7092 | Iter Mean Loss 9.9480
2020-11-05 21:04:50,887 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.2817 | MSE 0.3629
2020-11-05 21:04:50,896 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6819 | Iter Mean Loss 10.6819
2020-11-05 21:04:50,905 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8056 | Iter Mean Loss 7.2438
2020-11-05 21:04:50,913 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3506 | Iter Mean Loss 9.6127
2020-11-05 21:04:50,922 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0872 | Iter Mean Loss 10.2313
2020-11-05 21:04:50,930 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6755 | Iter Mean Loss 9.9202
2020-11-05 21:04:50,933 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.2817 | MSE 0.3624
2020-11-05 21:04:50,941 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6651 | Iter Mean Loss 10.6651
2020-11-05 21:04:50,950 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8001 | Iter Mean Loss 7.2326
2020-11-05 21:04:50,959 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2986 | Iter Mean Loss 9.5879
2020-11-05 21:04:50,967 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0562 | Iter Mean Loss 10.2050
2020-11-05 21:04:50,975 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6422 | Iter Mean Loss 9.8924
2020-11-05 21:04:50,977 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.2817 | MSE 0.3620
2020-11-05 21:04:50,985 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6480 | Iter Mean Loss 10.6480
2020-11-05 21:04:50,994 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7946 | Iter Mean Loss 7.2213
2020-11-05 21:04:51,002 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2470 | Iter Mean Loss 9.5632
2020-11-05 21:04:51,010 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0253 | Iter Mean Loss 10.1787
2020-11-05 21:04:51,018 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6090 | Iter Mean Loss 9.8648
2020-11-05 21:04:51,020 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.2817 | MSE 0.3616
2020-11-05 21:04:51,030 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6309 | Iter Mean Loss 10.6309
2020-11-05 21:04:51,039 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7891 | Iter Mean Loss 7.2100
2020-11-05 21:04:51,048 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1959 | Iter Mean Loss 9.5386
2020-11-05 21:04:51,057 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9945 | Iter Mean Loss 10.1526
2020-11-05 21:04:51,066 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5762 | Iter Mean Loss 9.8373
2020-11-05 21:04:51,068 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.2817 | MSE 0.3612
2020-11-05 21:04:51,079 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6135 | Iter Mean Loss 10.6135
2020-11-05 21:04:51,087 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7835 | Iter Mean Loss 7.1985
2020-11-05 21:04:51,097 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1451 | Iter Mean Loss 9.5141
2020-11-05 21:04:51,105 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9638 | Iter Mean Loss 10.1265
2020-11-05 21:04:51,115 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 9.8099
2020-11-05 21:04:51,117 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.2817 | MSE 0.3607
2020-11-05 21:04:51,128 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5960 | Iter Mean Loss 10.5960
2020-11-05 21:04:51,136 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7779 | Iter Mean Loss 7.1869
2020-11-05 21:04:51,145 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0949 | Iter Mean Loss 9.4896
2020-11-05 21:04:51,154 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9331 | Iter Mean Loss 10.1005
2020-11-05 21:04:51,161 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5111 | Iter Mean Loss 9.7826
2020-11-05 21:04:51,163 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.2817 | MSE 0.3603
2020-11-05 21:04:51,172 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5783 | Iter Mean Loss 10.5783
2020-11-05 21:04:51,180 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 7.1753
2020-11-05 21:04:51,188 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0450 | Iter Mean Loss 9.4652
2020-11-05 21:04:51,196 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9026 | Iter Mean Loss 10.0745
2020-11-05 21:04:51,204 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4790 | Iter Mean Loss 9.7554
2020-11-05 21:04:51,206 - root - INFO - Evaluate: Epoch 0285 | NDCG 1.0000 | MSE 0.3599
2020-11-05 21:04:51,214 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5605 | Iter Mean Loss 10.5605
2020-11-05 21:04:51,222 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7666 | Iter Mean Loss 7.1636
2020-11-05 21:04:51,229 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9955 | Iter Mean Loss 9.4409
2020-11-05 21:04:51,237 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8721 | Iter Mean Loss 10.0487
2020-11-05 21:04:51,245 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4471 | Iter Mean Loss 9.7283
2020-11-05 21:04:51,247 - root - INFO - Evaluate: Epoch 0286 | NDCG 1.0000 | MSE 0.3595
2020-11-05 21:04:51,256 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5426 | Iter Mean Loss 10.5426
2020-11-05 21:04:51,264 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7609 | Iter Mean Loss 7.1517
2020-11-05 21:04:51,273 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9464 | Iter Mean Loss 9.4166
2020-11-05 21:04:51,283 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8416 | Iter Mean Loss 10.0229
2020-11-05 21:04:51,291 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 9.7014
2020-11-05 21:04:51,294 - root - INFO - Evaluate: Epoch 0287 | NDCG 1.0000 | MSE 0.3591
2020-11-05 21:04:51,305 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5244 | Iter Mean Loss 10.5244
2020-11-05 21:04:51,318 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7551 | Iter Mean Loss 7.1398
2020-11-05 21:04:51,332 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8977 | Iter Mean Loss 9.3924
2020-11-05 21:04:51,340 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8113 | Iter Mean Loss 9.9971
2020-11-05 21:04:51,351 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3839 | Iter Mean Loss 9.6745
2020-11-05 21:04:51,353 - root - INFO - Evaluate: Epoch 0288 | NDCG 1.0000 | MSE 0.3587
2020-11-05 21:04:51,363 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5062 | Iter Mean Loss 10.5062
2020-11-05 21:04:51,372 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7493 | Iter Mean Loss 7.1278
2020-11-05 21:04:51,380 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8494 | Iter Mean Loss 9.3683
2020-11-05 21:04:51,388 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7810 | Iter Mean Loss 9.9715
2020-11-05 21:04:51,396 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3526 | Iter Mean Loss 9.6477
2020-11-05 21:04:51,399 - root - INFO - Evaluate: Epoch 0289 | NDCG 1.0000 | MSE 0.3583
2020-11-05 21:04:51,407 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4878 | Iter Mean Loss 10.4878
2020-11-05 21:04:51,417 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7435 | Iter Mean Loss 7.1156
2020-11-05 21:04:51,427 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8015 | Iter Mean Loss 9.3442
2020-11-05 21:04:51,437 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7508 | Iter Mean Loss 9.9459
2020-11-05 21:04:51,445 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3216 | Iter Mean Loss 9.6210
2020-11-05 21:04:51,449 - root - INFO - Evaluate: Epoch 0290 | NDCG 1.0000 | MSE 0.3579
2020-11-05 21:04:51,459 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4692 | Iter Mean Loss 10.4692
2020-11-05 21:04:51,469 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7376 | Iter Mean Loss 7.1034
2020-11-05 21:04:51,477 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7539 | Iter Mean Loss 9.3203
2020-11-05 21:04:51,487 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7206 | Iter Mean Loss 9.9203
2020-11-05 21:04:51,496 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2908 | Iter Mean Loss 9.5944
2020-11-05 21:04:51,499 - root - INFO - Evaluate: Epoch 0291 | NDCG 1.0000 | MSE 0.3575
2020-11-05 21:04:51,509 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4505 | Iter Mean Loss 10.4505
2020-11-05 21:04:51,520 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7318 | Iter Mean Loss 7.0911
2020-11-05 21:04:51,529 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7068 | Iter Mean Loss 9.2963
2020-11-05 21:04:51,539 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6905 | Iter Mean Loss 9.8949
2020-11-05 21:04:51,550 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2602 | Iter Mean Loss 9.5679
2020-11-05 21:04:51,554 - root - INFO - Evaluate: Epoch 0292 | NDCG 1.0000 | MSE 0.3571
2020-11-05 21:04:51,564 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4316 | Iter Mean Loss 10.4316
2020-11-05 21:04:51,573 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7258 | Iter Mean Loss 7.0787
2020-11-05 21:04:51,582 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6599 | Iter Mean Loss 9.2725
2020-11-05 21:04:51,590 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6605 | Iter Mean Loss 9.8695
2020-11-05 21:04:51,598 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2298 | Iter Mean Loss 9.5415
2020-11-05 21:04:51,600 - root - INFO - Evaluate: Epoch 0293 | NDCG 1.0000 | MSE 0.3567
2020-11-05 21:04:51,608 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4126 | Iter Mean Loss 10.4126
2020-11-05 21:04:51,616 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7198 | Iter Mean Loss 7.0662
2020-11-05 21:04:51,624 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6135 | Iter Mean Loss 9.2486
2020-11-05 21:04:51,632 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6305 | Iter Mean Loss 9.8441
2020-11-05 21:04:51,640 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1996 | Iter Mean Loss 9.5152
2020-11-05 21:04:51,642 - root - INFO - Evaluate: Epoch 0294 | NDCG 1.0000 | MSE 0.3563
2020-11-05 21:04:51,651 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3934 | Iter Mean Loss 10.3934
2020-11-05 21:04:51,659 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7138 | Iter Mean Loss 7.0536
2020-11-05 21:04:51,667 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5674 | Iter Mean Loss 9.2249
2020-11-05 21:04:51,675 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6006 | Iter Mean Loss 9.8188
2020-11-05 21:04:51,683 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1696 | Iter Mean Loss 9.4890
2020-11-05 21:04:51,685 - root - INFO - Evaluate: Epoch 0295 | NDCG 1.0000 | MSE 0.3559
2020-11-05 21:04:51,695 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3741 | Iter Mean Loss 10.3741
2020-11-05 21:04:51,704 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7078 | Iter Mean Loss 7.0410
2020-11-05 21:04:51,713 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5216 | Iter Mean Loss 9.2012
2020-11-05 21:04:51,722 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 9.7936
2020-11-05 21:04:51,730 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1398 | Iter Mean Loss 9.4628
2020-11-05 21:04:51,732 - root - INFO - Evaluate: Epoch 0296 | NDCG 1.0000 | MSE 0.3555
2020-11-05 21:04:51,742 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3547 | Iter Mean Loss 10.3547
2020-11-05 21:04:51,750 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7017 | Iter Mean Loss 7.0282
2020-11-05 21:04:51,759 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4762 | Iter Mean Loss 9.1775
2020-11-05 21:04:51,767 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5410 | Iter Mean Loss 9.7684
2020-11-05 21:04:51,777 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1102 | Iter Mean Loss 9.4368
2020-11-05 21:04:51,779 - root - INFO - Evaluate: Epoch 0297 | NDCG 1.0000 | MSE 0.3552
2020-11-05 21:04:51,787 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3351 | Iter Mean Loss 10.3351
2020-11-05 21:04:51,795 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6956 | Iter Mean Loss 7.0153
2020-11-05 21:04:51,803 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4311 | Iter Mean Loss 9.1539
2020-11-05 21:04:51,811 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5113 | Iter Mean Loss 9.7433
2020-11-05 21:04:51,819 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0808 | Iter Mean Loss 9.4108
2020-11-05 21:04:51,821 - root - INFO - Evaluate: Epoch 0298 | NDCG 1.0000 | MSE 0.3548
2020-11-05 21:04:51,829 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3154 | Iter Mean Loss 10.3154
2020-11-05 21:04:51,837 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6894 | Iter Mean Loss 7.0024
2020-11-05 21:04:51,845 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3864 | Iter Mean Loss 9.1304
2020-11-05 21:04:51,853 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4816 | Iter Mean Loss 9.7182
2020-11-05 21:04:51,861 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0516 | Iter Mean Loss 9.3849
2020-11-05 21:04:51,863 - root - INFO - Evaluate: Epoch 0299 | NDCG 1.0000 | MSE 0.3544
2020-11-05 21:04:51,873 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2955 | Iter Mean Loss 10.2955
2020-11-05 21:04:51,882 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6832 | Iter Mean Loss 6.9894
2020-11-05 21:04:51,890 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3420 | Iter Mean Loss 9.1069
2020-11-05 21:04:51,899 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4520 | Iter Mean Loss 9.6932
2020-11-05 21:04:51,907 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0226 | Iter Mean Loss 9.3591
2020-11-05 21:04:51,909 - root - INFO - Evaluate: Epoch 0300 | NDCG 1.0000 | MSE 0.3540
2020-11-05 21:04:51,918 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2755 | Iter Mean Loss 10.2755
2020-11-05 21:04:51,925 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6770 | Iter Mean Loss 6.9762
2020-11-05 21:04:51,934 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2979 | Iter Mean Loss 9.0835
2020-11-05 21:04:51,941 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4224 | Iter Mean Loss 9.6682
2020-11-05 21:04:51,950 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9937 | Iter Mean Loss 9.3333
2020-11-05 21:04:51,952 - root - INFO - Evaluate: Epoch 0301 | NDCG 1.0000 | MSE 0.3537
2020-11-05 21:04:51,961 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2554 | Iter Mean Loss 10.2554
2020-11-05 21:04:51,970 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6707 | Iter Mean Loss 6.9630
2020-11-05 21:04:51,977 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2541 | Iter Mean Loss 9.0601
2020-11-05 21:04:51,985 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3929 | Iter Mean Loss 9.6433
2020-11-05 21:04:51,993 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 9.3076
2020-11-05 21:04:51,995 - root - INFO - Evaluate: Epoch 0302 | NDCG 1.0000 | MSE 0.3533
2020-11-05 21:04:52,003 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2351 | Iter Mean Loss 10.2351
2020-11-05 21:04:52,011 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6644 | Iter Mean Loss 6.9497
2020-11-05 21:04:52,018 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2107 | Iter Mean Loss 9.0367
2020-11-05 21:04:52,027 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3635 | Iter Mean Loss 9.6184
2020-11-05 21:04:52,035 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9366 | Iter Mean Loss 9.2821
2020-11-05 21:04:52,037 - root - INFO - Evaluate: Epoch 0303 | NDCG 1.0000 | MSE 0.3529
2020-11-05 21:04:52,045 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2147 | Iter Mean Loss 10.2147
2020-11-05 21:04:52,053 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6580 | Iter Mean Loss 6.9364
2020-11-05 21:04:52,061 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1675 | Iter Mean Loss 9.0134
2020-11-05 21:04:52,069 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3341 | Iter Mean Loss 9.5936
2020-11-05 21:04:52,076 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9083 | Iter Mean Loss 9.2565
2020-11-05 21:04:52,078 - root - INFO - Evaluate: Epoch 0304 | NDCG 1.0000 | MSE 0.3526
2020-11-05 21:04:52,088 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1942 | Iter Mean Loss 10.1942
2020-11-05 21:04:52,096 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6516 | Iter Mean Loss 6.9229
2020-11-05 21:04:52,104 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1247 | Iter Mean Loss 8.9902
2020-11-05 21:04:52,112 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3047 | Iter Mean Loss 9.5688
2020-11-05 21:04:52,121 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8802 | Iter Mean Loss 9.2311
2020-11-05 21:04:52,124 - root - INFO - Evaluate: Epoch 0305 | NDCG 1.0000 | MSE 0.3522
2020-11-05 21:04:52,133 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1735 | Iter Mean Loss 10.1735
2020-11-05 21:04:52,142 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6452 | Iter Mean Loss 6.9093
2020-11-05 21:04:52,151 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0822 | Iter Mean Loss 8.9670
2020-11-05 21:04:52,160 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2754 | Iter Mean Loss 9.5441
2020-11-05 21:04:52,170 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8522 | Iter Mean Loss 9.2057
2020-11-05 21:04:52,172 - root - INFO - Evaluate: Epoch 0306 | NDCG 1.0000 | MSE 0.3519
2020-11-05 21:04:52,181 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1527 | Iter Mean Loss 10.1527
2020-11-05 21:04:52,190 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6387 | Iter Mean Loss 6.8957
2020-11-05 21:04:52,198 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0399 | Iter Mean Loss 8.9438
2020-11-05 21:04:52,205 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2462 | Iter Mean Loss 9.5194
2020-11-05 21:04:52,213 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8245 | Iter Mean Loss 9.1804
2020-11-05 21:04:52,215 - root - INFO - Evaluate: Epoch 0307 | NDCG 1.0000 | MSE 0.3515
2020-11-05 21:04:52,224 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1318 | Iter Mean Loss 10.1318
2020-11-05 21:04:52,232 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 6.8820
2020-11-05 21:04:52,239 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9980 | Iter Mean Loss 8.9207
2020-11-05 21:04:52,247 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2170 | Iter Mean Loss 9.4947
2020-11-05 21:04:52,255 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7968 | Iter Mean Loss 9.1552
2020-11-05 21:04:52,257 - root - INFO - Evaluate: Epoch 0308 | NDCG 1.0000 | MSE 0.3512
2020-11-05 21:04:52,265 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1107 | Iter Mean Loss 10.1107
2020-11-05 21:04:52,274 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 6.8682
2020-11-05 21:04:52,282 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9563 | Iter Mean Loss 8.8976
2020-11-05 21:04:52,290 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1878 | Iter Mean Loss 9.4701
2020-11-05 21:04:52,298 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7694 | Iter Mean Loss 9.1300
2020-11-05 21:04:52,300 - root - INFO - Evaluate: Epoch 0309 | NDCG 1.0000 | MSE 0.3508
2020-11-05 21:04:52,309 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0895 | Iter Mean Loss 10.0895
2020-11-05 21:04:52,323 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6191 | Iter Mean Loss 6.8543
2020-11-05 21:04:52,332 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9149 | Iter Mean Loss 8.8745
2020-11-05 21:04:52,340 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1587 | Iter Mean Loss 9.4456
2020-11-05 21:04:52,348 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7421 | Iter Mean Loss 9.1049
2020-11-05 21:04:52,351 - root - INFO - Evaluate: Epoch 0310 | NDCG 1.0000 | MSE 0.3505
2020-11-05 21:04:52,360 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0682 | Iter Mean Loss 10.0682
2020-11-05 21:04:52,368 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6124 | Iter Mean Loss 6.8403
2020-11-05 21:04:52,375 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8738 | Iter Mean Loss 8.8515
2020-11-05 21:04:52,384 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1297 | Iter Mean Loss 9.4210
2020-11-05 21:04:52,392 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7150 | Iter Mean Loss 9.0798
2020-11-05 21:04:52,394 - root - INFO - Evaluate: Epoch 0311 | NDCG 1.0000 | MSE 0.3501
2020-11-05 21:04:52,402 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0468 | Iter Mean Loss 10.0468
2020-11-05 21:04:52,410 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6058 | Iter Mean Loss 6.8263
2020-11-05 21:04:52,418 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8330 | Iter Mean Loss 8.8285
2020-11-05 21:04:52,425 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1007 | Iter Mean Loss 9.3966
2020-11-05 21:04:52,433 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6881 | Iter Mean Loss 9.0549
2020-11-05 21:04:52,435 - root - INFO - Evaluate: Epoch 0312 | NDCG 1.0000 | MSE 0.3498
2020-11-05 21:04:52,443 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0253 | Iter Mean Loss 10.0253
2020-11-05 21:04:52,450 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5991 | Iter Mean Loss 6.8122
2020-11-05 21:04:52,458 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7925 | Iter Mean Loss 8.8056
2020-11-05 21:04:52,465 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0717 | Iter Mean Loss 9.3721
2020-11-05 21:04:52,473 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6613 | Iter Mean Loss 9.0300
2020-11-05 21:04:52,475 - root - INFO - Evaluate: Epoch 0313 | NDCG 1.0000 | MSE 0.3494
2020-11-05 21:04:52,483 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0036 | Iter Mean Loss 10.0036
2020-11-05 21:04:52,491 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 6.7980
2020-11-05 21:04:52,500 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7522 | Iter Mean Loss 8.7827
2020-11-05 21:04:52,508 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0428 | Iter Mean Loss 9.3477
2020-11-05 21:04:52,518 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6347 | Iter Mean Loss 9.0051
2020-11-05 21:04:52,521 - root - INFO - Evaluate: Epoch 0314 | NDCG 1.0000 | MSE 0.3491
2020-11-05 21:04:52,531 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9818 | Iter Mean Loss 9.9818
2020-11-05 21:04:52,540 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5856 | Iter Mean Loss 6.7837
2020-11-05 21:04:52,550 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7122 | Iter Mean Loss 8.7599
2020-11-05 21:04:52,558 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 9.3234
2020-11-05 21:04:52,568 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6082 | Iter Mean Loss 8.9803
2020-11-05 21:04:52,570 - root - INFO - Evaluate: Epoch 0315 | NDCG 1.0000 | MSE 0.3488
2020-11-05 21:04:52,581 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9599 | Iter Mean Loss 9.9599
2020-11-05 21:04:52,589 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5788 | Iter Mean Loss 6.7693
2020-11-05 21:04:52,600 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6724 | Iter Mean Loss 8.7370
2020-11-05 21:04:52,609 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9851 | Iter Mean Loss 9.2991
2020-11-05 21:04:52,620 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5819 | Iter Mean Loss 8.9556
2020-11-05 21:04:52,623 - root - INFO - Evaluate: Epoch 0316 | NDCG 1.0000 | MSE 0.3484
2020-11-05 21:04:52,632 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9379 | Iter Mean Loss 9.9379
2020-11-05 21:04:52,642 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5719 | Iter Mean Loss 6.7549
2020-11-05 21:04:52,650 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6329 | Iter Mean Loss 8.7143
2020-11-05 21:04:52,660 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9564 | Iter Mean Loss 9.2748
2020-11-05 21:04:52,669 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5558 | Iter Mean Loss 8.9310
2020-11-05 21:04:52,673 - root - INFO - Evaluate: Epoch 0317 | NDCG 1.0000 | MSE 0.3481
2020-11-05 21:04:52,682 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9158 | Iter Mean Loss 9.9158
2020-11-05 21:04:52,692 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5651 | Iter Mean Loss 6.7404
2020-11-05 21:04:52,701 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5937 | Iter Mean Loss 8.6915
2020-11-05 21:04:52,710 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9277 | Iter Mean Loss 9.2505
2020-11-05 21:04:52,722 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5298 | Iter Mean Loss 8.9064
2020-11-05 21:04:52,725 - root - INFO - Evaluate: Epoch 0318 | NDCG 1.0000 | MSE 0.3478
2020-11-05 21:04:52,740 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8935 | Iter Mean Loss 9.8935
2020-11-05 21:04:52,754 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5581 | Iter Mean Loss 6.7258
2020-11-05 21:04:52,768 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5547 | Iter Mean Loss 8.6688
2020-11-05 21:04:52,780 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8990 | Iter Mean Loss 9.2264
2020-11-05 21:04:52,792 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5039 | Iter Mean Loss 8.8819
2020-11-05 21:04:52,795 - root - INFO - Evaluate: Epoch 0319 | NDCG 1.0000 | MSE 0.3475
2020-11-05 21:04:52,805 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8712 | Iter Mean Loss 9.8712
2020-11-05 21:04:52,816 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5512 | Iter Mean Loss 6.7112
2020-11-05 21:04:52,829 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5160 | Iter Mean Loss 8.6461
2020-11-05 21:04:52,841 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8704 | Iter Mean Loss 9.2022
2020-11-05 21:04:52,851 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4783 | Iter Mean Loss 8.8574
2020-11-05 21:04:52,855 - root - INFO - Evaluate: Epoch 0320 | NDCG 1.0000 | MSE 0.3472
2020-11-05 21:04:52,866 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8487 | Iter Mean Loss 9.8487
2020-11-05 21:04:52,877 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5442 | Iter Mean Loss 6.6965
2020-11-05 21:04:52,887 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4775 | Iter Mean Loss 8.6235
2020-11-05 21:04:52,898 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8418 | Iter Mean Loss 9.1781
2020-11-05 21:04:52,910 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4527 | Iter Mean Loss 8.8330
2020-11-05 21:04:52,913 - root - INFO - Evaluate: Epoch 0321 | NDCG 1.0000 | MSE 0.3468
2020-11-05 21:04:52,923 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8262 | Iter Mean Loss 9.8262
2020-11-05 21:04:52,934 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5372 | Iter Mean Loss 6.6817
2020-11-05 21:04:52,943 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4393 | Iter Mean Loss 8.6009
2020-11-05 21:04:52,952 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8133 | Iter Mean Loss 9.1540
2020-11-05 21:04:52,961 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4274 | Iter Mean Loss 8.8087
2020-11-05 21:04:52,964 - root - INFO - Evaluate: Epoch 0322 | NDCG 1.0000 | MSE 0.3465
2020-11-05 21:04:52,973 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8036 | Iter Mean Loss 9.8036
2020-11-05 21:04:52,981 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5302 | Iter Mean Loss 6.6669
2020-11-05 21:04:52,989 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4013 | Iter Mean Loss 8.5784
2020-11-05 21:04:52,998 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7848 | Iter Mean Loss 9.1300
2020-11-05 21:04:53,006 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4022 | Iter Mean Loss 8.7844
2020-11-05 21:04:53,008 - root - INFO - Evaluate: Epoch 0323 | NDCG 1.0000 | MSE 0.3462
2020-11-05 21:04:53,016 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7808 | Iter Mean Loss 9.7808
2020-11-05 21:04:53,025 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5231 | Iter Mean Loss 6.6520
2020-11-05 21:04:53,033 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3635 | Iter Mean Loss 8.5558
2020-11-05 21:04:53,040 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7564 | Iter Mean Loss 9.1060
2020-11-05 21:04:53,048 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 8.7602
2020-11-05 21:04:53,050 - root - INFO - Evaluate: Epoch 0324 | NDCG 1.0000 | MSE 0.3459
2020-11-05 21:04:53,059 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7580 | Iter Mean Loss 9.7580
2020-11-05 21:04:53,067 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5160 | Iter Mean Loss 6.6370
2020-11-05 21:04:53,075 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 8.5334
2020-11-05 21:04:53,082 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7281 | Iter Mean Loss 9.0820
2020-11-05 21:04:53,090 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3522 | Iter Mean Loss 8.7361
2020-11-05 21:04:53,093 - root - INFO - Evaluate: Epoch 0325 | NDCG 1.0000 | MSE 0.3456
2020-11-05 21:04:53,102 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7351 | Iter Mean Loss 9.7351
2020-11-05 21:04:53,111 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5089 | Iter Mean Loss 6.6220
2020-11-05 21:04:53,119 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2888 | Iter Mean Loss 8.5109
2020-11-05 21:04:53,127 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6998 | Iter Mean Loss 9.0581
2020-11-05 21:04:53,136 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3274 | Iter Mean Loss 8.7120
2020-11-05 21:04:53,138 - root - INFO - Evaluate: Epoch 0326 | NDCG 1.0000 | MSE 0.3453
2020-11-05 21:04:53,147 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7120 | Iter Mean Loss 9.7120
2020-11-05 21:04:53,156 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5018 | Iter Mean Loss 6.6069
2020-11-05 21:04:53,164 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2517 | Iter Mean Loss 8.4885
2020-11-05 21:04:53,173 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6715 | Iter Mean Loss 9.0343
2020-11-05 21:04:53,181 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3028 | Iter Mean Loss 8.6880
2020-11-05 21:04:53,185 - root - INFO - Evaluate: Epoch 0327 | NDCG 1.0000 | MSE 0.3450
2020-11-05 21:04:53,194 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6890 | Iter Mean Loss 9.6890
2020-11-05 21:04:53,203 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4946 | Iter Mean Loss 6.5918
2020-11-05 21:04:53,210 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2149 | Iter Mean Loss 8.4662
2020-11-05 21:04:53,218 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6433 | Iter Mean Loss 9.0104
2020-11-05 21:04:53,225 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2784 | Iter Mean Loss 8.6640
2020-11-05 21:04:53,228 - root - INFO - Evaluate: Epoch 0328 | NDCG 1.0000 | MSE 0.3447
2020-11-05 21:04:53,236 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6658 | Iter Mean Loss 9.6658
2020-11-05 21:04:53,243 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4874 | Iter Mean Loss 6.5766
2020-11-05 21:04:53,251 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1783 | Iter Mean Loss 8.4438
2020-11-05 21:04:53,259 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6152 | Iter Mean Loss 8.9867
2020-11-05 21:04:53,266 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2541 | Iter Mean Loss 8.6402
2020-11-05 21:04:53,268 - root - INFO - Evaluate: Epoch 0329 | NDCG 1.0000 | MSE 0.3444
2020-11-05 21:04:53,277 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6425 | Iter Mean Loss 9.6425
2020-11-05 21:04:53,285 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4802 | Iter Mean Loss 6.5614
2020-11-05 21:04:53,293 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1420 | Iter Mean Loss 8.4216
2020-11-05 21:04:53,300 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5871 | Iter Mean Loss 8.9629
2020-11-05 21:04:53,309 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2300 | Iter Mean Loss 8.6164
2020-11-05 21:04:53,313 - root - INFO - Evaluate: Epoch 0330 | NDCG 1.0000 | MSE 0.3441
2020-11-05 21:04:53,328 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6192 | Iter Mean Loss 9.6192
2020-11-05 21:04:53,337 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4730 | Iter Mean Loss 6.5461
2020-11-05 21:04:53,348 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1058 | Iter Mean Loss 8.3993
2020-11-05 21:04:53,357 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5591 | Iter Mean Loss 8.9393
2020-11-05 21:04:53,366 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2060 | Iter Mean Loss 8.5926
2020-11-05 21:04:53,369 - root - INFO - Evaluate: Epoch 0331 | NDCG 1.0000 | MSE 0.3438
2020-11-05 21:04:53,378 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.5958
2020-11-05 21:04:53,388 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4657 | Iter Mean Loss 6.5308
2020-11-05 21:04:53,397 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0699 | Iter Mean Loss 8.3772
2020-11-05 21:04:53,408 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5311 | Iter Mean Loss 8.9156
2020-11-05 21:04:53,422 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1822 | Iter Mean Loss 8.5689
2020-11-05 21:04:53,425 - root - INFO - Evaluate: Epoch 0332 | NDCG 1.0000 | MSE 0.3435
2020-11-05 21:04:53,439 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5724 | Iter Mean Loss 9.5724
2020-11-05 21:04:53,452 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4584 | Iter Mean Loss 6.5154
2020-11-05 21:04:53,465 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0343 | Iter Mean Loss 8.3550
2020-11-05 21:04:53,478 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5032 | Iter Mean Loss 8.8921
2020-11-05 21:04:53,488 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1585 | Iter Mean Loss 8.5454
2020-11-05 21:04:53,493 - root - INFO - Evaluate: Epoch 0333 | NDCG 1.0000 | MSE 0.3433
2020-11-05 21:04:53,506 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5489 | Iter Mean Loss 9.5489
2020-11-05 21:04:53,517 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4511 | Iter Mean Loss 6.5000
2020-11-05 21:04:53,527 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9988 | Iter Mean Loss 8.3329
2020-11-05 21:04:53,539 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4754 | Iter Mean Loss 8.8685
2020-11-05 21:04:53,550 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1350 | Iter Mean Loss 8.5218
2020-11-05 21:04:53,552 - root - INFO - Evaluate: Epoch 0334 | NDCG 1.0000 | MSE 0.3430
2020-11-05 21:04:53,562 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5253 | Iter Mean Loss 9.5253
2020-11-05 21:04:53,574 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4438 | Iter Mean Loss 6.4846
2020-11-05 21:04:53,587 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 8.3109
2020-11-05 21:04:53,599 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4476 | Iter Mean Loss 8.8451
2020-11-05 21:04:53,612 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1116 | Iter Mean Loss 8.4984
2020-11-05 21:04:53,615 - root - INFO - Evaluate: Epoch 0335 | NDCG 1.0000 | MSE 0.3427
2020-11-05 21:04:53,630 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5017 | Iter Mean Loss 9.5017
2020-11-05 21:04:53,641 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4365 | Iter Mean Loss 6.4691
2020-11-05 21:04:53,650 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9286 | Iter Mean Loss 8.2889
2020-11-05 21:04:53,660 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4199 | Iter Mean Loss 8.8217
2020-11-05 21:04:53,669 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0884 | Iter Mean Loss 8.4750
2020-11-05 21:04:53,671 - root - INFO - Evaluate: Epoch 0336 | NDCG 1.0000 | MSE 0.3424
2020-11-05 21:04:53,681 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4780 | Iter Mean Loss 9.4780
2020-11-05 21:04:53,689 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4292 | Iter Mean Loss 6.4536
2020-11-05 21:04:53,699 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8938 | Iter Mean Loss 8.2670
2020-11-05 21:04:53,707 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3922 | Iter Mean Loss 8.7983
2020-11-05 21:04:53,717 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0654 | Iter Mean Loss 8.4517
2020-11-05 21:04:53,719 - root - INFO - Evaluate: Epoch 0337 | NDCG 1.0000 | MSE 0.3421
2020-11-05 21:04:53,728 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4543 | Iter Mean Loss 9.4543
2020-11-05 21:04:53,738 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4218 | Iter Mean Loss 6.4381
2020-11-05 21:04:53,748 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8592 | Iter Mean Loss 8.2451
2020-11-05 21:04:53,758 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3647 | Iter Mean Loss 8.7750
2020-11-05 21:04:53,767 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0425 | Iter Mean Loss 8.4285
2020-11-05 21:04:53,771 - root - INFO - Evaluate: Epoch 0338 | NDCG 1.0000 | MSE 0.3419
2020-11-05 21:04:53,780 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4306 | Iter Mean Loss 9.4306
2020-11-05 21:04:53,790 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.4225
2020-11-05 21:04:53,798 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8248 | Iter Mean Loss 8.2233
2020-11-05 21:04:53,808 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3371 | Iter Mean Loss 8.7518
2020-11-05 21:04:53,818 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0198 | Iter Mean Loss 8.4054
2020-11-05 21:04:53,821 - root - INFO - Evaluate: Epoch 0339 | NDCG 1.0000 | MSE 0.3416
2020-11-05 21:04:53,830 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 9.4068
2020-11-05 21:04:53,839 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4071 | Iter Mean Loss 6.4070
2020-11-05 21:04:53,847 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7907 | Iter Mean Loss 8.2015
2020-11-05 21:04:53,855 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3097 | Iter Mean Loss 8.7286
2020-11-05 21:04:53,863 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9972 | Iter Mean Loss 8.3823
2020-11-05 21:04:53,865 - root - INFO - Evaluate: Epoch 0340 | NDCG 1.0000 | MSE 0.3413
2020-11-05 21:04:53,873 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3830 | Iter Mean Loss 9.3830
2020-11-05 21:04:53,881 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3998 | Iter Mean Loss 6.3914
2020-11-05 21:04:53,889 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7568 | Iter Mean Loss 8.1798
2020-11-05 21:04:53,896 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2824 | Iter Mean Loss 8.7055
2020-11-05 21:04:53,904 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9748 | Iter Mean Loss 8.3593
2020-11-05 21:04:53,906 - root - INFO - Evaluate: Epoch 0341 | NDCG 1.0000 | MSE 0.3411
2020-11-05 21:04:53,915 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3592 | Iter Mean Loss 9.3592
2020-11-05 21:04:53,923 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3924 | Iter Mean Loss 6.3758
2020-11-05 21:04:53,931 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7231 | Iter Mean Loss 8.1582
2020-11-05 21:04:53,939 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2551 | Iter Mean Loss 8.6824
2020-11-05 21:04:53,947 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9526 | Iter Mean Loss 8.3365
2020-11-05 21:04:53,950 - root - INFO - Evaluate: Epoch 0342 | NDCG 1.0000 | MSE 0.3408
2020-11-05 21:04:53,959 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3354 | Iter Mean Loss 9.3354
2020-11-05 21:04:53,968 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3850 | Iter Mean Loss 6.3602
2020-11-05 21:04:53,977 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6896 | Iter Mean Loss 8.1367
2020-11-05 21:04:53,985 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2279 | Iter Mean Loss 8.6595
2020-11-05 21:04:53,994 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9305 | Iter Mean Loss 8.3137
2020-11-05 21:04:53,996 - root - INFO - Evaluate: Epoch 0343 | NDCG 1.0000 | MSE 0.3406
2020-11-05 21:04:54,005 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3115 | Iter Mean Loss 9.3115
2020-11-05 21:04:54,014 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3777 | Iter Mean Loss 6.3446
2020-11-05 21:04:54,023 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6563 | Iter Mean Loss 8.1152
2020-11-05 21:04:54,031 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2007 | Iter Mean Loss 8.6366
2020-11-05 21:04:54,040 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 8.2910
2020-11-05 21:04:54,043 - root - INFO - Evaluate: Epoch 0344 | NDCG 1.0000 | MSE 0.3403
2020-11-05 21:04:54,051 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2877 | Iter Mean Loss 9.2877
2020-11-05 21:04:54,059 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3703 | Iter Mean Loss 6.3290
2020-11-05 21:04:54,067 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6232 | Iter Mean Loss 8.0937
2020-11-05 21:04:54,074 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1737 | Iter Mean Loss 8.6137
2020-11-05 21:04:54,082 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 8.2683
2020-11-05 21:04:54,084 - root - INFO - Evaluate: Epoch 0345 | NDCG 1.0000 | MSE 0.3401
2020-11-05 21:04:54,093 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2638 | Iter Mean Loss 9.2638
2020-11-05 21:04:54,100 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3629 | Iter Mean Loss 6.3134
2020-11-05 21:04:54,109 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5904 | Iter Mean Loss 8.0724
2020-11-05 21:04:54,117 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1467 | Iter Mean Loss 8.5910
2020-11-05 21:04:54,125 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8652 | Iter Mean Loss 8.2458
2020-11-05 21:04:54,127 - root - INFO - Evaluate: Epoch 0346 | NDCG 1.0000 | MSE 0.3398
2020-11-05 21:04:54,135 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2400 | Iter Mean Loss 9.2400
2020-11-05 21:04:54,144 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.2978
2020-11-05 21:04:54,152 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5577 | Iter Mean Loss 8.0511
2020-11-05 21:04:54,160 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1199 | Iter Mean Loss 8.5683
2020-11-05 21:04:54,169 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8438 | Iter Mean Loss 8.2234
2020-11-05 21:04:54,171 - root - INFO - Evaluate: Epoch 0347 | NDCG 1.0000 | MSE 0.3396
2020-11-05 21:04:54,180 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2162 | Iter Mean Loss 9.2162
2020-11-05 21:04:54,189 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3482 | Iter Mean Loss 6.2822
2020-11-05 21:04:54,197 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5253 | Iter Mean Loss 8.0299
2020-11-05 21:04:54,206 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0931 | Iter Mean Loss 8.5457
2020-11-05 21:04:54,214 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8226 | Iter Mean Loss 8.2011
2020-11-05 21:04:54,217 - root - INFO - Evaluate: Epoch 0348 | NDCG 1.0000 | MSE 0.3393
2020-11-05 21:04:54,225 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1924 | Iter Mean Loss 9.1924
2020-11-05 21:04:54,235 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3409 | Iter Mean Loss 6.2666
2020-11-05 21:04:54,242 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4931 | Iter Mean Loss 8.0088
2020-11-05 21:04:54,250 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 8.5232
2020-11-05 21:04:54,258 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8015 | Iter Mean Loss 8.1788
2020-11-05 21:04:54,260 - root - INFO - Evaluate: Epoch 0349 | NDCG 1.0000 | MSE 0.3391
2020-11-05 21:04:54,268 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1686 | Iter Mean Loss 9.1686
2020-11-05 21:04:54,277 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3336 | Iter Mean Loss 6.2511
2020-11-05 21:04:54,287 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4611 | Iter Mean Loss 7.9878
2020-11-05 21:04:54,297 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0398 | Iter Mean Loss 8.5008
2020-11-05 21:04:54,307 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7806 | Iter Mean Loss 8.1567
2020-11-05 21:04:54,309 - root - INFO - Evaluate: Epoch 0350 | NDCG 1.0000 | MSE 0.3389
2020-11-05 21:04:54,325 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1448 | Iter Mean Loss 9.1448
2020-11-05 21:04:54,338 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3263 | Iter Mean Loss 6.2355
2020-11-05 21:04:54,347 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4293 | Iter Mean Loss 7.9668
2020-11-05 21:04:54,357 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0133 | Iter Mean Loss 8.4784
2020-11-05 21:04:54,366 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 8.1347
2020-11-05 21:04:54,370 - root - INFO - Evaluate: Epoch 0351 | NDCG 1.0000 | MSE 0.3386
2020-11-05 21:04:54,379 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1211 | Iter Mean Loss 9.1211
2020-11-05 21:04:54,389 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3190 | Iter Mean Loss 6.2200
2020-11-05 21:04:54,397 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3978 | Iter Mean Loss 7.9460
2020-11-05 21:04:54,407 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9869 | Iter Mean Loss 8.4562
2020-11-05 21:04:54,416 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7392 | Iter Mean Loss 8.1128
2020-11-05 21:04:54,418 - root - INFO - Evaluate: Epoch 0352 | NDCG 1.0000 | MSE 0.3384
2020-11-05 21:04:54,429 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0974 | Iter Mean Loss 9.0974
2020-11-05 21:04:54,438 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3117 | Iter Mean Loss 6.2046
2020-11-05 21:04:54,448 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3664 | Iter Mean Loss 7.9252
2020-11-05 21:04:54,456 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9606 | Iter Mean Loss 8.4340
2020-11-05 21:04:54,466 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7188 | Iter Mean Loss 8.0910
2020-11-05 21:04:54,468 - root - INFO - Evaluate: Epoch 0353 | NDCG 1.0000 | MSE 0.3382
2020-11-05 21:04:54,478 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0738 | Iter Mean Loss 9.0738
2020-11-05 21:04:54,487 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3045 | Iter Mean Loss 6.1891
2020-11-05 21:04:54,497 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3353 | Iter Mean Loss 7.9045
2020-11-05 21:04:54,505 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9343 | Iter Mean Loss 8.4120
2020-11-05 21:04:54,515 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6986 | Iter Mean Loss 8.0693
2020-11-05 21:04:54,517 - root - INFO - Evaluate: Epoch 0354 | NDCG 1.0000 | MSE 0.3380
2020-11-05 21:04:54,527 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0502 | Iter Mean Loss 9.0502
2020-11-05 21:04:54,535 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2973 | Iter Mean Loss 6.1737
2020-11-05 21:04:54,544 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 7.8839
2020-11-05 21:04:54,552 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9082 | Iter Mean Loss 8.3900
2020-11-05 21:04:54,561 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6785 | Iter Mean Loss 8.0477
2020-11-05 21:04:54,564 - root - INFO - Evaluate: Epoch 0355 | NDCG 1.0000 | MSE 0.3377
2020-11-05 21:04:54,572 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0267 | Iter Mean Loss 9.0267
2020-11-05 21:04:54,582 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2901 | Iter Mean Loss 6.1584
2020-11-05 21:04:54,590 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2736 | Iter Mean Loss 7.8635
2020-11-05 21:04:54,599 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8822 | Iter Mean Loss 8.3681
2020-11-05 21:04:54,607 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6586 | Iter Mean Loss 8.0262
2020-11-05 21:04:54,609 - root - INFO - Evaluate: Epoch 0356 | NDCG 1.0000 | MSE 0.3375
2020-11-05 21:04:54,618 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0032 | Iter Mean Loss 9.0032
2020-11-05 21:04:54,627 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2829 | Iter Mean Loss 6.1431
2020-11-05 21:04:54,635 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2431 | Iter Mean Loss 7.8431
2020-11-05 21:04:54,643 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8563 | Iter Mean Loss 8.3464
2020-11-05 21:04:54,652 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6389 | Iter Mean Loss 8.0049
2020-11-05 21:04:54,654 - root - INFO - Evaluate: Epoch 0357 | NDCG 1.0000 | MSE 0.3373
2020-11-05 21:04:54,663 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9799 | Iter Mean Loss 8.9799
2020-11-05 21:04:54,670 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2758 | Iter Mean Loss 6.1278
2020-11-05 21:04:54,678 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2128 | Iter Mean Loss 7.8228
2020-11-05 21:04:54,686 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8306 | Iter Mean Loss 8.3247
2020-11-05 21:04:54,693 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6193 | Iter Mean Loss 7.9837
2020-11-05 21:04:54,696 - root - INFO - Evaluate: Epoch 0358 | NDCG 1.0000 | MSE 0.3371
2020-11-05 21:04:54,705 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9565 | Iter Mean Loss 8.9565
2020-11-05 21:04:54,713 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2687 | Iter Mean Loss 6.1126
2020-11-05 21:04:54,721 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1827 | Iter Mean Loss 7.8026
2020-11-05 21:04:54,728 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8049 | Iter Mean Loss 8.3032
2020-11-05 21:04:54,736 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5999 | Iter Mean Loss 7.9625
2020-11-05 21:04:54,738 - root - INFO - Evaluate: Epoch 0359 | NDCG 1.0000 | MSE 0.3369
2020-11-05 21:04:54,746 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9333 | Iter Mean Loss 8.9333
2020-11-05 21:04:54,754 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2616 | Iter Mean Loss 6.0975
2020-11-05 21:04:54,762 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1528 | Iter Mean Loss 7.7826
2020-11-05 21:04:54,771 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7793 | Iter Mean Loss 8.2818
2020-11-05 21:04:54,779 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5807 | Iter Mean Loss 7.9416
2020-11-05 21:04:54,782 - root - INFO - Evaluate: Epoch 0360 | NDCG 1.0000 | MSE 0.3367
2020-11-05 21:04:54,791 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9102 | Iter Mean Loss 8.9102
2020-11-05 21:04:54,800 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 6.0824
2020-11-05 21:04:54,807 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1232 | Iter Mean Loss 7.7626
2020-11-05 21:04:54,816 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7539 | Iter Mean Loss 8.2604
2020-11-05 21:04:54,824 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5616 | Iter Mean Loss 7.9207
2020-11-05 21:04:54,826 - root - INFO - Evaluate: Epoch 0361 | NDCG 1.0000 | MSE 0.3365
2020-11-05 21:04:54,836 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8871 | Iter Mean Loss 8.8871
2020-11-05 21:04:54,843 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2475 | Iter Mean Loss 6.0673
2020-11-05 21:04:54,852 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0937 | Iter Mean Loss 7.7428
2020-11-05 21:04:54,860 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7285 | Iter Mean Loss 8.2392
2020-11-05 21:04:54,868 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5428 | Iter Mean Loss 7.8999
2020-11-05 21:04:54,871 - root - INFO - Evaluate: Epoch 0362 | NDCG 1.0000 | MSE 0.3363
2020-11-05 21:04:54,879 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8642 | Iter Mean Loss 8.8642
2020-11-05 21:04:54,887 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2406 | Iter Mean Loss 6.0524
2020-11-05 21:04:54,894 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0645 | Iter Mean Loss 7.7231
2020-11-05 21:04:54,902 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7033 | Iter Mean Loss 8.2181
2020-11-05 21:04:54,909 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5241 | Iter Mean Loss 7.8793
2020-11-05 21:04:54,911 - root - INFO - Evaluate: Epoch 0363 | NDCG 1.0000 | MSE 0.3361
2020-11-05 21:04:54,919 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8413 | Iter Mean Loss 8.8413
2020-11-05 21:04:54,927 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2337 | Iter Mean Loss 6.0375
2020-11-05 21:04:54,934 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0355 | Iter Mean Loss 7.7035
2020-11-05 21:04:54,942 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6783 | Iter Mean Loss 8.1972
2020-11-05 21:04:54,949 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5055 | Iter Mean Loss 7.8588
2020-11-05 21:04:54,951 - root - INFO - Evaluate: Epoch 0364 | NDCG 1.0000 | MSE 0.3359
2020-11-05 21:04:54,960 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8186 | Iter Mean Loss 8.8186
2020-11-05 21:04:54,968 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2268 | Iter Mean Loss 6.0227
2020-11-05 21:04:54,976 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0066 | Iter Mean Loss 7.6840
2020-11-05 21:04:54,985 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6533 | Iter Mean Loss 8.1763
2020-11-05 21:04:54,993 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4871 | Iter Mean Loss 7.8385
2020-11-05 21:04:54,995 - root - INFO - Evaluate: Epoch 0365 | NDCG 1.0000 | MSE 0.3357
2020-11-05 21:04:55,004 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7960 | Iter Mean Loss 8.7960
2020-11-05 21:04:55,012 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2199 | Iter Mean Loss 6.0079
2020-11-05 21:04:55,022 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9780 | Iter Mean Loss 7.6646
2020-11-05 21:04:55,032 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6285 | Iter Mean Loss 8.1556
2020-11-05 21:04:55,043 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4689 | Iter Mean Loss 7.8183
2020-11-05 21:04:55,046 - root - INFO - Evaluate: Epoch 0366 | NDCG 1.0000 | MSE 0.3355
2020-11-05 21:04:55,057 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7734 | Iter Mean Loss 8.7734
2020-11-05 21:04:55,066 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2131 | Iter Mean Loss 5.9933
2020-11-05 21:04:55,076 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9496 | Iter Mean Loss 7.6454
2020-11-05 21:04:55,085 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6037 | Iter Mean Loss 8.1350
2020-11-05 21:04:55,095 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4509 | Iter Mean Loss 7.7982
2020-11-05 21:04:55,097 - root - INFO - Evaluate: Epoch 0367 | NDCG 1.0000 | MSE 0.3353
2020-11-05 21:04:55,107 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7510 | Iter Mean Loss 8.7510
2020-11-05 21:04:55,116 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2064 | Iter Mean Loss 5.9787
2020-11-05 21:04:55,126 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9214 | Iter Mean Loss 7.6263
2020-11-05 21:04:55,135 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5792 | Iter Mean Loss 8.1145
2020-11-05 21:04:55,146 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4330 | Iter Mean Loss 7.7782
2020-11-05 21:04:55,148 - root - INFO - Evaluate: Epoch 0368 | NDCG 1.0000 | MSE 0.3351
2020-11-05 21:04:55,158 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7288 | Iter Mean Loss 8.7288
2020-11-05 21:04:55,170 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1997 | Iter Mean Loss 5.9642
2020-11-05 21:04:55,180 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8934 | Iter Mean Loss 7.6073
2020-11-05 21:04:55,190 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5547 | Iter Mean Loss 8.0941
2020-11-05 21:04:55,200 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4153 | Iter Mean Loss 7.7584
2020-11-05 21:04:55,202 - root - INFO - Evaluate: Epoch 0369 | NDCG 1.0000 | MSE 0.3350
2020-11-05 21:04:55,214 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7066 | Iter Mean Loss 8.7066
2020-11-05 21:04:55,223 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1930 | Iter Mean Loss 5.9498
2020-11-05 21:04:55,232 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8657 | Iter Mean Loss 7.5884
2020-11-05 21:04:55,241 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5304 | Iter Mean Loss 8.0739
2020-11-05 21:04:55,251 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3977 | Iter Mean Loss 7.7387
2020-11-05 21:04:55,254 - root - INFO - Evaluate: Epoch 0370 | NDCG 1.0000 | MSE 0.3348
2020-11-05 21:04:55,264 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6846 | Iter Mean Loss 8.6846
2020-11-05 21:04:55,273 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1864 | Iter Mean Loss 5.9355
2020-11-05 21:04:55,282 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8381 | Iter Mean Loss 7.5697
2020-11-05 21:04:55,291 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5062 | Iter Mean Loss 8.0538
2020-11-05 21:04:55,299 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3803 | Iter Mean Loss 7.7191
2020-11-05 21:04:55,302 - root - INFO - Evaluate: Epoch 0371 | NDCG 1.0000 | MSE 0.3346
2020-11-05 21:04:55,311 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6628 | Iter Mean Loss 8.6628
2020-11-05 21:04:55,325 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1799 | Iter Mean Loss 5.9213
2020-11-05 21:04:55,333 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 7.5511
2020-11-05 21:04:55,341 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 8.0339
2020-11-05 21:04:55,349 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3631 | Iter Mean Loss 7.6997
2020-11-05 21:04:55,352 - root - INFO - Evaluate: Epoch 0372 | NDCG 1.0000 | MSE 0.3344
2020-11-05 21:04:55,361 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6410 | Iter Mean Loss 8.6410
2020-11-05 21:04:55,368 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.9072
2020-11-05 21:04:55,376 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7835 | Iter Mean Loss 7.5326
2020-11-05 21:04:55,385 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4582 | Iter Mean Loss 8.0140
2020-11-05 21:04:55,393 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3460 | Iter Mean Loss 7.6804
2020-11-05 21:04:55,395 - root - INFO - Evaluate: Epoch 0373 | NDCG 1.0000 | MSE 0.3343
2020-11-05 21:04:55,405 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6194 | Iter Mean Loss 8.6194
2020-11-05 21:04:55,414 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1669 | Iter Mean Loss 5.8932
2020-11-05 21:04:55,423 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7566 | Iter Mean Loss 7.5143
2020-11-05 21:04:55,431 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4344 | Iter Mean Loss 7.9943
2020-11-05 21:04:55,440 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3291 | Iter Mean Loss 7.6613
2020-11-05 21:04:55,442 - root - INFO - Evaluate: Epoch 0374 | NDCG 1.0000 | MSE 0.3341
2020-11-05 21:04:55,451 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5980 | Iter Mean Loss 8.5980
2020-11-05 21:04:55,459 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1605 | Iter Mean Loss 5.8792
2020-11-05 21:04:55,468 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7298 | Iter Mean Loss 7.4961
2020-11-05 21:04:55,476 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4108 | Iter Mean Loss 7.9748
2020-11-05 21:04:55,483 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3124 | Iter Mean Loss 7.6423
2020-11-05 21:04:55,486 - root - INFO - Evaluate: Epoch 0375 | NDCG 1.0000 | MSE 0.3339
2020-11-05 21:04:55,494 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5767
2020-11-05 21:04:55,503 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 5.8654
2020-11-05 21:04:55,511 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7033 | Iter Mean Loss 7.4780
2020-11-05 21:04:55,518 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3873 | Iter Mean Loss 7.9553
2020-11-05 21:04:55,527 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2958 | Iter Mean Loss 7.6234
2020-11-05 21:04:55,530 - root - INFO - Evaluate: Epoch 0376 | NDCG 1.0000 | MSE 0.3338
2020-11-05 21:04:55,538 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5555 | Iter Mean Loss 8.5555
2020-11-05 21:04:55,546 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1479 | Iter Mean Loss 5.8517
2020-11-05 21:04:55,554 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6769 | Iter Mean Loss 7.4601
2020-11-05 21:04:55,561 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3639 | Iter Mean Loss 7.9360
2020-11-05 21:04:55,569 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2793 | Iter Mean Loss 7.6047
2020-11-05 21:04:55,572 - root - INFO - Evaluate: Epoch 0377 | NDCG 1.0000 | MSE 0.3336
2020-11-05 21:04:55,581 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5346 | Iter Mean Loss 8.5346
2020-11-05 21:04:55,590 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1416 | Iter Mean Loss 5.8381
2020-11-05 21:04:55,598 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6507 | Iter Mean Loss 7.4423
2020-11-05 21:04:55,607 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3407 | Iter Mean Loss 7.9169
2020-11-05 21:04:55,615 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2630 | Iter Mean Loss 7.5861
2020-11-05 21:04:55,617 - root - INFO - Evaluate: Epoch 0378 | NDCG 1.0000 | MSE 0.3335
2020-11-05 21:04:55,627 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5137 | Iter Mean Loss 8.5137
2020-11-05 21:04:55,635 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1355 | Iter Mean Loss 5.8246
2020-11-05 21:04:55,643 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6248 | Iter Mean Loss 7.4246
2020-11-05 21:04:55,651 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3176 | Iter Mean Loss 7.8979
2020-11-05 21:04:55,660 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2468 | Iter Mean Loss 7.5677
2020-11-05 21:04:55,662 - root - INFO - Evaluate: Epoch 0379 | NDCG 1.0000 | MSE 0.3333
2020-11-05 21:04:55,670 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4930 | Iter Mean Loss 8.4930
2020-11-05 21:04:55,680 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1293 | Iter Mean Loss 5.8112
2020-11-05 21:04:55,688 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5990 | Iter Mean Loss 7.4071
2020-11-05 21:04:55,697 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2946 | Iter Mean Loss 7.8790
2020-11-05 21:04:55,706 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2308 | Iter Mean Loss 7.5494
2020-11-05 21:04:55,709 - root - INFO - Evaluate: Epoch 0380 | NDCG 1.0000 | MSE 0.3332
2020-11-05 21:04:55,718 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4725 | Iter Mean Loss 8.4725
2020-11-05 21:04:55,726 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1233 | Iter Mean Loss 5.7979
2020-11-05 21:04:55,734 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 7.3897
2020-11-05 21:04:55,742 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2718 | Iter Mean Loss 7.8602
2020-11-05 21:04:55,751 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2150 | Iter Mean Loss 7.5312
2020-11-05 21:04:55,753 - root - INFO - Evaluate: Epoch 0381 | NDCG 1.0000 | MSE 0.3330
2020-11-05 21:04:55,762 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 21:04:55,770 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1172 | Iter Mean Loss 5.7847
2020-11-05 21:04:55,778 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5480 | Iter Mean Loss 7.3725
2020-11-05 21:04:55,785 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2491 | Iter Mean Loss 7.8416
2020-11-05 21:04:55,794 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 7.5132
2020-11-05 21:04:55,797 - root - INFO - Evaluate: Epoch 0382 | NDCG 1.0000 | MSE 0.3329
2020-11-05 21:04:55,805 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4320 | Iter Mean Loss 8.4320
2020-11-05 21:04:55,814 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1113 | Iter Mean Loss 5.7716
2020-11-05 21:04:55,822 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5228 | Iter Mean Loss 7.3554
2020-11-05 21:04:55,830 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2266 | Iter Mean Loss 7.8232
2020-11-05 21:04:55,839 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1836 | Iter Mean Loss 7.4953
2020-11-05 21:04:55,841 - root - INFO - Evaluate: Epoch 0383 | NDCG 1.0000 | MSE 0.3327
2020-11-05 21:04:55,850 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4119 | Iter Mean Loss 8.4119
2020-11-05 21:04:55,858 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1054 | Iter Mean Loss 5.7587
2020-11-05 21:04:55,867 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4978 | Iter Mean Loss 7.3384
2020-11-05 21:04:55,874 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2042 | Iter Mean Loss 7.8048
2020-11-05 21:04:55,883 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1682 | Iter Mean Loss 7.4775
2020-11-05 21:04:55,886 - root - INFO - Evaluate: Epoch 0384 | NDCG 1.0000 | MSE 0.3326
2020-11-05 21:04:55,895 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3921 | Iter Mean Loss 8.3921
2020-11-05 21:04:55,903 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0996 | Iter Mean Loss 5.7458
2020-11-05 21:04:55,911 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4730 | Iter Mean Loss 7.3215
2020-11-05 21:04:55,918 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1820 | Iter Mean Loss 7.7867
2020-11-05 21:04:55,926 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1529 | Iter Mean Loss 7.4599
2020-11-05 21:04:55,929 - root - INFO - Evaluate: Epoch 0385 | NDCG 1.0000 | MSE 0.3324
2020-11-05 21:04:55,938 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3724 | Iter Mean Loss 8.3724
2020-11-05 21:04:55,946 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0938 | Iter Mean Loss 5.7331
2020-11-05 21:04:55,953 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4483 | Iter Mean Loss 7.3048
2020-11-05 21:04:55,962 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1599 | Iter Mean Loss 7.7686
2020-11-05 21:04:55,970 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1377 | Iter Mean Loss 7.4424
2020-11-05 21:04:55,973 - root - INFO - Evaluate: Epoch 0386 | NDCG 1.0000 | MSE 0.3323
2020-11-05 21:04:55,982 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3528 | Iter Mean Loss 8.3528
2020-11-05 21:04:55,990 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0880 | Iter Mean Loss 5.7204
2020-11-05 21:04:55,999 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4239 | Iter Mean Loss 7.2883
2020-11-05 21:04:56,007 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1379 | Iter Mean Loss 7.7507
2020-11-05 21:04:56,017 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1227 | Iter Mean Loss 7.4251
2020-11-05 21:04:56,019 - root - INFO - Evaluate: Epoch 0387 | NDCG 1.0000 | MSE 0.3322
2020-11-05 21:04:56,029 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.3335
2020-11-05 21:04:56,039 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0824 | Iter Mean Loss 5.7079
2020-11-05 21:04:56,047 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3996 | Iter Mean Loss 7.2718
2020-11-05 21:04:56,060 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1161 | Iter Mean Loss 7.7329
2020-11-05 21:04:56,075 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1077 | Iter Mean Loss 7.4079
2020-11-05 21:04:56,079 - root - INFO - Evaluate: Epoch 0388 | NDCG 1.0000 | MSE 0.3320
2020-11-05 21:04:56,091 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3143 | Iter Mean Loss 8.3143
2020-11-05 21:04:56,103 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0768 | Iter Mean Loss 5.6955
2020-11-05 21:04:56,113 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3755 | Iter Mean Loss 7.2555
2020-11-05 21:04:56,122 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0945 | Iter Mean Loss 7.7153
2020-11-05 21:04:56,130 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0929 | Iter Mean Loss 7.3908
2020-11-05 21:04:56,133 - root - INFO - Evaluate: Epoch 0389 | NDCG 1.0000 | MSE 0.3319
2020-11-05 21:04:56,143 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2953 | Iter Mean Loss 8.2953
2020-11-05 21:04:56,152 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0712 | Iter Mean Loss 5.6832
2020-11-05 21:04:56,162 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3516 | Iter Mean Loss 7.2393
2020-11-05 21:04:56,173 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0729 | Iter Mean Loss 7.6977
2020-11-05 21:04:56,184 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0783 | Iter Mean Loss 7.3738
2020-11-05 21:04:56,187 - root - INFO - Evaluate: Epoch 0390 | NDCG 1.0000 | MSE 0.3318
2020-11-05 21:04:56,198 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2764 | Iter Mean Loss 8.2764
2020-11-05 21:04:56,209 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0657 | Iter Mean Loss 5.6711
2020-11-05 21:04:56,218 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3278 | Iter Mean Loss 7.2233
2020-11-05 21:04:56,229 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0516 | Iter Mean Loss 7.6804
2020-11-05 21:04:56,240 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0637 | Iter Mean Loss 7.3570
2020-11-05 21:04:56,243 - root - INFO - Evaluate: Epoch 0391 | NDCG 1.0000 | MSE 0.3317
2020-11-05 21:04:56,255 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2577 | Iter Mean Loss 8.2577
2020-11-05 21:04:56,266 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0603 | Iter Mean Loss 5.6590
2020-11-05 21:04:56,276 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3042 | Iter Mean Loss 7.2074
2020-11-05 21:04:56,286 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0303 | Iter Mean Loss 7.6631
2020-11-05 21:04:56,295 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0493 | Iter Mean Loss 7.3404
2020-11-05 21:04:56,297 - root - INFO - Evaluate: Epoch 0392 | NDCG 1.0000 | MSE 0.3315
2020-11-05 21:04:56,307 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2392 | Iter Mean Loss 8.2392
2020-11-05 21:04:56,318 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0549 | Iter Mean Loss 5.6470
2020-11-05 21:04:56,330 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2808 | Iter Mean Loss 7.1916
2020-11-05 21:04:56,337 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0092 | Iter Mean Loss 7.6460
2020-11-05 21:04:56,345 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0350 | Iter Mean Loss 7.3238
2020-11-05 21:04:56,347 - root - INFO - Evaluate: Epoch 0393 | NDCG 1.0000 | MSE 0.3314
2020-11-05 21:04:56,355 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2208 | Iter Mean Loss 8.2208
2020-11-05 21:04:56,362 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0495 | Iter Mean Loss 5.6352
2020-11-05 21:04:56,370 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2576 | Iter Mean Loss 7.1760
2020-11-05 21:04:56,378 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9883 | Iter Mean Loss 7.6291
2020-11-05 21:04:56,386 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0208 | Iter Mean Loss 7.3074
2020-11-05 21:04:56,388 - root - INFO - Evaluate: Epoch 0394 | NDCG 1.0000 | MSE 0.3313
2020-11-05 21:04:56,396 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2026 | Iter Mean Loss 8.2026
2020-11-05 21:04:56,404 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0443 | Iter Mean Loss 5.6234
2020-11-05 21:04:56,413 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2345 | Iter Mean Loss 7.1605
2020-11-05 21:04:56,421 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9675 | Iter Mean Loss 7.6122
2020-11-05 21:04:56,430 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0067 | Iter Mean Loss 7.2911
2020-11-05 21:04:56,432 - root - INFO - Evaluate: Epoch 0395 | NDCG 1.0000 | MSE 0.3312
2020-11-05 21:04:56,441 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1846 | Iter Mean Loss 8.1846
2020-11-05 21:04:56,450 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0390 | Iter Mean Loss 5.6118
2020-11-05 21:04:56,457 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2116 | Iter Mean Loss 7.1451
2020-11-05 21:04:56,466 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 7.5955
2020-11-05 21:04:56,473 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9927 | Iter Mean Loss 7.2749
2020-11-05 21:04:56,476 - root - INFO - Evaluate: Epoch 0396 | NDCG 1.0000 | MSE 0.3310
2020-11-05 21:04:56,485 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1667 | Iter Mean Loss 8.1667
2020-11-05 21:04:56,493 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0339 | Iter Mean Loss 5.6003
2020-11-05 21:04:56,501 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1889 | Iter Mean Loss 7.1298
2020-11-05 21:04:56,509 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9263 | Iter Mean Loss 7.5789
2020-11-05 21:04:56,518 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9788 | Iter Mean Loss 7.2589
2020-11-05 21:04:56,520 - root - INFO - Evaluate: Epoch 0397 | NDCG 1.0000 | MSE 0.3309
2020-11-05 21:04:56,529 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1490 | Iter Mean Loss 8.1490
2020-11-05 21:04:56,538 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0287 | Iter Mean Loss 5.5889
2020-11-05 21:04:56,546 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1663 | Iter Mean Loss 7.1147
2020-11-05 21:04:56,554 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9059 | Iter Mean Loss 7.5625
2020-11-05 21:04:56,564 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9650 | Iter Mean Loss 7.2430
2020-11-05 21:04:56,566 - root - INFO - Evaluate: Epoch 0398 | NDCG 1.0000 | MSE 0.3308
2020-11-05 21:04:56,578 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1315 | Iter Mean Loss 8.1315
2020-11-05 21:04:56,587 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0237 | Iter Mean Loss 5.5776
2020-11-05 21:04:56,597 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1439 | Iter Mean Loss 7.0997
2020-11-05 21:04:56,606 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8856 | Iter Mean Loss 7.5462
2020-11-05 21:04:56,615 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 7.2272
2020-11-05 21:04:56,617 - root - INFO - Evaluate: Epoch 0399 | NDCG 1.0000 | MSE 0.3307
2020-11-05 21:04:56,629 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1141 | Iter Mean Loss 8.1141
2020-11-05 21:04:56,638 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0187 | Iter Mean Loss 5.5664
2020-11-05 21:04:56,648 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1216 | Iter Mean Loss 7.0848
2020-11-05 21:04:56,658 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8655 | Iter Mean Loss 7.5300
2020-11-05 21:04:56,667 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9378 | Iter Mean Loss 7.2115
2020-11-05 21:04:56,669 - root - INFO - Evaluate: Epoch 0400 | NDCG 1.0000 | MSE 0.3306
2020-11-05 21:04:56,680 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0969 | Iter Mean Loss 8.0969
2020-11-05 21:04:56,690 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0137 | Iter Mean Loss 5.5553
2020-11-05 21:04:56,700 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0995 | Iter Mean Loss 7.0700
2020-11-05 21:04:56,711 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8455 | Iter Mean Loss 7.5139
2020-11-05 21:04:56,721 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9243 | Iter Mean Loss 7.1960
2020-11-05 21:04:56,723 - root - INFO - Evaluate: Epoch 0401 | NDCG 1.0000 | MSE 0.3305
2020-11-05 21:04:56,737 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0799 | Iter Mean Loss 8.0799
2020-11-05 21:04:56,747 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0088 | Iter Mean Loss 5.5443
2020-11-05 21:04:56,757 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0775 | Iter Mean Loss 7.0554
2020-11-05 21:04:56,767 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8257 | Iter Mean Loss 7.4979
2020-11-05 21:04:56,776 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9110 | Iter Mean Loss 7.1806
2020-11-05 21:04:56,778 - root - INFO - Evaluate: Epoch 0402 | NDCG 1.0000 | MSE 0.3304
2020-11-05 21:04:56,790 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0630 | Iter Mean Loss 8.0630
2020-11-05 21:04:56,799 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0039 | Iter Mean Loss 5.5334
2020-11-05 21:04:56,811 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0557 | Iter Mean Loss 7.0409
2020-11-05 21:04:56,821 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8059 | Iter Mean Loss 7.4821
2020-11-05 21:04:56,830 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8977 | Iter Mean Loss 7.1652
2020-11-05 21:04:56,833 - root - INFO - Evaluate: Epoch 0403 | NDCG 1.0000 | MSE 0.3303
2020-11-05 21:04:56,843 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0462 | Iter Mean Loss 8.0462
2020-11-05 21:04:56,854 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9991 | Iter Mean Loss 5.5227
2020-11-05 21:04:56,863 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0340 | Iter Mean Loss 7.0264
2020-11-05 21:04:56,873 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7864 | Iter Mean Loss 7.4664
2020-11-05 21:04:56,882 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8845 | Iter Mean Loss 7.1500
2020-11-05 21:04:56,886 - root - INFO - Evaluate: Epoch 0404 | NDCG 1.0000 | MSE 0.3302
2020-11-05 21:04:56,895 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0297 | Iter Mean Loss 8.0297
2020-11-05 21:04:56,905 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9943 | Iter Mean Loss 5.5120
2020-11-05 21:04:56,913 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0125 | Iter Mean Loss 7.0122
2020-11-05 21:04:56,923 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7669 | Iter Mean Loss 7.4508
2020-11-05 21:04:56,931 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8714 | Iter Mean Loss 7.1350
2020-11-05 21:04:56,935 - root - INFO - Evaluate: Epoch 0405 | NDCG 1.0000 | MSE 0.3301
2020-11-05 21:04:56,944 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0132 | Iter Mean Loss 8.0132
2020-11-05 21:04:56,952 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9896 | Iter Mean Loss 5.5014
2020-11-05 21:04:56,959 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9911 | Iter Mean Loss 6.9980
2020-11-05 21:04:56,967 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7476 | Iter Mean Loss 7.4354
2020-11-05 21:04:56,976 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8584 | Iter Mean Loss 7.1200
2020-11-05 21:04:56,978 - root - INFO - Evaluate: Epoch 0406 | NDCG 1.0000 | MSE 0.3300
2020-11-05 21:04:56,987 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9970 | Iter Mean Loss 7.9970
2020-11-05 21:04:56,996 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9849 | Iter Mean Loss 5.4909
2020-11-05 21:04:57,003 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9699 | Iter Mean Loss 6.9839
2020-11-05 21:04:57,011 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7284 | Iter Mean Loss 7.4200
2020-11-05 21:04:57,019 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8454 | Iter Mean Loss 7.1051
2020-11-05 21:04:57,021 - root - INFO - Evaluate: Epoch 0407 | NDCG 1.0000 | MSE 0.3299
2020-11-05 21:04:57,032 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9808 | Iter Mean Loss 7.9808
2020-11-05 21:04:57,041 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9803 | Iter Mean Loss 5.4806
2020-11-05 21:04:57,050 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9488 | Iter Mean Loss 6.9700
2020-11-05 21:04:57,059 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7094 | Iter Mean Loss 7.4048
2020-11-05 21:04:57,067 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8326 | Iter Mean Loss 7.0904
2020-11-05 21:04:57,070 - root - INFO - Evaluate: Epoch 0408 | NDCG 1.0000 | MSE 0.3298
2020-11-05 21:04:57,081 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9649 | Iter Mean Loss 7.9649
2020-11-05 21:04:57,091 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9757 | Iter Mean Loss 5.4703
2020-11-05 21:04:57,099 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9278 | Iter Mean Loss 6.9561
2020-11-05 21:04:57,108 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6904 | Iter Mean Loss 7.3897
2020-11-05 21:04:57,117 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8198 | Iter Mean Loss 7.0757
2020-11-05 21:04:57,119 - root - INFO - Evaluate: Epoch 0409 | NDCG 1.0000 | MSE 0.3297
2020-11-05 21:04:57,129 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9490 | Iter Mean Loss 7.9490
2020-11-05 21:04:57,138 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9712 | Iter Mean Loss 5.4601
2020-11-05 21:04:57,146 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9070 | Iter Mean Loss 6.9424
2020-11-05 21:04:57,154 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6716 | Iter Mean Loss 7.3747
2020-11-05 21:04:57,162 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8072 | Iter Mean Loss 7.0612
2020-11-05 21:04:57,164 - root - INFO - Evaluate: Epoch 0410 | NDCG 1.0000 | MSE 0.3296
2020-11-05 21:04:57,172 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9334 | Iter Mean Loss 7.9334
2020-11-05 21:04:57,180 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9667 | Iter Mean Loss 5.4500
2020-11-05 21:04:57,188 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 6.9288
2020-11-05 21:04:57,196 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6530 | Iter Mean Loss 7.3598
2020-11-05 21:04:57,204 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7945 | Iter Mean Loss 7.0468
2020-11-05 21:04:57,206 - root - INFO - Evaluate: Epoch 0411 | NDCG 1.0000 | MSE 0.3295
2020-11-05 21:04:57,214 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9178 | Iter Mean Loss 7.9178
2020-11-05 21:04:57,222 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9622 | Iter Mean Loss 5.4400
2020-11-05 21:04:57,230 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8657 | Iter Mean Loss 6.9153
2020-11-05 21:04:57,240 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6344 | Iter Mean Loss 7.3450
2020-11-05 21:04:57,248 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7820 | Iter Mean Loss 7.0324
2020-11-05 21:04:57,250 - root - INFO - Evaluate: Epoch 0412 | NDCG 1.0000 | MSE 0.3294
2020-11-05 21:04:57,259 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9025 | Iter Mean Loss 7.9025
2020-11-05 21:04:57,267 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9578 | Iter Mean Loss 5.4301
2020-11-05 21:04:57,275 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8453 | Iter Mean Loss 6.9018
2020-11-05 21:04:57,285 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6160 | Iter Mean Loss 7.3304
2020-11-05 21:04:57,293 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7696 | Iter Mean Loss 7.0182
2020-11-05 21:04:57,295 - root - INFO - Evaluate: Epoch 0413 | NDCG 1.0000 | MSE 0.3293
2020-11-05 21:04:57,304 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8872 | Iter Mean Loss 7.8872
2020-11-05 21:04:57,314 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 5.4203
2020-11-05 21:04:57,328 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8250 | Iter Mean Loss 6.8885
2020-11-05 21:04:57,337 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5977 | Iter Mean Loss 7.3158
2020-11-05 21:04:57,345 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7572 | Iter Mean Loss 7.0041
2020-11-05 21:04:57,347 - root - INFO - Evaluate: Epoch 0414 | NDCG 1.0000 | MSE 0.3292
2020-11-05 21:04:57,356 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8721 | Iter Mean Loss 7.8721
2020-11-05 21:04:57,366 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9491 | Iter Mean Loss 5.4106
2020-11-05 21:04:57,375 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8048 | Iter Mean Loss 6.8753
2020-11-05 21:04:57,386 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5795 | Iter Mean Loss 7.3014
2020-11-05 21:04:57,396 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7449 | Iter Mean Loss 6.9901
2020-11-05 21:04:57,401 - root - INFO - Evaluate: Epoch 0415 | NDCG 1.0000 | MSE 0.3291
2020-11-05 21:04:57,412 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8571 | Iter Mean Loss 7.8571
2020-11-05 21:04:57,424 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9448 | Iter Mean Loss 5.4010
2020-11-05 21:04:57,435 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7847 | Iter Mean Loss 6.8622
2020-11-05 21:04:57,445 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5615 | Iter Mean Loss 7.2870
2020-11-05 21:04:57,457 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7326 | Iter Mean Loss 6.9761
2020-11-05 21:04:57,461 - root - INFO - Evaluate: Epoch 0416 | NDCG 1.0000 | MSE 0.3290
2020-11-05 21:04:57,475 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8423 | Iter Mean Loss 7.8423
2020-11-05 21:04:57,486 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9405 | Iter Mean Loss 5.3914
2020-11-05 21:04:57,499 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7648 | Iter Mean Loss 6.8492
2020-11-05 21:04:57,512 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 7.2728
2020-11-05 21:04:57,524 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7205 | Iter Mean Loss 6.9623
2020-11-05 21:04:57,529 - root - INFO - Evaluate: Epoch 0417 | NDCG 1.0000 | MSE 0.3289
2020-11-05 21:04:57,539 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 7.8276
2020-11-05 21:04:57,548 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 5.3820
2020-11-05 21:04:57,557 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7449 | Iter Mean Loss 6.8363
2020-11-05 21:04:57,567 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5257 | Iter Mean Loss 7.2586
2020-11-05 21:04:57,575 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7083 | Iter Mean Loss 6.9486
2020-11-05 21:04:57,577 - root - INFO - Evaluate: Epoch 0418 | NDCG 1.0000 | MSE 0.3288
2020-11-05 21:04:57,586 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8131 | Iter Mean Loss 7.8131
2020-11-05 21:04:57,595 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9321 | Iter Mean Loss 5.3726
2020-11-05 21:04:57,603 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7252 | Iter Mean Loss 6.8235
2020-11-05 21:04:57,611 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5080 | Iter Mean Loss 7.2446
2020-11-05 21:04:57,619 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6963 | Iter Mean Loss 6.9349
2020-11-05 21:04:57,621 - root - INFO - Evaluate: Epoch 0419 | NDCG 1.0000 | MSE 0.3287
2020-11-05 21:04:57,629 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7986 | Iter Mean Loss 7.7986
2020-11-05 21:04:57,637 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9279 | Iter Mean Loss 5.3633
2020-11-05 21:04:57,646 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7056 | Iter Mean Loss 6.8107
2020-11-05 21:04:57,654 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4904 | Iter Mean Loss 7.2307
2020-11-05 21:04:57,663 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6843 | Iter Mean Loss 6.9214
2020-11-05 21:04:57,665 - root - INFO - Evaluate: Epoch 0420 | NDCG 1.0000 | MSE 0.3286
2020-11-05 21:04:57,674 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7843 | Iter Mean Loss 7.7843
2020-11-05 21:04:57,683 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9238 | Iter Mean Loss 5.3541
2020-11-05 21:04:57,693 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6862 | Iter Mean Loss 6.7981
2020-11-05 21:04:57,702 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4729 | Iter Mean Loss 7.2168
2020-11-05 21:04:57,711 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6724 | Iter Mean Loss 6.9079
2020-11-05 21:04:57,714 - root - INFO - Evaluate: Epoch 0421 | NDCG 1.0000 | MSE 0.3285
2020-11-05 21:04:57,723 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7701 | Iter Mean Loss 7.7701
2020-11-05 21:04:57,732 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9197 | Iter Mean Loss 5.3449
2020-11-05 21:04:57,740 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6668 | Iter Mean Loss 6.7856
2020-11-05 21:04:57,748 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4555 | Iter Mean Loss 7.2031
2020-11-05 21:04:57,756 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6605 | Iter Mean Loss 6.8946
2020-11-05 21:04:57,759 - root - INFO - Evaluate: Epoch 0422 | NDCG 1.0000 | MSE 0.3284
2020-11-05 21:04:57,768 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7561 | Iter Mean Loss 7.7561
2020-11-05 21:04:57,776 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9157 | Iter Mean Loss 5.3359
2020-11-05 21:04:57,784 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6476 | Iter Mean Loss 6.7731
2020-11-05 21:04:57,792 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4383 | Iter Mean Loss 7.1894
2020-11-05 21:04:57,800 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6488 | Iter Mean Loss 6.8813
2020-11-05 21:04:57,802 - root - INFO - Evaluate: Epoch 0423 | NDCG 1.0000 | MSE 0.3284
2020-11-05 21:04:57,810 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7422 | Iter Mean Loss 7.7422
2020-11-05 21:04:57,818 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9117 | Iter Mean Loss 5.3269
2020-11-05 21:04:57,826 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6284 | Iter Mean Loss 6.7608
2020-11-05 21:04:57,834 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4211 | Iter Mean Loss 7.1758
2020-11-05 21:04:57,842 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6370 | Iter Mean Loss 6.8681
2020-11-05 21:04:57,844 - root - INFO - Evaluate: Epoch 0424 | NDCG 1.0000 | MSE 0.3283
2020-11-05 21:04:57,853 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7284 | Iter Mean Loss 7.7284
2020-11-05 21:04:57,861 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9077 | Iter Mean Loss 5.3180
2020-11-05 21:04:57,869 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6094 | Iter Mean Loss 6.7485
2020-11-05 21:04:57,877 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4041 | Iter Mean Loss 7.1624
2020-11-05 21:04:57,887 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6253 | Iter Mean Loss 6.8550
2020-11-05 21:04:57,889 - root - INFO - Evaluate: Epoch 0425 | NDCG 1.0000 | MSE 0.3282
2020-11-05 21:04:57,898 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7147 | Iter Mean Loss 7.7147
2020-11-05 21:04:57,907 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9037 | Iter Mean Loss 5.3092
2020-11-05 21:04:57,916 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5905 | Iter Mean Loss 6.7363
2020-11-05 21:04:57,924 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3871 | Iter Mean Loss 7.1490
2020-11-05 21:04:57,934 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6137 | Iter Mean Loss 6.8419
2020-11-05 21:04:57,936 - root - INFO - Evaluate: Epoch 0426 | NDCG 1.0000 | MSE 0.3281
2020-11-05 21:04:57,945 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7011 | Iter Mean Loss 7.7011
2020-11-05 21:04:57,954 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8998 | Iter Mean Loss 5.3005
2020-11-05 21:04:57,963 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5716 | Iter Mean Loss 6.7242
2020-11-05 21:04:57,971 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3703 | Iter Mean Loss 7.1357
2020-11-05 21:04:57,979 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6021 | Iter Mean Loss 6.8290
2020-11-05 21:04:57,982 - root - INFO - Evaluate: Epoch 0427 | NDCG 1.0000 | MSE 0.3280
2020-11-05 21:04:57,991 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6877 | Iter Mean Loss 7.6877
2020-11-05 21:04:58,000 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8959 | Iter Mean Loss 5.2918
2020-11-05 21:04:58,008 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5529 | Iter Mean Loss 6.7122
2020-11-05 21:04:58,016 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3536 | Iter Mean Loss 7.1225
2020-11-05 21:04:58,025 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5906 | Iter Mean Loss 6.8161
2020-11-05 21:04:58,028 - root - INFO - Evaluate: Epoch 0428 | NDCG 1.0000 | MSE 0.3279
2020-11-05 21:04:58,037 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6743 | Iter Mean Loss 7.6743
2020-11-05 21:04:58,046 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8920 | Iter Mean Loss 5.2832
2020-11-05 21:04:58,054 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5343 | Iter Mean Loss 6.7002
2020-11-05 21:04:58,064 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3370 | Iter Mean Loss 7.1094
2020-11-05 21:04:58,072 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5791 | Iter Mean Loss 6.8034
2020-11-05 21:04:58,075 - root - INFO - Evaluate: Epoch 0429 | NDCG 1.0000 | MSE 0.3278
2020-11-05 21:04:58,084 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6611 | Iter Mean Loss 7.6611
2020-11-05 21:04:58,094 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8882 | Iter Mean Loss 5.2747
2020-11-05 21:04:58,102 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 6.6884
2020-11-05 21:04:58,111 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3204 | Iter Mean Loss 7.0964
2020-11-05 21:04:58,119 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5677 | Iter Mean Loss 6.7907
2020-11-05 21:04:58,122 - root - INFO - Evaluate: Epoch 0430 | NDCG 1.0000 | MSE 0.3278
2020-11-05 21:04:58,131 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6480 | Iter Mean Loss 7.6480
2020-11-05 21:04:58,140 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8844 | Iter Mean Loss 5.2662
2020-11-05 21:04:58,148 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4974 | Iter Mean Loss 6.6766
2020-11-05 21:04:58,157 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3040 | Iter Mean Loss 7.0834
2020-11-05 21:04:58,165 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5564 | Iter Mean Loss 6.7780
2020-11-05 21:04:58,167 - root - INFO - Evaluate: Epoch 0431 | NDCG 1.0000 | MSE 0.3277
2020-11-05 21:04:58,175 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6350 | Iter Mean Loss 7.6350
2020-11-05 21:04:58,184 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8806 | Iter Mean Loss 5.2578
2020-11-05 21:04:58,191 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4791 | Iter Mean Loss 6.6649
2020-11-05 21:04:58,199 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 7.0706
2020-11-05 21:04:58,207 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5451 | Iter Mean Loss 6.7655
2020-11-05 21:04:58,209 - root - INFO - Evaluate: Epoch 0432 | NDCG 1.0000 | MSE 0.3276
2020-11-05 21:04:58,218 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6221 | Iter Mean Loss 7.6221
2020-11-05 21:04:58,226 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8768 | Iter Mean Loss 5.2495
2020-11-05 21:04:58,234 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4609 | Iter Mean Loss 6.6533
2020-11-05 21:04:58,242 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2714 | Iter Mean Loss 7.0578
2020-11-05 21:04:58,249 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5338 | Iter Mean Loss 6.7530
2020-11-05 21:04:58,252 - root - INFO - Evaluate: Epoch 0433 | NDCG 1.0000 | MSE 0.3275
2020-11-05 21:04:58,261 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 7.6093
2020-11-05 21:04:58,270 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8731 | Iter Mean Loss 5.2412
2020-11-05 21:04:58,279 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4427 | Iter Mean Loss 6.6417
2020-11-05 21:04:58,288 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2553 | Iter Mean Loss 7.0451
2020-11-05 21:04:58,297 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5226 | Iter Mean Loss 6.7406
2020-11-05 21:04:58,299 - root - INFO - Evaluate: Epoch 0434 | NDCG 1.0000 | MSE 0.3274
2020-11-05 21:04:58,310 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5966 | Iter Mean Loss 7.5966
2020-11-05 21:04:58,325 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8694 | Iter Mean Loss 5.2330
2020-11-05 21:04:58,333 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4247 | Iter Mean Loss 6.6302
2020-11-05 21:04:58,342 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2393 | Iter Mean Loss 7.0325
2020-11-05 21:04:58,350 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5114 | Iter Mean Loss 6.7283
2020-11-05 21:04:58,353 - root - INFO - Evaluate: Epoch 0435 | NDCG 1.0000 | MSE 0.3274
2020-11-05 21:04:58,362 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5840 | Iter Mean Loss 7.5840
2020-11-05 21:04:58,371 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8657 | Iter Mean Loss 5.2249
2020-11-05 21:04:58,379 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 6.6188
2020-11-05 21:04:58,387 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2233 | Iter Mean Loss 7.0200
2020-11-05 21:04:58,394 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5003 | Iter Mean Loss 6.7160
2020-11-05 21:04:58,397 - root - INFO - Evaluate: Epoch 0436 | NDCG 1.0000 | MSE 0.3273
2020-11-05 21:04:58,405 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5716 | Iter Mean Loss 7.5716
2020-11-05 21:04:58,413 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8620 | Iter Mean Loss 5.2168
2020-11-05 21:04:58,420 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3889 | Iter Mean Loss 6.6075
2020-11-05 21:04:58,428 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2075 | Iter Mean Loss 7.0075
2020-11-05 21:04:58,436 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4892 | Iter Mean Loss 6.7038
2020-11-05 21:04:58,438 - root - INFO - Evaluate: Epoch 0437 | NDCG 1.0000 | MSE 0.3272
2020-11-05 21:04:58,447 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5592 | Iter Mean Loss 7.5592
2020-11-05 21:04:58,456 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8584 | Iter Mean Loss 5.2088
2020-11-05 21:04:58,465 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3712 | Iter Mean Loss 6.5962
2020-11-05 21:04:58,473 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1917 | Iter Mean Loss 6.9951
2020-11-05 21:04:58,481 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4782 | Iter Mean Loss 6.6917
2020-11-05 21:04:58,484 - root - INFO - Evaluate: Epoch 0438 | NDCG 1.0000 | MSE 0.3271
2020-11-05 21:04:58,493 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5469 | Iter Mean Loss 7.5469
2020-11-05 21:04:58,502 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8548 | Iter Mean Loss 5.2008
2020-11-05 21:04:58,510 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3535 | Iter Mean Loss 6.5851
2020-11-05 21:04:58,518 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1760 | Iter Mean Loss 6.9828
2020-11-05 21:04:58,527 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4672 | Iter Mean Loss 6.6797
2020-11-05 21:04:58,529 - root - INFO - Evaluate: Epoch 0439 | NDCG 1.0000 | MSE 0.3270
2020-11-05 21:04:58,538 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5347 | Iter Mean Loss 7.5347
2020-11-05 21:04:58,547 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8512 | Iter Mean Loss 5.1930
2020-11-05 21:04:58,555 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3359 | Iter Mean Loss 6.5739
2020-11-05 21:04:58,564 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 6.9706
2020-11-05 21:04:58,572 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4562 | Iter Mean Loss 6.6677
2020-11-05 21:04:58,574 - root - INFO - Evaluate: Epoch 0440 | NDCG 1.0000 | MSE 0.3270
2020-11-05 21:04:58,583 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5227 | Iter Mean Loss 7.5227
2020-11-05 21:04:58,591 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8476 | Iter Mean Loss 5.1851
2020-11-05 21:04:58,599 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3184 | Iter Mean Loss 6.5629
2020-11-05 21:04:58,607 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1449 | Iter Mean Loss 6.9584
2020-11-05 21:04:58,615 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4453 | Iter Mean Loss 6.6558
2020-11-05 21:04:58,618 - root - INFO - Evaluate: Epoch 0441 | NDCG 1.0000 | MSE 0.3269
2020-11-05 21:04:58,626 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5107 | Iter Mean Loss 7.5107
2020-11-05 21:04:58,634 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8440 | Iter Mean Loss 5.1773
2020-11-05 21:04:58,642 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3010 | Iter Mean Loss 6.5519
2020-11-05 21:04:58,650 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1295 | Iter Mean Loss 6.9463
2020-11-05 21:04:58,659 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4344 | Iter Mean Loss 6.6439
2020-11-05 21:04:58,661 - root - INFO - Evaluate: Epoch 0442 | NDCG 1.0000 | MSE 0.3268
2020-11-05 21:04:58,670 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4988 | Iter Mean Loss 7.4988
2020-11-05 21:04:58,681 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8405 | Iter Mean Loss 5.1696
2020-11-05 21:04:58,689 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2837 | Iter Mean Loss 6.5410
2020-11-05 21:04:58,699 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1142 | Iter Mean Loss 6.9343
2020-11-05 21:04:58,707 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4236 | Iter Mean Loss 6.6321
2020-11-05 21:04:58,709 - root - INFO - Evaluate: Epoch 0443 | NDCG 1.0000 | MSE 0.3267
2020-11-05 21:04:58,719 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4870 | Iter Mean Loss 7.4870
2020-11-05 21:04:58,728 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8370 | Iter Mean Loss 5.1620
2020-11-05 21:04:58,737 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 6.5301
2020-11-05 21:04:58,745 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0989 | Iter Mean Loss 6.9223
2020-11-05 21:04:58,754 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4128 | Iter Mean Loss 6.6204
2020-11-05 21:04:58,756 - root - INFO - Evaluate: Epoch 0444 | NDCG 1.0000 | MSE 0.3267
2020-11-05 21:04:58,766 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4752 | Iter Mean Loss 7.4752
2020-11-05 21:04:58,774 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8334 | Iter Mean Loss 5.1543
2020-11-05 21:04:58,783 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2493 | Iter Mean Loss 6.5193
2020-11-05 21:04:58,791 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0837 | Iter Mean Loss 6.9104
2020-11-05 21:04:58,798 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4021 | Iter Mean Loss 6.6088
2020-11-05 21:04:58,801 - root - INFO - Evaluate: Epoch 0445 | NDCG 1.0000 | MSE 0.3266
2020-11-05 21:04:58,809 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4636 | Iter Mean Loss 7.4636
2020-11-05 21:04:58,816 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8300 | Iter Mean Loss 5.1468
2020-11-05 21:04:58,824 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2322 | Iter Mean Loss 6.5086
2020-11-05 21:04:58,831 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0686 | Iter Mean Loss 6.8986
2020-11-05 21:04:58,839 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3914 | Iter Mean Loss 6.5972
2020-11-05 21:04:58,841 - root - INFO - Evaluate: Epoch 0446 | NDCG 1.0000 | MSE 0.3265
2020-11-05 21:04:58,850 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4521 | Iter Mean Loss 7.4521
2020-11-05 21:04:58,858 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8265 | Iter Mean Loss 5.1393
2020-11-05 21:04:58,865 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2152 | Iter Mean Loss 6.4979
2020-11-05 21:04:58,873 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0536 | Iter Mean Loss 6.8868
2020-11-05 21:04:58,880 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3807 | Iter Mean Loss 6.5856
2020-11-05 21:04:58,883 - root - INFO - Evaluate: Epoch 0447 | NDCG 1.0000 | MSE 0.3264
2020-11-05 21:04:58,892 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4406 | Iter Mean Loss 7.4406
2020-11-05 21:04:58,901 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8230 | Iter Mean Loss 5.1318
2020-11-05 21:04:58,909 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1983 | Iter Mean Loss 6.4873
2020-11-05 21:04:58,917 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0387 | Iter Mean Loss 6.8752
2020-11-05 21:04:58,925 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3701 | Iter Mean Loss 6.5741
2020-11-05 21:04:58,927 - root - INFO - Evaluate: Epoch 0448 | NDCG 1.0000 | MSE 0.3264
2020-11-05 21:04:58,936 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4293 | Iter Mean Loss 7.4293
2020-11-05 21:04:58,944 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 5.1244
2020-11-05 21:04:58,952 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1815 | Iter Mean Loss 6.4768
2020-11-05 21:04:58,960 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0238 | Iter Mean Loss 6.8635
2020-11-05 21:04:58,969 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 6.5627
2020-11-05 21:04:58,971 - root - INFO - Evaluate: Epoch 0449 | NDCG 1.0000 | MSE 0.3263
2020-11-05 21:04:58,980 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 7.4180
2020-11-05 21:04:58,988 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8162 | Iter Mean Loss 5.1171
2020-11-05 21:04:58,996 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1647 | Iter Mean Loss 6.4663
2020-11-05 21:04:59,003 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0090 | Iter Mean Loss 6.8520
2020-11-05 21:04:59,010 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3489 | Iter Mean Loss 6.5514
2020-11-05 21:04:59,013 - root - INFO - Evaluate: Epoch 0450 | NDCG 1.0000 | MSE 0.3262
2020-11-05 21:04:59,022 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4068 | Iter Mean Loss 7.4068
2020-11-05 21:04:59,030 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8128 | Iter Mean Loss 5.1098
2020-11-05 21:04:59,037 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1480 | Iter Mean Loss 6.4558
2020-11-05 21:04:59,045 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9943 | Iter Mean Loss 6.8405
2020-11-05 21:04:59,052 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3384 | Iter Mean Loss 6.5401
2020-11-05 21:04:59,054 - root - INFO - Evaluate: Epoch 0451 | NDCG 1.0000 | MSE 0.3261
2020-11-05 21:04:59,062 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3956 | Iter Mean Loss 7.3956
2020-11-05 21:04:59,070 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8094 | Iter Mean Loss 5.1025
2020-11-05 21:04:59,078 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1314 | Iter Mean Loss 6.4455
2020-11-05 21:04:59,086 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9797 | Iter Mean Loss 6.8290
2020-11-05 21:04:59,094 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3279 | Iter Mean Loss 6.5288
2020-11-05 21:04:59,096 - root - INFO - Evaluate: Epoch 0452 | NDCG 1.0000 | MSE 0.3261
2020-11-05 21:04:59,105 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3846 | Iter Mean Loss 7.3846
2020-11-05 21:04:59,114 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8060 | Iter Mean Loss 5.0953
2020-11-05 21:04:59,122 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1149 | Iter Mean Loss 6.4351
2020-11-05 21:04:59,131 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 6.8176
2020-11-05 21:04:59,139 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3175 | Iter Mean Loss 6.5176
2020-11-05 21:04:59,142 - root - INFO - Evaluate: Epoch 0453 | NDCG 1.0000 | MSE 0.3260
2020-11-05 21:04:59,151 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3736 | Iter Mean Loss 7.3736
2020-11-05 21:04:59,160 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8026 | Iter Mean Loss 5.0881
2020-11-05 21:04:59,168 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 6.4249
2020-11-05 21:04:59,177 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9506 | Iter Mean Loss 6.8063
2020-11-05 21:04:59,185 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3071 | Iter Mean Loss 6.5065
2020-11-05 21:04:59,187 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.2817 | MSE 0.3259
2020-11-05 21:04:59,196 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3627 | Iter Mean Loss 7.3627
2020-11-05 21:04:59,204 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7992 | Iter Mean Loss 5.0810
2020-11-05 21:04:59,212 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0820 | Iter Mean Loss 6.4147
2020-11-05 21:04:59,219 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9362 | Iter Mean Loss 6.7951
2020-11-05 21:04:59,227 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2967 | Iter Mean Loss 6.4954
2020-11-05 21:04:59,229 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.2817 | MSE 0.3258
2020-11-05 21:04:59,237 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3519 | Iter Mean Loss 7.3519
2020-11-05 21:04:59,245 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7959 | Iter Mean Loss 5.0739
2020-11-05 21:04:59,252 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0657 | Iter Mean Loss 6.4045
2020-11-05 21:04:59,260 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9219 | Iter Mean Loss 6.7838
2020-11-05 21:04:59,268 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2863 | Iter Mean Loss 6.4843
2020-11-05 21:04:59,270 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.2817 | MSE 0.3258
2020-11-05 21:04:59,278 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3412 | Iter Mean Loss 7.3412
2020-11-05 21:04:59,286 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7926 | Iter Mean Loss 5.0669
2020-11-05 21:04:59,294 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0495 | Iter Mean Loss 6.3944
2020-11-05 21:04:59,302 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9076 | Iter Mean Loss 6.7727
2020-11-05 21:04:59,311 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2760 | Iter Mean Loss 6.4734
2020-11-05 21:04:59,315 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.2817 | MSE 0.3257
2020-11-05 21:04:59,328 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3305 | Iter Mean Loss 7.3305
2020-11-05 21:04:59,336 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7892 | Iter Mean Loss 5.0599
2020-11-05 21:04:59,345 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0333 | Iter Mean Loss 6.3844
2020-11-05 21:04:59,353 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8934 | Iter Mean Loss 6.7616
2020-11-05 21:04:59,362 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2657 | Iter Mean Loss 6.4624
2020-11-05 21:04:59,364 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.2817 | MSE 0.3256
2020-11-05 21:04:59,373 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3199 | Iter Mean Loss 7.3199
2020-11-05 21:04:59,382 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7859 | Iter Mean Loss 5.0529
2020-11-05 21:04:59,390 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0172 | Iter Mean Loss 6.3743
2020-11-05 21:04:59,397 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8792 | Iter Mean Loss 6.7506
2020-11-05 21:04:59,405 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2555 | Iter Mean Loss 6.4515
2020-11-05 21:04:59,407 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.2817 | MSE 0.3256
2020-11-05 21:04:59,415 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3094 | Iter Mean Loss 7.3094
2020-11-05 21:04:59,423 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7826 | Iter Mean Loss 5.0460
2020-11-05 21:04:59,430 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0011 | Iter Mean Loss 6.3644
2020-11-05 21:04:59,438 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8651 | Iter Mean Loss 6.7396
2020-11-05 21:04:59,445 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 6.4407
2020-11-05 21:04:59,447 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.2817 | MSE 0.3255
2020-11-05 21:04:59,455 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2990 | Iter Mean Loss 7.2990
2020-11-05 21:04:59,464 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7793 | Iter Mean Loss 5.0391
2020-11-05 21:04:59,475 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9852 | Iter Mean Loss 6.3545
2020-11-05 21:04:59,485 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8511 | Iter Mean Loss 6.7286
2020-11-05 21:04:59,495 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2351 | Iter Mean Loss 6.4299
2020-11-05 21:04:59,497 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.2817 | MSE 0.3254
2020-11-05 21:04:59,507 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2886 | Iter Mean Loss 7.2886
2020-11-05 21:04:59,517 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7760 | Iter Mean Loss 5.0323
2020-11-05 21:04:59,526 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9693 | Iter Mean Loss 6.3446
2020-11-05 21:04:59,535 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8371 | Iter Mean Loss 6.7178
2020-11-05 21:04:59,543 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2249 | Iter Mean Loss 6.4192
2020-11-05 21:04:59,546 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.2817 | MSE 0.3253
2020-11-05 21:04:59,555 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2783 | Iter Mean Loss 7.2783
2020-11-05 21:04:59,564 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7728 | Iter Mean Loss 5.0255
2020-11-05 21:04:59,572 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9534 | Iter Mean Loss 6.3348
2020-11-05 21:04:59,581 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8232 | Iter Mean Loss 6.7069
2020-11-05 21:04:59,589 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2148 | Iter Mean Loss 6.4085
2020-11-05 21:04:59,592 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.2817 | MSE 0.3253
2020-11-05 21:04:59,600 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2680 | Iter Mean Loss 7.2680
2020-11-05 21:04:59,607 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7695 | Iter Mean Loss 5.0188
2020-11-05 21:04:59,615 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9377 | Iter Mean Loss 6.3251
2020-11-05 21:04:59,623 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8094 | Iter Mean Loss 6.6961
2020-11-05 21:04:59,630 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2047 | Iter Mean Loss 6.3979
2020-11-05 21:04:59,632 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.2817 | MSE 0.3252
2020-11-05 21:04:59,641 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2578 | Iter Mean Loss 7.2578
2020-11-05 21:04:59,648 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7662 | Iter Mean Loss 5.0120
2020-11-05 21:04:59,656 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9220 | Iter Mean Loss 6.3153
2020-11-05 21:04:59,664 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7956 | Iter Mean Loss 6.6854
2020-11-05 21:04:59,671 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1947 | Iter Mean Loss 6.3873
2020-11-05 21:04:59,673 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.2817 | MSE 0.3251
2020-11-05 21:04:59,682 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2477 | Iter Mean Loss 7.2477
2020-11-05 21:04:59,690 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7630 | Iter Mean Loss 5.0054
2020-11-05 21:04:59,698 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9063 | Iter Mean Loss 6.3057
2020-11-05 21:04:59,706 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7819 | Iter Mean Loss 6.6747
2020-11-05 21:04:59,714 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1846 | Iter Mean Loss 6.3767
2020-11-05 21:04:59,716 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.2817 | MSE 0.3251
2020-11-05 21:04:59,725 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2377 | Iter Mean Loss 7.2377
2020-11-05 21:04:59,734 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7597 | Iter Mean Loss 4.9987
2020-11-05 21:04:59,743 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8907 | Iter Mean Loss 6.2961
2020-11-05 21:04:59,751 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7682 | Iter Mean Loss 6.6641
2020-11-05 21:04:59,760 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1746 | Iter Mean Loss 6.3662
2020-11-05 21:04:59,762 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.2817 | MSE 0.3250
2020-11-05 21:04:59,771 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2277 | Iter Mean Loss 7.2277
2020-11-05 21:04:59,782 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7565 | Iter Mean Loss 4.9921
2020-11-05 21:04:59,794 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8752 | Iter Mean Loss 6.2865
2020-11-05 21:04:59,807 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7546 | Iter Mean Loss 6.6535
2020-11-05 21:04:59,819 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 6.3557
2020-11-05 21:04:59,821 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.2817 | MSE 0.3249
2020-11-05 21:04:59,835 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2178 | Iter Mean Loss 7.2178
2020-11-05 21:04:59,849 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7533 | Iter Mean Loss 4.9855
2020-11-05 21:04:59,863 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8597 | Iter Mean Loss 6.2769
2020-11-05 21:04:59,875 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7411 | Iter Mean Loss 6.6430
2020-11-05 21:04:59,883 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1547 | Iter Mean Loss 6.3453
2020-11-05 21:04:59,885 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.2817 | MSE 0.3249
2020-11-05 21:04:59,894 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2079 | Iter Mean Loss 7.2079
2020-11-05 21:04:59,903 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7501 | Iter Mean Loss 4.9790
2020-11-05 21:04:59,911 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8443 | Iter Mean Loss 6.2674
2020-11-05 21:04:59,919 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7276 | Iter Mean Loss 6.6325
2020-11-05 21:04:59,928 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1448 | Iter Mean Loss 6.3349
2020-11-05 21:04:59,930 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.2817 | MSE 0.3248
2020-11-05 21:04:59,939 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1981 | Iter Mean Loss 7.1981
2020-11-05 21:04:59,948 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7468 | Iter Mean Loss 4.9725
2020-11-05 21:04:59,955 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8290 | Iter Mean Loss 6.2580
2020-11-05 21:04:59,965 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7141 | Iter Mean Loss 6.6220
2020-11-05 21:04:59,973 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1349 | Iter Mean Loss 6.3246
2020-11-05 21:04:59,976 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.2817 | MSE 0.3247
2020-11-05 21:04:59,985 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1884 | Iter Mean Loss 7.1884
2020-11-05 21:04:59,993 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7436 | Iter Mean Loss 4.9660
2020-11-05 21:05:00,001 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8137 | Iter Mean Loss 6.2486
2020-11-05 21:05:00,009 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7007 | Iter Mean Loss 6.6116
2020-11-05 21:05:00,017 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1250 | Iter Mean Loss 6.3143
2020-11-05 21:05:00,019 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.2817 | MSE 0.3247
2020-11-05 21:05:00,029 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1787 | Iter Mean Loss 7.1787
2020-11-05 21:05:00,037 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7404 | Iter Mean Loss 4.9595
2020-11-05 21:05:00,045 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7985 | Iter Mean Loss 6.2392
2020-11-05 21:05:00,053 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6874 | Iter Mean Loss 6.6012
2020-11-05 21:05:00,060 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1152 | Iter Mean Loss 6.3040
2020-11-05 21:05:00,062 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.2817 | MSE 0.3246
2020-11-05 21:05:00,071 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1690 | Iter Mean Loss 7.1690
2020-11-05 21:05:00,079 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7372 | Iter Mean Loss 4.9531
2020-11-05 21:05:00,086 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7833 | Iter Mean Loss 6.2299
2020-11-05 21:05:00,094 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6741 | Iter Mean Loss 6.5909
2020-11-05 21:05:00,102 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1054 | Iter Mean Loss 6.2938
2020-11-05 21:05:00,104 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.2817 | MSE 0.3245
2020-11-05 21:05:00,112 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1595 | Iter Mean Loss 7.1595
2020-11-05 21:05:00,120 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7340 | Iter Mean Loss 4.9467
2020-11-05 21:05:00,128 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7682 | Iter Mean Loss 6.2206
2020-11-05 21:05:00,136 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6609 | Iter Mean Loss 6.5806
2020-11-05 21:05:00,145 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0956 | Iter Mean Loss 6.2836
2020-11-05 21:05:00,147 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.2817 | MSE 0.3245
2020-11-05 21:05:00,156 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1500 | Iter Mean Loss 7.1500
2020-11-05 21:05:00,164 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7308 | Iter Mean Loss 4.9404
2020-11-05 21:05:00,172 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7532 | Iter Mean Loss 6.2113
2020-11-05 21:05:00,181 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6477 | Iter Mean Loss 6.5704
2020-11-05 21:05:00,189 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0858 | Iter Mean Loss 6.2735
2020-11-05 21:05:00,191 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.2817 | MSE 0.3244
2020-11-05 21:05:00,201 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1405 | Iter Mean Loss 7.1405
2020-11-05 21:05:00,210 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7276 | Iter Mean Loss 4.9340
2020-11-05 21:05:00,219 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7382 | Iter Mean Loss 6.2021
2020-11-05 21:05:00,228 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6345 | Iter Mean Loss 6.5602
2020-11-05 21:05:00,236 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0761 | Iter Mean Loss 6.2634
2020-11-05 21:05:00,239 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.2817 | MSE 0.3243
2020-11-05 21:05:00,248 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1311 | Iter Mean Loss 7.1311
2020-11-05 21:05:00,262 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7244 | Iter Mean Loss 4.9277
2020-11-05 21:05:00,274 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7232 | Iter Mean Loss 6.1929
2020-11-05 21:05:00,285 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6215 | Iter Mean Loss 6.5501
2020-11-05 21:05:00,295 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0664 | Iter Mean Loss 6.2533
2020-11-05 21:05:00,298 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.2817 | MSE 0.3243
2020-11-05 21:05:00,309 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1218 | Iter Mean Loss 7.1218
2020-11-05 21:05:00,324 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7212 | Iter Mean Loss 4.9215
2020-11-05 21:05:00,332 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7084 | Iter Mean Loss 6.1838
2020-11-05 21:05:00,340 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6084 | Iter Mean Loss 6.5399
2020-11-05 21:05:00,349 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0567 | Iter Mean Loss 6.2433
2020-11-05 21:05:00,351 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.2817 | MSE 0.3242
2020-11-05 21:05:00,361 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1125 | Iter Mean Loss 7.1125
2020-11-05 21:05:00,369 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7180 | Iter Mean Loss 4.9152
2020-11-05 21:05:00,378 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6935 | Iter Mean Loss 6.1747
2020-11-05 21:05:00,387 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5954 | Iter Mean Loss 6.5299
2020-11-05 21:05:00,397 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0470 | Iter Mean Loss 6.2333
2020-11-05 21:05:00,399 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.2817 | MSE 0.3241
2020-11-05 21:05:00,409 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1032 | Iter Mean Loss 7.1032
2020-11-05 21:05:00,418 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7148 | Iter Mean Loss 4.9090
2020-11-05 21:05:00,427 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6787 | Iter Mean Loss 6.1656
2020-11-05 21:05:00,436 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5825 | Iter Mean Loss 6.5198
2020-11-05 21:05:00,444 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0374 | Iter Mean Loss 6.2233
2020-11-05 21:05:00,446 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.2817 | MSE 0.3241
2020-11-05 21:05:00,455 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0940 | Iter Mean Loss 7.0940
2020-11-05 21:05:00,462 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7116 | Iter Mean Loss 4.9028
2020-11-05 21:05:00,470 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6640 | Iter Mean Loss 6.1566
2020-11-05 21:05:00,478 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5696 | Iter Mean Loss 6.5098
2020-11-05 21:05:00,486 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0278 | Iter Mean Loss 6.2134
2020-11-05 21:05:00,489 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.2817 | MSE 0.3240
2020-11-05 21:05:00,498 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0849 | Iter Mean Loss 7.0849
2020-11-05 21:05:00,506 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7084 | Iter Mean Loss 4.8967
2020-11-05 21:05:00,515 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6493 | Iter Mean Loss 6.1476
2020-11-05 21:05:00,523 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5567 | Iter Mean Loss 6.4998
2020-11-05 21:05:00,532 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0182 | Iter Mean Loss 6.2035
2020-11-05 21:05:00,534 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.2817 | MSE 0.3239
2020-11-05 21:05:00,543 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0758 | Iter Mean Loss 7.0758
2020-11-05 21:05:00,552 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7053 | Iter Mean Loss 4.8905
2020-11-05 21:05:00,560 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6347 | Iter Mean Loss 6.1386
2020-11-05 21:05:00,569 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5439 | Iter Mean Loss 6.4899
2020-11-05 21:05:00,577 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0086 | Iter Mean Loss 6.1936
2020-11-05 21:05:00,579 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.2817 | MSE 0.3239
2020-11-05 21:05:00,587 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0667 | Iter Mean Loss 7.0667
2020-11-05 21:05:00,595 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7021 | Iter Mean Loss 4.8844
2020-11-05 21:05:00,603 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1296
2020-11-05 21:05:00,610 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5311 | Iter Mean Loss 6.4800
2020-11-05 21:05:00,618 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9991 | Iter Mean Loss 6.1838
2020-11-05 21:05:00,620 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.2817 | MSE 0.3238
2020-11-05 21:05:00,628 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0577 | Iter Mean Loss 7.0577
2020-11-05 21:05:00,636 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6989 | Iter Mean Loss 4.8783
2020-11-05 21:05:00,644 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6056 | Iter Mean Loss 6.1207
2020-11-05 21:05:00,652 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5184 | Iter Mean Loss 6.4702
2020-11-05 21:05:00,660 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9895 | Iter Mean Loss 6.1740
2020-11-05 21:05:00,662 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.2817 | MSE 0.3237
2020-11-05 21:05:00,670 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0488 | Iter Mean Loss 7.0488
2020-11-05 21:05:00,679 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 4.8722
2020-11-05 21:05:00,687 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5911 | Iter Mean Loss 6.1119
2020-11-05 21:05:00,695 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 6.4603
2020-11-05 21:05:00,704 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9800 | Iter Mean Loss 6.1643
2020-11-05 21:05:00,706 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.2817 | MSE 0.3237
2020-11-05 21:05:00,714 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0399 | Iter Mean Loss 7.0399
2020-11-05 21:05:00,723 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 4.8662
2020-11-05 21:05:00,731 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 6.1030
2020-11-05 21:05:00,740 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4931 | Iter Mean Loss 6.4505
2020-11-05 21:05:00,748 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9706 | Iter Mean Loss 6.1545
2020-11-05 21:05:00,751 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.2817 | MSE 0.3236
2020-11-05 21:05:00,759 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0310 | Iter Mean Loss 7.0310
2020-11-05 21:05:00,769 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 4.8602
2020-11-05 21:05:00,778 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5623 | Iter Mean Loss 6.0942
2020-11-05 21:05:00,787 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4804 | Iter Mean Loss 6.4408
2020-11-05 21:05:00,796 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9611 | Iter Mean Loss 6.1448
2020-11-05 21:05:00,798 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.2817 | MSE 0.3236
2020-11-05 21:05:00,806 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0222 | Iter Mean Loss 7.0222
2020-11-05 21:05:00,814 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6861 | Iter Mean Loss 4.8542
2020-11-05 21:05:00,822 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5479 | Iter Mean Loss 6.0854
2020-11-05 21:05:00,829 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4679 | Iter Mean Loss 6.4310
2020-11-05 21:05:00,837 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9517 | Iter Mean Loss 6.1352
2020-11-05 21:05:00,839 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.2817 | MSE 0.3235
2020-11-05 21:05:00,847 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 7.0135
2020-11-05 21:05:00,855 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6829 | Iter Mean Loss 4.8482
2020-11-05 21:05:00,862 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5337 | Iter Mean Loss 6.0767
2020-11-05 21:05:00,870 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4553 | Iter Mean Loss 6.4213
2020-11-05 21:05:00,878 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9422 | Iter Mean Loss 6.1255
2020-11-05 21:05:00,880 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.2817 | MSE 0.3234
2020-11-05 21:05:00,888 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0047 | Iter Mean Loss 7.0047
2020-11-05 21:05:00,897 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6797 | Iter Mean Loss 4.8422
2020-11-05 21:05:00,905 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5194 | Iter Mean Loss 6.0679
2020-11-05 21:05:00,914 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4428 | Iter Mean Loss 6.4117
2020-11-05 21:05:00,923 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9328 | Iter Mean Loss 6.1159
2020-11-05 21:05:00,926 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.2817 | MSE 0.3234
2020-11-05 21:05:00,936 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9961 | Iter Mean Loss 6.9961
2020-11-05 21:05:00,945 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6765 | Iter Mean Loss 4.8363
2020-11-05 21:05:00,953 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5052 | Iter Mean Loss 6.0592
2020-11-05 21:05:00,961 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4304 | Iter Mean Loss 6.4020
2020-11-05 21:05:00,969 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9235 | Iter Mean Loss 6.1063
2020-11-05 21:05:00,972 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.2817 | MSE 0.3233
2020-11-05 21:05:00,981 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9874 | Iter Mean Loss 6.9874
2020-11-05 21:05:00,989 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6733 | Iter Mean Loss 4.8304
2020-11-05 21:05:00,996 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4910 | Iter Mean Loss 6.0506
2020-11-05 21:05:01,004 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 6.3924
2020-11-05 21:05:01,011 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9141 | Iter Mean Loss 6.0968
2020-11-05 21:05:01,013 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.2817 | MSE 0.3232
2020-11-05 21:05:01,021 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9788 | Iter Mean Loss 6.9788
2020-11-05 21:05:01,029 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6701 | Iter Mean Loss 4.8244
2020-11-05 21:05:01,037 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4769 | Iter Mean Loss 6.0419
2020-11-05 21:05:01,044 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4056 | Iter Mean Loss 6.3828
2020-11-05 21:05:01,052 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9048 | Iter Mean Loss 6.0872
2020-11-05 21:05:01,054 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.2817 | MSE 0.3232
2020-11-05 21:05:01,062 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9703 | Iter Mean Loss 6.9703
2020-11-05 21:05:01,069 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6668 | Iter Mean Loss 4.8186
2020-11-05 21:05:01,076 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4628 | Iter Mean Loss 6.0333
2020-11-05 21:05:01,084 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3932 | Iter Mean Loss 6.3733
2020-11-05 21:05:01,093 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8955 | Iter Mean Loss 6.0777
2020-11-05 21:05:01,095 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.2817 | MSE 0.3231
2020-11-05 21:05:01,103 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9618 | Iter Mean Loss 6.9618
2020-11-05 21:05:01,111 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6636 | Iter Mean Loss 4.8127
2020-11-05 21:05:01,119 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4488 | Iter Mean Loss 6.0247
2020-11-05 21:05:01,127 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3809 | Iter Mean Loss 6.3638
2020-11-05 21:05:01,136 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8861 | Iter Mean Loss 6.0682
2020-11-05 21:05:01,138 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.2817 | MSE 0.3231
2020-11-05 21:05:01,147 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9533 | Iter Mean Loss 6.9533
2020-11-05 21:05:01,155 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6604 | Iter Mean Loss 4.8068
2020-11-05 21:05:01,163 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4348 | Iter Mean Loss 6.0162
2020-11-05 21:05:01,171 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3686 | Iter Mean Loss 6.3543
2020-11-05 21:05:01,179 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8769 | Iter Mean Loss 6.0588
2020-11-05 21:05:01,182 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.2817 | MSE 0.3230
2020-11-05 21:05:01,190 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9449 | Iter Mean Loss 6.9449
2020-11-05 21:05:01,198 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6571 | Iter Mean Loss 4.8010
2020-11-05 21:05:01,205 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4209 | Iter Mean Loss 6.0076
2020-11-05 21:05:01,213 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3564 | Iter Mean Loss 6.3448
2020-11-05 21:05:01,220 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8676 | Iter Mean Loss 6.0494
2020-11-05 21:05:01,222 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.2817 | MSE 0.3229
2020-11-05 21:05:01,230 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9365 | Iter Mean Loss 6.9365
2020-11-05 21:05:01,237 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6539 | Iter Mean Loss 4.7952
2020-11-05 21:05:01,245 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4069 | Iter Mean Loss 5.9991
2020-11-05 21:05:01,253 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.3354
2020-11-05 21:05:01,260 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 6.0400
2020-11-05 21:05:01,262 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.2817 | MSE 0.3229
2020-11-05 21:05:01,270 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9281 | Iter Mean Loss 6.9281
2020-11-05 21:05:01,278 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6507 | Iter Mean Loss 4.7894
2020-11-05 21:05:01,285 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3931 | Iter Mean Loss 5.9906
2020-11-05 21:05:01,293 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3320 | Iter Mean Loss 6.3260
2020-11-05 21:05:01,301 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8491 | Iter Mean Loss 6.0306
2020-11-05 21:05:01,303 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.2817 | MSE 0.3228
2020-11-05 21:05:01,312 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9198 | Iter Mean Loss 6.9198
2020-11-05 21:05:01,326 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6474 | Iter Mean Loss 4.7836
2020-11-05 21:05:01,333 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 5.9821
2020-11-05 21:05:01,342 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3198 | Iter Mean Loss 6.3166
2020-11-05 21:05:01,349 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8399 | Iter Mean Loss 6.0212
2020-11-05 21:05:01,352 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.2817 | MSE 0.3228
2020-11-05 21:05:01,360 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9115 | Iter Mean Loss 6.9115
2020-11-05 21:05:01,368 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6441 | Iter Mean Loss 4.7778
2020-11-05 21:05:01,376 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3654 | Iter Mean Loss 5.9737
2020-11-05 21:05:01,384 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3077 | Iter Mean Loss 6.3072
2020-11-05 21:05:01,392 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8307 | Iter Mean Loss 6.0119
2020-11-05 21:05:01,394 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.2817 | MSE 0.3227
2020-11-05 21:05:01,402 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9033 | Iter Mean Loss 6.9033
2020-11-05 21:05:01,410 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6409 | Iter Mean Loss 4.7721
2020-11-05 21:05:01,417 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3517 | Iter Mean Loss 5.9653
2020-11-05 21:05:01,424 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2956 | Iter Mean Loss 6.2978
2020-11-05 21:05:01,432 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8215 | Iter Mean Loss 6.0026
2020-11-05 21:05:01,434 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.2817 | MSE 0.3227
2020-11-05 21:05:01,442 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8951 | Iter Mean Loss 6.8951
2020-11-05 21:05:01,449 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6376 | Iter Mean Loss 4.7663
2020-11-05 21:05:01,456 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3379 | Iter Mean Loss 5.9569
2020-11-05 21:05:01,463 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2835 | Iter Mean Loss 6.2885
2020-11-05 21:05:01,471 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8124 | Iter Mean Loss 5.9933
2020-11-05 21:05:01,473 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.2817 | MSE 0.3226
2020-11-05 21:05:01,481 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8869 | Iter Mean Loss 6.8869
2020-11-05 21:05:01,488 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6343 | Iter Mean Loss 4.7606
2020-11-05 21:05:01,496 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3242 | Iter Mean Loss 5.9485
2020-11-05 21:05:01,504 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2715 | Iter Mean Loss 6.2792
2020-11-05 21:05:01,512 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8032 | Iter Mean Loss 5.9840
2020-11-05 21:05:01,514 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.2817 | MSE 0.3225
2020-11-05 21:05:01,523 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8788 | Iter Mean Loss 6.8788
2020-11-05 21:05:01,530 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6310 | Iter Mean Loss 4.7549
2020-11-05 21:05:01,538 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3106 | Iter Mean Loss 5.9401
2020-11-05 21:05:01,546 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2594 | Iter Mean Loss 6.2700
2020-11-05 21:05:01,554 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7941 | Iter Mean Loss 5.9748
2020-11-05 21:05:01,556 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.2817 | MSE 0.3225
2020-11-05 21:05:01,565 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8707 | Iter Mean Loss 6.8707
2020-11-05 21:05:01,573 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6277 | Iter Mean Loss 4.7492
2020-11-05 21:05:01,580 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9318
2020-11-05 21:05:01,588 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2475 | Iter Mean Loss 6.2607
2020-11-05 21:05:01,596 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7849 | Iter Mean Loss 5.9655
2020-11-05 21:05:01,598 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.2817 | MSE 0.3224
2020-11-05 21:05:01,606 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8626 | Iter Mean Loss 6.8626
2020-11-05 21:05:01,613 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6244 | Iter Mean Loss 4.7435
2020-11-05 21:05:01,620 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2834 | Iter Mean Loss 5.9235
2020-11-05 21:05:01,627 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2355 | Iter Mean Loss 6.2515
2020-11-05 21:05:01,634 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7758 | Iter Mean Loss 5.9563
2020-11-05 21:05:01,636 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.2817 | MSE 0.3224
2020-11-05 21:05:01,644 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8546 | Iter Mean Loss 6.8546
2020-11-05 21:05:01,651 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6211 | Iter Mean Loss 4.7378
2020-11-05 21:05:01,658 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2698 | Iter Mean Loss 5.9152
2020-11-05 21:05:01,666 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2236 | Iter Mean Loss 6.2423
2020-11-05 21:05:01,673 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7667 | Iter Mean Loss 5.9471
2020-11-05 21:05:01,675 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.2817 | MSE 0.3223
2020-11-05 21:05:01,682 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 6.8466
2020-11-05 21:05:01,690 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6177 | Iter Mean Loss 4.7321
2020-11-05 21:05:01,697 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2563 | Iter Mean Loss 5.9069
2020-11-05 21:05:01,707 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2116 | Iter Mean Loss 6.2331
2020-11-05 21:05:01,716 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7576 | Iter Mean Loss 5.9380
2020-11-05 21:05:01,718 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.2817 | MSE 0.3223
2020-11-05 21:05:01,730 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8386 | Iter Mean Loss 6.8386
2020-11-05 21:05:01,739 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6144 | Iter Mean Loss 4.7265
2020-11-05 21:05:01,749 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2428 | Iter Mean Loss 5.8986
2020-11-05 21:05:01,758 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1998 | Iter Mean Loss 6.2239
2020-11-05 21:05:01,766 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7486 | Iter Mean Loss 5.9288
2020-11-05 21:05:01,768 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.2817 | MSE 0.3222
2020-11-05 21:05:01,777 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8307 | Iter Mean Loss 6.8307
2020-11-05 21:05:01,785 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6110 | Iter Mean Loss 4.7208
2020-11-05 21:05:01,793 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2293 | Iter Mean Loss 5.8903
2020-11-05 21:05:01,800 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1879 | Iter Mean Loss 6.2147
2020-11-05 21:05:01,808 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 5.9197
2020-11-05 21:05:01,810 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.2817 | MSE 0.3221
2020-11-05 21:05:01,817 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8228 | Iter Mean Loss 6.8228
2020-11-05 21:05:01,825 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6076 | Iter Mean Loss 4.7152
2020-11-05 21:05:01,832 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2159 | Iter Mean Loss 5.8821
2020-11-05 21:05:01,839 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1761 | Iter Mean Loss 6.2056
2020-11-05 21:05:01,846 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7305 | Iter Mean Loss 5.9106
2020-11-05 21:05:01,848 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.2817 | MSE 0.3221
2020-11-05 21:05:01,856 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8149 | Iter Mean Loss 6.8149
2020-11-05 21:05:01,863 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6042 | Iter Mean Loss 4.7096
2020-11-05 21:05:01,870 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2025 | Iter Mean Loss 5.8739
2020-11-05 21:05:01,877 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1642 | Iter Mean Loss 6.1965
2020-11-05 21:05:01,884 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7214 | Iter Mean Loss 5.9015
2020-11-05 21:05:01,886 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.2817 | MSE 0.3220
2020-11-05 21:05:01,894 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8070 | Iter Mean Loss 6.8070
2020-11-05 21:05:01,903 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6008 | Iter Mean Loss 4.7039
2020-11-05 21:05:01,910 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1891 | Iter Mean Loss 5.8657
2020-11-05 21:05:01,918 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1524 | Iter Mean Loss 6.1874
2020-11-05 21:05:01,926 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7124 | Iter Mean Loss 5.8924
2020-11-05 21:05:01,928 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.2817 | MSE 0.3220
2020-11-05 21:05:01,936 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7992 | Iter Mean Loss 6.7992
2020-11-05 21:05:01,944 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5974 | Iter Mean Loss 4.6983
2020-11-05 21:05:01,952 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1758 | Iter Mean Loss 5.8575
2020-11-05 21:05:01,960 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1407 | Iter Mean Loss 6.1783
2020-11-05 21:05:01,968 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7034 | Iter Mean Loss 5.8833
2020-11-05 21:05:01,971 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.2817 | MSE 0.3219
2020-11-05 21:05:01,979 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7914 | Iter Mean Loss 6.7914
2020-11-05 21:05:01,986 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5940 | Iter Mean Loss 4.6927
2020-11-05 21:05:01,994 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1625 | Iter Mean Loss 5.8493
2020-11-05 21:05:02,002 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1289 | Iter Mean Loss 6.1692
2020-11-05 21:05:02,010 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6944 | Iter Mean Loss 5.8742
2020-11-05 21:05:02,012 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.2817 | MSE 0.3219
2020-11-05 21:05:02,020 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7837 | Iter Mean Loss 6.7837
2020-11-05 21:05:02,027 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5906 | Iter Mean Loss 4.6871
2020-11-05 21:05:02,034 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1492 | Iter Mean Loss 5.8411
2020-11-05 21:05:02,041 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1172 | Iter Mean Loss 6.1602
2020-11-05 21:05:02,048 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6854 | Iter Mean Loss 5.8652
2020-11-05 21:05:02,050 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.2817 | MSE 0.3218
2020-11-05 21:05:02,058 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7759 | Iter Mean Loss 6.7759
2020-11-05 21:05:02,065 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5871 | Iter Mean Loss 4.6815
2020-11-05 21:05:02,072 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1359 | Iter Mean Loss 5.8330
2020-11-05 21:05:02,080 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1054 | Iter Mean Loss 6.1511
2020-11-05 21:05:02,087 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6764 | Iter Mean Loss 5.8562
2020-11-05 21:05:02,089 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.2817 | MSE 0.3218
2020-11-05 21:05:02,097 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7682 | Iter Mean Loss 6.7682
2020-11-05 21:05:02,105 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5837 | Iter Mean Loss 4.6759
2020-11-05 21:05:02,113 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1227 | Iter Mean Loss 5.8249
2020-11-05 21:05:02,120 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0937 | Iter Mean Loss 6.1421
2020-11-05 21:05:02,129 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6674 | Iter Mean Loss 5.8472
2020-11-05 21:05:02,131 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.2817 | MSE 0.3217
2020-11-05 21:05:02,140 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7605 | Iter Mean Loss 6.7605
2020-11-05 21:05:02,147 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5802 | Iter Mean Loss 4.6704
2020-11-05 21:05:02,155 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 5.8167
2020-11-05 21:05:02,163 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0821 | Iter Mean Loss 6.1331
2020-11-05 21:05:02,171 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6585 | Iter Mean Loss 5.8381
2020-11-05 21:05:02,174 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.2817 | MSE 0.3217
2020-11-05 21:05:02,182 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7529 | Iter Mean Loss 6.7529
2020-11-05 21:05:02,189 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5767 | Iter Mean Loss 4.6648
2020-11-05 21:05:02,197 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0963 | Iter Mean Loss 5.8086
2020-11-05 21:05:02,205 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0704 | Iter Mean Loss 6.1241
2020-11-05 21:05:02,212 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6495 | Iter Mean Loss 5.8292
2020-11-05 21:05:02,214 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.2817 | MSE 0.3216
2020-11-05 21:05:02,221 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7453 | Iter Mean Loss 6.7453
2020-11-05 21:05:02,229 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 4.6592
2020-11-05 21:05:02,236 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0831 | Iter Mean Loss 5.8005
2020-11-05 21:05:02,243 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0588 | Iter Mean Loss 6.1151
2020-11-05 21:05:02,250 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6406 | Iter Mean Loss 5.8202
2020-11-05 21:05:02,252 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.2817 | MSE 0.3216
2020-11-05 21:05:02,260 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7377 | Iter Mean Loss 6.7377
2020-11-05 21:05:02,267 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5696 | Iter Mean Loss 4.6536
2020-11-05 21:05:02,274 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0700 | Iter Mean Loss 5.7924
2020-11-05 21:05:02,281 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0471 | Iter Mean Loss 6.1061
2020-11-05 21:05:02,288 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6316 | Iter Mean Loss 5.8112
2020-11-05 21:05:02,290 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.2817 | MSE 0.3215
2020-11-05 21:05:02,298 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7301 | Iter Mean Loss 6.7301
2020-11-05 21:05:02,306 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5661 | Iter Mean Loss 4.6481
2020-11-05 21:05:02,316 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0569 | Iter Mean Loss 5.7843
2020-11-05 21:05:02,327 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0355 | Iter Mean Loss 6.0971
2020-11-05 21:05:02,335 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6227 | Iter Mean Loss 5.8022
2020-11-05 21:05:02,337 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.2817 | MSE 0.3215
2020-11-05 21:05:02,345 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7225 | Iter Mean Loss 6.7225
2020-11-05 21:05:02,353 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5625 | Iter Mean Loss 4.6425
2020-11-05 21:05:02,361 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0438 | Iter Mean Loss 5.7763
2020-11-05 21:05:02,368 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0239 | Iter Mean Loss 6.0882
2020-11-05 21:05:02,376 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6137 | Iter Mean Loss 5.7933
2020-11-05 21:05:02,378 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.2817 | MSE 0.3214
2020-11-05 21:05:02,386 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7150 | Iter Mean Loss 6.7150
2020-11-05 21:05:02,394 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5589 | Iter Mean Loss 4.6370
2020-11-05 21:05:02,401 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0307 | Iter Mean Loss 5.7682
2020-11-05 21:05:02,410 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0123 | Iter Mean Loss 6.0792
2020-11-05 21:05:02,418 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6048 | Iter Mean Loss 5.7844
2020-11-05 21:05:02,420 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.2817 | MSE 0.3214
2020-11-05 21:05:02,429 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7075 | Iter Mean Loss 6.7075
2020-11-05 21:05:02,437 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5553 | Iter Mean Loss 4.6314
2020-11-05 21:05:02,445 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0176 | Iter Mean Loss 5.7601
2020-11-05 21:05:02,452 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0008 | Iter Mean Loss 6.0703
2020-11-05 21:05:02,460 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5959 | Iter Mean Loss 5.7754
2020-11-05 21:05:02,462 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.2817 | MSE 0.3213
2020-11-05 21:05:02,471 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7000 | Iter Mean Loss 6.7000
2020-11-05 21:05:02,480 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5517 | Iter Mean Loss 4.6258
2020-11-05 21:05:02,489 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0046 | Iter Mean Loss 5.7521
2020-11-05 21:05:02,497 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9892 | Iter Mean Loss 6.0614
2020-11-05 21:05:02,506 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5870 | Iter Mean Loss 5.7665
2020-11-05 21:05:02,510 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.2817 | MSE 0.3213
2020-11-05 21:05:02,520 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6925 | Iter Mean Loss 6.6925
2020-11-05 21:05:02,529 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5480 | Iter Mean Loss 4.6203
2020-11-05 21:05:02,538 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9916 | Iter Mean Loss 5.7441
2020-11-05 21:05:02,546 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9776 | Iter Mean Loss 6.0525
2020-11-05 21:05:02,555 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5781 | Iter Mean Loss 5.7576
2020-11-05 21:05:02,557 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.2817 | MSE 0.3212
2020-11-05 21:05:02,565 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6851 | Iter Mean Loss 6.6851
2020-11-05 21:05:02,573 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5444 | Iter Mean Loss 4.6147
2020-11-05 21:05:02,581 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9786 | Iter Mean Loss 5.7360
2020-11-05 21:05:02,589 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9661 | Iter Mean Loss 6.0435
2020-11-05 21:05:02,596 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5692 | Iter Mean Loss 5.7487
2020-11-05 21:05:02,598 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.2817 | MSE 0.3212
2020-11-05 21:05:02,607 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6777 | Iter Mean Loss 6.6777
2020-11-05 21:05:02,614 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5407 | Iter Mean Loss 4.6092
2020-11-05 21:05:02,621 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9656 | Iter Mean Loss 5.7280
2020-11-05 21:05:02,628 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9546 | Iter Mean Loss 6.0346
2020-11-05 21:05:02,636 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5603 | Iter Mean Loss 5.7398
2020-11-05 21:05:02,638 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.2817 | MSE 0.3211
2020-11-05 21:05:02,645 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6703 | Iter Mean Loss 6.6703
2020-11-05 21:05:02,653 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5370 | Iter Mean Loss 4.6036
2020-11-05 21:05:02,660 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9526 | Iter Mean Loss 5.7200
2020-11-05 21:05:02,668 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9431 | Iter Mean Loss 6.0257
2020-11-05 21:05:02,675 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5514 | Iter Mean Loss 5.7309
2020-11-05 21:05:02,677 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.2817 | MSE 0.3211
2020-11-05 21:05:02,685 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6629 | Iter Mean Loss 6.6629
2020-11-05 21:05:02,692 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5333 | Iter Mean Loss 4.5981
2020-11-05 21:05:02,699 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9397 | Iter Mean Loss 5.7119
2020-11-05 21:05:02,706 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9316 | Iter Mean Loss 6.0169
2020-11-05 21:05:02,713 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5425 | Iter Mean Loss 5.7220
2020-11-05 21:05:02,715 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.2817 | MSE 0.3210
2020-11-05 21:05:02,724 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6556 | Iter Mean Loss 6.6556
2020-11-05 21:05:02,731 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5295 | Iter Mean Loss 4.5925
2020-11-05 21:05:02,740 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9267 | Iter Mean Loss 5.7039
2020-11-05 21:05:02,747 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9201 | Iter Mean Loss 6.0080
2020-11-05 21:05:02,755 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5336 | Iter Mean Loss 5.7131
2020-11-05 21:05:02,757 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.2817 | MSE 0.3210
2020-11-05 21:05:02,765 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6482 | Iter Mean Loss 6.6482
2020-11-05 21:05:02,773 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5257 | Iter Mean Loss 4.5870
2020-11-05 21:05:02,781 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9138 | Iter Mean Loss 5.6959
2020-11-05 21:05:02,789 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 5.9991
2020-11-05 21:05:02,796 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5247 | Iter Mean Loss 5.7042
2020-11-05 21:05:02,798 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.2817 | MSE 0.3209
2020-11-05 21:05:02,806 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6409 | Iter Mean Loss 6.6409
2020-11-05 21:05:02,814 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5219 | Iter Mean Loss 4.5814
2020-11-05 21:05:02,821 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 5.6879
2020-11-05 21:05:02,828 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8971 | Iter Mean Loss 5.9902
2020-11-05 21:05:02,836 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5158 | Iter Mean Loss 5.6953
2020-11-05 21:05:02,838 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.2817 | MSE 0.3209
2020-11-05 21:05:02,845 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6336 | Iter Mean Loss 6.6336
2020-11-05 21:05:02,853 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5181 | Iter Mean Loss 4.5759
2020-11-05 21:05:02,860 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8880 | Iter Mean Loss 5.6799
2020-11-05 21:05:02,867 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8856 | Iter Mean Loss 5.9813
2020-11-05 21:05:02,874 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 5.6865
2020-11-05 21:05:02,876 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.2817 | MSE 0.3208
2020-11-05 21:05:02,884 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6263 | Iter Mean Loss 6.6263
2020-11-05 21:05:02,891 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5143 | Iter Mean Loss 4.5703
2020-11-05 21:05:02,898 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8751 | Iter Mean Loss 5.6719
2020-11-05 21:05:02,906 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8742 | Iter Mean Loss 5.9725
2020-11-05 21:05:02,913 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4980 | Iter Mean Loss 5.6776
2020-11-05 21:05:02,915 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.2817 | MSE 0.3208
2020-11-05 21:05:02,924 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6191 | Iter Mean Loss 6.6191
2020-11-05 21:05:02,932 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5104 | Iter Mean Loss 4.5647
2020-11-05 21:05:02,940 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8623 | Iter Mean Loss 5.6639
2020-11-05 21:05:02,948 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8627 | Iter Mean Loss 5.9636
2020-11-05 21:05:02,955 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4891 | Iter Mean Loss 5.6687
2020-11-05 21:05:02,957 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.2817 | MSE 0.3207
2020-11-05 21:05:02,966 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6118 | Iter Mean Loss 6.6118
2020-11-05 21:05:02,974 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5065 | Iter Mean Loss 4.5592
2020-11-05 21:05:02,982 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 5.6559
2020-11-05 21:05:02,990 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8513 | Iter Mean Loss 5.9547
2020-11-05 21:05:02,998 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4802 | Iter Mean Loss 5.6598
2020-11-05 21:05:03,000 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.2817 | MSE 0.3207
2020-11-05 21:05:03,008 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.6046
2020-11-05 21:05:03,016 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5026 | Iter Mean Loss 4.5536
2020-11-05 21:05:03,024 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8365 | Iter Mean Loss 5.6479
2020-11-05 21:05:03,031 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8398 | Iter Mean Loss 5.9459
2020-11-05 21:05:03,038 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4713 | Iter Mean Loss 5.6510
2020-11-05 21:05:03,040 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:03,048 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5974 | Iter Mean Loss 6.5974
2020-11-05 21:05:03,055 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4986 | Iter Mean Loss 4.5480
2020-11-05 21:05:03,062 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8237 | Iter Mean Loss 5.6399
2020-11-05 21:05:03,069 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8284 | Iter Mean Loss 5.9370
2020-11-05 21:05:03,076 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4624 | Iter Mean Loss 5.6421
2020-11-05 21:05:03,078 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:03,086 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5902 | Iter Mean Loss 6.5902
2020-11-05 21:05:03,093 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4947 | Iter Mean Loss 4.5424
2020-11-05 21:05:03,100 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8109 | Iter Mean Loss 5.6319
2020-11-05 21:05:03,107 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8169 | Iter Mean Loss 5.9282
2020-11-05 21:05:03,114 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 5.6332
2020-11-05 21:05:03,116 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:03,125 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5830 | Iter Mean Loss 6.5830
2020-11-05 21:05:03,133 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4907 | Iter Mean Loss 4.5368
2020-11-05 21:05:03,140 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7981 | Iter Mean Loss 5.6239
2020-11-05 21:05:03,147 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8055 | Iter Mean Loss 5.9193
2020-11-05 21:05:03,156 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4446 | Iter Mean Loss 5.6244
2020-11-05 21:05:03,158 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:03,166 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5758 | Iter Mean Loss 6.5758
2020-11-05 21:05:03,175 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4866 | Iter Mean Loss 4.5312
2020-11-05 21:05:03,182 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7852 | Iter Mean Loss 5.6159
2020-11-05 21:05:03,190 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7941 | Iter Mean Loss 5.9104
2020-11-05 21:05:03,198 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4357 | Iter Mean Loss 5.6155
2020-11-05 21:05:03,201 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:03,209 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5687 | Iter Mean Loss 6.5687
2020-11-05 21:05:03,217 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4826 | Iter Mean Loss 4.5256
2020-11-05 21:05:03,225 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7724 | Iter Mean Loss 5.6079
2020-11-05 21:05:03,232 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7826 | Iter Mean Loss 5.9016
2020-11-05 21:05:03,239 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4268 | Iter Mean Loss 5.6066
2020-11-05 21:05:03,241 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.2817 | MSE 0.3204
2020-11-05 21:05:03,249 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5615 | Iter Mean Loss 6.5615
2020-11-05 21:05:03,256 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4785 | Iter Mean Loss 4.5200
2020-11-05 21:05:03,263 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7596 | Iter Mean Loss 5.5999
2020-11-05 21:05:03,270 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7712 | Iter Mean Loss 5.8927
2020-11-05 21:05:03,277 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 5.5978
2020-11-05 21:05:03,279 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.2817 | MSE 0.3204
2020-11-05 21:05:03,287 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5544 | Iter Mean Loss 6.5544
2020-11-05 21:05:03,294 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4744 | Iter Mean Loss 4.5144
2020-11-05 21:05:03,301 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7468 | Iter Mean Loss 5.5919
2020-11-05 21:05:03,308 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 5.8839
2020-11-05 21:05:03,320 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4090 | Iter Mean Loss 5.5889
2020-11-05 21:05:03,324 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:03,332 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5473 | Iter Mean Loss 6.5473
2020-11-05 21:05:03,340 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4703 | Iter Mean Loss 4.5088
2020-11-05 21:05:03,347 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7340 | Iter Mean Loss 5.5839
2020-11-05 21:05:03,355 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7484 | Iter Mean Loss 5.8750
2020-11-05 21:05:03,363 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 5.5800
2020-11-05 21:05:03,365 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:03,373 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5402 | Iter Mean Loss 6.5402
2020-11-05 21:05:03,381 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4661 | Iter Mean Loss 4.5031
2020-11-05 21:05:03,389 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7212 | Iter Mean Loss 5.5758
2020-11-05 21:05:03,396 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7369 | Iter Mean Loss 5.8661
2020-11-05 21:05:03,404 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3911 | Iter Mean Loss 5.5711
2020-11-05 21:05:03,406 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:03,414 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5331 | Iter Mean Loss 6.5331
2020-11-05 21:05:03,421 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4619 | Iter Mean Loss 4.4975
2020-11-05 21:05:03,429 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7085 | Iter Mean Loss 5.5678
2020-11-05 21:05:03,436 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7255 | Iter Mean Loss 5.8572
2020-11-05 21:05:03,443 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3822 | Iter Mean Loss 5.5622
2020-11-05 21:05:03,446 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:03,453 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5260 | Iter Mean Loss 6.5260
2020-11-05 21:05:03,460 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4576 | Iter Mean Loss 4.4918
2020-11-05 21:05:03,468 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6957 | Iter Mean Loss 5.5598
2020-11-05 21:05:03,475 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7141 | Iter Mean Loss 5.8484
2020-11-05 21:05:03,482 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3733 | Iter Mean Loss 5.5533
2020-11-05 21:05:03,484 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:03,491 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5190 | Iter Mean Loss 6.5190
2020-11-05 21:05:03,499 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 4.4862
2020-11-05 21:05:03,506 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6829 | Iter Mean Loss 5.5518
2020-11-05 21:05:03,513 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7026 | Iter Mean Loss 5.8395
2020-11-05 21:05:03,520 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3643 | Iter Mean Loss 5.5444
2020-11-05 21:05:03,522 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.2817 | MSE 0.3201
2020-11-05 21:05:03,530 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5119 | Iter Mean Loss 6.5119
2020-11-05 21:05:03,537 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4491 | Iter Mean Loss 4.4805
2020-11-05 21:05:03,545 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6701 | Iter Mean Loss 5.5437
2020-11-05 21:05:03,552 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6912 | Iter Mean Loss 5.8306
2020-11-05 21:05:03,560 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3553 | Iter Mean Loss 5.5355
2020-11-05 21:05:03,562 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.2817 | MSE 0.3201
2020-11-05 21:05:03,570 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5049 | Iter Mean Loss 6.5049
2020-11-05 21:05:03,578 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4447 | Iter Mean Loss 4.4748
2020-11-05 21:05:03,586 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6573 | Iter Mean Loss 5.5357
2020-11-05 21:05:03,594 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6798 | Iter Mean Loss 5.8217
2020-11-05 21:05:03,601 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3464 | Iter Mean Loss 5.5266
2020-11-05 21:05:03,604 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:03,612 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4979 | Iter Mean Loss 6.4979
2020-11-05 21:05:03,619 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4404 | Iter Mean Loss 4.4691
2020-11-05 21:05:03,627 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6445 | Iter Mean Loss 5.5276
2020-11-05 21:05:03,635 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6683 | Iter Mean Loss 5.8128
2020-11-05 21:05:03,643 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3374 | Iter Mean Loss 5.5177
2020-11-05 21:05:03,645 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:03,652 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4909 | Iter Mean Loss 6.4909
2020-11-05 21:05:03,660 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4360 | Iter Mean Loss 4.4634
2020-11-05 21:05:03,667 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5195
2020-11-05 21:05:03,674 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6569 | Iter Mean Loss 5.8039
2020-11-05 21:05:03,681 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3284 | Iter Mean Loss 5.5088
2020-11-05 21:05:03,683 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:03,691 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4839 | Iter Mean Loss 6.4839
2020-11-05 21:05:03,698 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4315 | Iter Mean Loss 4.4577
2020-11-05 21:05:03,705 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6190 | Iter Mean Loss 5.5115
2020-11-05 21:05:03,712 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6454 | Iter Mean Loss 5.7949
2020-11-05 21:05:03,719 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3194 | Iter Mean Loss 5.4998
2020-11-05 21:05:03,721 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:03,729 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4769 | Iter Mean Loss 6.4769
2020-11-05 21:05:03,736 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4271 | Iter Mean Loss 4.4520
2020-11-05 21:05:03,744 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6062 | Iter Mean Loss 5.5034
2020-11-05 21:05:03,751 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6339 | Iter Mean Loss 5.7860
2020-11-05 21:05:03,759 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3104 | Iter Mean Loss 5.4909
2020-11-05 21:05:03,761 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:03,769 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4699 | Iter Mean Loss 6.4699
2020-11-05 21:05:03,778 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4226 | Iter Mean Loss 4.4462
2020-11-05 21:05:03,786 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5934 | Iter Mean Loss 5.4953
2020-11-05 21:05:03,795 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6225 | Iter Mean Loss 5.7771
2020-11-05 21:05:03,803 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3014 | Iter Mean Loss 5.4819
2020-11-05 21:05:03,806 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:03,815 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4629 | Iter Mean Loss 6.4629
2020-11-05 21:05:03,824 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4180 | Iter Mean Loss 4.4405
2020-11-05 21:05:03,832 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5806 | Iter Mean Loss 5.4872
2020-11-05 21:05:03,841 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6110 | Iter Mean Loss 5.7681
2020-11-05 21:05:03,849 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2924 | Iter Mean Loss 5.4730
2020-11-05 21:05:03,851 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:03,859 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4560 | Iter Mean Loss 6.4560
2020-11-05 21:05:03,867 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4134 | Iter Mean Loss 4.4347
2020-11-05 21:05:03,875 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5678 | Iter Mean Loss 5.4791
2020-11-05 21:05:03,883 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5995 | Iter Mean Loss 5.7592
2020-11-05 21:05:03,891 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2833 | Iter Mean Loss 5.4640
2020-11-05 21:05:03,893 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:03,901 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4490 | Iter Mean Loss 6.4490
2020-11-05 21:05:03,910 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4088 | Iter Mean Loss 4.4289
2020-11-05 21:05:03,918 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5550 | Iter Mean Loss 5.4709
2020-11-05 21:05:03,925 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5880 | Iter Mean Loss 5.7502
2020-11-05 21:05:03,933 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2743 | Iter Mean Loss 5.4550
2020-11-05 21:05:03,935 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:03,944 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4421 | Iter Mean Loss 6.4421
2020-11-05 21:05:03,951 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4042 | Iter Mean Loss 4.4231
2020-11-05 21:05:03,960 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5422 | Iter Mean Loss 5.4628
2020-11-05 21:05:03,968 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5765 | Iter Mean Loss 5.7412
2020-11-05 21:05:03,977 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2652 | Iter Mean Loss 5.4460
2020-11-05 21:05:03,979 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:03,988 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4351 | Iter Mean Loss 6.4351
2020-11-05 21:05:03,997 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3995 | Iter Mean Loss 4.4173
2020-11-05 21:05:04,004 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5294 | Iter Mean Loss 5.4547
2020-11-05 21:05:04,013 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5650 | Iter Mean Loss 5.7323
2020-11-05 21:05:04,021 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2561 | Iter Mean Loss 5.4370
2020-11-05 21:05:04,025 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:04,034 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4282 | Iter Mean Loss 6.4282
2020-11-05 21:05:04,043 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3948 | Iter Mean Loss 4.4115
2020-11-05 21:05:04,051 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5166 | Iter Mean Loss 5.4465
2020-11-05 21:05:04,058 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5535 | Iter Mean Loss 5.7233
2020-11-05 21:05:04,066 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2470 | Iter Mean Loss 5.4280
2020-11-05 21:05:04,068 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:04,076 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4213 | Iter Mean Loss 6.4213
2020-11-05 21:05:04,084 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3900 | Iter Mean Loss 4.4056
2020-11-05 21:05:04,091 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5037 | Iter Mean Loss 5.4383
2020-11-05 21:05:04,099 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5419 | Iter Mean Loss 5.7142
2020-11-05 21:05:04,106 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2379 | Iter Mean Loss 5.4190
2020-11-05 21:05:04,109 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:04,117 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4144 | Iter Mean Loss 6.4144
2020-11-05 21:05:04,125 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3852 | Iter Mean Loss 4.3998
2020-11-05 21:05:04,132 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4909 | Iter Mean Loss 5.4302
2020-11-05 21:05:04,140 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5304 | Iter Mean Loss 5.7052
2020-11-05 21:05:04,147 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2288 | Iter Mean Loss 5.4099
2020-11-05 21:05:04,149 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:04,158 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4075 | Iter Mean Loss 6.4075
2020-11-05 21:05:04,167 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3803 | Iter Mean Loss 4.3939
2020-11-05 21:05:04,175 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4781 | Iter Mean Loss 5.4220
2020-11-05 21:05:04,184 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5188 | Iter Mean Loss 5.6962
2020-11-05 21:05:04,192 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2197 | Iter Mean Loss 5.4009
2020-11-05 21:05:04,194 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:04,203 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4006 | Iter Mean Loss 6.4006
2020-11-05 21:05:04,211 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3755 | Iter Mean Loss 4.3880
2020-11-05 21:05:04,220 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4652 | Iter Mean Loss 5.4137
2020-11-05 21:05:04,228 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5073 | Iter Mean Loss 5.6871
2020-11-05 21:05:04,236 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2105 | Iter Mean Loss 5.3918
2020-11-05 21:05:04,238 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:04,247 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3937 | Iter Mean Loss 6.3937
2020-11-05 21:05:04,256 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3705 | Iter Mean Loss 4.3821
2020-11-05 21:05:04,263 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4524 | Iter Mean Loss 5.4055
2020-11-05 21:05:04,271 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4957 | Iter Mean Loss 5.6781
2020-11-05 21:05:04,278 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2013 | Iter Mean Loss 5.3827
2020-11-05 21:05:04,280 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:04,288 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3868 | Iter Mean Loss 6.3868
2020-11-05 21:05:04,296 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3656 | Iter Mean Loss 4.3762
2020-11-05 21:05:04,303 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4395 | Iter Mean Loss 5.3973
2020-11-05 21:05:04,312 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4841 | Iter Mean Loss 5.6690
2020-11-05 21:05:04,325 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1922 | Iter Mean Loss 5.3736
2020-11-05 21:05:04,327 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:04,335 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3799 | Iter Mean Loss 6.3799
2020-11-05 21:05:04,343 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3606 | Iter Mean Loss 4.3702
2020-11-05 21:05:04,351 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4266 | Iter Mean Loss 5.3890
2020-11-05 21:05:04,358 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4725 | Iter Mean Loss 5.6599
2020-11-05 21:05:04,366 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1830 | Iter Mean Loss 5.3645
2020-11-05 21:05:04,369 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:04,377 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3730 | Iter Mean Loss 6.3730
2020-11-05 21:05:04,385 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3555 | Iter Mean Loss 4.3643
2020-11-05 21:05:04,394 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4137 | Iter Mean Loss 5.3807
2020-11-05 21:05:04,401 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4609 | Iter Mean Loss 5.6508
2020-11-05 21:05:04,409 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1737 | Iter Mean Loss 5.3554
2020-11-05 21:05:04,412 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:04,420 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 6.3662
2020-11-05 21:05:04,429 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3504 | Iter Mean Loss 4.3583
2020-11-05 21:05:04,436 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4008 | Iter Mean Loss 5.3725
2020-11-05 21:05:04,444 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4493 | Iter Mean Loss 5.6417
2020-11-05 21:05:04,452 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1645 | Iter Mean Loss 5.3462
2020-11-05 21:05:04,454 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:04,463 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3593 | Iter Mean Loss 6.3593
2020-11-05 21:05:04,471 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3453 | Iter Mean Loss 4.3523
2020-11-05 21:05:04,478 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3879 | Iter Mean Loss 5.3642
2020-11-05 21:05:04,486 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4376 | Iter Mean Loss 5.6325
2020-11-05 21:05:04,493 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1552 | Iter Mean Loss 5.3371
2020-11-05 21:05:04,495 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:04,503 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3524 | Iter Mean Loss 6.3524
2020-11-05 21:05:04,511 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3401 | Iter Mean Loss 4.3463
2020-11-05 21:05:04,518 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3750 | Iter Mean Loss 5.3558
2020-11-05 21:05:04,525 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4259 | Iter Mean Loss 5.6234
2020-11-05 21:05:04,533 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1460 | Iter Mean Loss 5.3279
2020-11-05 21:05:04,535 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:04,543 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3456 | Iter Mean Loss 6.3456
2020-11-05 21:05:04,550 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3349 | Iter Mean Loss 4.3403
2020-11-05 21:05:04,557 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3620 | Iter Mean Loss 5.3475
2020-11-05 21:05:04,565 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4143 | Iter Mean Loss 5.6142
2020-11-05 21:05:04,572 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1367 | Iter Mean Loss 5.3187
2020-11-05 21:05:04,574 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:04,583 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3388 | Iter Mean Loss 6.3388
2020-11-05 21:05:04,591 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3297 | Iter Mean Loss 4.3342
2020-11-05 21:05:04,599 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3491 | Iter Mean Loss 5.3392
2020-11-05 21:05:04,607 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4026 | Iter Mean Loss 5.6050
2020-11-05 21:05:04,614 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1274 | Iter Mean Loss 5.3095
2020-11-05 21:05:04,617 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:04,626 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3319 | Iter Mean Loss 6.3319
2020-11-05 21:05:04,634 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3244 | Iter Mean Loss 4.3281
2020-11-05 21:05:04,642 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3361 | Iter Mean Loss 5.3308
2020-11-05 21:05:04,650 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3909 | Iter Mean Loss 5.5958
2020-11-05 21:05:04,658 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1180 | Iter Mean Loss 5.3002
2020-11-05 21:05:04,660 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:04,669 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3251 | Iter Mean Loss 6.3251
2020-11-05 21:05:04,677 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3190 | Iter Mean Loss 4.3220
2020-11-05 21:05:04,684 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3231 | Iter Mean Loss 5.3224
2020-11-05 21:05:04,691 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3791 | Iter Mean Loss 5.5866
2020-11-05 21:05:04,698 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1087 | Iter Mean Loss 5.2910
2020-11-05 21:05:04,700 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:04,708 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3183 | Iter Mean Loss 6.3183
2020-11-05 21:05:04,716 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3136 | Iter Mean Loss 4.3159
2020-11-05 21:05:04,723 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3101 | Iter Mean Loss 5.3140
2020-11-05 21:05:04,730 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3674 | Iter Mean Loss 5.5773
2020-11-05 21:05:04,738 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0993 | Iter Mean Loss 5.2817
2020-11-05 21:05:04,740 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:04,747 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3114 | Iter Mean Loss 6.3114
2020-11-05 21:05:04,755 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3082 | Iter Mean Loss 4.3098
2020-11-05 21:05:04,762 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2971 | Iter Mean Loss 5.3056
2020-11-05 21:05:04,769 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3556 | Iter Mean Loss 5.5681
2020-11-05 21:05:04,777 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 5.2725
2020-11-05 21:05:04,779 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:04,788 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3046 | Iter Mean Loss 6.3046
2020-11-05 21:05:04,795 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3027 | Iter Mean Loss 4.3037
2020-11-05 21:05:04,803 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2841 | Iter Mean Loss 5.2971
2020-11-05 21:05:04,811 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3438 | Iter Mean Loss 5.5588
2020-11-05 21:05:04,818 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0805 | Iter Mean Loss 5.2632
2020-11-05 21:05:04,820 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:04,829 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2978 | Iter Mean Loss 6.2978
2020-11-05 21:05:04,837 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2972 | Iter Mean Loss 4.2975
2020-11-05 21:05:04,845 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2710 | Iter Mean Loss 5.2887
2020-11-05 21:05:04,852 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3320 | Iter Mean Loss 5.5495
2020-11-05 21:05:04,860 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 5.2538
2020-11-05 21:05:04,862 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:04,870 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2910 | Iter Mean Loss 6.2910
2020-11-05 21:05:04,878 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 4.2913
2020-11-05 21:05:04,886 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2580 | Iter Mean Loss 5.2802
2020-11-05 21:05:04,893 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3202 | Iter Mean Loss 5.5402
2020-11-05 21:05:04,900 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0616 | Iter Mean Loss 5.2445
2020-11-05 21:05:04,903 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:04,911 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2842 | Iter Mean Loss 6.2842
2020-11-05 21:05:04,919 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2860 | Iter Mean Loss 4.2851
2020-11-05 21:05:04,926 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2449 | Iter Mean Loss 5.2717
2020-11-05 21:05:04,933 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3084 | Iter Mean Loss 5.5309
2020-11-05 21:05:04,940 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0522 | Iter Mean Loss 5.2351
2020-11-05 21:05:04,942 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:04,950 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2774 | Iter Mean Loss 6.2774
2020-11-05 21:05:04,957 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2804 | Iter Mean Loss 4.2789
2020-11-05 21:05:04,964 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2318 | Iter Mean Loss 5.2632
2020-11-05 21:05:04,972 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2966 | Iter Mean Loss 5.5215
2020-11-05 21:05:04,980 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0427 | Iter Mean Loss 5.2258
2020-11-05 21:05:04,982 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:04,990 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 6.2706
2020-11-05 21:05:04,998 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2747 | Iter Mean Loss 4.2727
2020-11-05 21:05:05,005 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2187 | Iter Mean Loss 5.2547
2020-11-05 21:05:05,014 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2847 | Iter Mean Loss 5.5122
2020-11-05 21:05:05,022 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0332 | Iter Mean Loss 5.2164
2020-11-05 21:05:05,024 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:05,033 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2639 | Iter Mean Loss 6.2639
2020-11-05 21:05:05,041 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2690 | Iter Mean Loss 4.2664
2020-11-05 21:05:05,049 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2056 | Iter Mean Loss 5.2461
2020-11-05 21:05:05,056 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2728 | Iter Mean Loss 5.5028
2020-11-05 21:05:05,064 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0236 | Iter Mean Loss 5.2070
2020-11-05 21:05:05,067 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:05,075 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2571 | Iter Mean Loss 6.2571
2020-11-05 21:05:05,083 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2632 | Iter Mean Loss 4.2601
2020-11-05 21:05:05,090 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1925 | Iter Mean Loss 5.2376
2020-11-05 21:05:05,098 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2609 | Iter Mean Loss 5.4934
2020-11-05 21:05:05,105 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 5.1975
2020-11-05 21:05:05,107 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:05,114 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2503 | Iter Mean Loss 6.2503
2020-11-05 21:05:05,122 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2574 | Iter Mean Loss 4.2538
2020-11-05 21:05:05,129 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1793 | Iter Mean Loss 5.2290
2020-11-05 21:05:05,136 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2490 | Iter Mean Loss 5.4840
2020-11-05 21:05:05,143 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0045 | Iter Mean Loss 5.1881
2020-11-05 21:05:05,145 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:05,153 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2436 | Iter Mean Loss 6.2436
2020-11-05 21:05:05,161 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2515 | Iter Mean Loss 4.2475
2020-11-05 21:05:05,168 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1661 | Iter Mean Loss 5.2204
2020-11-05 21:05:05,175 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2370 | Iter Mean Loss 5.4746
2020-11-05 21:05:05,183 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9949 | Iter Mean Loss 5.1786
2020-11-05 21:05:05,185 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:05,193 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2368 | Iter Mean Loss 6.2368
2020-11-05 21:05:05,201 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2456 | Iter Mean Loss 4.2412
2020-11-05 21:05:05,209 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1530 | Iter Mean Loss 5.2118
2020-11-05 21:05:05,217 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2251 | Iter Mean Loss 5.4651
2020-11-05 21:05:05,224 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9853 | Iter Mean Loss 5.1691
2020-11-05 21:05:05,227 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:05,235 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2300 | Iter Mean Loss 6.2300
2020-11-05 21:05:05,243 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2397 | Iter Mean Loss 4.2349
2020-11-05 21:05:05,251 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1398 | Iter Mean Loss 5.2032
2020-11-05 21:05:05,258 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.4556
2020-11-05 21:05:05,266 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9757 | Iter Mean Loss 5.1596
2020-11-05 21:05:05,268 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:05,276 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2233 | Iter Mean Loss 6.2233
2020-11-05 21:05:05,284 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2337 | Iter Mean Loss 4.2285
2020-11-05 21:05:05,292 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1266 | Iter Mean Loss 5.1945
2020-11-05 21:05:05,299 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2011 | Iter Mean Loss 5.4462
2020-11-05 21:05:05,306 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9660 | Iter Mean Loss 5.1501
2020-11-05 21:05:05,308 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:05,316 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2166 | Iter Mean Loss 6.2166
2020-11-05 21:05:05,324 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2276 | Iter Mean Loss 4.2221
2020-11-05 21:05:05,332 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1133 | Iter Mean Loss 5.1859
2020-11-05 21:05:05,339 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1891 | Iter Mean Loss 5.4367
2020-11-05 21:05:05,346 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9563 | Iter Mean Loss 5.1406
2020-11-05 21:05:05,348 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:05,356 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2098 | Iter Mean Loss 6.2098
2020-11-05 21:05:05,363 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2216 | Iter Mean Loss 4.2157
2020-11-05 21:05:05,370 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1001 | Iter Mean Loss 5.1772
2020-11-05 21:05:05,377 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1771 | Iter Mean Loss 5.4271
2020-11-05 21:05:05,385 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9466 | Iter Mean Loss 5.1310
2020-11-05 21:05:05,387 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:05,395 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2031 | Iter Mean Loss 6.2031
2020-11-05 21:05:05,403 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2155 | Iter Mean Loss 4.2093
2020-11-05 21:05:05,412 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0869 | Iter Mean Loss 5.1685
2020-11-05 21:05:05,422 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1650 | Iter Mean Loss 5.4176
2020-11-05 21:05:05,433 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9369 | Iter Mean Loss 5.1215
2020-11-05 21:05:05,435 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:05,444 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1964 | Iter Mean Loss 6.1964
2020-11-05 21:05:05,453 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2093 | Iter Mean Loss 4.2029
2020-11-05 21:05:05,463 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0736 | Iter Mean Loss 5.1598
2020-11-05 21:05:05,473 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1530 | Iter Mean Loss 5.4081
2020-11-05 21:05:05,483 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9272 | Iter Mean Loss 5.1119
2020-11-05 21:05:05,486 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:05,495 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1897 | Iter Mean Loss 6.1897
2020-11-05 21:05:05,504 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2031 | Iter Mean Loss 4.1964
2020-11-05 21:05:05,512 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0603 | Iter Mean Loss 5.1510
2020-11-05 21:05:05,519 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1409 | Iter Mean Loss 5.3985
2020-11-05 21:05:05,527 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9175 | Iter Mean Loss 5.1023
2020-11-05 21:05:05,529 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:05,537 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 6.1830
2020-11-05 21:05:05,545 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1969 | Iter Mean Loss 4.1899
2020-11-05 21:05:05,553 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0470 | Iter Mean Loss 5.1423
2020-11-05 21:05:05,560 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1288 | Iter Mean Loss 5.3889
2020-11-05 21:05:05,569 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9077 | Iter Mean Loss 5.0927
2020-11-05 21:05:05,571 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:05,579 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1763 | Iter Mean Loss 6.1763
2020-11-05 21:05:05,588 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 4.1835
2020-11-05 21:05:05,596 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0337 | Iter Mean Loss 5.1336
2020-11-05 21:05:05,604 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1167 | Iter Mean Loss 5.3793
2020-11-05 21:05:05,612 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8979 | Iter Mean Loss 5.0830
2020-11-05 21:05:05,614 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:05,623 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1696 | Iter Mean Loss 6.1696
2020-11-05 21:05:05,630 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1843 | Iter Mean Loss 4.1770
2020-11-05 21:05:05,639 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0204 | Iter Mean Loss 5.1248
2020-11-05 21:05:05,647 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1045 | Iter Mean Loss 5.3697
2020-11-05 21:05:05,655 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8881 | Iter Mean Loss 5.0734
2020-11-05 21:05:05,658 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:05,666 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1630 | Iter Mean Loss 6.1630
2020-11-05 21:05:05,674 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1780 | Iter Mean Loss 4.1705
2020-11-05 21:05:05,682 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0071 | Iter Mean Loss 5.1160
2020-11-05 21:05:05,690 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0924 | Iter Mean Loss 5.3601
2020-11-05 21:05:05,698 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8783 | Iter Mean Loss 5.0637
2020-11-05 21:05:05,700 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:05,707 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1563 | Iter Mean Loss 6.1563
2020-11-05 21:05:05,715 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1716 | Iter Mean Loss 4.1640
2020-11-05 21:05:05,722 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9937 | Iter Mean Loss 5.1072
2020-11-05 21:05:05,729 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0803 | Iter Mean Loss 5.3505
2020-11-05 21:05:05,736 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8685 | Iter Mean Loss 5.0541
2020-11-05 21:05:05,738 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:05,745 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 6.1497
2020-11-05 21:05:05,753 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1652 | Iter Mean Loss 4.1574
2020-11-05 21:05:05,760 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9804 | Iter Mean Loss 5.0984
2020-11-05 21:05:05,767 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0681 | Iter Mean Loss 5.3408
2020-11-05 21:05:05,774 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8586 | Iter Mean Loss 5.0444
2020-11-05 21:05:05,776 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:05,784 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1430 | Iter Mean Loss 6.1430
2020-11-05 21:05:05,792 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1588 | Iter Mean Loss 4.1509
2020-11-05 21:05:05,800 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9670 | Iter Mean Loss 5.0896
2020-11-05 21:05:05,808 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0559 | Iter Mean Loss 5.3312
2020-11-05 21:05:05,816 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8488 | Iter Mean Loss 5.0347
2020-11-05 21:05:05,819 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:05,827 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1364 | Iter Mean Loss 6.1364
2020-11-05 21:05:05,835 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1523 | Iter Mean Loss 4.1443
2020-11-05 21:05:05,843 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9537 | Iter Mean Loss 5.0808
2020-11-05 21:05:05,851 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0437 | Iter Mean Loss 5.3215
2020-11-05 21:05:05,859 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8389 | Iter Mean Loss 5.0250
2020-11-05 21:05:05,861 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:05,870 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1298 | Iter Mean Loss 6.1298
2020-11-05 21:05:05,878 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1458 | Iter Mean Loss 4.1378
2020-11-05 21:05:05,885 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9403 | Iter Mean Loss 5.0719
2020-11-05 21:05:05,893 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0315 | Iter Mean Loss 5.3118
2020-11-05 21:05:05,901 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8290 | Iter Mean Loss 5.0153
2020-11-05 21:05:05,903 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:05,911 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1232 | Iter Mean Loss 6.1232
2020-11-05 21:05:05,918 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1392 | Iter Mean Loss 4.1312
2020-11-05 21:05:05,926 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9269 | Iter Mean Loss 5.0631
2020-11-05 21:05:05,933 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0193 | Iter Mean Loss 5.3022
2020-11-05 21:05:05,940 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8191 | Iter Mean Loss 5.0055
2020-11-05 21:05:05,942 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:05,949 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1166 | Iter Mean Loss 6.1166
2020-11-05 21:05:05,957 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1327 | Iter Mean Loss 4.1246
2020-11-05 21:05:05,964 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9135 | Iter Mean Loss 5.0543
2020-11-05 21:05:05,972 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0071 | Iter Mean Loss 5.2925
2020-11-05 21:05:05,980 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8092 | Iter Mean Loss 4.9958
2020-11-05 21:05:05,982 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:05,990 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1100 | Iter Mean Loss 6.1100
2020-11-05 21:05:05,998 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1261 | Iter Mean Loss 4.1180
2020-11-05 21:05:06,006 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9002 | Iter Mean Loss 5.0454
2020-11-05 21:05:06,013 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9949 | Iter Mean Loss 5.2828
2020-11-05 21:05:06,021 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7993 | Iter Mean Loss 4.9861
2020-11-05 21:05:06,023 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:06,033 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1034 | Iter Mean Loss 6.1034
2020-11-05 21:05:06,040 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1195 | Iter Mean Loss 4.1114
2020-11-05 21:05:06,049 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 5.0366
2020-11-05 21:05:06,056 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9827 | Iter Mean Loss 5.2731
2020-11-05 21:05:06,065 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7893 | Iter Mean Loss 4.9763
2020-11-05 21:05:06,067 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:06,075 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0969 | Iter Mean Loss 6.0969
2020-11-05 21:05:06,083 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1128 | Iter Mean Loss 4.1048
2020-11-05 21:05:06,091 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8734 | Iter Mean Loss 5.0277
2020-11-05 21:05:06,098 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9704 | Iter Mean Loss 5.2634
2020-11-05 21:05:06,106 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7794 | Iter Mean Loss 4.9666
2020-11-05 21:05:06,108 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:06,115 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0903 | Iter Mean Loss 6.0903
2020-11-05 21:05:06,123 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1062 | Iter Mean Loss 4.0982
2020-11-05 21:05:06,130 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8600 | Iter Mean Loss 5.0188
2020-11-05 21:05:06,137 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9582 | Iter Mean Loss 5.2537
2020-11-05 21:05:06,144 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7695 | Iter Mean Loss 4.9568
2020-11-05 21:05:06,146 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:06,154 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0838 | Iter Mean Loss 6.0838
2020-11-05 21:05:06,161 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0995 | Iter Mean Loss 4.0916
2020-11-05 21:05:06,168 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 5.0100
2020-11-05 21:05:06,175 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9459 | Iter Mean Loss 5.2440
2020-11-05 21:05:06,183 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7595 | Iter Mean Loss 4.9471
2020-11-05 21:05:06,185 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:06,193 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0773 | Iter Mean Loss 6.0773
2020-11-05 21:05:06,201 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0928 | Iter Mean Loss 4.0850
2020-11-05 21:05:06,208 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8332 | Iter Mean Loss 5.0011
2020-11-05 21:05:06,217 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9337 | Iter Mean Loss 5.2342
2020-11-05 21:05:06,224 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7495 | Iter Mean Loss 4.9373
2020-11-05 21:05:06,227 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:06,236 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0708 | Iter Mean Loss 6.0708
2020-11-05 21:05:06,244 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0860 | Iter Mean Loss 4.0784
2020-11-05 21:05:06,252 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8198 | Iter Mean Loss 4.9922
2020-11-05 21:05:06,260 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9215 | Iter Mean Loss 5.2245
2020-11-05 21:05:06,268 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7396 | Iter Mean Loss 4.9275
2020-11-05 21:05:06,270 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:06,278 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0643 | Iter Mean Loss 6.0643
2020-11-05 21:05:06,287 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0793 | Iter Mean Loss 4.0718
2020-11-05 21:05:06,295 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8064 | Iter Mean Loss 4.9834
2020-11-05 21:05:06,303 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9092 | Iter Mean Loss 5.2148
2020-11-05 21:05:06,310 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7296 | Iter Mean Loss 4.9178
2020-11-05 21:05:06,312 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,321 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0579 | Iter Mean Loss 6.0579
2020-11-05 21:05:06,329 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0725 | Iter Mean Loss 4.0652
2020-11-05 21:05:06,336 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7931 | Iter Mean Loss 4.9745
2020-11-05 21:05:06,343 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8970 | Iter Mean Loss 5.2051
2020-11-05 21:05:06,350 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7197 | Iter Mean Loss 4.9080
2020-11-05 21:05:06,352 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,360 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0514 | Iter Mean Loss 6.0514
2020-11-05 21:05:06,368 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0657 | Iter Mean Loss 4.0586
2020-11-05 21:05:06,375 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7797 | Iter Mean Loss 4.9656
2020-11-05 21:05:06,382 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8847 | Iter Mean Loss 5.1954
2020-11-05 21:05:06,389 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7097 | Iter Mean Loss 4.8983
2020-11-05 21:05:06,391 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,399 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0450 | Iter Mean Loss 6.0450
2020-11-05 21:05:06,408 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0589 | Iter Mean Loss 4.0520
2020-11-05 21:05:06,416 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7664 | Iter Mean Loss 4.9568
2020-11-05 21:05:06,423 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8725 | Iter Mean Loss 5.1857
2020-11-05 21:05:06,431 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6998 | Iter Mean Loss 4.8885
2020-11-05 21:05:06,433 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,442 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0386 | Iter Mean Loss 6.0386
2020-11-05 21:05:06,450 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0521 | Iter Mean Loss 4.0454
2020-11-05 21:05:06,458 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7530 | Iter Mean Loss 4.9479
2020-11-05 21:05:06,466 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8603 | Iter Mean Loss 5.1760
2020-11-05 21:05:06,475 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6898 | Iter Mean Loss 4.8788
2020-11-05 21:05:06,477 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,485 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0322 | Iter Mean Loss 6.0322
2020-11-05 21:05:06,493 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0453 | Iter Mean Loss 4.0388
2020-11-05 21:05:06,500 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7397 | Iter Mean Loss 4.9391
2020-11-05 21:05:06,508 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8481 | Iter Mean Loss 5.1663
2020-11-05 21:05:06,516 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6799 | Iter Mean Loss 4.8690
2020-11-05 21:05:06,518 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,525 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0259 | Iter Mean Loss 6.0259
2020-11-05 21:05:06,533 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0385 | Iter Mean Loss 4.0322
2020-11-05 21:05:06,540 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7264 | Iter Mean Loss 4.9303
2020-11-05 21:05:06,547 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.1567
2020-11-05 21:05:06,554 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6699 | Iter Mean Loss 4.8593
2020-11-05 21:05:06,556 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:06,564 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0195 | Iter Mean Loss 6.0195
2020-11-05 21:05:06,571 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0317 | Iter Mean Loss 4.0256
2020-11-05 21:05:06,578 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7131 | Iter Mean Loss 4.9214
2020-11-05 21:05:06,585 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8237 | Iter Mean Loss 5.1470
2020-11-05 21:05:06,592 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6600 | Iter Mean Loss 4.8496
2020-11-05 21:05:06,594 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,602 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0132 | Iter Mean Loss 6.0132
2020-11-05 21:05:06,610 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0249 | Iter Mean Loss 4.0191
2020-11-05 21:05:06,617 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6998 | Iter Mean Loss 4.9126
2020-11-05 21:05:06,625 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8115 | Iter Mean Loss 5.1373
2020-11-05 21:05:06,632 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6501 | Iter Mean Loss 4.8399
2020-11-05 21:05:06,634 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,643 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0069 | Iter Mean Loss 6.0069
2020-11-05 21:05:06,650 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0181 | Iter Mean Loss 4.0125
2020-11-05 21:05:06,659 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6865 | Iter Mean Loss 4.9038
2020-11-05 21:05:06,666 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7993 | Iter Mean Loss 5.1277
2020-11-05 21:05:06,674 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6401 | Iter Mean Loss 4.8302
2020-11-05 21:05:06,676 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,684 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0007 | Iter Mean Loss 6.0007
2020-11-05 21:05:06,692 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0112 | Iter Mean Loss 4.0059
2020-11-05 21:05:06,699 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6733 | Iter Mean Loss 4.8950
2020-11-05 21:05:06,706 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7872 | Iter Mean Loss 5.1181
2020-11-05 21:05:06,714 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6302 | Iter Mean Loss 4.8205
2020-11-05 21:05:06,717 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,724 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9944 | Iter Mean Loss 5.9944
2020-11-05 21:05:06,732 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0044 | Iter Mean Loss 3.9994
2020-11-05 21:05:06,739 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 4.8863
2020-11-05 21:05:06,746 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7751 | Iter Mean Loss 5.1085
2020-11-05 21:05:06,753 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6204 | Iter Mean Loss 4.8109
2020-11-05 21:05:06,755 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,763 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9882 | Iter Mean Loss 5.9882
2020-11-05 21:05:06,770 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9976 | Iter Mean Loss 3.9929
2020-11-05 21:05:06,777 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6468 | Iter Mean Loss 4.8775
2020-11-05 21:05:06,784 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7629 | Iter Mean Loss 5.0989
2020-11-05 21:05:06,791 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6105 | Iter Mean Loss 4.8012
2020-11-05 21:05:06,793 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,801 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9820 | Iter Mean Loss 5.9820
2020-11-05 21:05:06,808 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9908 | Iter Mean Loss 3.9864
2020-11-05 21:05:06,815 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6337 | Iter Mean Loss 4.8688
2020-11-05 21:05:06,823 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7509 | Iter Mean Loss 5.0893
2020-11-05 21:05:06,830 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6006 | Iter Mean Loss 4.7916
2020-11-05 21:05:06,832 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,841 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9758 | Iter Mean Loss 5.9758
2020-11-05 21:05:06,849 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9840 | Iter Mean Loss 3.9799
2020-11-05 21:05:06,857 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6205 | Iter Mean Loss 4.8601
2020-11-05 21:05:06,864 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7388 | Iter Mean Loss 5.0798
2020-11-05 21:05:06,872 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5908 | Iter Mean Loss 4.7820
2020-11-05 21:05:06,874 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:06,882 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9696 | Iter Mean Loss 5.9696
2020-11-05 21:05:06,890 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9772 | Iter Mean Loss 3.9734
2020-11-05 21:05:06,898 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6074 | Iter Mean Loss 4.8514
2020-11-05 21:05:06,906 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7268 | Iter Mean Loss 5.0702
2020-11-05 21:05:06,913 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5810 | Iter Mean Loss 4.7724
2020-11-05 21:05:06,915 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:06,923 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9635 | Iter Mean Loss 5.9635
2020-11-05 21:05:06,930 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9704 | Iter Mean Loss 3.9670
2020-11-05 21:05:06,938 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5943 | Iter Mean Loss 4.8427
2020-11-05 21:05:06,945 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7148 | Iter Mean Loss 5.0607
2020-11-05 21:05:06,952 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5712 | Iter Mean Loss 4.7628
2020-11-05 21:05:06,954 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:06,962 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9574 | Iter Mean Loss 5.9574
2020-11-05 21:05:06,969 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9637 | Iter Mean Loss 3.9605
2020-11-05 21:05:06,977 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5813 | Iter Mean Loss 4.8341
2020-11-05 21:05:06,984 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7028 | Iter Mean Loss 5.0513
2020-11-05 21:05:06,991 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5615 | Iter Mean Loss 4.7533
2020-11-05 21:05:06,994 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,001 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9513 | Iter Mean Loss 5.9513
2020-11-05 21:05:07,009 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9569 | Iter Mean Loss 3.9541
2020-11-05 21:05:07,016 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5683 | Iter Mean Loss 4.8255
2020-11-05 21:05:07,023 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6908 | Iter Mean Loss 5.0418
2020-11-05 21:05:07,031 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5517 | Iter Mean Loss 4.7438
2020-11-05 21:05:07,033 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,042 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9453 | Iter Mean Loss 5.9453
2020-11-05 21:05:07,049 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9502 | Iter Mean Loss 3.9477
2020-11-05 21:05:07,057 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5553 | Iter Mean Loss 4.8169
2020-11-05 21:05:07,065 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6789 | Iter Mean Loss 5.0324
2020-11-05 21:05:07,073 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5420 | Iter Mean Loss 4.7343
2020-11-05 21:05:07,075 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,083 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9393 | Iter Mean Loss 5.9393
2020-11-05 21:05:07,091 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9435 | Iter Mean Loss 3.9414
2020-11-05 21:05:07,099 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5423 | Iter Mean Loss 4.8084
2020-11-05 21:05:07,106 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6670 | Iter Mean Loss 5.0230
2020-11-05 21:05:07,114 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5323 | Iter Mean Loss 4.7249
2020-11-05 21:05:07,117 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,125 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9333 | Iter Mean Loss 5.9333
2020-11-05 21:05:07,132 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9368 | Iter Mean Loss 3.9350
2020-11-05 21:05:07,139 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5294 | Iter Mean Loss 4.7998
2020-11-05 21:05:07,146 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6552 | Iter Mean Loss 5.0137
2020-11-05 21:05:07,154 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5227 | Iter Mean Loss 4.7155
2020-11-05 21:05:07,155 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,163 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9273 | Iter Mean Loss 5.9273
2020-11-05 21:05:07,170 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9301 | Iter Mean Loss 3.9287
2020-11-05 21:05:07,178 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5166 | Iter Mean Loss 4.7913
2020-11-05 21:05:07,185 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6434 | Iter Mean Loss 5.0043
2020-11-05 21:05:07,192 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5131 | Iter Mean Loss 4.7061
2020-11-05 21:05:07,194 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,201 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9214 | Iter Mean Loss 5.9214
2020-11-05 21:05:07,209 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9235 | Iter Mean Loss 3.9224
2020-11-05 21:05:07,216 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5038 | Iter Mean Loss 4.7829
2020-11-05 21:05:07,223 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6316 | Iter Mean Loss 4.9951
2020-11-05 21:05:07,231 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 4.6967
2020-11-05 21:05:07,233 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,241 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9154 | Iter Mean Loss 5.9154
2020-11-05 21:05:07,249 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9169 | Iter Mean Loss 3.9162
2020-11-05 21:05:07,257 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4910 | Iter Mean Loss 4.7745
2020-11-05 21:05:07,264 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6199 | Iter Mean Loss 4.9858
2020-11-05 21:05:07,272 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4939 | Iter Mean Loss 4.6874
2020-11-05 21:05:07,274 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,283 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9096 | Iter Mean Loss 5.9096
2020-11-05 21:05:07,291 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9103 | Iter Mean Loss 3.9100
2020-11-05 21:05:07,299 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4783 | Iter Mean Loss 4.7661
2020-11-05 21:05:07,306 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 4.9766
2020-11-05 21:05:07,314 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4844 | Iter Mean Loss 4.6782
2020-11-05 21:05:07,318 - root - INFO - Evaluate: Epoch 0647 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,326 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9037 | Iter Mean Loss 5.9037
2020-11-05 21:05:07,334 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9038 | Iter Mean Loss 3.9038
2020-11-05 21:05:07,341 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4656 | Iter Mean Loss 4.7577
2020-11-05 21:05:07,348 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5966 | Iter Mean Loss 4.9674
2020-11-05 21:05:07,355 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4749 | Iter Mean Loss 4.6689
2020-11-05 21:05:07,357 - root - INFO - Evaluate: Epoch 0648 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,365 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8979 | Iter Mean Loss 5.8979
2020-11-05 21:05:07,372 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8973 | Iter Mean Loss 3.8976
2020-11-05 21:05:07,379 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4530 | Iter Mean Loss 4.7494
2020-11-05 21:05:07,386 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5850 | Iter Mean Loss 4.9583
2020-11-05 21:05:07,394 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4655 | Iter Mean Loss 4.6597
2020-11-05 21:05:07,395 - root - INFO - Evaluate: Epoch 0649 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,404 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8921 | Iter Mean Loss 5.8921
2020-11-05 21:05:07,412 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8908 | Iter Mean Loss 3.8915
2020-11-05 21:05:07,419 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4404 | Iter Mean Loss 4.7411
2020-11-05 21:05:07,426 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5734 | Iter Mean Loss 4.9492
2020-11-05 21:05:07,434 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4561 | Iter Mean Loss 4.6506
2020-11-05 21:05:07,436 - root - INFO - Evaluate: Epoch 0650 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,445 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8864 | Iter Mean Loss 5.8864
2020-11-05 21:05:07,453 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8844 | Iter Mean Loss 3.8854
2020-11-05 21:05:07,461 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4279 | Iter Mean Loss 4.7329
2020-11-05 21:05:07,468 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5619 | Iter Mean Loss 4.9402
2020-11-05 21:05:07,477 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4468 | Iter Mean Loss 4.6415
2020-11-05 21:05:07,479 - root - INFO - Evaluate: Epoch 0651 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,488 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8806 | Iter Mean Loss 5.8806
2020-11-05 21:05:07,496 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8780 | Iter Mean Loss 3.8793
2020-11-05 21:05:07,504 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4154 | Iter Mean Loss 4.7247
2020-11-05 21:05:07,511 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5505 | Iter Mean Loss 4.9311
2020-11-05 21:05:07,519 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4375 | Iter Mean Loss 4.6324
2020-11-05 21:05:07,521 - root - INFO - Evaluate: Epoch 0652 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,530 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8749 | Iter Mean Loss 5.8749
2020-11-05 21:05:07,537 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8717 | Iter Mean Loss 3.8733
2020-11-05 21:05:07,545 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4030 | Iter Mean Loss 4.7165
2020-11-05 21:05:07,552 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5391 | Iter Mean Loss 4.9222
2020-11-05 21:05:07,559 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4282 | Iter Mean Loss 4.6234
2020-11-05 21:05:07,561 - root - INFO - Evaluate: Epoch 0653 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,569 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8693 | Iter Mean Loss 5.8693
2020-11-05 21:05:07,576 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8654 | Iter Mean Loss 3.8673
2020-11-05 21:05:07,583 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3907 | Iter Mean Loss 4.7084
2020-11-05 21:05:07,590 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5278 | Iter Mean Loss 4.9133
2020-11-05 21:05:07,597 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4190 | Iter Mean Loss 4.6144
2020-11-05 21:05:07,599 - root - INFO - Evaluate: Epoch 0654 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,607 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8636 | Iter Mean Loss 5.8636
2020-11-05 21:05:07,614 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8591 | Iter Mean Loss 3.8614
2020-11-05 21:05:07,622 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3784 | Iter Mean Loss 4.7004
2020-11-05 21:05:07,629 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5165 | Iter Mean Loss 4.9044
2020-11-05 21:05:07,637 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4099 | Iter Mean Loss 4.6055
2020-11-05 21:05:07,639 - root - INFO - Evaluate: Epoch 0655 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,647 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 5.8580
2020-11-05 21:05:07,656 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 3.8555
2020-11-05 21:05:07,663 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 4.6924
2020-11-05 21:05:07,671 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5053 | Iter Mean Loss 4.8956
2020-11-05 21:05:07,679 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4008 | Iter Mean Loss 4.5966
2020-11-05 21:05:07,681 - root - INFO - Evaluate: Epoch 0656 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,690 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8525 | Iter Mean Loss 5.8525
2020-11-05 21:05:07,698 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8467 | Iter Mean Loss 3.8496
2020-11-05 21:05:07,705 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3540 | Iter Mean Loss 4.6844
2020-11-05 21:05:07,713 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4941 | Iter Mean Loss 4.8868
2020-11-05 21:05:07,721 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 4.5878
2020-11-05 21:05:07,723 - root - INFO - Evaluate: Epoch 0657 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,731 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 5.8469
2020-11-05 21:05:07,739 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8406 | Iter Mean Loss 3.8438
2020-11-05 21:05:07,746 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3419 | Iter Mean Loss 4.6765
2020-11-05 21:05:07,753 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4830 | Iter Mean Loss 4.8781
2020-11-05 21:05:07,760 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3827 | Iter Mean Loss 4.5790
2020-11-05 21:05:07,762 - root - INFO - Evaluate: Epoch 0658 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,770 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8414 | Iter Mean Loss 5.8414
2020-11-05 21:05:07,777 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8346 | Iter Mean Loss 3.8380
2020-11-05 21:05:07,784 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3298 | Iter Mean Loss 4.6686
2020-11-05 21:05:07,791 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4719 | Iter Mean Loss 4.8694
2020-11-05 21:05:07,798 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3737 | Iter Mean Loss 4.5703
2020-11-05 21:05:07,800 - root - INFO - Evaluate: Epoch 0659 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,808 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.8359
2020-11-05 21:05:07,815 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8285 | Iter Mean Loss 3.8322
2020-11-05 21:05:07,823 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3179 | Iter Mean Loss 4.6608
2020-11-05 21:05:07,830 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4610 | Iter Mean Loss 4.8608
2020-11-05 21:05:07,837 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 4.5616
2020-11-05 21:05:07,840 - root - INFO - Evaluate: Epoch 0660 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,848 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8305 | Iter Mean Loss 5.8305
2020-11-05 21:05:07,856 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8226 | Iter Mean Loss 3.8265
2020-11-05 21:05:07,864 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3060 | Iter Mean Loss 4.6530
2020-11-05 21:05:07,871 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4500 | Iter Mean Loss 4.8523
2020-11-05 21:05:07,879 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3560 | Iter Mean Loss 4.5530
2020-11-05 21:05:07,882 - root - INFO - Evaluate: Epoch 0661 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,890 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8251 | Iter Mean Loss 5.8251
2020-11-05 21:05:07,898 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8167 | Iter Mean Loss 3.8209
2020-11-05 21:05:07,906 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 4.6453
2020-11-05 21:05:07,913 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4392 | Iter Mean Loss 4.8438
2020-11-05 21:05:07,921 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3472 | Iter Mean Loss 4.5444
2020-11-05 21:05:07,924 - root - INFO - Evaluate: Epoch 0662 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,932 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8197 | Iter Mean Loss 5.8197
2020-11-05 21:05:07,940 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8108 | Iter Mean Loss 3.8153
2020-11-05 21:05:07,947 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2823 | Iter Mean Loss 4.6376
2020-11-05 21:05:07,954 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4284 | Iter Mean Loss 4.8353
2020-11-05 21:05:07,961 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3385 | Iter Mean Loss 4.5359
2020-11-05 21:05:07,963 - root - INFO - Evaluate: Epoch 0663 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:07,972 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8144 | Iter Mean Loss 5.8144
2020-11-05 21:05:07,979 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8050 | Iter Mean Loss 3.8097
2020-11-05 21:05:07,987 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 4.6300
2020-11-05 21:05:07,994 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4176 | Iter Mean Loss 4.8269
2020-11-05 21:05:08,001 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 4.5275
2020-11-05 21:05:08,003 - root - INFO - Evaluate: Epoch 0664 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,011 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8090 | Iter Mean Loss 5.8090
2020-11-05 21:05:08,019 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7993 | Iter Mean Loss 3.8042
2020-11-05 21:05:08,026 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2590 | Iter Mean Loss 4.6224
2020-11-05 21:05:08,033 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4070 | Iter Mean Loss 4.8186
2020-11-05 21:05:08,041 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3212 | Iter Mean Loss 4.5191
2020-11-05 21:05:08,043 - root - INFO - Evaluate: Epoch 0665 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,051 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8038 | Iter Mean Loss 5.8038
2020-11-05 21:05:08,063 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7936 | Iter Mean Loss 3.7987
2020-11-05 21:05:08,076 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2474 | Iter Mean Loss 4.6149
2020-11-05 21:05:08,088 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3964 | Iter Mean Loss 4.8103
2020-11-05 21:05:08,099 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3126 | Iter Mean Loss 4.5107
2020-11-05 21:05:08,102 - root - INFO - Evaluate: Epoch 0666 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,113 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7985 | Iter Mean Loss 5.7985
2020-11-05 21:05:08,121 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7880 | Iter Mean Loss 3.7932
2020-11-05 21:05:08,131 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2359 | Iter Mean Loss 4.6074
2020-11-05 21:05:08,140 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3858 | Iter Mean Loss 4.8020
2020-11-05 21:05:08,147 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3041 | Iter Mean Loss 4.5025
2020-11-05 21:05:08,150 - root - INFO - Evaluate: Epoch 0667 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,158 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7933 | Iter Mean Loss 5.7933
2020-11-05 21:05:08,166 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7824 | Iter Mean Loss 3.7878
2020-11-05 21:05:08,174 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2244 | Iter Mean Loss 4.6000
2020-11-05 21:05:08,181 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 4.7939
2020-11-05 21:05:08,189 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2957 | Iter Mean Loss 4.4942
2020-11-05 21:05:08,191 - root - INFO - Evaluate: Epoch 0668 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,199 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7881 | Iter Mean Loss 5.7881
2020-11-05 21:05:08,208 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7769 | Iter Mean Loss 3.7825
2020-11-05 21:05:08,216 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 4.5927
2020-11-05 21:05:08,223 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3649 | Iter Mean Loss 4.7857
2020-11-05 21:05:08,232 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2873 | Iter Mean Loss 4.4861
2020-11-05 21:05:08,234 - root - INFO - Evaluate: Epoch 0669 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,244 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7829 | Iter Mean Loss 5.7829
2020-11-05 21:05:08,252 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7714 | Iter Mean Loss 3.7772
2020-11-05 21:05:08,260 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2018 | Iter Mean Loss 4.5854
2020-11-05 21:05:08,268 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3546 | Iter Mean Loss 4.7777
2020-11-05 21:05:08,276 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2790 | Iter Mean Loss 4.4779
2020-11-05 21:05:08,278 - root - INFO - Evaluate: Epoch 0670 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,287 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7778 | Iter Mean Loss 5.7778
2020-11-05 21:05:08,295 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7660 | Iter Mean Loss 3.7719
2020-11-05 21:05:08,303 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1905 | Iter Mean Loss 4.5781
2020-11-05 21:05:08,311 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3443 | Iter Mean Loss 4.7697
2020-11-05 21:05:08,320 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2708 | Iter Mean Loss 4.4699
2020-11-05 21:05:08,323 - root - INFO - Evaluate: Epoch 0671 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,331 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7727 | Iter Mean Loss 5.7727
2020-11-05 21:05:08,340 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7607 | Iter Mean Loss 3.7667
2020-11-05 21:05:08,348 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1794 | Iter Mean Loss 4.5709
2020-11-05 21:05:08,356 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3341 | Iter Mean Loss 4.7617
2020-11-05 21:05:08,364 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2626 | Iter Mean Loss 4.4619
2020-11-05 21:05:08,366 - root - INFO - Evaluate: Epoch 0672 | NDCG 0.2817 | MSE 0.3179
2020-11-05 21:05:08,374 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7677 | Iter Mean Loss 5.7677
2020-11-05 21:05:08,382 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7554 | Iter Mean Loss 3.7615
2020-11-05 21:05:08,390 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1683 | Iter Mean Loss 4.5638
2020-11-05 21:05:08,398 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3240 | Iter Mean Loss 4.7538
2020-11-05 21:05:08,406 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2544 | Iter Mean Loss 4.4540
2020-11-05 21:05:08,409 - root - INFO - Evaluate: Epoch 0673 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,417 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7626 | Iter Mean Loss 5.7626
2020-11-05 21:05:08,425 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7502 | Iter Mean Loss 3.7564
2020-11-05 21:05:08,433 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1573 | Iter Mean Loss 4.5567
2020-11-05 21:05:08,441 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3139 | Iter Mean Loss 4.7460
2020-11-05 21:05:08,449 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2464 | Iter Mean Loss 4.4461
2020-11-05 21:05:08,452 - root - INFO - Evaluate: Epoch 0674 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,460 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7576 | Iter Mean Loss 5.7576
2020-11-05 21:05:08,469 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7450 | Iter Mean Loss 3.7513
2020-11-05 21:05:08,477 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1463 | Iter Mean Loss 4.5497
2020-11-05 21:05:08,486 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3039 | Iter Mean Loss 4.7382
2020-11-05 21:05:08,494 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2384 | Iter Mean Loss 4.4382
2020-11-05 21:05:08,498 - root - INFO - Evaluate: Epoch 0675 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,507 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7527 | Iter Mean Loss 5.7527
2020-11-05 21:05:08,516 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7399 | Iter Mean Loss 3.7463
2020-11-05 21:05:08,524 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1354 | Iter Mean Loss 4.5427
2020-11-05 21:05:08,531 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2940 | Iter Mean Loss 4.7305
2020-11-05 21:05:08,539 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2304 | Iter Mean Loss 4.4305
2020-11-05 21:05:08,541 - root - INFO - Evaluate: Epoch 0676 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,550 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7477 | Iter Mean Loss 5.7477
2020-11-05 21:05:08,558 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7349 | Iter Mean Loss 3.7413
2020-11-05 21:05:08,566 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1246 | Iter Mean Loss 4.5358
2020-11-05 21:05:08,573 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2841 | Iter Mean Loss 4.7228
2020-11-05 21:05:08,581 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 4.4228
2020-11-05 21:05:08,583 - root - INFO - Evaluate: Epoch 0677 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,591 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7428 | Iter Mean Loss 5.7428
2020-11-05 21:05:08,599 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7299 | Iter Mean Loss 3.7364
2020-11-05 21:05:08,606 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1139 | Iter Mean Loss 4.5289
2020-11-05 21:05:08,614 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2743 | Iter Mean Loss 4.7152
2020-11-05 21:05:08,621 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2147 | Iter Mean Loss 4.4151
2020-11-05 21:05:08,623 - root - INFO - Evaluate: Epoch 0678 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,631 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7379 | Iter Mean Loss 5.7379
2020-11-05 21:05:08,639 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7250 | Iter Mean Loss 3.7315
2020-11-05 21:05:08,647 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1032 | Iter Mean Loss 4.5221
2020-11-05 21:05:08,655 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2646 | Iter Mean Loss 4.7077
2020-11-05 21:05:08,663 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 4.4075
2020-11-05 21:05:08,665 - root - INFO - Evaluate: Epoch 0679 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,674 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7331 | Iter Mean Loss 5.7331
2020-11-05 21:05:08,682 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7201 | Iter Mean Loss 3.7266
2020-11-05 21:05:08,690 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0926 | Iter Mean Loss 4.5153
2020-11-05 21:05:08,699 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2549 | Iter Mean Loss 4.7002
2020-11-05 21:05:08,707 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1992 | Iter Mean Loss 4.4000
2020-11-05 21:05:08,710 - root - INFO - Evaluate: Epoch 0680 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,719 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7283 | Iter Mean Loss 5.7283
2020-11-05 21:05:08,727 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7153 | Iter Mean Loss 3.7218
2020-11-05 21:05:08,735 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0821 | Iter Mean Loss 4.5086
2020-11-05 21:05:08,743 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.6928
2020-11-05 21:05:08,751 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1916 | Iter Mean Loss 4.3925
2020-11-05 21:05:08,753 - root - INFO - Evaluate: Epoch 0681 | NDCG 0.2817 | MSE 0.3180
2020-11-05 21:05:08,761 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7235 | Iter Mean Loss 5.7235
2020-11-05 21:05:08,769 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7106 | Iter Mean Loss 3.7170
2020-11-05 21:05:08,776 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0717 | Iter Mean Loss 4.5019
2020-11-05 21:05:08,783 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2358 | Iter Mean Loss 4.6854
2020-11-05 21:05:08,791 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1840 | Iter Mean Loss 4.3851
2020-11-05 21:05:08,793 - root - INFO - Evaluate: Epoch 0682 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:08,801 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7187 | Iter Mean Loss 5.7187
2020-11-05 21:05:08,808 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7059 | Iter Mean Loss 3.7123
2020-11-05 21:05:08,816 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0613 | Iter Mean Loss 4.4953
2020-11-05 21:05:08,823 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2263 | Iter Mean Loss 4.6781
2020-11-05 21:05:08,831 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1765 | Iter Mean Loss 4.3778
2020-11-05 21:05:08,833 - root - INFO - Evaluate: Epoch 0683 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:08,840 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7140 | Iter Mean Loss 5.7140
2020-11-05 21:05:08,848 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7013 | Iter Mean Loss 3.7077
2020-11-05 21:05:08,856 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0510 | Iter Mean Loss 4.4888
2020-11-05 21:05:08,864 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2169 | Iter Mean Loss 4.6708
2020-11-05 21:05:08,871 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1690 | Iter Mean Loss 4.3705
2020-11-05 21:05:08,874 - root - INFO - Evaluate: Epoch 0684 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:08,883 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7093 | Iter Mean Loss 5.7093
2020-11-05 21:05:08,891 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6968 | Iter Mean Loss 3.7030
2020-11-05 21:05:08,899 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0407 | Iter Mean Loss 4.4823
2020-11-05 21:05:08,907 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2076 | Iter Mean Loss 4.6636
2020-11-05 21:05:08,915 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1616 | Iter Mean Loss 4.3632
2020-11-05 21:05:08,918 - root - INFO - Evaluate: Epoch 0685 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:08,926 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7046 | Iter Mean Loss 5.7046
2020-11-05 21:05:08,935 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6923 | Iter Mean Loss 3.6984
2020-11-05 21:05:08,942 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0305 | Iter Mean Loss 4.4758
2020-11-05 21:05:08,951 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1984 | Iter Mean Loss 4.6564
2020-11-05 21:05:08,958 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1543 | Iter Mean Loss 4.3560
2020-11-05 21:05:08,960 - root - INFO - Evaluate: Epoch 0686 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:08,968 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7000 | Iter Mean Loss 5.7000
2020-11-05 21:05:08,976 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6878 | Iter Mean Loss 3.6939
2020-11-05 21:05:08,985 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0204 | Iter Mean Loss 4.4694
2020-11-05 21:05:08,993 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1891 | Iter Mean Loss 4.6493
2020-11-05 21:05:09,000 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1470 | Iter Mean Loss 4.3489
2020-11-05 21:05:09,002 - root - INFO - Evaluate: Epoch 0687 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:09,010 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6953 | Iter Mean Loss 5.6953
2020-11-05 21:05:09,017 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6834 | Iter Mean Loss 3.6894
2020-11-05 21:05:09,025 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0104 | Iter Mean Loss 4.4630
2020-11-05 21:05:09,032 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1800 | Iter Mean Loss 4.6423
2020-11-05 21:05:09,039 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1398 | Iter Mean Loss 4.3418
2020-11-05 21:05:09,041 - root - INFO - Evaluate: Epoch 0688 | NDCG 0.2817 | MSE 0.3181
2020-11-05 21:05:09,049 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6907 | Iter Mean Loss 5.6907
2020-11-05 21:05:09,057 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6791 | Iter Mean Loss 3.6849
2020-11-05 21:05:09,066 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0004 | Iter Mean Loss 4.4567
2020-11-05 21:05:09,073 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1709 | Iter Mean Loss 4.6353
2020-11-05 21:05:09,081 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1326 | Iter Mean Loss 4.3348
2020-11-05 21:05:09,084 - root - INFO - Evaluate: Epoch 0689 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,092 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6862 | Iter Mean Loss 5.6862
2020-11-05 21:05:09,101 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6748 | Iter Mean Loss 3.6805
2020-11-05 21:05:09,109 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9905 | Iter Mean Loss 4.4505
2020-11-05 21:05:09,117 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1619 | Iter Mean Loss 4.6283
2020-11-05 21:05:09,125 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1255 | Iter Mean Loss 4.3278
2020-11-05 21:05:09,127 - root - INFO - Evaluate: Epoch 0690 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,137 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6816 | Iter Mean Loss 5.6816
2020-11-05 21:05:09,144 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6706 | Iter Mean Loss 3.6761
2020-11-05 21:05:09,153 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9806 | Iter Mean Loss 4.4443
2020-11-05 21:05:09,161 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1530 | Iter Mean Loss 4.6215
2020-11-05 21:05:09,168 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1185 | Iter Mean Loss 4.3209
2020-11-05 21:05:09,170 - root - INFO - Evaluate: Epoch 0691 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,179 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6771 | Iter Mean Loss 5.6771
2020-11-05 21:05:09,186 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6664 | Iter Mean Loss 3.6718
2020-11-05 21:05:09,194 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9708 | Iter Mean Loss 4.4381
2020-11-05 21:05:09,201 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1441 | Iter Mean Loss 4.6146
2020-11-05 21:05:09,208 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1115 | Iter Mean Loss 4.3140
2020-11-05 21:05:09,210 - root - INFO - Evaluate: Epoch 0692 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,218 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6726 | Iter Mean Loss 5.6726
2020-11-05 21:05:09,225 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6623 | Iter Mean Loss 3.6675
2020-11-05 21:05:09,233 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9611 | Iter Mean Loss 4.4320
2020-11-05 21:05:09,240 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1352 | Iter Mean Loss 4.6078
2020-11-05 21:05:09,247 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1046 | Iter Mean Loss 4.3072
2020-11-05 21:05:09,249 - root - INFO - Evaluate: Epoch 0693 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,258 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6682 | Iter Mean Loss 5.6682
2020-11-05 21:05:09,266 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6583 | Iter Mean Loss 3.6632
2020-11-05 21:05:09,273 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 4.4260
2020-11-05 21:05:09,281 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1265 | Iter Mean Loss 4.6011
2020-11-05 21:05:09,289 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0977 | Iter Mean Loss 4.3004
2020-11-05 21:05:09,291 - root - INFO - Evaluate: Epoch 0694 | NDCG 0.2817 | MSE 0.3182
2020-11-05 21:05:09,300 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6637 | Iter Mean Loss 5.6637
2020-11-05 21:05:09,308 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 3.6590
2020-11-05 21:05:09,317 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9418 | Iter Mean Loss 4.4199
2020-11-05 21:05:09,327 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1178 | Iter Mean Loss 4.5944
2020-11-05 21:05:09,334 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0909 | Iter Mean Loss 4.2937
2020-11-05 21:05:09,337 - root - INFO - Evaluate: Epoch 0695 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,346 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6593 | Iter Mean Loss 5.6593
2020-11-05 21:05:09,354 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6503 | Iter Mean Loss 3.6548
2020-11-05 21:05:09,361 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9323 | Iter Mean Loss 4.4140
2020-11-05 21:05:09,369 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1091 | Iter Mean Loss 4.5878
2020-11-05 21:05:09,376 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0841 | Iter Mean Loss 4.2870
2020-11-05 21:05:09,378 - root - INFO - Evaluate: Epoch 0696 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,386 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6549 | Iter Mean Loss 5.6549
2020-11-05 21:05:09,393 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6464 | Iter Mean Loss 3.6507
2020-11-05 21:05:09,400 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9228 | Iter Mean Loss 4.4081
2020-11-05 21:05:09,408 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1005 | Iter Mean Loss 4.5812
2020-11-05 21:05:09,416 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0774 | Iter Mean Loss 4.2804
2020-11-05 21:05:09,418 - root - INFO - Evaluate: Epoch 0697 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,426 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6506 | Iter Mean Loss 5.6506
2020-11-05 21:05:09,433 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6426 | Iter Mean Loss 3.6466
2020-11-05 21:05:09,440 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9134 | Iter Mean Loss 4.4022
2020-11-05 21:05:09,447 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0920 | Iter Mean Loss 4.5746
2020-11-05 21:05:09,455 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0707 | Iter Mean Loss 4.2738
2020-11-05 21:05:09,457 - root - INFO - Evaluate: Epoch 0698 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,466 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6462 | Iter Mean Loss 5.6462
2020-11-05 21:05:09,474 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6388 | Iter Mean Loss 3.6425
2020-11-05 21:05:09,482 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9040 | Iter Mean Loss 4.3963
2020-11-05 21:05:09,489 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0835 | Iter Mean Loss 4.5681
2020-11-05 21:05:09,498 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0641 | Iter Mean Loss 4.2673
2020-11-05 21:05:09,500 - root - INFO - Evaluate: Epoch 0699 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,508 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6419 | Iter Mean Loss 5.6419
2020-11-05 21:05:09,516 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6350 | Iter Mean Loss 3.6385
2020-11-05 21:05:09,524 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8947 | Iter Mean Loss 4.3906
2020-11-05 21:05:09,532 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0751 | Iter Mean Loss 4.5617
2020-11-05 21:05:09,539 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0576 | Iter Mean Loss 4.2609
2020-11-05 21:05:09,541 - root - INFO - Evaluate: Epoch 0700 | NDCG 0.2817 | MSE 0.3183
2020-11-05 21:05:09,550 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6376 | Iter Mean Loss 5.6376
2020-11-05 21:05:09,558 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6313 | Iter Mean Loss 3.6345
2020-11-05 21:05:09,565 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8855 | Iter Mean Loss 4.3848
2020-11-05 21:05:09,572 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0667 | Iter Mean Loss 4.5553
2020-11-05 21:05:09,579 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0511 | Iter Mean Loss 4.2544
2020-11-05 21:05:09,581 - root - INFO - Evaluate: Epoch 0701 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:09,589 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6334 | Iter Mean Loss 5.6334
2020-11-05 21:05:09,596 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6277 | Iter Mean Loss 3.6305
2020-11-05 21:05:09,603 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8763 | Iter Mean Loss 4.3791
2020-11-05 21:05:09,610 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0584 | Iter Mean Loss 4.5489
2020-11-05 21:05:09,618 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0446 | Iter Mean Loss 4.2481
2020-11-05 21:05:09,619 - root - INFO - Evaluate: Epoch 0702 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:09,627 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6291 | Iter Mean Loss 5.6291
2020-11-05 21:05:09,634 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6240 | Iter Mean Loss 3.6266
2020-11-05 21:05:09,641 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8671 | Iter Mean Loss 4.3734
2020-11-05 21:05:09,648 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0501 | Iter Mean Loss 4.5426
2020-11-05 21:05:09,656 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0382 | Iter Mean Loss 4.2417
2020-11-05 21:05:09,658 - root - INFO - Evaluate: Epoch 0703 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:09,666 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6249 | Iter Mean Loss 5.6249
2020-11-05 21:05:09,674 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6205 | Iter Mean Loss 3.6227
2020-11-05 21:05:09,682 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 4.3678
2020-11-05 21:05:09,690 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0419 | Iter Mean Loss 4.5363
2020-11-05 21:05:09,698 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0319 | Iter Mean Loss 4.2354
2020-11-05 21:05:09,700 - root - INFO - Evaluate: Epoch 0704 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:09,709 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6207 | Iter Mean Loss 5.6207
2020-11-05 21:05:09,717 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6170 | Iter Mean Loss 3.6188
2020-11-05 21:05:09,725 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8490 | Iter Mean Loss 4.3622
2020-11-05 21:05:09,732 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0337 | Iter Mean Loss 4.5301
2020-11-05 21:05:09,740 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0255 | Iter Mean Loss 4.2292
2020-11-05 21:05:09,743 - root - INFO - Evaluate: Epoch 0705 | NDCG 0.2817 | MSE 0.3184
2020-11-05 21:05:09,751 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6165 | Iter Mean Loss 5.6165
2020-11-05 21:05:09,759 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6135 | Iter Mean Loss 3.6150
2020-11-05 21:05:09,766 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8400 | Iter Mean Loss 4.3567
2020-11-05 21:05:09,773 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0256 | Iter Mean Loss 4.5239
2020-11-05 21:05:09,780 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0193 | Iter Mean Loss 4.2230
2020-11-05 21:05:09,782 - root - INFO - Evaluate: Epoch 0706 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:09,790 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6124 | Iter Mean Loss 5.6124
2020-11-05 21:05:09,798 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6101 | Iter Mean Loss 3.6112
2020-11-05 21:05:09,805 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8311 | Iter Mean Loss 4.3512
2020-11-05 21:05:09,812 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0176 | Iter Mean Loss 4.5178
2020-11-05 21:05:09,819 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0131 | Iter Mean Loss 4.2168
2020-11-05 21:05:09,821 - root - INFO - Evaluate: Epoch 0707 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:09,828 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 5.6082
2020-11-05 21:05:09,836 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6067 | Iter Mean Loss 3.6075
2020-11-05 21:05:09,843 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8222 | Iter Mean Loss 4.3457
2020-11-05 21:05:09,850 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0096 | Iter Mean Loss 4.5117
2020-11-05 21:05:09,857 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0069 | Iter Mean Loss 4.2107
2020-11-05 21:05:09,860 - root - INFO - Evaluate: Epoch 0708 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:09,868 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6041 | Iter Mean Loss 5.6041
2020-11-05 21:05:09,876 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6033 | Iter Mean Loss 3.6037
2020-11-05 21:05:09,883 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8134 | Iter Mean Loss 4.3403
2020-11-05 21:05:09,891 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0016 | Iter Mean Loss 4.5056
2020-11-05 21:05:09,899 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0008 | Iter Mean Loss 4.2047
2020-11-05 21:05:09,901 - root - INFO - Evaluate: Epoch 0709 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:09,910 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6000 | Iter Mean Loss 5.6000
2020-11-05 21:05:09,917 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6000 | Iter Mean Loss 3.6000
2020-11-05 21:05:09,925 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8047 | Iter Mean Loss 4.3349
2020-11-05 21:05:09,933 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9937 | Iter Mean Loss 4.4996
2020-11-05 21:05:09,941 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9947 | Iter Mean Loss 4.1986
2020-11-05 21:05:09,943 - root - INFO - Evaluate: Epoch 0710 | NDCG 0.2817 | MSE 0.3185
2020-11-05 21:05:09,951 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5959 | Iter Mean Loss 5.5959
2020-11-05 21:05:09,959 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5968 | Iter Mean Loss 3.5964
2020-11-05 21:05:09,967 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7959 | Iter Mean Loss 4.3295
2020-11-05 21:05:09,975 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9858 | Iter Mean Loss 4.4936
2020-11-05 21:05:09,983 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9887 | Iter Mean Loss 4.1926
2020-11-05 21:05:09,985 - root - INFO - Evaluate: Epoch 0711 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:09,993 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5919 | Iter Mean Loss 5.5919
2020-11-05 21:05:10,000 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5935 | Iter Mean Loss 3.5927
2020-11-05 21:05:10,007 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7873 | Iter Mean Loss 4.3242
2020-11-05 21:05:10,015 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9780 | Iter Mean Loss 4.4877
2020-11-05 21:05:10,022 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9827 | Iter Mean Loss 4.1867
2020-11-05 21:05:10,024 - root - INFO - Evaluate: Epoch 0712 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:10,032 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5879 | Iter Mean Loss 5.5879
2020-11-05 21:05:10,039 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5904 | Iter Mean Loss 3.5891
2020-11-05 21:05:10,046 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7786 | Iter Mean Loss 4.3189
2020-11-05 21:05:10,053 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9702 | Iter Mean Loss 4.4818
2020-11-05 21:05:10,061 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9768 | Iter Mean Loss 4.1808
2020-11-05 21:05:10,063 - root - INFO - Evaluate: Epoch 0713 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:10,071 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5838 | Iter Mean Loss 5.5838
2020-11-05 21:05:10,079 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 3.5855
2020-11-05 21:05:10,087 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7701 | Iter Mean Loss 4.3137
2020-11-05 21:05:10,095 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9625 | Iter Mean Loss 4.4759
2020-11-05 21:05:10,102 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9709 | Iter Mean Loss 4.1749
2020-11-05 21:05:10,105 - root - INFO - Evaluate: Epoch 0714 | NDCG 0.2817 | MSE 0.3186
2020-11-05 21:05:10,113 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5798 | Iter Mean Loss 5.5798
2020-11-05 21:05:10,122 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5841 | Iter Mean Loss 3.5820
2020-11-05 21:05:10,130 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7615 | Iter Mean Loss 4.3085
2020-11-05 21:05:10,137 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9548 | Iter Mean Loss 4.4701
2020-11-05 21:05:10,145 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9650 | Iter Mean Loss 4.1691
2020-11-05 21:05:10,147 - root - INFO - Evaluate: Epoch 0715 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:10,156 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5759 | Iter Mean Loss 5.5759
2020-11-05 21:05:10,164 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5810 | Iter Mean Loss 3.5784
2020-11-05 21:05:10,171 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7530 | Iter Mean Loss 4.3033
2020-11-05 21:05:10,178 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9472 | Iter Mean Loss 4.4643
2020-11-05 21:05:10,185 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9592 | Iter Mean Loss 4.1633
2020-11-05 21:05:10,187 - root - INFO - Evaluate: Epoch 0716 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:10,195 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5719 | Iter Mean Loss 5.5719
2020-11-05 21:05:10,202 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5780 | Iter Mean Loss 3.5749
2020-11-05 21:05:10,210 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7446 | Iter Mean Loss 4.2982
2020-11-05 21:05:10,217 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9396 | Iter Mean Loss 4.4585
2020-11-05 21:05:10,224 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 4.1575
2020-11-05 21:05:10,226 - root - INFO - Evaluate: Epoch 0717 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:10,233 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5680 | Iter Mean Loss 5.5680
2020-11-05 21:05:10,241 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5750 | Iter Mean Loss 3.5715
2020-11-05 21:05:10,248 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7362 | Iter Mean Loss 4.2931
2020-11-05 21:05:10,255 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9320 | Iter Mean Loss 4.4528
2020-11-05 21:05:10,262 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9477 | Iter Mean Loss 4.1518
2020-11-05 21:05:10,264 - root - INFO - Evaluate: Epoch 0718 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:10,273 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5640 | Iter Mean Loss 5.5640
2020-11-05 21:05:10,280 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5720 | Iter Mean Loss 3.5680
2020-11-05 21:05:10,288 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7278 | Iter Mean Loss 4.2880
2020-11-05 21:05:10,296 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9245 | Iter Mean Loss 4.4471
2020-11-05 21:05:10,304 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 4.1461
2020-11-05 21:05:10,306 - root - INFO - Evaluate: Epoch 0719 | NDCG 0.2817 | MSE 0.3187
2020-11-05 21:05:10,316 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5601 | Iter Mean Loss 5.5601
2020-11-05 21:05:10,324 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5691 | Iter Mean Loss 3.5646
2020-11-05 21:05:10,332 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7195 | Iter Mean Loss 4.2829
2020-11-05 21:05:10,339 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9170 | Iter Mean Loss 4.4414
2020-11-05 21:05:10,347 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 4.1404
2020-11-05 21:05:10,349 - root - INFO - Evaluate: Epoch 0720 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:10,357 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5562 | Iter Mean Loss 5.5562
2020-11-05 21:05:10,365 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5662 | Iter Mean Loss 3.5612
2020-11-05 21:05:10,372 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7113 | Iter Mean Loss 4.2779
2020-11-05 21:05:10,379 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9095 | Iter Mean Loss 4.4358
2020-11-05 21:05:10,386 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9307 | Iter Mean Loss 4.1348
2020-11-05 21:05:10,389 - root - INFO - Evaluate: Epoch 0721 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:10,396 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5524 | Iter Mean Loss 5.5524
2020-11-05 21:05:10,403 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 3.5578
2020-11-05 21:05:10,413 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7030 | Iter Mean Loss 4.2729
2020-11-05 21:05:10,423 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9021 | Iter Mean Loss 4.4302
2020-11-05 21:05:10,431 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9251 | Iter Mean Loss 4.1292
2020-11-05 21:05:10,433 - root - INFO - Evaluate: Epoch 0722 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:10,441 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5485 | Iter Mean Loss 5.5485
2020-11-05 21:05:10,452 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5605 | Iter Mean Loss 3.5545
2020-11-05 21:05:10,460 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6949 | Iter Mean Loss 4.2679
2020-11-05 21:05:10,469 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8948 | Iter Mean Loss 4.4247
2020-11-05 21:05:10,477 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9195 | Iter Mean Loss 4.1236
2020-11-05 21:05:10,479 - root - INFO - Evaluate: Epoch 0723 | NDCG 0.2817 | MSE 0.3188
2020-11-05 21:05:10,488 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5447 | Iter Mean Loss 5.5447
2020-11-05 21:05:10,497 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5577 | Iter Mean Loss 3.5512
2020-11-05 21:05:10,506 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6867 | Iter Mean Loss 4.2630
2020-11-05 21:05:10,514 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8875 | Iter Mean Loss 4.4191
2020-11-05 21:05:10,522 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9140 | Iter Mean Loss 4.1181
2020-11-05 21:05:10,525 - root - INFO - Evaluate: Epoch 0724 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:10,536 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5408 | Iter Mean Loss 5.5408
2020-11-05 21:05:10,545 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5549 | Iter Mean Loss 3.5479
2020-11-05 21:05:10,553 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6786 | Iter Mean Loss 4.2581
2020-11-05 21:05:10,562 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8802 | Iter Mean Loss 4.4136
2020-11-05 21:05:10,571 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9085 | Iter Mean Loss 4.1126
2020-11-05 21:05:10,573 - root - INFO - Evaluate: Epoch 0725 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:10,582 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5370 | Iter Mean Loss 5.5370
2020-11-05 21:05:10,590 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5522 | Iter Mean Loss 3.5446
2020-11-05 21:05:10,597 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6705 | Iter Mean Loss 4.2532
2020-11-05 21:05:10,604 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8729 | Iter Mean Loss 4.4082
2020-11-05 21:05:10,611 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9031 | Iter Mean Loss 4.1071
2020-11-05 21:05:10,613 - root - INFO - Evaluate: Epoch 0726 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:10,621 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5332 | Iter Mean Loss 5.5332
2020-11-05 21:05:10,628 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5495 | Iter Mean Loss 3.5413
2020-11-05 21:05:10,635 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6625 | Iter Mean Loss 4.2484
2020-11-05 21:05:10,642 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8657 | Iter Mean Loss 4.4027
2020-11-05 21:05:10,650 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8977 | Iter Mean Loss 4.1017
2020-11-05 21:05:10,652 - root - INFO - Evaluate: Epoch 0727 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:10,659 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5294 | Iter Mean Loss 5.5294
2020-11-05 21:05:10,666 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5468 | Iter Mean Loss 3.5381
2020-11-05 21:05:10,674 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6545 | Iter Mean Loss 4.2436
2020-11-05 21:05:10,681 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8585 | Iter Mean Loss 4.3973
2020-11-05 21:05:10,689 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8923 | Iter Mean Loss 4.0963
2020-11-05 21:05:10,691 - root - INFO - Evaluate: Epoch 0728 | NDCG 0.2817 | MSE 0.3189
2020-11-05 21:05:10,699 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5257 | Iter Mean Loss 5.5257
2020-11-05 21:05:10,707 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5441 | Iter Mean Loss 3.5349
2020-11-05 21:05:10,714 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6465 | Iter Mean Loss 4.2388
2020-11-05 21:05:10,722 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8514 | Iter Mean Loss 4.3919
2020-11-05 21:05:10,729 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 4.0909
2020-11-05 21:05:10,731 - root - INFO - Evaluate: Epoch 0729 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:10,740 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5219 | Iter Mean Loss 5.5219
2020-11-05 21:05:10,747 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5415 | Iter Mean Loss 3.5317
2020-11-05 21:05:10,755 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6386 | Iter Mean Loss 4.2340
2020-11-05 21:05:10,763 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8443 | Iter Mean Loss 4.3866
2020-11-05 21:05:10,770 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8817 | Iter Mean Loss 4.0856
2020-11-05 21:05:10,773 - root - INFO - Evaluate: Epoch 0730 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:10,780 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5182 | Iter Mean Loss 5.5182
2020-11-05 21:05:10,788 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5389 | Iter Mean Loss 3.5286
2020-11-05 21:05:10,795 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6307 | Iter Mean Loss 4.2293
2020-11-05 21:05:10,802 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8372 | Iter Mean Loss 4.3813
2020-11-05 21:05:10,809 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8764 | Iter Mean Loss 4.0803
2020-11-05 21:05:10,811 - root - INFO - Evaluate: Epoch 0731 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:10,819 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5145 | Iter Mean Loss 5.5145
2020-11-05 21:05:10,826 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5363 | Iter Mean Loss 3.5254
2020-11-05 21:05:10,833 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6229 | Iter Mean Loss 4.2246
2020-11-05 21:05:10,840 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8302 | Iter Mean Loss 4.3760
2020-11-05 21:05:10,848 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8711 | Iter Mean Loss 4.0750
2020-11-05 21:05:10,850 - root - INFO - Evaluate: Epoch 0732 | NDCG 0.2817 | MSE 0.3190
2020-11-05 21:05:10,857 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5108 | Iter Mean Loss 5.5108
2020-11-05 21:05:10,865 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5338 | Iter Mean Loss 3.5223
2020-11-05 21:05:10,872 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6151 | Iter Mean Loss 4.2199
2020-11-05 21:05:10,879 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8231 | Iter Mean Loss 4.3707
2020-11-05 21:05:10,887 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8659 | Iter Mean Loss 4.0697
2020-11-05 21:05:10,889 - root - INFO - Evaluate: Epoch 0733 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:10,897 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5071 | Iter Mean Loss 5.5071
2020-11-05 21:05:10,904 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5313 | Iter Mean Loss 3.5192
2020-11-05 21:05:10,913 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6073 | Iter Mean Loss 4.2152
2020-11-05 21:05:10,920 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8162 | Iter Mean Loss 4.3654
2020-11-05 21:05:10,928 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8608 | Iter Mean Loss 4.0645
2020-11-05 21:05:10,930 - root - INFO - Evaluate: Epoch 0734 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:10,938 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5034 | Iter Mean Loss 5.5034
2020-11-05 21:05:10,946 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5288 | Iter Mean Loss 3.5161
2020-11-05 21:05:10,953 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5995 | Iter Mean Loss 4.2106
2020-11-05 21:05:10,961 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8092 | Iter Mean Loss 4.3602
2020-11-05 21:05:10,969 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8556 | Iter Mean Loss 4.0593
2020-11-05 21:05:10,971 - root - INFO - Evaluate: Epoch 0735 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:10,980 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4997 | Iter Mean Loss 5.4997
2020-11-05 21:05:10,987 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5263 | Iter Mean Loss 3.5130
2020-11-05 21:05:10,994 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5918 | Iter Mean Loss 4.2059
2020-11-05 21:05:11,001 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8023 | Iter Mean Loss 4.3550
2020-11-05 21:05:11,009 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8505 | Iter Mean Loss 4.0541
2020-11-05 21:05:11,011 - root - INFO - Evaluate: Epoch 0736 | NDCG 0.2817 | MSE 0.3191
2020-11-05 21:05:11,019 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4961 | Iter Mean Loss 5.4961
2020-11-05 21:05:11,026 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5239 | Iter Mean Loss 3.5100
2020-11-05 21:05:11,033 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5841 | Iter Mean Loss 4.2013
2020-11-05 21:05:11,040 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7954 | Iter Mean Loss 4.3499
2020-11-05 21:05:11,047 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8454 | Iter Mean Loss 4.0490
2020-11-05 21:05:11,050 - root - INFO - Evaluate: Epoch 0737 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:11,057 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4924 | Iter Mean Loss 5.4924
2020-11-05 21:05:11,064 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5214 | Iter Mean Loss 3.5069
2020-11-05 21:05:11,072 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5765 | Iter Mean Loss 4.1968
2020-11-05 21:05:11,079 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7886 | Iter Mean Loss 4.3447
2020-11-05 21:05:11,086 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8403 | Iter Mean Loss 4.0438
2020-11-05 21:05:11,088 - root - INFO - Evaluate: Epoch 0738 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:11,097 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4888 | Iter Mean Loss 5.4888
2020-11-05 21:05:11,104 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5190 | Iter Mean Loss 3.5039
2020-11-05 21:05:11,112 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5688 | Iter Mean Loss 4.1922
2020-11-05 21:05:11,119 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7817 | Iter Mean Loss 4.3396
2020-11-05 21:05:11,127 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8353 | Iter Mean Loss 4.0387
2020-11-05 21:05:11,130 - root - INFO - Evaluate: Epoch 0739 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:11,138 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4852 | Iter Mean Loss 5.4852
2020-11-05 21:05:11,146 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5166 | Iter Mean Loss 3.5009
2020-11-05 21:05:11,154 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5612 | Iter Mean Loss 4.1877
2020-11-05 21:05:11,161 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7749 | Iter Mean Loss 4.3345
2020-11-05 21:05:11,169 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 4.0337
2020-11-05 21:05:11,172 - root - INFO - Evaluate: Epoch 0740 | NDCG 0.2817 | MSE 0.3192
2020-11-05 21:05:11,180 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4816 | Iter Mean Loss 5.4816
2020-11-05 21:05:11,188 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5143 | Iter Mean Loss 3.4979
2020-11-05 21:05:11,195 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5537 | Iter Mean Loss 4.1832
2020-11-05 21:05:11,202 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7682 | Iter Mean Loss 4.3294
2020-11-05 21:05:11,209 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8253 | Iter Mean Loss 4.0286
2020-11-05 21:05:11,211 - root - INFO - Evaluate: Epoch 0741 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:11,219 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4780 | Iter Mean Loss 5.4780
2020-11-05 21:05:11,226 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5120 | Iter Mean Loss 3.4950
2020-11-05 21:05:11,234 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5462 | Iter Mean Loss 4.1787
2020-11-05 21:05:11,241 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7614 | Iter Mean Loss 4.3244
2020-11-05 21:05:11,248 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8203 | Iter Mean Loss 4.0236
2020-11-05 21:05:11,250 - root - INFO - Evaluate: Epoch 0742 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:11,257 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4744 | Iter Mean Loss 5.4744
2020-11-05 21:05:11,265 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5096 | Iter Mean Loss 3.4920
2020-11-05 21:05:11,272 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5386 | Iter Mean Loss 4.1742
2020-11-05 21:05:11,279 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7547 | Iter Mean Loss 4.3194
2020-11-05 21:05:11,286 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8154 | Iter Mean Loss 4.0186
2020-11-05 21:05:11,288 - root - INFO - Evaluate: Epoch 0743 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:11,296 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4709 | Iter Mean Loss 5.4709
2020-11-05 21:05:11,304 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5073 | Iter Mean Loss 3.4891
2020-11-05 21:05:11,312 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5312 | Iter Mean Loss 4.1698
2020-11-05 21:05:11,320 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7480 | Iter Mean Loss 4.3144
2020-11-05 21:05:11,328 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8105 | Iter Mean Loss 4.0136
2020-11-05 21:05:11,331 - root - INFO - Evaluate: Epoch 0744 | NDCG 0.2817 | MSE 0.3193
2020-11-05 21:05:11,339 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4673 | Iter Mean Loss 5.4673
2020-11-05 21:05:11,347 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5051 | Iter Mean Loss 3.4862
2020-11-05 21:05:11,355 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5237 | Iter Mean Loss 4.1654
2020-11-05 21:05:11,362 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 4.3094
2020-11-05 21:05:11,370 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8056 | Iter Mean Loss 4.0086
2020-11-05 21:05:11,372 - root - INFO - Evaluate: Epoch 0745 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:11,380 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4638 | Iter Mean Loss 5.4638
2020-11-05 21:05:11,388 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5028 | Iter Mean Loss 3.4833
2020-11-05 21:05:11,396 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5163 | Iter Mean Loss 4.1610
2020-11-05 21:05:11,403 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7348 | Iter Mean Loss 4.3044
2020-11-05 21:05:11,411 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8008 | Iter Mean Loss 4.0037
2020-11-05 21:05:11,413 - root - INFO - Evaluate: Epoch 0746 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:11,421 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4602 | Iter Mean Loss 5.4602
2020-11-05 21:05:11,428 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5006 | Iter Mean Loss 3.4804
2020-11-05 21:05:11,435 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5089 | Iter Mean Loss 4.1566
2020-11-05 21:05:11,442 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7281 | Iter Mean Loss 4.2995
2020-11-05 21:05:11,449 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7960 | Iter Mean Loss 3.9988
2020-11-05 21:05:11,451 - root - INFO - Evaluate: Epoch 0747 | NDCG 0.2817 | MSE 0.3194
2020-11-05 21:05:11,459 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4567 | Iter Mean Loss 5.4567
2020-11-05 21:05:11,466 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4984 | Iter Mean Loss 3.4776
2020-11-05 21:05:11,474 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5016 | Iter Mean Loss 4.1522
2020-11-05 21:05:11,481 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7216 | Iter Mean Loss 4.2946
2020-11-05 21:05:11,488 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7912 | Iter Mean Loss 3.9939
2020-11-05 21:05:11,490 - root - INFO - Evaluate: Epoch 0748 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:11,498 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4532 | Iter Mean Loss 5.4532
2020-11-05 21:05:11,506 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4962 | Iter Mean Loss 3.4747
2020-11-05 21:05:11,513 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4942 | Iter Mean Loss 4.1479
2020-11-05 21:05:11,521 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7150 | Iter Mean Loss 4.2897
2020-11-05 21:05:11,529 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7864 | Iter Mean Loss 3.9890
2020-11-05 21:05:11,531 - root - INFO - Evaluate: Epoch 0749 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:11,539 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4497 | Iter Mean Loss 5.4497
2020-11-05 21:05:11,547 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4940 | Iter Mean Loss 3.4719
2020-11-05 21:05:11,554 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4869 | Iter Mean Loss 4.1435
2020-11-05 21:05:11,563 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7085 | Iter Mean Loss 4.2848
2020-11-05 21:05:11,570 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7817 | Iter Mean Loss 3.9842
2020-11-05 21:05:11,572 - root - INFO - Evaluate: Epoch 0750 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:11,580 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4462 | Iter Mean Loss 5.4462
2020-11-05 21:05:11,588 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4918 | Iter Mean Loss 3.4690
2020-11-05 21:05:11,596 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4796 | Iter Mean Loss 4.1392
2020-11-05 21:05:11,603 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7020 | Iter Mean Loss 4.2799
2020-11-05 21:05:11,610 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7769 | Iter Mean Loss 3.9793
2020-11-05 21:05:11,613 - root - INFO - Evaluate: Epoch 0751 | NDCG 0.2817 | MSE 0.3195
2020-11-05 21:05:11,620 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4428 | Iter Mean Loss 5.4428
2020-11-05 21:05:11,627 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4897 | Iter Mean Loss 3.4662
2020-11-05 21:05:11,635 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4724 | Iter Mean Loss 4.1349
2020-11-05 21:05:11,642 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6955 | Iter Mean Loss 4.2751
2020-11-05 21:05:11,649 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7722 | Iter Mean Loss 3.9745
2020-11-05 21:05:11,651 - root - INFO - Evaluate: Epoch 0752 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:11,659 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4393 | Iter Mean Loss 5.4393
2020-11-05 21:05:11,666 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4876 | Iter Mean Loss 3.4634
2020-11-05 21:05:11,673 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4651 | Iter Mean Loss 4.1307
2020-11-05 21:05:11,680 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6891 | Iter Mean Loss 4.2703
2020-11-05 21:05:11,687 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7676 | Iter Mean Loss 3.9697
2020-11-05 21:05:11,689 - root - INFO - Evaluate: Epoch 0753 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:11,697 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4358 | Iter Mean Loss 5.4358
2020-11-05 21:05:11,705 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 3.4607
2020-11-05 21:05:11,712 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4579 | Iter Mean Loss 4.1264
2020-11-05 21:05:11,719 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6826 | Iter Mean Loss 4.2655
2020-11-05 21:05:11,727 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7629 | Iter Mean Loss 3.9650
2020-11-05 21:05:11,729 - root - INFO - Evaluate: Epoch 0754 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:11,737 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4324 | Iter Mean Loss 5.4324
2020-11-05 21:05:11,745 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4834 | Iter Mean Loss 3.4579
2020-11-05 21:05:11,753 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4507 | Iter Mean Loss 4.1222
2020-11-05 21:05:11,760 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6762 | Iter Mean Loss 4.2607
2020-11-05 21:05:11,768 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7583 | Iter Mean Loss 3.9602
2020-11-05 21:05:11,770 - root - INFO - Evaluate: Epoch 0755 | NDCG 0.2817 | MSE 0.3196
2020-11-05 21:05:11,778 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4290 | Iter Mean Loss 5.4290
2020-11-05 21:05:11,786 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4813 | Iter Mean Loss 3.4551
2020-11-05 21:05:11,794 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4436 | Iter Mean Loss 4.1180
2020-11-05 21:05:11,801 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6698 | Iter Mean Loss 4.2559
2020-11-05 21:05:11,809 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7537 | Iter Mean Loss 3.9555
2020-11-05 21:05:11,810 - root - INFO - Evaluate: Epoch 0756 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:11,818 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4255 | Iter Mean Loss 5.4255
2020-11-05 21:05:11,826 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4793 | Iter Mean Loss 3.4524
2020-11-05 21:05:11,833 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4365 | Iter Mean Loss 4.1137
2020-11-05 21:05:11,840 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6635 | Iter Mean Loss 4.2512
2020-11-05 21:05:11,847 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7491 | Iter Mean Loss 3.9508
2020-11-05 21:05:11,849 - root - INFO - Evaluate: Epoch 0757 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:11,856 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4221 | Iter Mean Loss 5.4221
2020-11-05 21:05:11,864 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4772 | Iter Mean Loss 3.4497
2020-11-05 21:05:11,871 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4293 | Iter Mean Loss 4.1096
2020-11-05 21:05:11,878 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6572 | Iter Mean Loss 4.2465
2020-11-05 21:05:11,885 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7445 | Iter Mean Loss 3.9461
2020-11-05 21:05:11,887 - root - INFO - Evaluate: Epoch 0758 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:11,894 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4187 | Iter Mean Loss 5.4187
2020-11-05 21:05:11,902 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4752 | Iter Mean Loss 3.4469
2020-11-05 21:05:11,910 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4223 | Iter Mean Loss 4.1054
2020-11-05 21:05:11,917 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6508 | Iter Mean Loss 4.2417
2020-11-05 21:05:11,925 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7400 | Iter Mean Loss 3.9414
2020-11-05 21:05:11,927 - root - INFO - Evaluate: Epoch 0759 | NDCG 0.2817 | MSE 0.3197
2020-11-05 21:05:11,935 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4153 | Iter Mean Loss 5.4153
2020-11-05 21:05:11,943 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4732 | Iter Mean Loss 3.4442
2020-11-05 21:05:11,951 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4152 | Iter Mean Loss 4.1012
2020-11-05 21:05:11,958 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6445 | Iter Mean Loss 4.2371
2020-11-05 21:05:11,966 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7354 | Iter Mean Loss 3.9367
2020-11-05 21:05:11,969 - root - INFO - Evaluate: Epoch 0760 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:11,977 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4119 | Iter Mean Loss 5.4119
2020-11-05 21:05:11,985 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4712 | Iter Mean Loss 3.4416
2020-11-05 21:05:11,993 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4081 | Iter Mean Loss 4.0971
2020-11-05 21:05:12,000 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6383 | Iter Mean Loss 4.2324
2020-11-05 21:05:12,008 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7309 | Iter Mean Loss 3.9321
2020-11-05 21:05:12,010 - root - INFO - Evaluate: Epoch 0761 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:12,018 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4086 | Iter Mean Loss 5.4086
2020-11-05 21:05:12,025 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4692 | Iter Mean Loss 3.4389
2020-11-05 21:05:12,032 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4011 | Iter Mean Loss 4.0930
2020-11-05 21:05:12,039 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6320 | Iter Mean Loss 4.2277
2020-11-05 21:05:12,047 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7265 | Iter Mean Loss 3.9275
2020-11-05 21:05:12,048 - root - INFO - Evaluate: Epoch 0762 | NDCG 0.2817 | MSE 0.3198
2020-11-05 21:05:12,056 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4052 | Iter Mean Loss 5.4052
2020-11-05 21:05:12,063 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4672 | Iter Mean Loss 3.4362
2020-11-05 21:05:12,071 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3941 | Iter Mean Loss 4.0888
2020-11-05 21:05:12,078 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6258 | Iter Mean Loss 4.2231
2020-11-05 21:05:12,085 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7220 | Iter Mean Loss 3.9229
2020-11-05 21:05:12,087 - root - INFO - Evaluate: Epoch 0763 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:12,095 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4018 | Iter Mean Loss 5.4018
2020-11-05 21:05:12,102 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4653 | Iter Mean Loss 3.4336
2020-11-05 21:05:12,109 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3872 | Iter Mean Loss 4.0848
2020-11-05 21:05:12,117 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6196 | Iter Mean Loss 4.2185
2020-11-05 21:05:12,125 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7176 | Iter Mean Loss 3.9183
2020-11-05 21:05:12,127 - root - INFO - Evaluate: Epoch 0764 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:12,135 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3985 | Iter Mean Loss 5.3985
2020-11-05 21:05:12,143 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4633 | Iter Mean Loss 3.4309
2020-11-05 21:05:12,150 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3802 | Iter Mean Loss 4.0807
2020-11-05 21:05:12,158 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6134 | Iter Mean Loss 4.2139
2020-11-05 21:05:12,166 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7131 | Iter Mean Loss 3.9137
2020-11-05 21:05:12,168 - root - INFO - Evaluate: Epoch 0765 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:12,176 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3951 | Iter Mean Loss 5.3951
2020-11-05 21:05:12,184 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4614 | Iter Mean Loss 3.4283
2020-11-05 21:05:12,192 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3733 | Iter Mean Loss 4.0766
2020-11-05 21:05:12,199 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6072 | Iter Mean Loss 4.2093
2020-11-05 21:05:12,207 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7087 | Iter Mean Loss 3.9092
2020-11-05 21:05:12,209 - root - INFO - Evaluate: Epoch 0766 | NDCG 0.2817 | MSE 0.3199
2020-11-05 21:05:12,217 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3918 | Iter Mean Loss 5.3918
2020-11-05 21:05:12,224 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4595 | Iter Mean Loss 3.4257
2020-11-05 21:05:12,231 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3664 | Iter Mean Loss 4.0726
2020-11-05 21:05:12,238 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6011 | Iter Mean Loss 4.2047
2020-11-05 21:05:12,245 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7044 | Iter Mean Loss 3.9046
2020-11-05 21:05:12,247 - root - INFO - Evaluate: Epoch 0767 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:12,255 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3885 | Iter Mean Loss 5.3885
2020-11-05 21:05:12,262 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 3.4230
2020-11-05 21:05:12,269 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 4.0685
2020-11-05 21:05:12,276 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5950 | Iter Mean Loss 4.2001
2020-11-05 21:05:12,283 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7000 | Iter Mean Loss 3.9001
2020-11-05 21:05:12,285 - root - INFO - Evaluate: Epoch 0768 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:12,293 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3852 | Iter Mean Loss 5.3852
2020-11-05 21:05:12,300 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4557 | Iter Mean Loss 3.4204
2020-11-05 21:05:12,307 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3526 | Iter Mean Loss 4.0645
2020-11-05 21:05:12,315 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5889 | Iter Mean Loss 4.1956
2020-11-05 21:05:12,323 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 3.8956
2020-11-05 21:05:12,326 - root - INFO - Evaluate: Epoch 0769 | NDCG 0.2817 | MSE 0.3200
2020-11-05 21:05:12,333 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3818 | Iter Mean Loss 5.3818
2020-11-05 21:05:12,342 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4538 | Iter Mean Loss 3.4178
2020-11-05 21:05:12,349 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3457 | Iter Mean Loss 4.0605
2020-11-05 21:05:12,357 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5828 | Iter Mean Loss 4.1911
2020-11-05 21:05:12,364 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6913 | Iter Mean Loss 3.8911
2020-11-05 21:05:12,366 - root - INFO - Evaluate: Epoch 0770 | NDCG 0.2817 | MSE 0.3201
2020-11-05 21:05:12,375 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3785 | Iter Mean Loss 5.3785
2020-11-05 21:05:12,382 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4520 | Iter Mean Loss 3.4153
2020-11-05 21:05:12,390 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3389 | Iter Mean Loss 4.0565
2020-11-05 21:05:12,397 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5767 | Iter Mean Loss 4.1865
2020-11-05 21:05:12,405 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6870 | Iter Mean Loss 3.8866
2020-11-05 21:05:12,407 - root - INFO - Evaluate: Epoch 0771 | NDCG 0.2817 | MSE 0.3201
2020-11-05 21:05:12,415 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 5.3753
2020-11-05 21:05:12,423 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4501 | Iter Mean Loss 3.4127
2020-11-05 21:05:12,430 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3321 | Iter Mean Loss 4.0525
2020-11-05 21:05:12,437 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5707 | Iter Mean Loss 4.1820
2020-11-05 21:05:12,444 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 3.8822
2020-11-05 21:05:12,446 - root - INFO - Evaluate: Epoch 0772 | NDCG 0.2817 | MSE 0.3201
2020-11-05 21:05:12,454 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3720 | Iter Mean Loss 5.3720
2020-11-05 21:05:12,461 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4483 | Iter Mean Loss 3.4101
2020-11-05 21:05:12,468 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3253 | Iter Mean Loss 4.0485
2020-11-05 21:05:12,475 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5647 | Iter Mean Loss 4.1776
2020-11-05 21:05:12,482 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6785 | Iter Mean Loss 3.8777
2020-11-05 21:05:12,484 - root - INFO - Evaluate: Epoch 0773 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:12,492 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3687 | Iter Mean Loss 5.3687
2020-11-05 21:05:12,499 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4465 | Iter Mean Loss 3.4076
2020-11-05 21:05:12,506 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3185 | Iter Mean Loss 4.0446
2020-11-05 21:05:12,514 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5586 | Iter Mean Loss 4.1731
2020-11-05 21:05:12,521 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6742 | Iter Mean Loss 3.8733
2020-11-05 21:05:12,523 - root - INFO - Evaluate: Epoch 0774 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:12,531 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3654 | Iter Mean Loss 5.3654
2020-11-05 21:05:12,539 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4447 | Iter Mean Loss 3.4050
2020-11-05 21:05:12,546 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3118 | Iter Mean Loss 4.0406
2020-11-05 21:05:12,554 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5527 | Iter Mean Loss 4.1686
2020-11-05 21:05:12,561 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6700 | Iter Mean Loss 3.8689
2020-11-05 21:05:12,563 - root - INFO - Evaluate: Epoch 0775 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:12,572 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3622 | Iter Mean Loss 5.3622
2020-11-05 21:05:12,580 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4429 | Iter Mean Loss 3.4025
2020-11-05 21:05:12,588 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3050 | Iter Mean Loss 4.0367
2020-11-05 21:05:12,595 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5467 | Iter Mean Loss 4.1642
2020-11-05 21:05:12,603 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6658 | Iter Mean Loss 3.8645
2020-11-05 21:05:12,605 - root - INFO - Evaluate: Epoch 0776 | NDCG 0.2817 | MSE 0.3202
2020-11-05 21:05:12,613 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3589 | Iter Mean Loss 5.3589
2020-11-05 21:05:12,621 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4411 | Iter Mean Loss 3.4000
2020-11-05 21:05:12,629 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 4.0328
2020-11-05 21:05:12,636 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5407 | Iter Mean Loss 4.1598
2020-11-05 21:05:12,643 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6616 | Iter Mean Loss 3.8601
2020-11-05 21:05:12,645 - root - INFO - Evaluate: Epoch 0777 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:12,652 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3557 | Iter Mean Loss 5.3557
2020-11-05 21:05:12,660 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4393 | Iter Mean Loss 3.3975
2020-11-05 21:05:12,667 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2916 | Iter Mean Loss 4.0289
2020-11-05 21:05:12,674 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5348 | Iter Mean Loss 4.1553
2020-11-05 21:05:12,681 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6574 | Iter Mean Loss 3.8558
2020-11-05 21:05:12,683 - root - INFO - Evaluate: Epoch 0778 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:12,691 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3524 | Iter Mean Loss 5.3524
2020-11-05 21:05:12,698 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4375 | Iter Mean Loss 3.3950
2020-11-05 21:05:12,705 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2850 | Iter Mean Loss 4.0250
2020-11-05 21:05:12,712 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5289 | Iter Mean Loss 4.1509
2020-11-05 21:05:12,719 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6532 | Iter Mean Loss 3.8514
2020-11-05 21:05:12,721 - root - INFO - Evaluate: Epoch 0779 | NDCG 0.2817 | MSE 0.3203
2020-11-05 21:05:12,729 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3492 | Iter Mean Loss 5.3492
2020-11-05 21:05:12,737 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 3.3925
2020-11-05 21:05:12,744 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2783 | Iter Mean Loss 4.0211
2020-11-05 21:05:12,752 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5230 | Iter Mean Loss 4.1466
2020-11-05 21:05:12,760 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6491 | Iter Mean Loss 3.8471
2020-11-05 21:05:12,762 - root - INFO - Evaluate: Epoch 0780 | NDCG 0.2817 | MSE 0.3204
2020-11-05 21:05:12,770 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3460 | Iter Mean Loss 5.3460
2020-11-05 21:05:12,778 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4340 | Iter Mean Loss 3.3900
2020-11-05 21:05:12,785 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2717 | Iter Mean Loss 4.0172
2020-11-05 21:05:12,793 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 4.1422
2020-11-05 21:05:12,800 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6449 | Iter Mean Loss 3.8427
2020-11-05 21:05:12,802 - root - INFO - Evaluate: Epoch 0781 | NDCG 0.2817 | MSE 0.3204
2020-11-05 21:05:12,811 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3427 | Iter Mean Loss 5.3427
2020-11-05 21:05:12,818 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4323 | Iter Mean Loss 3.3875
2020-11-05 21:05:12,826 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2650 | Iter Mean Loss 4.0133
2020-11-05 21:05:12,833 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5112 | Iter Mean Loss 4.1378
2020-11-05 21:05:12,840 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6408 | Iter Mean Loss 3.8384
2020-11-05 21:05:12,842 - root - INFO - Evaluate: Epoch 0782 | NDCG 0.2817 | MSE 0.3204
2020-11-05 21:05:12,850 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3395 | Iter Mean Loss 5.3395
2020-11-05 21:05:12,857 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4305 | Iter Mean Loss 3.3850
2020-11-05 21:05:12,864 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2584 | Iter Mean Loss 4.0095
2020-11-05 21:05:12,871 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5054 | Iter Mean Loss 4.1335
2020-11-05 21:05:12,879 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6367 | Iter Mean Loss 3.8341
2020-11-05 21:05:12,880 - root - INFO - Evaluate: Epoch 0783 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:12,888 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3363 | Iter Mean Loss 5.3363
2020-11-05 21:05:12,896 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4288 | Iter Mean Loss 3.3826
2020-11-05 21:05:12,903 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2518 | Iter Mean Loss 4.0057
2020-11-05 21:05:12,910 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4996 | Iter Mean Loss 4.1291
2020-11-05 21:05:12,917 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6326 | Iter Mean Loss 3.8298
2020-11-05 21:05:12,919 - root - INFO - Evaluate: Epoch 0784 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:12,928 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3331 | Iter Mean Loss 5.3331
2020-11-05 21:05:12,936 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4271 | Iter Mean Loss 3.3801
2020-11-05 21:05:12,943 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.0018
2020-11-05 21:05:12,950 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4938 | Iter Mean Loss 4.1248
2020-11-05 21:05:12,958 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6286 | Iter Mean Loss 3.8256
2020-11-05 21:05:12,960 - root - INFO - Evaluate: Epoch 0785 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:12,968 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3299 | Iter Mean Loss 5.3299
2020-11-05 21:05:12,977 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4254 | Iter Mean Loss 3.3777
2020-11-05 21:05:12,984 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2387 | Iter Mean Loss 3.9980
2020-11-05 21:05:12,992 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4880 | Iter Mean Loss 4.1205
2020-11-05 21:05:13,000 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6245 | Iter Mean Loss 3.8213
2020-11-05 21:05:13,002 - root - INFO - Evaluate: Epoch 0786 | NDCG 0.2817 | MSE 0.3205
2020-11-05 21:05:13,010 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3267 | Iter Mean Loss 5.3267
2020-11-05 21:05:13,018 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4237 | Iter Mean Loss 3.3752
2020-11-05 21:05:13,026 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2322 | Iter Mean Loss 3.9942
2020-11-05 21:05:13,033 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4822 | Iter Mean Loss 4.1162
2020-11-05 21:05:13,041 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6205 | Iter Mean Loss 3.8171
2020-11-05 21:05:13,043 - root - INFO - Evaluate: Epoch 0787 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:13,050 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3236 | Iter Mean Loss 5.3236
2020-11-05 21:05:13,058 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4220 | Iter Mean Loss 3.3728
2020-11-05 21:05:13,065 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2256 | Iter Mean Loss 3.9904
2020-11-05 21:05:13,072 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4764 | Iter Mean Loss 4.1119
2020-11-05 21:05:13,079 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6165 | Iter Mean Loss 3.8128
2020-11-05 21:05:13,081 - root - INFO - Evaluate: Epoch 0788 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:13,088 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3204 | Iter Mean Loss 5.3204
2020-11-05 21:05:13,096 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4204 | Iter Mean Loss 3.3704
2020-11-05 21:05:13,103 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2191 | Iter Mean Loss 3.9866
2020-11-05 21:05:13,110 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4707 | Iter Mean Loss 4.1076
2020-11-05 21:05:13,117 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6125 | Iter Mean Loss 3.8086
2020-11-05 21:05:13,119 - root - INFO - Evaluate: Epoch 0789 | NDCG 0.2817 | MSE 0.3206
2020-11-05 21:05:13,127 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3172 | Iter Mean Loss 5.3172
2020-11-05 21:05:13,134 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4187 | Iter Mean Loss 3.3680
2020-11-05 21:05:13,142 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2126 | Iter Mean Loss 3.9829
2020-11-05 21:05:13,149 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4649 | Iter Mean Loss 4.1034
2020-11-05 21:05:13,157 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6085 | Iter Mean Loss 3.8044
2020-11-05 21:05:13,159 - root - INFO - Evaluate: Epoch 0790 | NDCG 0.2817 | MSE 0.3207
2020-11-05 21:05:13,167 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3141 | Iter Mean Loss 5.3141
2020-11-05 21:05:13,175 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4171 | Iter Mean Loss 3.3656
2020-11-05 21:05:13,183 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2062 | Iter Mean Loss 3.9791
2020-11-05 21:05:13,190 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4592 | Iter Mean Loss 4.0991
2020-11-05 21:05:13,198 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6045 | Iter Mean Loss 3.8002
2020-11-05 21:05:13,200 - root - INFO - Evaluate: Epoch 0791 | NDCG 0.2817 | MSE 0.3207
2020-11-05 21:05:13,208 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3109 | Iter Mean Loss 5.3109
2020-11-05 21:05:13,216 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 3.3632
2020-11-05 21:05:13,224 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1997 | Iter Mean Loss 3.9753
2020-11-05 21:05:13,231 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 4.0949
2020-11-05 21:05:13,239 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6005 | Iter Mean Loss 3.7960
2020-11-05 21:05:13,241 - root - INFO - Evaluate: Epoch 0792 | NDCG 0.2817 | MSE 0.3207
2020-11-05 21:05:13,249 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3078 | Iter Mean Loss 5.3078
2020-11-05 21:05:13,256 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4138 | Iter Mean Loss 3.3608
2020-11-05 21:05:13,263 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1933 | Iter Mean Loss 3.9716
2020-11-05 21:05:13,270 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 4.0907
2020-11-05 21:05:13,277 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5966 | Iter Mean Loss 3.7918
2020-11-05 21:05:13,279 - root - INFO - Evaluate: Epoch 0793 | NDCG 0.2817 | MSE 0.3208
2020-11-05 21:05:13,287 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3046 | Iter Mean Loss 5.3046
2020-11-05 21:05:13,294 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4122 | Iter Mean Loss 3.3584
2020-11-05 21:05:13,302 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1868 | Iter Mean Loss 3.9679
2020-11-05 21:05:13,308 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4422 | Iter Mean Loss 4.0864
2020-11-05 21:05:13,316 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5927 | Iter Mean Loss 3.7877
2020-11-05 21:05:13,319 - root - INFO - Evaluate: Epoch 0794 | NDCG 0.2817 | MSE 0.3208
2020-11-05 21:05:13,328 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3015 | Iter Mean Loss 5.3015
2020-11-05 21:05:13,335 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4105 | Iter Mean Loss 3.3560
2020-11-05 21:05:13,343 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1804 | Iter Mean Loss 3.9641
2020-11-05 21:05:13,351 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4365 | Iter Mean Loss 4.0822
2020-11-05 21:05:13,358 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5887 | Iter Mean Loss 3.7835
2020-11-05 21:05:13,361 - root - INFO - Evaluate: Epoch 0795 | NDCG 0.2817 | MSE 0.3208
2020-11-05 21:05:13,369 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 5.2983
2020-11-05 21:05:13,377 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4089 | Iter Mean Loss 3.3536
2020-11-05 21:05:13,385 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1740 | Iter Mean Loss 3.9604
2020-11-05 21:05:13,394 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4309 | Iter Mean Loss 4.0780
2020-11-05 21:05:13,401 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5848 | Iter Mean Loss 3.7794
2020-11-05 21:05:13,404 - root - INFO - Evaluate: Epoch 0796 | NDCG 0.2817 | MSE 0.3209
2020-11-05 21:05:13,412 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2952 | Iter Mean Loss 5.2952
2020-11-05 21:05:13,420 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4073 | Iter Mean Loss 3.3513
2020-11-05 21:05:13,428 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1677 | Iter Mean Loss 3.9567
2020-11-05 21:05:13,435 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4253 | Iter Mean Loss 4.0739
2020-11-05 21:05:13,443 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5809 | Iter Mean Loss 3.7753
2020-11-05 21:05:13,445 - root - INFO - Evaluate: Epoch 0797 | NDCG 0.2817 | MSE 0.3209
2020-11-05 21:05:13,452 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2921 | Iter Mean Loss 5.2921
2020-11-05 21:05:13,460 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4057 | Iter Mean Loss 3.3489
2020-11-05 21:05:13,467 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1613 | Iter Mean Loss 3.9530
2020-11-05 21:05:13,474 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4197 | Iter Mean Loss 4.0697
2020-11-05 21:05:13,481 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5771 | Iter Mean Loss 3.7712
2020-11-05 21:05:13,483 - root - INFO - Evaluate: Epoch 0798 | NDCG 0.2817 | MSE 0.3209
2020-11-05 21:05:13,491 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2890 | Iter Mean Loss 5.2890
2020-11-05 21:05:13,498 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4041 | Iter Mean Loss 3.3466
2020-11-05 21:05:13,505 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1549 | Iter Mean Loss 3.9494
2020-11-05 21:05:13,512 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4141 | Iter Mean Loss 4.0655
2020-11-05 21:05:13,520 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 3.7671
2020-11-05 21:05:13,521 - root - INFO - Evaluate: Epoch 0799 | NDCG 0.2817 | MSE 0.3210
2020-11-05 21:05:13,529 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2859 | Iter Mean Loss 5.2859
2020-11-05 21:05:13,537 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4025 | Iter Mean Loss 3.3442
2020-11-05 21:05:13,544 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1486 | Iter Mean Loss 3.9457
2020-11-05 21:05:13,552 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4085 | Iter Mean Loss 4.0614
2020-11-05 21:05:13,559 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5694 | Iter Mean Loss 3.7630
2020-11-05 21:05:13,561 - root - INFO - Evaluate: Epoch 0800 | NDCG 0.2817 | MSE 0.3210
2020-11-05 21:05:13,569 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2828 | Iter Mean Loss 5.2828
2020-11-05 21:05:13,577 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4010 | Iter Mean Loss 3.3419
2020-11-05 21:05:13,585 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1423 | Iter Mean Loss 3.9420
2020-11-05 21:05:13,593 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4029 | Iter Mean Loss 4.0572
2020-11-05 21:05:13,600 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5655 | Iter Mean Loss 3.7589
2020-11-05 21:05:13,603 - root - INFO - Evaluate: Epoch 0801 | NDCG 0.2817 | MSE 0.3210
2020-11-05 21:05:13,612 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2797 | Iter Mean Loss 5.2797
2020-11-05 21:05:13,619 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3994 | Iter Mean Loss 3.3395
2020-11-05 21:05:13,627 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1360 | Iter Mean Loss 3.9383
2020-11-05 21:05:13,634 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3974 | Iter Mean Loss 4.0531
2020-11-05 21:05:13,642 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5617 | Iter Mean Loss 3.7548
2020-11-05 21:05:13,645 - root - INFO - Evaluate: Epoch 0802 | NDCG 0.2817 | MSE 0.3211
2020-11-05 21:05:13,652 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2766 | Iter Mean Loss 5.2766
2020-11-05 21:05:13,660 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3978 | Iter Mean Loss 3.3372
2020-11-05 21:05:13,667 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1297 | Iter Mean Loss 3.9347
2020-11-05 21:05:13,674 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3918 | Iter Mean Loss 4.0490
2020-11-05 21:05:13,681 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5579 | Iter Mean Loss 3.7508
2020-11-05 21:05:13,683 - root - INFO - Evaluate: Epoch 0803 | NDCG 0.2817 | MSE 0.3211
2020-11-05 21:05:13,690 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2735 | Iter Mean Loss 5.2735
2020-11-05 21:05:13,698 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3963 | Iter Mean Loss 3.3349
2020-11-05 21:05:13,705 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1234 | Iter Mean Loss 3.9311
2020-11-05 21:05:13,712 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3863 | Iter Mean Loss 4.0449
2020-11-05 21:05:13,719 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5541 | Iter Mean Loss 3.7467
2020-11-05 21:05:13,721 - root - INFO - Evaluate: Epoch 0804 | NDCG 0.2817 | MSE 0.3211
2020-11-05 21:05:13,729 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2704 | Iter Mean Loss 5.2704
2020-11-05 21:05:13,736 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3947 | Iter Mean Loss 3.3326
2020-11-05 21:05:13,743 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1172 | Iter Mean Loss 3.9274
2020-11-05 21:05:13,751 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3808 | Iter Mean Loss 4.0408
2020-11-05 21:05:13,758 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5503 | Iter Mean Loss 3.7427
2020-11-05 21:05:13,760 - root - INFO - Evaluate: Epoch 0805 | NDCG 0.2817 | MSE 0.3212
2020-11-05 21:05:13,768 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2673 | Iter Mean Loss 5.2673
2020-11-05 21:05:13,776 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3932 | Iter Mean Loss 3.3303
2020-11-05 21:05:13,783 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1109 | Iter Mean Loss 3.9238
2020-11-05 21:05:13,791 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3753 | Iter Mean Loss 4.0367
2020-11-05 21:05:13,799 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5465 | Iter Mean Loss 3.7387
2020-11-05 21:05:13,801 - root - INFO - Evaluate: Epoch 0806 | NDCG 0.2817 | MSE 0.3212
2020-11-05 21:05:13,810 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2642 | Iter Mean Loss 5.2642
2020-11-05 21:05:13,817 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3917 | Iter Mean Loss 3.3279
2020-11-05 21:05:13,825 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1047 | Iter Mean Loss 3.9202
2020-11-05 21:05:13,833 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3698 | Iter Mean Loss 4.0326
2020-11-05 21:05:13,840 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5428 | Iter Mean Loss 3.7346
2020-11-05 21:05:13,842 - root - INFO - Evaluate: Epoch 0807 | NDCG 0.2817 | MSE 0.3212
2020-11-05 21:05:13,850 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2612 | Iter Mean Loss 5.2612
2020-11-05 21:05:13,858 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3901 | Iter Mean Loss 3.3256
2020-11-05 21:05:13,865 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0985 | Iter Mean Loss 3.9166
2020-11-05 21:05:13,872 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3644 | Iter Mean Loss 4.0285
2020-11-05 21:05:13,879 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5390 | Iter Mean Loss 3.7306
2020-11-05 21:05:13,881 - root - INFO - Evaluate: Epoch 0808 | NDCG 0.2817 | MSE 0.3213
2020-11-05 21:05:13,888 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2581 | Iter Mean Loss 5.2581
2020-11-05 21:05:13,896 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3886 | Iter Mean Loss 3.3234
2020-11-05 21:05:13,903 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0922 | Iter Mean Loss 3.9130
2020-11-05 21:05:13,910 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 4.0245
2020-11-05 21:05:13,918 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5353 | Iter Mean Loss 3.7266
2020-11-05 21:05:13,920 - root - INFO - Evaluate: Epoch 0809 | NDCG 0.2817 | MSE 0.3213
2020-11-05 21:05:13,928 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2550 | Iter Mean Loss 5.2550
2020-11-05 21:05:13,935 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3871 | Iter Mean Loss 3.3211
2020-11-05 21:05:13,942 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0861 | Iter Mean Loss 3.9094
2020-11-05 21:05:13,949 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3535 | Iter Mean Loss 4.0204
2020-11-05 21:05:13,957 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5316 | Iter Mean Loss 3.7227
2020-11-05 21:05:13,959 - root - INFO - Evaluate: Epoch 0810 | NDCG 0.2817 | MSE 0.3213
2020-11-05 21:05:13,967 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2520 | Iter Mean Loss 5.2520
2020-11-05 21:05:13,976 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3856 | Iter Mean Loss 3.3188
2020-11-05 21:05:13,983 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0799 | Iter Mean Loss 3.9058
2020-11-05 21:05:13,991 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3481 | Iter Mean Loss 4.0164
2020-11-05 21:05:13,998 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5279 | Iter Mean Loss 3.7187
2020-11-05 21:05:14,000 - root - INFO - Evaluate: Epoch 0811 | NDCG 0.2817 | MSE 0.3214
2020-11-05 21:05:14,009 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2489 | Iter Mean Loss 5.2489
2020-11-05 21:05:14,017 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3841 | Iter Mean Loss 3.3165
2020-11-05 21:05:14,025 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0737 | Iter Mean Loss 3.9022
2020-11-05 21:05:14,032 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3427 | Iter Mean Loss 4.0123
2020-11-05 21:05:14,039 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5242 | Iter Mean Loss 3.7147
2020-11-05 21:05:14,041 - root - INFO - Evaluate: Epoch 0812 | NDCG 0.2817 | MSE 0.3214
2020-11-05 21:05:14,050 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2458 | Iter Mean Loss 5.2458
2020-11-05 21:05:14,057 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3826 | Iter Mean Loss 3.3142
2020-11-05 21:05:14,064 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0676 | Iter Mean Loss 3.8987
2020-11-05 21:05:14,071 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3373 | Iter Mean Loss 4.0083
2020-11-05 21:05:14,079 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5205 | Iter Mean Loss 3.7108
2020-11-05 21:05:14,080 - root - INFO - Evaluate: Epoch 0813 | NDCG 0.2817 | MSE 0.3214
2020-11-05 21:05:14,088 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2428 | Iter Mean Loss 5.2428
2020-11-05 21:05:14,096 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3811 | Iter Mean Loss 3.3120
2020-11-05 21:05:14,103 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0614 | Iter Mean Loss 3.8951
2020-11-05 21:05:14,110 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3319 | Iter Mean Loss 4.0043
2020-11-05 21:05:14,117 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5168 | Iter Mean Loss 3.7068
2020-11-05 21:05:14,119 - root - INFO - Evaluate: Epoch 0814 | NDCG 0.2817 | MSE 0.3215
2020-11-05 21:05:14,127 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2398 | Iter Mean Loss 5.2398
2020-11-05 21:05:14,134 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3796 | Iter Mean Loss 3.3097
2020-11-05 21:05:14,141 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0553 | Iter Mean Loss 3.8916
2020-11-05 21:05:14,148 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3265 | Iter Mean Loss 4.0003
2020-11-05 21:05:14,156 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5132 | Iter Mean Loss 3.7029
2020-11-05 21:05:14,158 - root - INFO - Evaluate: Epoch 0815 | NDCG 0.2817 | MSE 0.3215
2020-11-05 21:05:14,166 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2367 | Iter Mean Loss 5.2367
2020-11-05 21:05:14,174 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 3.3074
2020-11-05 21:05:14,182 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0492 | Iter Mean Loss 3.8880
2020-11-05 21:05:14,189 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3212 | Iter Mean Loss 3.9963
2020-11-05 21:05:14,197 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5095 | Iter Mean Loss 3.6989
2020-11-05 21:05:14,199 - root - INFO - Evaluate: Epoch 0816 | NDCG 0.2817 | MSE 0.3215
2020-11-05 21:05:14,207 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2337 | Iter Mean Loss 5.2337
2020-11-05 21:05:14,216 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3767 | Iter Mean Loss 3.3052
2020-11-05 21:05:14,223 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0431 | Iter Mean Loss 3.8845
2020-11-05 21:05:14,231 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3158 | Iter Mean Loss 3.9923
2020-11-05 21:05:14,238 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5059 | Iter Mean Loss 3.6950
2020-11-05 21:05:14,240 - root - INFO - Evaluate: Epoch 0817 | NDCG 0.2817 | MSE 0.3216
2020-11-05 21:05:14,249 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2306 | Iter Mean Loss 5.2306
2020-11-05 21:05:14,257 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3752 | Iter Mean Loss 3.3029
2020-11-05 21:05:14,264 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0370 | Iter Mean Loss 3.8809
2020-11-05 21:05:14,271 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3105 | Iter Mean Loss 3.9883
2020-11-05 21:05:14,278 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5023 | Iter Mean Loss 3.6911
2020-11-05 21:05:14,280 - root - INFO - Evaluate: Epoch 0818 | NDCG 0.2817 | MSE 0.3216
2020-11-05 21:05:14,288 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2276 | Iter Mean Loss 5.2276
2020-11-05 21:05:14,295 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3737 | Iter Mean Loss 3.3007
2020-11-05 21:05:14,302 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0309 | Iter Mean Loss 3.8774
2020-11-05 21:05:14,309 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3052 | Iter Mean Loss 3.9844
2020-11-05 21:05:14,317 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4987 | Iter Mean Loss 3.6872
2020-11-05 21:05:14,320 - root - INFO - Evaluate: Epoch 0819 | NDCG 0.2817 | MSE 0.3217
2020-11-05 21:05:14,329 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2246 | Iter Mean Loss 5.2246
2020-11-05 21:05:14,336 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3723 | Iter Mean Loss 3.2984
2020-11-05 21:05:14,343 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0248 | Iter Mean Loss 3.8739
2020-11-05 21:05:14,350 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.9804
2020-11-05 21:05:14,357 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4951 | Iter Mean Loss 3.6833
2020-11-05 21:05:14,360 - root - INFO - Evaluate: Epoch 0820 | NDCG 0.2817 | MSE 0.3217
2020-11-05 21:05:14,368 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2216 | Iter Mean Loss 5.2216
2020-11-05 21:05:14,376 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3708 | Iter Mean Loss 3.2962
2020-11-05 21:05:14,383 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0188 | Iter Mean Loss 3.8704
2020-11-05 21:05:14,391 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 3.9764
2020-11-05 21:05:14,399 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4915 | Iter Mean Loss 3.6794
2020-11-05 21:05:14,401 - root - INFO - Evaluate: Epoch 0821 | NDCG 0.2817 | MSE 0.3217
2020-11-05 21:05:14,410 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2185 | Iter Mean Loss 5.2185
2020-11-05 21:05:14,417 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3694 | Iter Mean Loss 3.2940
2020-11-05 21:05:14,425 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0128 | Iter Mean Loss 3.8669
2020-11-05 21:05:14,433 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2893 | Iter Mean Loss 3.9725
2020-11-05 21:05:14,441 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4879 | Iter Mean Loss 3.6756
2020-11-05 21:05:14,443 - root - INFO - Evaluate: Epoch 0822 | NDCG 0.2817 | MSE 0.3218
2020-11-05 21:05:14,451 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2155 | Iter Mean Loss 5.2155
2020-11-05 21:05:14,459 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3679 | Iter Mean Loss 3.2917
2020-11-05 21:05:14,467 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0067 | Iter Mean Loss 3.8634
2020-11-05 21:05:14,474 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2840 | Iter Mean Loss 3.9686
2020-11-05 21:05:14,481 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4843 | Iter Mean Loss 3.6717
2020-11-05 21:05:14,483 - root - INFO - Evaluate: Epoch 0823 | NDCG 0.2817 | MSE 0.3218
2020-11-05 21:05:14,491 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2125 | Iter Mean Loss 5.2125
2020-11-05 21:05:14,498 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3665 | Iter Mean Loss 3.2895
2020-11-05 21:05:14,505 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0007 | Iter Mean Loss 3.8599
2020-11-05 21:05:14,512 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 3.9646
2020-11-05 21:05:14,520 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4808 | Iter Mean Loss 3.6679
2020-11-05 21:05:14,522 - root - INFO - Evaluate: Epoch 0824 | NDCG 0.2817 | MSE 0.3218
2020-11-05 21:05:14,529 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2095 | Iter Mean Loss 5.2095
2020-11-05 21:05:14,537 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3651 | Iter Mean Loss 3.2873
2020-11-05 21:05:14,544 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9947 | Iter Mean Loss 3.8564
2020-11-05 21:05:14,551 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2735 | Iter Mean Loss 3.9607
2020-11-05 21:05:14,558 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4772 | Iter Mean Loss 3.6640
2020-11-05 21:05:14,560 - root - INFO - Evaluate: Epoch 0825 | NDCG 0.2817 | MSE 0.3219
2020-11-05 21:05:14,568 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2065 | Iter Mean Loss 5.2065
2020-11-05 21:05:14,576 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3636 | Iter Mean Loss 3.2851
2020-11-05 21:05:14,584 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9887 | Iter Mean Loss 3.8529
2020-11-05 21:05:14,592 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2683 | Iter Mean Loss 3.9568
2020-11-05 21:05:14,599 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4737 | Iter Mean Loss 3.6602
2020-11-05 21:05:14,602 - root - INFO - Evaluate: Epoch 0826 | NDCG 0.2817 | MSE 0.3219
2020-11-05 21:05:14,611 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2035 | Iter Mean Loss 5.2035
2020-11-05 21:05:14,618 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3622 | Iter Mean Loss 3.2828
2020-11-05 21:05:14,627 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9827 | Iter Mean Loss 3.8495
2020-11-05 21:05:14,634 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 3.9529
2020-11-05 21:05:14,642 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4701 | Iter Mean Loss 3.6563
2020-11-05 21:05:14,644 - root - INFO - Evaluate: Epoch 0827 | NDCG 0.2817 | MSE 0.3219
2020-11-05 21:05:14,652 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2005 | Iter Mean Loss 5.2005
2020-11-05 21:05:14,660 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3608 | Iter Mean Loss 3.2806
2020-11-05 21:05:14,668 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9768 | Iter Mean Loss 3.8460
2020-11-05 21:05:14,675 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2579 | Iter Mean Loss 3.9490
2020-11-05 21:05:14,682 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4666 | Iter Mean Loss 3.6525
2020-11-05 21:05:14,684 - root - INFO - Evaluate: Epoch 0828 | NDCG 0.2817 | MSE 0.3220
2020-11-05 21:05:14,692 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1975 | Iter Mean Loss 5.1975
2020-11-05 21:05:14,699 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 3.2784
2020-11-05 21:05:14,706 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9708 | Iter Mean Loss 3.8426
2020-11-05 21:05:14,713 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2527 | Iter Mean Loss 3.9451
2020-11-05 21:05:14,720 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4631 | Iter Mean Loss 3.6487
2020-11-05 21:05:14,722 - root - INFO - Evaluate: Epoch 0829 | NDCG 0.2817 | MSE 0.3220
2020-11-05 21:05:14,730 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1945 | Iter Mean Loss 5.1945
2020-11-05 21:05:14,737 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3580 | Iter Mean Loss 3.2762
2020-11-05 21:05:14,744 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9649 | Iter Mean Loss 3.8391
2020-11-05 21:05:14,751 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2475 | Iter Mean Loss 3.9412
2020-11-05 21:05:14,758 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4596 | Iter Mean Loss 3.6449
2020-11-05 21:05:14,761 - root - INFO - Evaluate: Epoch 0830 | NDCG 0.2817 | MSE 0.3221
2020-11-05 21:05:14,769 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1915 | Iter Mean Loss 5.1915
2020-11-05 21:05:14,777 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3566 | Iter Mean Loss 3.2740
2020-11-05 21:05:14,784 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 3.8357
2020-11-05 21:05:14,792 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2423 | Iter Mean Loss 3.9373
2020-11-05 21:05:14,800 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4561 | Iter Mean Loss 3.6411
2020-11-05 21:05:14,802 - root - INFO - Evaluate: Epoch 0831 | NDCG 0.2817 | MSE 0.3221
2020-11-05 21:05:14,811 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1885 | Iter Mean Loss 5.1885
2020-11-05 21:05:14,819 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3552 | Iter Mean Loss 3.2718
2020-11-05 21:05:14,827 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9530 | Iter Mean Loss 3.8322
2020-11-05 21:05:14,835 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2372 | Iter Mean Loss 3.9335
2020-11-05 21:05:14,843 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4527 | Iter Mean Loss 3.6373
2020-11-05 21:05:14,845 - root - INFO - Evaluate: Epoch 0832 | NDCG 0.2817 | MSE 0.3221
2020-11-05 21:05:14,853 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1855 | Iter Mean Loss 5.1855
2020-11-05 21:05:14,862 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3538 | Iter Mean Loss 3.2696
2020-11-05 21:05:14,869 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9471 | Iter Mean Loss 3.8288
2020-11-05 21:05:14,876 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2320 | Iter Mean Loss 3.9296
2020-11-05 21:05:14,883 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4492 | Iter Mean Loss 3.6335
2020-11-05 21:05:14,885 - root - INFO - Evaluate: Epoch 0833 | NDCG 0.2817 | MSE 0.3222
2020-11-05 21:05:14,893 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1825 | Iter Mean Loss 5.1825
2020-11-05 21:05:14,900 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3524 | Iter Mean Loss 3.2674
2020-11-05 21:05:14,908 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9412 | Iter Mean Loss 3.8254
2020-11-05 21:05:14,915 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2269 | Iter Mean Loss 3.9257
2020-11-05 21:05:14,923 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4457 | Iter Mean Loss 3.6297
2020-11-05 21:05:14,925 - root - INFO - Evaluate: Epoch 0834 | NDCG 0.2817 | MSE 0.3222
2020-11-05 21:05:14,933 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1795 | Iter Mean Loss 5.1795
2020-11-05 21:05:14,940 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3510 | Iter Mean Loss 3.2652
2020-11-05 21:05:14,947 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9353 | Iter Mean Loss 3.8219
2020-11-05 21:05:14,954 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 3.9219
2020-11-05 21:05:14,962 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4423 | Iter Mean Loss 3.6260
2020-11-05 21:05:14,964 - root - INFO - Evaluate: Epoch 0835 | NDCG 0.2817 | MSE 0.3222
2020-11-05 21:05:14,972 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1765 | Iter Mean Loss 5.1765
2020-11-05 21:05:14,980 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3496 | Iter Mean Loss 3.2631
2020-11-05 21:05:14,988 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9295 | Iter Mean Loss 3.8185
2020-11-05 21:05:14,996 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2166 | Iter Mean Loss 3.9181
2020-11-05 21:05:15,004 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4389 | Iter Mean Loss 3.6222
2020-11-05 21:05:15,006 - root - INFO - Evaluate: Epoch 0836 | NDCG 0.2817 | MSE 0.3223
2020-11-05 21:05:15,014 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1735 | Iter Mean Loss 5.1735
2020-11-05 21:05:15,023 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3482 | Iter Mean Loss 3.2609
2020-11-05 21:05:15,030 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 3.8151
2020-11-05 21:05:15,038 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2115 | Iter Mean Loss 3.9142
2020-11-05 21:05:15,047 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4354 | Iter Mean Loss 3.6185
2020-11-05 21:05:15,049 - root - INFO - Evaluate: Epoch 0837 | NDCG 0.2817 | MSE 0.3223
2020-11-05 21:05:15,057 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1706 | Iter Mean Loss 5.1706
2020-11-05 21:05:15,065 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3468 | Iter Mean Loss 3.2587
2020-11-05 21:05:15,073 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9178 | Iter Mean Loss 3.8117
2020-11-05 21:05:15,080 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2065 | Iter Mean Loss 3.9104
2020-11-05 21:05:15,087 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4320 | Iter Mean Loss 3.6147
2020-11-05 21:05:15,089 - root - INFO - Evaluate: Epoch 0838 | NDCG 0.2817 | MSE 0.3224
2020-11-05 21:05:15,097 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1676 | Iter Mean Loss 5.1676
2020-11-05 21:05:15,104 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3454 | Iter Mean Loss 3.2565
2020-11-05 21:05:15,111 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9119 | Iter Mean Loss 3.8083
2020-11-05 21:05:15,119 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2014 | Iter Mean Loss 3.9066
2020-11-05 21:05:15,126 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4286 | Iter Mean Loss 3.6110
2020-11-05 21:05:15,128 - root - INFO - Evaluate: Epoch 0839 | NDCG 0.2817 | MSE 0.3224
2020-11-05 21:05:15,136 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 5.1646
2020-11-05 21:05:15,143 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3441 | Iter Mean Loss 3.2543
2020-11-05 21:05:15,150 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9061 | Iter Mean Loss 3.8049
2020-11-05 21:05:15,157 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1963 | Iter Mean Loss 3.9028
2020-11-05 21:05:15,165 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4252 | Iter Mean Loss 3.6073
2020-11-05 21:05:15,167 - root - INFO - Evaluate: Epoch 0840 | NDCG 0.2817 | MSE 0.3224
2020-11-05 21:05:15,175 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1616 | Iter Mean Loss 5.1616
2020-11-05 21:05:15,183 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 3.2522
2020-11-05 21:05:15,190 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9003 | Iter Mean Loss 3.8015
2020-11-05 21:05:15,198 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1913 | Iter Mean Loss 3.8990
2020-11-05 21:05:15,205 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4218 | Iter Mean Loss 3.6035
2020-11-05 21:05:15,207 - root - INFO - Evaluate: Epoch 0841 | NDCG 0.2817 | MSE 0.3225
2020-11-05 21:05:15,216 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1586 | Iter Mean Loss 5.1586
2020-11-05 21:05:15,224 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 3.2500
2020-11-05 21:05:15,232 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8945 | Iter Mean Loss 3.7981
2020-11-05 21:05:15,239 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1862 | Iter Mean Loss 3.8952
2020-11-05 21:05:15,247 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4184 | Iter Mean Loss 3.5998
2020-11-05 21:05:15,249 - root - INFO - Evaluate: Epoch 0842 | NDCG 0.2817 | MSE 0.3225
2020-11-05 21:05:15,258 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1557 | Iter Mean Loss 5.1557
2020-11-05 21:05:15,266 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3400 | Iter Mean Loss 3.2478
2020-11-05 21:05:15,273 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8887 | Iter Mean Loss 3.7948
2020-11-05 21:05:15,280 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1812 | Iter Mean Loss 3.8914
2020-11-05 21:05:15,287 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4151 | Iter Mean Loss 3.5961
2020-11-05 21:05:15,289 - root - INFO - Evaluate: Epoch 0843 | NDCG 0.2817 | MSE 0.3225
2020-11-05 21:05:15,297 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1527 | Iter Mean Loss 5.1527
2020-11-05 21:05:15,305 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3386 | Iter Mean Loss 3.2456
2020-11-05 21:05:15,312 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8829 | Iter Mean Loss 3.7914
2020-11-05 21:05:15,320 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1761 | Iter Mean Loss 3.8876
2020-11-05 21:05:15,328 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4117 | Iter Mean Loss 3.5924
2020-11-05 21:05:15,330 - root - INFO - Evaluate: Epoch 0844 | NDCG 0.2817 | MSE 0.3226
2020-11-05 21:05:15,338 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1497 | Iter Mean Loss 5.1497
2020-11-05 21:05:15,345 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3372 | Iter Mean Loss 3.2435
2020-11-05 21:05:15,352 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8771 | Iter Mean Loss 3.7880
2020-11-05 21:05:15,359 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1711 | Iter Mean Loss 3.8838
2020-11-05 21:05:15,367 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4084 | Iter Mean Loss 3.5887
2020-11-05 21:05:15,369 - root - INFO - Evaluate: Epoch 0845 | NDCG 0.2817 | MSE 0.3226
2020-11-05 21:05:15,377 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1467 | Iter Mean Loss 5.1467
2020-11-05 21:05:15,385 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3359 | Iter Mean Loss 3.2413
2020-11-05 21:05:15,392 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8713 | Iter Mean Loss 3.7846
2020-11-05 21:05:15,399 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1661 | Iter Mean Loss 3.8800
2020-11-05 21:05:15,407 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4050 | Iter Mean Loss 3.5850
2020-11-05 21:05:15,409 - root - INFO - Evaluate: Epoch 0846 | NDCG 0.2817 | MSE 0.3227
2020-11-05 21:05:15,418 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1438 | Iter Mean Loss 5.1438
2020-11-05 21:05:15,426 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3345 | Iter Mean Loss 3.2391
2020-11-05 21:05:15,433 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8656 | Iter Mean Loss 3.7813
2020-11-05 21:05:15,441 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1611 | Iter Mean Loss 3.8762
2020-11-05 21:05:15,448 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4017 | Iter Mean Loss 3.5813
2020-11-05 21:05:15,451 - root - INFO - Evaluate: Epoch 0847 | NDCG 0.2817 | MSE 0.3227
2020-11-05 21:05:15,460 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1408 | Iter Mean Loss 5.1408
2020-11-05 21:05:15,467 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3332 | Iter Mean Loss 3.2370
2020-11-05 21:05:15,475 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8598 | Iter Mean Loss 3.7779
2020-11-05 21:05:15,482 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1561 | Iter Mean Loss 3.8725
2020-11-05 21:05:15,490 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3983 | Iter Mean Loss 3.5777
2020-11-05 21:05:15,492 - root - INFO - Evaluate: Epoch 0848 | NDCG 0.2817 | MSE 0.3227
2020-11-05 21:05:15,499 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1378 | Iter Mean Loss 5.1378
2020-11-05 21:05:15,507 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3318 | Iter Mean Loss 3.2348
2020-11-05 21:05:15,514 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8541 | Iter Mean Loss 3.7746
2020-11-05 21:05:15,521 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1512 | Iter Mean Loss 3.8687
2020-11-05 21:05:15,528 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3950 | Iter Mean Loss 3.5740
2020-11-05 21:05:15,530 - root - INFO - Evaluate: Epoch 0849 | NDCG 0.2817 | MSE 0.3228
2020-11-05 21:05:15,538 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1348 | Iter Mean Loss 5.1348
2020-11-05 21:05:15,545 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3305 | Iter Mean Loss 3.2327
2020-11-05 21:05:15,553 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8484 | Iter Mean Loss 3.7712
2020-11-05 21:05:15,560 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1462 | Iter Mean Loss 3.8650
2020-11-05 21:05:15,567 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3917 | Iter Mean Loss 3.5703
2020-11-05 21:05:15,569 - root - INFO - Evaluate: Epoch 0850 | NDCG 0.2817 | MSE 0.3228
2020-11-05 21:05:15,577 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1319 | Iter Mean Loss 5.1319
2020-11-05 21:05:15,585 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3292 | Iter Mean Loss 3.2305
2020-11-05 21:05:15,593 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8426 | Iter Mean Loss 3.7679
2020-11-05 21:05:15,600 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1413 | Iter Mean Loss 3.8612
2020-11-05 21:05:15,608 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3884 | Iter Mean Loss 3.5667
2020-11-05 21:05:15,610 - root - INFO - Evaluate: Epoch 0851 | NDCG 0.2817 | MSE 0.3229
2020-11-05 21:05:15,619 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1289 | Iter Mean Loss 5.1289
2020-11-05 21:05:15,627 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3278 | Iter Mean Loss 3.2284
2020-11-05 21:05:15,634 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8369 | Iter Mean Loss 3.7645
2020-11-05 21:05:15,642 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1363 | Iter Mean Loss 3.8575
2020-11-05 21:05:15,649 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3851 | Iter Mean Loss 3.5630
2020-11-05 21:05:15,652 - root - INFO - Evaluate: Epoch 0852 | NDCG 0.2817 | MSE 0.3229
2020-11-05 21:05:15,661 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1259 | Iter Mean Loss 5.1259
2020-11-05 21:05:15,668 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 3.2262
2020-11-05 21:05:15,676 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 3.7612
2020-11-05 21:05:15,683 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1314 | Iter Mean Loss 3.8538
2020-11-05 21:05:15,691 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3818 | Iter Mean Loss 3.5594
2020-11-05 21:05:15,693 - root - INFO - Evaluate: Epoch 0853 | NDCG 0.2817 | MSE 0.3229
2020-11-05 21:05:15,700 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1230 | Iter Mean Loss 5.1230
2020-11-05 21:05:15,708 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 3.2240
2020-11-05 21:05:15,715 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8255 | Iter Mean Loss 3.7579
2020-11-05 21:05:15,722 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1265 | Iter Mean Loss 3.8500
2020-11-05 21:05:15,729 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3786 | Iter Mean Loss 3.5557
2020-11-05 21:05:15,732 - root - INFO - Evaluate: Epoch 0854 | NDCG 0.2817 | MSE 0.3230
2020-11-05 21:05:15,739 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1200 | Iter Mean Loss 5.1200
2020-11-05 21:05:15,747 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3238 | Iter Mean Loss 3.2219
2020-11-05 21:05:15,754 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8199 | Iter Mean Loss 3.7546
2020-11-05 21:05:15,761 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1216 | Iter Mean Loss 3.8463
2020-11-05 21:05:15,768 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3753 | Iter Mean Loss 3.5521
2020-11-05 21:05:15,770 - root - INFO - Evaluate: Epoch 0855 | NDCG 0.2817 | MSE 0.3230
2020-11-05 21:05:15,778 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1170 | Iter Mean Loss 5.1170
2020-11-05 21:05:15,786 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3225 | Iter Mean Loss 3.2197
2020-11-05 21:05:15,794 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8142 | Iter Mean Loss 3.7512
2020-11-05 21:05:15,801 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1166 | Iter Mean Loss 3.8426
2020-11-05 21:05:15,809 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3720 | Iter Mean Loss 3.5485
2020-11-05 21:05:15,811 - root - INFO - Evaluate: Epoch 0856 | NDCG 0.2817 | MSE 0.3230
2020-11-05 21:05:15,820 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1140 | Iter Mean Loss 5.1140
2020-11-05 21:05:15,827 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3211 | Iter Mean Loss 3.2176
2020-11-05 21:05:15,835 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8085 | Iter Mean Loss 3.7479
2020-11-05 21:05:15,843 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1118 | Iter Mean Loss 3.8389
2020-11-05 21:05:15,851 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3688 | Iter Mean Loss 3.5448
2020-11-05 21:05:15,853 - root - INFO - Evaluate: Epoch 0857 | NDCG 0.2817 | MSE 0.3231
2020-11-05 21:05:15,861 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1111 | Iter Mean Loss 5.1111
2020-11-05 21:05:15,869 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3198 | Iter Mean Loss 3.2154
2020-11-05 21:05:15,877 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8029 | Iter Mean Loss 3.7446
2020-11-05 21:05:15,884 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1069 | Iter Mean Loss 3.8352
2020-11-05 21:05:15,891 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3655 | Iter Mean Loss 3.5412
2020-11-05 21:05:15,893 - root - INFO - Evaluate: Epoch 0858 | NDCG 0.2817 | MSE 0.3231
2020-11-05 21:05:15,901 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 5.1081
2020-11-05 21:05:15,908 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3185 | Iter Mean Loss 3.2133
2020-11-05 21:05:15,916 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7973 | Iter Mean Loss 3.7413
2020-11-05 21:05:15,923 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1020 | Iter Mean Loss 3.8315
2020-11-05 21:05:15,931 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3623 | Iter Mean Loss 3.5376
2020-11-05 21:05:15,933 - root - INFO - Evaluate: Epoch 0859 | NDCG 0.2817 | MSE 0.3232
2020-11-05 21:05:15,940 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1051 | Iter Mean Loss 5.1051
2020-11-05 21:05:15,948 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3172 | Iter Mean Loss 3.2111
2020-11-05 21:05:15,955 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7916 | Iter Mean Loss 3.7380
2020-11-05 21:05:15,962 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0971 | Iter Mean Loss 3.8278
2020-11-05 21:05:15,969 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3591 | Iter Mean Loss 3.5340
2020-11-05 21:05:15,971 - root - INFO - Evaluate: Epoch 0860 | NDCG 0.2817 | MSE 0.3232
2020-11-05 21:05:15,979 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1021 | Iter Mean Loss 5.1021
2020-11-05 21:05:15,988 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3158 | Iter Mean Loss 3.2090
2020-11-05 21:05:15,995 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7860 | Iter Mean Loss 3.7347
2020-11-05 21:05:16,003 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0923 | Iter Mean Loss 3.8241
2020-11-05 21:05:16,011 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3558 | Iter Mean Loss 3.5304
2020-11-05 21:05:16,013 - root - INFO - Evaluate: Epoch 0861 | NDCG 0.2817 | MSE 0.3232
2020-11-05 21:05:16,021 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0992 | Iter Mean Loss 5.0992
2020-11-05 21:05:16,029 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3145 | Iter Mean Loss 3.2068
2020-11-05 21:05:16,037 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7804 | Iter Mean Loss 3.7314
2020-11-05 21:05:16,044 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0874 | Iter Mean Loss 3.8204
2020-11-05 21:05:16,052 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3526 | Iter Mean Loss 3.5268
2020-11-05 21:05:16,054 - root - INFO - Evaluate: Epoch 0862 | NDCG 0.2817 | MSE 0.3233
2020-11-05 21:05:16,062 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0962 | Iter Mean Loss 5.0962
2020-11-05 21:05:16,070 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3132 | Iter Mean Loss 3.2047
2020-11-05 21:05:16,078 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7748 | Iter Mean Loss 3.7281
2020-11-05 21:05:16,085 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0826 | Iter Mean Loss 3.8167
2020-11-05 21:05:16,092 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3494 | Iter Mean Loss 3.5232
2020-11-05 21:05:16,094 - root - INFO - Evaluate: Epoch 0863 | NDCG 0.2817 | MSE 0.3233
2020-11-05 21:05:16,102 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0932 | Iter Mean Loss 5.0932
2020-11-05 21:05:16,109 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 3.2025
2020-11-05 21:05:16,116 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7692 | Iter Mean Loss 3.7248
2020-11-05 21:05:16,123 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0778 | Iter Mean Loss 3.8130
2020-11-05 21:05:16,130 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3462 | Iter Mean Loss 3.5197
2020-11-05 21:05:16,133 - root - INFO - Evaluate: Epoch 0864 | NDCG 0.2817 | MSE 0.3234
2020-11-05 21:05:16,140 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0902 | Iter Mean Loss 5.0902
2020-11-05 21:05:16,147 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3106 | Iter Mean Loss 3.2004
2020-11-05 21:05:16,155 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7636 | Iter Mean Loss 3.7215
2020-11-05 21:05:16,162 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0730 | Iter Mean Loss 3.8093
2020-11-05 21:05:16,169 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3430 | Iter Mean Loss 3.5161
2020-11-05 21:05:16,171 - root - INFO - Evaluate: Epoch 0865 | NDCG 0.2817 | MSE 0.3234
2020-11-05 21:05:16,179 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0872 | Iter Mean Loss 5.0872
2020-11-05 21:05:16,187 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3093 | Iter Mean Loss 3.1982
2020-11-05 21:05:16,194 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7580 | Iter Mean Loss 3.7182
2020-11-05 21:05:16,201 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0682 | Iter Mean Loss 3.8057
2020-11-05 21:05:16,209 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3398 | Iter Mean Loss 3.5125
2020-11-05 21:05:16,211 - root - INFO - Evaluate: Epoch 0866 | NDCG 0.2817 | MSE 0.3235
2020-11-05 21:05:16,219 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0843 | Iter Mean Loss 5.0843
2020-11-05 21:05:16,227 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3079 | Iter Mean Loss 3.1961
2020-11-05 21:05:16,235 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7525 | Iter Mean Loss 3.7149
2020-11-05 21:05:16,243 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0634 | Iter Mean Loss 3.8020
2020-11-05 21:05:16,251 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3366 | Iter Mean Loss 3.5089
2020-11-05 21:05:16,255 - root - INFO - Evaluate: Epoch 0867 | NDCG 0.2817 | MSE 0.3235
2020-11-05 21:05:16,269 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0813 | Iter Mean Loss 5.0813
2020-11-05 21:05:16,282 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3066 | Iter Mean Loss 3.1939
2020-11-05 21:05:16,293 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7469 | Iter Mean Loss 3.7116
2020-11-05 21:05:16,303 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0586 | Iter Mean Loss 3.7983
2020-11-05 21:05:16,312 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 3.5054
2020-11-05 21:05:16,314 - root - INFO - Evaluate: Epoch 0868 | NDCG 0.2817 | MSE 0.3235
2020-11-05 21:05:16,325 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0783 | Iter Mean Loss 5.0783
2020-11-05 21:05:16,335 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3053 | Iter Mean Loss 3.1918
2020-11-05 21:05:16,344 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 3.7083
2020-11-05 21:05:16,354 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0538 | Iter Mean Loss 3.7947
2020-11-05 21:05:16,363 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3303 | Iter Mean Loss 3.5018
2020-11-05 21:05:16,365 - root - INFO - Evaluate: Epoch 0869 | NDCG 0.2817 | MSE 0.3236
2020-11-05 21:05:16,374 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0753 | Iter Mean Loss 5.0753
2020-11-05 21:05:16,383 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3040 | Iter Mean Loss 3.1896
2020-11-05 21:05:16,390 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7358 | Iter Mean Loss 3.7050
2020-11-05 21:05:16,398 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0490 | Iter Mean Loss 3.7910
2020-11-05 21:05:16,406 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3271 | Iter Mean Loss 3.4983
2020-11-05 21:05:16,409 - root - INFO - Evaluate: Epoch 0870 | NDCG 0.2817 | MSE 0.3236
2020-11-05 21:05:16,418 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0723 | Iter Mean Loss 5.0723
2020-11-05 21:05:16,428 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3027 | Iter Mean Loss 3.1875
2020-11-05 21:05:16,437 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7303 | Iter Mean Loss 3.7018
2020-11-05 21:05:16,447 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0443 | Iter Mean Loss 3.7874
2020-11-05 21:05:16,454 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3240 | Iter Mean Loss 3.4947
2020-11-05 21:05:16,457 - root - INFO - Evaluate: Epoch 0871 | NDCG 0.2817 | MSE 0.3237
2020-11-05 21:05:16,466 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0693 | Iter Mean Loss 5.0693
2020-11-05 21:05:16,474 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3014 | Iter Mean Loss 3.1853
2020-11-05 21:05:16,482 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7248 | Iter Mean Loss 3.6985
2020-11-05 21:05:16,489 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0395 | Iter Mean Loss 3.7837
2020-11-05 21:05:16,496 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3208 | Iter Mean Loss 3.4912
2020-11-05 21:05:16,498 - root - INFO - Evaluate: Epoch 0872 | NDCG 0.2817 | MSE 0.3237
2020-11-05 21:05:16,506 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0663 | Iter Mean Loss 5.0663
2020-11-05 21:05:16,513 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3001 | Iter Mean Loss 3.1832
2020-11-05 21:05:16,520 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7193 | Iter Mean Loss 3.6952
2020-11-05 21:05:16,527 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 3.7801
2020-11-05 21:05:16,535 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3177 | Iter Mean Loss 3.4876
2020-11-05 21:05:16,536 - root - INFO - Evaluate: Epoch 0873 | NDCG 0.2817 | MSE 0.3237
2020-11-05 21:05:16,544 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0633 | Iter Mean Loss 5.0633
2020-11-05 21:05:16,552 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 3.1810
2020-11-05 21:05:16,559 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7138 | Iter Mean Loss 3.6919
2020-11-05 21:05:16,566 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0300 | Iter Mean Loss 3.7765
2020-11-05 21:05:16,573 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3146 | Iter Mean Loss 3.4841
2020-11-05 21:05:16,575 - root - INFO - Evaluate: Epoch 0874 | NDCG 0.2817 | MSE 0.3238
2020-11-05 21:05:16,583 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0603 | Iter Mean Loss 5.0603
2020-11-05 21:05:16,591 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2975 | Iter Mean Loss 3.1789
2020-11-05 21:05:16,599 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7083 | Iter Mean Loss 3.6887
2020-11-05 21:05:16,606 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0253 | Iter Mean Loss 3.7728
2020-11-05 21:05:16,614 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3114 | Iter Mean Loss 3.4806
2020-11-05 21:05:16,616 - root - INFO - Evaluate: Epoch 0875 | NDCG 0.2817 | MSE 0.3238
2020-11-05 21:05:16,625 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0573 | Iter Mean Loss 5.0573
2020-11-05 21:05:16,633 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2961 | Iter Mean Loss 3.1767
2020-11-05 21:05:16,640 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7028 | Iter Mean Loss 3.6854
2020-11-05 21:05:16,649 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0206 | Iter Mean Loss 3.7692
2020-11-05 21:05:16,656 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3083 | Iter Mean Loss 3.4770
2020-11-05 21:05:16,659 - root - INFO - Evaluate: Epoch 0876 | NDCG 0.2817 | MSE 0.3239
2020-11-05 21:05:16,667 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0543 | Iter Mean Loss 5.0543
2020-11-05 21:05:16,675 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2948 | Iter Mean Loss 3.1746
2020-11-05 21:05:16,683 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6973 | Iter Mean Loss 3.6821
2020-11-05 21:05:16,690 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0159 | Iter Mean Loss 3.7656
2020-11-05 21:05:16,697 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3052 | Iter Mean Loss 3.4735
2020-11-05 21:05:16,699 - root - INFO - Evaluate: Epoch 0877 | NDCG 0.2817 | MSE 0.3239
2020-11-05 21:05:16,707 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0513 | Iter Mean Loss 5.0513
2020-11-05 21:05:16,714 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2935 | Iter Mean Loss 3.1724
2020-11-05 21:05:16,721 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6918 | Iter Mean Loss 3.6789
2020-11-05 21:05:16,728 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0112 | Iter Mean Loss 3.7620
2020-11-05 21:05:16,735 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3021 | Iter Mean Loss 3.4700
2020-11-05 21:05:16,737 - root - INFO - Evaluate: Epoch 0878 | NDCG 0.2817 | MSE 0.3239
2020-11-05 21:05:16,745 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0483 | Iter Mean Loss 5.0483
2020-11-05 21:05:16,752 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2922 | Iter Mean Loss 3.1703
2020-11-05 21:05:16,760 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6864 | Iter Mean Loss 3.6756
2020-11-05 21:05:16,767 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0065 | Iter Mean Loss 3.7583
2020-11-05 21:05:16,774 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2990 | Iter Mean Loss 3.4665
2020-11-05 21:05:16,776 - root - INFO - Evaluate: Epoch 0879 | NDCG 0.2817 | MSE 0.3240
2020-11-05 21:05:16,784 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0453 | Iter Mean Loss 5.0453
2020-11-05 21:05:16,792 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2909 | Iter Mean Loss 3.1681
2020-11-05 21:05:16,799 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6809 | Iter Mean Loss 3.6724
2020-11-05 21:05:16,807 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0018 | Iter Mean Loss 3.7547
2020-11-05 21:05:16,815 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2959 | Iter Mean Loss 3.4630
2020-11-05 21:05:16,817 - root - INFO - Evaluate: Epoch 0880 | NDCG 0.2817 | MSE 0.3240
2020-11-05 21:05:16,826 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0423 | Iter Mean Loss 5.0423
2020-11-05 21:05:16,834 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2896 | Iter Mean Loss 3.1659
2020-11-05 21:05:16,841 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 3.6691
2020-11-05 21:05:16,849 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9971 | Iter Mean Loss 3.7511
2020-11-05 21:05:16,857 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2928 | Iter Mean Loss 3.4594
2020-11-05 21:05:16,860 - root - INFO - Evaluate: Epoch 0881 | NDCG 0.2817 | MSE 0.3241
2020-11-05 21:05:16,868 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0392 | Iter Mean Loss 5.0392
2020-11-05 21:05:16,876 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2883 | Iter Mean Loss 3.1638
2020-11-05 21:05:16,884 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6700 | Iter Mean Loss 3.6659
2020-11-05 21:05:16,891 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9924 | Iter Mean Loss 3.7475
2020-11-05 21:05:16,898 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2897 | Iter Mean Loss 3.4559
2020-11-05 21:05:16,900 - root - INFO - Evaluate: Epoch 0882 | NDCG 0.2817 | MSE 0.3241
2020-11-05 21:05:16,908 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0362 | Iter Mean Loss 5.0362
2020-11-05 21:05:16,916 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 3.1616
2020-11-05 21:05:16,923 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6646 | Iter Mean Loss 3.6626
2020-11-05 21:05:16,930 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9878 | Iter Mean Loss 3.7439
2020-11-05 21:05:16,937 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2866 | Iter Mean Loss 3.4524
2020-11-05 21:05:16,940 - root - INFO - Evaluate: Epoch 0883 | NDCG 0.2817 | MSE 0.3242
2020-11-05 21:05:16,947 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0332 | Iter Mean Loss 5.0332
2020-11-05 21:05:16,955 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2857 | Iter Mean Loss 3.1594
2020-11-05 21:05:16,962 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6592 | Iter Mean Loss 3.6593
2020-11-05 21:05:16,969 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9831 | Iter Mean Loss 3.7403
2020-11-05 21:05:16,976 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2836 | Iter Mean Loss 3.4489
2020-11-05 21:05:16,978 - root - INFO - Evaluate: Epoch 0884 | NDCG 0.2817 | MSE 0.3242
2020-11-05 21:05:16,986 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0301 | Iter Mean Loss 5.0301
2020-11-05 21:05:16,994 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2844 | Iter Mean Loss 3.1573
2020-11-05 21:05:17,001 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 3.6561
2020-11-05 21:05:17,009 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 3.7367
2020-11-05 21:05:17,017 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2805 | Iter Mean Loss 3.4455
2020-11-05 21:05:17,019 - root - INFO - Evaluate: Epoch 0885 | NDCG 0.2817 | MSE 0.3242
2020-11-05 21:05:17,028 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0271 | Iter Mean Loss 5.0271
2020-11-05 21:05:17,036 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2831 | Iter Mean Loss 3.1551
2020-11-05 21:05:17,043 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6483 | Iter Mean Loss 3.6528
2020-11-05 21:05:17,051 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9738 | Iter Mean Loss 3.7331
2020-11-05 21:05:17,058 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2774 | Iter Mean Loss 3.4420
2020-11-05 21:05:17,061 - root - INFO - Evaluate: Epoch 0886 | NDCG 0.2817 | MSE 0.3243
2020-11-05 21:05:17,069 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0241 | Iter Mean Loss 5.0241
2020-11-05 21:05:17,077 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2818 | Iter Mean Loss 3.1529
2020-11-05 21:05:17,085 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6429 | Iter Mean Loss 3.6496
2020-11-05 21:05:17,092 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 3.7295
2020-11-05 21:05:17,099 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2744 | Iter Mean Loss 3.4385
2020-11-05 21:05:17,101 - root - INFO - Evaluate: Epoch 0887 | NDCG 0.2817 | MSE 0.3243
2020-11-05 21:05:17,109 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0210 | Iter Mean Loss 5.0210
2020-11-05 21:05:17,116 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2805 | Iter Mean Loss 3.1507
2020-11-05 21:05:17,123 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6375 | Iter Mean Loss 3.6463
2020-11-05 21:05:17,131 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 3.7259
2020-11-05 21:05:17,138 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2713 | Iter Mean Loss 3.4350
2020-11-05 21:05:17,140 - root - INFO - Evaluate: Epoch 0888 | NDCG 0.2817 | MSE 0.3244
2020-11-05 21:05:17,147 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0180 | Iter Mean Loss 5.0180
2020-11-05 21:05:17,155 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2791 | Iter Mean Loss 3.1486
2020-11-05 21:05:17,162 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6322 | Iter Mean Loss 3.6431
2020-11-05 21:05:17,169 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9600 | Iter Mean Loss 3.7223
2020-11-05 21:05:17,176 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2683 | Iter Mean Loss 3.4315
2020-11-05 21:05:17,178 - root - INFO - Evaluate: Epoch 0889 | NDCG 0.2817 | MSE 0.3244
2020-11-05 21:05:17,186 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0149 | Iter Mean Loss 5.0149
2020-11-05 21:05:17,194 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2778 | Iter Mean Loss 3.1464
2020-11-05 21:05:17,201 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6268 | Iter Mean Loss 3.6398
2020-11-05 21:05:17,209 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9554 | Iter Mean Loss 3.7187
2020-11-05 21:05:17,217 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2652 | Iter Mean Loss 3.4280
2020-11-05 21:05:17,219 - root - INFO - Evaluate: Epoch 0890 | NDCG 0.2817 | MSE 0.3244
2020-11-05 21:05:17,227 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0119 | Iter Mean Loss 5.0119
2020-11-05 21:05:17,235 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2765 | Iter Mean Loss 3.1442
2020-11-05 21:05:17,242 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6214 | Iter Mean Loss 3.6366
2020-11-05 21:05:17,250 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9508 | Iter Mean Loss 3.7151
2020-11-05 21:05:17,258 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2622 | Iter Mean Loss 3.4246
2020-11-05 21:05:17,260 - root - INFO - Evaluate: Epoch 0891 | NDCG 0.2817 | MSE 0.3245
2020-11-05 21:05:17,269 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0088 | Iter Mean Loss 5.0088
2020-11-05 21:05:17,276 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2752 | Iter Mean Loss 3.1420
2020-11-05 21:05:17,284 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6160 | Iter Mean Loss 3.6334
2020-11-05 21:05:17,291 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9462 | Iter Mean Loss 3.7116
2020-11-05 21:05:17,299 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2592 | Iter Mean Loss 3.4211
2020-11-05 21:05:17,301 - root - INFO - Evaluate: Epoch 0892 | NDCG 0.2817 | MSE 0.3245
2020-11-05 21:05:17,308 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0057 | Iter Mean Loss 5.0057
2020-11-05 21:05:17,317 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2739 | Iter Mean Loss 3.1398
2020-11-05 21:05:17,325 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6107 | Iter Mean Loss 3.6301
2020-11-05 21:05:17,332 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 3.7080
2020-11-05 21:05:17,339 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2561 | Iter Mean Loss 3.4176
2020-11-05 21:05:17,341 - root - INFO - Evaluate: Epoch 0893 | NDCG 0.2817 | MSE 0.3246
2020-11-05 21:05:17,349 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0027 | Iter Mean Loss 5.0027
2020-11-05 21:05:17,356 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2726 | Iter Mean Loss 3.1376
2020-11-05 21:05:17,363 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6053 | Iter Mean Loss 3.6269
2020-11-05 21:05:17,370 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 3.7044
2020-11-05 21:05:17,377 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2531 | Iter Mean Loss 3.4141
2020-11-05 21:05:17,379 - root - INFO - Evaluate: Epoch 0894 | NDCG 0.2817 | MSE 0.3246
2020-11-05 21:05:17,388 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9996 | Iter Mean Loss 4.9996
2020-11-05 21:05:17,395 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2713 | Iter Mean Loss 3.1354
2020-11-05 21:05:17,403 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6000 | Iter Mean Loss 3.6236
2020-11-05 21:05:17,410 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9324 | Iter Mean Loss 3.7008
2020-11-05 21:05:17,418 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2501 | Iter Mean Loss 3.4107
2020-11-05 21:05:17,420 - root - INFO - Evaluate: Epoch 0895 | NDCG 0.2817 | MSE 0.3247
2020-11-05 21:05:17,429 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9965 | Iter Mean Loss 4.9965
2020-11-05 21:05:17,437 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2700 | Iter Mean Loss 3.1332
2020-11-05 21:05:17,444 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5947 | Iter Mean Loss 3.6204
2020-11-05 21:05:17,452 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9279 | Iter Mean Loss 3.6972
2020-11-05 21:05:17,465 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2471 | Iter Mean Loss 3.4072
2020-11-05 21:05:17,468 - root - INFO - Evaluate: Epoch 0896 | NDCG 0.2817 | MSE 0.3247
2020-11-05 21:05:17,480 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9934 | Iter Mean Loss 4.9934
2020-11-05 21:05:17,488 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2686 | Iter Mean Loss 3.1310
2020-11-05 21:05:17,496 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5893 | Iter Mean Loss 3.6171
2020-11-05 21:05:17,503 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9233 | Iter Mean Loss 3.6937
2020-11-05 21:05:17,511 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2441 | Iter Mean Loss 3.4038
2020-11-05 21:05:17,513 - root - INFO - Evaluate: Epoch 0897 | NDCG 0.2817 | MSE 0.3247
2020-11-05 21:05:17,521 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9903 | Iter Mean Loss 4.9903
2020-11-05 21:05:17,528 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2673 | Iter Mean Loss 3.1288
2020-11-05 21:05:17,536 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5840 | Iter Mean Loss 3.6139
2020-11-05 21:05:17,543 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9188 | Iter Mean Loss 3.6901
2020-11-05 21:05:17,551 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2411 | Iter Mean Loss 3.4003
2020-11-05 21:05:17,553 - root - INFO - Evaluate: Epoch 0898 | NDCG 0.2817 | MSE 0.3248
2020-11-05 21:05:17,561 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9872 | Iter Mean Loss 4.9872
2020-11-05 21:05:17,568 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 3.1266
2020-11-05 21:05:17,576 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5787 | Iter Mean Loss 3.6106
2020-11-05 21:05:17,584 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9142 | Iter Mean Loss 3.6865
2020-11-05 21:05:17,593 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2381 | Iter Mean Loss 3.3968
2020-11-05 21:05:17,595 - root - INFO - Evaluate: Epoch 0899 | NDCG 0.2817 | MSE 0.3248
2020-11-05 21:05:17,605 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9841 | Iter Mean Loss 4.9841
2020-11-05 21:05:17,614 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2647 | Iter Mean Loss 3.1244
2020-11-05 21:05:17,623 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5734 | Iter Mean Loss 3.6074
2020-11-05 21:05:17,632 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9097 | Iter Mean Loss 3.6830
2020-11-05 21:05:17,639 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2351 | Iter Mean Loss 3.3934
2020-11-05 21:05:17,642 - root - INFO - Evaluate: Epoch 0900 | NDCG 0.2817 | MSE 0.3249
2020-11-05 21:05:17,650 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9810 | Iter Mean Loss 4.9810
2020-11-05 21:05:17,658 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2634 | Iter Mean Loss 3.1222
2020-11-05 21:05:17,665 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5681 | Iter Mean Loss 3.6041
2020-11-05 21:05:17,672 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9052 | Iter Mean Loss 3.6794
2020-11-05 21:05:17,680 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2321 | Iter Mean Loss 3.3899
2020-11-05 21:05:17,682 - root - INFO - Evaluate: Epoch 0901 | NDCG 0.2817 | MSE 0.3249
2020-11-05 21:05:17,690 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9778 | Iter Mean Loss 4.9778
2020-11-05 21:05:17,697 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2620 | Iter Mean Loss 3.1199
2020-11-05 21:05:17,704 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5628 | Iter Mean Loss 3.6009
2020-11-05 21:05:17,711 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9007 | Iter Mean Loss 3.6758
2020-11-05 21:05:17,719 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2291 | Iter Mean Loss 3.3865
2020-11-05 21:05:17,720 - root - INFO - Evaluate: Epoch 0902 | NDCG 0.2817 | MSE 0.3250
2020-11-05 21:05:17,728 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9747 | Iter Mean Loss 4.9747
2020-11-05 21:05:17,735 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2607 | Iter Mean Loss 3.1177
2020-11-05 21:05:17,742 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5575 | Iter Mean Loss 3.5976
2020-11-05 21:05:17,749 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8961 | Iter Mean Loss 3.6723
2020-11-05 21:05:17,757 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 3.3830
2020-11-05 21:05:17,758 - root - INFO - Evaluate: Epoch 0903 | NDCG 0.2817 | MSE 0.3250
2020-11-05 21:05:17,766 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9716 | Iter Mean Loss 4.9716
2020-11-05 21:05:17,773 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2594 | Iter Mean Loss 3.1155
2020-11-05 21:05:17,780 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5522 | Iter Mean Loss 3.5944
2020-11-05 21:05:17,788 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8916 | Iter Mean Loss 3.6687
2020-11-05 21:05:17,795 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2231 | Iter Mean Loss 3.3796
2020-11-05 21:05:17,797 - root - INFO - Evaluate: Epoch 0904 | NDCG 0.2817 | MSE 0.3250
2020-11-05 21:05:17,805 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9684 | Iter Mean Loss 4.9684
2020-11-05 21:05:17,813 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2581 | Iter Mean Loss 3.1132
2020-11-05 21:05:17,820 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5469 | Iter Mean Loss 3.5911
2020-11-05 21:05:17,828 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8871 | Iter Mean Loss 3.6651
2020-11-05 21:05:17,836 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2202 | Iter Mean Loss 3.3761
2020-11-05 21:05:17,838 - root - INFO - Evaluate: Epoch 0905 | NDCG 0.2817 | MSE 0.3251
2020-11-05 21:05:17,846 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9653 | Iter Mean Loss 4.9653
2020-11-05 21:05:17,854 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2567 | Iter Mean Loss 3.1110
2020-11-05 21:05:17,861 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5417 | Iter Mean Loss 3.5879
2020-11-05 21:05:17,868 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8826 | Iter Mean Loss 3.6616
2020-11-05 21:05:17,876 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2172 | Iter Mean Loss 3.3727
2020-11-05 21:05:17,878 - root - INFO - Evaluate: Epoch 0906 | NDCG 0.2817 | MSE 0.3251
2020-11-05 21:05:17,887 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9621 | Iter Mean Loss 4.9621
2020-11-05 21:05:17,895 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2554 | Iter Mean Loss 3.1088
2020-11-05 21:05:17,902 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5364 | Iter Mean Loss 3.5846
2020-11-05 21:05:17,909 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8782 | Iter Mean Loss 3.6580
2020-11-05 21:05:17,917 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2142 | Iter Mean Loss 3.3693
2020-11-05 21:05:17,919 - root - INFO - Evaluate: Epoch 0907 | NDCG 0.2817 | MSE 0.3252
2020-11-05 21:05:17,927 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 4.9590
2020-11-05 21:05:17,935 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2541 | Iter Mean Loss 3.1065
2020-11-05 21:05:17,942 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5311 | Iter Mean Loss 3.5814
2020-11-05 21:05:17,949 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 3.6545
2020-11-05 21:05:17,956 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2113 | Iter Mean Loss 3.3658
2020-11-05 21:05:17,958 - root - INFO - Evaluate: Epoch 0908 | NDCG 0.2817 | MSE 0.3252
2020-11-05 21:05:17,966 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9558 | Iter Mean Loss 4.9558
2020-11-05 21:05:17,973 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2527 | Iter Mean Loss 3.1043
2020-11-05 21:05:17,980 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5259 | Iter Mean Loss 3.5781
2020-11-05 21:05:17,988 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8692 | Iter Mean Loss 3.6509
2020-11-05 21:05:17,996 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2083 | Iter Mean Loss 3.3624
2020-11-05 21:05:17,997 - root - INFO - Evaluate: Epoch 0909 | NDCG 0.2817 | MSE 0.3253
2020-11-05 21:05:18,006 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9526 | Iter Mean Loss 4.9526
2020-11-05 21:05:18,014 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2514 | Iter Mean Loss 3.1020
2020-11-05 21:05:18,022 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5207 | Iter Mean Loss 3.5749
2020-11-05 21:05:18,029 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8647 | Iter Mean Loss 3.6473
2020-11-05 21:05:18,037 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2054 | Iter Mean Loss 3.3589
2020-11-05 21:05:18,040 - root - INFO - Evaluate: Epoch 0910 | NDCG 0.2817 | MSE 0.3253
2020-11-05 21:05:18,048 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9494 | Iter Mean Loss 4.9494
2020-11-05 21:05:18,056 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2500 | Iter Mean Loss 3.0997
2020-11-05 21:05:18,063 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5154 | Iter Mean Loss 3.5716
2020-11-05 21:05:18,071 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8603 | Iter Mean Loss 3.6438
2020-11-05 21:05:18,079 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2024 | Iter Mean Loss 3.3555
2020-11-05 21:05:18,081 - root - INFO - Evaluate: Epoch 0911 | NDCG 0.2817 | MSE 0.3254
2020-11-05 21:05:18,089 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9462 | Iter Mean Loss 4.9462
2020-11-05 21:05:18,097 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2487 | Iter Mean Loss 3.0975
2020-11-05 21:05:18,104 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 3.5684
2020-11-05 21:05:18,111 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8558 | Iter Mean Loss 3.6402
2020-11-05 21:05:18,118 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1995 | Iter Mean Loss 3.3521
2020-11-05 21:05:18,120 - root - INFO - Evaluate: Epoch 0912 | NDCG 0.2817 | MSE 0.3254
2020-11-05 21:05:18,128 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9430 | Iter Mean Loss 4.9430
2020-11-05 21:05:18,135 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2473 | Iter Mean Loss 3.0952
2020-11-05 21:05:18,142 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 3.5651
2020-11-05 21:05:18,149 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8514 | Iter Mean Loss 3.6367
2020-11-05 21:05:18,157 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1965 | Iter Mean Loss 3.3486
2020-11-05 21:05:18,158 - root - INFO - Evaluate: Epoch 0913 | NDCG 0.2817 | MSE 0.3254
2020-11-05 21:05:18,166 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9398 | Iter Mean Loss 4.9398
2020-11-05 21:05:18,174 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2460 | Iter Mean Loss 3.0929
2020-11-05 21:05:18,181 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4997 | Iter Mean Loss 3.5618
2020-11-05 21:05:18,188 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8469 | Iter Mean Loss 3.6331
2020-11-05 21:05:18,195 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1936 | Iter Mean Loss 3.3452
2020-11-05 21:05:18,197 - root - INFO - Evaluate: Epoch 0914 | NDCG 0.2817 | MSE 0.3255
2020-11-05 21:05:18,205 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9366 | Iter Mean Loss 4.9366
2020-11-05 21:05:18,213 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2446 | Iter Mean Loss 3.0906
2020-11-05 21:05:18,220 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4945 | Iter Mean Loss 3.5586
2020-11-05 21:05:18,227 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8425 | Iter Mean Loss 3.6296
2020-11-05 21:05:18,235 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 3.3418
2020-11-05 21:05:18,237 - root - INFO - Evaluate: Epoch 0915 | NDCG 0.2817 | MSE 0.3255
2020-11-05 21:05:18,245 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9334 | Iter Mean Loss 4.9334
2020-11-05 21:05:18,253 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2433 | Iter Mean Loss 3.0883
2020-11-05 21:05:18,260 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4893 | Iter Mean Loss 3.5553
2020-11-05 21:05:18,268 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8380 | Iter Mean Loss 3.6260
2020-11-05 21:05:18,276 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1877 | Iter Mean Loss 3.3383
2020-11-05 21:05:18,278 - root - INFO - Evaluate: Epoch 0916 | NDCG 0.2817 | MSE 0.3256
2020-11-05 21:05:18,286 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9301 | Iter Mean Loss 4.9301
2020-11-05 21:05:18,294 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2419 | Iter Mean Loss 3.0860
2020-11-05 21:05:18,302 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4841 | Iter Mean Loss 3.5520
2020-11-05 21:05:18,309 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8336 | Iter Mean Loss 3.6224
2020-11-05 21:05:18,317 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1848 | Iter Mean Loss 3.3349
2020-11-05 21:05:18,320 - root - INFO - Evaluate: Epoch 0917 | NDCG 0.2817 | MSE 0.3256
2020-11-05 21:05:18,328 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9269 | Iter Mean Loss 4.9269
2020-11-05 21:05:18,335 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2406 | Iter Mean Loss 3.0837
2020-11-05 21:05:18,342 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4789 | Iter Mean Loss 3.5488
2020-11-05 21:05:18,349 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8292 | Iter Mean Loss 3.6189
2020-11-05 21:05:18,356 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1818 | Iter Mean Loss 3.3315
2020-11-05 21:05:18,358 - root - INFO - Evaluate: Epoch 0918 | NDCG 0.2817 | MSE 0.3257
2020-11-05 21:05:18,366 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 4.9236
2020-11-05 21:05:18,373 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2392 | Iter Mean Loss 3.0814
2020-11-05 21:05:18,380 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4737 | Iter Mean Loss 3.5455
2020-11-05 21:05:18,387 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8248 | Iter Mean Loss 3.6153
2020-11-05 21:05:18,395 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1789 | Iter Mean Loss 3.3280
2020-11-05 21:05:18,396 - root - INFO - Evaluate: Epoch 0919 | NDCG 0.2817 | MSE 0.3257
2020-11-05 21:05:18,404 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9203 | Iter Mean Loss 4.9203
2020-11-05 21:05:18,412 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2378 | Iter Mean Loss 3.0791
2020-11-05 21:05:18,420 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4685 | Iter Mean Loss 3.5422
2020-11-05 21:05:18,427 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8204 | Iter Mean Loss 3.6118
2020-11-05 21:05:18,435 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1760 | Iter Mean Loss 3.3246
2020-11-05 21:05:18,437 - root - INFO - Evaluate: Epoch 0920 | NDCG 0.2817 | MSE 0.3257
2020-11-05 21:05:18,445 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9171 | Iter Mean Loss 4.9171
2020-11-05 21:05:18,453 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2364 | Iter Mean Loss 3.0767
2020-11-05 21:05:18,460 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4633 | Iter Mean Loss 3.5389
2020-11-05 21:05:18,468 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8160 | Iter Mean Loss 3.6082
2020-11-05 21:05:18,475 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1730 | Iter Mean Loss 3.3212
2020-11-05 21:05:18,477 - root - INFO - Evaluate: Epoch 0921 | NDCG 0.2817 | MSE 0.3258
2020-11-05 21:05:18,486 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9138 | Iter Mean Loss 4.9138
2020-11-05 21:05:18,493 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2351 | Iter Mean Loss 3.0744
2020-11-05 21:05:18,501 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4582 | Iter Mean Loss 3.5357
2020-11-05 21:05:18,508 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8116 | Iter Mean Loss 3.6046
2020-11-05 21:05:18,515 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1701 | Iter Mean Loss 3.3177
2020-11-05 21:05:18,517 - root - INFO - Evaluate: Epoch 0922 | NDCG 0.2817 | MSE 0.3258
2020-11-05 21:05:18,525 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9105 | Iter Mean Loss 4.9105
2020-11-05 21:05:18,532 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2337 | Iter Mean Loss 3.0721
2020-11-05 21:05:18,539 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4530 | Iter Mean Loss 3.5324
2020-11-05 21:05:18,546 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8072 | Iter Mean Loss 3.6011
2020-11-05 21:05:18,554 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1672 | Iter Mean Loss 3.3143
2020-11-05 21:05:18,555 - root - INFO - Evaluate: Epoch 0923 | NDCG 0.2817 | MSE 0.3259
2020-11-05 21:05:18,563 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9072 | Iter Mean Loss 4.9072
2020-11-05 21:05:18,570 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2323 | Iter Mean Loss 3.0697
2020-11-05 21:05:18,578 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 3.5291
2020-11-05 21:05:18,584 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8028 | Iter Mean Loss 3.5975
2020-11-05 21:05:18,592 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1643 | Iter Mean Loss 3.3109
2020-11-05 21:05:18,594 - root - INFO - Evaluate: Epoch 0924 | NDCG 0.2817 | MSE 0.3259
2020-11-05 21:05:18,601 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9038 | Iter Mean Loss 4.9038
2020-11-05 21:05:18,609 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2309 | Iter Mean Loss 3.0674
2020-11-05 21:05:18,616 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4427 | Iter Mean Loss 3.5258
2020-11-05 21:05:18,624 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7984 | Iter Mean Loss 3.5940
2020-11-05 21:05:18,631 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1614 | Iter Mean Loss 3.3074
2020-11-05 21:05:18,634 - root - INFO - Evaluate: Epoch 0925 | NDCG 0.2817 | MSE 0.3260
2020-11-05 21:05:18,642 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9005 | Iter Mean Loss 4.9005
2020-11-05 21:05:18,650 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2295 | Iter Mean Loss 3.0650
2020-11-05 21:05:18,657 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4375 | Iter Mean Loss 3.5225
2020-11-05 21:05:18,665 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7940 | Iter Mean Loss 3.5904
2020-11-05 21:05:18,672 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1585 | Iter Mean Loss 3.3040
2020-11-05 21:05:18,675 - root - INFO - Evaluate: Epoch 0926 | NDCG 0.2817 | MSE 0.3260
2020-11-05 21:05:18,683 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8972 | Iter Mean Loss 4.8972
2020-11-05 21:05:18,690 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2281 | Iter Mean Loss 3.0626
2020-11-05 21:05:18,698 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4324 | Iter Mean Loss 3.5192
2020-11-05 21:05:18,706 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7896 | Iter Mean Loss 3.5868
2020-11-05 21:05:18,713 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1556 | Iter Mean Loss 3.3006
2020-11-05 21:05:18,715 - root - INFO - Evaluate: Epoch 0927 | NDCG 0.2817 | MSE 0.3261
2020-11-05 21:05:18,723 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8938 | Iter Mean Loss 4.8938
2020-11-05 21:05:18,730 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2267 | Iter Mean Loss 3.0603
2020-11-05 21:05:18,737 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4272 | Iter Mean Loss 3.5159
2020-11-05 21:05:18,744 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7853 | Iter Mean Loss 3.5833
2020-11-05 21:05:18,751 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1526 | Iter Mean Loss 3.2971
2020-11-05 21:05:18,753 - root - INFO - Evaluate: Epoch 0928 | NDCG 0.2817 | MSE 0.3261
2020-11-05 21:05:18,761 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8904 | Iter Mean Loss 4.8904
2020-11-05 21:05:18,768 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2253 | Iter Mean Loss 3.0579
2020-11-05 21:05:18,775 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4221 | Iter Mean Loss 3.5126
2020-11-05 21:05:18,782 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7809 | Iter Mean Loss 3.5797
2020-11-05 21:05:18,789 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1497 | Iter Mean Loss 3.2937
2020-11-05 21:05:18,791 - root - INFO - Evaluate: Epoch 0929 | NDCG 0.2817 | MSE 0.3261
2020-11-05 21:05:18,799 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8871 | Iter Mean Loss 4.8871
2020-11-05 21:05:18,806 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2239 | Iter Mean Loss 3.0555
2020-11-05 21:05:18,813 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4169 | Iter Mean Loss 3.5093
2020-11-05 21:05:18,821 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7765 | Iter Mean Loss 3.5761
2020-11-05 21:05:18,828 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1468 | Iter Mean Loss 3.2903
2020-11-05 21:05:18,830 - root - INFO - Evaluate: Epoch 0930 | NDCG 0.2817 | MSE 0.3262
2020-11-05 21:05:18,838 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8837 | Iter Mean Loss 4.8837
2020-11-05 21:05:18,846 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2225 | Iter Mean Loss 3.0531
2020-11-05 21:05:18,853 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4118 | Iter Mean Loss 3.5060
2020-11-05 21:05:18,861 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 3.5725
2020-11-05 21:05:18,868 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1439 | Iter Mean Loss 3.2868
2020-11-05 21:05:18,870 - root - INFO - Evaluate: Epoch 0931 | NDCG 0.2817 | MSE 0.3262
2020-11-05 21:05:18,879 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8803 | Iter Mean Loss 4.8803
2020-11-05 21:05:18,887 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2211 | Iter Mean Loss 3.0507
2020-11-05 21:05:18,894 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4067 | Iter Mean Loss 3.5027
2020-11-05 21:05:18,902 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7678 | Iter Mean Loss 3.5690
2020-11-05 21:05:18,909 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1410 | Iter Mean Loss 3.2834
2020-11-05 21:05:18,912 - root - INFO - Evaluate: Epoch 0932 | NDCG 0.2817 | MSE 0.3263
2020-11-05 21:05:18,920 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8768 | Iter Mean Loss 4.8768
2020-11-05 21:05:18,928 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2197 | Iter Mean Loss 3.0483
2020-11-05 21:05:18,936 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4016 | Iter Mean Loss 3.4994
2020-11-05 21:05:18,943 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7635 | Iter Mean Loss 3.5654
2020-11-05 21:05:18,950 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1381 | Iter Mean Loss 3.2799
2020-11-05 21:05:18,952 - root - INFO - Evaluate: Epoch 0933 | NDCG 0.2817 | MSE 0.3263
2020-11-05 21:05:18,960 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8734 | Iter Mean Loss 4.8734
2020-11-05 21:05:18,967 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 3.0458
2020-11-05 21:05:18,974 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3964 | Iter Mean Loss 3.4960
2020-11-05 21:05:18,982 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7591 | Iter Mean Loss 3.5618
2020-11-05 21:05:18,989 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1352 | Iter Mean Loss 3.2765
2020-11-05 21:05:18,991 - root - INFO - Evaluate: Epoch 0934 | NDCG 0.2817 | MSE 0.3264
2020-11-05 21:05:18,999 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8700 | Iter Mean Loss 4.8700
2020-11-05 21:05:19,006 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2168 | Iter Mean Loss 3.0434
2020-11-05 21:05:19,013 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 3.4927
2020-11-05 21:05:19,021 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7548 | Iter Mean Loss 3.5582
2020-11-05 21:05:19,029 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1323 | Iter Mean Loss 3.2731
2020-11-05 21:05:19,031 - root - INFO - Evaluate: Epoch 0935 | NDCG 0.2817 | MSE 0.3264
2020-11-05 21:05:19,039 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8665 | Iter Mean Loss 4.8665
2020-11-05 21:05:19,047 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2154 | Iter Mean Loss 3.0410
2020-11-05 21:05:19,054 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3862 | Iter Mean Loss 3.4894
2020-11-05 21:05:19,062 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7505 | Iter Mean Loss 3.5546
2020-11-05 21:05:19,070 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1294 | Iter Mean Loss 3.2696
2020-11-05 21:05:19,072 - root - INFO - Evaluate: Epoch 0936 | NDCG 0.2817 | MSE 0.3264
2020-11-05 21:05:19,081 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8631 | Iter Mean Loss 4.8631
2020-11-05 21:05:19,088 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2140 | Iter Mean Loss 3.0385
2020-11-05 21:05:19,096 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3811 | Iter Mean Loss 3.4860
2020-11-05 21:05:19,103 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7461 | Iter Mean Loss 3.5511
2020-11-05 21:05:19,111 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1265 | Iter Mean Loss 3.2662
2020-11-05 21:05:19,113 - root - INFO - Evaluate: Epoch 0937 | NDCG 0.2817 | MSE 0.3265
2020-11-05 21:05:19,121 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8596 | Iter Mean Loss 4.8596
2020-11-05 21:05:19,129 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2125 | Iter Mean Loss 3.0360
2020-11-05 21:05:19,136 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3760 | Iter Mean Loss 3.4827
2020-11-05 21:05:19,143 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7418 | Iter Mean Loss 3.5475
2020-11-05 21:05:19,150 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1237 | Iter Mean Loss 3.2627
2020-11-05 21:05:19,152 - root - INFO - Evaluate: Epoch 0938 | NDCG 0.2817 | MSE 0.3265
2020-11-05 21:05:19,160 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8561 | Iter Mean Loss 4.8561
2020-11-05 21:05:19,167 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2111 | Iter Mean Loss 3.0336
2020-11-05 21:05:19,174 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3709 | Iter Mean Loss 3.4793
2020-11-05 21:05:19,181 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7375 | Iter Mean Loss 3.5439
2020-11-05 21:05:19,189 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1208 | Iter Mean Loss 3.2593
2020-11-05 21:05:19,191 - root - INFO - Evaluate: Epoch 0939 | NDCG 0.2817 | MSE 0.3266
2020-11-05 21:05:19,199 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8526 | Iter Mean Loss 4.8526
2020-11-05 21:05:19,206 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2096 | Iter Mean Loss 3.0311
2020-11-05 21:05:19,213 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3658 | Iter Mean Loss 3.4760
2020-11-05 21:05:19,220 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7332 | Iter Mean Loss 3.5403
2020-11-05 21:05:19,228 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1179 | Iter Mean Loss 3.2558
2020-11-05 21:05:19,230 - root - INFO - Evaluate: Epoch 0940 | NDCG 0.2817 | MSE 0.3266
2020-11-05 21:05:19,238 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8490 | Iter Mean Loss 4.8490
2020-11-05 21:05:19,246 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 3.0286
2020-11-05 21:05:19,254 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3607 | Iter Mean Loss 3.4726
2020-11-05 21:05:19,262 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7288 | Iter Mean Loss 3.5367
2020-11-05 21:05:19,269 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1150 | Iter Mean Loss 3.2523
2020-11-05 21:05:19,271 - root - INFO - Evaluate: Epoch 0941 | NDCG 0.2817 | MSE 0.3267
2020-11-05 21:05:19,280 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8455 | Iter Mean Loss 4.8455
2020-11-05 21:05:19,287 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2067 | Iter Mean Loss 3.0261
2020-11-05 21:05:19,295 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3556 | Iter Mean Loss 3.4693
2020-11-05 21:05:19,302 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7245 | Iter Mean Loss 3.5331
2020-11-05 21:05:19,311 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1121 | Iter Mean Loss 3.2489
2020-11-05 21:05:19,314 - root - INFO - Evaluate: Epoch 0942 | NDCG 0.2817 | MSE 0.3267
2020-11-05 21:05:19,322 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8420 | Iter Mean Loss 4.8420
2020-11-05 21:05:19,330 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2052 | Iter Mean Loss 3.0236
2020-11-05 21:05:19,338 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3505 | Iter Mean Loss 3.4659
2020-11-05 21:05:19,345 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7202 | Iter Mean Loss 3.5295
2020-11-05 21:05:19,352 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1092 | Iter Mean Loss 3.2454
2020-11-05 21:05:19,354 - root - INFO - Evaluate: Epoch 0943 | NDCG 0.2817 | MSE 0.3268
2020-11-05 21:05:19,361 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8384 | Iter Mean Loss 4.8384
2020-11-05 21:05:19,369 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2038 | Iter Mean Loss 3.0211
2020-11-05 21:05:19,376 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3455 | Iter Mean Loss 3.4625
2020-11-05 21:05:19,383 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7159 | Iter Mean Loss 3.5259
2020-11-05 21:05:19,390 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1063 | Iter Mean Loss 3.2420
2020-11-05 21:05:19,392 - root - INFO - Evaluate: Epoch 0944 | NDCG 0.2817 | MSE 0.3268
2020-11-05 21:05:19,400 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8348 | Iter Mean Loss 4.8348
2020-11-05 21:05:19,407 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2023 | Iter Mean Loss 3.0185
2020-11-05 21:05:19,414 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3404 | Iter Mean Loss 3.4592
2020-11-05 21:05:19,422 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7116 | Iter Mean Loss 3.5223
2020-11-05 21:05:19,429 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1034 | Iter Mean Loss 3.2385
2020-11-05 21:05:19,431 - root - INFO - Evaluate: Epoch 0945 | NDCG 0.2817 | MSE 0.3268
2020-11-05 21:05:19,440 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 4.8312
2020-11-05 21:05:19,448 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2008 | Iter Mean Loss 3.0160
2020-11-05 21:05:19,456 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3353 | Iter Mean Loss 3.4558
2020-11-05 21:05:19,463 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7073 | Iter Mean Loss 3.5187
2020-11-05 21:05:19,471 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1005 | Iter Mean Loss 3.2350
2020-11-05 21:05:19,473 - root - INFO - Evaluate: Epoch 0946 | NDCG 0.2817 | MSE 0.3269
2020-11-05 21:05:19,481 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8276 | Iter Mean Loss 4.8276
2020-11-05 21:05:19,489 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1993 | Iter Mean Loss 3.0134
2020-11-05 21:05:19,497 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3302 | Iter Mean Loss 3.4524
2020-11-05 21:05:19,505 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7030 | Iter Mean Loss 3.5150
2020-11-05 21:05:19,513 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0976 | Iter Mean Loss 3.2316
2020-11-05 21:05:19,515 - root - INFO - Evaluate: Epoch 0947 | NDCG 0.2817 | MSE 0.3269
2020-11-05 21:05:19,523 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8240 | Iter Mean Loss 4.8240
2020-11-05 21:05:19,531 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1978 | Iter Mean Loss 3.0109
2020-11-05 21:05:19,538 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3252 | Iter Mean Loss 3.4490
2020-11-05 21:05:19,545 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6987 | Iter Mean Loss 3.5114
2020-11-05 21:05:19,552 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0948 | Iter Mean Loss 3.2281
2020-11-05 21:05:19,554 - root - INFO - Evaluate: Epoch 0948 | NDCG 0.2817 | MSE 0.3270
2020-11-05 21:05:19,562 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8203 | Iter Mean Loss 4.8203
2020-11-05 21:05:19,570 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1963 | Iter Mean Loss 3.0083
2020-11-05 21:05:19,577 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 3.4456
2020-11-05 21:05:19,584 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6945 | Iter Mean Loss 3.5078
2020-11-05 21:05:19,591 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0919 | Iter Mean Loss 3.2246
2020-11-05 21:05:19,593 - root - INFO - Evaluate: Epoch 0949 | NDCG 0.2817 | MSE 0.3270
2020-11-05 21:05:19,601 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8166 | Iter Mean Loss 4.8166
2020-11-05 21:05:19,608 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1948 | Iter Mean Loss 3.0057
2020-11-05 21:05:19,615 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 3.4422
2020-11-05 21:05:19,622 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6902 | Iter Mean Loss 3.5042
2020-11-05 21:05:19,630 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0890 | Iter Mean Loss 3.2211
2020-11-05 21:05:19,632 - root - INFO - Evaluate: Epoch 0950 | NDCG 0.2817 | MSE 0.3271
2020-11-05 21:05:19,640 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8130 | Iter Mean Loss 4.8130
2020-11-05 21:05:19,648 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1933 | Iter Mean Loss 3.0031
2020-11-05 21:05:19,655 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3100 | Iter Mean Loss 3.4387
2020-11-05 21:05:19,663 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6859 | Iter Mean Loss 3.5005
2020-11-05 21:05:19,670 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0861 | Iter Mean Loss 3.2176
2020-11-05 21:05:19,673 - root - INFO - Evaluate: Epoch 0951 | NDCG 0.2817 | MSE 0.3271
2020-11-05 21:05:19,681 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8093 | Iter Mean Loss 4.8093
2020-11-05 21:05:19,689 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1918 | Iter Mean Loss 3.0005
2020-11-05 21:05:19,697 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3049 | Iter Mean Loss 3.4353
2020-11-05 21:05:19,704 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6816 | Iter Mean Loss 3.4969
2020-11-05 21:05:19,712 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0832 | Iter Mean Loss 3.2142
2020-11-05 21:05:19,714 - root - INFO - Evaluate: Epoch 0952 | NDCG 0.2817 | MSE 0.3272
2020-11-05 21:05:19,722 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8055 | Iter Mean Loss 4.8055
2020-11-05 21:05:19,731 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1902 | Iter Mean Loss 2.9979
2020-11-05 21:05:19,738 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.4319
2020-11-05 21:05:19,745 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6773 | Iter Mean Loss 3.4933
2020-11-05 21:05:19,752 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0803 | Iter Mean Loss 3.2107
2020-11-05 21:05:19,754 - root - INFO - Evaluate: Epoch 0953 | NDCG 0.2817 | MSE 0.3272
2020-11-05 21:05:19,762 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8018 | Iter Mean Loss 4.8018
2020-11-05 21:05:19,769 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1887 | Iter Mean Loss 2.9953
2020-11-05 21:05:19,776 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2948 | Iter Mean Loss 3.4285
2020-11-05 21:05:19,783 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6731 | Iter Mean Loss 3.4896
2020-11-05 21:05:19,791 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0774 | Iter Mean Loss 3.2072
2020-11-05 21:05:19,793 - root - INFO - Evaluate: Epoch 0954 | NDCG 0.2817 | MSE 0.3272
2020-11-05 21:05:19,800 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7981 | Iter Mean Loss 4.7981
2020-11-05 21:05:19,808 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1872 | Iter Mean Loss 2.9926
2020-11-05 21:05:19,815 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2898 | Iter Mean Loss 3.4250
2020-11-05 21:05:19,822 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6688 | Iter Mean Loss 3.4860
2020-11-05 21:05:19,829 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0745 | Iter Mean Loss 3.2037
2020-11-05 21:05:19,831 - root - INFO - Evaluate: Epoch 0955 | NDCG 0.2817 | MSE 0.3273
2020-11-05 21:05:19,840 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7943 | Iter Mean Loss 4.7943
2020-11-05 21:05:19,847 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1856 | Iter Mean Loss 2.9900
2020-11-05 21:05:19,855 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 3.4216
2020-11-05 21:05:19,863 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6645 | Iter Mean Loss 3.4823
2020-11-05 21:05:19,870 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0716 | Iter Mean Loss 3.2002
2020-11-05 21:05:19,873 - root - INFO - Evaluate: Epoch 0956 | NDCG 0.2817 | MSE 0.3273
2020-11-05 21:05:19,880 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7905 | Iter Mean Loss 4.7905
2020-11-05 21:05:19,888 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1841 | Iter Mean Loss 2.9873
2020-11-05 21:05:19,896 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2797 | Iter Mean Loss 3.4181
2020-11-05 21:05:19,903 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6603 | Iter Mean Loss 3.4786
2020-11-05 21:05:19,911 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0687 | Iter Mean Loss 3.1967
2020-11-05 21:05:19,913 - root - INFO - Evaluate: Epoch 0957 | NDCG 0.2817 | MSE 0.3274
2020-11-05 21:05:19,922 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7867 | Iter Mean Loss 4.7867
2020-11-05 21:05:19,929 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1825 | Iter Mean Loss 2.9846
2020-11-05 21:05:19,937 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2747 | Iter Mean Loss 3.4146
2020-11-05 21:05:19,944 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6560 | Iter Mean Loss 3.4750
2020-11-05 21:05:19,951 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0659 | Iter Mean Loss 3.1931
2020-11-05 21:05:19,953 - root - INFO - Evaluate: Epoch 0958 | NDCG 0.2817 | MSE 0.3274
2020-11-05 21:05:19,960 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7829 | Iter Mean Loss 4.7829
2020-11-05 21:05:19,968 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1809 | Iter Mean Loss 2.9819
2020-11-05 21:05:19,975 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2696 | Iter Mean Loss 3.4112
2020-11-05 21:05:19,982 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6517 | Iter Mean Loss 3.4713
2020-11-05 21:05:19,990 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0630 | Iter Mean Loss 3.1896
2020-11-05 21:05:19,992 - root - INFO - Evaluate: Epoch 0959 | NDCG 0.2817 | MSE 0.3275
2020-11-05 21:05:20,000 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7790 | Iter Mean Loss 4.7790
2020-11-05 21:05:20,007 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1794 | Iter Mean Loss 2.9792
2020-11-05 21:05:20,015 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2646 | Iter Mean Loss 3.4077
2020-11-05 21:05:20,022 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6475 | Iter Mean Loss 3.4676
2020-11-05 21:05:20,029 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0601 | Iter Mean Loss 3.1861
2020-11-05 21:05:20,031 - root - INFO - Evaluate: Epoch 0960 | NDCG 0.2817 | MSE 0.3275
2020-11-05 21:05:20,039 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7752 | Iter Mean Loss 4.7752
2020-11-05 21:05:20,047 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1778 | Iter Mean Loss 2.9765
2020-11-05 21:05:20,054 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 3.4042
2020-11-05 21:05:20,062 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 3.4639
2020-11-05 21:05:20,070 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0572 | Iter Mean Loss 3.1826
2020-11-05 21:05:20,072 - root - INFO - Evaluate: Epoch 0961 | NDCG 0.2817 | MSE 0.3275
2020-11-05 21:05:20,081 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7713 | Iter Mean Loss 4.7713
2020-11-05 21:05:20,088 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1762 | Iter Mean Loss 2.9738
2020-11-05 21:05:20,096 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2545 | Iter Mean Loss 3.4007
2020-11-05 21:05:20,104 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6390 | Iter Mean Loss 3.4603
2020-11-05 21:05:20,112 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0543 | Iter Mean Loss 3.1791
2020-11-05 21:05:20,114 - root - INFO - Evaluate: Epoch 0962 | NDCG 0.2817 | MSE 0.3276
2020-11-05 21:05:20,122 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7674 | Iter Mean Loss 4.7674
2020-11-05 21:05:20,129 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1746 | Iter Mean Loss 2.9710
2020-11-05 21:05:20,137 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2495 | Iter Mean Loss 3.3972
2020-11-05 21:05:20,144 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6347 | Iter Mean Loss 3.4566
2020-11-05 21:05:20,152 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0514 | Iter Mean Loss 3.1755
2020-11-05 21:05:20,154 - root - INFO - Evaluate: Epoch 0963 | NDCG 0.2817 | MSE 0.3276
2020-11-05 21:05:20,161 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7635 | Iter Mean Loss 4.7635
2020-11-05 21:05:20,169 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1730 | Iter Mean Loss 2.9682
2020-11-05 21:05:20,176 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2445 | Iter Mean Loss 3.3937
2020-11-05 21:05:20,183 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6305 | Iter Mean Loss 3.4529
2020-11-05 21:05:20,190 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0485 | Iter Mean Loss 3.1720
2020-11-05 21:05:20,192 - root - INFO - Evaluate: Epoch 0964 | NDCG 0.2817 | MSE 0.3277
2020-11-05 21:05:20,200 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7595 | Iter Mean Loss 4.7595
2020-11-05 21:05:20,207 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 2.9655
2020-11-05 21:05:20,214 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2395 | Iter Mean Loss 3.3901
2020-11-05 21:05:20,221 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6262 | Iter Mean Loss 3.4492
2020-11-05 21:05:20,229 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0456 | Iter Mean Loss 3.1684
2020-11-05 21:05:20,230 - root - INFO - Evaluate: Epoch 0965 | NDCG 0.2817 | MSE 0.3277
2020-11-05 21:05:20,238 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7556 | Iter Mean Loss 4.7556
2020-11-05 21:05:20,246 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1698 | Iter Mean Loss 2.9627
2020-11-05 21:05:20,254 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2344 | Iter Mean Loss 3.3866
2020-11-05 21:05:20,262 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6220 | Iter Mean Loss 3.4454
2020-11-05 21:05:20,269 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0427 | Iter Mean Loss 3.1649
2020-11-05 21:05:20,271 - root - INFO - Evaluate: Epoch 0966 | NDCG 0.2817 | MSE 0.3278
2020-11-05 21:05:20,280 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7516 | Iter Mean Loss 4.7516
2020-11-05 21:05:20,288 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1682 | Iter Mean Loss 2.9599
2020-11-05 21:05:20,295 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2294 | Iter Mean Loss 3.3831
2020-11-05 21:05:20,303 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6177 | Iter Mean Loss 3.4417
2020-11-05 21:05:20,311 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0398 | Iter Mean Loss 3.1613
2020-11-05 21:05:20,314 - root - INFO - Evaluate: Epoch 0967 | NDCG 0.2817 | MSE 0.3278
2020-11-05 21:05:20,323 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7476 | Iter Mean Loss 4.7476
2020-11-05 21:05:20,331 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1665 | Iter Mean Loss 2.9571
2020-11-05 21:05:20,338 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2244 | Iter Mean Loss 3.3795
2020-11-05 21:05:20,345 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6135 | Iter Mean Loss 3.4380
2020-11-05 21:05:20,353 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0369 | Iter Mean Loss 3.1578
2020-11-05 21:05:20,355 - root - INFO - Evaluate: Epoch 0968 | NDCG 0.2817 | MSE 0.3278
2020-11-05 21:05:20,362 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7436 | Iter Mean Loss 4.7436
2020-11-05 21:05:20,370 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1649 | Iter Mean Loss 2.9542
2020-11-05 21:05:20,377 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2194 | Iter Mean Loss 3.3760
2020-11-05 21:05:20,384 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6092 | Iter Mean Loss 3.4343
2020-11-05 21:05:20,391 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0339 | Iter Mean Loss 3.1542
2020-11-05 21:05:20,393 - root - INFO - Evaluate: Epoch 0969 | NDCG 0.2817 | MSE 0.3279
2020-11-05 21:05:20,401 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 4.7395
2020-11-05 21:05:20,408 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1633 | Iter Mean Loss 2.9514
2020-11-05 21:05:20,418 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2144 | Iter Mean Loss 3.3724
2020-11-05 21:05:20,429 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6050 | Iter Mean Loss 3.4305
2020-11-05 21:05:20,439 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0310 | Iter Mean Loss 3.1506
2020-11-05 21:05:20,441 - root - INFO - Evaluate: Epoch 0970 | NDCG 0.2817 | MSE 0.3279
2020-11-05 21:05:20,450 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7354 | Iter Mean Loss 4.7354
2020-11-05 21:05:20,459 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1616 | Iter Mean Loss 2.9485
2020-11-05 21:05:20,469 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2094 | Iter Mean Loss 3.3688
2020-11-05 21:05:20,477 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6008 | Iter Mean Loss 3.4268
2020-11-05 21:05:20,486 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0281 | Iter Mean Loss 3.1471
2020-11-05 21:05:20,488 - root - INFO - Evaluate: Epoch 0971 | NDCG 0.2817 | MSE 0.3280
2020-11-05 21:05:20,498 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7313 | Iter Mean Loss 4.7313
2020-11-05 21:05:20,508 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1600 | Iter Mean Loss 2.9457
2020-11-05 21:05:20,518 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2043 | Iter Mean Loss 3.3652
2020-11-05 21:05:20,526 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5965 | Iter Mean Loss 3.4230
2020-11-05 21:05:20,534 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0252 | Iter Mean Loss 3.1435
2020-11-05 21:05:20,536 - root - INFO - Evaluate: Epoch 0972 | NDCG 0.2817 | MSE 0.3280
2020-11-05 21:05:20,545 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7272 | Iter Mean Loss 4.7272
2020-11-05 21:05:20,552 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1583 | Iter Mean Loss 2.9428
2020-11-05 21:05:20,560 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1993 | Iter Mean Loss 3.3616
2020-11-05 21:05:20,567 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 3.4193
2020-11-05 21:05:20,576 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0223 | Iter Mean Loss 3.1399
2020-11-05 21:05:20,578 - root - INFO - Evaluate: Epoch 0973 | NDCG 0.2817 | MSE 0.3281
2020-11-05 21:05:20,588 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7231 | Iter Mean Loss 4.7231
2020-11-05 21:05:20,596 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1566 | Iter Mean Loss 2.9399
2020-11-05 21:05:20,603 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1943 | Iter Mean Loss 3.3580
2020-11-05 21:05:20,610 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5881 | Iter Mean Loss 3.4155
2020-11-05 21:05:20,617 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0194 | Iter Mean Loss 3.1363
2020-11-05 21:05:20,619 - root - INFO - Evaluate: Epoch 0974 | NDCG 0.2817 | MSE 0.3281
2020-11-05 21:05:20,627 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7189 | Iter Mean Loss 4.7189
2020-11-05 21:05:20,634 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1549 | Iter Mean Loss 2.9369
2020-11-05 21:05:20,642 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1893 | Iter Mean Loss 3.3544
2020-11-05 21:05:20,649 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5838 | Iter Mean Loss 3.4118
2020-11-05 21:05:20,657 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0164 | Iter Mean Loss 3.1327
2020-11-05 21:05:20,659 - root - INFO - Evaluate: Epoch 0975 | NDCG 0.2817 | MSE 0.3282
2020-11-05 21:05:20,667 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7148 | Iter Mean Loss 4.7148
2020-11-05 21:05:20,675 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1533 | Iter Mean Loss 2.9340
2020-11-05 21:05:20,682 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1843 | Iter Mean Loss 3.3508
2020-11-05 21:05:20,690 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5796 | Iter Mean Loss 3.4080
2020-11-05 21:05:20,698 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0135 | Iter Mean Loss 3.1291
2020-11-05 21:05:20,700 - root - INFO - Evaluate: Epoch 0976 | NDCG 0.2817 | MSE 0.3282
2020-11-05 21:05:20,708 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7106 | Iter Mean Loss 4.7106
2020-11-05 21:05:20,716 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 2.9311
2020-11-05 21:05:20,724 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1793 | Iter Mean Loss 3.3471
2020-11-05 21:05:20,732 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5754 | Iter Mean Loss 3.4042
2020-11-05 21:05:20,739 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0106 | Iter Mean Loss 3.1255
2020-11-05 21:05:20,742 - root - INFO - Evaluate: Epoch 0977 | NDCG 0.2817 | MSE 0.3282
2020-11-05 21:05:20,750 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7063 | Iter Mean Loss 4.7063
2020-11-05 21:05:20,757 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1499 | Iter Mean Loss 2.9281
2020-11-05 21:05:20,765 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1743 | Iter Mean Loss 3.3435
2020-11-05 21:05:20,772 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5711 | Iter Mean Loss 3.4004
2020-11-05 21:05:20,779 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0076 | Iter Mean Loss 3.1218
2020-11-05 21:05:20,781 - root - INFO - Evaluate: Epoch 0978 | NDCG 0.2817 | MSE 0.3283
2020-11-05 21:05:20,788 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7021 | Iter Mean Loss 4.7021
2020-11-05 21:05:20,796 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1481 | Iter Mean Loss 2.9251
2020-11-05 21:05:20,803 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1693 | Iter Mean Loss 3.3398
2020-11-05 21:05:20,810 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5669 | Iter Mean Loss 3.3966
2020-11-05 21:05:20,817 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0047 | Iter Mean Loss 3.1182
2020-11-05 21:05:20,819 - root - INFO - Evaluate: Epoch 0979 | NDCG 0.2817 | MSE 0.3283
2020-11-05 21:05:20,827 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6978 | Iter Mean Loss 4.6978
2020-11-05 21:05:20,834 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1464 | Iter Mean Loss 2.9221
2020-11-05 21:05:20,841 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1643 | Iter Mean Loss 3.3362
2020-11-05 21:05:20,849 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5627 | Iter Mean Loss 3.3928
2020-11-05 21:05:20,856 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0018 | Iter Mean Loss 3.1146
2020-11-05 21:05:20,858 - root - INFO - Evaluate: Epoch 0980 | NDCG 0.2817 | MSE 0.3284
2020-11-05 21:05:20,866 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6935 | Iter Mean Loss 4.6935
2020-11-05 21:05:20,874 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1447 | Iter Mean Loss 2.9191
2020-11-05 21:05:20,882 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1592 | Iter Mean Loss 3.3325
2020-11-05 21:05:20,889 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5584 | Iter Mean Loss 3.3890
2020-11-05 21:05:20,897 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9988 | Iter Mean Loss 3.1109
2020-11-05 21:05:20,899 - root - INFO - Evaluate: Epoch 0981 | NDCG 0.2817 | MSE 0.3284
2020-11-05 21:05:20,907 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6892 | Iter Mean Loss 4.6892
2020-11-05 21:05:20,915 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1430 | Iter Mean Loss 2.9161
2020-11-05 21:05:20,923 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1542 | Iter Mean Loss 3.3288
2020-11-05 21:05:20,930 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5542 | Iter Mean Loss 3.3851
2020-11-05 21:05:20,938 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9959 | Iter Mean Loss 3.1073
2020-11-05 21:05:20,940 - root - INFO - Evaluate: Epoch 0982 | NDCG 0.2817 | MSE 0.3284
2020-11-05 21:05:20,948 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6848 | Iter Mean Loss 4.6848
2020-11-05 21:05:20,957 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1412 | Iter Mean Loss 2.9130
2020-11-05 21:05:20,965 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1492 | Iter Mean Loss 3.3251
2020-11-05 21:05:20,972 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5500 | Iter Mean Loss 3.3813
2020-11-05 21:05:20,979 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9929 | Iter Mean Loss 3.1036
2020-11-05 21:05:20,981 - root - INFO - Evaluate: Epoch 0983 | NDCG 0.2817 | MSE 0.3285
2020-11-05 21:05:20,989 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6805 | Iter Mean Loss 4.6805
2020-11-05 21:05:20,997 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1395 | Iter Mean Loss 2.9100
2020-11-05 21:05:21,004 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1442 | Iter Mean Loss 3.3214
2020-11-05 21:05:21,011 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5458 | Iter Mean Loss 3.3775
2020-11-05 21:05:21,019 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9900 | Iter Mean Loss 3.1000
2020-11-05 21:05:21,021 - root - INFO - Evaluate: Epoch 0984 | NDCG 0.2817 | MSE 0.3285
2020-11-05 21:05:21,029 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6761 | Iter Mean Loss 4.6761
2020-11-05 21:05:21,036 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1377 | Iter Mean Loss 2.9069
2020-11-05 21:05:21,043 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1392 | Iter Mean Loss 3.3177
2020-11-05 21:05:21,050 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5415 | Iter Mean Loss 3.3736
2020-11-05 21:05:21,058 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9870 | Iter Mean Loss 3.0963
2020-11-05 21:05:21,060 - root - INFO - Evaluate: Epoch 0985 | NDCG 0.2817 | MSE 0.3286
2020-11-05 21:05:21,068 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6716 | Iter Mean Loss 4.6716
2020-11-05 21:05:21,076 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1359 | Iter Mean Loss 2.9038
2020-11-05 21:05:21,084 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1342 | Iter Mean Loss 3.3139
2020-11-05 21:05:21,091 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5373 | Iter Mean Loss 3.3698
2020-11-05 21:05:21,099 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9841 | Iter Mean Loss 3.0926
2020-11-05 21:05:21,101 - root - INFO - Evaluate: Epoch 0986 | NDCG 0.2817 | MSE 0.3286
2020-11-05 21:05:21,110 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6672 | Iter Mean Loss 4.6672
2020-11-05 21:05:21,117 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1342 | Iter Mean Loss 2.9007
2020-11-05 21:05:21,125 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1292 | Iter Mean Loss 3.3102
2020-11-05 21:05:21,133 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5331 | Iter Mean Loss 3.3659
2020-11-05 21:05:21,141 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9811 | Iter Mean Loss 3.0889
2020-11-05 21:05:21,143 - root - INFO - Evaluate: Epoch 0987 | NDCG 0.2817 | MSE 0.3287
2020-11-05 21:05:21,151 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6627 | Iter Mean Loss 4.6627
2020-11-05 21:05:21,159 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1324 | Iter Mean Loss 2.8975
2020-11-05 21:05:21,167 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1242 | Iter Mean Loss 3.3064
2020-11-05 21:05:21,174 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5289 | Iter Mean Loss 3.3620
2020-11-05 21:05:21,181 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9781 | Iter Mean Loss 3.0853
2020-11-05 21:05:21,183 - root - INFO - Evaluate: Epoch 0988 | NDCG 0.2817 | MSE 0.3287
2020-11-05 21:05:21,191 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6582 | Iter Mean Loss 4.6582
2020-11-05 21:05:21,198 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1306 | Iter Mean Loss 2.8944
2020-11-05 21:05:21,205 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1192 | Iter Mean Loss 3.3027
2020-11-05 21:05:21,212 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5246 | Iter Mean Loss 3.3582
2020-11-05 21:05:21,219 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9752 | Iter Mean Loss 3.0816
2020-11-05 21:05:21,221 - root - INFO - Evaluate: Epoch 0989 | NDCG 0.2817 | MSE 0.3287
2020-11-05 21:05:21,229 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 4.6537
2020-11-05 21:05:21,236 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1288 | Iter Mean Loss 2.8912
2020-11-05 21:05:21,244 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1142 | Iter Mean Loss 3.2989
2020-11-05 21:05:21,251 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5204 | Iter Mean Loss 3.3543
2020-11-05 21:05:21,258 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9722 | Iter Mean Loss 3.0779
2020-11-05 21:05:21,261 - root - INFO - Evaluate: Epoch 0990 | NDCG 0.2817 | MSE 0.3288
2020-11-05 21:05:21,269 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6491 | Iter Mean Loss 4.6491
2020-11-05 21:05:21,277 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1270 | Iter Mean Loss 2.8881
2020-11-05 21:05:21,285 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 3.2951
2020-11-05 21:05:21,292 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5162 | Iter Mean Loss 3.3504
2020-11-05 21:05:21,300 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9692 | Iter Mean Loss 3.0741
2020-11-05 21:05:21,302 - root - INFO - Evaluate: Epoch 0991 | NDCG 0.2817 | MSE 0.3288
2020-11-05 21:05:21,311 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6446 | Iter Mean Loss 4.6446
2020-11-05 21:05:21,319 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1252 | Iter Mean Loss 2.8849
2020-11-05 21:05:21,327 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1042 | Iter Mean Loss 3.2913
2020-11-05 21:05:21,335 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5120 | Iter Mean Loss 3.3465
2020-11-05 21:05:21,342 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9662 | Iter Mean Loss 3.0704
2020-11-05 21:05:21,344 - root - INFO - Evaluate: Epoch 0992 | NDCG 0.2817 | MSE 0.3289
2020-11-05 21:05:21,353 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6400 | Iter Mean Loss 4.6400
2020-11-05 21:05:21,360 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1234 | Iter Mean Loss 2.8817
2020-11-05 21:05:21,368 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0991 | Iter Mean Loss 3.2875
2020-11-05 21:05:21,375 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5077 | Iter Mean Loss 3.3425
2020-11-05 21:05:21,382 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9633 | Iter Mean Loss 3.0667
2020-11-05 21:05:21,384 - root - INFO - Evaluate: Epoch 0993 | NDCG 0.2817 | MSE 0.3289
2020-11-05 21:05:21,392 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6353 | Iter Mean Loss 4.6353
2020-11-05 21:05:21,399 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1215 | Iter Mean Loss 2.8784
2020-11-05 21:05:21,406 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0941 | Iter Mean Loss 3.2837
2020-11-05 21:05:21,413 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 3.3386
2020-11-05 21:05:21,421 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9603 | Iter Mean Loss 3.0629
2020-11-05 21:05:21,423 - root - INFO - Evaluate: Epoch 0994 | NDCG 0.2817 | MSE 0.3289
2020-11-05 21:05:21,431 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6307 | Iter Mean Loss 4.6307
2020-11-05 21:05:21,438 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1197 | Iter Mean Loss 2.8752
2020-11-05 21:05:21,446 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0891 | Iter Mean Loss 3.2798
2020-11-05 21:05:21,453 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4993 | Iter Mean Loss 3.3347
2020-11-05 21:05:21,460 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9573 | Iter Mean Loss 3.0592
2020-11-05 21:05:21,463 - root - INFO - Evaluate: Epoch 0995 | NDCG 0.2817 | MSE 0.3290
2020-11-05 21:05:21,471 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6260 | Iter Mean Loss 4.6260
2020-11-05 21:05:21,478 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1178 | Iter Mean Loss 2.8719
2020-11-05 21:05:21,486 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0841 | Iter Mean Loss 3.2760
2020-11-05 21:05:21,494 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4950 | Iter Mean Loss 3.3307
2020-11-05 21:05:21,502 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9543 | Iter Mean Loss 3.0555
2020-11-05 21:05:21,504 - root - INFO - Evaluate: Epoch 0996 | NDCG 0.2817 | MSE 0.3290
2020-11-05 21:05:21,512 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6213 | Iter Mean Loss 4.6213
2020-11-05 21:05:21,520 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1160 | Iter Mean Loss 2.8686
2020-11-05 21:05:21,528 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 3.2721
2020-11-05 21:05:21,536 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4908 | Iter Mean Loss 3.3268
2020-11-05 21:05:21,543 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9513 | Iter Mean Loss 3.0517
2020-11-05 21:05:21,545 - root - INFO - Evaluate: Epoch 0997 | NDCG 0.2817 | MSE 0.3291
2020-11-05 21:05:21,554 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6166 | Iter Mean Loss 4.6166
2020-11-05 21:05:21,562 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1141 | Iter Mean Loss 2.8653
2020-11-05 21:05:21,569 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0741 | Iter Mean Loss 3.2683
2020-11-05 21:05:21,576 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4866 | Iter Mean Loss 3.3228
2020-11-05 21:05:21,583 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9483 | Iter Mean Loss 3.0479
2020-11-05 21:05:21,585 - root - INFO - Evaluate: Epoch 0998 | NDCG 0.2817 | MSE 0.3291
2020-11-05 21:05:21,593 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6118 | Iter Mean Loss 4.6118
2020-11-05 21:05:21,600 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1123 | Iter Mean Loss 2.8620
2020-11-05 21:05:21,607 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0691 | Iter Mean Loss 3.2644
2020-11-05 21:05:21,614 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4824 | Iter Mean Loss 3.3189
2020-11-05 21:05:21,622 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9452 | Iter Mean Loss 3.0441
2020-11-05 21:05:21,624 - root - INFO - Evaluate: Epoch 0999 | NDCG 0.2817 | MSE 0.3291
2020-11-05 21:05:21,624 - root - INFO - [!]-----------training done.
2020-11-05 21:05:21,804 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,805 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 21:05:21,806 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,807 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,808 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,809 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,810 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,811 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,812 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,813 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,814 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,815 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,816 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,817 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,818 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 21:05:21,819 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,820 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,821 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,822 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,823 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,823 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,823 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,823 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,823 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,824 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 21:05:21,825 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,826 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,827 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,828 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,829 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,830 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,831 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,832 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,833 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,834 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,835 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,836 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,837 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,838 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,839 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,840 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,841 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 21:05:21,842 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,843 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,844 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,845 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,846 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,847 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,848 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,849 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,850 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,851 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,852 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,853 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,854 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 21:05:21,855 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,856 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,857 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,858 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,859 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,860 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,861 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,862 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,863 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,864 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,865 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,866 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,867 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,868 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,869 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,870 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,871 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 21:05:21,872 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,873 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 21:05:21,874 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 21:05:21,875 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 21:05:21,875 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,875 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,875 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 21:05:21,875 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 21:05:22,245 - root - INFO - [!]-----------start testing.
2020-11-05 21:05:22,247 - root - INFO - Real Rank:
2020-11-05 21:05:22,247 - root - INFO - [116 142]
2020-11-05 21:05:22,248 - root - INFO - Pred Rank:
2020-11-05 21:05:22,248 - root - INFO - [142  91 116 135]
