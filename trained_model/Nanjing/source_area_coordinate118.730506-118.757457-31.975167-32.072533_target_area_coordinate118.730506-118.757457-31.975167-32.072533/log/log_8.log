2020-11-05 18:32:52,134 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.730506-118.757457-31.975167-32.072533_target_area_coordinate118.730506-118.757457-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], target_enterprise='大众书局')
2020-11-05 18:32:52,135 - root - INFO - --------------parse args and init done.
2020-11-05 18:32:54,992 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 18:33:01,175 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 18:33:01,175 - root - INFO - n_source_grid: 95, n_target_grid: 152
2020-11-05 18:33:01,175 - root - INFO - [3 /10]       split grid done.
2020-11-05 18:33:02,467 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 18:33:02,471 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 18:33:02,555 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 18:33:02,670 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 18:33:02,670 - root - INFO - [8 /10]       combine features done.
2020-11-05 18:33:02,765 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 18:33:02,767 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 18:33:02,819 - root - INFO - --------------load data done.
2020-11-05 18:33:02,824 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 18:33:02,827 - root - INFO - --------------construct model and optimizer done.
2020-11-05 18:33:02,827 - root - INFO - --------------initialize metrics done.
2020-11-05 18:33:02,827 - root - INFO - [!]-----------start training.
2020-11-05 18:33:02,843 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 599.9505 | Iter Mean Loss 599.9505
2020-11-05 18:33:02,857 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 563.8873 | Iter Mean Loss 581.9189
2020-11-05 18:33:02,869 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 584.5262 | Iter Mean Loss 582.7880
2020-11-05 18:33:02,883 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 507.9936 | Iter Mean Loss 564.0894
2020-11-05 18:33:02,895 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 458.8430 | Iter Mean Loss 543.0401
2020-11-05 18:33:02,899 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.6699
2020-11-05 18:33:02,912 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 471.0423 | Iter Mean Loss 471.0423
2020-11-05 18:33:02,925 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 438.9006 | Iter Mean Loss 454.9715
2020-11-05 18:33:02,938 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 467.8340 | Iter Mean Loss 459.2590
2020-11-05 18:33:02,950 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 403.4666 | Iter Mean Loss 445.3109
2020-11-05 18:33:02,963 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 363.2046 | Iter Mean Loss 428.8896
2020-11-05 18:33:02,968 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.6592
2020-11-05 18:33:02,977 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 370.4881 | Iter Mean Loss 370.4881
2020-11-05 18:33:02,986 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 342.5330 | Iter Mean Loss 356.5105
2020-11-05 18:33:02,994 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 377.8442 | Iter Mean Loss 363.6218
2020-11-05 18:33:03,003 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 323.3188 | Iter Mean Loss 353.5460
2020-11-05 18:33:03,011 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 289.7713 | Iter Mean Loss 340.7911
2020-11-05 18:33:03,013 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.6435
2020-11-05 18:33:03,022 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 293.7136 | Iter Mean Loss 293.7136
2020-11-05 18:33:03,029 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 270.0704 | Iter Mean Loss 281.8920
2020-11-05 18:33:03,037 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 310.1771 | Iter Mean Loss 291.3204
2020-11-05 18:33:03,045 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 263.4282 | Iter Mean Loss 284.3473
2020-11-05 18:33:03,053 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 234.8489 | Iter Mean Loss 274.4476
2020-11-05 18:33:03,055 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.6286
2020-11-05 18:33:03,063 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 236.6264 | Iter Mean Loss 236.6264
2020-11-05 18:33:03,071 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 217.0520 | Iter Mean Loss 226.8392
2020-11-05 18:33:03,079 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.5522 | Iter Mean Loss 238.0769
2020-11-05 18:33:03,087 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 219.7862 | Iter Mean Loss 233.5042
2020-11-05 18:33:03,094 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 194.8294 | Iter Mean Loss 225.7692
2020-11-05 18:33:03,096 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.6161
2020-11-05 18:33:03,105 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 195.2402 | Iter Mean Loss 195.2402
2020-11-05 18:33:03,113 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 179.2348 | Iter Mean Loss 187.2375
2020-11-05 18:33:03,120 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 224.8896 | Iter Mean Loss 199.7882
2020-11-05 18:33:03,128 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 188.5862 | Iter Mean Loss 196.9877
2020-11-05 18:33:03,136 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 166.2150 | Iter Mean Loss 190.8331
2020-11-05 18:33:03,138 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6060
2020-11-05 18:33:03,146 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7128 | Iter Mean Loss 165.7128
2020-11-05 18:33:03,154 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 152.6226 | Iter Mean Loss 159.1677
2020-11-05 18:33:03,161 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 199.3787 | Iter Mean Loss 172.5714
2020-11-05 18:33:03,169 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 166.3069 | Iter Mean Loss 171.0053
2020-11-05 18:33:03,176 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 145.7488 | Iter Mean Loss 165.9540
2020-11-05 18:33:03,178 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.5978
2020-11-05 18:33:03,187 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 144.5331 | Iter Mean Loss 144.5331
2020-11-05 18:33:03,195 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 133.6582 | Iter Mean Loss 139.0957
2020-11-05 18:33:03,203 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 180.6999 | Iter Mean Loss 152.9638
2020-11-05 18:33:03,210 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 149.9379 | Iter Mean Loss 152.2073
2020-11-05 18:33:03,218 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 130.6678 | Iter Mean Loss 147.8994
2020-11-05 18:33:03,220 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5912
2020-11-05 18:33:03,228 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 128.7950 | Iter Mean Loss 128.7950
2020-11-05 18:33:03,236 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 119.4939 | Iter Mean Loss 124.1445
2020-11-05 18:33:03,244 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 166.2718 | Iter Mean Loss 138.1869
2020-11-05 18:33:03,251 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 137.1909 | Iter Mean Loss 137.9379
2020-11-05 18:33:03,259 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 118.9059 | Iter Mean Loss 134.1315
2020-11-05 18:33:03,261 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5858
2020-11-05 18:33:03,269 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 116.3777 | Iter Mean Loss 116.3777
2020-11-05 18:33:03,277 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.1299 | Iter Mean Loss 112.2538
2020-11-05 18:33:03,284 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 154.3308 | Iter Mean Loss 126.2795
2020-11-05 18:33:03,292 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 126.5405 | Iter Mean Loss 126.3447
2020-11-05 18:33:03,300 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 109.1168 | Iter Mean Loss 122.8991
2020-11-05 18:33:03,302 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.5813
2020-11-05 18:33:03,310 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 105.9358 | Iter Mean Loss 105.9358
2020-11-05 18:33:03,318 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 98.3574 | Iter Mean Loss 102.1466
2020-11-05 18:33:03,327 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 143.8448 | Iter Mean Loss 116.0460
2020-11-05 18:33:03,335 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 117.1201 | Iter Mean Loss 116.3145
2020-11-05 18:33:03,342 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 100.5567 | Iter Mean Loss 113.1630
2020-11-05 18:33:03,344 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.5768
2020-11-05 18:33:03,352 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 96.7500 | Iter Mean Loss 96.7500
2020-11-05 18:33:03,360 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 89.5796 | Iter Mean Loss 93.1648
2020-11-05 18:33:03,367 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.3275 | Iter Mean Loss 106.8857
2020-11-05 18:33:03,374 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 108.5400 | Iter Mean Loss 107.2993
2020-11-05 18:33:03,382 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 92.8969 | Iter Mean Loss 104.4188
2020-11-05 18:33:03,384 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.5719
2020-11-05 18:33:03,392 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 88.5143 | Iter Mean Loss 88.5143
2020-11-05 18:33:03,399 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 81.5814 | Iter Mean Loss 85.0478
2020-11-05 18:33:03,407 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 125.6180 | Iter Mean Loss 98.5712
2020-11-05 18:33:03,415 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.6804 | Iter Mean Loss 99.0985
2020-11-05 18:33:03,424 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 86.0280 | Iter Mean Loss 96.4844
2020-11-05 18:33:03,426 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.5662
2020-11-05 18:33:03,436 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 81.1286 | Iter Mean Loss 81.1286
2020-11-05 18:33:03,444 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 74.3207 | Iter Mean Loss 77.7246
2020-11-05 18:33:03,452 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 117.6934 | Iter Mean Loss 91.0476
2020-11-05 18:33:03,460 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.5280 | Iter Mean Loss 91.6677
2020-11-05 18:33:03,468 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 79.9200 | Iter Mean Loss 89.3181
2020-11-05 18:33:03,470 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.5598
2020-11-05 18:33:03,479 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.5577 | Iter Mean Loss 74.5577
2020-11-05 18:33:03,489 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 67.7987 | Iter Mean Loss 71.1782
2020-11-05 18:33:03,499 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 110.5582 | Iter Mean Loss 84.3049
2020-11-05 18:33:03,508 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.0850 | Iter Mean Loss 84.9999
2020-11-05 18:33:03,516 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 74.5488 | Iter Mean Loss 82.9097
2020-11-05 18:33:03,519 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.5531
2020-11-05 18:33:03,527 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.7612 | Iter Mean Loss 68.7612
2020-11-05 18:33:03,535 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 61.9997 | Iter Mean Loss 65.3805
2020-11-05 18:33:03,543 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 104.1932 | Iter Mean Loss 78.3180
2020-11-05 18:33:03,551 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.3271 | Iter Mean Loss 79.0703
2020-11-05 18:33:03,559 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 69.8635 | Iter Mean Loss 77.2289
2020-11-05 18:33:03,561 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.5464
2020-11-05 18:33:03,569 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.6676 | Iter Mean Loss 63.6676
2020-11-05 18:33:03,577 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 56.8697 | Iter Mean Loss 60.2687
2020-11-05 18:33:03,585 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 98.5402 | Iter Mean Loss 73.0259
2020-11-05 18:33:03,593 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.1936 | Iter Mean Loss 73.8178
2020-11-05 18:33:03,601 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 65.7818 | Iter Mean Loss 72.2106
2020-11-05 18:33:03,603 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.5403
2020-11-05 18:33:03,611 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.1769 | Iter Mean Loss 59.1769
2020-11-05 18:33:03,619 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 52.3209 | Iter Mean Loss 55.7489
2020-11-05 18:33:03,627 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 93.5118 | Iter Mean Loss 68.3365
2020-11-05 18:33:03,634 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 71.5985 | Iter Mean Loss 69.1520
2020-11-05 18:33:03,642 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 62.2030 | Iter Mean Loss 67.7622
2020-11-05 18:33:03,644 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.5349
2020-11-05 18:33:03,652 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.1791 | Iter Mean Loss 55.1791
2020-11-05 18:33:03,659 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 48.2524 | Iter Mean Loss 51.7158
2020-11-05 18:33:03,666 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 89.0110 | Iter Mean Loss 64.1475
2020-11-05 18:33:03,674 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 67.4521 | Iter Mean Loss 64.9737
2020-11-05 18:33:03,681 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 59.0294 | Iter Mean Loss 63.7848
2020-11-05 18:33:03,683 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.5301
2020-11-05 18:33:03,691 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.5756 | Iter Mean Loss 51.5756
2020-11-05 18:33:03,699 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.5715 | Iter Mean Loss 48.0735
2020-11-05 18:33:03,706 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 84.9521 | Iter Mean Loss 60.3664
2020-11-05 18:33:03,714 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 63.6805 | Iter Mean Loss 61.1949
2020-11-05 18:33:03,721 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 56.1838 | Iter Mean Loss 60.1927
2020-11-05 18:33:03,723 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.5260
2020-11-05 18:33:03,731 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2950 | Iter Mean Loss 48.2950
2020-11-05 18:33:03,739 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2096 | Iter Mean Loss 44.7523
2020-11-05 18:33:03,746 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 81.2730 | Iter Mean Loss 56.9259
2020-11-05 18:33:03,753 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 60.2347 | Iter Mean Loss 57.7531
2020-11-05 18:33:03,761 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 53.6153 | Iter Mean Loss 56.9255
2020-11-05 18:33:03,763 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.5224
2020-11-05 18:33:03,770 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.2965 | Iter Mean Loss 45.2965
2020-11-05 18:33:03,778 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.1255 | Iter Mean Loss 41.7110
2020-11-05 18:33:03,785 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.9367 | Iter Mean Loss 53.7862
2020-11-05 18:33:03,792 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 57.0892 | Iter Mean Loss 54.6120
2020-11-05 18:33:03,800 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 51.2955 | Iter Mean Loss 53.9487
2020-11-05 18:33:03,802 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.5192
2020-11-05 18:33:03,809 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.5641 | Iter Mean Loss 42.5641
2020-11-05 18:33:03,817 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.3007 | Iter Mean Loss 38.9324
2020-11-05 18:33:03,824 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 74.9256 | Iter Mean Loss 50.9301
2020-11-05 18:33:03,831 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 54.2351 | Iter Mean Loss 51.7564
2020-11-05 18:33:03,839 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 49.2126 | Iter Mean Loss 51.2476
2020-11-05 18:33:03,841 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.5164
2020-11-05 18:33:03,848 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.0977 | Iter Mean Loss 40.0977
2020-11-05 18:33:03,856 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 32.7323 | Iter Mean Loss 36.4150
2020-11-05 18:33:03,863 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.2329 | Iter Mean Loss 48.3543
2020-11-05 18:33:03,870 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.6722 | Iter Mean Loss 49.1838
2020-11-05 18:33:03,877 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 47.3629 | Iter Mean Loss 48.8196
2020-11-05 18:33:03,879 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.5139
2020-11-05 18:33:03,887 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.9030 | Iter Mean Loss 37.9030
2020-11-05 18:33:03,895 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 30.4248 | Iter Mean Loss 34.1639
2020-11-05 18:33:03,902 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.8550 | Iter Mean Loss 46.0609
2020-11-05 18:33:03,909 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.4024 | Iter Mean Loss 46.8963
2020-11-05 18:33:03,916 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.7445 | Iter Mean Loss 46.6659
2020-11-05 18:33:03,918 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.5117
2020-11-05 18:33:03,926 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9842 | Iter Mean Loss 35.9842
2020-11-05 18:33:03,934 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.3828 | Iter Mean Loss 32.1835
2020-11-05 18:33:03,941 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.7854 | Iter Mean Loss 44.0508
2020-11-05 18:33:03,948 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.4234 | Iter Mean Loss 44.8940
2020-11-05 18:33:03,955 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 44.3515 | Iter Mean Loss 44.7855
2020-11-05 18:33:03,958 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.5098
2020-11-05 18:33:03,966 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.3389 | Iter Mean Loss 34.3389
2020-11-05 18:33:03,974 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.6056 | Iter Mean Loss 30.4722
2020-11-05 18:33:03,981 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0123 | Iter Mean Loss 42.3189
2020-11-05 18:33:03,988 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.7268 | Iter Mean Loss 43.1709
2020-11-05 18:33:03,995 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 43.1727 | Iter Mean Loss 43.1712
2020-11-05 18:33:03,997 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.5081
2020-11-05 18:33:04,006 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.9560 | Iter Mean Loss 32.9560
2020-11-05 18:33:04,013 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.0850 | Iter Mean Loss 29.0205
2020-11-05 18:33:04,021 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.5169 | Iter Mean Loss 40.8526
2020-11-05 18:33:04,028 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.2964 | Iter Mean Loss 41.7136
2020-11-05 18:33:04,035 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 42.1911 | Iter Mean Loss 41.8091
2020-11-05 18:33:04,037 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.5066
2020-11-05 18:33:04,045 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.8164 | Iter Mean Loss 31.8164
2020-11-05 18:33:04,052 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.8048 | Iter Mean Loss 27.8106
2020-11-05 18:33:04,059 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2742 | Iter Mean Loss 39.6318
2020-11-05 18:33:04,066 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.1094 | Iter Mean Loss 40.5012
2020-11-05 18:33:04,074 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 41.3853 | Iter Mean Loss 40.6780
2020-11-05 18:33:04,076 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.5052
2020-11-05 18:33:04,083 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.8940 | Iter Mean Loss 30.8940
2020-11-05 18:33:04,091 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7426 | Iter Mean Loss 26.8183
2020-11-05 18:33:04,098 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.2539 | Iter Mean Loss 38.6302
2020-11-05 18:33:04,105 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1375 | Iter Mean Loss 39.5070
2020-11-05 18:33:04,112 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.7305 | Iter Mean Loss 39.7517
2020-11-05 18:33:04,114 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.5041
2020-11-05 18:33:04,122 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1582 | Iter Mean Loss 30.1582
2020-11-05 18:33:04,129 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.8714 | Iter Mean Loss 26.0148
2020-11-05 18:33:04,136 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.4230 | Iter Mean Loss 37.8175
2020-11-05 18:33:04,143 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3496 | Iter Mean Loss 38.7006
2020-11-05 18:33:04,150 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.2007 | Iter Mean Loss 39.0006
2020-11-05 18:33:04,152 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.2817 | MSE 0.5031
2020-11-05 18:33:04,159 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.5766 | Iter Mean Loss 29.5766
2020-11-05 18:33:04,167 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.1624 | Iter Mean Loss 25.3695
2020-11-05 18:33:04,174 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.7478 | Iter Mean Loss 37.1623
2020-11-05 18:33:04,181 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.7138 | Iter Mean Loss 38.0501
2020-11-05 18:33:04,188 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.7704 | Iter Mean Loss 38.3942
2020-11-05 18:33:04,190 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.2817 | MSE 0.5022
2020-11-05 18:33:04,197 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.1174 | Iter Mean Loss 29.1174
2020-11-05 18:33:04,204 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5868 | Iter Mean Loss 24.8521
2020-11-05 18:33:04,211 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.1961 | Iter Mean Loss 36.6334
2020-11-05 18:33:04,218 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1997 | Iter Mean Loss 37.5250
2020-11-05 18:33:04,225 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.4166 | Iter Mean Loss 37.9033
2020-11-05 18:33:04,227 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.2817 | MSE 0.5015
2020-11-05 18:33:04,235 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.7520 | Iter Mean Loss 28.7520
2020-11-05 18:33:04,242 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1178 | Iter Mean Loss 24.4349
2020-11-05 18:33:04,249 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.7387 | Iter Mean Loss 36.2028
2020-11-05 18:33:04,256 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7799 | Iter Mean Loss 37.0971
2020-11-05 18:33:04,263 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 39.1192 | Iter Mean Loss 37.5015
2020-11-05 18:33:04,265 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.2817 | MSE 0.5009
2020-11-05 18:33:04,272 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4556 | Iter Mean Loss 28.4556
2020-11-05 18:33:04,280 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7321 | Iter Mean Loss 24.0938
2020-11-05 18:33:04,287 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3507 | Iter Mean Loss 35.8461
2020-11-05 18:33:04,294 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4309 | Iter Mean Loss 36.7423
2020-11-05 18:33:04,301 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.8614 | Iter Mean Loss 37.1661
2020-11-05 18:33:04,303 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.2817 | MSE 0.5003
2020-11-05 18:33:04,311 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2086 | Iter Mean Loss 28.2086
2020-11-05 18:33:04,324 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.4101 | Iter Mean Loss 23.8093
2020-11-05 18:33:04,331 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0119 | Iter Mean Loss 35.5435
2020-11-05 18:33:04,338 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1339 | Iter Mean Loss 36.4411
2020-11-05 18:33:04,345 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.6306 | Iter Mean Loss 36.8790
2020-11-05 18:33:04,347 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.2817 | MSE 0.4999
2020-11-05 18:33:04,355 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.9961 | Iter Mean Loss 27.9961
2020-11-05 18:33:04,362 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1364 | Iter Mean Loss 23.5663
2020-11-05 18:33:04,369 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7064 | Iter Mean Loss 35.2796
2020-11-05 18:33:04,376 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8739 | Iter Mean Loss 36.1782
2020-11-05 18:33:04,383 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.4172 | Iter Mean Loss 36.6260
2020-11-05 18:33:04,385 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.2817 | MSE 0.4996
2020-11-05 18:33:04,392 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8074 | Iter Mean Loss 27.8074
2020-11-05 18:33:04,399 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8993 | Iter Mean Loss 23.3534
2020-11-05 18:33:04,406 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.4225 | Iter Mean Loss 35.0431
2020-11-05 18:33:04,413 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6401 | Iter Mean Loss 35.9423
2020-11-05 18:33:04,421 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.2145 | Iter Mean Loss 36.3967
2020-11-05 18:33:04,423 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.2817 | MSE 0.4993
2020-11-05 18:33:04,430 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.6351 | Iter Mean Loss 27.6351
2020-11-05 18:33:04,437 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6900 | Iter Mean Loss 23.1625
2020-11-05 18:33:04,444 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.1517 | Iter Mean Loss 34.8256
2020-11-05 18:33:04,451 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.4241 | Iter Mean Loss 35.7252
2020-11-05 18:33:04,458 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 38.0179 | Iter Mean Loss 36.1837
2020-11-05 18:33:04,460 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.2817 | MSE 0.4991
2020-11-05 18:33:04,468 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.4741 | Iter Mean Loss 27.4741
2020-11-05 18:33:04,475 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.5017 | Iter Mean Loss 22.9879
2020-11-05 18:33:04,482 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.8881 | Iter Mean Loss 34.6213
2020-11-05 18:33:04,489 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2203 | Iter Mean Loss 35.5210
2020-11-05 18:33:04,496 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.8245 | Iter Mean Loss 35.9817
2020-11-05 18:33:04,498 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.2817 | MSE 0.4989
2020-11-05 18:33:04,505 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3210 | Iter Mean Loss 27.3210
2020-11-05 18:33:04,512 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3295 | Iter Mean Loss 22.8252
2020-11-05 18:33:04,519 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.6279 | Iter Mean Loss 34.4261
2020-11-05 18:33:04,526 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0246 | Iter Mean Loss 35.3257
2020-11-05 18:33:04,534 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.6324 | Iter Mean Loss 35.7871
2020-11-05 18:33:04,535 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.2817 | MSE 0.4988
2020-11-05 18:33:04,543 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.1733 | Iter Mean Loss 27.1733
2020-11-05 18:33:04,550 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.1695 | Iter Mean Loss 22.6714
2020-11-05 18:33:04,557 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3683 | Iter Mean Loss 34.2370
2020-11-05 18:33:04,564 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8340 | Iter Mean Loss 35.1363
2020-11-05 18:33:04,571 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.4404 | Iter Mean Loss 35.5971
2020-11-05 18:33:04,573 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.2817 | MSE 0.4987
2020-11-05 18:33:04,581 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0294 | Iter Mean Loss 27.0294
2020-11-05 18:33:04,588 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0186 | Iter Mean Loss 22.5240
2020-11-05 18:33:04,595 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.1077 | Iter Mean Loss 34.0519
2020-11-05 18:33:04,602 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.6466 | Iter Mean Loss 34.9506
2020-11-05 18:33:04,609 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.2477 | Iter Mean Loss 35.4100
2020-11-05 18:33:04,611 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.2817 | MSE 0.4986
2020-11-05 18:33:04,618 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.8878 | Iter Mean Loss 26.8878
2020-11-05 18:33:04,625 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.8743 | Iter Mean Loss 22.3811
2020-11-05 18:33:04,632 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.8452 | Iter Mean Loss 33.8691
2020-11-05 18:33:04,640 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.4607 | Iter Mean Loss 34.7670
2020-11-05 18:33:04,648 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 37.0539 | Iter Mean Loss 35.2244
2020-11-05 18:33:04,651 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.2817 | MSE 0.4986
2020-11-05 18:33:04,659 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7473 | Iter Mean Loss 26.7473
2020-11-05 18:33:04,667 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7345 | Iter Mean Loss 22.2409
2020-11-05 18:33:04,675 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.5801 | Iter Mean Loss 33.6873
2020-11-05 18:33:04,682 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2753 | Iter Mean Loss 34.5843
2020-11-05 18:33:04,690 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.8584 | Iter Mean Loss 35.0391
2020-11-05 18:33:04,692 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:33:04,700 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6069 | Iter Mean Loss 26.6069
2020-11-05 18:33:04,708 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5973 | Iter Mean Loss 22.1021
2020-11-05 18:33:04,716 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.3121 | Iter Mean Loss 33.5054
2020-11-05 18:33:04,724 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0895 | Iter Mean Loss 34.4015
2020-11-05 18:33:04,732 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6610 | Iter Mean Loss 34.8534
2020-11-05 18:33:04,734 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:33:04,742 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.4657 | Iter Mean Loss 26.4657
2020-11-05 18:33:04,751 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4612 | Iter Mean Loss 21.9635
2020-11-05 18:33:04,758 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.0410 | Iter Mean Loss 33.3226
2020-11-05 18:33:04,766 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.9027 | Iter Mean Loss 34.2176
2020-11-05 18:33:04,774 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.4613 | Iter Mean Loss 34.6664
2020-11-05 18:33:04,776 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:33:04,785 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3228 | Iter Mean Loss 26.3228
2020-11-05 18:33:04,793 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.3249 | Iter Mean Loss 21.8239
2020-11-05 18:33:04,800 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.7666 | Iter Mean Loss 33.1381
2020-11-05 18:33:04,808 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.7143 | Iter Mean Loss 34.0322
2020-11-05 18:33:04,816 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.2590 | Iter Mean Loss 34.4775
2020-11-05 18:33:04,818 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:33:04,826 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1776 | Iter Mean Loss 26.1776
2020-11-05 18:33:04,834 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.1874 | Iter Mean Loss 21.6825
2020-11-05 18:33:04,842 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.4889 | Iter Mean Loss 32.9513
2020-11-05 18:33:04,849 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.5238 | Iter Mean Loss 33.8444
2020-11-05 18:33:04,857 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.0538 | Iter Mean Loss 34.2863
2020-11-05 18:33:04,859 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.2817 | MSE 0.4985
2020-11-05 18:33:04,867 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.0292 | Iter Mean Loss 26.0292
2020-11-05 18:33:04,875 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0477 | Iter Mean Loss 21.5385
2020-11-05 18:33:04,883 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.2077 | Iter Mean Loss 32.7616
2020-11-05 18:33:04,890 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.3308 | Iter Mean Loss 33.6539
2020-11-05 18:33:04,898 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.8454 | Iter Mean Loss 34.0922
2020-11-05 18:33:04,900 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:04,909 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8773 | Iter Mean Loss 25.8773
2020-11-05 18:33:04,916 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.9051 | Iter Mean Loss 21.3912
2020-11-05 18:33:04,924 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.9228 | Iter Mean Loss 32.5684
2020-11-05 18:33:04,931 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.1349 | Iter Mean Loss 33.4600
2020-11-05 18:33:04,939 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.6332 | Iter Mean Loss 33.8947
2020-11-05 18:33:04,941 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:04,949 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7211 | Iter Mean Loss 25.7211
2020-11-05 18:33:04,957 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7588 | Iter Mean Loss 21.2400
2020-11-05 18:33:04,964 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.6339 | Iter Mean Loss 32.3713
2020-11-05 18:33:04,972 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.9358 | Iter Mean Loss 33.2624
2020-11-05 18:33:04,980 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.4170 | Iter Mean Loss 33.6933
2020-11-05 18:33:04,982 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:04,990 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.5602 | Iter Mean Loss 25.5602
2020-11-05 18:33:04,998 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.6084 | Iter Mean Loss 21.0843
2020-11-05 18:33:05,006 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.3408 | Iter Mean Loss 32.1698
2020-11-05 18:33:05,014 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.7330 | Iter Mean Loss 33.0606
2020-11-05 18:33:05,021 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 35.1963 | Iter Mean Loss 33.4877
2020-11-05 18:33:05,024 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,032 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3942 | Iter Mean Loss 25.3942
2020-11-05 18:33:05,040 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.4533 | Iter Mean Loss 20.9238
2020-11-05 18:33:05,047 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0431 | Iter Mean Loss 31.9635
2020-11-05 18:33:05,054 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.5263 | Iter Mean Loss 32.8542
2020-11-05 18:33:05,062 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.9707 | Iter Mean Loss 33.2775
2020-11-05 18:33:05,064 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,072 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2227 | Iter Mean Loss 25.2227
2020-11-05 18:33:05,080 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.2930 | Iter Mean Loss 20.7579
2020-11-05 18:33:05,087 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.7405 | Iter Mean Loss 31.7521
2020-11-05 18:33:05,095 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.3152 | Iter Mean Loss 32.6429
2020-11-05 18:33:05,102 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.7399 | Iter Mean Loss 33.0623
2020-11-05 18:33:05,104 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,112 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0453 | Iter Mean Loss 25.0453
2020-11-05 18:33:05,120 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1273 | Iter Mean Loss 20.5863
2020-11-05 18:33:05,128 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.4327 | Iter Mean Loss 31.5351
2020-11-05 18:33:05,135 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0995 | Iter Mean Loss 32.4262
2020-11-05 18:33:05,143 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.5034 | Iter Mean Loss 32.8417
2020-11-05 18:33:05,145 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,153 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8616 | Iter Mean Loss 24.8616
2020-11-05 18:33:05,160 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9557 | Iter Mean Loss 20.4086
2020-11-05 18:33:05,168 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.1193 | Iter Mean Loss 31.3122
2020-11-05 18:33:05,175 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.8789 | Iter Mean Loss 32.2039
2020-11-05 18:33:05,182 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.2609 | Iter Mean Loss 32.6153
2020-11-05 18:33:05,184 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,192 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6712 | Iter Mean Loss 24.6712
2020-11-05 18:33:05,200 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.7779 | Iter Mean Loss 20.2245
2020-11-05 18:33:05,207 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.7999 | Iter Mean Loss 31.0830
2020-11-05 18:33:05,215 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.6530 | Iter Mean Loss 31.9755
2020-11-05 18:33:05,222 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 34.0120 | Iter Mean Loss 32.3828
2020-11-05 18:33:05,224 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,232 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4738 | Iter Mean Loss 24.4738
2020-11-05 18:33:05,240 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.5936 | Iter Mean Loss 20.0337
2020-11-05 18:33:05,247 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.4743 | Iter Mean Loss 30.8472
2020-11-05 18:33:05,255 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.4216 | Iter Mean Loss 31.7408
2020-11-05 18:33:05,262 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.7564 | Iter Mean Loss 32.1439
2020-11-05 18:33:05,264 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.2817 | MSE 0.4984
2020-11-05 18:33:05,272 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2691 | Iter Mean Loss 24.2691
2020-11-05 18:33:05,280 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4025 | Iter Mean Loss 19.8358
2020-11-05 18:33:05,287 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.1423 | Iter Mean Loss 30.6046
2020-11-05 18:33:05,294 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1844 | Iter Mean Loss 31.4996
2020-11-05 18:33:05,302 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.4938 | Iter Mean Loss 31.8984
2020-11-05 18:33:05,304 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,312 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0568 | Iter Mean Loss 24.0568
2020-11-05 18:33:05,321 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2046 | Iter Mean Loss 19.6307
2020-11-05 18:33:05,329 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.8035 | Iter Mean Loss 30.3549
2020-11-05 18:33:05,336 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.9413 | Iter Mean Loss 31.2515
2020-11-05 18:33:05,344 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 33.2241 | Iter Mean Loss 31.6460
2020-11-05 18:33:05,346 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,354 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8366 | Iter Mean Loss 23.8366
2020-11-05 18:33:05,361 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.9995 | Iter Mean Loss 19.4181
2020-11-05 18:33:05,369 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.4578 | Iter Mean Loss 30.0980
2020-11-05 18:33:05,376 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6920 | Iter Mean Loss 30.9965
2020-11-05 18:33:05,384 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9471 | Iter Mean Loss 31.3866
2020-11-05 18:33:05,386 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,393 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6084 | Iter Mean Loss 23.6084
2020-11-05 18:33:05,401 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7872 | Iter Mean Loss 19.1978
2020-11-05 18:33:05,408 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1051 | Iter Mean Loss 29.8336
2020-11-05 18:33:05,416 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4366 | Iter Mean Loss 30.7343
2020-11-05 18:33:05,423 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.6626 | Iter Mean Loss 31.1200
2020-11-05 18:33:05,425 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,433 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3720 | Iter Mean Loss 23.3720
2020-11-05 18:33:05,441 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5678 | Iter Mean Loss 18.9699
2020-11-05 18:33:05,448 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7455 | Iter Mean Loss 29.5618
2020-11-05 18:33:05,455 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1749 | Iter Mean Loss 30.4650
2020-11-05 18:33:05,463 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.3708 | Iter Mean Loss 30.8462
2020-11-05 18:33:05,465 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,472 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1274 | Iter Mean Loss 23.1274
2020-11-05 18:33:05,480 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.3412 | Iter Mean Loss 18.7343
2020-11-05 18:33:05,487 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3788 | Iter Mean Loss 29.2825
2020-11-05 18:33:05,495 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9071 | Iter Mean Loss 30.1886
2020-11-05 18:33:05,502 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.0718 | Iter Mean Loss 30.5653
2020-11-05 18:33:05,504 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,512 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8747 | Iter Mean Loss 22.8747
2020-11-05 18:33:05,519 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.1076 | Iter Mean Loss 18.4912
2020-11-05 18:33:05,527 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.0055 | Iter Mean Loss 28.9959
2020-11-05 18:33:05,534 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6333 | Iter Mean Loss 29.9053
2020-11-05 18:33:05,541 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.7657 | Iter Mean Loss 30.2774
2020-11-05 18:33:05,543 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,551 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6140 | Iter Mean Loss 22.6140
2020-11-05 18:33:05,558 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.8674 | Iter Mean Loss 18.2407
2020-11-05 18:33:05,566 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.6256 | Iter Mean Loss 28.7023
2020-11-05 18:33:05,573 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.3538 | Iter Mean Loss 29.6152
2020-11-05 18:33:05,580 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.4529 | Iter Mean Loss 29.9827
2020-11-05 18:33:05,582 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,590 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3457 | Iter Mean Loss 22.3457
2020-11-05 18:33:05,597 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.6209 | Iter Mean Loss 17.9833
2020-11-05 18:33:05,605 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.2396 | Iter Mean Loss 28.4020
2020-11-05 18:33:05,612 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.0689 | Iter Mean Loss 29.3188
2020-11-05 18:33:05,619 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 31.1339 | Iter Mean Loss 29.6818
2020-11-05 18:33:05,621 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.2817 | MSE 0.4983
2020-11-05 18:33:05,629 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0700 | Iter Mean Loss 22.0700
2020-11-05 18:33:05,636 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.3688 | Iter Mean Loss 17.7194
2020-11-05 18:33:05,643 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.8480 | Iter Mean Loss 28.0956
2020-11-05 18:33:05,651 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7791 | Iter Mean Loss 29.0165
2020-11-05 18:33:05,658 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 29.3751
2020-11-05 18:33:05,660 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:33:05,667 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7878 | Iter Mean Loss 21.7878
2020-11-05 18:33:05,675 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.1117 | Iter Mean Loss 17.4497
2020-11-05 18:33:05,682 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.4515 | Iter Mean Loss 27.7837
2020-11-05 18:33:05,689 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.4851 | Iter Mean Loss 28.7090
2020-11-05 18:33:05,696 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.4802 | Iter Mean Loss 29.0633
2020-11-05 18:33:05,698 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:33:05,706 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4996 | Iter Mean Loss 21.4996
2020-11-05 18:33:05,713 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.8505 | Iter Mean Loss 17.1750
2020-11-05 18:33:05,721 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.0509 | Iter Mean Loss 27.4670
2020-11-05 18:33:05,728 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.1877 | Iter Mean Loss 28.3972
2020-11-05 18:33:05,735 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 30.1473 | Iter Mean Loss 28.7472
2020-11-05 18:33:05,737 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:33:05,745 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2065 | Iter Mean Loss 21.2065
2020-11-05 18:33:05,753 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5862 | Iter Mean Loss 16.8963
2020-11-05 18:33:05,760 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.6471 | Iter Mean Loss 27.1466
2020-11-05 18:33:05,767 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8876 | Iter Mean Loss 28.0818
2020-11-05 18:33:05,775 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.8117 | Iter Mean Loss 28.4278
2020-11-05 18:33:05,777 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.2817 | MSE 0.4982
2020-11-05 18:33:05,784 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9094 | Iter Mean Loss 20.9094
2020-11-05 18:33:05,792 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.3201 | Iter Mean Loss 16.6147
2020-11-05 18:33:05,799 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.2411 | Iter Mean Loss 26.8235
2020-11-05 18:33:05,806 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5859 | Iter Mean Loss 27.7641
2020-11-05 18:33:05,813 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4748 | Iter Mean Loss 28.1063
2020-11-05 18:33:05,815 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.2817 | MSE 0.4981
2020-11-05 18:33:05,823 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6096 | Iter Mean Loss 20.6096
2020-11-05 18:33:05,830 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.0533 | Iter Mean Loss 16.3314
2020-11-05 18:33:05,838 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.8343 | Iter Mean Loss 26.4990
2020-11-05 18:33:05,845 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.2837 | Iter Mean Loss 27.4452
2020-11-05 18:33:05,852 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.1379 | Iter Mean Loss 27.7837
2020-11-05 18:33:05,854 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.2817 | MSE 0.4981
2020-11-05 18:33:05,862 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3084 | Iter Mean Loss 20.3084
2020-11-05 18:33:05,869 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7873 | Iter Mean Loss 16.0478
2020-11-05 18:33:05,876 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.4277 | Iter Mean Loss 26.1744
2020-11-05 18:33:05,883 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9821 | Iter Mean Loss 27.1264
2020-11-05 18:33:05,890 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.8025 | Iter Mean Loss 27.4616
2020-11-05 18:33:05,892 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.2817 | MSE 0.4980
2020-11-05 18:33:05,900 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0072 | Iter Mean Loss 20.0072
2020-11-05 18:33:05,907 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.5235 | Iter Mean Loss 15.7653
2020-11-05 18:33:05,914 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.0226 | Iter Mean Loss 25.8511
2020-11-05 18:33:05,921 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6824 | Iter Mean Loss 26.8089
2020-11-05 18:33:05,928 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.4702 | Iter Mean Loss 27.1412
2020-11-05 18:33:05,930 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.2817 | MSE 0.4980
2020-11-05 18:33:05,938 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7075 | Iter Mean Loss 19.7075
2020-11-05 18:33:05,945 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2634 | Iter Mean Loss 15.4854
2020-11-05 18:33:05,952 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.6204 | Iter Mean Loss 25.5304
2020-11-05 18:33:05,959 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.3856 | Iter Mean Loss 26.4942
2020-11-05 18:33:05,966 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 28.1424 | Iter Mean Loss 26.8239
2020-11-05 18:33:05,968 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.2817 | MSE 0.4979
2020-11-05 18:33:05,976 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4107 | Iter Mean Loss 19.4107
2020-11-05 18:33:05,983 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.0085 | Iter Mean Loss 15.2096
2020-11-05 18:33:05,990 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.2223 | Iter Mean Loss 25.2138
2020-11-05 18:33:05,997 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0930 | Iter Mean Loss 26.1836
2020-11-05 18:33:06,004 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.8205 | Iter Mean Loss 26.5110
2020-11-05 18:33:06,007 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.2817 | MSE 0.4978
2020-11-05 18:33:06,015 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1182 | Iter Mean Loss 19.1182
2020-11-05 18:33:06,022 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7601 | Iter Mean Loss 14.9391
2020-11-05 18:33:06,029 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.8294 | Iter Mean Loss 24.9026
2020-11-05 18:33:06,036 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8055 | Iter Mean Loss 25.8783
2020-11-05 18:33:06,043 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.5060 | Iter Mean Loss 26.2038
2020-11-05 18:33:06,045 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.2817 | MSE 0.4978
2020-11-05 18:33:06,053 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8312 | Iter Mean Loss 18.8312
2020-11-05 18:33:06,060 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5194 | Iter Mean Loss 14.6753
2020-11-05 18:33:06,067 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.4427 | Iter Mean Loss 24.5978
2020-11-05 18:33:06,074 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.5241 | Iter Mean Loss 25.5794
2020-11-05 18:33:06,081 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 27.1998 | Iter Mean Loss 25.9034
2020-11-05 18:33:06,083 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.2817 | MSE 0.4977
2020-11-05 18:33:06,091 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5509 | Iter Mean Loss 18.5509
2020-11-05 18:33:06,098 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.2874 | Iter Mean Loss 14.4192
2020-11-05 18:33:06,105 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0630 | Iter Mean Loss 24.3004
2020-11-05 18:33:06,112 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.2495 | Iter Mean Loss 25.2877
2020-11-05 18:33:06,119 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.9029 | Iter Mean Loss 25.6107
2020-11-05 18:33:06,121 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.2817 | MSE 0.4975
2020-11-05 18:33:06,129 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2782 | Iter Mean Loss 18.2782
2020-11-05 18:33:06,136 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0649 | Iter Mean Loss 14.1715
2020-11-05 18:33:06,143 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6909 | Iter Mean Loss 24.0113
2020-11-05 18:33:06,150 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9822 | Iter Mean Loss 25.0040
2020-11-05 18:33:06,157 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.6160 | Iter Mean Loss 25.3264
2020-11-05 18:33:06,159 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.2817 | MSE 0.4974
2020-11-05 18:33:06,167 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0136 | Iter Mean Loss 18.0136
2020-11-05 18:33:06,174 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8524 | Iter Mean Loss 13.9330
2020-11-05 18:33:06,181 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3267 | Iter Mean Loss 23.7309
2020-11-05 18:33:06,188 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7225 | Iter Mean Loss 24.7288
2020-11-05 18:33:06,195 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.3393 | Iter Mean Loss 25.0509
2020-11-05 18:33:06,197 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.2817 | MSE 0.4972
2020-11-05 18:33:06,204 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7576 | Iter Mean Loss 17.7576
2020-11-05 18:33:06,212 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6501 | Iter Mean Loss 13.7039
2020-11-05 18:33:06,219 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.9706 | Iter Mean Loss 23.4594
2020-11-05 18:33:06,226 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.4706 | Iter Mean Loss 24.4622
2020-11-05 18:33:06,233 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.0730 | Iter Mean Loss 24.7844
2020-11-05 18:33:06,235 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.2817 | MSE 0.4971
2020-11-05 18:33:06,243 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5104 | Iter Mean Loss 17.5104
2020-11-05 18:33:06,251 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4581 | Iter Mean Loss 13.4843
2020-11-05 18:33:06,258 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6225 | Iter Mean Loss 23.1970
2020-11-05 18:33:06,265 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.2264 | Iter Mean Loss 24.2044
2020-11-05 18:33:06,272 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.8169 | Iter Mean Loss 24.5269
2020-11-05 18:33:06,274 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.2817 | MSE 0.4969
2020-11-05 18:33:06,282 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2718 | Iter Mean Loss 17.2718
2020-11-05 18:33:06,289 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2762 | Iter Mean Loss 13.2740
2020-11-05 18:33:06,296 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.2822 | Iter Mean Loss 22.9434
2020-11-05 18:33:06,303 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9895 | Iter Mean Loss 23.9549
2020-11-05 18:33:06,310 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.5706 | Iter Mean Loss 24.2781
2020-11-05 18:33:06,312 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.2817 | MSE 0.4966
2020-11-05 18:33:06,321 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0416 | Iter Mean Loss 17.0416
2020-11-05 18:33:06,328 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.1037 | Iter Mean Loss 13.0727
2020-11-05 18:33:06,336 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.9491 | Iter Mean Loss 22.6982
2020-11-05 18:33:06,343 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7597 | Iter Mean Loss 23.7136
2020-11-05 18:33:06,350 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.3335 | Iter Mean Loss 24.0375
2020-11-05 18:33:06,352 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.2817 | MSE 0.4964
2020-11-05 18:33:06,359 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8193 | Iter Mean Loss 16.8193
2020-11-05 18:33:06,367 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.9402 | Iter Mean Loss 12.8798
2020-11-05 18:33:06,374 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.6228 | Iter Mean Loss 22.4608
2020-11-05 18:33:06,382 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.5364 | Iter Mean Loss 23.4797
2020-11-05 18:33:06,389 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 25.1048 | Iter Mean Loss 23.8047
2020-11-05 18:33:06,391 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.2817 | MSE 0.4961
2020-11-05 18:33:06,400 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6043 | Iter Mean Loss 16.6043
2020-11-05 18:33:06,408 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.7848 | Iter Mean Loss 12.6946
2020-11-05 18:33:06,418 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3025 | Iter Mean Loss 22.2305
2020-11-05 18:33:06,428 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.3189 | Iter Mean Loss 23.2526
2020-11-05 18:33:06,437 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.8837 | Iter Mean Loss 23.5788
2020-11-05 18:33:06,439 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.2817 | MSE 0.4958
2020-11-05 18:33:06,449 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3959 | Iter Mean Loss 16.3959
2020-11-05 18:33:06,458 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 12.5163
2020-11-05 18:33:06,466 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.9874 | Iter Mean Loss 22.0067
2020-11-05 18:33:06,473 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.1066 | Iter Mean Loss 23.0316
2020-11-05 18:33:06,482 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.6691 | Iter Mean Loss 23.3591
2020-11-05 18:33:06,484 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.2817 | MSE 0.4955
2020-11-05 18:33:06,495 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1933 | Iter Mean Loss 16.1933
2020-11-05 18:33:06,505 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 12.3441
2020-11-05 18:33:06,516 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.6769 | Iter Mean Loss 21.7883
2020-11-05 18:33:06,527 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8988 | Iter Mean Loss 22.8159
2020-11-05 18:33:06,537 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.4602 | Iter Mean Loss 23.1448
2020-11-05 18:33:06,540 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.2817 | MSE 0.4952
2020-11-05 18:33:06,552 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9957 | Iter Mean Loss 15.9957
2020-11-05 18:33:06,561 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3584 | Iter Mean Loss 12.1771
2020-11-05 18:33:06,571 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.3700 | Iter Mean Loss 21.5747
2020-11-05 18:33:06,583 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6948 | Iter Mean Loss 22.6047
2020-11-05 18:33:06,593 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.2559 | Iter Mean Loss 22.9350
2020-11-05 18:33:06,596 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.2817 | MSE 0.4948
2020-11-05 18:33:06,608 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8024 | Iter Mean Loss 15.8024
2020-11-05 18:33:06,619 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 12.0144
2020-11-05 18:33:06,629 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.0662 | Iter Mean Loss 21.3650
2020-11-05 18:33:06,637 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4940 | Iter Mean Loss 22.3973
2020-11-05 18:33:06,646 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 24.0553 | Iter Mean Loss 22.7289
2020-11-05 18:33:06,648 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.2817 | MSE 0.4944
2020-11-05 18:33:06,657 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6127 | Iter Mean Loss 15.6127
2020-11-05 18:33:06,665 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.0982 | Iter Mean Loss 11.8555
2020-11-05 18:33:06,673 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.7648 | Iter Mean Loss 21.1586
2020-11-05 18:33:06,681 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2957 | Iter Mean Loss 22.1929
2020-11-05 18:33:06,689 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.8577 | Iter Mean Loss 22.5259
2020-11-05 18:33:06,691 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.2817 | MSE 0.4940
2020-11-05 18:33:06,699 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4260 | Iter Mean Loss 15.4260
2020-11-05 18:33:06,708 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9730 | Iter Mean Loss 11.6995
2020-11-05 18:33:06,715 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.4652 | Iter Mean Loss 20.9547
2020-11-05 18:33:06,723 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0996 | Iter Mean Loss 21.9909
2020-11-05 18:33:06,731 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.6624 | Iter Mean Loss 22.3252
2020-11-05 18:33:06,733 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.2817 | MSE 0.4936
2020-11-05 18:33:06,741 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2417 | Iter Mean Loss 15.2417
2020-11-05 18:33:06,749 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.8501 | Iter Mean Loss 11.5459
2020-11-05 18:33:06,757 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.1670 | Iter Mean Loss 20.7529
2020-11-05 18:33:06,765 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.9051 | Iter Mean Loss 21.7910
2020-11-05 18:33:06,773 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.4687 | Iter Mean Loss 22.1265
2020-11-05 18:33:06,775 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.2817 | MSE 0.4932
2020-11-05 18:33:06,783 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0594 | Iter Mean Loss 15.0594
2020-11-05 18:33:06,791 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7290 | Iter Mean Loss 11.3942
2020-11-05 18:33:06,799 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.8697 | Iter Mean Loss 20.5527
2020-11-05 18:33:06,807 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7120 | Iter Mean Loss 21.5925
2020-11-05 18:33:06,815 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.2761 | Iter Mean Loss 21.9292
2020-11-05 18:33:06,817 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.2817 | MSE 0.4927
2020-11-05 18:33:06,826 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8789 | Iter Mean Loss 14.8789
2020-11-05 18:33:06,834 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 11.2441
2020-11-05 18:33:06,842 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.5732 | Iter Mean Loss 20.3538
2020-11-05 18:33:06,850 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5200 | Iter Mean Loss 21.3953
2020-11-05 18:33:06,858 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.0843 | Iter Mean Loss 21.7331
2020-11-05 18:33:06,860 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.2817 | MSE 0.4922
2020-11-05 18:33:06,869 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6999 | Iter Mean Loss 14.6999
2020-11-05 18:33:06,878 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4908 | Iter Mean Loss 11.0953
2020-11-05 18:33:06,886 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.2772 | Iter Mean Loss 20.1560
2020-11-05 18:33:06,894 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3290 | Iter Mean Loss 21.1992
2020-11-05 18:33:06,903 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.8930 | Iter Mean Loss 21.5380
2020-11-05 18:33:06,905 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.2817 | MSE 0.4917
2020-11-05 18:33:06,914 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5223 | Iter Mean Loss 14.5223
2020-11-05 18:33:06,923 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.3731 | Iter Mean Loss 10.9477
2020-11-05 18:33:06,931 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.9818 | Iter Mean Loss 19.9591
2020-11-05 18:33:06,938 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1389 | Iter Mean Loss 21.0040
2020-11-05 18:33:06,946 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.7019 | Iter Mean Loss 21.3436
2020-11-05 18:33:06,948 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.2817 | MSE 0.4912
2020-11-05 18:33:06,956 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3462 | Iter Mean Loss 14.3462
2020-11-05 18:33:06,964 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2563 | Iter Mean Loss 10.8012
2020-11-05 18:33:06,972 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.6868 | Iter Mean Loss 19.7631
2020-11-05 18:33:06,980 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9496 | Iter Mean Loss 20.8097
2020-11-05 18:33:06,988 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.5111 | Iter Mean Loss 21.1500
2020-11-05 18:33:06,990 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.2817 | MSE 0.4907
2020-11-05 18:33:06,999 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1715 | Iter Mean Loss 14.1715
2020-11-05 18:33:07,007 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1402 | Iter Mean Loss 10.6558
2020-11-05 18:33:07,016 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.3925 | Iter Mean Loss 19.5681
2020-11-05 18:33:07,025 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.7613 | Iter Mean Loss 20.6164
2020-11-05 18:33:07,035 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.3204 | Iter Mean Loss 20.9572
2020-11-05 18:33:07,037 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.2817 | MSE 0.4902
2020-11-05 18:33:07,046 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9984 | Iter Mean Loss 13.9984
2020-11-05 18:33:07,054 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.0249 | Iter Mean Loss 10.5117
2020-11-05 18:33:07,062 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.0988 | Iter Mean Loss 19.3741
2020-11-05 18:33:07,070 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5741 | Iter Mean Loss 20.4241
2020-11-05 18:33:07,079 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 22.1299 | Iter Mean Loss 20.7652
2020-11-05 18:33:07,082 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.2817 | MSE 0.4896
2020-11-05 18:33:07,091 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8272 | Iter Mean Loss 13.8272
2020-11-05 18:33:07,099 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9105 | Iter Mean Loss 10.3689
2020-11-05 18:33:07,108 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.8061 | Iter Mean Loss 19.1813
2020-11-05 18:33:07,115 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3881 | Iter Mean Loss 20.2330
2020-11-05 18:33:07,123 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.9397 | Iter Mean Loss 20.5743
2020-11-05 18:33:07,125 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.2817 | MSE 0.4890
2020-11-05 18:33:07,134 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6581 | Iter Mean Loss 13.6581
2020-11-05 18:33:07,142 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7971 | Iter Mean Loss 10.2276
2020-11-05 18:33:07,151 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.5145 | Iter Mean Loss 18.9899
2020-11-05 18:33:07,159 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2034 | Iter Mean Loss 20.0433
2020-11-05 18:33:07,167 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.7500 | Iter Mean Loss 20.3846
2020-11-05 18:33:07,169 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.2817 | MSE 0.4885
2020-11-05 18:33:07,178 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4913 | Iter Mean Loss 13.4913
2020-11-05 18:33:07,186 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6850 | Iter Mean Loss 10.0881
2020-11-05 18:33:07,194 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2243 | Iter Mean Loss 18.8002
2020-11-05 18:33:07,202 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0204 | Iter Mean Loss 19.8553
2020-11-05 18:33:07,210 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 20.1964
2020-11-05 18:33:07,212 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.2817 | MSE 0.4879
2020-11-05 18:33:07,220 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3273 | Iter Mean Loss 13.3273
2020-11-05 18:33:07,228 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.5742 | Iter Mean Loss 9.9508
2020-11-05 18:33:07,235 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9359 | Iter Mean Loss 18.6125
2020-11-05 18:33:07,243 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8393 | Iter Mean Loss 19.6692
2020-11-05 18:33:07,251 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.3726 | Iter Mean Loss 20.0099
2020-11-05 18:33:07,253 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.2817 | MSE 0.4873
2020-11-05 18:33:07,261 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1664 | Iter Mean Loss 13.1664
2020-11-05 18:33:07,269 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4650 | Iter Mean Loss 9.8157
2020-11-05 18:33:07,276 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.6495 | Iter Mean Loss 18.4270
2020-11-05 18:33:07,284 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6602 | Iter Mean Loss 19.4853
2020-11-05 18:33:07,291 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.1854 | Iter Mean Loss 19.8253
2020-11-05 18:33:07,293 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.2817 | MSE 0.4867
2020-11-05 18:33:07,302 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0090 | Iter Mean Loss 13.0090
2020-11-05 18:33:07,309 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3577 | Iter Mean Loss 9.6834
2020-11-05 18:33:07,318 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.3655 | Iter Mean Loss 18.2441
2020-11-05 18:33:07,327 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4836 | Iter Mean Loss 19.3040
2020-11-05 18:33:07,334 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.9996 | Iter Mean Loss 19.6431
2020-11-05 18:33:07,337 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.2817 | MSE 0.4860
2020-11-05 18:33:07,345 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8554 | Iter Mean Loss 12.8554
2020-11-05 18:33:07,353 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.2525 | Iter Mean Loss 9.5540
2020-11-05 18:33:07,360 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0843 | Iter Mean Loss 18.0641
2020-11-05 18:33:07,368 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3097 | Iter Mean Loss 19.1255
2020-11-05 18:33:07,375 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.8154 | Iter Mean Loss 19.4635
2020-11-05 18:33:07,377 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.2817 | MSE 0.4854
2020-11-05 18:33:07,385 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7061 | Iter Mean Loss 12.7061
2020-11-05 18:33:07,393 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 9.4279
2020-11-05 18:33:07,401 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.8062 | Iter Mean Loss 17.8873
2020-11-05 18:33:07,409 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1387 | Iter Mean Loss 18.9502
2020-11-05 18:33:07,417 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.6330 | Iter Mean Loss 19.2867
2020-11-05 18:33:07,419 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.2817 | MSE 0.4848
2020-11-05 18:33:07,427 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5615 | Iter Mean Loss 12.5615
2020-11-05 18:33:07,434 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.0494 | Iter Mean Loss 9.3055
2020-11-05 18:33:07,442 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5314 | Iter Mean Loss 17.7141
2020-11-05 18:33:07,449 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9709 | Iter Mean Loss 18.7783
2020-11-05 18:33:07,457 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.4529 | Iter Mean Loss 19.1132
2020-11-05 18:33:07,459 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.2817 | MSE 0.4841
2020-11-05 18:33:07,467 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4218 | Iter Mean Loss 12.4218
2020-11-05 18:33:07,474 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9520 | Iter Mean Loss 9.1869
2020-11-05 18:33:07,482 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.2604 | Iter Mean Loss 17.5448
2020-11-05 18:33:07,489 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8066 | Iter Mean Loss 18.6102
2020-11-05 18:33:07,496 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.2752 | Iter Mean Loss 18.9432
2020-11-05 18:33:07,498 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.2817 | MSE 0.4835
2020-11-05 18:33:07,506 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2876 | Iter Mean Loss 12.2876
2020-11-05 18:33:07,514 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8576 | Iter Mean Loss 9.0726
2020-11-05 18:33:07,522 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9935 | Iter Mean Loss 17.3795
2020-11-05 18:33:07,529 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6460 | Iter Mean Loss 18.4462
2020-11-05 18:33:07,538 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 20.1002 | Iter Mean Loss 18.7770
2020-11-05 18:33:07,541 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.2817 | MSE 0.4828
2020-11-05 18:33:07,549 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1589 | Iter Mean Loss 12.1589
2020-11-05 18:33:07,557 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.7664 | Iter Mean Loss 8.9627
2020-11-05 18:33:07,565 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7308 | Iter Mean Loss 17.2187
2020-11-05 18:33:07,573 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4892 | Iter Mean Loss 18.2863
2020-11-05 18:33:07,581 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.9281 | Iter Mean Loss 18.6147
2020-11-05 18:33:07,583 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.2817 | MSE 0.4821
2020-11-05 18:33:07,591 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0362 | Iter Mean Loss 12.0362
2020-11-05 18:33:07,599 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6785 | Iter Mean Loss 8.8574
2020-11-05 18:33:07,607 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4727 | Iter Mean Loss 17.0625
2020-11-05 18:33:07,614 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3365 | Iter Mean Loss 18.1310
2020-11-05 18:33:07,623 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.7593 | Iter Mean Loss 18.4567
2020-11-05 18:33:07,625 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.2817 | MSE 0.4815
2020-11-05 18:33:07,635 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9197 | Iter Mean Loss 11.9197
2020-11-05 18:33:07,647 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5942 | Iter Mean Loss 8.7570
2020-11-05 18:33:07,655 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2193 | Iter Mean Loss 16.9111
2020-11-05 18:33:07,663 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1879 | Iter Mean Loss 17.9803
2020-11-05 18:33:07,671 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5939 | Iter Mean Loss 18.3030
2020-11-05 18:33:07,673 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.2817 | MSE 0.4808
2020-11-05 18:33:07,682 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8095 | Iter Mean Loss 11.8095
2020-11-05 18:33:07,691 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5136 | Iter Mean Loss 8.6615
2020-11-05 18:33:07,701 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9707 | Iter Mean Loss 16.7646
2020-11-05 18:33:07,709 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0436 | Iter Mean Loss 17.8343
2020-11-05 18:33:07,717 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.4321 | Iter Mean Loss 18.1539
2020-11-05 18:33:07,719 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.2817 | MSE 0.4801
2020-11-05 18:33:07,728 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7057 | Iter Mean Loss 11.7057
2020-11-05 18:33:07,736 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4366 | Iter Mean Loss 8.5711
2020-11-05 18:33:07,744 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7271 | Iter Mean Loss 16.6231
2020-11-05 18:33:07,752 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9036 | Iter Mean Loss 17.6932
2020-11-05 18:33:07,760 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.2740 | Iter Mean Loss 18.0094
2020-11-05 18:33:07,762 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.2817 | MSE 0.4794
2020-11-05 18:33:07,771 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6085 | Iter Mean Loss 11.6085
2020-11-05 18:33:07,779 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.3634 | Iter Mean Loss 8.4859
2020-11-05 18:33:07,787 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4886 | Iter Mean Loss 16.4868
2020-11-05 18:33:07,795 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7679 | Iter Mean Loss 17.5571
2020-11-05 18:33:07,803 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.1197 | Iter Mean Loss 17.8696
2020-11-05 18:33:07,805 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.2817 | MSE 0.4786
2020-11-05 18:33:07,814 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5178 | Iter Mean Loss 11.5178
2020-11-05 18:33:07,823 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2939 | Iter Mean Loss 8.4058
2020-11-05 18:33:07,832 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2551 | Iter Mean Loss 16.3556
2020-11-05 18:33:07,841 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6366 | Iter Mean Loss 17.4258
2020-11-05 18:33:07,850 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.9694 | Iter Mean Loss 17.7345
2020-11-05 18:33:07,853 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.2817 | MSE 0.4779
2020-11-05 18:33:07,863 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4336 | Iter Mean Loss 11.4336
2020-11-05 18:33:07,872 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2283 | Iter Mean Loss 8.3309
2020-11-05 18:33:07,881 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0266 | Iter Mean Loss 16.2295
2020-11-05 18:33:07,890 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5095 | Iter Mean Loss 17.2995
2020-11-05 18:33:07,898 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.8231 | Iter Mean Loss 17.6042
2020-11-05 18:33:07,900 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.2817 | MSE 0.4772
2020-11-05 18:33:07,910 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3558 | Iter Mean Loss 11.3558
2020-11-05 18:33:07,919 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1663 | Iter Mean Loss 8.2611
2020-11-05 18:33:07,928 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8031 | Iter Mean Loss 16.1084
2020-11-05 18:33:07,936 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3867 | Iter Mean Loss 17.1780
2020-11-05 18:33:07,944 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.6807 | Iter Mean Loss 17.4785
2020-11-05 18:33:07,946 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.2817 | MSE 0.4764
2020-11-05 18:33:07,955 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2844 | Iter Mean Loss 11.2844
2020-11-05 18:33:07,963 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 8.1962
2020-11-05 18:33:07,971 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.5845 | Iter Mean Loss 15.9923
2020-11-05 18:33:07,980 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2679 | Iter Mean Loss 17.0612
2020-11-05 18:33:07,988 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.5423 | Iter Mean Loss 17.3574
2020-11-05 18:33:07,990 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.2817 | MSE 0.4757
2020-11-05 18:33:07,998 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2192 | Iter Mean Loss 11.2192
2020-11-05 18:33:08,007 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0534 | Iter Mean Loss 8.1363
2020-11-05 18:33:08,015 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3707 | Iter Mean Loss 15.8811
2020-11-05 18:33:08,024 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1531 | Iter Mean Loss 16.9491
2020-11-05 18:33:08,033 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.4078 | Iter Mean Loss 17.2409
2020-11-05 18:33:08,035 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.2817 | MSE 0.4749
2020-11-05 18:33:08,044 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1600 | Iter Mean Loss 11.1600
2020-11-05 18:33:08,053 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0022 | Iter Mean Loss 8.0811
2020-11-05 18:33:08,061 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1615 | Iter Mean Loss 15.7746
2020-11-05 18:33:08,069 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0422 | Iter Mean Loss 16.8415
2020-11-05 18:33:08,079 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.2772 | Iter Mean Loss 17.1286
2020-11-05 18:33:08,081 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.2817 | MSE 0.4741
2020-11-05 18:33:08,090 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1065 | Iter Mean Loss 11.1065
2020-11-05 18:33:08,099 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9544 | Iter Mean Loss 8.0304
2020-11-05 18:33:08,107 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.9567 | Iter Mean Loss 15.6725
2020-11-05 18:33:08,117 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9349 | Iter Mean Loss 16.7381
2020-11-05 18:33:08,126 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.1504 | Iter Mean Loss 17.0206
2020-11-05 18:33:08,128 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.2817 | MSE 0.4734
2020-11-05 18:33:08,137 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0586 | Iter Mean Loss 11.0586
2020-11-05 18:33:08,145 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.9098 | Iter Mean Loss 7.9842
2020-11-05 18:33:08,153 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7562 | Iter Mean Loss 15.5749
2020-11-05 18:33:08,160 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8310 | Iter Mean Loss 16.6389
2020-11-05 18:33:08,168 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 18.0272 | Iter Mean Loss 16.9166
2020-11-05 18:33:08,171 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.2817 | MSE 0.4726
2020-11-05 18:33:08,179 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0159 | Iter Mean Loss 11.0159
2020-11-05 18:33:08,188 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8683 | Iter Mean Loss 7.9421
2020-11-05 18:33:08,196 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5597 | Iter Mean Loss 15.4813
2020-11-05 18:33:08,204 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7305 | Iter Mean Loss 16.5436
2020-11-05 18:33:08,211 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9075 | Iter Mean Loss 16.8164
2020-11-05 18:33:08,214 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.2817 | MSE 0.4718
2020-11-05 18:33:08,223 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9782 | Iter Mean Loss 10.9782
2020-11-05 18:33:08,232 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8298 | Iter Mean Loss 7.9040
2020-11-05 18:33:08,240 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3670 | Iter Mean Loss 15.3917
2020-11-05 18:33:08,248 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6330 | Iter Mean Loss 16.4520
2020-11-05 18:33:08,256 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.7911 | Iter Mean Loss 16.7198
2020-11-05 18:33:08,258 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.2817 | MSE 0.4710
2020-11-05 18:33:08,268 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9452 | Iter Mean Loss 10.9452
2020-11-05 18:33:08,276 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7940 | Iter Mean Loss 7.8696
2020-11-05 18:33:08,286 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1779 | Iter Mean Loss 15.3057
2020-11-05 18:33:08,294 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5384 | Iter Mean Loss 16.3639
2020-11-05 18:33:08,303 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.6780 | Iter Mean Loss 16.6267
2020-11-05 18:33:08,305 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.2817 | MSE 0.4702
2020-11-05 18:33:08,316 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9165 | Iter Mean Loss 10.9165
2020-11-05 18:33:08,324 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7609 | Iter Mean Loss 7.8387
2020-11-05 18:33:08,333 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9922 | Iter Mean Loss 15.2232
2020-11-05 18:33:08,341 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4465 | Iter Mean Loss 16.2790
2020-11-05 18:33:08,348 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.5679 | Iter Mean Loss 16.5368
2020-11-05 18:33:08,351 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.2817 | MSE 0.4694
2020-11-05 18:33:08,359 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8920 | Iter Mean Loss 10.8920
2020-11-05 18:33:08,367 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7302 | Iter Mean Loss 7.8111
2020-11-05 18:33:08,375 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8097 | Iter Mean Loss 15.1440
2020-11-05 18:33:08,382 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3571 | Iter Mean Loss 16.1972
2020-11-05 18:33:08,390 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.4607 | Iter Mean Loss 16.4499
2020-11-05 18:33:08,392 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.2817 | MSE 0.4685
2020-11-05 18:33:08,400 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 18:33:08,408 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7018 | Iter Mean Loss 7.7865
2020-11-05 18:33:08,415 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6301 | Iter Mean Loss 15.0677
2020-11-05 18:33:08,423 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2699 | Iter Mean Loss 16.1183
2020-11-05 18:33:08,430 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.3562 | Iter Mean Loss 16.3659
2020-11-05 18:33:08,433 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.2817 | MSE 0.4677
2020-11-05 18:33:08,442 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8540 | Iter Mean Loss 10.8540
2020-11-05 18:33:08,450 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 7.7648
2020-11-05 18:33:08,458 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4533 | Iter Mean Loss 14.9943
2020-11-05 18:33:08,466 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1848 | Iter Mean Loss 16.0419
2020-11-05 18:33:08,474 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.2542 | Iter Mean Loss 16.2844
2020-11-05 18:33:08,476 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.2817 | MSE 0.4668
2020-11-05 18:33:08,485 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8400 | Iter Mean Loss 10.8400
2020-11-05 18:33:08,493 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6512 | Iter Mean Loss 7.7456
2020-11-05 18:33:08,501 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2789 | Iter Mean Loss 14.9234
2020-11-05 18:33:08,509 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1017 | Iter Mean Loss 15.9679
2020-11-05 18:33:08,517 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.1545 | Iter Mean Loss 16.2053
2020-11-05 18:33:08,520 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.2817 | MSE 0.4660
2020-11-05 18:33:08,529 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8289 | Iter Mean Loss 10.8289
2020-11-05 18:33:08,537 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6287 | Iter Mean Loss 7.7288
2020-11-05 18:33:08,546 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1069 | Iter Mean Loss 14.8548
2020-11-05 18:33:08,554 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0203 | Iter Mean Loss 15.8962
2020-11-05 18:33:08,561 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.0571 | Iter Mean Loss 16.1284
2020-11-05 18:33:08,564 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.2817 | MSE 0.4651
2020-11-05 18:33:08,572 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8205 | Iter Mean Loss 10.8205
2020-11-05 18:33:08,580 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6078 | Iter Mean Loss 7.7142
2020-11-05 18:33:08,588 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9371 | Iter Mean Loss 14.7885
2020-11-05 18:33:08,595 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9405 | Iter Mean Loss 15.8265
2020-11-05 18:33:08,603 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.9616 | Iter Mean Loss 16.0535
2020-11-05 18:33:08,605 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.2817 | MSE 0.4643
2020-11-05 18:33:08,614 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8146 | Iter Mean Loss 10.8146
2020-11-05 18:33:08,621 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5885 | Iter Mean Loss 7.7015
2020-11-05 18:33:08,629 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7693 | Iter Mean Loss 14.7241
2020-11-05 18:33:08,637 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8621 | Iter Mean Loss 15.7586
2020-11-05 18:33:08,645 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.8681 | Iter Mean Loss 15.9805
2020-11-05 18:33:08,648 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.2817 | MSE 0.4634
2020-11-05 18:33:08,656 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:33:08,665 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5705 | Iter Mean Loss 7.6907
2020-11-05 18:33:08,673 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6033 | Iter Mean Loss 14.6616
2020-11-05 18:33:08,682 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7850 | Iter Mean Loss 15.6924
2020-11-05 18:33:08,690 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.7762 | Iter Mean Loss 15.9092
2020-11-05 18:33:08,693 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.2817 | MSE 0.4625
2020-11-05 18:33:08,702 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8091 | Iter Mean Loss 10.8091
2020-11-05 18:33:08,710 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5538 | Iter Mean Loss 7.6815
2020-11-05 18:33:08,718 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4390 | Iter Mean Loss 14.6007
2020-11-05 18:33:08,727 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7092 | Iter Mean Loss 15.6278
2020-11-05 18:33:08,735 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6860 | Iter Mean Loss 15.8394
2020-11-05 18:33:08,738 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.2817 | MSE 0.4617
2020-11-05 18:33:08,747 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8092 | Iter Mean Loss 10.8092
2020-11-05 18:33:08,755 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5383 | Iter Mean Loss 7.6738
2020-11-05 18:33:08,763 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2763 | Iter Mean Loss 14.5413
2020-11-05 18:33:08,770 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6344 | Iter Mean Loss 15.5646
2020-11-05 18:33:08,778 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5972 | Iter Mean Loss 15.7711
2020-11-05 18:33:08,781 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.2817 | MSE 0.4608
2020-11-05 18:33:08,789 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:33:08,797 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5238 | Iter Mean Loss 7.6673
2020-11-05 18:33:08,805 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1151 | Iter Mean Loss 14.4833
2020-11-05 18:33:08,812 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5606 | Iter Mean Loss 15.5026
2020-11-05 18:33:08,820 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.5098 | Iter Mean Loss 15.7040
2020-11-05 18:33:08,822 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.2817 | MSE 0.4599
2020-11-05 18:33:08,830 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8140 | Iter Mean Loss 10.8140
2020-11-05 18:33:08,838 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 7.6621
2020-11-05 18:33:08,846 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9552 | Iter Mean Loss 14.4265
2020-11-05 18:33:08,854 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4877 | Iter Mean Loss 15.4418
2020-11-05 18:33:08,862 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.4236 | Iter Mean Loss 15.6382
2020-11-05 18:33:08,865 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.2817 | MSE 0.4590
2020-11-05 18:33:08,874 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8184 | Iter Mean Loss 10.8184
2020-11-05 18:33:08,883 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4975 | Iter Mean Loss 7.6580
2020-11-05 18:33:08,892 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7967 | Iter Mean Loss 14.3709
2020-11-05 18:33:08,900 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4156 | Iter Mean Loss 15.3820
2020-11-05 18:33:08,908 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.3386 | Iter Mean Loss 15.5734
2020-11-05 18:33:08,910 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.2817 | MSE 0.4581
2020-11-05 18:33:08,920 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8240 | Iter Mean Loss 10.8240
2020-11-05 18:33:08,928 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4856 | Iter Mean Loss 7.6548
2020-11-05 18:33:08,936 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6393 | Iter Mean Loss 14.3163
2020-11-05 18:33:08,944 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3442 | Iter Mean Loss 15.3233
2020-11-05 18:33:08,952 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.2546 | Iter Mean Loss 15.5095
2020-11-05 18:33:08,955 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.2817 | MSE 0.4572
2020-11-05 18:33:08,963 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8305 | Iter Mean Loss 10.8305
2020-11-05 18:33:08,971 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4743 | Iter Mean Loss 7.6524
2020-11-05 18:33:08,978 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4831 | Iter Mean Loss 14.2626
2020-11-05 18:33:08,986 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2736 | Iter Mean Loss 15.2654
2020-11-05 18:33:08,993 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.1716 | Iter Mean Loss 15.4466
2020-11-05 18:33:08,995 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.2817 | MSE 0.4563
2020-11-05 18:33:09,003 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8379 | Iter Mean Loss 10.8379
2020-11-05 18:33:09,012 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4637 | Iter Mean Loss 7.6508
2020-11-05 18:33:09,020 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3279 | Iter Mean Loss 14.2098
2020-11-05 18:33:09,027 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2035 | Iter Mean Loss 15.2083
2020-11-05 18:33:09,035 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0894 | Iter Mean Loss 15.3845
2020-11-05 18:33:09,037 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.2817 | MSE 0.4554
2020-11-05 18:33:09,045 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 10.8461
2020-11-05 18:33:09,054 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4536 | Iter Mean Loss 7.6499
2020-11-05 18:33:09,062 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1738 | Iter Mean Loss 14.1579
2020-11-05 18:33:09,070 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1341 | Iter Mean Loss 15.1519
2020-11-05 18:33:09,078 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.0081 | Iter Mean Loss 15.3232
2020-11-05 18:33:09,080 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.2817 | MSE 0.4544
2020-11-05 18:33:09,089 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8550 | Iter Mean Loss 10.8550
2020-11-05 18:33:09,098 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4440 | Iter Mean Loss 7.6495
2020-11-05 18:33:09,106 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0207 | Iter Mean Loss 14.1066
2020-11-05 18:33:09,114 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 15.0962
2020-11-05 18:33:09,122 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.9276 | Iter Mean Loss 15.2625
2020-11-05 18:33:09,125 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.2817 | MSE 0.4535
2020-11-05 18:33:09,133 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8645 | Iter Mean Loss 10.8645
2020-11-05 18:33:09,142 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4349 | Iter Mean Loss 7.6497
2020-11-05 18:33:09,150 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8685 | Iter Mean Loss 14.0560
2020-11-05 18:33:09,158 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9969 | Iter Mean Loss 15.0412
2020-11-05 18:33:09,166 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.8477 | Iter Mean Loss 15.2025
2020-11-05 18:33:09,168 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.2817 | MSE 0.4526
2020-11-05 18:33:09,176 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8745 | Iter Mean Loss 10.8745
2020-11-05 18:33:09,184 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4262 | Iter Mean Loss 7.6504
2020-11-05 18:33:09,191 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7173 | Iter Mean Loss 14.0060
2020-11-05 18:33:09,199 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9290 | Iter Mean Loss 14.9868
2020-11-05 18:33:09,206 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.7685 | Iter Mean Loss 15.1431
2020-11-05 18:33:09,208 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.2817 | MSE 0.4517
2020-11-05 18:33:09,216 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8849 | Iter Mean Loss 10.8849
2020-11-05 18:33:09,223 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 7.6514
2020-11-05 18:33:09,231 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5669 | Iter Mean Loss 13.9566
2020-11-05 18:33:09,238 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8617 | Iter Mean Loss 14.9329
2020-11-05 18:33:09,246 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6900 | Iter Mean Loss 15.0843
2020-11-05 18:33:09,248 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.2817 | MSE 0.4508
2020-11-05 18:33:09,257 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8957 | Iter Mean Loss 10.8957
2020-11-05 18:33:09,265 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4099 | Iter Mean Loss 7.6528
2020-11-05 18:33:09,273 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4174 | Iter Mean Loss 13.9077
2020-11-05 18:33:09,281 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7948 | Iter Mean Loss 14.8795
2020-11-05 18:33:09,289 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.6120 | Iter Mean Loss 15.0260
2020-11-05 18:33:09,292 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.2817 | MSE 0.4498
2020-11-05 18:33:09,300 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9069 | Iter Mean Loss 10.9069
2020-11-05 18:33:09,308 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4022 | Iter Mean Loss 7.6545
2020-11-05 18:33:09,317 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2688 | Iter Mean Loss 13.8593
2020-11-05 18:33:09,326 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7283 | Iter Mean Loss 14.8265
2020-11-05 18:33:09,334 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5345 | Iter Mean Loss 14.9681
2020-11-05 18:33:09,336 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.2817 | MSE 0.4489
2020-11-05 18:33:09,344 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9183 | Iter Mean Loss 10.9183
2020-11-05 18:33:09,353 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3948 | Iter Mean Loss 7.6565
2020-11-05 18:33:09,361 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1211 | Iter Mean Loss 13.8114
2020-11-05 18:33:09,368 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6622 | Iter Mean Loss 14.7741
2020-11-05 18:33:09,375 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.4576 | Iter Mean Loss 14.9108
2020-11-05 18:33:09,377 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.2817 | MSE 0.4480
2020-11-05 18:33:09,385 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9299 | Iter Mean Loss 10.9299
2020-11-05 18:33:09,393 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3876 | Iter Mean Loss 7.6587
2020-11-05 18:33:09,400 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9742 | Iter Mean Loss 13.7639
2020-11-05 18:33:09,407 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5966 | Iter Mean Loss 14.7221
2020-11-05 18:33:09,416 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3811 | Iter Mean Loss 14.8539
2020-11-05 18:33:09,418 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.2817 | MSE 0.4471
2020-11-05 18:33:09,429 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9416 | Iter Mean Loss 10.9416
2020-11-05 18:33:09,439 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3807 | Iter Mean Loss 7.6612
2020-11-05 18:33:09,447 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8281 | Iter Mean Loss 13.7168
2020-11-05 18:33:09,455 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5314 | Iter Mean Loss 14.6705
2020-11-05 18:33:09,465 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.3051 | Iter Mean Loss 14.7974
2020-11-05 18:33:09,468 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.2817 | MSE 0.4461
2020-11-05 18:33:09,479 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9536 | Iter Mean Loss 10.9536
2020-11-05 18:33:09,488 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3739 | Iter Mean Loss 7.6638
2020-11-05 18:33:09,496 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6829 | Iter Mean Loss 13.6701
2020-11-05 18:33:09,505 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4666 | Iter Mean Loss 14.6192
2020-11-05 18:33:09,514 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.2295 | Iter Mean Loss 14.7413
2020-11-05 18:33:09,516 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.2817 | MSE 0.4452
2020-11-05 18:33:09,525 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9656 | Iter Mean Loss 10.9656
2020-11-05 18:33:09,534 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3674 | Iter Mean Loss 7.6665
2020-11-05 18:33:09,542 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5385 | Iter Mean Loss 13.6238
2020-11-05 18:33:09,551 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4022 | Iter Mean Loss 14.5684
2020-11-05 18:33:09,560 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.1544 | Iter Mean Loss 14.6856
2020-11-05 18:33:09,564 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.2817 | MSE 0.4443
2020-11-05 18:33:09,572 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9776 | Iter Mean Loss 10.9776
2020-11-05 18:33:09,581 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3610 | Iter Mean Loss 7.6693
2020-11-05 18:33:09,589 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3949 | Iter Mean Loss 13.5779
2020-11-05 18:33:09,597 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3382 | Iter Mean Loss 14.5179
2020-11-05 18:33:09,604 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0796 | Iter Mean Loss 14.6303
2020-11-05 18:33:09,606 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.2817 | MSE 0.4433
2020-11-05 18:33:09,614 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9897 | Iter Mean Loss 10.9897
2020-11-05 18:33:09,621 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3548 | Iter Mean Loss 7.6723
2020-11-05 18:33:09,629 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2522 | Iter Mean Loss 13.5322
2020-11-05 18:33:09,636 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2746 | Iter Mean Loss 14.4678
2020-11-05 18:33:09,643 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.0053 | Iter Mean Loss 14.5753
2020-11-05 18:33:09,645 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.2817 | MSE 0.4424
2020-11-05 18:33:09,654 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0019 | Iter Mean Loss 11.0019
2020-11-05 18:33:09,662 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3487 | Iter Mean Loss 7.6753
2020-11-05 18:33:09,669 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1103 | Iter Mean Loss 13.4870
2020-11-05 18:33:09,677 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2114 | Iter Mean Loss 14.4181
2020-11-05 18:33:09,685 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.9313 | Iter Mean Loss 14.5207
2020-11-05 18:33:09,687 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.2817 | MSE 0.4415
2020-11-05 18:33:09,695 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 11.0139
2020-11-05 18:33:09,704 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3428 | Iter Mean Loss 7.6784
2020-11-05 18:33:09,711 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9693 | Iter Mean Loss 13.4420
2020-11-05 18:33:09,719 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1485 | Iter Mean Loss 14.3686
2020-11-05 18:33:09,727 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.8577 | Iter Mean Loss 14.4664
2020-11-05 18:33:09,729 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.2817 | MSE 0.4406
2020-11-05 18:33:09,738 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0260 | Iter Mean Loss 11.0260
2020-11-05 18:33:09,746 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3370 | Iter Mean Loss 7.6815
2020-11-05 18:33:09,754 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8291 | Iter Mean Loss 13.3974
2020-11-05 18:33:09,762 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0861 | Iter Mean Loss 14.3195
2020-11-05 18:33:09,769 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7844 | Iter Mean Loss 14.4125
2020-11-05 18:33:09,772 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.2817 | MSE 0.4396
2020-11-05 18:33:09,779 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0380 | Iter Mean Loss 11.0380
2020-11-05 18:33:09,787 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3312 | Iter Mean Loss 7.6846
2020-11-05 18:33:09,794 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6898 | Iter Mean Loss 13.3530
2020-11-05 18:33:09,802 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0241 | Iter Mean Loss 14.2708
2020-11-05 18:33:09,809 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.7115 | Iter Mean Loss 14.3589
2020-11-05 18:33:09,811 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.2817 | MSE 0.4387
2020-11-05 18:33:09,819 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0499 | Iter Mean Loss 11.0499
2020-11-05 18:33:09,827 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3256 | Iter Mean Loss 7.6878
2020-11-05 18:33:09,834 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5513 | Iter Mean Loss 13.3090
2020-11-05 18:33:09,841 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9624 | Iter Mean Loss 14.2223
2020-11-05 18:33:09,848 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.6390 | Iter Mean Loss 14.3057
2020-11-05 18:33:09,850 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.2817 | MSE 0.4378
2020-11-05 18:33:09,858 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0617 | Iter Mean Loss 11.0617
2020-11-05 18:33:09,866 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 7.6909
2020-11-05 18:33:09,873 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4137 | Iter Mean Loss 13.2652
2020-11-05 18:33:09,881 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9011 | Iter Mean Loss 14.1742
2020-11-05 18:33:09,889 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5668 | Iter Mean Loss 14.2527
2020-11-05 18:33:09,891 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.2817 | MSE 0.4369
2020-11-05 18:33:09,900 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0734 | Iter Mean Loss 11.0734
2020-11-05 18:33:09,908 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3147 | Iter Mean Loss 7.6941
2020-11-05 18:33:09,916 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2770 | Iter Mean Loss 13.2217
2020-11-05 18:33:09,924 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8403 | Iter Mean Loss 14.1263
2020-11-05 18:33:09,931 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4949 | Iter Mean Loss 14.2001
2020-11-05 18:33:09,934 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.2817 | MSE 0.4360
2020-11-05 18:33:09,942 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0850 | Iter Mean Loss 11.0850
2020-11-05 18:33:09,950 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3094 | Iter Mean Loss 7.6972
2020-11-05 18:33:09,959 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1411 | Iter Mean Loss 13.1785
2020-11-05 18:33:09,966 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7798 | Iter Mean Loss 14.0788
2020-11-05 18:33:09,974 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.4233 | Iter Mean Loss 14.1477
2020-11-05 18:33:09,976 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.2817 | MSE 0.4350
2020-11-05 18:33:09,984 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0964 | Iter Mean Loss 11.0964
2020-11-05 18:33:09,991 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3041 | Iter Mean Loss 7.7003
2020-11-05 18:33:09,998 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0062 | Iter Mean Loss 13.1356
2020-11-05 18:33:10,005 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7197 | Iter Mean Loss 14.0316
2020-11-05 18:33:10,013 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.3521 | Iter Mean Loss 14.0957
2020-11-05 18:33:10,015 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.2817 | MSE 0.4341
2020-11-05 18:33:10,023 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.1076
2020-11-05 18:33:10,031 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 7.7033
2020-11-05 18:33:10,038 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8721 | Iter Mean Loss 13.0929
2020-11-05 18:33:10,045 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6600 | Iter Mean Loss 13.9846
2020-11-05 18:33:10,052 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2812 | Iter Mean Loss 14.0440
2020-11-05 18:33:10,054 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.2817 | MSE 0.4332
2020-11-05 18:33:10,062 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1187 | Iter Mean Loss 11.1187
2020-11-05 18:33:10,070 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2938 | Iter Mean Loss 7.7063
2020-11-05 18:33:10,077 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7389 | Iter Mean Loss 13.0505
2020-11-05 18:33:10,085 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6006 | Iter Mean Loss 13.9380
2020-11-05 18:33:10,093 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.2106 | Iter Mean Loss 13.9925
2020-11-05 18:33:10,095 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.2817 | MSE 0.4323
2020-11-05 18:33:10,103 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1296 | Iter Mean Loss 11.1296
2020-11-05 18:33:10,111 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2888 | Iter Mean Loss 7.7092
2020-11-05 18:33:10,119 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6065 | Iter Mean Loss 13.0083
2020-11-05 18:33:10,127 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5417 | Iter Mean Loss 13.8917
2020-11-05 18:33:10,135 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.1404 | Iter Mean Loss 13.9414
2020-11-05 18:33:10,137 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.2817 | MSE 0.4314
2020-11-05 18:33:10,146 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1403 | Iter Mean Loss 11.1403
2020-11-05 18:33:10,154 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2838 | Iter Mean Loss 7.7120
2020-11-05 18:33:10,162 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4751 | Iter Mean Loss 12.9664
2020-11-05 18:33:10,169 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4831 | Iter Mean Loss 13.8456
2020-11-05 18:33:10,177 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0704 | Iter Mean Loss 13.8906
2020-11-05 18:33:10,179 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.2817 | MSE 0.4305
2020-11-05 18:33:10,187 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1508 | Iter Mean Loss 11.1508
2020-11-05 18:33:10,194 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 7.7148
2020-11-05 18:33:10,201 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3446 | Iter Mean Loss 12.9247
2020-11-05 18:33:10,208 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4250 | Iter Mean Loss 13.7998
2020-11-05 18:33:10,216 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.0008 | Iter Mean Loss 13.8400
2020-11-05 18:33:10,218 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.2817 | MSE 0.4296
2020-11-05 18:33:10,225 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1611 | Iter Mean Loss 11.1611
2020-11-05 18:33:10,233 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2739 | Iter Mean Loss 7.7175
2020-11-05 18:33:10,240 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2150 | Iter Mean Loss 12.8833
2020-11-05 18:33:10,247 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3672 | Iter Mean Loss 13.7543
2020-11-05 18:33:10,254 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.9315 | Iter Mean Loss 13.7897
2020-11-05 18:33:10,256 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.2817 | MSE 0.4287
2020-11-05 18:33:10,264 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1711 | Iter Mean Loss 11.1711
2020-11-05 18:33:10,271 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2691 | Iter Mean Loss 7.7201
2020-11-05 18:33:10,279 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0863 | Iter Mean Loss 12.8422
2020-11-05 18:33:10,286 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3098 | Iter Mean Loss 13.7091
2020-11-05 18:33:10,294 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.8625 | Iter Mean Loss 13.7398
2020-11-05 18:33:10,297 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.2817 | MSE 0.4278
2020-11-05 18:33:10,305 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1809 | Iter Mean Loss 11.1809
2020-11-05 18:33:10,313 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2643 | Iter Mean Loss 7.7226
2020-11-05 18:33:10,322 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9586 | Iter Mean Loss 12.8013
2020-11-05 18:33:10,329 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2528 | Iter Mean Loss 13.6641
2020-11-05 18:33:10,337 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.6901
2020-11-05 18:33:10,339 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.2817 | MSE 0.4270
2020-11-05 18:33:10,348 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1905 | Iter Mean Loss 11.1905
2020-11-05 18:33:10,355 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 7.7250
2020-11-05 18:33:10,363 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8317 | Iter Mean Loss 12.7606
2020-11-05 18:33:10,370 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1962 | Iter Mean Loss 13.6195
2020-11-05 18:33:10,378 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7255 | Iter Mean Loss 13.6407
2020-11-05 18:33:10,380 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.2817 | MSE 0.4261
2020-11-05 18:33:10,388 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1998 | Iter Mean Loss 11.1998
2020-11-05 18:33:10,395 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 7.7273
2020-11-05 18:33:10,403 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7058 | Iter Mean Loss 12.7201
2020-11-05 18:33:10,410 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1399 | Iter Mean Loss 13.5751
2020-11-05 18:33:10,417 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.6575 | Iter Mean Loss 13.5916
2020-11-05 18:33:10,419 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.2817 | MSE 0.4252
2020-11-05 18:33:10,426 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2088 | Iter Mean Loss 11.2088
2020-11-05 18:33:10,434 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2502 | Iter Mean Loss 7.7295
2020-11-05 18:33:10,441 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5808 | Iter Mean Loss 12.6799
2020-11-05 18:33:10,448 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0841 | Iter Mean Loss 13.5310
2020-11-05 18:33:10,455 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5898 | Iter Mean Loss 13.5427
2020-11-05 18:33:10,457 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.2817 | MSE 0.4243
2020-11-05 18:33:10,465 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2176 | Iter Mean Loss 11.2176
2020-11-05 18:33:10,473 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2456 | Iter Mean Loss 7.7316
2020-11-05 18:33:10,481 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4567 | Iter Mean Loss 12.6400
2020-11-05 18:33:10,488 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0286 | Iter Mean Loss 13.4871
2020-11-05 18:33:10,496 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.5224 | Iter Mean Loss 13.4942
2020-11-05 18:33:10,498 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.2817 | MSE 0.4235
2020-11-05 18:33:10,507 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2261 | Iter Mean Loss 11.2261
2020-11-05 18:33:10,516 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2410 | Iter Mean Loss 7.7336
2020-11-05 18:33:10,527 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3335 | Iter Mean Loss 12.6002
2020-11-05 18:33:10,536 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9735 | Iter Mean Loss 13.4435
2020-11-05 18:33:10,544 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.4554 | Iter Mean Loss 13.4459
2020-11-05 18:33:10,547 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.2817 | MSE 0.4226
2020-11-05 18:33:10,556 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2343 | Iter Mean Loss 11.2343
2020-11-05 18:33:10,564 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 7.7354
2020-11-05 18:33:10,574 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2113 | Iter Mean Loss 12.5607
2020-11-05 18:33:10,582 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9187 | Iter Mean Loss 13.4002
2020-11-05 18:33:10,591 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3886 | Iter Mean Loss 13.3979
2020-11-05 18:33:10,593 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.2817 | MSE 0.4217
2020-11-05 18:33:10,602 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2423 | Iter Mean Loss 11.2423
2020-11-05 18:33:10,610 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2319 | Iter Mean Loss 7.7371
2020-11-05 18:33:10,618 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0900 | Iter Mean Loss 12.5214
2020-11-05 18:33:10,625 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8644 | Iter Mean Loss 13.3571
2020-11-05 18:33:10,633 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.3222 | Iter Mean Loss 13.3502
2020-11-05 18:33:10,635 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.2817 | MSE 0.4209
2020-11-05 18:33:10,644 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2499 | Iter Mean Loss 11.2499
2020-11-05 18:33:10,652 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2274 | Iter Mean Loss 7.7387
2020-11-05 18:33:10,660 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9697 | Iter Mean Loss 12.4823
2020-11-05 18:33:10,668 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8104 | Iter Mean Loss 13.3143
2020-11-05 18:33:10,676 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.2561 | Iter Mean Loss 13.3027
2020-11-05 18:33:10,679 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.2817 | MSE 0.4200
2020-11-05 18:33:10,688 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2573 | Iter Mean Loss 11.2573
2020-11-05 18:33:10,697 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2229 | Iter Mean Loss 7.7401
2020-11-05 18:33:10,705 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8502 | Iter Mean Loss 12.4435
2020-11-05 18:33:10,713 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7568 | Iter Mean Loss 13.2718
2020-11-05 18:33:10,722 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1904 | Iter Mean Loss 13.2555
2020-11-05 18:33:10,724 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.2817 | MSE 0.4192
2020-11-05 18:33:10,733 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2643 | Iter Mean Loss 11.2643
2020-11-05 18:33:10,741 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2185 | Iter Mean Loss 7.7414
2020-11-05 18:33:10,750 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7318 | Iter Mean Loss 12.4049
2020-11-05 18:33:10,758 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7035 | Iter Mean Loss 13.2295
2020-11-05 18:33:10,766 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.1250 | Iter Mean Loss 13.2086
2020-11-05 18:33:10,768 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.2817 | MSE 0.4184
2020-11-05 18:33:10,777 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2711 | Iter Mean Loss 11.2711
2020-11-05 18:33:10,786 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2141 | Iter Mean Loss 7.7426
2020-11-05 18:33:10,794 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6142 | Iter Mean Loss 12.3665
2020-11-05 18:33:10,802 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6507 | Iter Mean Loss 13.1875
2020-11-05 18:33:10,810 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.0599 | Iter Mean Loss 13.1620
2020-11-05 18:33:10,812 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.2817 | MSE 0.4175
2020-11-05 18:33:10,820 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2775 | Iter Mean Loss 11.2775
2020-11-05 18:33:10,828 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2097 | Iter Mean Loss 7.7436
2020-11-05 18:33:10,836 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4976 | Iter Mean Loss 12.3283
2020-11-05 18:33:10,843 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5982 | Iter Mean Loss 13.1457
2020-11-05 18:33:10,851 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9951 | Iter Mean Loss 13.1156
2020-11-05 18:33:10,853 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.2817 | MSE 0.4167
2020-11-05 18:33:10,861 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2837 | Iter Mean Loss 11.2837
2020-11-05 18:33:10,869 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2053 | Iter Mean Loss 7.7445
2020-11-05 18:33:10,877 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3819 | Iter Mean Loss 12.2903
2020-11-05 18:33:10,885 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5460 | Iter Mean Loss 13.1042
2020-11-05 18:33:10,893 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9307 | Iter Mean Loss 13.0695
2020-11-05 18:33:10,896 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.2817 | MSE 0.4159
2020-11-05 18:33:10,905 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2895 | Iter Mean Loss 11.2895
2020-11-05 18:33:10,914 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2009 | Iter Mean Loss 7.7452
2020-11-05 18:33:10,922 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2671 | Iter Mean Loss 12.2525
2020-11-05 18:33:10,931 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4942 | Iter Mean Loss 13.0629
2020-11-05 18:33:10,939 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8666 | Iter Mean Loss 13.0237
2020-11-05 18:33:10,941 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.2817 | MSE 0.4150
2020-11-05 18:33:10,950 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2950 | Iter Mean Loss 11.2950
2020-11-05 18:33:10,958 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1966 | Iter Mean Loss 7.7458
2020-11-05 18:33:10,966 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1533 | Iter Mean Loss 12.2150
2020-11-05 18:33:10,974 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4428 | Iter Mean Loss 13.0219
2020-11-05 18:33:10,982 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.8028 | Iter Mean Loss 12.9781
2020-11-05 18:33:10,985 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.2817 | MSE 0.4142
2020-11-05 18:33:10,994 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3002 | Iter Mean Loss 11.3002
2020-11-05 18:33:11,002 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1923 | Iter Mean Loss 7.7462
2020-11-05 18:33:11,010 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0404 | Iter Mean Loss 12.1776
2020-11-05 18:33:11,018 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3918 | Iter Mean Loss 12.9811
2020-11-05 18:33:11,025 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.7394 | Iter Mean Loss 12.9328
2020-11-05 18:33:11,027 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.2817 | MSE 0.4134
2020-11-05 18:33:11,035 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3050 | Iter Mean Loss 11.3050
2020-11-05 18:33:11,043 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1880 | Iter Mean Loss 7.7465
2020-11-05 18:33:11,050 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9284 | Iter Mean Loss 12.1405
2020-11-05 18:33:11,058 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3411 | Iter Mean Loss 12.9406
2020-11-05 18:33:11,065 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6763 | Iter Mean Loss 12.8878
2020-11-05 18:33:11,067 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.2817 | MSE 0.4126
2020-11-05 18:33:11,076 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3096 | Iter Mean Loss 11.3096
2020-11-05 18:33:11,085 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 7.7466
2020-11-05 18:33:11,093 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8174 | Iter Mean Loss 12.1035
2020-11-05 18:33:11,101 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2907 | Iter Mean Loss 12.9003
2020-11-05 18:33:11,110 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.6136 | Iter Mean Loss 12.8430
2020-11-05 18:33:11,112 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.2817 | MSE 0.4118
2020-11-05 18:33:11,121 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3138 | Iter Mean Loss 11.3138
2020-11-05 18:33:11,130 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1794 | Iter Mean Loss 7.7466
2020-11-05 18:33:11,138 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7072 | Iter Mean Loss 12.0668
2020-11-05 18:33:11,146 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2407 | Iter Mean Loss 12.8603
2020-11-05 18:33:11,155 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.5512 | Iter Mean Loss 12.7985
2020-11-05 18:33:11,157 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.2817 | MSE 0.4110
2020-11-05 18:33:11,166 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3177 | Iter Mean Loss 11.3177
2020-11-05 18:33:11,175 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1751 | Iter Mean Loss 7.7464
2020-11-05 18:33:11,183 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5980 | Iter Mean Loss 12.0303
2020-11-05 18:33:11,191 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1911 | Iter Mean Loss 12.8205
2020-11-05 18:33:11,199 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4891 | Iter Mean Loss 12.7542
2020-11-05 18:33:11,201 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.2817 | MSE 0.4102
2020-11-05 18:33:11,209 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3212 | Iter Mean Loss 11.3212
2020-11-05 18:33:11,218 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1709 | Iter Mean Loss 7.7460
2020-11-05 18:33:11,226 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4897 | Iter Mean Loss 11.9939
2020-11-05 18:33:11,233 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1418 | Iter Mean Loss 12.7809
2020-11-05 18:33:11,241 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.4274 | Iter Mean Loss 12.7102
2020-11-05 18:33:11,243 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.2817 | MSE 0.4095
2020-11-05 18:33:11,252 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3244 | Iter Mean Loss 11.3244
2020-11-05 18:33:11,259 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1666 | Iter Mean Loss 7.7455
2020-11-05 18:33:11,267 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3824 | Iter Mean Loss 11.9578
2020-11-05 18:33:11,275 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0928 | Iter Mean Loss 12.7416
2020-11-05 18:33:11,283 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3661 | Iter Mean Loss 12.6665
2020-11-05 18:33:11,285 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.2817 | MSE 0.4087
2020-11-05 18:33:11,294 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3273 | Iter Mean Loss 11.3273
2020-11-05 18:33:11,302 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1624 | Iter Mean Loss 7.7449
2020-11-05 18:33:11,310 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2759 | Iter Mean Loss 11.9219
2020-11-05 18:33:11,319 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0442 | Iter Mean Loss 12.7025
2020-11-05 18:33:11,329 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3051 | Iter Mean Loss 12.6230
2020-11-05 18:33:11,331 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.2817 | MSE 0.4079
2020-11-05 18:33:11,340 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3299 | Iter Mean Loss 11.3299
2020-11-05 18:33:11,348 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1582 | Iter Mean Loss 7.7440
2020-11-05 18:33:11,356 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1703 | Iter Mean Loss 11.8861
2020-11-05 18:33:11,365 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9960 | Iter Mean Loss 12.6636
2020-11-05 18:33:11,373 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.2444 | Iter Mean Loss 12.5798
2020-11-05 18:33:11,376 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.2817 | MSE 0.4072
2020-11-05 18:33:11,385 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3321 | Iter Mean Loss 11.3321
2020-11-05 18:33:11,393 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1540 | Iter Mean Loss 7.7431
2020-11-05 18:33:11,401 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0657 | Iter Mean Loss 11.8506
2020-11-05 18:33:11,409 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9480 | Iter Mean Loss 12.6250
2020-11-05 18:33:11,416 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1841 | Iter Mean Loss 12.5368
2020-11-05 18:33:11,418 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.2817 | MSE 0.4064
2020-11-05 18:33:11,426 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3340 | Iter Mean Loss 11.3340
2020-11-05 18:33:11,434 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1498 | Iter Mean Loss 7.7419
2020-11-05 18:33:11,442 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9620 | Iter Mean Loss 11.8153
2020-11-05 18:33:11,449 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9004 | Iter Mean Loss 12.5866
2020-11-05 18:33:11,457 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.1242 | Iter Mean Loss 12.4941
2020-11-05 18:33:11,459 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.2817 | MSE 0.4056
2020-11-05 18:33:11,467 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3356 | Iter Mean Loss 11.3356
2020-11-05 18:33:11,475 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1456 | Iter Mean Loss 7.7406
2020-11-05 18:33:11,482 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8591 | Iter Mean Loss 11.7801
2020-11-05 18:33:11,490 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8532 | Iter Mean Loss 12.5484
2020-11-05 18:33:11,498 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0646 | Iter Mean Loss 12.4516
2020-11-05 18:33:11,500 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.2817 | MSE 0.4049
2020-11-05 18:33:11,508 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3368 | Iter Mean Loss 11.3368
2020-11-05 18:33:11,516 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1414 | Iter Mean Loss 7.7391
2020-11-05 18:33:11,524 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7571 | Iter Mean Loss 11.7451
2020-11-05 18:33:11,532 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8063 | Iter Mean Loss 12.5104
2020-11-05 18:33:11,541 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.0053 | Iter Mean Loss 12.4094
2020-11-05 18:33:11,543 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.2817 | MSE 0.4042
2020-11-05 18:33:11,552 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3378 | Iter Mean Loss 11.3378
2020-11-05 18:33:11,560 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1372 | Iter Mean Loss 7.7375
2020-11-05 18:33:11,568 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6561 | Iter Mean Loss 11.7103
2020-11-05 18:33:11,576 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7597 | Iter Mean Loss 12.4727
2020-11-05 18:33:11,584 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.9465 | Iter Mean Loss 12.3674
2020-11-05 18:33:11,587 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.2817 | MSE 0.4034
2020-11-05 18:33:11,595 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3383 | Iter Mean Loss 11.3383
2020-11-05 18:33:11,604 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1330 | Iter Mean Loss 7.7357
2020-11-05 18:33:11,612 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5559 | Iter Mean Loss 11.6757
2020-11-05 18:33:11,619 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7135 | Iter Mean Loss 12.4352
2020-11-05 18:33:11,626 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8880 | Iter Mean Loss 12.3257
2020-11-05 18:33:11,628 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.2817 | MSE 0.4027
2020-11-05 18:33:11,637 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3386 | Iter Mean Loss 11.3386
2020-11-05 18:33:11,644 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 7.7337
2020-11-05 18:33:11,652 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4566 | Iter Mean Loss 11.6413
2020-11-05 18:33:11,659 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6676 | Iter Mean Loss 12.3979
2020-11-05 18:33:11,667 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.8298 | Iter Mean Loss 12.2843
2020-11-05 18:33:11,669 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.2817 | MSE 0.4020
2020-11-05 18:33:11,677 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3385 | Iter Mean Loss 11.3385
2020-11-05 18:33:11,685 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1246 | Iter Mean Loss 7.7316
2020-11-05 18:33:11,692 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3582 | Iter Mean Loss 11.6071
2020-11-05 18:33:11,700 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6220 | Iter Mean Loss 12.3608
2020-11-05 18:33:11,708 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7720 | Iter Mean Loss 12.2431
2020-11-05 18:33:11,710 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.2817 | MSE 0.4012
2020-11-05 18:33:11,719 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3381 | Iter Mean Loss 11.3381
2020-11-05 18:33:11,727 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1204 | Iter Mean Loss 7.7293
2020-11-05 18:33:11,735 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2606 | Iter Mean Loss 11.5731
2020-11-05 18:33:11,743 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5767 | Iter Mean Loss 12.3240
2020-11-05 18:33:11,751 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7146 | Iter Mean Loss 12.2021
2020-11-05 18:33:11,753 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.2817 | MSE 0.4005
2020-11-05 18:33:11,762 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3374 | Iter Mean Loss 11.3374
2020-11-05 18:33:11,770 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1163 | Iter Mean Loss 7.7268
2020-11-05 18:33:11,778 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1639 | Iter Mean Loss 11.5392
2020-11-05 18:33:11,786 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5317 | Iter Mean Loss 12.2873
2020-11-05 18:33:11,794 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6576 | Iter Mean Loss 12.1614
2020-11-05 18:33:11,796 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.2817 | MSE 0.3998
2020-11-05 18:33:11,804 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3364 | Iter Mean Loss 11.3364
2020-11-05 18:33:11,813 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1121 | Iter Mean Loss 7.7242
2020-11-05 18:33:11,820 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0681 | Iter Mean Loss 11.5055
2020-11-05 18:33:11,827 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4871 | Iter Mean Loss 12.2509
2020-11-05 18:33:11,835 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.6009 | Iter Mean Loss 12.1209
2020-11-05 18:33:11,837 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.2817 | MSE 0.3991
2020-11-05 18:33:11,845 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3350 | Iter Mean Loss 11.3350
2020-11-05 18:33:11,852 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1079 | Iter Mean Loss 7.7215
2020-11-05 18:33:11,860 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9731 | Iter Mean Loss 11.4720
2020-11-05 18:33:11,867 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4428 | Iter Mean Loss 12.2147
2020-11-05 18:33:11,874 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.5446 | Iter Mean Loss 12.0807
2020-11-05 18:33:11,876 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.2817 | MSE 0.3984
2020-11-05 18:33:11,885 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3334 | Iter Mean Loss 11.3334
2020-11-05 18:33:11,892 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1037 | Iter Mean Loss 7.7185
2020-11-05 18:33:11,900 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8790 | Iter Mean Loss 11.4387
2020-11-05 18:33:11,908 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3988 | Iter Mean Loss 12.1787
2020-11-05 18:33:11,915 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4887 | Iter Mean Loss 12.0407
2020-11-05 18:33:11,917 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.2817 | MSE 0.3977
2020-11-05 18:33:11,926 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3314 | Iter Mean Loss 11.3314
2020-11-05 18:33:11,934 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0995 | Iter Mean Loss 7.7154
2020-11-05 18:33:11,942 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7857 | Iter Mean Loss 11.4055
2020-11-05 18:33:11,950 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3551 | Iter Mean Loss 12.1429
2020-11-05 18:33:11,958 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.4331 | Iter Mean Loss 12.0010
2020-11-05 18:33:11,960 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.2817 | MSE 0.3970
2020-11-05 18:33:11,968 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3290 | Iter Mean Loss 11.3290
2020-11-05 18:33:11,977 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0953 | Iter Mean Loss 7.7122
2020-11-05 18:33:11,984 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6933 | Iter Mean Loss 11.3726
2020-11-05 18:33:11,992 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3118 | Iter Mean Loss 12.1074
2020-11-05 18:33:12,000 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3779 | Iter Mean Loss 11.9615
2020-11-05 18:33:12,002 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.2817 | MSE 0.3963
2020-11-05 18:33:12,011 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3264 | Iter Mean Loss 11.3264
2020-11-05 18:33:12,018 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0911 | Iter Mean Loss 7.7088
2020-11-05 18:33:12,026 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6017 | Iter Mean Loss 11.3397
2020-11-05 18:33:12,033 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2687 | Iter Mean Loss 12.0720
2020-11-05 18:33:12,040 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.3231 | Iter Mean Loss 11.9222
2020-11-05 18:33:12,042 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.2817 | MSE 0.3956
2020-11-05 18:33:12,050 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3235 | Iter Mean Loss 11.3235
2020-11-05 18:33:12,058 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0869 | Iter Mean Loss 7.7052
2020-11-05 18:33:12,066 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5109 | Iter Mean Loss 11.3071
2020-11-05 18:33:12,073 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2260 | Iter Mean Loss 12.0368
2020-11-05 18:33:12,080 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2687 | Iter Mean Loss 11.8832
2020-11-05 18:33:12,082 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.2817 | MSE 0.3950
2020-11-05 18:33:12,090 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3203 | Iter Mean Loss 11.3203
2020-11-05 18:33:12,098 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0827 | Iter Mean Loss 7.7015
2020-11-05 18:33:12,105 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4210 | Iter Mean Loss 11.2746
2020-11-05 18:33:12,113 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1835 | Iter Mean Loss 12.0019
2020-11-05 18:33:12,121 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2146 | Iter Mean Loss 11.8444
2020-11-05 18:33:12,123 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.2817 | MSE 0.3943
2020-11-05 18:33:12,131 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3167 | Iter Mean Loss 11.3167
2020-11-05 18:33:12,139 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0785 | Iter Mean Loss 7.6976
2020-11-05 18:33:12,147 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3319 | Iter Mean Loss 11.2424
2020-11-05 18:33:12,155 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1414 | Iter Mean Loss 11.9671
2020-11-05 18:33:12,163 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1609 | Iter Mean Loss 11.8059
2020-11-05 18:33:12,165 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.2817 | MSE 0.3936
2020-11-05 18:33:12,173 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3129 | Iter Mean Loss 11.3129
2020-11-05 18:33:12,182 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0743 | Iter Mean Loss 7.6936
2020-11-05 18:33:12,189 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.2102
2020-11-05 18:33:12,197 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0995 | Iter Mean Loss 11.9325
2020-11-05 18:33:12,205 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.1076 | Iter Mean Loss 11.7676
2020-11-05 18:33:12,207 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.2817 | MSE 0.3930
2020-11-05 18:33:12,216 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3087 | Iter Mean Loss 11.3087
2020-11-05 18:33:12,223 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0700 | Iter Mean Loss 7.6894
2020-11-05 18:33:12,231 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1560 | Iter Mean Loss 11.1783
2020-11-05 18:33:12,238 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0579 | Iter Mean Loss 11.8982
2020-11-05 18:33:12,245 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0547 | Iter Mean Loss 11.7295
2020-11-05 18:33:12,247 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.2817 | MSE 0.3923
2020-11-05 18:33:12,255 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 11.3043
2020-11-05 18:33:12,262 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 7.6850
2020-11-05 18:33:12,270 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0693 | Iter Mean Loss 11.1465
2020-11-05 18:33:12,277 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0167 | Iter Mean Loss 11.8640
2020-11-05 18:33:12,284 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.0022 | Iter Mean Loss 11.6917
2020-11-05 18:33:12,286 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.2817 | MSE 0.3917
2020-11-05 18:33:12,294 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2995 | Iter Mean Loss 11.2995
2020-11-05 18:33:12,301 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0615 | Iter Mean Loss 7.6805
2020-11-05 18:33:12,309 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9834 | Iter Mean Loss 11.1148
2020-11-05 18:33:12,317 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9757 | Iter Mean Loss 11.8301
2020-11-05 18:33:12,325 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.9500 | Iter Mean Loss 11.6540
2020-11-05 18:33:12,328 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.2817 | MSE 0.3910
2020-11-05 18:33:12,336 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 11.2945
2020-11-05 18:33:12,344 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0573 | Iter Mean Loss 7.6759
2020-11-05 18:33:12,352 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8983 | Iter Mean Loss 11.0834
2020-11-05 18:33:12,360 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9350 | Iter Mean Loss 11.7963
2020-11-05 18:33:12,368 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8983 | Iter Mean Loss 11.6167
2020-11-05 18:33:12,370 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.2817 | MSE 0.3904
2020-11-05 18:33:12,378 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2892 | Iter Mean Loss 11.2892
2020-11-05 18:33:12,386 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0530 | Iter Mean Loss 7.6711
2020-11-05 18:33:12,394 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8140 | Iter Mean Loss 11.0521
2020-11-05 18:33:12,402 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8946 | Iter Mean Loss 11.7627
2020-11-05 18:33:12,410 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8469 | Iter Mean Loss 11.5795
2020-11-05 18:33:12,412 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.2817 | MSE 0.3898
2020-11-05 18:33:12,420 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2836 | Iter Mean Loss 11.2836
2020-11-05 18:33:12,428 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0487 | Iter Mean Loss 7.6661
2020-11-05 18:33:12,435 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7304 | Iter Mean Loss 11.0209
2020-11-05 18:33:12,442 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8545 | Iter Mean Loss 11.7293
2020-11-05 18:33:12,449 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7959 | Iter Mean Loss 11.5426
2020-11-05 18:33:12,451 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.2817 | MSE 0.3891
2020-11-05 18:33:12,459 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2777 | Iter Mean Loss 11.2777
2020-11-05 18:33:12,466 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0445 | Iter Mean Loss 7.6611
2020-11-05 18:33:12,473 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6476 | Iter Mean Loss 10.9899
2020-11-05 18:33:12,480 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8146 | Iter Mean Loss 11.6961
2020-11-05 18:33:12,488 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.7453 | Iter Mean Loss 11.5059
2020-11-05 18:33:12,490 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.2817 | MSE 0.3885
2020-11-05 18:33:12,497 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2715 | Iter Mean Loss 11.2715
2020-11-05 18:33:12,505 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0402 | Iter Mean Loss 7.6558
2020-11-05 18:33:12,512 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5656 | Iter Mean Loss 10.9591
2020-11-05 18:33:12,520 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7750 | Iter Mean Loss 11.6631
2020-11-05 18:33:12,528 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6950 | Iter Mean Loss 11.4695
2020-11-05 18:33:12,530 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.2817 | MSE 0.3879
2020-11-05 18:33:12,538 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2650 | Iter Mean Loss 11.2650
2020-11-05 18:33:12,546 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0358 | Iter Mean Loss 7.6504
2020-11-05 18:33:12,554 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4844 | Iter Mean Loss 10.9284
2020-11-05 18:33:12,562 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7357 | Iter Mean Loss 11.6302
2020-11-05 18:33:12,569 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.6452 | Iter Mean Loss 11.4332
2020-11-05 18:33:12,572 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.2817 | MSE 0.3873
2020-11-05 18:33:12,581 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2583 | Iter Mean Loss 11.2583
2020-11-05 18:33:12,588 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0315 | Iter Mean Loss 7.6449
2020-11-05 18:33:12,596 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4038 | Iter Mean Loss 10.8979
2020-11-05 18:33:12,604 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6967 | Iter Mean Loss 11.5976
2020-11-05 18:33:12,612 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5957 | Iter Mean Loss 11.3972
2020-11-05 18:33:12,614 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.2817 | MSE 0.3867
2020-11-05 18:33:12,622 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2513 | Iter Mean Loss 11.2513
2020-11-05 18:33:12,630 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 7.6392
2020-11-05 18:33:12,638 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3241 | Iter Mean Loss 10.8675
2020-11-05 18:33:12,645 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6579 | Iter Mean Loss 11.5651
2020-11-05 18:33:12,652 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.5466 | Iter Mean Loss 11.3614
2020-11-05 18:33:12,654 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.2817 | MSE 0.3860
2020-11-05 18:33:12,661 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2440 | Iter Mean Loss 11.2440
2020-11-05 18:33:12,669 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0228 | Iter Mean Loss 7.6334
2020-11-05 18:33:12,676 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2451 | Iter Mean Loss 10.8373
2020-11-05 18:33:12,683 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6194 | Iter Mean Loss 11.5328
2020-11-05 18:33:12,690 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4979 | Iter Mean Loss 11.3258
2020-11-05 18:33:12,692 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.2817 | MSE 0.3854
2020-11-05 18:33:12,700 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2365 | Iter Mean Loss 11.2365
2020-11-05 18:33:12,707 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0185 | Iter Mean Loss 7.6275
2020-11-05 18:33:12,715 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1668 | Iter Mean Loss 10.8072
2020-11-05 18:33:12,722 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5811 | Iter Mean Loss 11.5007
2020-11-05 18:33:12,730 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4496 | Iter Mean Loss 11.2905
2020-11-05 18:33:12,733 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.2817 | MSE 0.3848
2020-11-05 18:33:12,741 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2287 | Iter Mean Loss 11.2287
2020-11-05 18:33:12,749 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 7.6214
2020-11-05 18:33:12,757 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0892 | Iter Mean Loss 10.7773
2020-11-05 18:33:12,765 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5431 | Iter Mean Loss 11.4688
2020-11-05 18:33:12,773 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4017 | Iter Mean Loss 11.2553
2020-11-05 18:33:12,775 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.2817 | MSE 0.3843
2020-11-05 18:33:12,784 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2206 | Iter Mean Loss 11.2206
2020-11-05 18:33:12,791 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0097 | Iter Mean Loss 7.6152
2020-11-05 18:33:12,799 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0124 | Iter Mean Loss 10.7476
2020-11-05 18:33:12,807 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5053 | Iter Mean Loss 11.4370
2020-11-05 18:33:12,815 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3541 | Iter Mean Loss 11.2204
2020-11-05 18:33:12,817 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.2817 | MSE 0.3837
2020-11-05 18:33:12,825 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2123 | Iter Mean Loss 11.2123
2020-11-05 18:33:12,833 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0053 | Iter Mean Loss 7.6088
2020-11-05 18:33:12,840 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9363 | Iter Mean Loss 10.7179
2020-11-05 18:33:12,847 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4678 | Iter Mean Loss 11.4054
2020-11-05 18:33:12,854 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.3070 | Iter Mean Loss 11.1857
2020-11-05 18:33:12,856 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.2817 | MSE 0.3831
2020-11-05 18:33:12,864 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2037 | Iter Mean Loss 11.2037
2020-11-05 18:33:12,872 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0009 | Iter Mean Loss 7.6023
2020-11-05 18:33:12,879 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8608 | Iter Mean Loss 10.6885
2020-11-05 18:33:12,886 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4305 | Iter Mean Loss 11.3740
2020-11-05 18:33:12,894 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2602 | Iter Mean Loss 11.1512
2020-11-05 18:33:12,896 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.2817 | MSE 0.3825
2020-11-05 18:33:12,904 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1949 | Iter Mean Loss 11.1949
2020-11-05 18:33:12,911 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9964 | Iter Mean Loss 7.5957
2020-11-05 18:33:12,918 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7861 | Iter Mean Loss 10.6591
2020-11-05 18:33:12,926 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3934 | Iter Mean Loss 11.3427
2020-11-05 18:33:12,933 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.2138 | Iter Mean Loss 11.1169
2020-11-05 18:33:12,936 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.2817 | MSE 0.3819
2020-11-05 18:33:12,944 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1858 | Iter Mean Loss 11.1858
2020-11-05 18:33:12,952 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9920 | Iter Mean Loss 7.5889
2020-11-05 18:33:12,960 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7121 | Iter Mean Loss 10.6300
2020-11-05 18:33:12,968 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3566 | Iter Mean Loss 11.3116
2020-11-05 18:33:12,975 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1677 | Iter Mean Loss 11.0829
2020-11-05 18:33:12,978 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.2817 | MSE 0.3813
2020-11-05 18:33:12,986 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1765 | Iter Mean Loss 11.1765
2020-11-05 18:33:12,994 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9875 | Iter Mean Loss 7.5820
2020-11-05 18:33:13,003 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6388 | Iter Mean Loss 10.6009
2020-11-05 18:33:13,010 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3200 | Iter Mean Loss 11.2807
2020-11-05 18:33:13,018 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1221 | Iter Mean Loss 11.0490
2020-11-05 18:33:13,020 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.2817 | MSE 0.3808
2020-11-05 18:33:13,029 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1669 | Iter Mean Loss 11.1669
2020-11-05 18:33:13,036 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9830 | Iter Mean Loss 7.5750
2020-11-05 18:33:13,044 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5662 | Iter Mean Loss 10.5720
2020-11-05 18:33:13,051 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2837 | Iter Mean Loss 11.2499
2020-11-05 18:33:13,058 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0768 | Iter Mean Loss 11.0153
2020-11-05 18:33:13,060 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.2817 | MSE 0.3802
2020-11-05 18:33:13,067 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1571 | Iter Mean Loss 11.1571
2020-11-05 18:33:13,075 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 7.5678
2020-11-05 18:33:13,082 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4942 | Iter Mean Loss 10.5433
2020-11-05 18:33:13,089 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2475 | Iter Mean Loss 11.2193
2020-11-05 18:33:13,096 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.0319 | Iter Mean Loss 10.9818
2020-11-05 18:33:13,098 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.2817 | MSE 0.3797
2020-11-05 18:33:13,106 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1471 | Iter Mean Loss 11.1471
2020-11-05 18:33:13,113 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9740 | Iter Mean Loss 7.5605
2020-11-05 18:33:13,120 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4229 | Iter Mean Loss 10.5146
2020-11-05 18:33:13,128 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2116 | Iter Mean Loss 11.1889
2020-11-05 18:33:13,135 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9874 | Iter Mean Loss 10.9486
2020-11-05 18:33:13,138 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.2817 | MSE 0.3791
2020-11-05 18:33:13,146 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1368 | Iter Mean Loss 11.1368
2020-11-05 18:33:13,154 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9694 | Iter Mean Loss 7.5531
2020-11-05 18:33:13,161 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3523 | Iter Mean Loss 10.4861
2020-11-05 18:33:13,169 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1758 | Iter Mean Loss 11.1586
2020-11-05 18:33:13,177 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.9432 | Iter Mean Loss 10.9155
2020-11-05 18:33:13,179 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.2817 | MSE 0.3786
2020-11-05 18:33:13,188 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1263 | Iter Mean Loss 11.1263
2020-11-05 18:33:13,195 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9648 | Iter Mean Loss 7.5456
2020-11-05 18:33:13,203 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2823 | Iter Mean Loss 10.4578
2020-11-05 18:33:13,210 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1403 | Iter Mean Loss 11.1284
2020-11-05 18:33:13,218 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8995 | Iter Mean Loss 10.8826
2020-11-05 18:33:13,220 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.2817 | MSE 0.3780
2020-11-05 18:33:13,228 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1155 | Iter Mean Loss 11.1155
2020-11-05 18:33:13,236 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9603 | Iter Mean Loss 7.5379
2020-11-05 18:33:13,243 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2130 | Iter Mean Loss 10.4296
2020-11-05 18:33:13,250 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1050 | Iter Mean Loss 11.0984
2020-11-05 18:33:13,258 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8560 | Iter Mean Loss 10.8499
2020-11-05 18:33:13,260 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.2817 | MSE 0.3775
2020-11-05 18:33:13,267 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1045 | Iter Mean Loss 11.1045
2020-11-05 18:33:13,275 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9556 | Iter Mean Loss 7.5301
2020-11-05 18:33:13,282 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1443 | Iter Mean Loss 10.4015
2020-11-05 18:33:13,289 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0698 | Iter Mean Loss 11.0686
2020-11-05 18:33:13,296 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8130 | Iter Mean Loss 10.8175
2020-11-05 18:33:13,298 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.2817 | MSE 0.3769
2020-11-05 18:33:13,306 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0934 | Iter Mean Loss 11.0934
2020-11-05 18:33:13,314 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9510 | Iter Mean Loss 7.5222
2020-11-05 18:33:13,322 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0763 | Iter Mean Loss 10.3735
2020-11-05 18:33:13,330 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0349 | Iter Mean Loss 11.0389
2020-11-05 18:33:13,338 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7703 | Iter Mean Loss 10.7852
2020-11-05 18:33:13,340 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.2817 | MSE 0.3764
2020-11-05 18:33:13,348 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0819 | Iter Mean Loss 11.0819
2020-11-05 18:33:13,356 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9464 | Iter Mean Loss 7.5141
2020-11-05 18:33:13,364 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0088 | Iter Mean Loss 10.3457
2020-11-05 18:33:13,372 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0002 | Iter Mean Loss 11.0093
2020-11-05 18:33:13,380 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.7280 | Iter Mean Loss 10.7531
2020-11-05 18:33:13,382 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.2817 | MSE 0.3759
2020-11-05 18:33:13,391 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0703 | Iter Mean Loss 11.0703
2020-11-05 18:33:13,398 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9417 | Iter Mean Loss 7.5060
2020-11-05 18:33:13,406 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9421 | Iter Mean Loss 10.3180
2020-11-05 18:33:13,414 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9656 | Iter Mean Loss 10.9799
2020-11-05 18:33:13,422 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 10.7211
2020-11-05 18:33:13,425 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.2817 | MSE 0.3753
2020-11-05 18:33:13,433 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0585 | Iter Mean Loss 11.0585
2020-11-05 18:33:13,440 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 7.4977
2020-11-05 18:33:13,448 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8759 | Iter Mean Loss 10.2904
2020-11-05 18:33:13,455 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9312 | Iter Mean Loss 10.9506
2020-11-05 18:33:13,462 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6444 | Iter Mean Loss 10.6894
2020-11-05 18:33:13,464 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.2817 | MSE 0.3748
2020-11-05 18:33:13,472 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0464 | Iter Mean Loss 11.0464
2020-11-05 18:33:13,479 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9323 | Iter Mean Loss 7.4893
2020-11-05 18:33:13,486 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.2630
2020-11-05 18:33:13,494 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8970 | Iter Mean Loss 10.9215
2020-11-05 18:33:13,501 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6031 | Iter Mean Loss 10.6578
2020-11-05 18:33:13,503 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.2817 | MSE 0.3743
2020-11-05 18:33:13,510 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0341 | Iter Mean Loss 11.0341
2020-11-05 18:33:13,518 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9275 | Iter Mean Loss 7.4808
2020-11-05 18:33:13,526 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7454 | Iter Mean Loss 10.2357
2020-11-05 18:33:13,533 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8630 | Iter Mean Loss 10.8925
2020-11-05 18:33:13,541 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5622 | Iter Mean Loss 10.6264
2020-11-05 18:33:13,543 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.2817 | MSE 0.3738
2020-11-05 18:33:13,552 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0216 | Iter Mean Loss 11.0216
2020-11-05 18:33:13,560 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9228 | Iter Mean Loss 7.4722
2020-11-05 18:33:13,568 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6810 | Iter Mean Loss 10.2085
2020-11-05 18:33:13,576 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8291 | Iter Mean Loss 10.8636
2020-11-05 18:33:13,584 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.5216 | Iter Mean Loss 10.5952
2020-11-05 18:33:13,587 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.2817 | MSE 0.3733
2020-11-05 18:33:13,595 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0089 | Iter Mean Loss 11.0089
2020-11-05 18:33:13,603 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9180 | Iter Mean Loss 7.4635
2020-11-05 18:33:13,611 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6173 | Iter Mean Loss 10.1814
2020-11-05 18:33:13,619 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7954 | Iter Mean Loss 10.8349
2020-11-05 18:33:13,627 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4813 | Iter Mean Loss 10.5642
2020-11-05 18:33:13,629 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.2817 | MSE 0.3727
2020-11-05 18:33:13,637 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9961 | Iter Mean Loss 10.9961
2020-11-05 18:33:13,645 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9132 | Iter Mean Loss 7.4546
2020-11-05 18:33:13,652 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5541 | Iter Mean Loss 10.1544
2020-11-05 18:33:13,659 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7618 | Iter Mean Loss 10.8063
2020-11-05 18:33:13,666 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4415 | Iter Mean Loss 10.5333
2020-11-05 18:33:13,669 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.2817 | MSE 0.3722
2020-11-05 18:33:13,676 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9830 | Iter Mean Loss 10.9830
2020-11-05 18:33:13,683 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9083 | Iter Mean Loss 7.4456
2020-11-05 18:33:13,691 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4915 | Iter Mean Loss 10.1276
2020-11-05 18:33:13,698 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7284 | Iter Mean Loss 10.7778
2020-11-05 18:33:13,705 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4019 | Iter Mean Loss 10.5026
2020-11-05 18:33:13,707 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.2817 | MSE 0.3717
2020-11-05 18:33:13,715 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9697 | Iter Mean Loss 10.9697
2020-11-05 18:33:13,722 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 7.4366
2020-11-05 18:33:13,730 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4295 | Iter Mean Loss 10.1009
2020-11-05 18:33:13,738 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6952 | Iter Mean Loss 10.7494
2020-11-05 18:33:13,745 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3627 | Iter Mean Loss 10.4721
2020-11-05 18:33:13,747 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.2817 | MSE 0.3712
2020-11-05 18:33:13,755 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9562 | Iter Mean Loss 10.9562
2020-11-05 18:33:13,764 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8986 | Iter Mean Loss 7.4274
2020-11-05 18:33:13,771 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3680 | Iter Mean Loss 10.0742
2020-11-05 18:33:13,779 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6621 | Iter Mean Loss 10.7212
2020-11-05 18:33:13,787 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3238 | Iter Mean Loss 10.4417
2020-11-05 18:33:13,789 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.2817 | MSE 0.3708
2020-11-05 18:33:13,798 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9425 | Iter Mean Loss 10.9425
2020-11-05 18:33:13,806 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8936 | Iter Mean Loss 7.4181
2020-11-05 18:33:13,814 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3071 | Iter Mean Loss 10.0477
2020-11-05 18:33:13,821 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6291 | Iter Mean Loss 10.6931
2020-11-05 18:33:13,830 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2852 | Iter Mean Loss 10.4115
2020-11-05 18:33:13,832 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.2817 | MSE 0.3703
2020-11-05 18:33:13,840 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9286 | Iter Mean Loss 10.9286
2020-11-05 18:33:13,848 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8887 | Iter Mean Loss 7.4086
2020-11-05 18:33:13,855 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2467 | Iter Mean Loss 10.0213
2020-11-05 18:33:13,862 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5963 | Iter Mean Loss 10.6651
2020-11-05 18:33:13,870 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2470 | Iter Mean Loss 10.3815
2020-11-05 18:33:13,872 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.2817 | MSE 0.3698
2020-11-05 18:33:13,880 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9145 | Iter Mean Loss 10.9145
2020-11-05 18:33:13,887 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8837 | Iter Mean Loss 7.3991
2020-11-05 18:33:13,895 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1869 | Iter Mean Loss 9.9951
2020-11-05 18:33:13,907 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5636 | Iter Mean Loss 10.6372
2020-11-05 18:33:13,919 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.2090 | Iter Mean Loss 10.3516
2020-11-05 18:33:13,923 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.2817 | MSE 0.3693
2020-11-05 18:33:13,933 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9003 | Iter Mean Loss 10.9003
2020-11-05 18:33:13,942 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8787 | Iter Mean Loss 7.3895
2020-11-05 18:33:13,950 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1276 | Iter Mean Loss 9.9689
2020-11-05 18:33:13,957 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5310 | Iter Mean Loss 10.6094
2020-11-05 18:33:13,966 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1714 | Iter Mean Loss 10.3218
2020-11-05 18:33:13,968 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.2817 | MSE 0.3688
2020-11-05 18:33:13,977 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8858 | Iter Mean Loss 10.8858
2020-11-05 18:33:13,987 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 7.3798
2020-11-05 18:33:13,995 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0689 | Iter Mean Loss 9.9428
2020-11-05 18:33:14,003 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4986 | Iter Mean Loss 10.5818
2020-11-05 18:33:14,012 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1341 | Iter Mean Loss 10.2922
2020-11-05 18:33:14,014 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.2817 | MSE 0.3683
2020-11-05 18:33:14,022 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8712 | Iter Mean Loss 10.8712
2020-11-05 18:33:14,030 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8686 | Iter Mean Loss 7.3699
2020-11-05 18:33:14,041 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0107 | Iter Mean Loss 9.9168
2020-11-05 18:33:14,052 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4663 | Iter Mean Loss 10.5542
2020-11-05 18:33:14,061 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0971 | Iter Mean Loss 10.2628
2020-11-05 18:33:14,063 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.2817 | MSE 0.3679
2020-11-05 18:33:14,071 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8564 | Iter Mean Loss 10.8564
2020-11-05 18:33:14,080 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8635 | Iter Mean Loss 7.3600
2020-11-05 18:33:14,090 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9530 | Iter Mean Loss 9.8910
2020-11-05 18:33:14,097 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4341 | Iter Mean Loss 10.5268
2020-11-05 18:33:14,105 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0604 | Iter Mean Loss 10.2335
2020-11-05 18:33:14,107 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.2817 | MSE 0.3674
2020-11-05 18:33:14,114 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8414 | Iter Mean Loss 10.8414
2020-11-05 18:33:14,122 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8584 | Iter Mean Loss 7.3499
2020-11-05 18:33:14,129 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8958 | Iter Mean Loss 9.8652
2020-11-05 18:33:14,136 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4020 | Iter Mean Loss 10.4994
2020-11-05 18:33:14,144 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0240 | Iter Mean Loss 10.2043
2020-11-05 18:33:14,146 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.2817 | MSE 0.3669
2020-11-05 18:33:14,154 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8262 | Iter Mean Loss 10.8262
2020-11-05 18:33:14,162 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8533 | Iter Mean Loss 7.3398
2020-11-05 18:33:14,169 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8391 | Iter Mean Loss 9.8395
2020-11-05 18:33:14,177 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3701 | Iter Mean Loss 10.4722
2020-11-05 18:33:14,185 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9879 | Iter Mean Loss 10.1753
2020-11-05 18:33:14,187 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.2817 | MSE 0.3665
2020-11-05 18:33:14,196 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8109 | Iter Mean Loss 10.8109
2020-11-05 18:33:14,203 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8481 | Iter Mean Loss 7.3295
2020-11-05 18:33:14,211 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7829 | Iter Mean Loss 9.8140
2020-11-05 18:33:14,218 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3383 | Iter Mean Loss 10.4450
2020-11-05 18:33:14,226 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9521 | Iter Mean Loss 10.1464
2020-11-05 18:33:14,228 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.2817 | MSE 0.3660
2020-11-05 18:33:14,236 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7954 | Iter Mean Loss 10.7954
2020-11-05 18:33:14,244 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8429 | Iter Mean Loss 7.3191
2020-11-05 18:33:14,252 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7272 | Iter Mean Loss 9.7885
2020-11-05 18:33:14,259 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3065 | Iter Mean Loss 10.4180
2020-11-05 18:33:14,266 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9165 | Iter Mean Loss 10.1177
2020-11-05 18:33:14,268 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.2817 | MSE 0.3655
2020-11-05 18:33:14,276 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7797 | Iter Mean Loss 10.7797
2020-11-05 18:33:14,283 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8377 | Iter Mean Loss 7.3087
2020-11-05 18:33:14,291 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6720 | Iter Mean Loss 9.7631
2020-11-05 18:33:14,298 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2749 | Iter Mean Loss 10.3911
2020-11-05 18:33:14,305 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8813 | Iter Mean Loss 10.0891
2020-11-05 18:33:14,307 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.2817 | MSE 0.3651
2020-11-05 18:33:14,315 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7638 | Iter Mean Loss 10.7638
2020-11-05 18:33:14,324 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8324 | Iter Mean Loss 7.2981
2020-11-05 18:33:14,331 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6173 | Iter Mean Loss 9.7378
2020-11-05 18:33:14,338 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2434 | Iter Mean Loss 10.3642
2020-11-05 18:33:14,346 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8463 | Iter Mean Loss 10.0606
2020-11-05 18:33:14,349 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.2817 | MSE 0.3646
2020-11-05 18:33:14,357 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7478 | Iter Mean Loss 10.7478
2020-11-05 18:33:14,364 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8271 | Iter Mean Loss 7.2874
2020-11-05 18:33:14,372 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5630 | Iter Mean Loss 9.7126
2020-11-05 18:33:14,380 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2119 | Iter Mean Loss 10.3374
2020-11-05 18:33:14,388 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8116 | Iter Mean Loss 10.0323
2020-11-05 18:33:14,390 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.2817 | MSE 0.3642
2020-11-05 18:33:14,398 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7316 | Iter Mean Loss 10.7316
2020-11-05 18:33:14,406 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8218 | Iter Mean Loss 7.2767
2020-11-05 18:33:14,414 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5092 | Iter Mean Loss 9.6875
2020-11-05 18:33:14,422 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1806 | Iter Mean Loss 10.3108
2020-11-05 18:33:14,430 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7772 | Iter Mean Loss 10.0041
2020-11-05 18:33:14,432 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.2817 | MSE 0.3638
2020-11-05 18:33:14,441 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7152 | Iter Mean Loss 10.7152
2020-11-05 18:33:14,449 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8164 | Iter Mean Loss 7.2658
2020-11-05 18:33:14,456 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4559 | Iter Mean Loss 9.6625
2020-11-05 18:33:14,464 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1494 | Iter Mean Loss 10.2842
2020-11-05 18:33:14,471 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7431 | Iter Mean Loss 9.9760
2020-11-05 18:33:14,473 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.2817 | MSE 0.3633
2020-11-05 18:33:14,481 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6986 | Iter Mean Loss 10.6986
2020-11-05 18:33:14,488 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8110 | Iter Mean Loss 7.2548
2020-11-05 18:33:14,495 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4030 | Iter Mean Loss 9.6375
2020-11-05 18:33:14,502 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1182 | Iter Mean Loss 10.2577
2020-11-05 18:33:14,509 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7092 | Iter Mean Loss 9.9480
2020-11-05 18:33:14,511 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.2817 | MSE 0.3629
2020-11-05 18:33:14,519 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6819 | Iter Mean Loss 10.6819
2020-11-05 18:33:14,527 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8056 | Iter Mean Loss 7.2438
2020-11-05 18:33:14,534 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3506 | Iter Mean Loss 9.6127
2020-11-05 18:33:14,541 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0872 | Iter Mean Loss 10.2313
2020-11-05 18:33:14,549 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6755 | Iter Mean Loss 9.9202
2020-11-05 18:33:14,551 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.2817 | MSE 0.3624
2020-11-05 18:33:14,559 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6651 | Iter Mean Loss 10.6651
2020-11-05 18:33:14,567 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8001 | Iter Mean Loss 7.2326
2020-11-05 18:33:14,575 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2986 | Iter Mean Loss 9.5879
2020-11-05 18:33:14,582 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0562 | Iter Mean Loss 10.2050
2020-11-05 18:33:14,590 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6422 | Iter Mean Loss 9.8924
2020-11-05 18:33:14,592 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.2817 | MSE 0.3620
2020-11-05 18:33:14,601 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6480 | Iter Mean Loss 10.6480
2020-11-05 18:33:14,609 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7946 | Iter Mean Loss 7.2213
2020-11-05 18:33:14,617 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2470 | Iter Mean Loss 9.5632
2020-11-05 18:33:14,624 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0253 | Iter Mean Loss 10.1787
2020-11-05 18:33:14,632 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6090 | Iter Mean Loss 9.8648
2020-11-05 18:33:14,634 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.2817 | MSE 0.3616
2020-11-05 18:33:14,643 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6309 | Iter Mean Loss 10.6309
2020-11-05 18:33:14,651 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7891 | Iter Mean Loss 7.2100
2020-11-05 18:33:14,658 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1959 | Iter Mean Loss 9.5386
2020-11-05 18:33:14,666 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9945 | Iter Mean Loss 10.1526
2020-11-05 18:33:14,673 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5762 | Iter Mean Loss 9.8373
2020-11-05 18:33:14,675 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.2817 | MSE 0.3612
2020-11-05 18:33:14,683 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6135 | Iter Mean Loss 10.6135
2020-11-05 18:33:14,690 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7835 | Iter Mean Loss 7.1985
2020-11-05 18:33:14,697 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1451 | Iter Mean Loss 9.5141
2020-11-05 18:33:14,704 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9638 | Iter Mean Loss 10.1265
2020-11-05 18:33:14,711 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 9.8099
2020-11-05 18:33:14,713 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.2817 | MSE 0.3607
2020-11-05 18:33:14,721 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5960 | Iter Mean Loss 10.5960
2020-11-05 18:33:14,728 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7779 | Iter Mean Loss 7.1869
2020-11-05 18:33:14,735 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0949 | Iter Mean Loss 9.4896
2020-11-05 18:33:14,742 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9331 | Iter Mean Loss 10.1005
2020-11-05 18:33:14,750 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5111 | Iter Mean Loss 9.7826
2020-11-05 18:33:14,753 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.2817 | MSE 0.3603
2020-11-05 18:33:14,761 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5783 | Iter Mean Loss 10.5783
2020-11-05 18:33:14,768 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 7.1753
2020-11-05 18:33:14,776 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0450 | Iter Mean Loss 9.4652
2020-11-05 18:33:14,783 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9026 | Iter Mean Loss 10.0745
2020-11-05 18:33:14,791 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4790 | Iter Mean Loss 9.7554
2020-11-05 18:33:14,794 - root - INFO - Evaluate: Epoch 0285 | NDCG 1.0000 | MSE 0.3599
2020-11-05 18:33:14,802 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5605 | Iter Mean Loss 10.5605
2020-11-05 18:33:14,810 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7666 | Iter Mean Loss 7.1636
2020-11-05 18:33:14,818 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9955 | Iter Mean Loss 9.4409
2020-11-05 18:33:14,826 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8721 | Iter Mean Loss 10.0487
2020-11-05 18:33:14,833 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4471 | Iter Mean Loss 9.7283
2020-11-05 18:33:14,836 - root - INFO - Evaluate: Epoch 0286 | NDCG 1.0000 | MSE 0.3595
2020-11-05 18:33:14,845 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5426 | Iter Mean Loss 10.5426
2020-11-05 18:33:14,852 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7609 | Iter Mean Loss 7.1517
2020-11-05 18:33:14,860 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9464 | Iter Mean Loss 9.4166
2020-11-05 18:33:14,868 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8416 | Iter Mean Loss 10.0229
2020-11-05 18:33:14,875 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 9.7014
2020-11-05 18:33:14,878 - root - INFO - Evaluate: Epoch 0287 | NDCG 1.0000 | MSE 0.3591
2020-11-05 18:33:14,886 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5244 | Iter Mean Loss 10.5244
2020-11-05 18:33:14,893 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7551 | Iter Mean Loss 7.1398
2020-11-05 18:33:14,900 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8977 | Iter Mean Loss 9.3924
2020-11-05 18:33:14,907 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8113 | Iter Mean Loss 9.9971
2020-11-05 18:33:14,914 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3839 | Iter Mean Loss 9.6745
2020-11-05 18:33:14,917 - root - INFO - Evaluate: Epoch 0288 | NDCG 1.0000 | MSE 0.3587
2020-11-05 18:33:14,924 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5062 | Iter Mean Loss 10.5062
2020-11-05 18:33:14,931 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7493 | Iter Mean Loss 7.1278
2020-11-05 18:33:14,939 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8494 | Iter Mean Loss 9.3683
2020-11-05 18:33:14,946 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7810 | Iter Mean Loss 9.9715
2020-11-05 18:33:14,954 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3526 | Iter Mean Loss 9.6477
2020-11-05 18:33:14,956 - root - INFO - Evaluate: Epoch 0289 | NDCG 1.0000 | MSE 0.3583
2020-11-05 18:33:14,964 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4878 | Iter Mean Loss 10.4878
2020-11-05 18:33:14,972 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7435 | Iter Mean Loss 7.1156
2020-11-05 18:33:14,980 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8015 | Iter Mean Loss 9.3442
2020-11-05 18:33:14,988 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7508 | Iter Mean Loss 9.9459
2020-11-05 18:33:14,996 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3216 | Iter Mean Loss 9.6210
2020-11-05 18:33:14,998 - root - INFO - Evaluate: Epoch 0290 | NDCG 1.0000 | MSE 0.3579
2020-11-05 18:33:15,007 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4692 | Iter Mean Loss 10.4692
2020-11-05 18:33:15,015 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7376 | Iter Mean Loss 7.1034
2020-11-05 18:33:15,023 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7539 | Iter Mean Loss 9.3203
2020-11-05 18:33:15,030 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7206 | Iter Mean Loss 9.9203
2020-11-05 18:33:15,038 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2908 | Iter Mean Loss 9.5944
2020-11-05 18:33:15,041 - root - INFO - Evaluate: Epoch 0291 | NDCG 1.0000 | MSE 0.3575
2020-11-05 18:33:15,049 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4505 | Iter Mean Loss 10.4505
2020-11-05 18:33:15,057 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7318 | Iter Mean Loss 7.0911
2020-11-05 18:33:15,064 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7068 | Iter Mean Loss 9.2963
2020-11-05 18:33:15,071 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6905 | Iter Mean Loss 9.8949
2020-11-05 18:33:15,079 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2602 | Iter Mean Loss 9.5679
2020-11-05 18:33:15,081 - root - INFO - Evaluate: Epoch 0292 | NDCG 1.0000 | MSE 0.3571
2020-11-05 18:33:15,088 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4316 | Iter Mean Loss 10.4316
2020-11-05 18:33:15,096 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7258 | Iter Mean Loss 7.0787
2020-11-05 18:33:15,103 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6599 | Iter Mean Loss 9.2725
2020-11-05 18:33:15,110 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6605 | Iter Mean Loss 9.8695
2020-11-05 18:33:15,117 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2298 | Iter Mean Loss 9.5415
2020-11-05 18:33:15,119 - root - INFO - Evaluate: Epoch 0293 | NDCG 1.0000 | MSE 0.3567
2020-11-05 18:33:15,127 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4126 | Iter Mean Loss 10.4126
2020-11-05 18:33:15,134 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7198 | Iter Mean Loss 7.0662
2020-11-05 18:33:15,141 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6135 | Iter Mean Loss 9.2486
2020-11-05 18:33:15,149 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6305 | Iter Mean Loss 9.8441
2020-11-05 18:33:15,156 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1996 | Iter Mean Loss 9.5152
2020-11-05 18:33:15,158 - root - INFO - Evaluate: Epoch 0294 | NDCG 1.0000 | MSE 0.3563
2020-11-05 18:33:15,166 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3934 | Iter Mean Loss 10.3934
2020-11-05 18:33:15,174 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7138 | Iter Mean Loss 7.0536
2020-11-05 18:33:15,181 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5674 | Iter Mean Loss 9.2249
2020-11-05 18:33:15,189 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6006 | Iter Mean Loss 9.8188
2020-11-05 18:33:15,197 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1696 | Iter Mean Loss 9.4890
2020-11-05 18:33:15,199 - root - INFO - Evaluate: Epoch 0295 | NDCG 1.0000 | MSE 0.3559
2020-11-05 18:33:15,207 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3741 | Iter Mean Loss 10.3741
2020-11-05 18:33:15,215 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7078 | Iter Mean Loss 7.0410
2020-11-05 18:33:15,222 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5216 | Iter Mean Loss 9.2012
2020-11-05 18:33:15,230 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 9.7936
2020-11-05 18:33:15,238 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1398 | Iter Mean Loss 9.4628
2020-11-05 18:33:15,240 - root - INFO - Evaluate: Epoch 0296 | NDCG 1.0000 | MSE 0.3555
2020-11-05 18:33:15,248 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3547 | Iter Mean Loss 10.3547
2020-11-05 18:33:15,256 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7017 | Iter Mean Loss 7.0282
2020-11-05 18:33:15,263 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4762 | Iter Mean Loss 9.1775
2020-11-05 18:33:15,271 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5410 | Iter Mean Loss 9.7684
2020-11-05 18:33:15,278 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1102 | Iter Mean Loss 9.4368
2020-11-05 18:33:15,280 - root - INFO - Evaluate: Epoch 0297 | NDCG 1.0000 | MSE 0.3552
2020-11-05 18:33:15,288 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3351 | Iter Mean Loss 10.3351
2020-11-05 18:33:15,295 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6956 | Iter Mean Loss 7.0153
2020-11-05 18:33:15,302 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4311 | Iter Mean Loss 9.1539
2020-11-05 18:33:15,309 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5113 | Iter Mean Loss 9.7433
2020-11-05 18:33:15,317 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0808 | Iter Mean Loss 9.4108
2020-11-05 18:33:15,319 - root - INFO - Evaluate: Epoch 0298 | NDCG 1.0000 | MSE 0.3548
2020-11-05 18:33:15,328 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3154 | Iter Mean Loss 10.3154
2020-11-05 18:33:15,335 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6894 | Iter Mean Loss 7.0024
2020-11-05 18:33:15,342 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3864 | Iter Mean Loss 9.1304
2020-11-05 18:33:15,349 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4816 | Iter Mean Loss 9.7182
2020-11-05 18:33:15,357 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0516 | Iter Mean Loss 9.3849
2020-11-05 18:33:15,359 - root - INFO - Evaluate: Epoch 0299 | NDCG 1.0000 | MSE 0.3544
2020-11-05 18:33:15,368 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2955 | Iter Mean Loss 10.2955
2020-11-05 18:33:15,375 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6832 | Iter Mean Loss 6.9894
2020-11-05 18:33:15,383 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3420 | Iter Mean Loss 9.1069
2020-11-05 18:33:15,391 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4520 | Iter Mean Loss 9.6932
2020-11-05 18:33:15,399 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0226 | Iter Mean Loss 9.3591
2020-11-05 18:33:15,401 - root - INFO - Evaluate: Epoch 0300 | NDCG 1.0000 | MSE 0.3540
2020-11-05 18:33:15,410 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2755 | Iter Mean Loss 10.2755
2020-11-05 18:33:15,423 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6770 | Iter Mean Loss 6.9762
2020-11-05 18:33:15,435 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2979 | Iter Mean Loss 9.0835
2020-11-05 18:33:15,445 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4224 | Iter Mean Loss 9.6682
2020-11-05 18:33:15,454 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9937 | Iter Mean Loss 9.3333
2020-11-05 18:33:15,457 - root - INFO - Evaluate: Epoch 0301 | NDCG 1.0000 | MSE 0.3537
2020-11-05 18:33:15,467 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2554 | Iter Mean Loss 10.2554
2020-11-05 18:33:15,478 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6707 | Iter Mean Loss 6.9630
2020-11-05 18:33:15,488 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2541 | Iter Mean Loss 9.0601
2020-11-05 18:33:15,498 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3929 | Iter Mean Loss 9.6433
2020-11-05 18:33:15,508 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 9.3076
2020-11-05 18:33:15,511 - root - INFO - Evaluate: Epoch 0302 | NDCG 1.0000 | MSE 0.3533
2020-11-05 18:33:15,523 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2351 | Iter Mean Loss 10.2351
2020-11-05 18:33:15,533 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6644 | Iter Mean Loss 6.9497
2020-11-05 18:33:15,543 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2107 | Iter Mean Loss 9.0367
2020-11-05 18:33:15,552 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3635 | Iter Mean Loss 9.6184
2020-11-05 18:33:15,562 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9366 | Iter Mean Loss 9.2821
2020-11-05 18:33:15,564 - root - INFO - Evaluate: Epoch 0303 | NDCG 1.0000 | MSE 0.3529
2020-11-05 18:33:15,573 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2147 | Iter Mean Loss 10.2147
2020-11-05 18:33:15,582 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6580 | Iter Mean Loss 6.9364
2020-11-05 18:33:15,593 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1675 | Iter Mean Loss 9.0134
2020-11-05 18:33:15,603 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3341 | Iter Mean Loss 9.5936
2020-11-05 18:33:15,612 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9083 | Iter Mean Loss 9.2565
2020-11-05 18:33:15,614 - root - INFO - Evaluate: Epoch 0304 | NDCG 1.0000 | MSE 0.3526
2020-11-05 18:33:15,625 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1942 | Iter Mean Loss 10.1942
2020-11-05 18:33:15,635 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6516 | Iter Mean Loss 6.9229
2020-11-05 18:33:15,644 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1247 | Iter Mean Loss 8.9902
2020-11-05 18:33:15,654 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3047 | Iter Mean Loss 9.5688
2020-11-05 18:33:15,662 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8802 | Iter Mean Loss 9.2311
2020-11-05 18:33:15,665 - root - INFO - Evaluate: Epoch 0305 | NDCG 1.0000 | MSE 0.3522
2020-11-05 18:33:15,675 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1735 | Iter Mean Loss 10.1735
2020-11-05 18:33:15,684 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6452 | Iter Mean Loss 6.9093
2020-11-05 18:33:15,693 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0822 | Iter Mean Loss 8.9670
2020-11-05 18:33:15,701 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2754 | Iter Mean Loss 9.5441
2020-11-05 18:33:15,710 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8522 | Iter Mean Loss 9.2057
2020-11-05 18:33:15,712 - root - INFO - Evaluate: Epoch 0306 | NDCG 1.0000 | MSE 0.3519
2020-11-05 18:33:15,721 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1527 | Iter Mean Loss 10.1527
2020-11-05 18:33:15,730 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6387 | Iter Mean Loss 6.8957
2020-11-05 18:33:15,737 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0399 | Iter Mean Loss 8.9438
2020-11-05 18:33:15,744 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2462 | Iter Mean Loss 9.5194
2020-11-05 18:33:15,751 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8245 | Iter Mean Loss 9.1804
2020-11-05 18:33:15,753 - root - INFO - Evaluate: Epoch 0307 | NDCG 1.0000 | MSE 0.3515
2020-11-05 18:33:15,761 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1318 | Iter Mean Loss 10.1318
2020-11-05 18:33:15,769 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 6.8820
2020-11-05 18:33:15,776 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9980 | Iter Mean Loss 8.9207
2020-11-05 18:33:15,784 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2170 | Iter Mean Loss 9.4947
2020-11-05 18:33:15,791 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7968 | Iter Mean Loss 9.1552
2020-11-05 18:33:15,794 - root - INFO - Evaluate: Epoch 0308 | NDCG 1.0000 | MSE 0.3512
2020-11-05 18:33:15,802 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1107 | Iter Mean Loss 10.1107
2020-11-05 18:33:15,809 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 6.8682
2020-11-05 18:33:15,817 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9563 | Iter Mean Loss 8.8976
2020-11-05 18:33:15,824 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1878 | Iter Mean Loss 9.4701
2020-11-05 18:33:15,832 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7694 | Iter Mean Loss 9.1300
2020-11-05 18:33:15,834 - root - INFO - Evaluate: Epoch 0309 | NDCG 1.0000 | MSE 0.3508
2020-11-05 18:33:15,842 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0895 | Iter Mean Loss 10.0895
2020-11-05 18:33:15,849 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6191 | Iter Mean Loss 6.8543
2020-11-05 18:33:15,856 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9149 | Iter Mean Loss 8.8745
2020-11-05 18:33:15,864 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1587 | Iter Mean Loss 9.4456
2020-11-05 18:33:15,872 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7421 | Iter Mean Loss 9.1049
2020-11-05 18:33:15,874 - root - INFO - Evaluate: Epoch 0310 | NDCG 1.0000 | MSE 0.3505
2020-11-05 18:33:15,882 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0682 | Iter Mean Loss 10.0682
2020-11-05 18:33:15,889 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6124 | Iter Mean Loss 6.8403
2020-11-05 18:33:15,896 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8738 | Iter Mean Loss 8.8515
2020-11-05 18:33:15,903 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1297 | Iter Mean Loss 9.4210
2020-11-05 18:33:15,911 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7150 | Iter Mean Loss 9.0798
2020-11-05 18:33:15,913 - root - INFO - Evaluate: Epoch 0311 | NDCG 1.0000 | MSE 0.3501
2020-11-05 18:33:15,920 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0468 | Iter Mean Loss 10.0468
2020-11-05 18:33:15,927 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6058 | Iter Mean Loss 6.8263
2020-11-05 18:33:15,934 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8330 | Iter Mean Loss 8.8285
2020-11-05 18:33:15,942 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1007 | Iter Mean Loss 9.3966
2020-11-05 18:33:15,949 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6881 | Iter Mean Loss 9.0549
2020-11-05 18:33:15,951 - root - INFO - Evaluate: Epoch 0312 | NDCG 1.0000 | MSE 0.3498
2020-11-05 18:33:15,959 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0253 | Iter Mean Loss 10.0253
2020-11-05 18:33:15,967 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5991 | Iter Mean Loss 6.8122
2020-11-05 18:33:15,975 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7925 | Iter Mean Loss 8.8056
2020-11-05 18:33:15,982 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0717 | Iter Mean Loss 9.3721
2020-11-05 18:33:15,990 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6613 | Iter Mean Loss 9.0300
2020-11-05 18:33:15,992 - root - INFO - Evaluate: Epoch 0313 | NDCG 1.0000 | MSE 0.3494
2020-11-05 18:33:16,001 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0036 | Iter Mean Loss 10.0036
2020-11-05 18:33:16,009 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 6.7980
2020-11-05 18:33:16,017 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7522 | Iter Mean Loss 8.7827
2020-11-05 18:33:16,024 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0428 | Iter Mean Loss 9.3477
2020-11-05 18:33:16,032 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6347 | Iter Mean Loss 9.0051
2020-11-05 18:33:16,035 - root - INFO - Evaluate: Epoch 0314 | NDCG 1.0000 | MSE 0.3491
2020-11-05 18:33:16,043 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9818 | Iter Mean Loss 9.9818
2020-11-05 18:33:16,050 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5856 | Iter Mean Loss 6.7837
2020-11-05 18:33:16,059 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7122 | Iter Mean Loss 8.7599
2020-11-05 18:33:16,066 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0139 | Iter Mean Loss 9.3234
2020-11-05 18:33:16,074 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6082 | Iter Mean Loss 8.9803
2020-11-05 18:33:16,076 - root - INFO - Evaluate: Epoch 0315 | NDCG 1.0000 | MSE 0.3488
2020-11-05 18:33:16,084 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9599 | Iter Mean Loss 9.9599
2020-11-05 18:33:16,091 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5788 | Iter Mean Loss 6.7693
2020-11-05 18:33:16,098 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6724 | Iter Mean Loss 8.7370
2020-11-05 18:33:16,105 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9851 | Iter Mean Loss 9.2991
2020-11-05 18:33:16,112 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5819 | Iter Mean Loss 8.9556
2020-11-05 18:33:16,114 - root - INFO - Evaluate: Epoch 0316 | NDCG 1.0000 | MSE 0.3484
2020-11-05 18:33:16,121 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9379 | Iter Mean Loss 9.9379
2020-11-05 18:33:16,129 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5719 | Iter Mean Loss 6.7549
2020-11-05 18:33:16,136 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6329 | Iter Mean Loss 8.7143
2020-11-05 18:33:16,143 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9564 | Iter Mean Loss 9.2748
2020-11-05 18:33:16,150 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5558 | Iter Mean Loss 8.9310
2020-11-05 18:33:16,152 - root - INFO - Evaluate: Epoch 0317 | NDCG 1.0000 | MSE 0.3481
2020-11-05 18:33:16,159 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9158 | Iter Mean Loss 9.9158
2020-11-05 18:33:16,167 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5651 | Iter Mean Loss 6.7404
2020-11-05 18:33:16,175 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5937 | Iter Mean Loss 8.6915
2020-11-05 18:33:16,182 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9277 | Iter Mean Loss 9.2505
2020-11-05 18:33:16,189 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5298 | Iter Mean Loss 8.9064
2020-11-05 18:33:16,192 - root - INFO - Evaluate: Epoch 0318 | NDCG 1.0000 | MSE 0.3478
2020-11-05 18:33:16,200 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8935 | Iter Mean Loss 9.8935
2020-11-05 18:33:16,208 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5581 | Iter Mean Loss 6.7258
2020-11-05 18:33:16,216 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5547 | Iter Mean Loss 8.6688
2020-11-05 18:33:16,223 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8990 | Iter Mean Loss 9.2264
2020-11-05 18:33:16,231 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5039 | Iter Mean Loss 8.8819
2020-11-05 18:33:16,233 - root - INFO - Evaluate: Epoch 0319 | NDCG 1.0000 | MSE 0.3475
2020-11-05 18:33:16,241 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8712 | Iter Mean Loss 9.8712
2020-11-05 18:33:16,249 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5512 | Iter Mean Loss 6.7112
2020-11-05 18:33:16,256 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5160 | Iter Mean Loss 8.6461
2020-11-05 18:33:16,264 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8704 | Iter Mean Loss 9.2022
2020-11-05 18:33:16,272 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4783 | Iter Mean Loss 8.8574
2020-11-05 18:33:16,274 - root - INFO - Evaluate: Epoch 0320 | NDCG 1.0000 | MSE 0.3472
2020-11-05 18:33:16,282 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8487 | Iter Mean Loss 9.8487
2020-11-05 18:33:16,289 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5442 | Iter Mean Loss 6.6965
2020-11-05 18:33:16,297 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4775 | Iter Mean Loss 8.6235
2020-11-05 18:33:16,304 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8418 | Iter Mean Loss 9.1781
2020-11-05 18:33:16,311 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4527 | Iter Mean Loss 8.8330
2020-11-05 18:33:16,313 - root - INFO - Evaluate: Epoch 0321 | NDCG 1.0000 | MSE 0.3468
2020-11-05 18:33:16,322 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8262 | Iter Mean Loss 9.8262
2020-11-05 18:33:16,330 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5372 | Iter Mean Loss 6.6817
2020-11-05 18:33:16,337 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4393 | Iter Mean Loss 8.6009
2020-11-05 18:33:16,344 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8133 | Iter Mean Loss 9.1540
2020-11-05 18:33:16,351 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4274 | Iter Mean Loss 8.8087
2020-11-05 18:33:16,353 - root - INFO - Evaluate: Epoch 0322 | NDCG 1.0000 | MSE 0.3465
2020-11-05 18:33:16,361 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8036 | Iter Mean Loss 9.8036
2020-11-05 18:33:16,368 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5302 | Iter Mean Loss 6.6669
2020-11-05 18:33:16,376 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4013 | Iter Mean Loss 8.5784
2020-11-05 18:33:16,383 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7848 | Iter Mean Loss 9.1300
2020-11-05 18:33:16,391 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4022 | Iter Mean Loss 8.7844
2020-11-05 18:33:16,393 - root - INFO - Evaluate: Epoch 0323 | NDCG 1.0000 | MSE 0.3462
2020-11-05 18:33:16,402 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7808 | Iter Mean Loss 9.7808
2020-11-05 18:33:16,410 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5231 | Iter Mean Loss 6.6520
2020-11-05 18:33:16,417 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3635 | Iter Mean Loss 8.5558
2020-11-05 18:33:16,425 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7564 | Iter Mean Loss 9.1060
2020-11-05 18:33:16,432 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 8.7602
2020-11-05 18:33:16,434 - root - INFO - Evaluate: Epoch 0324 | NDCG 1.0000 | MSE 0.3459
2020-11-05 18:33:16,443 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7580 | Iter Mean Loss 9.7580
2020-11-05 18:33:16,450 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5160 | Iter Mean Loss 6.6370
2020-11-05 18:33:16,458 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 8.5334
2020-11-05 18:33:16,465 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7281 | Iter Mean Loss 9.0820
2020-11-05 18:33:16,473 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3522 | Iter Mean Loss 8.7361
2020-11-05 18:33:16,475 - root - INFO - Evaluate: Epoch 0325 | NDCG 1.0000 | MSE 0.3456
2020-11-05 18:33:16,483 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7351 | Iter Mean Loss 9.7351
2020-11-05 18:33:16,490 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5089 | Iter Mean Loss 6.6220
2020-11-05 18:33:16,497 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2888 | Iter Mean Loss 8.5109
2020-11-05 18:33:16,505 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6998 | Iter Mean Loss 9.0581
2020-11-05 18:33:16,512 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3274 | Iter Mean Loss 8.7120
2020-11-05 18:33:16,513 - root - INFO - Evaluate: Epoch 0326 | NDCG 1.0000 | MSE 0.3453
2020-11-05 18:33:16,521 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7120 | Iter Mean Loss 9.7120
2020-11-05 18:33:16,528 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5018 | Iter Mean Loss 6.6069
2020-11-05 18:33:16,536 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2517 | Iter Mean Loss 8.4885
2020-11-05 18:33:16,543 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6715 | Iter Mean Loss 9.0343
2020-11-05 18:33:16,550 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3028 | Iter Mean Loss 8.6880
2020-11-05 18:33:16,552 - root - INFO - Evaluate: Epoch 0327 | NDCG 1.0000 | MSE 0.3450
2020-11-05 18:33:16,559 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6890 | Iter Mean Loss 9.6890
2020-11-05 18:33:16,568 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4946 | Iter Mean Loss 6.5918
2020-11-05 18:33:16,575 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2149 | Iter Mean Loss 8.4662
2020-11-05 18:33:16,583 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6433 | Iter Mean Loss 9.0104
2020-11-05 18:33:16,590 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2784 | Iter Mean Loss 8.6640
2020-11-05 18:33:16,593 - root - INFO - Evaluate: Epoch 0328 | NDCG 1.0000 | MSE 0.3447
2020-11-05 18:33:16,601 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6658 | Iter Mean Loss 9.6658
2020-11-05 18:33:16,609 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4874 | Iter Mean Loss 6.5766
2020-11-05 18:33:16,617 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1783 | Iter Mean Loss 8.4438
2020-11-05 18:33:16,624 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6152 | Iter Mean Loss 8.9867
2020-11-05 18:33:16,632 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2541 | Iter Mean Loss 8.6402
2020-11-05 18:33:16,634 - root - INFO - Evaluate: Epoch 0329 | NDCG 1.0000 | MSE 0.3444
2020-11-05 18:33:16,642 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6425 | Iter Mean Loss 9.6425
2020-11-05 18:33:16,650 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4802 | Iter Mean Loss 6.5614
2020-11-05 18:33:16,658 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1420 | Iter Mean Loss 8.4216
2020-11-05 18:33:16,665 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5871 | Iter Mean Loss 8.9629
2020-11-05 18:33:16,673 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2300 | Iter Mean Loss 8.6164
2020-11-05 18:33:16,675 - root - INFO - Evaluate: Epoch 0330 | NDCG 1.0000 | MSE 0.3441
2020-11-05 18:33:16,683 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6192 | Iter Mean Loss 9.6192
2020-11-05 18:33:16,690 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4730 | Iter Mean Loss 6.5461
2020-11-05 18:33:16,697 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1058 | Iter Mean Loss 8.3993
2020-11-05 18:33:16,704 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5591 | Iter Mean Loss 8.9393
2020-11-05 18:33:16,711 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2060 | Iter Mean Loss 8.5926
2020-11-05 18:33:16,713 - root - INFO - Evaluate: Epoch 0331 | NDCG 1.0000 | MSE 0.3438
2020-11-05 18:33:16,721 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.5958
2020-11-05 18:33:16,728 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4657 | Iter Mean Loss 6.5308
2020-11-05 18:33:16,735 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0699 | Iter Mean Loss 8.3772
2020-11-05 18:33:16,742 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5311 | Iter Mean Loss 8.9156
2020-11-05 18:33:16,749 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1822 | Iter Mean Loss 8.5689
2020-11-05 18:33:16,751 - root - INFO - Evaluate: Epoch 0332 | NDCG 1.0000 | MSE 0.3435
2020-11-05 18:33:16,759 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5724 | Iter Mean Loss 9.5724
2020-11-05 18:33:16,766 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4584 | Iter Mean Loss 6.5154
2020-11-05 18:33:16,773 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0343 | Iter Mean Loss 8.3550
2020-11-05 18:33:16,781 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5032 | Iter Mean Loss 8.8921
2020-11-05 18:33:16,788 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1585 | Iter Mean Loss 8.5454
2020-11-05 18:33:16,790 - root - INFO - Evaluate: Epoch 0333 | NDCG 1.0000 | MSE 0.3433
2020-11-05 18:33:16,798 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5489 | Iter Mean Loss 9.5489
2020-11-05 18:33:16,806 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4511 | Iter Mean Loss 6.5000
2020-11-05 18:33:16,814 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9988 | Iter Mean Loss 8.3329
2020-11-05 18:33:16,822 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4754 | Iter Mean Loss 8.8685
2020-11-05 18:33:16,829 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1350 | Iter Mean Loss 8.5218
2020-11-05 18:33:16,831 - root - INFO - Evaluate: Epoch 0334 | NDCG 1.0000 | MSE 0.3430
2020-11-05 18:33:16,840 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5253 | Iter Mean Loss 9.5253
2020-11-05 18:33:16,847 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4438 | Iter Mean Loss 6.4846
2020-11-05 18:33:16,855 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 8.3109
2020-11-05 18:33:16,863 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4476 | Iter Mean Loss 8.8451
2020-11-05 18:33:16,871 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1116 | Iter Mean Loss 8.4984
2020-11-05 18:33:16,873 - root - INFO - Evaluate: Epoch 0335 | NDCG 1.0000 | MSE 0.3427
2020-11-05 18:33:16,881 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5017 | Iter Mean Loss 9.5017
2020-11-05 18:33:16,888 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4365 | Iter Mean Loss 6.4691
2020-11-05 18:33:16,895 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9286 | Iter Mean Loss 8.2889
2020-11-05 18:33:16,902 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4199 | Iter Mean Loss 8.8217
2020-11-05 18:33:16,909 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0884 | Iter Mean Loss 8.4750
2020-11-05 18:33:16,911 - root - INFO - Evaluate: Epoch 0336 | NDCG 1.0000 | MSE 0.3424
2020-11-05 18:33:16,919 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4780 | Iter Mean Loss 9.4780
2020-11-05 18:33:16,926 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4292 | Iter Mean Loss 6.4536
2020-11-05 18:33:16,933 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8938 | Iter Mean Loss 8.2670
2020-11-05 18:33:16,940 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3922 | Iter Mean Loss 8.7983
2020-11-05 18:33:16,947 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0654 | Iter Mean Loss 8.4517
2020-11-05 18:33:16,949 - root - INFO - Evaluate: Epoch 0337 | NDCG 1.0000 | MSE 0.3421
2020-11-05 18:33:16,957 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4543 | Iter Mean Loss 9.4543
2020-11-05 18:33:16,964 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4218 | Iter Mean Loss 6.4381
2020-11-05 18:33:16,971 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8592 | Iter Mean Loss 8.2451
2020-11-05 18:33:16,978 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3647 | Iter Mean Loss 8.7750
2020-11-05 18:33:16,986 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0425 | Iter Mean Loss 8.4285
2020-11-05 18:33:16,988 - root - INFO - Evaluate: Epoch 0338 | NDCG 1.0000 | MSE 0.3419
2020-11-05 18:33:16,996 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4306 | Iter Mean Loss 9.4306
2020-11-05 18:33:17,004 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.4225
2020-11-05 18:33:17,012 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8248 | Iter Mean Loss 8.2233
2020-11-05 18:33:17,020 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3371 | Iter Mean Loss 8.7518
2020-11-05 18:33:17,027 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0198 | Iter Mean Loss 8.4054
2020-11-05 18:33:17,029 - root - INFO - Evaluate: Epoch 0339 | NDCG 1.0000 | MSE 0.3416
2020-11-05 18:33:17,038 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 9.4068
2020-11-05 18:33:17,045 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4071 | Iter Mean Loss 6.4070
2020-11-05 18:33:17,053 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7907 | Iter Mean Loss 8.2015
2020-11-05 18:33:17,060 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3097 | Iter Mean Loss 8.7286
2020-11-05 18:33:17,067 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9972 | Iter Mean Loss 8.3823
2020-11-05 18:33:17,070 - root - INFO - Evaluate: Epoch 0340 | NDCG 1.0000 | MSE 0.3413
2020-11-05 18:33:17,078 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3830 | Iter Mean Loss 9.3830
2020-11-05 18:33:17,086 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3998 | Iter Mean Loss 6.3914
2020-11-05 18:33:17,094 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7568 | Iter Mean Loss 8.1798
2020-11-05 18:33:17,101 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2824 | Iter Mean Loss 8.7055
2020-11-05 18:33:17,108 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9748 | Iter Mean Loss 8.3593
2020-11-05 18:33:17,110 - root - INFO - Evaluate: Epoch 0341 | NDCG 1.0000 | MSE 0.3411
2020-11-05 18:33:17,117 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3592 | Iter Mean Loss 9.3592
2020-11-05 18:33:17,125 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3924 | Iter Mean Loss 6.3758
2020-11-05 18:33:17,132 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7231 | Iter Mean Loss 8.1582
2020-11-05 18:33:17,139 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2551 | Iter Mean Loss 8.6824
2020-11-05 18:33:17,146 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9526 | Iter Mean Loss 8.3365
2020-11-05 18:33:17,148 - root - INFO - Evaluate: Epoch 0342 | NDCG 1.0000 | MSE 0.3408
2020-11-05 18:33:17,155 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3354 | Iter Mean Loss 9.3354
2020-11-05 18:33:17,163 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3850 | Iter Mean Loss 6.3602
2020-11-05 18:33:17,170 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6896 | Iter Mean Loss 8.1367
2020-11-05 18:33:17,177 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2279 | Iter Mean Loss 8.6595
2020-11-05 18:33:17,184 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9305 | Iter Mean Loss 8.3137
2020-11-05 18:33:17,186 - root - INFO - Evaluate: Epoch 0343 | NDCG 1.0000 | MSE 0.3406
2020-11-05 18:33:17,194 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3115 | Iter Mean Loss 9.3115
2020-11-05 18:33:17,202 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3777 | Iter Mean Loss 6.3446
2020-11-05 18:33:17,209 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6563 | Iter Mean Loss 8.1152
2020-11-05 18:33:17,217 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2007 | Iter Mean Loss 8.6366
2020-11-05 18:33:17,224 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 8.2910
2020-11-05 18:33:17,226 - root - INFO - Evaluate: Epoch 0344 | NDCG 1.0000 | MSE 0.3403
2020-11-05 18:33:17,234 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2877 | Iter Mean Loss 9.2877
2020-11-05 18:33:17,242 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3703 | Iter Mean Loss 6.3290
2020-11-05 18:33:17,250 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6232 | Iter Mean Loss 8.0937
2020-11-05 18:33:17,257 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1737 | Iter Mean Loss 8.6137
2020-11-05 18:33:17,265 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 8.2683
2020-11-05 18:33:17,267 - root - INFO - Evaluate: Epoch 0345 | NDCG 1.0000 | MSE 0.3401
2020-11-05 18:33:17,275 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2638 | Iter Mean Loss 9.2638
2020-11-05 18:33:17,282 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3629 | Iter Mean Loss 6.3134
2020-11-05 18:33:17,290 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5904 | Iter Mean Loss 8.0724
2020-11-05 18:33:17,297 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1467 | Iter Mean Loss 8.5910
2020-11-05 18:33:17,304 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8652 | Iter Mean Loss 8.2458
2020-11-05 18:33:17,306 - root - INFO - Evaluate: Epoch 0346 | NDCG 1.0000 | MSE 0.3398
2020-11-05 18:33:17,314 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2400 | Iter Mean Loss 9.2400
2020-11-05 18:33:17,323 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.2978
2020-11-05 18:33:17,330 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5577 | Iter Mean Loss 8.0511
2020-11-05 18:33:17,337 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1199 | Iter Mean Loss 8.5683
2020-11-05 18:33:17,345 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8438 | Iter Mean Loss 8.2234
2020-11-05 18:33:17,347 - root - INFO - Evaluate: Epoch 0347 | NDCG 1.0000 | MSE 0.3396
2020-11-05 18:33:17,354 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2162 | Iter Mean Loss 9.2162
2020-11-05 18:33:17,361 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3482 | Iter Mean Loss 6.2822
2020-11-05 18:33:17,369 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5253 | Iter Mean Loss 8.0299
2020-11-05 18:33:17,376 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0931 | Iter Mean Loss 8.5457
2020-11-05 18:33:17,384 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8226 | Iter Mean Loss 8.2011
2020-11-05 18:33:17,386 - root - INFO - Evaluate: Epoch 0348 | NDCG 1.0000 | MSE 0.3393
2020-11-05 18:33:17,393 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1924 | Iter Mean Loss 9.1924
2020-11-05 18:33:17,401 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3409 | Iter Mean Loss 6.2666
2020-11-05 18:33:17,410 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4931 | Iter Mean Loss 8.0088
2020-11-05 18:33:17,423 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 8.5232
2020-11-05 18:33:17,433 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8015 | Iter Mean Loss 8.1788
2020-11-05 18:33:17,437 - root - INFO - Evaluate: Epoch 0349 | NDCG 1.0000 | MSE 0.3391
2020-11-05 18:33:17,447 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1686 | Iter Mean Loss 9.1686
2020-11-05 18:33:17,456 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3336 | Iter Mean Loss 6.2511
2020-11-05 18:33:17,465 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4611 | Iter Mean Loss 7.9878
2020-11-05 18:33:17,474 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0398 | Iter Mean Loss 8.5008
2020-11-05 18:33:17,482 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7806 | Iter Mean Loss 8.1567
2020-11-05 18:33:17,485 - root - INFO - Evaluate: Epoch 0350 | NDCG 1.0000 | MSE 0.3389
2020-11-05 18:33:17,495 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1448 | Iter Mean Loss 9.1448
2020-11-05 18:33:17,504 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3263 | Iter Mean Loss 6.2355
2020-11-05 18:33:17,513 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4293 | Iter Mean Loss 7.9668
2020-11-05 18:33:17,522 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0133 | Iter Mean Loss 8.4784
2020-11-05 18:33:17,531 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 8.1347
2020-11-05 18:33:17,534 - root - INFO - Evaluate: Epoch 0351 | NDCG 1.0000 | MSE 0.3386
2020-11-05 18:33:17,543 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1211 | Iter Mean Loss 9.1211
2020-11-05 18:33:17,551 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3190 | Iter Mean Loss 6.2200
2020-11-05 18:33:17,560 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3978 | Iter Mean Loss 7.9460
2020-11-05 18:33:17,568 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9869 | Iter Mean Loss 8.4562
2020-11-05 18:33:17,577 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7392 | Iter Mean Loss 8.1128
2020-11-05 18:33:17,579 - root - INFO - Evaluate: Epoch 0352 | NDCG 1.0000 | MSE 0.3384
2020-11-05 18:33:17,588 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0974 | Iter Mean Loss 9.0974
2020-11-05 18:33:17,598 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3117 | Iter Mean Loss 6.2046
2020-11-05 18:33:17,607 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3664 | Iter Mean Loss 7.9252
2020-11-05 18:33:17,615 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9606 | Iter Mean Loss 8.4340
2020-11-05 18:33:17,622 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7188 | Iter Mean Loss 8.0910
2020-11-05 18:33:17,624 - root - INFO - Evaluate: Epoch 0353 | NDCG 1.0000 | MSE 0.3382
2020-11-05 18:33:17,632 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0738 | Iter Mean Loss 9.0738
2020-11-05 18:33:17,640 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3045 | Iter Mean Loss 6.1891
2020-11-05 18:33:17,648 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3353 | Iter Mean Loss 7.9045
2020-11-05 18:33:17,655 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9343 | Iter Mean Loss 8.4120
2020-11-05 18:33:17,662 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6986 | Iter Mean Loss 8.0693
2020-11-05 18:33:17,665 - root - INFO - Evaluate: Epoch 0354 | NDCG 1.0000 | MSE 0.3380
2020-11-05 18:33:17,673 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0502 | Iter Mean Loss 9.0502
2020-11-05 18:33:17,680 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2973 | Iter Mean Loss 6.1737
2020-11-05 18:33:17,688 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3043 | Iter Mean Loss 7.8839
2020-11-05 18:33:17,696 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9082 | Iter Mean Loss 8.3900
2020-11-05 18:33:17,703 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6785 | Iter Mean Loss 8.0477
2020-11-05 18:33:17,705 - root - INFO - Evaluate: Epoch 0355 | NDCG 1.0000 | MSE 0.3377
2020-11-05 18:33:17,713 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0267 | Iter Mean Loss 9.0267
2020-11-05 18:33:17,720 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2901 | Iter Mean Loss 6.1584
2020-11-05 18:33:17,727 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2736 | Iter Mean Loss 7.8635
2020-11-05 18:33:17,734 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8822 | Iter Mean Loss 8.3681
2020-11-05 18:33:17,742 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6586 | Iter Mean Loss 8.0262
2020-11-05 18:33:17,744 - root - INFO - Evaluate: Epoch 0356 | NDCG 1.0000 | MSE 0.3375
2020-11-05 18:33:17,751 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0032 | Iter Mean Loss 9.0032
2020-11-05 18:33:17,758 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2829 | Iter Mean Loss 6.1431
2020-11-05 18:33:17,765 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2431 | Iter Mean Loss 7.8431
2020-11-05 18:33:17,772 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8563 | Iter Mean Loss 8.3464
2020-11-05 18:33:17,780 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6389 | Iter Mean Loss 8.0049
2020-11-05 18:33:17,782 - root - INFO - Evaluate: Epoch 0357 | NDCG 1.0000 | MSE 0.3373
2020-11-05 18:33:17,789 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9799 | Iter Mean Loss 8.9799
2020-11-05 18:33:17,796 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2758 | Iter Mean Loss 6.1278
2020-11-05 18:33:17,804 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2128 | Iter Mean Loss 7.8228
2020-11-05 18:33:17,811 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8306 | Iter Mean Loss 8.3247
2020-11-05 18:33:17,819 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6193 | Iter Mean Loss 7.9837
2020-11-05 18:33:17,821 - root - INFO - Evaluate: Epoch 0358 | NDCG 1.0000 | MSE 0.3371
2020-11-05 18:33:17,829 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9565 | Iter Mean Loss 8.9565
2020-11-05 18:33:17,836 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2687 | Iter Mean Loss 6.1126
2020-11-05 18:33:17,844 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1827 | Iter Mean Loss 7.8026
2020-11-05 18:33:17,852 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8049 | Iter Mean Loss 8.3032
2020-11-05 18:33:17,859 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5999 | Iter Mean Loss 7.9625
2020-11-05 18:33:17,861 - root - INFO - Evaluate: Epoch 0359 | NDCG 1.0000 | MSE 0.3369
2020-11-05 18:33:17,869 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9333 | Iter Mean Loss 8.9333
2020-11-05 18:33:17,877 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2616 | Iter Mean Loss 6.0975
2020-11-05 18:33:17,884 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1528 | Iter Mean Loss 7.7826
2020-11-05 18:33:17,892 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7793 | Iter Mean Loss 8.2818
2020-11-05 18:33:17,899 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5807 | Iter Mean Loss 7.9416
2020-11-05 18:33:17,901 - root - INFO - Evaluate: Epoch 0360 | NDCG 1.0000 | MSE 0.3367
2020-11-05 18:33:17,909 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9102 | Iter Mean Loss 8.9102
2020-11-05 18:33:17,916 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 6.0824
2020-11-05 18:33:17,923 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1232 | Iter Mean Loss 7.7626
2020-11-05 18:33:17,930 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7539 | Iter Mean Loss 8.2604
2020-11-05 18:33:17,938 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5616 | Iter Mean Loss 7.9207
2020-11-05 18:33:17,940 - root - INFO - Evaluate: Epoch 0361 | NDCG 1.0000 | MSE 0.3365
2020-11-05 18:33:17,947 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8871 | Iter Mean Loss 8.8871
2020-11-05 18:33:17,954 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2475 | Iter Mean Loss 6.0673
2020-11-05 18:33:17,961 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0937 | Iter Mean Loss 7.7428
2020-11-05 18:33:17,968 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7285 | Iter Mean Loss 8.2392
2020-11-05 18:33:17,975 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5428 | Iter Mean Loss 7.8999
2020-11-05 18:33:17,977 - root - INFO - Evaluate: Epoch 0362 | NDCG 1.0000 | MSE 0.3363
2020-11-05 18:33:17,985 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8642 | Iter Mean Loss 8.8642
2020-11-05 18:33:17,992 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2406 | Iter Mean Loss 6.0524
2020-11-05 18:33:18,000 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0645 | Iter Mean Loss 7.7231
2020-11-05 18:33:18,007 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7033 | Iter Mean Loss 8.2181
2020-11-05 18:33:18,015 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5241 | Iter Mean Loss 7.8793
2020-11-05 18:33:18,017 - root - INFO - Evaluate: Epoch 0363 | NDCG 1.0000 | MSE 0.3361
2020-11-05 18:33:18,025 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8413 | Iter Mean Loss 8.8413
2020-11-05 18:33:18,033 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2337 | Iter Mean Loss 6.0375
2020-11-05 18:33:18,041 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0355 | Iter Mean Loss 7.7035
2020-11-05 18:33:18,048 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6783 | Iter Mean Loss 8.1972
2020-11-05 18:33:18,056 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5055 | Iter Mean Loss 7.8588
2020-11-05 18:33:18,058 - root - INFO - Evaluate: Epoch 0364 | NDCG 1.0000 | MSE 0.3359
2020-11-05 18:33:18,066 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8186 | Iter Mean Loss 8.8186
2020-11-05 18:33:18,074 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2268 | Iter Mean Loss 6.0227
2020-11-05 18:33:18,081 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0066 | Iter Mean Loss 7.6840
2020-11-05 18:33:18,088 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6533 | Iter Mean Loss 8.1763
2020-11-05 18:33:18,096 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4871 | Iter Mean Loss 7.8385
2020-11-05 18:33:18,098 - root - INFO - Evaluate: Epoch 0365 | NDCG 1.0000 | MSE 0.3357
2020-11-05 18:33:18,106 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7960 | Iter Mean Loss 8.7960
2020-11-05 18:33:18,113 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2199 | Iter Mean Loss 6.0079
2020-11-05 18:33:18,121 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9780 | Iter Mean Loss 7.6646
2020-11-05 18:33:18,128 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6285 | Iter Mean Loss 8.1556
2020-11-05 18:33:18,135 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4689 | Iter Mean Loss 7.8183
2020-11-05 18:33:18,137 - root - INFO - Evaluate: Epoch 0366 | NDCG 1.0000 | MSE 0.3355
2020-11-05 18:33:18,144 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7734 | Iter Mean Loss 8.7734
2020-11-05 18:33:18,151 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2131 | Iter Mean Loss 5.9933
2020-11-05 18:33:18,159 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9496 | Iter Mean Loss 7.6454
2020-11-05 18:33:18,166 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6037 | Iter Mean Loss 8.1350
2020-11-05 18:33:18,173 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4509 | Iter Mean Loss 7.7982
2020-11-05 18:33:18,175 - root - INFO - Evaluate: Epoch 0367 | NDCG 1.0000 | MSE 0.3353
2020-11-05 18:33:18,182 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7510 | Iter Mean Loss 8.7510
2020-11-05 18:33:18,190 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2064 | Iter Mean Loss 5.9787
2020-11-05 18:33:18,197 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9214 | Iter Mean Loss 7.6263
2020-11-05 18:33:18,204 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5792 | Iter Mean Loss 8.1145
2020-11-05 18:33:18,212 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4330 | Iter Mean Loss 7.7782
2020-11-05 18:33:18,214 - root - INFO - Evaluate: Epoch 0368 | NDCG 1.0000 | MSE 0.3351
2020-11-05 18:33:18,222 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7288 | Iter Mean Loss 8.7288
2020-11-05 18:33:18,230 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1997 | Iter Mean Loss 5.9642
2020-11-05 18:33:18,237 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8934 | Iter Mean Loss 7.6073
2020-11-05 18:33:18,245 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5547 | Iter Mean Loss 8.0941
2020-11-05 18:33:18,252 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4153 | Iter Mean Loss 7.7584
2020-11-05 18:33:18,255 - root - INFO - Evaluate: Epoch 0369 | NDCG 1.0000 | MSE 0.3350
2020-11-05 18:33:18,263 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7066 | Iter Mean Loss 8.7066
2020-11-05 18:33:18,270 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1930 | Iter Mean Loss 5.9498
2020-11-05 18:33:18,278 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8657 | Iter Mean Loss 7.5884
2020-11-05 18:33:18,285 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5304 | Iter Mean Loss 8.0739
2020-11-05 18:33:18,292 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3977 | Iter Mean Loss 7.7387
2020-11-05 18:33:18,295 - root - INFO - Evaluate: Epoch 0370 | NDCG 1.0000 | MSE 0.3348
2020-11-05 18:33:18,303 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6846 | Iter Mean Loss 8.6846
2020-11-05 18:33:18,311 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1864 | Iter Mean Loss 5.9355
2020-11-05 18:33:18,320 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8381 | Iter Mean Loss 7.5697
2020-11-05 18:33:18,328 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5062 | Iter Mean Loss 8.0538
2020-11-05 18:33:18,336 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3803 | Iter Mean Loss 7.7191
2020-11-05 18:33:18,338 - root - INFO - Evaluate: Epoch 0371 | NDCG 1.0000 | MSE 0.3346
2020-11-05 18:33:18,345 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6628 | Iter Mean Loss 8.6628
2020-11-05 18:33:18,353 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1799 | Iter Mean Loss 5.9213
2020-11-05 18:33:18,360 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 7.5511
2020-11-05 18:33:18,367 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 8.0339
2020-11-05 18:33:18,374 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3631 | Iter Mean Loss 7.6997
2020-11-05 18:33:18,376 - root - INFO - Evaluate: Epoch 0372 | NDCG 1.0000 | MSE 0.3344
2020-11-05 18:33:18,384 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6410 | Iter Mean Loss 8.6410
2020-11-05 18:33:18,391 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.9072
2020-11-05 18:33:18,399 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7835 | Iter Mean Loss 7.5326
2020-11-05 18:33:18,406 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4582 | Iter Mean Loss 8.0140
2020-11-05 18:33:18,413 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3460 | Iter Mean Loss 7.6804
2020-11-05 18:33:18,416 - root - INFO - Evaluate: Epoch 0373 | NDCG 1.0000 | MSE 0.3343
2020-11-05 18:33:18,423 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6194 | Iter Mean Loss 8.6194
2020-11-05 18:33:18,431 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1669 | Iter Mean Loss 5.8932
2020-11-05 18:33:18,439 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7566 | Iter Mean Loss 7.5143
2020-11-05 18:33:18,446 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4344 | Iter Mean Loss 7.9943
2020-11-05 18:33:18,454 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3291 | Iter Mean Loss 7.6613
2020-11-05 18:33:18,456 - root - INFO - Evaluate: Epoch 0374 | NDCG 1.0000 | MSE 0.3341
2020-11-05 18:33:18,464 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5980 | Iter Mean Loss 8.5980
2020-11-05 18:33:18,471 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1605 | Iter Mean Loss 5.8792
2020-11-05 18:33:18,479 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7298 | Iter Mean Loss 7.4961
2020-11-05 18:33:18,486 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4108 | Iter Mean Loss 7.9748
2020-11-05 18:33:18,494 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3124 | Iter Mean Loss 7.6423
2020-11-05 18:33:18,496 - root - INFO - Evaluate: Epoch 0375 | NDCG 1.0000 | MSE 0.3339
2020-11-05 18:33:18,504 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5767
2020-11-05 18:33:18,512 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 5.8654
2020-11-05 18:33:18,519 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7033 | Iter Mean Loss 7.4780
2020-11-05 18:33:18,526 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3873 | Iter Mean Loss 7.9553
2020-11-05 18:33:18,533 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2958 | Iter Mean Loss 7.6234
2020-11-05 18:33:18,535 - root - INFO - Evaluate: Epoch 0376 | NDCG 1.0000 | MSE 0.3338
2020-11-05 18:33:18,543 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5555 | Iter Mean Loss 8.5555
2020-11-05 18:33:18,550 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1479 | Iter Mean Loss 5.8517
2020-11-05 18:33:18,557 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6769 | Iter Mean Loss 7.4601
2020-11-05 18:33:18,564 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3639 | Iter Mean Loss 7.9360
2020-11-05 18:33:18,571 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2793 | Iter Mean Loss 7.6047
2020-11-05 18:33:18,573 - root - INFO - Evaluate: Epoch 0377 | NDCG 1.0000 | MSE 0.3336
2020-11-05 18:33:18,581 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5346 | Iter Mean Loss 8.5346
2020-11-05 18:33:18,588 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1416 | Iter Mean Loss 5.8381
2020-11-05 18:33:18,596 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6507 | Iter Mean Loss 7.4423
2020-11-05 18:33:18,603 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3407 | Iter Mean Loss 7.9169
2020-11-05 18:33:18,610 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2630 | Iter Mean Loss 7.5861
2020-11-05 18:33:18,612 - root - INFO - Evaluate: Epoch 0378 | NDCG 1.0000 | MSE 0.3335
2020-11-05 18:33:18,620 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5137 | Iter Mean Loss 8.5137
2020-11-05 18:33:18,628 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1355 | Iter Mean Loss 5.8246
2020-11-05 18:33:18,635 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6248 | Iter Mean Loss 7.4246
2020-11-05 18:33:18,643 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3176 | Iter Mean Loss 7.8979
2020-11-05 18:33:18,650 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2468 | Iter Mean Loss 7.5677
2020-11-05 18:33:18,653 - root - INFO - Evaluate: Epoch 0379 | NDCG 1.0000 | MSE 0.3333
2020-11-05 18:33:18,661 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4930 | Iter Mean Loss 8.4930
2020-11-05 18:33:18,668 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1293 | Iter Mean Loss 5.8112
2020-11-05 18:33:18,676 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5990 | Iter Mean Loss 7.4071
2020-11-05 18:33:18,683 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2946 | Iter Mean Loss 7.8790
2020-11-05 18:33:18,691 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2308 | Iter Mean Loss 7.5494
2020-11-05 18:33:18,693 - root - INFO - Evaluate: Epoch 0380 | NDCG 1.0000 | MSE 0.3332
2020-11-05 18:33:18,701 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4725 | Iter Mean Loss 8.4725
2020-11-05 18:33:18,709 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1233 | Iter Mean Loss 5.7979
2020-11-05 18:33:18,717 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 7.3897
2020-11-05 18:33:18,724 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2718 | Iter Mean Loss 7.8602
2020-11-05 18:33:18,732 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2150 | Iter Mean Loss 7.5312
2020-11-05 18:33:18,734 - root - INFO - Evaluate: Epoch 0381 | NDCG 1.0000 | MSE 0.3330
2020-11-05 18:33:18,742 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 18:33:18,749 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1172 | Iter Mean Loss 5.7847
2020-11-05 18:33:18,756 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5480 | Iter Mean Loss 7.3725
2020-11-05 18:33:18,763 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2491 | Iter Mean Loss 7.8416
2020-11-05 18:33:18,770 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 7.5132
2020-11-05 18:33:18,772 - root - INFO - Evaluate: Epoch 0382 | NDCG 1.0000 | MSE 0.3329
2020-11-05 18:33:18,780 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4320 | Iter Mean Loss 8.4320
2020-11-05 18:33:18,787 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1113 | Iter Mean Loss 5.7716
2020-11-05 18:33:18,794 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5228 | Iter Mean Loss 7.3554
2020-11-05 18:33:18,801 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2266 | Iter Mean Loss 7.8232
2020-11-05 18:33:18,808 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1836 | Iter Mean Loss 7.4953
2020-11-05 18:33:18,810 - root - INFO - Evaluate: Epoch 0383 | NDCG 1.0000 | MSE 0.3327
2020-11-05 18:33:18,819 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4119 | Iter Mean Loss 8.4119
2020-11-05 18:33:18,826 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1054 | Iter Mean Loss 5.7587
2020-11-05 18:33:18,833 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4978 | Iter Mean Loss 7.3384
2020-11-05 18:33:18,841 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2042 | Iter Mean Loss 7.8048
2020-11-05 18:33:18,848 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1682 | Iter Mean Loss 7.4775
2020-11-05 18:33:18,850 - root - INFO - Evaluate: Epoch 0384 | NDCG 1.0000 | MSE 0.3326
2020-11-05 18:33:18,858 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3921 | Iter Mean Loss 8.3921
2020-11-05 18:33:18,866 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0996 | Iter Mean Loss 5.7458
2020-11-05 18:33:18,873 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4730 | Iter Mean Loss 7.3215
2020-11-05 18:33:18,881 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1820 | Iter Mean Loss 7.7867
2020-11-05 18:33:18,888 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1529 | Iter Mean Loss 7.4599
2020-11-05 18:33:18,891 - root - INFO - Evaluate: Epoch 0385 | NDCG 1.0000 | MSE 0.3324
2020-11-05 18:33:18,898 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3724 | Iter Mean Loss 8.3724
2020-11-05 18:33:18,907 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0938 | Iter Mean Loss 5.7331
2020-11-05 18:33:18,914 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4483 | Iter Mean Loss 7.3048
2020-11-05 18:33:18,921 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1599 | Iter Mean Loss 7.7686
2020-11-05 18:33:18,929 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1377 | Iter Mean Loss 7.4424
2020-11-05 18:33:18,931 - root - INFO - Evaluate: Epoch 0386 | NDCG 1.0000 | MSE 0.3323
2020-11-05 18:33:18,939 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3528 | Iter Mean Loss 8.3528
2020-11-05 18:33:18,946 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0880 | Iter Mean Loss 5.7204
2020-11-05 18:33:18,953 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4239 | Iter Mean Loss 7.2883
2020-11-05 18:33:18,960 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1379 | Iter Mean Loss 7.7507
2020-11-05 18:33:18,967 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1227 | Iter Mean Loss 7.4251
2020-11-05 18:33:18,969 - root - INFO - Evaluate: Epoch 0387 | NDCG 1.0000 | MSE 0.3322
2020-11-05 18:33:18,977 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.3335
2020-11-05 18:33:18,984 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0824 | Iter Mean Loss 5.7079
2020-11-05 18:33:18,991 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3996 | Iter Mean Loss 7.2718
2020-11-05 18:33:18,998 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1161 | Iter Mean Loss 7.7329
2020-11-05 18:33:19,005 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1077 | Iter Mean Loss 7.4079
2020-11-05 18:33:19,007 - root - INFO - Evaluate: Epoch 0388 | NDCG 1.0000 | MSE 0.3320
2020-11-05 18:33:19,016 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3143 | Iter Mean Loss 8.3143
2020-11-05 18:33:19,023 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0768 | Iter Mean Loss 5.6955
2020-11-05 18:33:19,031 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3755 | Iter Mean Loss 7.2555
2020-11-05 18:33:19,038 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0945 | Iter Mean Loss 7.7153
2020-11-05 18:33:19,046 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0929 | Iter Mean Loss 7.3908
2020-11-05 18:33:19,048 - root - INFO - Evaluate: Epoch 0389 | NDCG 1.0000 | MSE 0.3319
2020-11-05 18:33:19,056 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2953 | Iter Mean Loss 8.2953
2020-11-05 18:33:19,063 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0712 | Iter Mean Loss 5.6832
2020-11-05 18:33:19,071 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3516 | Iter Mean Loss 7.2393
2020-11-05 18:33:19,079 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0729 | Iter Mean Loss 7.6977
2020-11-05 18:33:19,086 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0783 | Iter Mean Loss 7.3738
2020-11-05 18:33:19,088 - root - INFO - Evaluate: Epoch 0390 | NDCG 1.0000 | MSE 0.3318
2020-11-05 18:33:19,096 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2764 | Iter Mean Loss 8.2764
2020-11-05 18:33:19,104 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0657 | Iter Mean Loss 5.6711
2020-11-05 18:33:19,112 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3278 | Iter Mean Loss 7.2233
2020-11-05 18:33:19,119 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0516 | Iter Mean Loss 7.6804
2020-11-05 18:33:19,127 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0637 | Iter Mean Loss 7.3570
2020-11-05 18:33:19,129 - root - INFO - Evaluate: Epoch 0391 | NDCG 1.0000 | MSE 0.3317
2020-11-05 18:33:19,137 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2577 | Iter Mean Loss 8.2577
2020-11-05 18:33:19,144 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0603 | Iter Mean Loss 5.6590
2020-11-05 18:33:19,151 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3042 | Iter Mean Loss 7.2074
2020-11-05 18:33:19,158 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0303 | Iter Mean Loss 7.6631
2020-11-05 18:33:19,165 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0493 | Iter Mean Loss 7.3404
2020-11-05 18:33:19,167 - root - INFO - Evaluate: Epoch 0392 | NDCG 1.0000 | MSE 0.3315
2020-11-05 18:33:19,175 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2392 | Iter Mean Loss 8.2392
2020-11-05 18:33:19,182 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0549 | Iter Mean Loss 5.6470
2020-11-05 18:33:19,189 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2808 | Iter Mean Loss 7.1916
2020-11-05 18:33:19,196 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0092 | Iter Mean Loss 7.6460
2020-11-05 18:33:19,203 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0350 | Iter Mean Loss 7.3238
2020-11-05 18:33:19,205 - root - INFO - Evaluate: Epoch 0393 | NDCG 1.0000 | MSE 0.3314
2020-11-05 18:33:19,213 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2208 | Iter Mean Loss 8.2208
2020-11-05 18:33:19,220 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0495 | Iter Mean Loss 5.6352
2020-11-05 18:33:19,228 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2576 | Iter Mean Loss 7.1760
2020-11-05 18:33:19,235 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9883 | Iter Mean Loss 7.6291
2020-11-05 18:33:19,243 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0208 | Iter Mean Loss 7.3074
2020-11-05 18:33:19,245 - root - INFO - Evaluate: Epoch 0394 | NDCG 1.0000 | MSE 0.3313
2020-11-05 18:33:19,253 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2026 | Iter Mean Loss 8.2026
2020-11-05 18:33:19,261 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0443 | Iter Mean Loss 5.6234
2020-11-05 18:33:19,268 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2345 | Iter Mean Loss 7.1605
2020-11-05 18:33:19,276 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9675 | Iter Mean Loss 7.6122
2020-11-05 18:33:19,284 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0067 | Iter Mean Loss 7.2911
2020-11-05 18:33:19,286 - root - INFO - Evaluate: Epoch 0395 | NDCG 1.0000 | MSE 0.3312
2020-11-05 18:33:19,294 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1846 | Iter Mean Loss 8.1846
2020-11-05 18:33:19,302 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0390 | Iter Mean Loss 5.6118
2020-11-05 18:33:19,310 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2116 | Iter Mean Loss 7.1451
2020-11-05 18:33:19,319 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 7.5955
2020-11-05 18:33:19,327 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9927 | Iter Mean Loss 7.2749
2020-11-05 18:33:19,329 - root - INFO - Evaluate: Epoch 0396 | NDCG 1.0000 | MSE 0.3310
2020-11-05 18:33:19,337 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1667 | Iter Mean Loss 8.1667
2020-11-05 18:33:19,345 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0339 | Iter Mean Loss 5.6003
2020-11-05 18:33:19,352 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1889 | Iter Mean Loss 7.1298
2020-11-05 18:33:19,359 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9263 | Iter Mean Loss 7.5789
2020-11-05 18:33:19,366 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9788 | Iter Mean Loss 7.2589
2020-11-05 18:33:19,368 - root - INFO - Evaluate: Epoch 0397 | NDCG 1.0000 | MSE 0.3309
2020-11-05 18:33:19,376 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1490 | Iter Mean Loss 8.1490
2020-11-05 18:33:19,384 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0287 | Iter Mean Loss 5.5889
2020-11-05 18:33:19,391 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1663 | Iter Mean Loss 7.1147
2020-11-05 18:33:19,398 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9059 | Iter Mean Loss 7.5625
2020-11-05 18:33:19,405 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9650 | Iter Mean Loss 7.2430
2020-11-05 18:33:19,407 - root - INFO - Evaluate: Epoch 0398 | NDCG 1.0000 | MSE 0.3308
2020-11-05 18:33:19,418 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1315 | Iter Mean Loss 8.1315
2020-11-05 18:33:19,432 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0237 | Iter Mean Loss 5.5776
2020-11-05 18:33:19,444 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1439 | Iter Mean Loss 7.0997
2020-11-05 18:33:19,454 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8856 | Iter Mean Loss 7.5462
2020-11-05 18:33:19,465 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 7.2272
2020-11-05 18:33:19,467 - root - INFO - Evaluate: Epoch 0399 | NDCG 1.0000 | MSE 0.3307
2020-11-05 18:33:19,477 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1141 | Iter Mean Loss 8.1141
2020-11-05 18:33:19,486 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0187 | Iter Mean Loss 5.5664
2020-11-05 18:33:19,497 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1216 | Iter Mean Loss 7.0848
2020-11-05 18:33:19,508 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8655 | Iter Mean Loss 7.5300
2020-11-05 18:33:19,520 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9378 | Iter Mean Loss 7.2115
2020-11-05 18:33:19,523 - root - INFO - Evaluate: Epoch 0400 | NDCG 1.0000 | MSE 0.3306
2020-11-05 18:33:19,533 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0969 | Iter Mean Loss 8.0969
2020-11-05 18:33:19,541 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0137 | Iter Mean Loss 5.5553
2020-11-05 18:33:19,550 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0995 | Iter Mean Loss 7.0700
2020-11-05 18:33:19,557 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8455 | Iter Mean Loss 7.5139
2020-11-05 18:33:19,565 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9243 | Iter Mean Loss 7.1960
2020-11-05 18:33:19,567 - root - INFO - Evaluate: Epoch 0401 | NDCG 1.0000 | MSE 0.3305
2020-11-05 18:33:19,575 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0799 | Iter Mean Loss 8.0799
2020-11-05 18:33:19,584 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0088 | Iter Mean Loss 5.5443
2020-11-05 18:33:19,594 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0775 | Iter Mean Loss 7.0554
2020-11-05 18:33:19,603 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8257 | Iter Mean Loss 7.4979
2020-11-05 18:33:19,610 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9110 | Iter Mean Loss 7.1806
2020-11-05 18:33:19,612 - root - INFO - Evaluate: Epoch 0402 | NDCG 1.0000 | MSE 0.3304
2020-11-05 18:33:19,619 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0630 | Iter Mean Loss 8.0630
2020-11-05 18:33:19,627 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0039 | Iter Mean Loss 5.5334
2020-11-05 18:33:19,634 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0557 | Iter Mean Loss 7.0409
2020-11-05 18:33:19,641 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8059 | Iter Mean Loss 7.4821
2020-11-05 18:33:19,649 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8977 | Iter Mean Loss 7.1652
2020-11-05 18:33:19,651 - root - INFO - Evaluate: Epoch 0403 | NDCG 1.0000 | MSE 0.3303
2020-11-05 18:33:19,659 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0462 | Iter Mean Loss 8.0462
2020-11-05 18:33:19,666 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9991 | Iter Mean Loss 5.5227
2020-11-05 18:33:19,674 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0340 | Iter Mean Loss 7.0264
2020-11-05 18:33:19,681 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7864 | Iter Mean Loss 7.4664
2020-11-05 18:33:19,689 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8845 | Iter Mean Loss 7.1500
2020-11-05 18:33:19,691 - root - INFO - Evaluate: Epoch 0404 | NDCG 1.0000 | MSE 0.3302
2020-11-05 18:33:19,699 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0297 | Iter Mean Loss 8.0297
2020-11-05 18:33:19,707 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9943 | Iter Mean Loss 5.5120
2020-11-05 18:33:19,714 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0125 | Iter Mean Loss 7.0122
2020-11-05 18:33:19,722 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7669 | Iter Mean Loss 7.4508
2020-11-05 18:33:19,729 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8714 | Iter Mean Loss 7.1350
2020-11-05 18:33:19,731 - root - INFO - Evaluate: Epoch 0405 | NDCG 1.0000 | MSE 0.3301
2020-11-05 18:33:19,740 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0132 | Iter Mean Loss 8.0132
2020-11-05 18:33:19,747 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9896 | Iter Mean Loss 5.5014
2020-11-05 18:33:19,755 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9911 | Iter Mean Loss 6.9980
2020-11-05 18:33:19,762 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7476 | Iter Mean Loss 7.4354
2020-11-05 18:33:19,770 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8584 | Iter Mean Loss 7.1200
2020-11-05 18:33:19,772 - root - INFO - Evaluate: Epoch 0406 | NDCG 1.0000 | MSE 0.3300
2020-11-05 18:33:19,779 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9970 | Iter Mean Loss 7.9970
2020-11-05 18:33:19,787 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9849 | Iter Mean Loss 5.4909
2020-11-05 18:33:19,794 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9699 | Iter Mean Loss 6.9839
2020-11-05 18:33:19,801 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7284 | Iter Mean Loss 7.4200
2020-11-05 18:33:19,808 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8454 | Iter Mean Loss 7.1051
2020-11-05 18:33:19,810 - root - INFO - Evaluate: Epoch 0407 | NDCG 1.0000 | MSE 0.3299
2020-11-05 18:33:19,817 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9808 | Iter Mean Loss 7.9808
2020-11-05 18:33:19,825 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9803 | Iter Mean Loss 5.4806
2020-11-05 18:33:19,832 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9488 | Iter Mean Loss 6.9700
2020-11-05 18:33:19,839 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7094 | Iter Mean Loss 7.4048
2020-11-05 18:33:19,847 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8326 | Iter Mean Loss 7.0904
2020-11-05 18:33:19,849 - root - INFO - Evaluate: Epoch 0408 | NDCG 1.0000 | MSE 0.3298
2020-11-05 18:33:19,856 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9649 | Iter Mean Loss 7.9649
2020-11-05 18:33:19,864 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9757 | Iter Mean Loss 5.4703
2020-11-05 18:33:19,871 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9278 | Iter Mean Loss 6.9561
2020-11-05 18:33:19,879 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6904 | Iter Mean Loss 7.3897
2020-11-05 18:33:19,886 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8198 | Iter Mean Loss 7.0757
2020-11-05 18:33:19,889 - root - INFO - Evaluate: Epoch 0409 | NDCG 1.0000 | MSE 0.3297
2020-11-05 18:33:19,896 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9490 | Iter Mean Loss 7.9490
2020-11-05 18:33:19,904 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9712 | Iter Mean Loss 5.4601
2020-11-05 18:33:19,911 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9070 | Iter Mean Loss 6.9424
2020-11-05 18:33:19,919 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6716 | Iter Mean Loss 7.3747
2020-11-05 18:33:19,927 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8072 | Iter Mean Loss 7.0612
2020-11-05 18:33:19,929 - root - INFO - Evaluate: Epoch 0410 | NDCG 1.0000 | MSE 0.3296
2020-11-05 18:33:19,937 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9334 | Iter Mean Loss 7.9334
2020-11-05 18:33:19,945 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9667 | Iter Mean Loss 5.4500
2020-11-05 18:33:19,952 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 6.9288
2020-11-05 18:33:19,960 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6530 | Iter Mean Loss 7.3598
2020-11-05 18:33:19,967 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7945 | Iter Mean Loss 7.0468
2020-11-05 18:33:19,969 - root - INFO - Evaluate: Epoch 0411 | NDCG 1.0000 | MSE 0.3295
2020-11-05 18:33:19,976 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9178 | Iter Mean Loss 7.9178
2020-11-05 18:33:19,983 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9622 | Iter Mean Loss 5.4400
2020-11-05 18:33:19,991 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8657 | Iter Mean Loss 6.9153
2020-11-05 18:33:19,998 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6344 | Iter Mean Loss 7.3450
2020-11-05 18:33:20,005 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7820 | Iter Mean Loss 7.0324
2020-11-05 18:33:20,007 - root - INFO - Evaluate: Epoch 0412 | NDCG 1.0000 | MSE 0.3294
2020-11-05 18:33:20,015 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9025 | Iter Mean Loss 7.9025
2020-11-05 18:33:20,022 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9578 | Iter Mean Loss 5.4301
2020-11-05 18:33:20,030 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8453 | Iter Mean Loss 6.9018
2020-11-05 18:33:20,037 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6160 | Iter Mean Loss 7.3304
2020-11-05 18:33:20,044 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7696 | Iter Mean Loss 7.0182
2020-11-05 18:33:20,046 - root - INFO - Evaluate: Epoch 0413 | NDCG 1.0000 | MSE 0.3293
2020-11-05 18:33:20,055 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8872 | Iter Mean Loss 7.8872
2020-11-05 18:33:20,062 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 5.4203
2020-11-05 18:33:20,069 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8250 | Iter Mean Loss 6.8885
2020-11-05 18:33:20,077 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5977 | Iter Mean Loss 7.3158
2020-11-05 18:33:20,084 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7572 | Iter Mean Loss 7.0041
2020-11-05 18:33:20,086 - root - INFO - Evaluate: Epoch 0414 | NDCG 1.0000 | MSE 0.3292
2020-11-05 18:33:20,095 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8721 | Iter Mean Loss 7.8721
2020-11-05 18:33:20,102 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9491 | Iter Mean Loss 5.4106
2020-11-05 18:33:20,110 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8048 | Iter Mean Loss 6.8753
2020-11-05 18:33:20,117 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5795 | Iter Mean Loss 7.3014
2020-11-05 18:33:20,125 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7449 | Iter Mean Loss 6.9901
2020-11-05 18:33:20,127 - root - INFO - Evaluate: Epoch 0415 | NDCG 1.0000 | MSE 0.3291
2020-11-05 18:33:20,135 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8571 | Iter Mean Loss 7.8571
2020-11-05 18:33:20,143 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9448 | Iter Mean Loss 5.4010
2020-11-05 18:33:20,151 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7847 | Iter Mean Loss 6.8622
2020-11-05 18:33:20,158 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5615 | Iter Mean Loss 7.2870
2020-11-05 18:33:20,166 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7326 | Iter Mean Loss 6.9761
2020-11-05 18:33:20,168 - root - INFO - Evaluate: Epoch 0416 | NDCG 1.0000 | MSE 0.3290
2020-11-05 18:33:20,175 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8423 | Iter Mean Loss 7.8423
2020-11-05 18:33:20,183 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9405 | Iter Mean Loss 5.3914
2020-11-05 18:33:20,190 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7648 | Iter Mean Loss 6.8492
2020-11-05 18:33:20,197 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5435 | Iter Mean Loss 7.2728
2020-11-05 18:33:20,204 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7205 | Iter Mean Loss 6.9623
2020-11-05 18:33:20,206 - root - INFO - Evaluate: Epoch 0417 | NDCG 1.0000 | MSE 0.3289
2020-11-05 18:33:20,213 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 7.8276
2020-11-05 18:33:20,220 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 5.3820
2020-11-05 18:33:20,228 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7449 | Iter Mean Loss 6.8363
2020-11-05 18:33:20,235 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5257 | Iter Mean Loss 7.2586
2020-11-05 18:33:20,242 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7083 | Iter Mean Loss 6.9486
2020-11-05 18:33:20,244 - root - INFO - Evaluate: Epoch 0418 | NDCG 1.0000 | MSE 0.3288
2020-11-05 18:33:20,252 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8131 | Iter Mean Loss 7.8131
2020-11-05 18:33:20,260 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9321 | Iter Mean Loss 5.3726
2020-11-05 18:33:20,267 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7252 | Iter Mean Loss 6.8235
2020-11-05 18:33:20,274 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5080 | Iter Mean Loss 7.2446
2020-11-05 18:33:20,282 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6963 | Iter Mean Loss 6.9349
2020-11-05 18:33:20,284 - root - INFO - Evaluate: Epoch 0419 | NDCG 1.0000 | MSE 0.3287
2020-11-05 18:33:20,292 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7986 | Iter Mean Loss 7.7986
2020-11-05 18:33:20,300 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9279 | Iter Mean Loss 5.3633
2020-11-05 18:33:20,307 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7056 | Iter Mean Loss 6.8107
2020-11-05 18:33:20,316 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4904 | Iter Mean Loss 7.2307
2020-11-05 18:33:20,324 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6843 | Iter Mean Loss 6.9214
2020-11-05 18:33:20,327 - root - INFO - Evaluate: Epoch 0420 | NDCG 1.0000 | MSE 0.3286
2020-11-05 18:33:20,337 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7843 | Iter Mean Loss 7.7843
2020-11-05 18:33:20,346 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9238 | Iter Mean Loss 5.3541
2020-11-05 18:33:20,354 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6862 | Iter Mean Loss 6.7981
2020-11-05 18:33:20,363 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4729 | Iter Mean Loss 7.2168
2020-11-05 18:33:20,371 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6724 | Iter Mean Loss 6.9079
2020-11-05 18:33:20,373 - root - INFO - Evaluate: Epoch 0421 | NDCG 1.0000 | MSE 0.3285
2020-11-05 18:33:20,382 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7701 | Iter Mean Loss 7.7701
2020-11-05 18:33:20,391 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9197 | Iter Mean Loss 5.3449
2020-11-05 18:33:20,398 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6668 | Iter Mean Loss 6.7856
2020-11-05 18:33:20,406 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4555 | Iter Mean Loss 7.2031
2020-11-05 18:33:20,414 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6605 | Iter Mean Loss 6.8946
2020-11-05 18:33:20,416 - root - INFO - Evaluate: Epoch 0422 | NDCG 1.0000 | MSE 0.3284
2020-11-05 18:33:20,424 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7561 | Iter Mean Loss 7.7561
2020-11-05 18:33:20,432 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9157 | Iter Mean Loss 5.3359
2020-11-05 18:33:20,439 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6476 | Iter Mean Loss 6.7731
2020-11-05 18:33:20,447 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4383 | Iter Mean Loss 7.1894
2020-11-05 18:33:20,455 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6488 | Iter Mean Loss 6.8813
2020-11-05 18:33:20,457 - root - INFO - Evaluate: Epoch 0423 | NDCG 1.0000 | MSE 0.3284
2020-11-05 18:33:20,466 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7422 | Iter Mean Loss 7.7422
2020-11-05 18:33:20,474 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9117 | Iter Mean Loss 5.3269
2020-11-05 18:33:20,482 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6284 | Iter Mean Loss 6.7608
2020-11-05 18:33:20,490 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4211 | Iter Mean Loss 7.1758
2020-11-05 18:33:20,499 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6370 | Iter Mean Loss 6.8681
2020-11-05 18:33:20,501 - root - INFO - Evaluate: Epoch 0424 | NDCG 1.0000 | MSE 0.3283
2020-11-05 18:33:20,510 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7284 | Iter Mean Loss 7.7284
2020-11-05 18:33:20,518 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9077 | Iter Mean Loss 5.3180
2020-11-05 18:33:20,526 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6094 | Iter Mean Loss 6.7485
2020-11-05 18:33:20,534 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4041 | Iter Mean Loss 7.1624
2020-11-05 18:33:20,542 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6253 | Iter Mean Loss 6.8550
2020-11-05 18:33:20,545 - root - INFO - Evaluate: Epoch 0425 | NDCG 1.0000 | MSE 0.3282
2020-11-05 18:33:20,554 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7147 | Iter Mean Loss 7.7147
2020-11-05 18:33:20,562 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9037 | Iter Mean Loss 5.3092
2020-11-05 18:33:20,570 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5905 | Iter Mean Loss 6.7363
2020-11-05 18:33:20,578 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3871 | Iter Mean Loss 7.1490
2020-11-05 18:33:20,585 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6137 | Iter Mean Loss 6.8419
2020-11-05 18:33:20,587 - root - INFO - Evaluate: Epoch 0426 | NDCG 1.0000 | MSE 0.3281
2020-11-05 18:33:20,596 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.7011 | Iter Mean Loss 7.7011
2020-11-05 18:33:20,603 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8998 | Iter Mean Loss 5.3005
2020-11-05 18:33:20,611 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5716 | Iter Mean Loss 6.7242
2020-11-05 18:33:20,618 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3703 | Iter Mean Loss 7.1357
2020-11-05 18:33:20,626 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6021 | Iter Mean Loss 6.8290
2020-11-05 18:33:20,628 - root - INFO - Evaluate: Epoch 0427 | NDCG 1.0000 | MSE 0.3280
2020-11-05 18:33:20,636 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6877 | Iter Mean Loss 7.6877
2020-11-05 18:33:20,644 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8959 | Iter Mean Loss 5.2918
2020-11-05 18:33:20,651 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5529 | Iter Mean Loss 6.7122
2020-11-05 18:33:20,659 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3536 | Iter Mean Loss 7.1225
2020-11-05 18:33:20,667 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5906 | Iter Mean Loss 6.8161
2020-11-05 18:33:20,669 - root - INFO - Evaluate: Epoch 0428 | NDCG 1.0000 | MSE 0.3279
2020-11-05 18:33:20,678 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6743 | Iter Mean Loss 7.6743
2020-11-05 18:33:20,685 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8920 | Iter Mean Loss 5.2832
2020-11-05 18:33:20,694 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5343 | Iter Mean Loss 6.7002
2020-11-05 18:33:20,702 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3370 | Iter Mean Loss 7.1094
2020-11-05 18:33:20,710 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5791 | Iter Mean Loss 6.8034
2020-11-05 18:33:20,712 - root - INFO - Evaluate: Epoch 0429 | NDCG 1.0000 | MSE 0.3278
2020-11-05 18:33:20,721 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6611 | Iter Mean Loss 7.6611
2020-11-05 18:33:20,729 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8882 | Iter Mean Loss 5.2747
2020-11-05 18:33:20,737 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 6.6884
2020-11-05 18:33:20,745 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3204 | Iter Mean Loss 7.0964
2020-11-05 18:33:20,753 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5677 | Iter Mean Loss 6.7907
2020-11-05 18:33:20,755 - root - INFO - Evaluate: Epoch 0430 | NDCG 1.0000 | MSE 0.3278
2020-11-05 18:33:20,765 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6480 | Iter Mean Loss 7.6480
2020-11-05 18:33:20,772 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8844 | Iter Mean Loss 5.2662
2020-11-05 18:33:20,781 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4974 | Iter Mean Loss 6.6766
2020-11-05 18:33:20,788 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3040 | Iter Mean Loss 7.0834
2020-11-05 18:33:20,796 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5564 | Iter Mean Loss 6.7780
2020-11-05 18:33:20,798 - root - INFO - Evaluate: Epoch 0431 | NDCG 1.0000 | MSE 0.3277
2020-11-05 18:33:20,806 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6350 | Iter Mean Loss 7.6350
2020-11-05 18:33:20,814 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8806 | Iter Mean Loss 5.2578
2020-11-05 18:33:20,821 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4791 | Iter Mean Loss 6.6649
2020-11-05 18:33:20,828 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 7.0706
2020-11-05 18:33:20,836 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5451 | Iter Mean Loss 6.7655
2020-11-05 18:33:20,838 - root - INFO - Evaluate: Epoch 0432 | NDCG 1.0000 | MSE 0.3276
2020-11-05 18:33:20,846 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6221 | Iter Mean Loss 7.6221
2020-11-05 18:33:20,853 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8768 | Iter Mean Loss 5.2495
2020-11-05 18:33:20,861 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4609 | Iter Mean Loss 6.6533
2020-11-05 18:33:20,868 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2714 | Iter Mean Loss 7.0578
2020-11-05 18:33:20,876 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5338 | Iter Mean Loss 6.7530
2020-11-05 18:33:20,878 - root - INFO - Evaluate: Epoch 0433 | NDCG 1.0000 | MSE 0.3275
2020-11-05 18:33:20,887 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.6093 | Iter Mean Loss 7.6093
2020-11-05 18:33:20,895 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8731 | Iter Mean Loss 5.2412
2020-11-05 18:33:20,903 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4427 | Iter Mean Loss 6.6417
2020-11-05 18:33:20,911 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2553 | Iter Mean Loss 7.0451
2020-11-05 18:33:20,919 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5226 | Iter Mean Loss 6.7406
2020-11-05 18:33:20,922 - root - INFO - Evaluate: Epoch 0434 | NDCG 1.0000 | MSE 0.3274
2020-11-05 18:33:20,931 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5966 | Iter Mean Loss 7.5966
2020-11-05 18:33:20,939 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8694 | Iter Mean Loss 5.2330
2020-11-05 18:33:20,947 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4247 | Iter Mean Loss 6.6302
2020-11-05 18:33:20,955 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2393 | Iter Mean Loss 7.0325
2020-11-05 18:33:20,963 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5114 | Iter Mean Loss 6.7283
2020-11-05 18:33:20,965 - root - INFO - Evaluate: Epoch 0435 | NDCG 1.0000 | MSE 0.3274
2020-11-05 18:33:20,974 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5840 | Iter Mean Loss 7.5840
2020-11-05 18:33:20,982 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8657 | Iter Mean Loss 5.2249
2020-11-05 18:33:20,989 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4068 | Iter Mean Loss 6.6188
2020-11-05 18:33:20,997 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2233 | Iter Mean Loss 7.0200
2020-11-05 18:33:21,004 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5003 | Iter Mean Loss 6.7160
2020-11-05 18:33:21,006 - root - INFO - Evaluate: Epoch 0436 | NDCG 1.0000 | MSE 0.3273
2020-11-05 18:33:21,015 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5716 | Iter Mean Loss 7.5716
2020-11-05 18:33:21,023 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8620 | Iter Mean Loss 5.2168
2020-11-05 18:33:21,030 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3889 | Iter Mean Loss 6.6075
2020-11-05 18:33:21,038 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2075 | Iter Mean Loss 7.0075
2020-11-05 18:33:21,045 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4892 | Iter Mean Loss 6.7038
2020-11-05 18:33:21,047 - root - INFO - Evaluate: Epoch 0437 | NDCG 1.0000 | MSE 0.3272
2020-11-05 18:33:21,055 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5592 | Iter Mean Loss 7.5592
2020-11-05 18:33:21,063 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8584 | Iter Mean Loss 5.2088
2020-11-05 18:33:21,070 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3712 | Iter Mean Loss 6.5962
2020-11-05 18:33:21,079 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1917 | Iter Mean Loss 6.9951
2020-11-05 18:33:21,086 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4782 | Iter Mean Loss 6.6917
2020-11-05 18:33:21,089 - root - INFO - Evaluate: Epoch 0438 | NDCG 1.0000 | MSE 0.3271
2020-11-05 18:33:21,097 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5469 | Iter Mean Loss 7.5469
2020-11-05 18:33:21,105 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8548 | Iter Mean Loss 5.2008
2020-11-05 18:33:21,114 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3535 | Iter Mean Loss 6.5851
2020-11-05 18:33:21,121 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1760 | Iter Mean Loss 6.9828
2020-11-05 18:33:21,129 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4672 | Iter Mean Loss 6.6797
2020-11-05 18:33:21,132 - root - INFO - Evaluate: Epoch 0439 | NDCG 1.0000 | MSE 0.3270
2020-11-05 18:33:21,140 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5347 | Iter Mean Loss 7.5347
2020-11-05 18:33:21,148 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8512 | Iter Mean Loss 5.1930
2020-11-05 18:33:21,156 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3359 | Iter Mean Loss 6.5739
2020-11-05 18:33:21,164 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 6.9706
2020-11-05 18:33:21,171 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4562 | Iter Mean Loss 6.6677
2020-11-05 18:33:21,174 - root - INFO - Evaluate: Epoch 0440 | NDCG 1.0000 | MSE 0.3270
2020-11-05 18:33:21,182 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5227 | Iter Mean Loss 7.5227
2020-11-05 18:33:21,190 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8476 | Iter Mean Loss 5.1851
2020-11-05 18:33:21,197 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3184 | Iter Mean Loss 6.5629
2020-11-05 18:33:21,204 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1449 | Iter Mean Loss 6.9584
2020-11-05 18:33:21,212 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4453 | Iter Mean Loss 6.6558
2020-11-05 18:33:21,214 - root - INFO - Evaluate: Epoch 0441 | NDCG 1.0000 | MSE 0.3269
2020-11-05 18:33:21,222 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.5107 | Iter Mean Loss 7.5107
2020-11-05 18:33:21,229 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8440 | Iter Mean Loss 5.1773
2020-11-05 18:33:21,236 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3010 | Iter Mean Loss 6.5519
2020-11-05 18:33:21,243 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1295 | Iter Mean Loss 6.9463
2020-11-05 18:33:21,251 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4344 | Iter Mean Loss 6.6439
2020-11-05 18:33:21,253 - root - INFO - Evaluate: Epoch 0442 | NDCG 1.0000 | MSE 0.3268
2020-11-05 18:33:21,261 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4988 | Iter Mean Loss 7.4988
2020-11-05 18:33:21,268 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8405 | Iter Mean Loss 5.1696
2020-11-05 18:33:21,276 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2837 | Iter Mean Loss 6.5410
2020-11-05 18:33:21,283 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1142 | Iter Mean Loss 6.9343
2020-11-05 18:33:21,291 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4236 | Iter Mean Loss 6.6321
2020-11-05 18:33:21,293 - root - INFO - Evaluate: Epoch 0443 | NDCG 1.0000 | MSE 0.3267
2020-11-05 18:33:21,302 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4870 | Iter Mean Loss 7.4870
2020-11-05 18:33:21,309 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8370 | Iter Mean Loss 5.1620
2020-11-05 18:33:21,320 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 6.5301
2020-11-05 18:33:21,328 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0989 | Iter Mean Loss 6.9223
2020-11-05 18:33:21,337 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4128 | Iter Mean Loss 6.6204
2020-11-05 18:33:21,339 - root - INFO - Evaluate: Epoch 0444 | NDCG 1.0000 | MSE 0.3267
2020-11-05 18:33:21,349 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4752 | Iter Mean Loss 7.4752
2020-11-05 18:33:21,357 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8334 | Iter Mean Loss 5.1543
2020-11-05 18:33:21,366 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2493 | Iter Mean Loss 6.5193
2020-11-05 18:33:21,374 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0837 | Iter Mean Loss 6.9104
2020-11-05 18:33:21,383 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4021 | Iter Mean Loss 6.6088
2020-11-05 18:33:21,385 - root - INFO - Evaluate: Epoch 0445 | NDCG 1.0000 | MSE 0.3266
2020-11-05 18:33:21,393 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4636 | Iter Mean Loss 7.4636
2020-11-05 18:33:21,401 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8300 | Iter Mean Loss 5.1468
2020-11-05 18:33:21,409 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2322 | Iter Mean Loss 6.5086
2020-11-05 18:33:21,416 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0686 | Iter Mean Loss 6.8986
2020-11-05 18:33:21,424 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3914 | Iter Mean Loss 6.5972
2020-11-05 18:33:21,426 - root - INFO - Evaluate: Epoch 0446 | NDCG 1.0000 | MSE 0.3265
2020-11-05 18:33:21,434 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4521 | Iter Mean Loss 7.4521
2020-11-05 18:33:21,442 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8265 | Iter Mean Loss 5.1393
2020-11-05 18:33:21,450 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2152 | Iter Mean Loss 6.4979
2020-11-05 18:33:21,457 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0536 | Iter Mean Loss 6.8868
2020-11-05 18:33:21,465 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3807 | Iter Mean Loss 6.5856
2020-11-05 18:33:21,467 - root - INFO - Evaluate: Epoch 0447 | NDCG 1.0000 | MSE 0.3264
2020-11-05 18:33:21,475 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4406 | Iter Mean Loss 7.4406
2020-11-05 18:33:21,484 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8230 | Iter Mean Loss 5.1318
2020-11-05 18:33:21,491 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1983 | Iter Mean Loss 6.4873
2020-11-05 18:33:21,500 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0387 | Iter Mean Loss 6.8752
2020-11-05 18:33:21,508 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3701 | Iter Mean Loss 6.5741
2020-11-05 18:33:21,511 - root - INFO - Evaluate: Epoch 0448 | NDCG 1.0000 | MSE 0.3264
2020-11-05 18:33:21,520 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4293 | Iter Mean Loss 7.4293
2020-11-05 18:33:21,528 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 5.1244
2020-11-05 18:33:21,537 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1815 | Iter Mean Loss 6.4768
2020-11-05 18:33:21,544 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0238 | Iter Mean Loss 6.8635
2020-11-05 18:33:21,553 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 6.5627
2020-11-05 18:33:21,555 - root - INFO - Evaluate: Epoch 0449 | NDCG 1.0000 | MSE 0.3263
2020-11-05 18:33:21,564 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 7.4180
2020-11-05 18:33:21,572 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8162 | Iter Mean Loss 5.1171
2020-11-05 18:33:21,580 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1647 | Iter Mean Loss 6.4663
2020-11-05 18:33:21,589 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0090 | Iter Mean Loss 6.8520
2020-11-05 18:33:21,596 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3489 | Iter Mean Loss 6.5514
2020-11-05 18:33:21,599 - root - INFO - Evaluate: Epoch 0450 | NDCG 1.0000 | MSE 0.3262
2020-11-05 18:33:21,607 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.4068 | Iter Mean Loss 7.4068
2020-11-05 18:33:21,615 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8128 | Iter Mean Loss 5.1098
2020-11-05 18:33:21,622 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1480 | Iter Mean Loss 6.4558
2020-11-05 18:33:21,630 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9943 | Iter Mean Loss 6.8405
2020-11-05 18:33:21,637 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3384 | Iter Mean Loss 6.5401
2020-11-05 18:33:21,639 - root - INFO - Evaluate: Epoch 0451 | NDCG 1.0000 | MSE 0.3261
2020-11-05 18:33:21,647 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3956 | Iter Mean Loss 7.3956
2020-11-05 18:33:21,655 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8094 | Iter Mean Loss 5.1025
2020-11-05 18:33:21,663 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1314 | Iter Mean Loss 6.4455
2020-11-05 18:33:21,670 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9797 | Iter Mean Loss 6.8290
2020-11-05 18:33:21,678 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3279 | Iter Mean Loss 6.5288
2020-11-05 18:33:21,680 - root - INFO - Evaluate: Epoch 0452 | NDCG 1.0000 | MSE 0.3261
2020-11-05 18:33:21,689 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3846 | Iter Mean Loss 7.3846
2020-11-05 18:33:21,696 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8060 | Iter Mean Loss 5.0953
2020-11-05 18:33:21,704 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1149 | Iter Mean Loss 6.4351
2020-11-05 18:33:21,712 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9651 | Iter Mean Loss 6.8176
2020-11-05 18:33:21,720 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3175 | Iter Mean Loss 6.5176
2020-11-05 18:33:21,722 - root - INFO - Evaluate: Epoch 0453 | NDCG 1.0000 | MSE 0.3260
2020-11-05 18:33:21,731 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3736 | Iter Mean Loss 7.3736
2020-11-05 18:33:21,739 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8026 | Iter Mean Loss 5.0881
2020-11-05 18:33:21,748 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 6.4249
2020-11-05 18:33:21,755 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9506 | Iter Mean Loss 6.8063
2020-11-05 18:33:21,764 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3071 | Iter Mean Loss 6.5065
2020-11-05 18:33:21,766 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:33:21,774 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3627 | Iter Mean Loss 7.3627
2020-11-05 18:33:21,783 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7992 | Iter Mean Loss 5.0810
2020-11-05 18:33:21,791 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0820 | Iter Mean Loss 6.4147
2020-11-05 18:33:21,799 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9362 | Iter Mean Loss 6.7951
2020-11-05 18:33:21,806 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2967 | Iter Mean Loss 6.4954
2020-11-05 18:33:21,808 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:33:21,816 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3519 | Iter Mean Loss 7.3519
2020-11-05 18:33:21,824 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7959 | Iter Mean Loss 5.0739
2020-11-05 18:33:21,831 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0657 | Iter Mean Loss 6.4045
2020-11-05 18:33:21,839 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9219 | Iter Mean Loss 6.7838
2020-11-05 18:33:21,846 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2863 | Iter Mean Loss 6.4843
2020-11-05 18:33:21,848 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:33:21,856 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3412 | Iter Mean Loss 7.3412
2020-11-05 18:33:21,864 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7926 | Iter Mean Loss 5.0669
2020-11-05 18:33:21,871 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0495 | Iter Mean Loss 6.3944
2020-11-05 18:33:21,879 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9076 | Iter Mean Loss 6.7727
2020-11-05 18:33:21,887 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2760 | Iter Mean Loss 6.4734
2020-11-05 18:33:21,889 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:33:21,898 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3305 | Iter Mean Loss 7.3305
2020-11-05 18:33:21,906 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7892 | Iter Mean Loss 5.0599
2020-11-05 18:33:21,914 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0333 | Iter Mean Loss 6.3844
2020-11-05 18:33:21,921 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8934 | Iter Mean Loss 6.7616
2020-11-05 18:33:21,930 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2657 | Iter Mean Loss 6.4624
2020-11-05 18:33:21,932 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:33:21,940 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3199 | Iter Mean Loss 7.3199
2020-11-05 18:33:21,949 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7859 | Iter Mean Loss 5.0529
2020-11-05 18:33:21,956 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0172 | Iter Mean Loss 6.3743
2020-11-05 18:33:21,964 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8792 | Iter Mean Loss 6.7506
2020-11-05 18:33:21,972 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2555 | Iter Mean Loss 6.4515
2020-11-05 18:33:21,974 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:33:21,983 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.3094 | Iter Mean Loss 7.3094
2020-11-05 18:33:21,991 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7826 | Iter Mean Loss 5.0460
2020-11-05 18:33:21,999 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0011 | Iter Mean Loss 6.3644
2020-11-05 18:33:22,007 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8651 | Iter Mean Loss 6.7396
2020-11-05 18:33:22,015 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 6.4407
2020-11-05 18:33:22,017 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:33:22,025 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2990 | Iter Mean Loss 7.2990
2020-11-05 18:33:22,033 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7793 | Iter Mean Loss 5.0391
2020-11-05 18:33:22,040 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9852 | Iter Mean Loss 6.3545
2020-11-05 18:33:22,048 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8511 | Iter Mean Loss 6.7286
2020-11-05 18:33:22,055 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2351 | Iter Mean Loss 6.4299
2020-11-05 18:33:22,057 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:33:22,065 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2886 | Iter Mean Loss 7.2886
2020-11-05 18:33:22,072 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7760 | Iter Mean Loss 5.0323
2020-11-05 18:33:22,080 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9693 | Iter Mean Loss 6.3446
2020-11-05 18:33:22,087 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8371 | Iter Mean Loss 6.7178
2020-11-05 18:33:22,096 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2249 | Iter Mean Loss 6.4192
2020-11-05 18:33:22,098 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:33:22,106 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2783 | Iter Mean Loss 7.2783
2020-11-05 18:33:22,114 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7728 | Iter Mean Loss 5.0255
2020-11-05 18:33:22,122 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9534 | Iter Mean Loss 6.3348
2020-11-05 18:33:22,130 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8232 | Iter Mean Loss 6.7069
2020-11-05 18:33:22,137 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2148 | Iter Mean Loss 6.4085
2020-11-05 18:33:22,140 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:33:22,149 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2680 | Iter Mean Loss 7.2680
2020-11-05 18:33:22,157 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7695 | Iter Mean Loss 5.0188
2020-11-05 18:33:22,165 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9377 | Iter Mean Loss 6.3251
2020-11-05 18:33:22,172 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8094 | Iter Mean Loss 6.6961
2020-11-05 18:33:22,180 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2047 | Iter Mean Loss 6.3979
2020-11-05 18:33:22,183 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:33:22,191 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2578 | Iter Mean Loss 7.2578
2020-11-05 18:33:22,199 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7662 | Iter Mean Loss 5.0120
2020-11-05 18:33:22,207 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9220 | Iter Mean Loss 6.3153
2020-11-05 18:33:22,214 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7956 | Iter Mean Loss 6.6854
2020-11-05 18:33:22,221 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1947 | Iter Mean Loss 6.3873
2020-11-05 18:33:22,223 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:33:22,231 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2477 | Iter Mean Loss 7.2477
2020-11-05 18:33:22,238 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7630 | Iter Mean Loss 5.0054
2020-11-05 18:33:22,246 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9063 | Iter Mean Loss 6.3057
2020-11-05 18:33:22,253 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7819 | Iter Mean Loss 6.6747
2020-11-05 18:33:22,260 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1846 | Iter Mean Loss 6.3767
2020-11-05 18:33:22,262 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:33:22,270 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2377 | Iter Mean Loss 7.2377
2020-11-05 18:33:22,277 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7597 | Iter Mean Loss 4.9987
2020-11-05 18:33:22,285 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8907 | Iter Mean Loss 6.2961
2020-11-05 18:33:22,293 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7682 | Iter Mean Loss 6.6641
2020-11-05 18:33:22,300 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1746 | Iter Mean Loss 6.3662
2020-11-05 18:33:22,302 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:33:22,310 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2277 | Iter Mean Loss 7.2277
2020-11-05 18:33:22,319 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7565 | Iter Mean Loss 4.9921
2020-11-05 18:33:22,326 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8752 | Iter Mean Loss 6.2865
2020-11-05 18:33:22,335 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7546 | Iter Mean Loss 6.6535
2020-11-05 18:33:22,342 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 6.3557
2020-11-05 18:33:22,344 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:33:22,353 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2178 | Iter Mean Loss 7.2178
2020-11-05 18:33:22,361 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7533 | Iter Mean Loss 4.9855
2020-11-05 18:33:22,369 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8597 | Iter Mean Loss 6.2769
2020-11-05 18:33:22,377 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7411 | Iter Mean Loss 6.6430
2020-11-05 18:33:22,386 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1547 | Iter Mean Loss 6.3453
2020-11-05 18:33:22,388 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:33:22,396 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.2079 | Iter Mean Loss 7.2079
2020-11-05 18:33:22,404 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7501 | Iter Mean Loss 4.9790
2020-11-05 18:33:22,411 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8443 | Iter Mean Loss 6.2674
2020-11-05 18:33:22,422 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7276 | Iter Mean Loss 6.6325
2020-11-05 18:33:22,434 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1448 | Iter Mean Loss 6.3349
2020-11-05 18:33:22,438 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:33:22,447 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1981 | Iter Mean Loss 7.1981
2020-11-05 18:33:22,457 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7468 | Iter Mean Loss 4.9725
2020-11-05 18:33:22,467 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8290 | Iter Mean Loss 6.2580
2020-11-05 18:33:22,476 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7141 | Iter Mean Loss 6.6220
2020-11-05 18:33:22,485 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1349 | Iter Mean Loss 6.3246
2020-11-05 18:33:22,488 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:33:22,498 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1884 | Iter Mean Loss 7.1884
2020-11-05 18:33:22,507 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7436 | Iter Mean Loss 4.9660
2020-11-05 18:33:22,514 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8137 | Iter Mean Loss 6.2486
2020-11-05 18:33:22,523 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7007 | Iter Mean Loss 6.6116
2020-11-05 18:33:22,531 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1250 | Iter Mean Loss 6.3143
2020-11-05 18:33:22,534 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:33:22,545 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1787 | Iter Mean Loss 7.1787
2020-11-05 18:33:22,554 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7404 | Iter Mean Loss 4.9595
2020-11-05 18:33:22,562 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7985 | Iter Mean Loss 6.2392
2020-11-05 18:33:22,569 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6874 | Iter Mean Loss 6.6012
2020-11-05 18:33:22,577 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1152 | Iter Mean Loss 6.3040
2020-11-05 18:33:22,579 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:33:22,588 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1690 | Iter Mean Loss 7.1690
2020-11-05 18:33:22,596 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7372 | Iter Mean Loss 4.9531
2020-11-05 18:33:22,603 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7833 | Iter Mean Loss 6.2299
2020-11-05 18:33:22,611 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6741 | Iter Mean Loss 6.5909
2020-11-05 18:33:22,618 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1054 | Iter Mean Loss 6.2938
2020-11-05 18:33:22,620 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:33:22,628 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1595 | Iter Mean Loss 7.1595
2020-11-05 18:33:22,635 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7340 | Iter Mean Loss 4.9467
2020-11-05 18:33:22,643 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7682 | Iter Mean Loss 6.2206
2020-11-05 18:33:22,650 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6609 | Iter Mean Loss 6.5806
2020-11-05 18:33:22,658 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0956 | Iter Mean Loss 6.2836
2020-11-05 18:33:22,660 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:33:22,668 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1500 | Iter Mean Loss 7.1500
2020-11-05 18:33:22,675 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7308 | Iter Mean Loss 4.9404
2020-11-05 18:33:22,682 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7532 | Iter Mean Loss 6.2113
2020-11-05 18:33:22,689 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6477 | Iter Mean Loss 6.5704
2020-11-05 18:33:22,697 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0858 | Iter Mean Loss 6.2735
2020-11-05 18:33:22,699 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:33:22,707 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1405 | Iter Mean Loss 7.1405
2020-11-05 18:33:22,715 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7276 | Iter Mean Loss 4.9340
2020-11-05 18:33:22,723 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7382 | Iter Mean Loss 6.2021
2020-11-05 18:33:22,731 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6345 | Iter Mean Loss 6.5602
2020-11-05 18:33:22,738 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0761 | Iter Mean Loss 6.2634
2020-11-05 18:33:22,740 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:33:22,749 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1311 | Iter Mean Loss 7.1311
2020-11-05 18:33:22,756 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7244 | Iter Mean Loss 4.9277
2020-11-05 18:33:22,764 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7232 | Iter Mean Loss 6.1929
2020-11-05 18:33:22,772 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6215 | Iter Mean Loss 6.5501
2020-11-05 18:33:22,779 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0664 | Iter Mean Loss 6.2533
2020-11-05 18:33:22,781 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:33:22,790 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1218 | Iter Mean Loss 7.1218
2020-11-05 18:33:22,797 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7212 | Iter Mean Loss 4.9215
2020-11-05 18:33:22,805 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7084 | Iter Mean Loss 6.1838
2020-11-05 18:33:22,812 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6084 | Iter Mean Loss 6.5399
2020-11-05 18:33:22,819 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0567 | Iter Mean Loss 6.2433
2020-11-05 18:33:22,821 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:33:22,829 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1125 | Iter Mean Loss 7.1125
2020-11-05 18:33:22,836 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7180 | Iter Mean Loss 4.9152
2020-11-05 18:33:22,843 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6935 | Iter Mean Loss 6.1747
2020-11-05 18:33:22,850 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5954 | Iter Mean Loss 6.5299
2020-11-05 18:33:22,858 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0470 | Iter Mean Loss 6.2333
2020-11-05 18:33:22,859 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:33:22,867 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.1032 | Iter Mean Loss 7.1032
2020-11-05 18:33:22,874 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7148 | Iter Mean Loss 4.9090
2020-11-05 18:33:22,882 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6787 | Iter Mean Loss 6.1656
2020-11-05 18:33:22,891 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5825 | Iter Mean Loss 6.5198
2020-11-05 18:33:22,898 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0374 | Iter Mean Loss 6.2233
2020-11-05 18:33:22,901 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:33:22,909 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0940 | Iter Mean Loss 7.0940
2020-11-05 18:33:22,917 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7116 | Iter Mean Loss 4.9028
2020-11-05 18:33:22,924 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6640 | Iter Mean Loss 6.1566
2020-11-05 18:33:22,932 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5696 | Iter Mean Loss 6.5098
2020-11-05 18:33:22,940 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0278 | Iter Mean Loss 6.2134
2020-11-05 18:33:22,942 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:33:22,950 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0849 | Iter Mean Loss 7.0849
2020-11-05 18:33:22,958 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7084 | Iter Mean Loss 4.8967
2020-11-05 18:33:22,965 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6493 | Iter Mean Loss 6.1476
2020-11-05 18:33:22,973 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5567 | Iter Mean Loss 6.4998
2020-11-05 18:33:22,980 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0182 | Iter Mean Loss 6.2035
2020-11-05 18:33:22,982 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:33:22,990 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0758 | Iter Mean Loss 7.0758
2020-11-05 18:33:22,998 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7053 | Iter Mean Loss 4.8905
2020-11-05 18:33:23,005 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6347 | Iter Mean Loss 6.1386
2020-11-05 18:33:23,013 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5439 | Iter Mean Loss 6.4899
2020-11-05 18:33:23,020 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0086 | Iter Mean Loss 6.1936
2020-11-05 18:33:23,023 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:33:23,031 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0667 | Iter Mean Loss 7.0667
2020-11-05 18:33:23,038 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7021 | Iter Mean Loss 4.8844
2020-11-05 18:33:23,045 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1296
2020-11-05 18:33:23,052 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5311 | Iter Mean Loss 6.4800
2020-11-05 18:33:23,059 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9991 | Iter Mean Loss 6.1838
2020-11-05 18:33:23,061 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:33:23,069 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0577 | Iter Mean Loss 7.0577
2020-11-05 18:33:23,076 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6989 | Iter Mean Loss 4.8783
2020-11-05 18:33:23,083 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6056 | Iter Mean Loss 6.1207
2020-11-05 18:33:23,090 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5184 | Iter Mean Loss 6.4702
2020-11-05 18:33:23,097 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9895 | Iter Mean Loss 6.1740
2020-11-05 18:33:23,099 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:33:23,107 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0488 | Iter Mean Loss 7.0488
2020-11-05 18:33:23,115 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 4.8722
2020-11-05 18:33:23,122 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5911 | Iter Mean Loss 6.1119
2020-11-05 18:33:23,130 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 6.4603
2020-11-05 18:33:23,137 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9800 | Iter Mean Loss 6.1643
2020-11-05 18:33:23,139 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:33:23,147 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0399 | Iter Mean Loss 7.0399
2020-11-05 18:33:23,155 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 4.8662
2020-11-05 18:33:23,162 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 6.1030
2020-11-05 18:33:23,169 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4931 | Iter Mean Loss 6.4505
2020-11-05 18:33:23,177 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9706 | Iter Mean Loss 6.1545
2020-11-05 18:33:23,179 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:33:23,187 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0310 | Iter Mean Loss 7.0310
2020-11-05 18:33:23,195 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 4.8602
2020-11-05 18:33:23,203 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5623 | Iter Mean Loss 6.0942
2020-11-05 18:33:23,210 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4804 | Iter Mean Loss 6.4408
2020-11-05 18:33:23,217 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9611 | Iter Mean Loss 6.1448
2020-11-05 18:33:23,220 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:33:23,227 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0222 | Iter Mean Loss 7.0222
2020-11-05 18:33:23,234 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6861 | Iter Mean Loss 4.8542
2020-11-05 18:33:23,241 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5479 | Iter Mean Loss 6.0854
2020-11-05 18:33:23,248 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4679 | Iter Mean Loss 6.4310
2020-11-05 18:33:23,255 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9517 | Iter Mean Loss 6.1352
2020-11-05 18:33:23,257 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:33:23,265 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 7.0135
2020-11-05 18:33:23,272 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6829 | Iter Mean Loss 4.8482
2020-11-05 18:33:23,279 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5337 | Iter Mean Loss 6.0767
2020-11-05 18:33:23,286 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4553 | Iter Mean Loss 6.4213
2020-11-05 18:33:23,293 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9422 | Iter Mean Loss 6.1255
2020-11-05 18:33:23,295 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:33:23,303 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.0047 | Iter Mean Loss 7.0047
2020-11-05 18:33:23,311 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6797 | Iter Mean Loss 4.8422
2020-11-05 18:33:23,319 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5194 | Iter Mean Loss 6.0679
2020-11-05 18:33:23,327 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4428 | Iter Mean Loss 6.4117
2020-11-05 18:33:23,334 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9328 | Iter Mean Loss 6.1159
2020-11-05 18:33:23,336 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:33:23,345 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9961 | Iter Mean Loss 6.9961
2020-11-05 18:33:23,352 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6765 | Iter Mean Loss 4.8363
2020-11-05 18:33:23,360 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5052 | Iter Mean Loss 6.0592
2020-11-05 18:33:23,367 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4304 | Iter Mean Loss 6.4020
2020-11-05 18:33:23,375 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9235 | Iter Mean Loss 6.1063
2020-11-05 18:33:23,377 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:33:23,385 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9874 | Iter Mean Loss 6.9874
2020-11-05 18:33:23,393 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6733 | Iter Mean Loss 4.8304
2020-11-05 18:33:23,400 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4910 | Iter Mean Loss 6.0506
2020-11-05 18:33:23,408 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4180 | Iter Mean Loss 6.3924
2020-11-05 18:33:23,415 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9141 | Iter Mean Loss 6.0968
2020-11-05 18:33:23,418 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:33:23,426 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9788 | Iter Mean Loss 6.9788
2020-11-05 18:33:23,433 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6701 | Iter Mean Loss 4.8244
2020-11-05 18:33:23,440 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4769 | Iter Mean Loss 6.0419
2020-11-05 18:33:23,447 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4056 | Iter Mean Loss 6.3828
2020-11-05 18:33:23,454 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9048 | Iter Mean Loss 6.0872
2020-11-05 18:33:23,456 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:33:23,463 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9703 | Iter Mean Loss 6.9703
2020-11-05 18:33:23,471 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6668 | Iter Mean Loss 4.8186
2020-11-05 18:33:23,478 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4628 | Iter Mean Loss 6.0333
2020-11-05 18:33:23,485 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3932 | Iter Mean Loss 6.3733
2020-11-05 18:33:23,491 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8955 | Iter Mean Loss 6.0777
2020-11-05 18:33:23,493 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:33:23,501 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9618 | Iter Mean Loss 6.9618
2020-11-05 18:33:23,509 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6636 | Iter Mean Loss 4.8127
2020-11-05 18:33:23,516 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4488 | Iter Mean Loss 6.0247
2020-11-05 18:33:23,523 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3809 | Iter Mean Loss 6.3638
2020-11-05 18:33:23,531 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8861 | Iter Mean Loss 6.0682
2020-11-05 18:33:23,533 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:33:23,541 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9533 | Iter Mean Loss 6.9533
2020-11-05 18:33:23,548 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6604 | Iter Mean Loss 4.8068
2020-11-05 18:33:23,556 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4348 | Iter Mean Loss 6.0162
2020-11-05 18:33:23,563 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3686 | Iter Mean Loss 6.3543
2020-11-05 18:33:23,571 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8769 | Iter Mean Loss 6.0588
2020-11-05 18:33:23,574 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:33:23,582 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9449 | Iter Mean Loss 6.9449
2020-11-05 18:33:23,589 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6571 | Iter Mean Loss 4.8010
2020-11-05 18:33:23,597 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4209 | Iter Mean Loss 6.0076
2020-11-05 18:33:23,604 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3564 | Iter Mean Loss 6.3448
2020-11-05 18:33:23,612 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8676 | Iter Mean Loss 6.0494
2020-11-05 18:33:23,615 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:33:23,622 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9365 | Iter Mean Loss 6.9365
2020-11-05 18:33:23,630 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6539 | Iter Mean Loss 4.7952
2020-11-05 18:33:23,637 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4069 | Iter Mean Loss 5.9991
2020-11-05 18:33:23,644 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.3354
2020-11-05 18:33:23,651 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 6.0400
2020-11-05 18:33:23,653 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:33:23,661 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9281 | Iter Mean Loss 6.9281
2020-11-05 18:33:23,668 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6507 | Iter Mean Loss 4.7894
2020-11-05 18:33:23,675 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3931 | Iter Mean Loss 5.9906
2020-11-05 18:33:23,682 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3320 | Iter Mean Loss 6.3260
2020-11-05 18:33:23,689 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8491 | Iter Mean Loss 6.0306
2020-11-05 18:33:23,691 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:33:23,699 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9198 | Iter Mean Loss 6.9198
2020-11-05 18:33:23,706 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6474 | Iter Mean Loss 4.7836
2020-11-05 18:33:23,713 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 5.9821
2020-11-05 18:33:23,721 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3198 | Iter Mean Loss 6.3166
2020-11-05 18:33:23,728 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8399 | Iter Mean Loss 6.0212
2020-11-05 18:33:23,730 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:33:23,739 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9115 | Iter Mean Loss 6.9115
2020-11-05 18:33:23,746 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6441 | Iter Mean Loss 4.7778
2020-11-05 18:33:23,754 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3654 | Iter Mean Loss 5.9737
2020-11-05 18:33:23,762 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3077 | Iter Mean Loss 6.3072
2020-11-05 18:33:23,769 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8307 | Iter Mean Loss 6.0119
2020-11-05 18:33:23,772 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:33:23,780 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.9033 | Iter Mean Loss 6.9033
2020-11-05 18:33:23,787 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6409 | Iter Mean Loss 4.7721
2020-11-05 18:33:23,795 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3517 | Iter Mean Loss 5.9653
2020-11-05 18:33:23,803 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2956 | Iter Mean Loss 6.2978
2020-11-05 18:33:23,811 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8215 | Iter Mean Loss 6.0026
2020-11-05 18:33:23,813 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:33:23,821 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8951 | Iter Mean Loss 6.8951
2020-11-05 18:33:23,829 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6376 | Iter Mean Loss 4.7663
2020-11-05 18:33:23,836 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3379 | Iter Mean Loss 5.9569
2020-11-05 18:33:23,843 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2835 | Iter Mean Loss 6.2885
2020-11-05 18:33:23,850 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8124 | Iter Mean Loss 5.9933
2020-11-05 18:33:23,852 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:33:23,860 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8869 | Iter Mean Loss 6.8869
2020-11-05 18:33:23,867 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6343 | Iter Mean Loss 4.7606
2020-11-05 18:33:23,874 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3242 | Iter Mean Loss 5.9485
2020-11-05 18:33:23,882 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2715 | Iter Mean Loss 6.2792
2020-11-05 18:33:23,889 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8032 | Iter Mean Loss 5.9840
2020-11-05 18:33:23,891 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:33:23,899 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8788 | Iter Mean Loss 6.8788
2020-11-05 18:33:23,906 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6310 | Iter Mean Loss 4.7549
2020-11-05 18:33:23,913 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3106 | Iter Mean Loss 5.9401
2020-11-05 18:33:23,920 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2594 | Iter Mean Loss 6.2700
2020-11-05 18:33:23,928 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7941 | Iter Mean Loss 5.9748
2020-11-05 18:33:23,930 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:33:23,938 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8707 | Iter Mean Loss 6.8707
2020-11-05 18:33:23,946 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6277 | Iter Mean Loss 4.7492
2020-11-05 18:33:23,954 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9318
2020-11-05 18:33:23,962 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2475 | Iter Mean Loss 6.2607
2020-11-05 18:33:23,969 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7849 | Iter Mean Loss 5.9655
2020-11-05 18:33:23,971 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:33:23,980 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8626 | Iter Mean Loss 6.8626
2020-11-05 18:33:23,987 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6244 | Iter Mean Loss 4.7435
2020-11-05 18:33:23,995 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2834 | Iter Mean Loss 5.9235
2020-11-05 18:33:24,003 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2355 | Iter Mean Loss 6.2515
2020-11-05 18:33:24,011 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7758 | Iter Mean Loss 5.9563
2020-11-05 18:33:24,013 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:33:24,022 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8546 | Iter Mean Loss 6.8546
2020-11-05 18:33:24,031 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6211 | Iter Mean Loss 4.7378
2020-11-05 18:33:24,038 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2698 | Iter Mean Loss 5.9152
2020-11-05 18:33:24,045 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2236 | Iter Mean Loss 6.2423
2020-11-05 18:33:24,052 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7667 | Iter Mean Loss 5.9471
2020-11-05 18:33:24,054 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:33:24,062 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 6.8466
2020-11-05 18:33:24,069 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6177 | Iter Mean Loss 4.7321
2020-11-05 18:33:24,076 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2563 | Iter Mean Loss 5.9069
2020-11-05 18:33:24,084 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2116 | Iter Mean Loss 6.2331
2020-11-05 18:33:24,091 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7576 | Iter Mean Loss 5.9380
2020-11-05 18:33:24,092 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:33:24,100 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8386 | Iter Mean Loss 6.8386
2020-11-05 18:33:24,107 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6144 | Iter Mean Loss 4.7265
2020-11-05 18:33:24,114 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2428 | Iter Mean Loss 5.8986
2020-11-05 18:33:24,121 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1998 | Iter Mean Loss 6.2239
2020-11-05 18:33:24,129 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7486 | Iter Mean Loss 5.9288
2020-11-05 18:33:24,131 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:33:24,139 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8307 | Iter Mean Loss 6.8307
2020-11-05 18:33:24,147 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6110 | Iter Mean Loss 4.7208
2020-11-05 18:33:24,155 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2293 | Iter Mean Loss 5.8903
2020-11-05 18:33:24,162 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1879 | Iter Mean Loss 6.2147
2020-11-05 18:33:24,169 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 5.9197
2020-11-05 18:33:24,172 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:33:24,179 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8228 | Iter Mean Loss 6.8228
2020-11-05 18:33:24,187 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6076 | Iter Mean Loss 4.7152
2020-11-05 18:33:24,195 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2159 | Iter Mean Loss 5.8821
2020-11-05 18:33:24,202 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1761 | Iter Mean Loss 6.2056
2020-11-05 18:33:24,210 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7305 | Iter Mean Loss 5.9106
2020-11-05 18:33:24,212 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:33:24,220 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8149 | Iter Mean Loss 6.8149
2020-11-05 18:33:24,228 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6042 | Iter Mean Loss 4.7096
2020-11-05 18:33:24,235 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2025 | Iter Mean Loss 5.8739
2020-11-05 18:33:24,243 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1642 | Iter Mean Loss 6.1965
2020-11-05 18:33:24,250 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7214 | Iter Mean Loss 5.9015
2020-11-05 18:33:24,252 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:33:24,259 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.8070 | Iter Mean Loss 6.8070
2020-11-05 18:33:24,267 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6008 | Iter Mean Loss 4.7039
2020-11-05 18:33:24,274 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1891 | Iter Mean Loss 5.8657
2020-11-05 18:33:24,281 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1524 | Iter Mean Loss 6.1874
2020-11-05 18:33:24,288 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7124 | Iter Mean Loss 5.8924
2020-11-05 18:33:24,290 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:33:24,297 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7992 | Iter Mean Loss 6.7992
2020-11-05 18:33:24,305 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5974 | Iter Mean Loss 4.6983
2020-11-05 18:33:24,312 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1758 | Iter Mean Loss 5.8575
2020-11-05 18:33:24,320 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1407 | Iter Mean Loss 6.1783
2020-11-05 18:33:24,327 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7034 | Iter Mean Loss 5.8833
2020-11-05 18:33:24,330 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:33:24,338 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7914 | Iter Mean Loss 6.7914
2020-11-05 18:33:24,345 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5940 | Iter Mean Loss 4.6927
2020-11-05 18:33:24,353 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1625 | Iter Mean Loss 5.8493
2020-11-05 18:33:24,360 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1289 | Iter Mean Loss 6.1692
2020-11-05 18:33:24,368 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6944 | Iter Mean Loss 5.8742
2020-11-05 18:33:24,370 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:33:24,378 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7837 | Iter Mean Loss 6.7837
2020-11-05 18:33:24,386 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5906 | Iter Mean Loss 4.6871
2020-11-05 18:33:24,393 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1492 | Iter Mean Loss 5.8411
2020-11-05 18:33:24,401 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1172 | Iter Mean Loss 6.1602
2020-11-05 18:33:24,408 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6854 | Iter Mean Loss 5.8652
2020-11-05 18:33:24,410 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:33:24,419 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7759 | Iter Mean Loss 6.7759
2020-11-05 18:33:24,426 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5871 | Iter Mean Loss 4.6815
2020-11-05 18:33:24,434 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1359 | Iter Mean Loss 5.8330
2020-11-05 18:33:24,441 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1054 | Iter Mean Loss 6.1511
2020-11-05 18:33:24,449 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6764 | Iter Mean Loss 5.8562
2020-11-05 18:33:24,451 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:33:24,459 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7682 | Iter Mean Loss 6.7682
2020-11-05 18:33:24,466 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5837 | Iter Mean Loss 4.6759
2020-11-05 18:33:24,473 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1227 | Iter Mean Loss 5.8249
2020-11-05 18:33:24,480 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0937 | Iter Mean Loss 6.1421
2020-11-05 18:33:24,487 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6674 | Iter Mean Loss 5.8472
2020-11-05 18:33:24,489 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:33:24,497 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7605 | Iter Mean Loss 6.7605
2020-11-05 18:33:24,504 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5802 | Iter Mean Loss 4.6704
2020-11-05 18:33:24,511 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 5.8167
2020-11-05 18:33:24,518 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0821 | Iter Mean Loss 6.1331
2020-11-05 18:33:24,525 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6585 | Iter Mean Loss 5.8381
2020-11-05 18:33:24,527 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:33:24,535 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7529 | Iter Mean Loss 6.7529
2020-11-05 18:33:24,542 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5767 | Iter Mean Loss 4.6648
2020-11-05 18:33:24,550 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0963 | Iter Mean Loss 5.8086
2020-11-05 18:33:24,558 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0704 | Iter Mean Loss 6.1241
2020-11-05 18:33:24,565 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6495 | Iter Mean Loss 5.8292
2020-11-05 18:33:24,567 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:33:24,575 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7453 | Iter Mean Loss 6.7453
2020-11-05 18:33:24,583 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 4.6592
2020-11-05 18:33:24,591 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0831 | Iter Mean Loss 5.8005
2020-11-05 18:33:24,598 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0588 | Iter Mean Loss 6.1151
2020-11-05 18:33:24,606 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6406 | Iter Mean Loss 5.8202
2020-11-05 18:33:24,609 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:33:24,617 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7377 | Iter Mean Loss 6.7377
2020-11-05 18:33:24,624 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5696 | Iter Mean Loss 4.6536
2020-11-05 18:33:24,632 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0700 | Iter Mean Loss 5.7924
2020-11-05 18:33:24,640 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0471 | Iter Mean Loss 6.1061
2020-11-05 18:33:24,647 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6316 | Iter Mean Loss 5.8112
2020-11-05 18:33:24,649 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:33:24,657 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7301 | Iter Mean Loss 6.7301
2020-11-05 18:33:24,664 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5661 | Iter Mean Loss 4.6481
2020-11-05 18:33:24,671 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0569 | Iter Mean Loss 5.7843
2020-11-05 18:33:24,679 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0355 | Iter Mean Loss 6.0971
2020-11-05 18:33:24,686 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6227 | Iter Mean Loss 5.8022
2020-11-05 18:33:24,688 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:33:24,695 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7225 | Iter Mean Loss 6.7225
2020-11-05 18:33:24,703 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5625 | Iter Mean Loss 4.6425
2020-11-05 18:33:24,710 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0438 | Iter Mean Loss 5.7763
2020-11-05 18:33:24,717 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0239 | Iter Mean Loss 6.0882
2020-11-05 18:33:24,724 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6137 | Iter Mean Loss 5.7933
2020-11-05 18:33:24,726 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:33:24,733 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7150 | Iter Mean Loss 6.7150
2020-11-05 18:33:24,741 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5589 | Iter Mean Loss 4.6370
2020-11-05 18:33:24,748 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0307 | Iter Mean Loss 5.7682
2020-11-05 18:33:24,756 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0123 | Iter Mean Loss 6.0792
2020-11-05 18:33:24,763 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6048 | Iter Mean Loss 5.7844
2020-11-05 18:33:24,765 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:33:24,773 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7075 | Iter Mean Loss 6.7075
2020-11-05 18:33:24,781 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5553 | Iter Mean Loss 4.6314
2020-11-05 18:33:24,788 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0176 | Iter Mean Loss 5.7601
2020-11-05 18:33:24,796 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0008 | Iter Mean Loss 6.0703
2020-11-05 18:33:24,803 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5959 | Iter Mean Loss 5.7754
2020-11-05 18:33:24,806 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:33:24,814 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.7000 | Iter Mean Loss 6.7000
2020-11-05 18:33:24,821 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5517 | Iter Mean Loss 4.6258
2020-11-05 18:33:24,829 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0046 | Iter Mean Loss 5.7521
2020-11-05 18:33:24,836 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9892 | Iter Mean Loss 6.0614
2020-11-05 18:33:24,844 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5870 | Iter Mean Loss 5.7665
2020-11-05 18:33:24,846 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:33:24,854 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6925 | Iter Mean Loss 6.6925
2020-11-05 18:33:24,861 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5480 | Iter Mean Loss 4.6203
2020-11-05 18:33:24,869 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9916 | Iter Mean Loss 5.7441
2020-11-05 18:33:24,876 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9776 | Iter Mean Loss 6.0525
2020-11-05 18:33:24,883 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5781 | Iter Mean Loss 5.7576
2020-11-05 18:33:24,885 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:33:24,893 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6851 | Iter Mean Loss 6.6851
2020-11-05 18:33:24,900 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5444 | Iter Mean Loss 4.6147
2020-11-05 18:33:24,908 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9786 | Iter Mean Loss 5.7360
2020-11-05 18:33:24,915 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9661 | Iter Mean Loss 6.0435
2020-11-05 18:33:24,922 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5692 | Iter Mean Loss 5.7487
2020-11-05 18:33:24,924 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:33:24,931 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6777 | Iter Mean Loss 6.6777
2020-11-05 18:33:24,939 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5407 | Iter Mean Loss 4.6092
2020-11-05 18:33:24,946 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9656 | Iter Mean Loss 5.7280
2020-11-05 18:33:24,953 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9546 | Iter Mean Loss 6.0346
2020-11-05 18:33:24,961 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5603 | Iter Mean Loss 5.7398
2020-11-05 18:33:24,963 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:33:24,971 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6703 | Iter Mean Loss 6.6703
2020-11-05 18:33:24,979 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5370 | Iter Mean Loss 4.6036
2020-11-05 18:33:24,986 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9526 | Iter Mean Loss 5.7200
2020-11-05 18:33:24,994 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9431 | Iter Mean Loss 6.0257
2020-11-05 18:33:25,001 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5514 | Iter Mean Loss 5.7309
2020-11-05 18:33:25,003 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:33:25,012 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6629 | Iter Mean Loss 6.6629
2020-11-05 18:33:25,019 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5333 | Iter Mean Loss 4.5981
2020-11-05 18:33:25,028 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9397 | Iter Mean Loss 5.7119
2020-11-05 18:33:25,035 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9316 | Iter Mean Loss 6.0169
2020-11-05 18:33:25,043 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5425 | Iter Mean Loss 5.7220
2020-11-05 18:33:25,045 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:33:25,053 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6556 | Iter Mean Loss 6.6556
2020-11-05 18:33:25,060 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5295 | Iter Mean Loss 4.5925
2020-11-05 18:33:25,068 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9267 | Iter Mean Loss 5.7039
2020-11-05 18:33:25,075 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9201 | Iter Mean Loss 6.0080
2020-11-05 18:33:25,082 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5336 | Iter Mean Loss 5.7131
2020-11-05 18:33:25,084 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:33:25,092 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6482 | Iter Mean Loss 6.6482
2020-11-05 18:33:25,099 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5257 | Iter Mean Loss 4.5870
2020-11-05 18:33:25,106 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9138 | Iter Mean Loss 5.6959
2020-11-05 18:33:25,113 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9086 | Iter Mean Loss 5.9991
2020-11-05 18:33:25,120 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5247 | Iter Mean Loss 5.7042
2020-11-05 18:33:25,122 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:33:25,130 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6409 | Iter Mean Loss 6.6409
2020-11-05 18:33:25,137 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5219 | Iter Mean Loss 4.5814
2020-11-05 18:33:25,144 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 5.6879
2020-11-05 18:33:25,151 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8971 | Iter Mean Loss 5.9902
2020-11-05 18:33:25,159 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5158 | Iter Mean Loss 5.6953
2020-11-05 18:33:25,161 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:33:25,169 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6336 | Iter Mean Loss 6.6336
2020-11-05 18:33:25,176 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5181 | Iter Mean Loss 4.5759
2020-11-05 18:33:25,184 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8880 | Iter Mean Loss 5.6799
2020-11-05 18:33:25,191 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8856 | Iter Mean Loss 5.9813
2020-11-05 18:33:25,199 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 5.6865
2020-11-05 18:33:25,201 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:33:25,209 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6263 | Iter Mean Loss 6.6263
2020-11-05 18:33:25,217 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5143 | Iter Mean Loss 4.5703
2020-11-05 18:33:25,225 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8751 | Iter Mean Loss 5.6719
2020-11-05 18:33:25,232 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8742 | Iter Mean Loss 5.9725
2020-11-05 18:33:25,240 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4980 | Iter Mean Loss 5.6776
2020-11-05 18:33:25,242 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:33:25,251 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6191 | Iter Mean Loss 6.6191
2020-11-05 18:33:25,258 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5104 | Iter Mean Loss 4.5647
2020-11-05 18:33:25,266 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8623 | Iter Mean Loss 5.6639
2020-11-05 18:33:25,273 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8627 | Iter Mean Loss 5.9636
2020-11-05 18:33:25,280 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4891 | Iter Mean Loss 5.6687
2020-11-05 18:33:25,282 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:33:25,290 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6118 | Iter Mean Loss 6.6118
2020-11-05 18:33:25,297 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5065 | Iter Mean Loss 4.5592
2020-11-05 18:33:25,304 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 5.6559
2020-11-05 18:33:25,312 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8513 | Iter Mean Loss 5.9547
2020-11-05 18:33:25,320 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4802 | Iter Mean Loss 5.6598
2020-11-05 18:33:25,322 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:33:25,330 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.6046
2020-11-05 18:33:25,338 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5026 | Iter Mean Loss 4.5536
2020-11-05 18:33:25,345 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8365 | Iter Mean Loss 5.6479
2020-11-05 18:33:25,352 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8398 | Iter Mean Loss 5.9459
2020-11-05 18:33:25,359 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4713 | Iter Mean Loss 5.6510
2020-11-05 18:33:25,361 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:25,369 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5974 | Iter Mean Loss 6.5974
2020-11-05 18:33:25,377 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4986 | Iter Mean Loss 4.5480
2020-11-05 18:33:25,385 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8237 | Iter Mean Loss 5.6399
2020-11-05 18:33:25,392 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8284 | Iter Mean Loss 5.9370
2020-11-05 18:33:25,400 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4624 | Iter Mean Loss 5.6421
2020-11-05 18:33:25,402 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:25,410 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5902 | Iter Mean Loss 6.5902
2020-11-05 18:33:25,418 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4947 | Iter Mean Loss 4.5424
2020-11-05 18:33:25,426 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8109 | Iter Mean Loss 5.6319
2020-11-05 18:33:25,434 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8169 | Iter Mean Loss 5.9282
2020-11-05 18:33:25,441 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 5.6332
2020-11-05 18:33:25,443 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:25,451 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5830 | Iter Mean Loss 6.5830
2020-11-05 18:33:25,459 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4907 | Iter Mean Loss 4.5368
2020-11-05 18:33:25,466 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7981 | Iter Mean Loss 5.6239
2020-11-05 18:33:25,474 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8055 | Iter Mean Loss 5.9193
2020-11-05 18:33:25,481 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4446 | Iter Mean Loss 5.6244
2020-11-05 18:33:25,483 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:25,491 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5758 | Iter Mean Loss 6.5758
2020-11-05 18:33:25,498 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4866 | Iter Mean Loss 4.5312
2020-11-05 18:33:25,506 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7852 | Iter Mean Loss 5.6159
2020-11-05 18:33:25,513 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7941 | Iter Mean Loss 5.9104
2020-11-05 18:33:25,520 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4357 | Iter Mean Loss 5.6155
2020-11-05 18:33:25,522 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:25,529 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5687 | Iter Mean Loss 6.5687
2020-11-05 18:33:25,536 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4826 | Iter Mean Loss 4.5256
2020-11-05 18:33:25,544 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7724 | Iter Mean Loss 5.6079
2020-11-05 18:33:25,551 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7826 | Iter Mean Loss 5.9016
2020-11-05 18:33:25,558 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4268 | Iter Mean Loss 5.6066
2020-11-05 18:33:25,560 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:33:25,568 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5615 | Iter Mean Loss 6.5615
2020-11-05 18:33:25,576 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4785 | Iter Mean Loss 4.5200
2020-11-05 18:33:25,583 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7596 | Iter Mean Loss 5.5999
2020-11-05 18:33:25,590 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7712 | Iter Mean Loss 5.8927
2020-11-05 18:33:25,598 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4179 | Iter Mean Loss 5.5978
2020-11-05 18:33:25,601 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:33:25,609 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5544 | Iter Mean Loss 6.5544
2020-11-05 18:33:25,617 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4744 | Iter Mean Loss 4.5144
2020-11-05 18:33:25,624 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7468 | Iter Mean Loss 5.5919
2020-11-05 18:33:25,632 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7598 | Iter Mean Loss 5.8839
2020-11-05 18:33:25,639 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4090 | Iter Mean Loss 5.5889
2020-11-05 18:33:25,642 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:25,650 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5473 | Iter Mean Loss 6.5473
2020-11-05 18:33:25,658 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4703 | Iter Mean Loss 4.5088
2020-11-05 18:33:25,666 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7340 | Iter Mean Loss 5.5839
2020-11-05 18:33:25,673 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7484 | Iter Mean Loss 5.8750
2020-11-05 18:33:25,681 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 5.5800
2020-11-05 18:33:25,683 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:25,691 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5402 | Iter Mean Loss 6.5402
2020-11-05 18:33:25,698 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4661 | Iter Mean Loss 4.5031
2020-11-05 18:33:25,705 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7212 | Iter Mean Loss 5.5758
2020-11-05 18:33:25,712 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7369 | Iter Mean Loss 5.8661
2020-11-05 18:33:25,719 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3911 | Iter Mean Loss 5.5711
2020-11-05 18:33:25,721 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:25,729 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5331 | Iter Mean Loss 6.5331
2020-11-05 18:33:25,736 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4619 | Iter Mean Loss 4.4975
2020-11-05 18:33:25,743 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7085 | Iter Mean Loss 5.5678
2020-11-05 18:33:25,750 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7255 | Iter Mean Loss 5.8572
2020-11-05 18:33:25,758 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3822 | Iter Mean Loss 5.5622
2020-11-05 18:33:25,759 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:25,768 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5260 | Iter Mean Loss 6.5260
2020-11-05 18:33:25,775 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4576 | Iter Mean Loss 4.4918
2020-11-05 18:33:25,783 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6957 | Iter Mean Loss 5.5598
2020-11-05 18:33:25,790 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7141 | Iter Mean Loss 5.8484
2020-11-05 18:33:25,798 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3733 | Iter Mean Loss 5.5533
2020-11-05 18:33:25,800 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:25,808 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5190 | Iter Mean Loss 6.5190
2020-11-05 18:33:25,816 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 4.4862
2020-11-05 18:33:25,824 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6829 | Iter Mean Loss 5.5518
2020-11-05 18:33:25,832 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7026 | Iter Mean Loss 5.8395
2020-11-05 18:33:25,840 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3643 | Iter Mean Loss 5.5444
2020-11-05 18:33:25,842 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:33:25,850 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5119 | Iter Mean Loss 6.5119
2020-11-05 18:33:25,858 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4491 | Iter Mean Loss 4.4805
2020-11-05 18:33:25,866 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6701 | Iter Mean Loss 5.5437
2020-11-05 18:33:25,873 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6912 | Iter Mean Loss 5.8306
2020-11-05 18:33:25,880 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3553 | Iter Mean Loss 5.5355
2020-11-05 18:33:25,883 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:33:25,890 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.5049 | Iter Mean Loss 6.5049
2020-11-05 18:33:25,898 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4447 | Iter Mean Loss 4.4748
2020-11-05 18:33:25,906 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6573 | Iter Mean Loss 5.5357
2020-11-05 18:33:25,913 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6798 | Iter Mean Loss 5.8217
2020-11-05 18:33:25,920 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3464 | Iter Mean Loss 5.5266
2020-11-05 18:33:25,922 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:25,929 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4979 | Iter Mean Loss 6.4979
2020-11-05 18:33:25,937 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4404 | Iter Mean Loss 4.4691
2020-11-05 18:33:25,944 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6445 | Iter Mean Loss 5.5276
2020-11-05 18:33:25,951 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6683 | Iter Mean Loss 5.8128
2020-11-05 18:33:25,958 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3374 | Iter Mean Loss 5.5177
2020-11-05 18:33:25,960 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:25,968 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4909 | Iter Mean Loss 6.4909
2020-11-05 18:33:25,976 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4360 | Iter Mean Loss 4.4634
2020-11-05 18:33:25,984 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5195
2020-11-05 18:33:25,991 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6569 | Iter Mean Loss 5.8039
2020-11-05 18:33:25,999 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3284 | Iter Mean Loss 5.5088
2020-11-05 18:33:26,001 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:26,010 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4839 | Iter Mean Loss 6.4839
2020-11-05 18:33:26,019 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4315 | Iter Mean Loss 4.4577
2020-11-05 18:33:26,027 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6190 | Iter Mean Loss 5.5115
2020-11-05 18:33:26,035 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6454 | Iter Mean Loss 5.7949
2020-11-05 18:33:26,042 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3194 | Iter Mean Loss 5.4998
2020-11-05 18:33:26,045 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:26,053 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4769 | Iter Mean Loss 6.4769
2020-11-05 18:33:26,061 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4271 | Iter Mean Loss 4.4520
2020-11-05 18:33:26,068 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6062 | Iter Mean Loss 5.5034
2020-11-05 18:33:26,076 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6339 | Iter Mean Loss 5.7860
2020-11-05 18:33:26,083 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3104 | Iter Mean Loss 5.4909
2020-11-05 18:33:26,086 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:26,095 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4699 | Iter Mean Loss 6.4699
2020-11-05 18:33:26,102 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4226 | Iter Mean Loss 4.4462
2020-11-05 18:33:26,109 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5934 | Iter Mean Loss 5.4953
2020-11-05 18:33:26,116 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6225 | Iter Mean Loss 5.7771
2020-11-05 18:33:26,123 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3014 | Iter Mean Loss 5.4819
2020-11-05 18:33:26,125 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:26,133 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4629 | Iter Mean Loss 6.4629
2020-11-05 18:33:26,140 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4180 | Iter Mean Loss 4.4405
2020-11-05 18:33:26,147 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5806 | Iter Mean Loss 5.4872
2020-11-05 18:33:26,154 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6110 | Iter Mean Loss 5.7681
2020-11-05 18:33:26,162 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2924 | Iter Mean Loss 5.4730
2020-11-05 18:33:26,164 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:26,172 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4560 | Iter Mean Loss 6.4560
2020-11-05 18:33:26,180 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4134 | Iter Mean Loss 4.4347
2020-11-05 18:33:26,187 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5678 | Iter Mean Loss 5.4791
2020-11-05 18:33:26,195 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5995 | Iter Mean Loss 5.7592
2020-11-05 18:33:26,202 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2833 | Iter Mean Loss 5.4640
2020-11-05 18:33:26,205 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:26,213 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4490 | Iter Mean Loss 6.4490
2020-11-05 18:33:26,221 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4088 | Iter Mean Loss 4.4289
2020-11-05 18:33:26,229 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5550 | Iter Mean Loss 5.4709
2020-11-05 18:33:26,237 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5880 | Iter Mean Loss 5.7502
2020-11-05 18:33:26,244 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2743 | Iter Mean Loss 5.4550
2020-11-05 18:33:26,246 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:26,255 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4421 | Iter Mean Loss 6.4421
2020-11-05 18:33:26,263 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4042 | Iter Mean Loss 4.4231
2020-11-05 18:33:26,271 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5422 | Iter Mean Loss 5.4628
2020-11-05 18:33:26,279 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5765 | Iter Mean Loss 5.7412
2020-11-05 18:33:26,286 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2652 | Iter Mean Loss 5.4460
2020-11-05 18:33:26,288 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:26,296 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4351 | Iter Mean Loss 6.4351
2020-11-05 18:33:26,303 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3995 | Iter Mean Loss 4.4173
2020-11-05 18:33:26,311 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5294 | Iter Mean Loss 5.4547
2020-11-05 18:33:26,318 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5650 | Iter Mean Loss 5.7323
2020-11-05 18:33:26,327 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2561 | Iter Mean Loss 5.4370
2020-11-05 18:33:26,329 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:26,337 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4282 | Iter Mean Loss 6.4282
2020-11-05 18:33:26,344 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3948 | Iter Mean Loss 4.4115
2020-11-05 18:33:26,351 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5166 | Iter Mean Loss 5.4465
2020-11-05 18:33:26,358 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5535 | Iter Mean Loss 5.7233
2020-11-05 18:33:26,366 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2470 | Iter Mean Loss 5.4280
2020-11-05 18:33:26,368 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:26,376 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4213 | Iter Mean Loss 6.4213
2020-11-05 18:33:26,384 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3900 | Iter Mean Loss 4.4056
2020-11-05 18:33:26,392 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5037 | Iter Mean Loss 5.4383
2020-11-05 18:33:26,400 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5419 | Iter Mean Loss 5.7142
2020-11-05 18:33:26,408 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2379 | Iter Mean Loss 5.4190
2020-11-05 18:33:26,410 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:26,419 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4144 | Iter Mean Loss 6.4144
2020-11-05 18:33:26,427 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3852 | Iter Mean Loss 4.3998
2020-11-05 18:33:26,435 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4909 | Iter Mean Loss 5.4302
2020-11-05 18:33:26,443 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5304 | Iter Mean Loss 5.7052
2020-11-05 18:33:26,450 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2288 | Iter Mean Loss 5.4099
2020-11-05 18:33:26,452 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:26,461 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4075 | Iter Mean Loss 6.4075
2020-11-05 18:33:26,468 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3803 | Iter Mean Loss 4.3939
2020-11-05 18:33:26,476 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4781 | Iter Mean Loss 5.4220
2020-11-05 18:33:26,484 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5188 | Iter Mean Loss 5.6962
2020-11-05 18:33:26,491 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2197 | Iter Mean Loss 5.4009
2020-11-05 18:33:26,493 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:26,501 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.4006 | Iter Mean Loss 6.4006
2020-11-05 18:33:26,508 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3755 | Iter Mean Loss 4.3880
2020-11-05 18:33:26,516 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4652 | Iter Mean Loss 5.4137
2020-11-05 18:33:26,523 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5073 | Iter Mean Loss 5.6871
2020-11-05 18:33:26,530 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2105 | Iter Mean Loss 5.3918
2020-11-05 18:33:26,532 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:26,539 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3937 | Iter Mean Loss 6.3937
2020-11-05 18:33:26,546 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3705 | Iter Mean Loss 4.3821
2020-11-05 18:33:26,554 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4524 | Iter Mean Loss 5.4055
2020-11-05 18:33:26,561 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4957 | Iter Mean Loss 5.6781
2020-11-05 18:33:26,568 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2013 | Iter Mean Loss 5.3827
2020-11-05 18:33:26,570 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:26,579 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3868 | Iter Mean Loss 6.3868
2020-11-05 18:33:26,586 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3656 | Iter Mean Loss 4.3762
2020-11-05 18:33:26,594 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4395 | Iter Mean Loss 5.3973
2020-11-05 18:33:26,601 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4841 | Iter Mean Loss 5.6690
2020-11-05 18:33:26,609 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1922 | Iter Mean Loss 5.3736
2020-11-05 18:33:26,611 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:26,620 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3799 | Iter Mean Loss 6.3799
2020-11-05 18:33:26,628 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3606 | Iter Mean Loss 4.3702
2020-11-05 18:33:26,636 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4266 | Iter Mean Loss 5.3890
2020-11-05 18:33:26,644 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4725 | Iter Mean Loss 5.6599
2020-11-05 18:33:26,651 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1830 | Iter Mean Loss 5.3645
2020-11-05 18:33:26,653 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:26,662 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3730 | Iter Mean Loss 6.3730
2020-11-05 18:33:26,670 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3555 | Iter Mean Loss 4.3643
2020-11-05 18:33:26,678 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4137 | Iter Mean Loss 5.3807
2020-11-05 18:33:26,685 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4609 | Iter Mean Loss 5.6508
2020-11-05 18:33:26,693 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1737 | Iter Mean Loss 5.3554
2020-11-05 18:33:26,695 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:26,703 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 6.3662
2020-11-05 18:33:26,710 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3504 | Iter Mean Loss 4.3583
2020-11-05 18:33:26,717 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4008 | Iter Mean Loss 5.3725
2020-11-05 18:33:26,724 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4493 | Iter Mean Loss 5.6417
2020-11-05 18:33:26,731 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1645 | Iter Mean Loss 5.3462
2020-11-05 18:33:26,733 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:26,741 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3593 | Iter Mean Loss 6.3593
2020-11-05 18:33:26,748 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3453 | Iter Mean Loss 4.3523
2020-11-05 18:33:26,755 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3879 | Iter Mean Loss 5.3642
2020-11-05 18:33:26,762 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4376 | Iter Mean Loss 5.6325
2020-11-05 18:33:26,770 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1552 | Iter Mean Loss 5.3371
2020-11-05 18:33:26,772 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:26,780 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3524 | Iter Mean Loss 6.3524
2020-11-05 18:33:26,788 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3401 | Iter Mean Loss 4.3463
2020-11-05 18:33:26,795 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3750 | Iter Mean Loss 5.3558
2020-11-05 18:33:26,803 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4259 | Iter Mean Loss 5.6234
2020-11-05 18:33:26,810 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1460 | Iter Mean Loss 5.3279
2020-11-05 18:33:26,813 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:26,821 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3456 | Iter Mean Loss 6.3456
2020-11-05 18:33:26,829 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3349 | Iter Mean Loss 4.3403
2020-11-05 18:33:26,838 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3620 | Iter Mean Loss 5.3475
2020-11-05 18:33:26,845 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4143 | Iter Mean Loss 5.6142
2020-11-05 18:33:26,853 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1367 | Iter Mean Loss 5.3187
2020-11-05 18:33:26,855 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:26,864 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3388 | Iter Mean Loss 6.3388
2020-11-05 18:33:26,871 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3297 | Iter Mean Loss 4.3342
2020-11-05 18:33:26,879 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3491 | Iter Mean Loss 5.3392
2020-11-05 18:33:26,887 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4026 | Iter Mean Loss 5.6050
2020-11-05 18:33:26,894 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1274 | Iter Mean Loss 5.3095
2020-11-05 18:33:26,896 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:26,904 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3319 | Iter Mean Loss 6.3319
2020-11-05 18:33:26,911 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3244 | Iter Mean Loss 4.3281
2020-11-05 18:33:26,918 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3361 | Iter Mean Loss 5.3308
2020-11-05 18:33:26,925 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3909 | Iter Mean Loss 5.5958
2020-11-05 18:33:26,932 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1180 | Iter Mean Loss 5.3002
2020-11-05 18:33:26,934 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:26,942 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3251 | Iter Mean Loss 6.3251
2020-11-05 18:33:26,949 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3190 | Iter Mean Loss 4.3220
2020-11-05 18:33:26,956 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3231 | Iter Mean Loss 5.3224
2020-11-05 18:33:26,963 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3791 | Iter Mean Loss 5.5866
2020-11-05 18:33:26,971 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1087 | Iter Mean Loss 5.2910
2020-11-05 18:33:26,973 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:26,981 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3183 | Iter Mean Loss 6.3183
2020-11-05 18:33:26,989 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3136 | Iter Mean Loss 4.3159
2020-11-05 18:33:26,996 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3101 | Iter Mean Loss 5.3140
2020-11-05 18:33:27,004 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3674 | Iter Mean Loss 5.5773
2020-11-05 18:33:27,011 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0993 | Iter Mean Loss 5.2817
2020-11-05 18:33:27,014 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:27,023 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3114 | Iter Mean Loss 6.3114
2020-11-05 18:33:27,031 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3082 | Iter Mean Loss 4.3098
2020-11-05 18:33:27,039 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2971 | Iter Mean Loss 5.3056
2020-11-05 18:33:27,047 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3556 | Iter Mean Loss 5.5681
2020-11-05 18:33:27,055 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 5.2725
2020-11-05 18:33:27,057 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:27,065 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.3046 | Iter Mean Loss 6.3046
2020-11-05 18:33:27,073 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3027 | Iter Mean Loss 4.3037
2020-11-05 18:33:27,081 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2841 | Iter Mean Loss 5.2971
2020-11-05 18:33:27,089 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3438 | Iter Mean Loss 5.5588
2020-11-05 18:33:27,096 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0805 | Iter Mean Loss 5.2632
2020-11-05 18:33:27,098 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:27,107 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2978 | Iter Mean Loss 6.2978
2020-11-05 18:33:27,114 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2972 | Iter Mean Loss 4.2975
2020-11-05 18:33:27,121 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2710 | Iter Mean Loss 5.2887
2020-11-05 18:33:27,128 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3320 | Iter Mean Loss 5.5495
2020-11-05 18:33:27,135 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 5.2538
2020-11-05 18:33:27,137 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:27,145 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2910 | Iter Mean Loss 6.2910
2020-11-05 18:33:27,152 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 4.2913
2020-11-05 18:33:27,159 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2580 | Iter Mean Loss 5.2802
2020-11-05 18:33:27,166 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3202 | Iter Mean Loss 5.5402
2020-11-05 18:33:27,174 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0616 | Iter Mean Loss 5.2445
2020-11-05 18:33:27,176 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:27,184 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2842 | Iter Mean Loss 6.2842
2020-11-05 18:33:27,192 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2860 | Iter Mean Loss 4.2851
2020-11-05 18:33:27,200 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2449 | Iter Mean Loss 5.2717
2020-11-05 18:33:27,207 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3084 | Iter Mean Loss 5.5309
2020-11-05 18:33:27,214 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0522 | Iter Mean Loss 5.2351
2020-11-05 18:33:27,217 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:27,225 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2774 | Iter Mean Loss 6.2774
2020-11-05 18:33:27,234 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2804 | Iter Mean Loss 4.2789
2020-11-05 18:33:27,242 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2318 | Iter Mean Loss 5.2632
2020-11-05 18:33:27,249 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2966 | Iter Mean Loss 5.5215
2020-11-05 18:33:27,257 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0427 | Iter Mean Loss 5.2258
2020-11-05 18:33:27,259 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:27,268 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 6.2706
2020-11-05 18:33:27,276 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2747 | Iter Mean Loss 4.2727
2020-11-05 18:33:27,284 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2187 | Iter Mean Loss 5.2547
2020-11-05 18:33:27,291 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2847 | Iter Mean Loss 5.5122
2020-11-05 18:33:27,299 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0332 | Iter Mean Loss 5.2164
2020-11-05 18:33:27,301 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:27,309 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2639 | Iter Mean Loss 6.2639
2020-11-05 18:33:27,318 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2690 | Iter Mean Loss 4.2664
2020-11-05 18:33:27,326 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.2056 | Iter Mean Loss 5.2461
2020-11-05 18:33:27,333 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2728 | Iter Mean Loss 5.5028
2020-11-05 18:33:27,340 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0236 | Iter Mean Loss 5.2070
2020-11-05 18:33:27,342 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:27,350 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2571 | Iter Mean Loss 6.2571
2020-11-05 18:33:27,357 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2632 | Iter Mean Loss 4.2601
2020-11-05 18:33:27,364 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1925 | Iter Mean Loss 5.2376
2020-11-05 18:33:27,371 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2609 | Iter Mean Loss 5.4934
2020-11-05 18:33:27,378 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0141 | Iter Mean Loss 5.1975
2020-11-05 18:33:27,381 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:27,390 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2503 | Iter Mean Loss 6.2503
2020-11-05 18:33:27,398 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2574 | Iter Mean Loss 4.2538
2020-11-05 18:33:27,406 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1793 | Iter Mean Loss 5.2290
2020-11-05 18:33:27,413 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2490 | Iter Mean Loss 5.4840
2020-11-05 18:33:27,422 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0045 | Iter Mean Loss 5.1881
2020-11-05 18:33:27,424 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:27,432 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2436 | Iter Mean Loss 6.2436
2020-11-05 18:33:27,440 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2515 | Iter Mean Loss 4.2475
2020-11-05 18:33:27,448 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1661 | Iter Mean Loss 5.2204
2020-11-05 18:33:27,456 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2370 | Iter Mean Loss 5.4746
2020-11-05 18:33:27,463 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9949 | Iter Mean Loss 5.1786
2020-11-05 18:33:27,465 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:27,474 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2368 | Iter Mean Loss 6.2368
2020-11-05 18:33:27,481 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2456 | Iter Mean Loss 4.2412
2020-11-05 18:33:27,489 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1530 | Iter Mean Loss 5.2118
2020-11-05 18:33:27,497 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2251 | Iter Mean Loss 5.4651
2020-11-05 18:33:27,504 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9853 | Iter Mean Loss 5.1691
2020-11-05 18:33:27,506 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:27,514 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2300 | Iter Mean Loss 6.2300
2020-11-05 18:33:27,521 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2397 | Iter Mean Loss 4.2349
2020-11-05 18:33:27,528 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1398 | Iter Mean Loss 5.2032
2020-11-05 18:33:27,535 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.4556
2020-11-05 18:33:27,542 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9757 | Iter Mean Loss 5.1596
2020-11-05 18:33:27,544 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:27,552 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2233 | Iter Mean Loss 6.2233
2020-11-05 18:33:27,560 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2337 | Iter Mean Loss 4.2285
2020-11-05 18:33:27,567 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1266 | Iter Mean Loss 5.1945
2020-11-05 18:33:27,574 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2011 | Iter Mean Loss 5.4462
2020-11-05 18:33:27,581 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9660 | Iter Mean Loss 5.1501
2020-11-05 18:33:27,583 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:27,591 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2166 | Iter Mean Loss 6.2166
2020-11-05 18:33:27,599 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2276 | Iter Mean Loss 4.2221
2020-11-05 18:33:27,608 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1133 | Iter Mean Loss 5.1859
2020-11-05 18:33:27,615 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1891 | Iter Mean Loss 5.4367
2020-11-05 18:33:27,623 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9563 | Iter Mean Loss 5.1406
2020-11-05 18:33:27,625 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:27,634 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2098 | Iter Mean Loss 6.2098
2020-11-05 18:33:27,642 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2216 | Iter Mean Loss 4.2157
2020-11-05 18:33:27,650 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.1001 | Iter Mean Loss 5.1772
2020-11-05 18:33:27,658 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1771 | Iter Mean Loss 5.4271
2020-11-05 18:33:27,665 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9466 | Iter Mean Loss 5.1310
2020-11-05 18:33:27,667 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:27,676 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.2031 | Iter Mean Loss 6.2031
2020-11-05 18:33:27,684 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2155 | Iter Mean Loss 4.2093
2020-11-05 18:33:27,692 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0869 | Iter Mean Loss 5.1685
2020-11-05 18:33:27,700 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1650 | Iter Mean Loss 5.4176
2020-11-05 18:33:27,707 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9369 | Iter Mean Loss 5.1215
2020-11-05 18:33:27,709 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:27,717 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1964 | Iter Mean Loss 6.1964
2020-11-05 18:33:27,724 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2093 | Iter Mean Loss 4.2029
2020-11-05 18:33:27,731 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0736 | Iter Mean Loss 5.1598
2020-11-05 18:33:27,738 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1530 | Iter Mean Loss 5.4081
2020-11-05 18:33:27,745 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9272 | Iter Mean Loss 5.1119
2020-11-05 18:33:27,747 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:27,755 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1897 | Iter Mean Loss 6.1897
2020-11-05 18:33:27,762 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2031 | Iter Mean Loss 4.1964
2020-11-05 18:33:27,769 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0603 | Iter Mean Loss 5.1510
2020-11-05 18:33:27,776 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1409 | Iter Mean Loss 5.3985
2020-11-05 18:33:27,784 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9175 | Iter Mean Loss 5.1023
2020-11-05 18:33:27,786 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:27,794 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 6.1830
2020-11-05 18:33:27,802 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1969 | Iter Mean Loss 4.1899
2020-11-05 18:33:27,810 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0470 | Iter Mean Loss 5.1423
2020-11-05 18:33:27,817 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1288 | Iter Mean Loss 5.3889
2020-11-05 18:33:27,825 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9077 | Iter Mean Loss 5.0927
2020-11-05 18:33:27,828 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:27,836 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1763 | Iter Mean Loss 6.1763
2020-11-05 18:33:27,844 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 4.1835
2020-11-05 18:33:27,852 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0337 | Iter Mean Loss 5.1336
2020-11-05 18:33:27,860 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1167 | Iter Mean Loss 5.3793
2020-11-05 18:33:27,867 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8979 | Iter Mean Loss 5.0830
2020-11-05 18:33:27,870 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:27,878 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1696 | Iter Mean Loss 6.1696
2020-11-05 18:33:27,886 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1843 | Iter Mean Loss 4.1770
2020-11-05 18:33:27,894 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0204 | Iter Mean Loss 5.1248
2020-11-05 18:33:27,902 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1045 | Iter Mean Loss 5.3697
2020-11-05 18:33:27,909 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8881 | Iter Mean Loss 5.0734
2020-11-05 18:33:27,911 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:27,919 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1630 | Iter Mean Loss 6.1630
2020-11-05 18:33:27,926 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1780 | Iter Mean Loss 4.1705
2020-11-05 18:33:27,934 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.0071 | Iter Mean Loss 5.1160
2020-11-05 18:33:27,941 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0924 | Iter Mean Loss 5.3601
2020-11-05 18:33:27,948 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8783 | Iter Mean Loss 5.0637
2020-11-05 18:33:27,950 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:27,957 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1563 | Iter Mean Loss 6.1563
2020-11-05 18:33:27,964 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1716 | Iter Mean Loss 4.1640
2020-11-05 18:33:27,972 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9937 | Iter Mean Loss 5.1072
2020-11-05 18:33:27,979 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0803 | Iter Mean Loss 5.3505
2020-11-05 18:33:27,986 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8685 | Iter Mean Loss 5.0541
2020-11-05 18:33:27,988 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:27,996 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1497 | Iter Mean Loss 6.1497
2020-11-05 18:33:28,004 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1652 | Iter Mean Loss 4.1574
2020-11-05 18:33:28,012 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9804 | Iter Mean Loss 5.0984
2020-11-05 18:33:28,019 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0681 | Iter Mean Loss 5.3408
2020-11-05 18:33:28,027 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8586 | Iter Mean Loss 5.0444
2020-11-05 18:33:28,029 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:28,038 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1430 | Iter Mean Loss 6.1430
2020-11-05 18:33:28,046 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1588 | Iter Mean Loss 4.1509
2020-11-05 18:33:28,053 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9670 | Iter Mean Loss 5.0896
2020-11-05 18:33:28,061 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0559 | Iter Mean Loss 5.3312
2020-11-05 18:33:28,069 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8488 | Iter Mean Loss 5.0347
2020-11-05 18:33:28,071 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:28,080 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1364 | Iter Mean Loss 6.1364
2020-11-05 18:33:28,087 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1523 | Iter Mean Loss 4.1443
2020-11-05 18:33:28,095 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9537 | Iter Mean Loss 5.0808
2020-11-05 18:33:28,103 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0437 | Iter Mean Loss 5.3215
2020-11-05 18:33:28,110 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8389 | Iter Mean Loss 5.0250
2020-11-05 18:33:28,112 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:28,120 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1298 | Iter Mean Loss 6.1298
2020-11-05 18:33:28,127 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1458 | Iter Mean Loss 4.1378
2020-11-05 18:33:28,135 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9403 | Iter Mean Loss 5.0719
2020-11-05 18:33:28,142 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0315 | Iter Mean Loss 5.3118
2020-11-05 18:33:28,149 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8290 | Iter Mean Loss 5.0153
2020-11-05 18:33:28,151 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:28,159 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1232 | Iter Mean Loss 6.1232
2020-11-05 18:33:28,166 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1392 | Iter Mean Loss 4.1312
2020-11-05 18:33:28,173 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9269 | Iter Mean Loss 5.0631
2020-11-05 18:33:28,180 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0193 | Iter Mean Loss 5.3022
2020-11-05 18:33:28,187 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8191 | Iter Mean Loss 5.0055
2020-11-05 18:33:28,189 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:28,197 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1166 | Iter Mean Loss 6.1166
2020-11-05 18:33:28,205 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1327 | Iter Mean Loss 4.1246
2020-11-05 18:33:28,213 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9135 | Iter Mean Loss 5.0543
2020-11-05 18:33:28,221 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.0071 | Iter Mean Loss 5.2925
2020-11-05 18:33:28,229 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8092 | Iter Mean Loss 4.9958
2020-11-05 18:33:28,231 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:28,239 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1100 | Iter Mean Loss 6.1100
2020-11-05 18:33:28,247 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1261 | Iter Mean Loss 4.1180
2020-11-05 18:33:28,254 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.9002 | Iter Mean Loss 5.0454
2020-11-05 18:33:28,262 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9949 | Iter Mean Loss 5.2828
2020-11-05 18:33:28,269 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7993 | Iter Mean Loss 4.9861
2020-11-05 18:33:28,271 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:28,279 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.1034 | Iter Mean Loss 6.1034
2020-11-05 18:33:28,287 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1195 | Iter Mean Loss 4.1114
2020-11-05 18:33:28,295 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8868 | Iter Mean Loss 5.0366
2020-11-05 18:33:28,302 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9827 | Iter Mean Loss 5.2731
2020-11-05 18:33:28,309 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7893 | Iter Mean Loss 4.9763
2020-11-05 18:33:28,312 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:28,320 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0969 | Iter Mean Loss 6.0969
2020-11-05 18:33:28,328 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1128 | Iter Mean Loss 4.1048
2020-11-05 18:33:28,336 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8734 | Iter Mean Loss 5.0277
2020-11-05 18:33:28,343 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9704 | Iter Mean Loss 5.2634
2020-11-05 18:33:28,350 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7794 | Iter Mean Loss 4.9666
2020-11-05 18:33:28,352 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:28,360 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0903 | Iter Mean Loss 6.0903
2020-11-05 18:33:28,367 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1062 | Iter Mean Loss 4.0982
2020-11-05 18:33:28,374 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8600 | Iter Mean Loss 5.0188
2020-11-05 18:33:28,381 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9582 | Iter Mean Loss 5.2537
2020-11-05 18:33:28,388 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7695 | Iter Mean Loss 4.9568
2020-11-05 18:33:28,391 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:28,398 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0838 | Iter Mean Loss 6.0838
2020-11-05 18:33:28,406 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0995 | Iter Mean Loss 4.0916
2020-11-05 18:33:28,414 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8466 | Iter Mean Loss 5.0100
2020-11-05 18:33:28,421 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9459 | Iter Mean Loss 5.2440
2020-11-05 18:33:28,429 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7595 | Iter Mean Loss 4.9471
2020-11-05 18:33:28,431 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:28,439 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0773 | Iter Mean Loss 6.0773
2020-11-05 18:33:28,446 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0928 | Iter Mean Loss 4.0850
2020-11-05 18:33:28,454 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8332 | Iter Mean Loss 5.0011
2020-11-05 18:33:28,462 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9337 | Iter Mean Loss 5.2342
2020-11-05 18:33:28,469 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7495 | Iter Mean Loss 4.9373
2020-11-05 18:33:28,471 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:28,480 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0708 | Iter Mean Loss 6.0708
2020-11-05 18:33:28,487 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0860 | Iter Mean Loss 4.0784
2020-11-05 18:33:28,494 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8198 | Iter Mean Loss 4.9922
2020-11-05 18:33:28,502 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9215 | Iter Mean Loss 5.2245
2020-11-05 18:33:28,509 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7396 | Iter Mean Loss 4.9275
2020-11-05 18:33:28,512 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:28,520 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0643 | Iter Mean Loss 6.0643
2020-11-05 18:33:28,527 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0793 | Iter Mean Loss 4.0718
2020-11-05 18:33:28,534 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.8064 | Iter Mean Loss 4.9834
2020-11-05 18:33:28,541 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.9092 | Iter Mean Loss 5.2148
2020-11-05 18:33:28,548 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7296 | Iter Mean Loss 4.9178
2020-11-05 18:33:28,550 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,558 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0579 | Iter Mean Loss 6.0579
2020-11-05 18:33:28,565 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0725 | Iter Mean Loss 4.0652
2020-11-05 18:33:28,572 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7931 | Iter Mean Loss 4.9745
2020-11-05 18:33:28,579 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8970 | Iter Mean Loss 5.2051
2020-11-05 18:33:28,586 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7197 | Iter Mean Loss 4.9080
2020-11-05 18:33:28,588 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,596 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0514 | Iter Mean Loss 6.0514
2020-11-05 18:33:28,603 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0657 | Iter Mean Loss 4.0586
2020-11-05 18:33:28,611 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7797 | Iter Mean Loss 4.9656
2020-11-05 18:33:28,618 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8847 | Iter Mean Loss 5.1954
2020-11-05 18:33:28,626 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7097 | Iter Mean Loss 4.8983
2020-11-05 18:33:28,628 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,636 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0450 | Iter Mean Loss 6.0450
2020-11-05 18:33:28,644 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0589 | Iter Mean Loss 4.0520
2020-11-05 18:33:28,652 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7664 | Iter Mean Loss 4.9568
2020-11-05 18:33:28,660 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8725 | Iter Mean Loss 5.1857
2020-11-05 18:33:28,667 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6998 | Iter Mean Loss 4.8885
2020-11-05 18:33:28,669 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,678 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0386 | Iter Mean Loss 6.0386
2020-11-05 18:33:28,685 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0521 | Iter Mean Loss 4.0454
2020-11-05 18:33:28,692 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7530 | Iter Mean Loss 4.9479
2020-11-05 18:33:28,700 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8603 | Iter Mean Loss 5.1760
2020-11-05 18:33:28,708 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6898 | Iter Mean Loss 4.8788
2020-11-05 18:33:28,710 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,718 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0322 | Iter Mean Loss 6.0322
2020-11-05 18:33:28,725 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0453 | Iter Mean Loss 4.0388
2020-11-05 18:33:28,733 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7397 | Iter Mean Loss 4.9391
2020-11-05 18:33:28,740 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8481 | Iter Mean Loss 5.1663
2020-11-05 18:33:28,747 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6799 | Iter Mean Loss 4.8690
2020-11-05 18:33:28,749 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,757 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0259 | Iter Mean Loss 6.0259
2020-11-05 18:33:28,764 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0385 | Iter Mean Loss 4.0322
2020-11-05 18:33:28,771 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7264 | Iter Mean Loss 4.9303
2020-11-05 18:33:28,778 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.1567
2020-11-05 18:33:28,785 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6699 | Iter Mean Loss 4.8593
2020-11-05 18:33:28,787 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:28,795 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0195 | Iter Mean Loss 6.0195
2020-11-05 18:33:28,802 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0317 | Iter Mean Loss 4.0256
2020-11-05 18:33:28,809 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.7131 | Iter Mean Loss 4.9214
2020-11-05 18:33:28,817 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8237 | Iter Mean Loss 5.1470
2020-11-05 18:33:28,824 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6600 | Iter Mean Loss 4.8496
2020-11-05 18:33:28,826 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:28,835 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0132 | Iter Mean Loss 6.0132
2020-11-05 18:33:28,842 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0249 | Iter Mean Loss 4.0191
2020-11-05 18:33:28,850 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6998 | Iter Mean Loss 4.9126
2020-11-05 18:33:28,857 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.8115 | Iter Mean Loss 5.1373
2020-11-05 18:33:28,865 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6501 | Iter Mean Loss 4.8399
2020-11-05 18:33:28,868 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:28,877 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0069 | Iter Mean Loss 6.0069
2020-11-05 18:33:28,884 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0181 | Iter Mean Loss 4.0125
2020-11-05 18:33:28,892 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6865 | Iter Mean Loss 4.9038
2020-11-05 18:33:28,900 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7993 | Iter Mean Loss 5.1277
2020-11-05 18:33:28,908 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6401 | Iter Mean Loss 4.8302
2020-11-05 18:33:28,910 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:28,918 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 6.0007 | Iter Mean Loss 6.0007
2020-11-05 18:33:28,925 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0112 | Iter Mean Loss 4.0059
2020-11-05 18:33:28,933 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6733 | Iter Mean Loss 4.8950
2020-11-05 18:33:28,940 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7872 | Iter Mean Loss 5.1181
2020-11-05 18:33:28,947 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6302 | Iter Mean Loss 4.8205
2020-11-05 18:33:28,949 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:28,957 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9944 | Iter Mean Loss 5.9944
2020-11-05 18:33:28,964 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0044 | Iter Mean Loss 3.9994
2020-11-05 18:33:28,971 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 4.8863
2020-11-05 18:33:28,978 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7751 | Iter Mean Loss 5.1085
2020-11-05 18:33:28,985 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6204 | Iter Mean Loss 4.8109
2020-11-05 18:33:28,987 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:28,995 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9882 | Iter Mean Loss 5.9882
2020-11-05 18:33:29,002 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9976 | Iter Mean Loss 3.9929
2020-11-05 18:33:29,009 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6468 | Iter Mean Loss 4.8775
2020-11-05 18:33:29,017 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7629 | Iter Mean Loss 5.0989
2020-11-05 18:33:29,025 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6105 | Iter Mean Loss 4.8012
2020-11-05 18:33:29,027 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:29,035 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9820 | Iter Mean Loss 5.9820
2020-11-05 18:33:29,043 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9908 | Iter Mean Loss 3.9864
2020-11-05 18:33:29,050 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6337 | Iter Mean Loss 4.8688
2020-11-05 18:33:29,058 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7509 | Iter Mean Loss 5.0893
2020-11-05 18:33:29,065 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6006 | Iter Mean Loss 4.7916
2020-11-05 18:33:29,067 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:29,076 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9758 | Iter Mean Loss 5.9758
2020-11-05 18:33:29,083 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9840 | Iter Mean Loss 3.9799
2020-11-05 18:33:29,091 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6205 | Iter Mean Loss 4.8601
2020-11-05 18:33:29,098 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7388 | Iter Mean Loss 5.0798
2020-11-05 18:33:29,106 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5908 | Iter Mean Loss 4.7820
2020-11-05 18:33:29,108 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:29,116 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9696 | Iter Mean Loss 5.9696
2020-11-05 18:33:29,124 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9772 | Iter Mean Loss 3.9734
2020-11-05 18:33:29,132 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.6074 | Iter Mean Loss 4.8514
2020-11-05 18:33:29,139 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7268 | Iter Mean Loss 5.0702
2020-11-05 18:33:29,146 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5810 | Iter Mean Loss 4.7724
2020-11-05 18:33:29,148 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,156 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9635 | Iter Mean Loss 5.9635
2020-11-05 18:33:29,163 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9704 | Iter Mean Loss 3.9670
2020-11-05 18:33:29,170 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5943 | Iter Mean Loss 4.8427
2020-11-05 18:33:29,177 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7148 | Iter Mean Loss 5.0607
2020-11-05 18:33:29,184 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5712 | Iter Mean Loss 4.7628
2020-11-05 18:33:29,186 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,193 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9574 | Iter Mean Loss 5.9574
2020-11-05 18:33:29,201 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9637 | Iter Mean Loss 3.9605
2020-11-05 18:33:29,208 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5813 | Iter Mean Loss 4.8341
2020-11-05 18:33:29,215 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.7028 | Iter Mean Loss 5.0513
2020-11-05 18:33:29,222 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5615 | Iter Mean Loss 4.7533
2020-11-05 18:33:29,224 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,233 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9513 | Iter Mean Loss 5.9513
2020-11-05 18:33:29,240 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9569 | Iter Mean Loss 3.9541
2020-11-05 18:33:29,247 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5683 | Iter Mean Loss 4.8255
2020-11-05 18:33:29,257 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6908 | Iter Mean Loss 5.0418
2020-11-05 18:33:29,267 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5517 | Iter Mean Loss 4.7438
2020-11-05 18:33:29,271 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,281 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9453 | Iter Mean Loss 5.9453
2020-11-05 18:33:29,292 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9502 | Iter Mean Loss 3.9477
2020-11-05 18:33:29,302 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5553 | Iter Mean Loss 4.8169
2020-11-05 18:33:29,312 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6789 | Iter Mean Loss 5.0324
2020-11-05 18:33:29,323 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5420 | Iter Mean Loss 4.7343
2020-11-05 18:33:29,326 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,336 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9393 | Iter Mean Loss 5.9393
2020-11-05 18:33:29,346 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9435 | Iter Mean Loss 3.9414
2020-11-05 18:33:29,355 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5423 | Iter Mean Loss 4.8084
2020-11-05 18:33:29,364 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6670 | Iter Mean Loss 5.0230
2020-11-05 18:33:29,373 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5323 | Iter Mean Loss 4.7249
2020-11-05 18:33:29,375 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,383 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9333 | Iter Mean Loss 5.9333
2020-11-05 18:33:29,392 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9368 | Iter Mean Loss 3.9350
2020-11-05 18:33:29,400 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5294 | Iter Mean Loss 4.7998
2020-11-05 18:33:29,407 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6552 | Iter Mean Loss 5.0137
2020-11-05 18:33:29,414 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5227 | Iter Mean Loss 4.7155
2020-11-05 18:33:29,416 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,426 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9273 | Iter Mean Loss 5.9273
2020-11-05 18:33:29,436 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9301 | Iter Mean Loss 3.9287
2020-11-05 18:33:29,446 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5166 | Iter Mean Loss 4.7913
2020-11-05 18:33:29,455 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6434 | Iter Mean Loss 5.0043
2020-11-05 18:33:29,462 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5131 | Iter Mean Loss 4.7061
2020-11-05 18:33:29,464 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,473 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9214 | Iter Mean Loss 5.9214
2020-11-05 18:33:29,481 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9235 | Iter Mean Loss 3.9224
2020-11-05 18:33:29,489 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.5038 | Iter Mean Loss 4.7829
2020-11-05 18:33:29,496 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6316 | Iter Mean Loss 4.9951
2020-11-05 18:33:29,504 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 4.6967
2020-11-05 18:33:29,506 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,514 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9154 | Iter Mean Loss 5.9154
2020-11-05 18:33:29,523 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9169 | Iter Mean Loss 3.9162
2020-11-05 18:33:29,530 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4910 | Iter Mean Loss 4.7745
2020-11-05 18:33:29,538 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6199 | Iter Mean Loss 4.9858
2020-11-05 18:33:29,545 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4939 | Iter Mean Loss 4.6874
2020-11-05 18:33:29,547 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,555 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9096 | Iter Mean Loss 5.9096
2020-11-05 18:33:29,562 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9103 | Iter Mean Loss 3.9100
2020-11-05 18:33:29,569 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4783 | Iter Mean Loss 4.7661
2020-11-05 18:33:29,576 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 4.9766
2020-11-05 18:33:29,584 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4844 | Iter Mean Loss 4.6782
2020-11-05 18:33:29,585 - root - INFO - Evaluate: Epoch 0647 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,593 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.9037 | Iter Mean Loss 5.9037
2020-11-05 18:33:29,600 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9038 | Iter Mean Loss 3.9038
2020-11-05 18:33:29,608 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4656 | Iter Mean Loss 4.7577
2020-11-05 18:33:29,615 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5966 | Iter Mean Loss 4.9674
2020-11-05 18:33:29,622 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4749 | Iter Mean Loss 4.6689
2020-11-05 18:33:29,624 - root - INFO - Evaluate: Epoch 0648 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,631 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8979 | Iter Mean Loss 5.8979
2020-11-05 18:33:29,639 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8973 | Iter Mean Loss 3.8976
2020-11-05 18:33:29,647 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4530 | Iter Mean Loss 4.7494
2020-11-05 18:33:29,654 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5850 | Iter Mean Loss 4.9583
2020-11-05 18:33:29,662 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4655 | Iter Mean Loss 4.6597
2020-11-05 18:33:29,664 - root - INFO - Evaluate: Epoch 0649 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,672 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8921 | Iter Mean Loss 5.8921
2020-11-05 18:33:29,680 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8908 | Iter Mean Loss 3.8915
2020-11-05 18:33:29,687 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4404 | Iter Mean Loss 4.7411
2020-11-05 18:33:29,695 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5734 | Iter Mean Loss 4.9492
2020-11-05 18:33:29,703 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4561 | Iter Mean Loss 4.6506
2020-11-05 18:33:29,705 - root - INFO - Evaluate: Epoch 0650 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,714 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8864 | Iter Mean Loss 5.8864
2020-11-05 18:33:29,721 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8844 | Iter Mean Loss 3.8854
2020-11-05 18:33:29,729 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4279 | Iter Mean Loss 4.7329
2020-11-05 18:33:29,737 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5619 | Iter Mean Loss 4.9402
2020-11-05 18:33:29,745 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4468 | Iter Mean Loss 4.6415
2020-11-05 18:33:29,747 - root - INFO - Evaluate: Epoch 0651 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,755 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8806 | Iter Mean Loss 5.8806
2020-11-05 18:33:29,762 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8780 | Iter Mean Loss 3.8793
2020-11-05 18:33:29,769 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4154 | Iter Mean Loss 4.7247
2020-11-05 18:33:29,776 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5505 | Iter Mean Loss 4.9311
2020-11-05 18:33:29,783 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4375 | Iter Mean Loss 4.6324
2020-11-05 18:33:29,785 - root - INFO - Evaluate: Epoch 0652 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,793 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8749 | Iter Mean Loss 5.8749
2020-11-05 18:33:29,800 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8717 | Iter Mean Loss 3.8733
2020-11-05 18:33:29,807 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.4030 | Iter Mean Loss 4.7165
2020-11-05 18:33:29,814 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5391 | Iter Mean Loss 4.9222
2020-11-05 18:33:29,821 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4282 | Iter Mean Loss 4.6234
2020-11-05 18:33:29,823 - root - INFO - Evaluate: Epoch 0653 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,831 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8693 | Iter Mean Loss 5.8693
2020-11-05 18:33:29,838 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8654 | Iter Mean Loss 3.8673
2020-11-05 18:33:29,846 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3907 | Iter Mean Loss 4.7084
2020-11-05 18:33:29,853 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5278 | Iter Mean Loss 4.9133
2020-11-05 18:33:29,861 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4190 | Iter Mean Loss 4.6144
2020-11-05 18:33:29,863 - root - INFO - Evaluate: Epoch 0654 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,871 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8636 | Iter Mean Loss 5.8636
2020-11-05 18:33:29,879 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8591 | Iter Mean Loss 3.8614
2020-11-05 18:33:29,887 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3784 | Iter Mean Loss 4.7004
2020-11-05 18:33:29,895 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5165 | Iter Mean Loss 4.9044
2020-11-05 18:33:29,902 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4099 | Iter Mean Loss 4.6055
2020-11-05 18:33:29,904 - root - INFO - Evaluate: Epoch 0655 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,912 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 5.8580
2020-11-05 18:33:29,920 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 3.8555
2020-11-05 18:33:29,927 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3662 | Iter Mean Loss 4.6924
2020-11-05 18:33:29,935 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.5053 | Iter Mean Loss 4.8956
2020-11-05 18:33:29,942 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4008 | Iter Mean Loss 4.5966
2020-11-05 18:33:29,945 - root - INFO - Evaluate: Epoch 0656 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,953 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8525 | Iter Mean Loss 5.8525
2020-11-05 18:33:29,961 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8467 | Iter Mean Loss 3.8496
2020-11-05 18:33:29,968 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3540 | Iter Mean Loss 4.6844
2020-11-05 18:33:29,975 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4941 | Iter Mean Loss 4.8868
2020-11-05 18:33:29,982 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 4.5878
2020-11-05 18:33:29,984 - root - INFO - Evaluate: Epoch 0657 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:29,992 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 5.8469
2020-11-05 18:33:29,999 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8406 | Iter Mean Loss 3.8438
2020-11-05 18:33:30,006 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3419 | Iter Mean Loss 4.6765
2020-11-05 18:33:30,013 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4830 | Iter Mean Loss 4.8781
2020-11-05 18:33:30,021 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3827 | Iter Mean Loss 4.5790
2020-11-05 18:33:30,023 - root - INFO - Evaluate: Epoch 0658 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,031 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8414 | Iter Mean Loss 5.8414
2020-11-05 18:33:30,039 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8346 | Iter Mean Loss 3.8380
2020-11-05 18:33:30,046 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3298 | Iter Mean Loss 4.6686
2020-11-05 18:33:30,054 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4719 | Iter Mean Loss 4.8694
2020-11-05 18:33:30,061 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3737 | Iter Mean Loss 4.5703
2020-11-05 18:33:30,064 - root - INFO - Evaluate: Epoch 0659 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,072 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8359 | Iter Mean Loss 5.8359
2020-11-05 18:33:30,080 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8285 | Iter Mean Loss 3.8322
2020-11-05 18:33:30,087 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3179 | Iter Mean Loss 4.6608
2020-11-05 18:33:30,095 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4610 | Iter Mean Loss 4.8608
2020-11-05 18:33:30,102 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 4.5616
2020-11-05 18:33:30,105 - root - INFO - Evaluate: Epoch 0660 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,113 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8305 | Iter Mean Loss 5.8305
2020-11-05 18:33:30,121 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8226 | Iter Mean Loss 3.8265
2020-11-05 18:33:30,129 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.3060 | Iter Mean Loss 4.6530
2020-11-05 18:33:30,136 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4500 | Iter Mean Loss 4.8523
2020-11-05 18:33:30,144 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3560 | Iter Mean Loss 4.5530
2020-11-05 18:33:30,146 - root - INFO - Evaluate: Epoch 0661 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,154 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8251 | Iter Mean Loss 5.8251
2020-11-05 18:33:30,162 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8167 | Iter Mean Loss 3.8209
2020-11-05 18:33:30,169 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 4.6453
2020-11-05 18:33:30,176 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4392 | Iter Mean Loss 4.8438
2020-11-05 18:33:30,184 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3472 | Iter Mean Loss 4.5444
2020-11-05 18:33:30,186 - root - INFO - Evaluate: Epoch 0662 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,193 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8197 | Iter Mean Loss 5.8197
2020-11-05 18:33:30,200 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8108 | Iter Mean Loss 3.8153
2020-11-05 18:33:30,207 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2823 | Iter Mean Loss 4.6376
2020-11-05 18:33:30,215 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4284 | Iter Mean Loss 4.8353
2020-11-05 18:33:30,221 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3385 | Iter Mean Loss 4.5359
2020-11-05 18:33:30,223 - root - INFO - Evaluate: Epoch 0663 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,231 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8144 | Iter Mean Loss 5.8144
2020-11-05 18:33:30,238 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8050 | Iter Mean Loss 3.8097
2020-11-05 18:33:30,246 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2706 | Iter Mean Loss 4.6300
2020-11-05 18:33:30,253 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4176 | Iter Mean Loss 4.8269
2020-11-05 18:33:30,261 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 4.5275
2020-11-05 18:33:30,263 - root - INFO - Evaluate: Epoch 0664 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,272 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8090 | Iter Mean Loss 5.8090
2020-11-05 18:33:30,279 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7993 | Iter Mean Loss 3.8042
2020-11-05 18:33:30,287 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2590 | Iter Mean Loss 4.6224
2020-11-05 18:33:30,295 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.4070 | Iter Mean Loss 4.8186
2020-11-05 18:33:30,303 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3212 | Iter Mean Loss 4.5191
2020-11-05 18:33:30,305 - root - INFO - Evaluate: Epoch 0665 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,313 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.8038 | Iter Mean Loss 5.8038
2020-11-05 18:33:30,323 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7936 | Iter Mean Loss 3.7987
2020-11-05 18:33:30,331 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2474 | Iter Mean Loss 4.6149
2020-11-05 18:33:30,340 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3964 | Iter Mean Loss 4.8103
2020-11-05 18:33:30,348 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3126 | Iter Mean Loss 4.5107
2020-11-05 18:33:30,350 - root - INFO - Evaluate: Epoch 0666 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,360 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7985 | Iter Mean Loss 5.7985
2020-11-05 18:33:30,368 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7880 | Iter Mean Loss 3.7932
2020-11-05 18:33:30,376 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2359 | Iter Mean Loss 4.6074
2020-11-05 18:33:30,383 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3858 | Iter Mean Loss 4.8020
2020-11-05 18:33:30,392 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3041 | Iter Mean Loss 4.5025
2020-11-05 18:33:30,394 - root - INFO - Evaluate: Epoch 0667 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,403 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7933 | Iter Mean Loss 5.7933
2020-11-05 18:33:30,410 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7824 | Iter Mean Loss 3.7878
2020-11-05 18:33:30,418 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2244 | Iter Mean Loss 4.6000
2020-11-05 18:33:30,426 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 4.7939
2020-11-05 18:33:30,434 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2957 | Iter Mean Loss 4.4942
2020-11-05 18:33:30,436 - root - INFO - Evaluate: Epoch 0668 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,444 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7881 | Iter Mean Loss 5.7881
2020-11-05 18:33:30,452 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7769 | Iter Mean Loss 3.7825
2020-11-05 18:33:30,462 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 4.5927
2020-11-05 18:33:30,475 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3649 | Iter Mean Loss 4.7857
2020-11-05 18:33:30,486 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2873 | Iter Mean Loss 4.4861
2020-11-05 18:33:30,489 - root - INFO - Evaluate: Epoch 0669 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,501 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7829 | Iter Mean Loss 5.7829
2020-11-05 18:33:30,511 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7714 | Iter Mean Loss 3.7772
2020-11-05 18:33:30,521 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.2018 | Iter Mean Loss 4.5854
2020-11-05 18:33:30,531 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3546 | Iter Mean Loss 4.7777
2020-11-05 18:33:30,539 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2790 | Iter Mean Loss 4.4779
2020-11-05 18:33:30,542 - root - INFO - Evaluate: Epoch 0670 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,552 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7778 | Iter Mean Loss 5.7778
2020-11-05 18:33:30,562 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7660 | Iter Mean Loss 3.7719
2020-11-05 18:33:30,571 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1905 | Iter Mean Loss 4.5781
2020-11-05 18:33:30,579 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3443 | Iter Mean Loss 4.7697
2020-11-05 18:33:30,587 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2708 | Iter Mean Loss 4.4699
2020-11-05 18:33:30,589 - root - INFO - Evaluate: Epoch 0671 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,598 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7727 | Iter Mean Loss 5.7727
2020-11-05 18:33:30,606 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7607 | Iter Mean Loss 3.7667
2020-11-05 18:33:30,614 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1794 | Iter Mean Loss 4.5709
2020-11-05 18:33:30,622 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3341 | Iter Mean Loss 4.7617
2020-11-05 18:33:30,630 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2626 | Iter Mean Loss 4.4619
2020-11-05 18:33:30,632 - root - INFO - Evaluate: Epoch 0672 | NDCG 0.2817 | MSE 0.3179
2020-11-05 18:33:30,641 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7677 | Iter Mean Loss 5.7677
2020-11-05 18:33:30,649 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7554 | Iter Mean Loss 3.7615
2020-11-05 18:33:30,658 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1683 | Iter Mean Loss 4.5638
2020-11-05 18:33:30,666 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3240 | Iter Mean Loss 4.7538
2020-11-05 18:33:30,674 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2544 | Iter Mean Loss 4.4540
2020-11-05 18:33:30,676 - root - INFO - Evaluate: Epoch 0673 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,686 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7626 | Iter Mean Loss 5.7626
2020-11-05 18:33:30,694 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7502 | Iter Mean Loss 3.7564
2020-11-05 18:33:30,703 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1573 | Iter Mean Loss 4.5567
2020-11-05 18:33:30,711 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3139 | Iter Mean Loss 4.7460
2020-11-05 18:33:30,720 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2464 | Iter Mean Loss 4.4461
2020-11-05 18:33:30,722 - root - INFO - Evaluate: Epoch 0674 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,732 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7576 | Iter Mean Loss 5.7576
2020-11-05 18:33:30,741 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7450 | Iter Mean Loss 3.7513
2020-11-05 18:33:30,749 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1463 | Iter Mean Loss 4.5497
2020-11-05 18:33:30,757 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.3039 | Iter Mean Loss 4.7382
2020-11-05 18:33:30,765 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2384 | Iter Mean Loss 4.4382
2020-11-05 18:33:30,767 - root - INFO - Evaluate: Epoch 0675 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,777 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7527 | Iter Mean Loss 5.7527
2020-11-05 18:33:30,785 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7399 | Iter Mean Loss 3.7463
2020-11-05 18:33:30,792 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1354 | Iter Mean Loss 4.5427
2020-11-05 18:33:30,800 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2940 | Iter Mean Loss 4.7305
2020-11-05 18:33:30,808 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2304 | Iter Mean Loss 4.4305
2020-11-05 18:33:30,810 - root - INFO - Evaluate: Epoch 0676 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,818 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7477 | Iter Mean Loss 5.7477
2020-11-05 18:33:30,826 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7349 | Iter Mean Loss 3.7413
2020-11-05 18:33:30,834 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1246 | Iter Mean Loss 4.5358
2020-11-05 18:33:30,841 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2841 | Iter Mean Loss 4.7228
2020-11-05 18:33:30,849 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 4.4228
2020-11-05 18:33:30,851 - root - INFO - Evaluate: Epoch 0677 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,860 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7428 | Iter Mean Loss 5.7428
2020-11-05 18:33:30,868 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7299 | Iter Mean Loss 3.7364
2020-11-05 18:33:30,876 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1139 | Iter Mean Loss 4.5289
2020-11-05 18:33:30,884 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2743 | Iter Mean Loss 4.7152
2020-11-05 18:33:30,892 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2147 | Iter Mean Loss 4.4151
2020-11-05 18:33:30,894 - root - INFO - Evaluate: Epoch 0678 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,904 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7379 | Iter Mean Loss 5.7379
2020-11-05 18:33:30,912 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7250 | Iter Mean Loss 3.7315
2020-11-05 18:33:30,921 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.1032 | Iter Mean Loss 4.5221
2020-11-05 18:33:30,929 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2646 | Iter Mean Loss 4.7077
2020-11-05 18:33:30,938 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 4.4075
2020-11-05 18:33:30,940 - root - INFO - Evaluate: Epoch 0679 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,948 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7331 | Iter Mean Loss 5.7331
2020-11-05 18:33:30,957 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7201 | Iter Mean Loss 3.7266
2020-11-05 18:33:30,966 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0926 | Iter Mean Loss 4.5153
2020-11-05 18:33:30,973 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2549 | Iter Mean Loss 4.7002
2020-11-05 18:33:30,982 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1992 | Iter Mean Loss 4.4000
2020-11-05 18:33:30,984 - root - INFO - Evaluate: Epoch 0680 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:30,992 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7283 | Iter Mean Loss 5.7283
2020-11-05 18:33:31,000 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7153 | Iter Mean Loss 3.7218
2020-11-05 18:33:31,008 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0821 | Iter Mean Loss 4.5086
2020-11-05 18:33:31,016 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.6928
2020-11-05 18:33:31,025 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1916 | Iter Mean Loss 4.3925
2020-11-05 18:33:31,027 - root - INFO - Evaluate: Epoch 0681 | NDCG 0.2817 | MSE 0.3180
2020-11-05 18:33:31,035 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7235 | Iter Mean Loss 5.7235
2020-11-05 18:33:31,043 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7106 | Iter Mean Loss 3.7170
2020-11-05 18:33:31,051 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0717 | Iter Mean Loss 4.5019
2020-11-05 18:33:31,059 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2358 | Iter Mean Loss 4.6854
2020-11-05 18:33:31,067 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1840 | Iter Mean Loss 4.3851
2020-11-05 18:33:31,070 - root - INFO - Evaluate: Epoch 0682 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,079 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7187 | Iter Mean Loss 5.7187
2020-11-05 18:33:31,087 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7059 | Iter Mean Loss 3.7123
2020-11-05 18:33:31,096 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0613 | Iter Mean Loss 4.4953
2020-11-05 18:33:31,104 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2263 | Iter Mean Loss 4.6781
2020-11-05 18:33:31,113 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1765 | Iter Mean Loss 4.3778
2020-11-05 18:33:31,115 - root - INFO - Evaluate: Epoch 0683 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,124 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7140 | Iter Mean Loss 5.7140
2020-11-05 18:33:31,133 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7013 | Iter Mean Loss 3.7077
2020-11-05 18:33:31,141 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0510 | Iter Mean Loss 4.4888
2020-11-05 18:33:31,149 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2169 | Iter Mean Loss 4.6708
2020-11-05 18:33:31,157 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1690 | Iter Mean Loss 4.3705
2020-11-05 18:33:31,161 - root - INFO - Evaluate: Epoch 0684 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,170 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7093 | Iter Mean Loss 5.7093
2020-11-05 18:33:31,179 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6968 | Iter Mean Loss 3.7030
2020-11-05 18:33:31,186 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0407 | Iter Mean Loss 4.4823
2020-11-05 18:33:31,194 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.2076 | Iter Mean Loss 4.6636
2020-11-05 18:33:31,202 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1616 | Iter Mean Loss 4.3632
2020-11-05 18:33:31,204 - root - INFO - Evaluate: Epoch 0685 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,212 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7046 | Iter Mean Loss 5.7046
2020-11-05 18:33:31,220 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6923 | Iter Mean Loss 3.6984
2020-11-05 18:33:31,228 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0305 | Iter Mean Loss 4.4758
2020-11-05 18:33:31,236 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1984 | Iter Mean Loss 4.6564
2020-11-05 18:33:31,244 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1543 | Iter Mean Loss 4.3560
2020-11-05 18:33:31,246 - root - INFO - Evaluate: Epoch 0686 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,254 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.7000 | Iter Mean Loss 5.7000
2020-11-05 18:33:31,262 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6878 | Iter Mean Loss 3.6939
2020-11-05 18:33:31,270 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0204 | Iter Mean Loss 4.4694
2020-11-05 18:33:31,278 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1891 | Iter Mean Loss 4.6493
2020-11-05 18:33:31,287 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1470 | Iter Mean Loss 4.3489
2020-11-05 18:33:31,289 - root - INFO - Evaluate: Epoch 0687 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,297 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6953 | Iter Mean Loss 5.6953
2020-11-05 18:33:31,306 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6834 | Iter Mean Loss 3.6894
2020-11-05 18:33:31,315 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0104 | Iter Mean Loss 4.4630
2020-11-05 18:33:31,325 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1800 | Iter Mean Loss 4.6423
2020-11-05 18:33:31,333 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1398 | Iter Mean Loss 4.3418
2020-11-05 18:33:31,336 - root - INFO - Evaluate: Epoch 0688 | NDCG 0.2817 | MSE 0.3181
2020-11-05 18:33:31,345 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6907 | Iter Mean Loss 5.6907
2020-11-05 18:33:31,354 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6791 | Iter Mean Loss 3.6849
2020-11-05 18:33:31,363 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 6.0004 | Iter Mean Loss 4.4567
2020-11-05 18:33:31,371 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1709 | Iter Mean Loss 4.6353
2020-11-05 18:33:31,379 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1326 | Iter Mean Loss 4.3348
2020-11-05 18:33:31,381 - root - INFO - Evaluate: Epoch 0689 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,391 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6862 | Iter Mean Loss 5.6862
2020-11-05 18:33:31,398 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6748 | Iter Mean Loss 3.6805
2020-11-05 18:33:31,406 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9905 | Iter Mean Loss 4.4505
2020-11-05 18:33:31,414 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1619 | Iter Mean Loss 4.6283
2020-11-05 18:33:31,421 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1255 | Iter Mean Loss 4.3278
2020-11-05 18:33:31,423 - root - INFO - Evaluate: Epoch 0690 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,432 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6816 | Iter Mean Loss 5.6816
2020-11-05 18:33:31,439 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6706 | Iter Mean Loss 3.6761
2020-11-05 18:33:31,447 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9806 | Iter Mean Loss 4.4443
2020-11-05 18:33:31,455 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1530 | Iter Mean Loss 4.6215
2020-11-05 18:33:31,462 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1185 | Iter Mean Loss 4.3209
2020-11-05 18:33:31,464 - root - INFO - Evaluate: Epoch 0691 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,473 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6771 | Iter Mean Loss 5.6771
2020-11-05 18:33:31,481 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6664 | Iter Mean Loss 3.6718
2020-11-05 18:33:31,490 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9708 | Iter Mean Loss 4.4381
2020-11-05 18:33:31,499 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1441 | Iter Mean Loss 4.6146
2020-11-05 18:33:31,508 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1115 | Iter Mean Loss 4.3140
2020-11-05 18:33:31,510 - root - INFO - Evaluate: Epoch 0692 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,520 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6726 | Iter Mean Loss 5.6726
2020-11-05 18:33:31,528 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6623 | Iter Mean Loss 3.6675
2020-11-05 18:33:31,538 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9611 | Iter Mean Loss 4.4320
2020-11-05 18:33:31,546 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1352 | Iter Mean Loss 4.6078
2020-11-05 18:33:31,555 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1046 | Iter Mean Loss 4.3072
2020-11-05 18:33:31,557 - root - INFO - Evaluate: Epoch 0693 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,566 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6682 | Iter Mean Loss 5.6682
2020-11-05 18:33:31,576 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6583 | Iter Mean Loss 3.6632
2020-11-05 18:33:31,584 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9514 | Iter Mean Loss 4.4260
2020-11-05 18:33:31,593 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1265 | Iter Mean Loss 4.6011
2020-11-05 18:33:31,601 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0977 | Iter Mean Loss 4.3004
2020-11-05 18:33:31,603 - root - INFO - Evaluate: Epoch 0694 | NDCG 0.2817 | MSE 0.3182
2020-11-05 18:33:31,611 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6637 | Iter Mean Loss 5.6637
2020-11-05 18:33:31,619 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 3.6590
2020-11-05 18:33:31,627 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9418 | Iter Mean Loss 4.4199
2020-11-05 18:33:31,634 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1178 | Iter Mean Loss 4.5944
2020-11-05 18:33:31,641 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0909 | Iter Mean Loss 4.2937
2020-11-05 18:33:31,644 - root - INFO - Evaluate: Epoch 0695 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,652 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6593 | Iter Mean Loss 5.6593
2020-11-05 18:33:31,659 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6503 | Iter Mean Loss 3.6548
2020-11-05 18:33:31,667 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9323 | Iter Mean Loss 4.4140
2020-11-05 18:33:31,674 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1091 | Iter Mean Loss 4.5878
2020-11-05 18:33:31,682 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0841 | Iter Mean Loss 4.2870
2020-11-05 18:33:31,685 - root - INFO - Evaluate: Epoch 0696 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,693 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6549 | Iter Mean Loss 5.6549
2020-11-05 18:33:31,701 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6464 | Iter Mean Loss 3.6507
2020-11-05 18:33:31,710 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9228 | Iter Mean Loss 4.4081
2020-11-05 18:33:31,717 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.1005 | Iter Mean Loss 4.5812
2020-11-05 18:33:31,726 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0774 | Iter Mean Loss 4.2804
2020-11-05 18:33:31,728 - root - INFO - Evaluate: Epoch 0697 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,737 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6506 | Iter Mean Loss 5.6506
2020-11-05 18:33:31,745 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6426 | Iter Mean Loss 3.6466
2020-11-05 18:33:31,753 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9134 | Iter Mean Loss 4.4022
2020-11-05 18:33:31,761 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0920 | Iter Mean Loss 4.5746
2020-11-05 18:33:31,769 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0707 | Iter Mean Loss 4.2738
2020-11-05 18:33:31,771 - root - INFO - Evaluate: Epoch 0698 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,781 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6462 | Iter Mean Loss 5.6462
2020-11-05 18:33:31,789 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6388 | Iter Mean Loss 3.6425
2020-11-05 18:33:31,797 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.9040 | Iter Mean Loss 4.3963
2020-11-05 18:33:31,805 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0835 | Iter Mean Loss 4.5681
2020-11-05 18:33:31,812 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0641 | Iter Mean Loss 4.2673
2020-11-05 18:33:31,815 - root - INFO - Evaluate: Epoch 0699 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,823 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6419 | Iter Mean Loss 5.6419
2020-11-05 18:33:31,830 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6350 | Iter Mean Loss 3.6385
2020-11-05 18:33:31,837 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8947 | Iter Mean Loss 4.3906
2020-11-05 18:33:31,845 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0751 | Iter Mean Loss 4.5617
2020-11-05 18:33:31,852 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0576 | Iter Mean Loss 4.2609
2020-11-05 18:33:31,854 - root - INFO - Evaluate: Epoch 0700 | NDCG 0.2817 | MSE 0.3183
2020-11-05 18:33:31,862 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6376 | Iter Mean Loss 5.6376
2020-11-05 18:33:31,870 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6313 | Iter Mean Loss 3.6345
2020-11-05 18:33:31,878 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8855 | Iter Mean Loss 4.3848
2020-11-05 18:33:31,885 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0667 | Iter Mean Loss 4.5553
2020-11-05 18:33:31,893 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0511 | Iter Mean Loss 4.2544
2020-11-05 18:33:31,895 - root - INFO - Evaluate: Epoch 0701 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:31,904 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6334 | Iter Mean Loss 5.6334
2020-11-05 18:33:31,912 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6277 | Iter Mean Loss 3.6305
2020-11-05 18:33:31,921 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8763 | Iter Mean Loss 4.3791
2020-11-05 18:33:31,929 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0584 | Iter Mean Loss 4.5489
2020-11-05 18:33:31,937 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0446 | Iter Mean Loss 4.2481
2020-11-05 18:33:31,940 - root - INFO - Evaluate: Epoch 0702 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:31,948 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6291 | Iter Mean Loss 5.6291
2020-11-05 18:33:31,956 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6240 | Iter Mean Loss 3.6266
2020-11-05 18:33:31,964 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8671 | Iter Mean Loss 4.3734
2020-11-05 18:33:31,972 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0501 | Iter Mean Loss 4.5426
2020-11-05 18:33:31,980 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0382 | Iter Mean Loss 4.2417
2020-11-05 18:33:31,982 - root - INFO - Evaluate: Epoch 0703 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:31,991 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6249 | Iter Mean Loss 5.6249
2020-11-05 18:33:31,998 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6205 | Iter Mean Loss 3.6227
2020-11-05 18:33:32,006 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8580 | Iter Mean Loss 4.3678
2020-11-05 18:33:32,013 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0419 | Iter Mean Loss 4.5363
2020-11-05 18:33:32,020 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0319 | Iter Mean Loss 4.2354
2020-11-05 18:33:32,024 - root - INFO - Evaluate: Epoch 0704 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:32,032 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6207 | Iter Mean Loss 5.6207
2020-11-05 18:33:32,040 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6170 | Iter Mean Loss 3.6188
2020-11-05 18:33:32,047 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8490 | Iter Mean Loss 4.3622
2020-11-05 18:33:32,054 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0337 | Iter Mean Loss 4.5301
2020-11-05 18:33:32,062 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0255 | Iter Mean Loss 4.2292
2020-11-05 18:33:32,064 - root - INFO - Evaluate: Epoch 0705 | NDCG 0.2817 | MSE 0.3184
2020-11-05 18:33:32,072 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6165 | Iter Mean Loss 5.6165
2020-11-05 18:33:32,079 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6135 | Iter Mean Loss 3.6150
2020-11-05 18:33:32,087 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8400 | Iter Mean Loss 4.3567
2020-11-05 18:33:32,095 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0256 | Iter Mean Loss 4.5239
2020-11-05 18:33:32,103 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0193 | Iter Mean Loss 4.2230
2020-11-05 18:33:32,106 - root - INFO - Evaluate: Epoch 0706 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:32,114 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6124 | Iter Mean Loss 5.6124
2020-11-05 18:33:32,123 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6101 | Iter Mean Loss 3.6112
2020-11-05 18:33:32,131 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8311 | Iter Mean Loss 4.3512
2020-11-05 18:33:32,139 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0176 | Iter Mean Loss 4.5178
2020-11-05 18:33:32,147 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0131 | Iter Mean Loss 4.2168
2020-11-05 18:33:32,149 - root - INFO - Evaluate: Epoch 0707 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:32,158 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6082 | Iter Mean Loss 5.6082
2020-11-05 18:33:32,166 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6067 | Iter Mean Loss 3.6075
2020-11-05 18:33:32,173 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8222 | Iter Mean Loss 4.3457
2020-11-05 18:33:32,181 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0096 | Iter Mean Loss 4.5117
2020-11-05 18:33:32,189 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0069 | Iter Mean Loss 4.2107
2020-11-05 18:33:32,191 - root - INFO - Evaluate: Epoch 0708 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:32,200 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6041 | Iter Mean Loss 5.6041
2020-11-05 18:33:32,207 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6033 | Iter Mean Loss 3.6037
2020-11-05 18:33:32,215 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8134 | Iter Mean Loss 4.3403
2020-11-05 18:33:32,222 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 5.0016 | Iter Mean Loss 4.5056
2020-11-05 18:33:32,229 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.0008 | Iter Mean Loss 4.2047
2020-11-05 18:33:32,231 - root - INFO - Evaluate: Epoch 0709 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:32,239 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.6000 | Iter Mean Loss 5.6000
2020-11-05 18:33:32,247 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6000 | Iter Mean Loss 3.6000
2020-11-05 18:33:32,254 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.8047 | Iter Mean Loss 4.3349
2020-11-05 18:33:32,261 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9937 | Iter Mean Loss 4.4996
2020-11-05 18:33:32,268 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9947 | Iter Mean Loss 4.1986
2020-11-05 18:33:32,270 - root - INFO - Evaluate: Epoch 0710 | NDCG 0.2817 | MSE 0.3185
2020-11-05 18:33:32,278 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5959 | Iter Mean Loss 5.5959
2020-11-05 18:33:32,286 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5968 | Iter Mean Loss 3.5964
2020-11-05 18:33:32,294 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7959 | Iter Mean Loss 4.3295
2020-11-05 18:33:32,302 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9858 | Iter Mean Loss 4.4936
2020-11-05 18:33:32,310 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9887 | Iter Mean Loss 4.1926
2020-11-05 18:33:32,312 - root - INFO - Evaluate: Epoch 0711 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:32,321 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5919 | Iter Mean Loss 5.5919
2020-11-05 18:33:32,330 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5935 | Iter Mean Loss 3.5927
2020-11-05 18:33:32,338 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7873 | Iter Mean Loss 4.3242
2020-11-05 18:33:32,346 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9780 | Iter Mean Loss 4.4877
2020-11-05 18:33:32,354 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9827 | Iter Mean Loss 4.1867
2020-11-05 18:33:32,356 - root - INFO - Evaluate: Epoch 0712 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:32,365 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5879 | Iter Mean Loss 5.5879
2020-11-05 18:33:32,372 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5904 | Iter Mean Loss 3.5891
2020-11-05 18:33:32,381 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7786 | Iter Mean Loss 4.3189
2020-11-05 18:33:32,388 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9702 | Iter Mean Loss 4.4818
2020-11-05 18:33:32,396 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9768 | Iter Mean Loss 4.1808
2020-11-05 18:33:32,398 - root - INFO - Evaluate: Epoch 0713 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:32,406 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5838 | Iter Mean Loss 5.5838
2020-11-05 18:33:32,415 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 3.5855
2020-11-05 18:33:32,424 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7701 | Iter Mean Loss 4.3137
2020-11-05 18:33:32,433 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9625 | Iter Mean Loss 4.4759
2020-11-05 18:33:32,441 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9709 | Iter Mean Loss 4.1749
2020-11-05 18:33:32,444 - root - INFO - Evaluate: Epoch 0714 | NDCG 0.2817 | MSE 0.3186
2020-11-05 18:33:32,452 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5798 | Iter Mean Loss 5.5798
2020-11-05 18:33:32,460 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5841 | Iter Mean Loss 3.5820
2020-11-05 18:33:32,467 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7615 | Iter Mean Loss 4.3085
2020-11-05 18:33:32,474 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9548 | Iter Mean Loss 4.4701
2020-11-05 18:33:32,482 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9650 | Iter Mean Loss 4.1691
2020-11-05 18:33:32,484 - root - INFO - Evaluate: Epoch 0715 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:32,493 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5759 | Iter Mean Loss 5.5759
2020-11-05 18:33:32,502 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5810 | Iter Mean Loss 3.5784
2020-11-05 18:33:32,510 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7530 | Iter Mean Loss 4.3033
2020-11-05 18:33:32,517 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9472 | Iter Mean Loss 4.4643
2020-11-05 18:33:32,526 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9592 | Iter Mean Loss 4.1633
2020-11-05 18:33:32,529 - root - INFO - Evaluate: Epoch 0716 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:32,539 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5719 | Iter Mean Loss 5.5719
2020-11-05 18:33:32,548 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5780 | Iter Mean Loss 3.5749
2020-11-05 18:33:32,557 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7446 | Iter Mean Loss 4.2982
2020-11-05 18:33:32,564 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9396 | Iter Mean Loss 4.4585
2020-11-05 18:33:32,574 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9534 | Iter Mean Loss 4.1575
2020-11-05 18:33:32,576 - root - INFO - Evaluate: Epoch 0717 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:32,585 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5680 | Iter Mean Loss 5.5680
2020-11-05 18:33:32,594 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5750 | Iter Mean Loss 3.5715
2020-11-05 18:33:32,601 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7362 | Iter Mean Loss 4.2931
2020-11-05 18:33:32,609 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9320 | Iter Mean Loss 4.4528
2020-11-05 18:33:32,617 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9477 | Iter Mean Loss 4.1518
2020-11-05 18:33:32,619 - root - INFO - Evaluate: Epoch 0718 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:32,626 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5640 | Iter Mean Loss 5.5640
2020-11-05 18:33:32,634 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5720 | Iter Mean Loss 3.5680
2020-11-05 18:33:32,641 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7278 | Iter Mean Loss 4.2880
2020-11-05 18:33:32,648 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9245 | Iter Mean Loss 4.4471
2020-11-05 18:33:32,655 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 4.1461
2020-11-05 18:33:32,657 - root - INFO - Evaluate: Epoch 0719 | NDCG 0.2817 | MSE 0.3187
2020-11-05 18:33:32,665 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5601 | Iter Mean Loss 5.5601
2020-11-05 18:33:32,673 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5691 | Iter Mean Loss 3.5646
2020-11-05 18:33:32,680 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7195 | Iter Mean Loss 4.2829
2020-11-05 18:33:32,687 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9170 | Iter Mean Loss 4.4414
2020-11-05 18:33:32,694 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9363 | Iter Mean Loss 4.1404
2020-11-05 18:33:32,696 - root - INFO - Evaluate: Epoch 0720 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:32,705 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5562 | Iter Mean Loss 5.5562
2020-11-05 18:33:32,713 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5662 | Iter Mean Loss 3.5612
2020-11-05 18:33:32,720 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7113 | Iter Mean Loss 4.2779
2020-11-05 18:33:32,728 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9095 | Iter Mean Loss 4.4358
2020-11-05 18:33:32,736 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9307 | Iter Mean Loss 4.1348
2020-11-05 18:33:32,738 - root - INFO - Evaluate: Epoch 0721 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:32,747 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5524 | Iter Mean Loss 5.5524
2020-11-05 18:33:32,754 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 3.5578
2020-11-05 18:33:32,762 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.7030 | Iter Mean Loss 4.2729
2020-11-05 18:33:32,770 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.9021 | Iter Mean Loss 4.4302
2020-11-05 18:33:32,778 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9251 | Iter Mean Loss 4.1292
2020-11-05 18:33:32,780 - root - INFO - Evaluate: Epoch 0722 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:32,788 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5485 | Iter Mean Loss 5.5485
2020-11-05 18:33:32,796 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5605 | Iter Mean Loss 3.5545
2020-11-05 18:33:32,804 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6949 | Iter Mean Loss 4.2679
2020-11-05 18:33:32,812 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8948 | Iter Mean Loss 4.4247
2020-11-05 18:33:32,819 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9195 | Iter Mean Loss 4.1236
2020-11-05 18:33:32,821 - root - INFO - Evaluate: Epoch 0723 | NDCG 0.2817 | MSE 0.3188
2020-11-05 18:33:32,829 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5447 | Iter Mean Loss 5.5447
2020-11-05 18:33:32,836 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5577 | Iter Mean Loss 3.5512
2020-11-05 18:33:32,843 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6867 | Iter Mean Loss 4.2630
2020-11-05 18:33:32,850 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8875 | Iter Mean Loss 4.4191
2020-11-05 18:33:32,858 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9140 | Iter Mean Loss 4.1181
2020-11-05 18:33:32,860 - root - INFO - Evaluate: Epoch 0724 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:32,867 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5408 | Iter Mean Loss 5.5408
2020-11-05 18:33:32,875 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5549 | Iter Mean Loss 3.5479
2020-11-05 18:33:32,882 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6786 | Iter Mean Loss 4.2581
2020-11-05 18:33:32,889 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8802 | Iter Mean Loss 4.4136
2020-11-05 18:33:32,897 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9085 | Iter Mean Loss 4.1126
2020-11-05 18:33:32,899 - root - INFO - Evaluate: Epoch 0725 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:32,907 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5370 | Iter Mean Loss 5.5370
2020-11-05 18:33:32,915 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5522 | Iter Mean Loss 3.5446
2020-11-05 18:33:32,923 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6705 | Iter Mean Loss 4.2532
2020-11-05 18:33:32,930 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8729 | Iter Mean Loss 4.4082
2020-11-05 18:33:32,937 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.9031 | Iter Mean Loss 4.1071
2020-11-05 18:33:32,940 - root - INFO - Evaluate: Epoch 0726 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:32,948 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5332 | Iter Mean Loss 5.5332
2020-11-05 18:33:32,956 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5495 | Iter Mean Loss 3.5413
2020-11-05 18:33:32,963 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6625 | Iter Mean Loss 4.2484
2020-11-05 18:33:32,971 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8657 | Iter Mean Loss 4.4027
2020-11-05 18:33:32,979 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8977 | Iter Mean Loss 4.1017
2020-11-05 18:33:32,981 - root - INFO - Evaluate: Epoch 0727 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:32,988 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5294 | Iter Mean Loss 5.5294
2020-11-05 18:33:32,996 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5468 | Iter Mean Loss 3.5381
2020-11-05 18:33:33,004 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6545 | Iter Mean Loss 4.2436
2020-11-05 18:33:33,011 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8585 | Iter Mean Loss 4.3973
2020-11-05 18:33:33,019 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8923 | Iter Mean Loss 4.0963
2020-11-05 18:33:33,021 - root - INFO - Evaluate: Epoch 0728 | NDCG 0.2817 | MSE 0.3189
2020-11-05 18:33:33,030 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5257 | Iter Mean Loss 5.5257
2020-11-05 18:33:33,037 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5441 | Iter Mean Loss 3.5349
2020-11-05 18:33:33,045 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6465 | Iter Mean Loss 4.2388
2020-11-05 18:33:33,052 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8514 | Iter Mean Loss 4.3919
2020-11-05 18:33:33,059 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 4.0909
2020-11-05 18:33:33,061 - root - INFO - Evaluate: Epoch 0729 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:33,068 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5219 | Iter Mean Loss 5.5219
2020-11-05 18:33:33,076 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5415 | Iter Mean Loss 3.5317
2020-11-05 18:33:33,083 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6386 | Iter Mean Loss 4.2340
2020-11-05 18:33:33,090 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8443 | Iter Mean Loss 4.3866
2020-11-05 18:33:33,097 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8817 | Iter Mean Loss 4.0856
2020-11-05 18:33:33,099 - root - INFO - Evaluate: Epoch 0730 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:33,107 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5182 | Iter Mean Loss 5.5182
2020-11-05 18:33:33,115 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5389 | Iter Mean Loss 3.5286
2020-11-05 18:33:33,122 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6307 | Iter Mean Loss 4.2293
2020-11-05 18:33:33,130 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8372 | Iter Mean Loss 4.3813
2020-11-05 18:33:33,138 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8764 | Iter Mean Loss 4.0803
2020-11-05 18:33:33,140 - root - INFO - Evaluate: Epoch 0731 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:33,148 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5145 | Iter Mean Loss 5.5145
2020-11-05 18:33:33,156 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5363 | Iter Mean Loss 3.5254
2020-11-05 18:33:33,163 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6229 | Iter Mean Loss 4.2246
2020-11-05 18:33:33,171 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8302 | Iter Mean Loss 4.3760
2020-11-05 18:33:33,178 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8711 | Iter Mean Loss 4.0750
2020-11-05 18:33:33,180 - root - INFO - Evaluate: Epoch 0732 | NDCG 0.2817 | MSE 0.3190
2020-11-05 18:33:33,189 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5108 | Iter Mean Loss 5.5108
2020-11-05 18:33:33,196 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5338 | Iter Mean Loss 3.5223
2020-11-05 18:33:33,204 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6151 | Iter Mean Loss 4.2199
2020-11-05 18:33:33,212 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8231 | Iter Mean Loss 4.3707
2020-11-05 18:33:33,219 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8659 | Iter Mean Loss 4.0697
2020-11-05 18:33:33,221 - root - INFO - Evaluate: Epoch 0733 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:33,229 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5071 | Iter Mean Loss 5.5071
2020-11-05 18:33:33,236 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5313 | Iter Mean Loss 3.5192
2020-11-05 18:33:33,243 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.6073 | Iter Mean Loss 4.2152
2020-11-05 18:33:33,250 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8162 | Iter Mean Loss 4.3654
2020-11-05 18:33:33,258 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8608 | Iter Mean Loss 4.0645
2020-11-05 18:33:33,260 - root - INFO - Evaluate: Epoch 0734 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:33,267 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.5034 | Iter Mean Loss 5.5034
2020-11-05 18:33:33,275 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5288 | Iter Mean Loss 3.5161
2020-11-05 18:33:33,282 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5995 | Iter Mean Loss 4.2106
2020-11-05 18:33:33,289 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8092 | Iter Mean Loss 4.3602
2020-11-05 18:33:33,296 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8556 | Iter Mean Loss 4.0593
2020-11-05 18:33:33,298 - root - INFO - Evaluate: Epoch 0735 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:33,306 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4997 | Iter Mean Loss 5.4997
2020-11-05 18:33:33,314 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5263 | Iter Mean Loss 3.5130
2020-11-05 18:33:33,322 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5918 | Iter Mean Loss 4.2059
2020-11-05 18:33:33,330 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.8023 | Iter Mean Loss 4.3550
2020-11-05 18:33:33,338 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8505 | Iter Mean Loss 4.0541
2020-11-05 18:33:33,340 - root - INFO - Evaluate: Epoch 0736 | NDCG 0.2817 | MSE 0.3191
2020-11-05 18:33:33,348 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4961 | Iter Mean Loss 5.4961
2020-11-05 18:33:33,356 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5239 | Iter Mean Loss 3.5100
2020-11-05 18:33:33,364 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5841 | Iter Mean Loss 4.2013
2020-11-05 18:33:33,371 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7954 | Iter Mean Loss 4.3499
2020-11-05 18:33:33,379 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8454 | Iter Mean Loss 4.0490
2020-11-05 18:33:33,381 - root - INFO - Evaluate: Epoch 0737 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:33,389 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4924 | Iter Mean Loss 5.4924
2020-11-05 18:33:33,397 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5214 | Iter Mean Loss 3.5069
2020-11-05 18:33:33,404 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5765 | Iter Mean Loss 4.1968
2020-11-05 18:33:33,412 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7886 | Iter Mean Loss 4.3447
2020-11-05 18:33:33,419 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8403 | Iter Mean Loss 4.0438
2020-11-05 18:33:33,421 - root - INFO - Evaluate: Epoch 0738 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:33,429 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4888 | Iter Mean Loss 5.4888
2020-11-05 18:33:33,436 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5190 | Iter Mean Loss 3.5039
2020-11-05 18:33:33,443 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5688 | Iter Mean Loss 4.1922
2020-11-05 18:33:33,450 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7817 | Iter Mean Loss 4.3396
2020-11-05 18:33:33,457 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8353 | Iter Mean Loss 4.0387
2020-11-05 18:33:33,459 - root - INFO - Evaluate: Epoch 0739 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:33,467 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4852 | Iter Mean Loss 5.4852
2020-11-05 18:33:33,474 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5166 | Iter Mean Loss 3.5009
2020-11-05 18:33:33,481 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5612 | Iter Mean Loss 4.1877
2020-11-05 18:33:33,488 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7749 | Iter Mean Loss 4.3345
2020-11-05 18:33:33,496 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 4.0337
2020-11-05 18:33:33,498 - root - INFO - Evaluate: Epoch 0740 | NDCG 0.2817 | MSE 0.3192
2020-11-05 18:33:33,505 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4816 | Iter Mean Loss 5.4816
2020-11-05 18:33:33,513 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5143 | Iter Mean Loss 3.4979
2020-11-05 18:33:33,521 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5537 | Iter Mean Loss 4.1832
2020-11-05 18:33:33,528 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7682 | Iter Mean Loss 4.3294
2020-11-05 18:33:33,536 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8253 | Iter Mean Loss 4.0286
2020-11-05 18:33:33,538 - root - INFO - Evaluate: Epoch 0741 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:33,546 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4780 | Iter Mean Loss 5.4780
2020-11-05 18:33:33,554 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5120 | Iter Mean Loss 3.4950
2020-11-05 18:33:33,561 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5462 | Iter Mean Loss 4.1787
2020-11-05 18:33:33,569 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7614 | Iter Mean Loss 4.3244
2020-11-05 18:33:33,577 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8203 | Iter Mean Loss 4.0236
2020-11-05 18:33:33,579 - root - INFO - Evaluate: Epoch 0742 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:33,587 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4744 | Iter Mean Loss 5.4744
2020-11-05 18:33:33,595 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5096 | Iter Mean Loss 3.4920
2020-11-05 18:33:33,603 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5386 | Iter Mean Loss 4.1742
2020-11-05 18:33:33,610 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7547 | Iter Mean Loss 4.3194
2020-11-05 18:33:33,617 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8154 | Iter Mean Loss 4.0186
2020-11-05 18:33:33,620 - root - INFO - Evaluate: Epoch 0743 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:33,628 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4709 | Iter Mean Loss 5.4709
2020-11-05 18:33:33,635 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5073 | Iter Mean Loss 3.4891
2020-11-05 18:33:33,642 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5312 | Iter Mean Loss 4.1698
2020-11-05 18:33:33,649 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7480 | Iter Mean Loss 4.3144
2020-11-05 18:33:33,656 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8105 | Iter Mean Loss 4.0136
2020-11-05 18:33:33,658 - root - INFO - Evaluate: Epoch 0744 | NDCG 0.2817 | MSE 0.3193
2020-11-05 18:33:33,666 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4673 | Iter Mean Loss 5.4673
2020-11-05 18:33:33,673 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5051 | Iter Mean Loss 3.4862
2020-11-05 18:33:33,681 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5237 | Iter Mean Loss 4.1654
2020-11-05 18:33:33,688 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 4.3094
2020-11-05 18:33:33,695 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8056 | Iter Mean Loss 4.0086
2020-11-05 18:33:33,697 - root - INFO - Evaluate: Epoch 0745 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:33,704 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4638 | Iter Mean Loss 5.4638
2020-11-05 18:33:33,712 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5028 | Iter Mean Loss 3.4833
2020-11-05 18:33:33,720 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5163 | Iter Mean Loss 4.1610
2020-11-05 18:33:33,727 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7348 | Iter Mean Loss 4.3044
2020-11-05 18:33:33,735 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.8008 | Iter Mean Loss 4.0037
2020-11-05 18:33:33,737 - root - INFO - Evaluate: Epoch 0746 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:33,745 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4602 | Iter Mean Loss 5.4602
2020-11-05 18:33:33,753 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5006 | Iter Mean Loss 3.4804
2020-11-05 18:33:33,760 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5089 | Iter Mean Loss 4.1566
2020-11-05 18:33:33,768 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7281 | Iter Mean Loss 4.2995
2020-11-05 18:33:33,775 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7960 | Iter Mean Loss 3.9988
2020-11-05 18:33:33,777 - root - INFO - Evaluate: Epoch 0747 | NDCG 0.2817 | MSE 0.3194
2020-11-05 18:33:33,786 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4567 | Iter Mean Loss 5.4567
2020-11-05 18:33:33,793 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4984 | Iter Mean Loss 3.4776
2020-11-05 18:33:33,801 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.5016 | Iter Mean Loss 4.1522
2020-11-05 18:33:33,809 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7216 | Iter Mean Loss 4.2946
2020-11-05 18:33:33,816 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7912 | Iter Mean Loss 3.9939
2020-11-05 18:33:33,819 - root - INFO - Evaluate: Epoch 0748 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:33,827 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4532 | Iter Mean Loss 5.4532
2020-11-05 18:33:33,835 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4962 | Iter Mean Loss 3.4747
2020-11-05 18:33:33,842 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4942 | Iter Mean Loss 4.1479
2020-11-05 18:33:33,849 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7150 | Iter Mean Loss 4.2897
2020-11-05 18:33:33,856 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7864 | Iter Mean Loss 3.9890
2020-11-05 18:33:33,858 - root - INFO - Evaluate: Epoch 0749 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:33,866 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4497 | Iter Mean Loss 5.4497
2020-11-05 18:33:33,873 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4940 | Iter Mean Loss 3.4719
2020-11-05 18:33:33,880 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4869 | Iter Mean Loss 4.1435
2020-11-05 18:33:33,887 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7085 | Iter Mean Loss 4.2848
2020-11-05 18:33:33,895 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7817 | Iter Mean Loss 3.9842
2020-11-05 18:33:33,897 - root - INFO - Evaluate: Epoch 0750 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:33,905 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4462 | Iter Mean Loss 5.4462
2020-11-05 18:33:33,912 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4918 | Iter Mean Loss 3.4690
2020-11-05 18:33:33,920 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4796 | Iter Mean Loss 4.1392
2020-11-05 18:33:33,927 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.7020 | Iter Mean Loss 4.2799
2020-11-05 18:33:33,934 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7769 | Iter Mean Loss 3.9793
2020-11-05 18:33:33,937 - root - INFO - Evaluate: Epoch 0751 | NDCG 0.2817 | MSE 0.3195
2020-11-05 18:33:33,945 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4428 | Iter Mean Loss 5.4428
2020-11-05 18:33:33,953 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4897 | Iter Mean Loss 3.4662
2020-11-05 18:33:33,960 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4724 | Iter Mean Loss 4.1349
2020-11-05 18:33:33,968 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6955 | Iter Mean Loss 4.2751
2020-11-05 18:33:33,976 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7722 | Iter Mean Loss 3.9745
2020-11-05 18:33:33,978 - root - INFO - Evaluate: Epoch 0752 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:33,986 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4393 | Iter Mean Loss 5.4393
2020-11-05 18:33:33,993 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4876 | Iter Mean Loss 3.4634
2020-11-05 18:33:34,001 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4651 | Iter Mean Loss 4.1307
2020-11-05 18:33:34,008 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6891 | Iter Mean Loss 4.2703
2020-11-05 18:33:34,017 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7676 | Iter Mean Loss 3.9697
2020-11-05 18:33:34,019 - root - INFO - Evaluate: Epoch 0753 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:34,027 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4358 | Iter Mean Loss 5.4358
2020-11-05 18:33:34,035 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 3.4607
2020-11-05 18:33:34,042 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4579 | Iter Mean Loss 4.1264
2020-11-05 18:33:34,049 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6826 | Iter Mean Loss 4.2655
2020-11-05 18:33:34,056 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7629 | Iter Mean Loss 3.9650
2020-11-05 18:33:34,058 - root - INFO - Evaluate: Epoch 0754 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:34,066 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4324 | Iter Mean Loss 5.4324
2020-11-05 18:33:34,073 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4834 | Iter Mean Loss 3.4579
2020-11-05 18:33:34,080 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4507 | Iter Mean Loss 4.1222
2020-11-05 18:33:34,087 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6762 | Iter Mean Loss 4.2607
2020-11-05 18:33:34,095 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7583 | Iter Mean Loss 3.9602
2020-11-05 18:33:34,097 - root - INFO - Evaluate: Epoch 0755 | NDCG 0.2817 | MSE 0.3196
2020-11-05 18:33:34,104 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4290 | Iter Mean Loss 5.4290
2020-11-05 18:33:34,111 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4813 | Iter Mean Loss 3.4551
2020-11-05 18:33:34,119 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4436 | Iter Mean Loss 4.1180
2020-11-05 18:33:34,126 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6698 | Iter Mean Loss 4.2559
2020-11-05 18:33:34,134 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7537 | Iter Mean Loss 3.9555
2020-11-05 18:33:34,136 - root - INFO - Evaluate: Epoch 0756 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:34,144 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4255 | Iter Mean Loss 5.4255
2020-11-05 18:33:34,152 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4793 | Iter Mean Loss 3.4524
2020-11-05 18:33:34,159 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4365 | Iter Mean Loss 4.1137
2020-11-05 18:33:34,167 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6635 | Iter Mean Loss 4.2512
2020-11-05 18:33:34,175 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7491 | Iter Mean Loss 3.9508
2020-11-05 18:33:34,177 - root - INFO - Evaluate: Epoch 0757 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:34,185 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4221 | Iter Mean Loss 5.4221
2020-11-05 18:33:34,193 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4772 | Iter Mean Loss 3.4497
2020-11-05 18:33:34,201 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4293 | Iter Mean Loss 4.1096
2020-11-05 18:33:34,208 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6572 | Iter Mean Loss 4.2465
2020-11-05 18:33:34,216 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7445 | Iter Mean Loss 3.9461
2020-11-05 18:33:34,218 - root - INFO - Evaluate: Epoch 0758 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:34,226 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4187 | Iter Mean Loss 5.4187
2020-11-05 18:33:34,234 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4752 | Iter Mean Loss 3.4469
2020-11-05 18:33:34,241 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4223 | Iter Mean Loss 4.1054
2020-11-05 18:33:34,248 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6508 | Iter Mean Loss 4.2417
2020-11-05 18:33:34,256 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7400 | Iter Mean Loss 3.9414
2020-11-05 18:33:34,258 - root - INFO - Evaluate: Epoch 0759 | NDCG 0.2817 | MSE 0.3197
2020-11-05 18:33:34,266 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4153 | Iter Mean Loss 5.4153
2020-11-05 18:33:34,273 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4732 | Iter Mean Loss 3.4442
2020-11-05 18:33:34,280 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4152 | Iter Mean Loss 4.1012
2020-11-05 18:33:34,287 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6445 | Iter Mean Loss 4.2371
2020-11-05 18:33:34,294 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7354 | Iter Mean Loss 3.9367
2020-11-05 18:33:34,296 - root - INFO - Evaluate: Epoch 0760 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:34,304 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4119 | Iter Mean Loss 5.4119
2020-11-05 18:33:34,311 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4712 | Iter Mean Loss 3.4416
2020-11-05 18:33:34,320 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4081 | Iter Mean Loss 4.0971
2020-11-05 18:33:34,328 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6383 | Iter Mean Loss 4.2324
2020-11-05 18:33:34,335 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7309 | Iter Mean Loss 3.9321
2020-11-05 18:33:34,338 - root - INFO - Evaluate: Epoch 0761 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:34,346 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4086 | Iter Mean Loss 5.4086
2020-11-05 18:33:34,354 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4692 | Iter Mean Loss 3.4389
2020-11-05 18:33:34,362 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.4011 | Iter Mean Loss 4.0930
2020-11-05 18:33:34,369 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6320 | Iter Mean Loss 4.2277
2020-11-05 18:33:34,377 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7265 | Iter Mean Loss 3.9275
2020-11-05 18:33:34,379 - root - INFO - Evaluate: Epoch 0762 | NDCG 0.2817 | MSE 0.3198
2020-11-05 18:33:34,387 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4052 | Iter Mean Loss 5.4052
2020-11-05 18:33:34,395 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4672 | Iter Mean Loss 3.4362
2020-11-05 18:33:34,403 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3941 | Iter Mean Loss 4.0888
2020-11-05 18:33:34,410 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6258 | Iter Mean Loss 4.2231
2020-11-05 18:33:34,418 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7220 | Iter Mean Loss 3.9229
2020-11-05 18:33:34,420 - root - INFO - Evaluate: Epoch 0763 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:34,428 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.4018 | Iter Mean Loss 5.4018
2020-11-05 18:33:34,436 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4653 | Iter Mean Loss 3.4336
2020-11-05 18:33:34,443 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3872 | Iter Mean Loss 4.0848
2020-11-05 18:33:34,451 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6196 | Iter Mean Loss 4.2185
2020-11-05 18:33:34,458 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7176 | Iter Mean Loss 3.9183
2020-11-05 18:33:34,460 - root - INFO - Evaluate: Epoch 0764 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:34,468 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3985 | Iter Mean Loss 5.3985
2020-11-05 18:33:34,475 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4633 | Iter Mean Loss 3.4309
2020-11-05 18:33:34,482 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3802 | Iter Mean Loss 4.0807
2020-11-05 18:33:34,489 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6134 | Iter Mean Loss 4.2139
2020-11-05 18:33:34,496 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7131 | Iter Mean Loss 3.9137
2020-11-05 18:33:34,498 - root - INFO - Evaluate: Epoch 0765 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:34,506 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3951 | Iter Mean Loss 5.3951
2020-11-05 18:33:34,513 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4614 | Iter Mean Loss 3.4283
2020-11-05 18:33:34,520 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3733 | Iter Mean Loss 4.0766
2020-11-05 18:33:34,527 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6072 | Iter Mean Loss 4.2093
2020-11-05 18:33:34,535 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7087 | Iter Mean Loss 3.9092
2020-11-05 18:33:34,537 - root - INFO - Evaluate: Epoch 0766 | NDCG 0.2817 | MSE 0.3199
2020-11-05 18:33:34,545 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3918 | Iter Mean Loss 5.3918
2020-11-05 18:33:34,552 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4595 | Iter Mean Loss 3.4257
2020-11-05 18:33:34,560 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3664 | Iter Mean Loss 4.0726
2020-11-05 18:33:34,567 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.6011 | Iter Mean Loss 4.2047
2020-11-05 18:33:34,575 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7044 | Iter Mean Loss 3.9046
2020-11-05 18:33:34,577 - root - INFO - Evaluate: Epoch 0767 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:34,586 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3885 | Iter Mean Loss 5.3885
2020-11-05 18:33:34,593 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 3.4230
2020-11-05 18:33:34,601 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3595 | Iter Mean Loss 4.0685
2020-11-05 18:33:34,608 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5950 | Iter Mean Loss 4.2001
2020-11-05 18:33:34,616 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.7000 | Iter Mean Loss 3.9001
2020-11-05 18:33:34,618 - root - INFO - Evaluate: Epoch 0768 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:34,626 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3852 | Iter Mean Loss 5.3852
2020-11-05 18:33:34,634 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4557 | Iter Mean Loss 3.4204
2020-11-05 18:33:34,642 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3526 | Iter Mean Loss 4.0645
2020-11-05 18:33:34,650 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5889 | Iter Mean Loss 4.1956
2020-11-05 18:33:34,657 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6957 | Iter Mean Loss 3.8956
2020-11-05 18:33:34,659 - root - INFO - Evaluate: Epoch 0769 | NDCG 0.2817 | MSE 0.3200
2020-11-05 18:33:34,667 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3818 | Iter Mean Loss 5.3818
2020-11-05 18:33:34,674 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4538 | Iter Mean Loss 3.4178
2020-11-05 18:33:34,681 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3457 | Iter Mean Loss 4.0605
2020-11-05 18:33:34,688 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5828 | Iter Mean Loss 4.1911
2020-11-05 18:33:34,695 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6913 | Iter Mean Loss 3.8911
2020-11-05 18:33:34,697 - root - INFO - Evaluate: Epoch 0770 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:33:34,705 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3785 | Iter Mean Loss 5.3785
2020-11-05 18:33:34,712 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4520 | Iter Mean Loss 3.4153
2020-11-05 18:33:34,719 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3389 | Iter Mean Loss 4.0565
2020-11-05 18:33:34,726 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5767 | Iter Mean Loss 4.1865
2020-11-05 18:33:34,734 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6870 | Iter Mean Loss 3.8866
2020-11-05 18:33:34,736 - root - INFO - Evaluate: Epoch 0771 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:33:34,744 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3753 | Iter Mean Loss 5.3753
2020-11-05 18:33:34,751 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4501 | Iter Mean Loss 3.4127
2020-11-05 18:33:34,759 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3321 | Iter Mean Loss 4.0525
2020-11-05 18:33:34,766 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5707 | Iter Mean Loss 4.1820
2020-11-05 18:33:34,774 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 3.8822
2020-11-05 18:33:34,776 - root - INFO - Evaluate: Epoch 0772 | NDCG 0.2817 | MSE 0.3201
2020-11-05 18:33:34,784 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3720 | Iter Mean Loss 5.3720
2020-11-05 18:33:34,792 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4483 | Iter Mean Loss 3.4101
2020-11-05 18:33:34,800 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3253 | Iter Mean Loss 4.0485
2020-11-05 18:33:34,808 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5647 | Iter Mean Loss 4.1776
2020-11-05 18:33:34,815 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6785 | Iter Mean Loss 3.8777
2020-11-05 18:33:34,817 - root - INFO - Evaluate: Epoch 0773 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:34,826 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3687 | Iter Mean Loss 5.3687
2020-11-05 18:33:34,833 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4465 | Iter Mean Loss 3.4076
2020-11-05 18:33:34,841 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3185 | Iter Mean Loss 4.0446
2020-11-05 18:33:34,849 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5586 | Iter Mean Loss 4.1731
2020-11-05 18:33:34,856 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6742 | Iter Mean Loss 3.8733
2020-11-05 18:33:34,858 - root - INFO - Evaluate: Epoch 0774 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:34,866 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3654 | Iter Mean Loss 5.3654
2020-11-05 18:33:34,874 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4447 | Iter Mean Loss 3.4050
2020-11-05 18:33:34,881 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3118 | Iter Mean Loss 4.0406
2020-11-05 18:33:34,888 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5527 | Iter Mean Loss 4.1686
2020-11-05 18:33:34,896 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6700 | Iter Mean Loss 3.8689
2020-11-05 18:33:34,898 - root - INFO - Evaluate: Epoch 0775 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:34,906 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3622 | Iter Mean Loss 5.3622
2020-11-05 18:33:34,913 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4429 | Iter Mean Loss 3.4025
2020-11-05 18:33:34,920 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.3050 | Iter Mean Loss 4.0367
2020-11-05 18:33:34,927 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5467 | Iter Mean Loss 4.1642
2020-11-05 18:33:34,934 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6658 | Iter Mean Loss 3.8645
2020-11-05 18:33:34,936 - root - INFO - Evaluate: Epoch 0776 | NDCG 0.2817 | MSE 0.3202
2020-11-05 18:33:34,945 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3589 | Iter Mean Loss 5.3589
2020-11-05 18:33:34,952 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4411 | Iter Mean Loss 3.4000
2020-11-05 18:33:34,959 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 4.0328
2020-11-05 18:33:34,967 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5407 | Iter Mean Loss 4.1598
2020-11-05 18:33:34,975 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6616 | Iter Mean Loss 3.8601
2020-11-05 18:33:34,977 - root - INFO - Evaluate: Epoch 0777 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:34,986 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3557 | Iter Mean Loss 5.3557
2020-11-05 18:33:34,993 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4393 | Iter Mean Loss 3.3975
2020-11-05 18:33:35,001 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2916 | Iter Mean Loss 4.0289
2020-11-05 18:33:35,009 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5348 | Iter Mean Loss 4.1553
2020-11-05 18:33:35,017 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6574 | Iter Mean Loss 3.8558
2020-11-05 18:33:35,020 - root - INFO - Evaluate: Epoch 0778 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:35,028 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3524 | Iter Mean Loss 5.3524
2020-11-05 18:33:35,036 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4375 | Iter Mean Loss 3.3950
2020-11-05 18:33:35,043 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2850 | Iter Mean Loss 4.0250
2020-11-05 18:33:35,051 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5289 | Iter Mean Loss 4.1509
2020-11-05 18:33:35,058 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6532 | Iter Mean Loss 3.8514
2020-11-05 18:33:35,060 - root - INFO - Evaluate: Epoch 0779 | NDCG 0.2817 | MSE 0.3203
2020-11-05 18:33:35,068 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3492 | Iter Mean Loss 5.3492
2020-11-05 18:33:35,075 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 3.3925
2020-11-05 18:33:35,083 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2783 | Iter Mean Loss 4.0211
2020-11-05 18:33:35,090 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5230 | Iter Mean Loss 4.1466
2020-11-05 18:33:35,097 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6491 | Iter Mean Loss 3.8471
2020-11-05 18:33:35,099 - root - INFO - Evaluate: Epoch 0780 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:33:35,106 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3460 | Iter Mean Loss 5.3460
2020-11-05 18:33:35,114 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4340 | Iter Mean Loss 3.3900
2020-11-05 18:33:35,121 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2717 | Iter Mean Loss 4.0172
2020-11-05 18:33:35,128 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 4.1422
2020-11-05 18:33:35,136 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6449 | Iter Mean Loss 3.8427
2020-11-05 18:33:35,138 - root - INFO - Evaluate: Epoch 0781 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:33:35,146 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3427 | Iter Mean Loss 5.3427
2020-11-05 18:33:35,154 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4323 | Iter Mean Loss 3.3875
2020-11-05 18:33:35,161 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2650 | Iter Mean Loss 4.0133
2020-11-05 18:33:35,168 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5112 | Iter Mean Loss 4.1378
2020-11-05 18:33:35,176 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6408 | Iter Mean Loss 3.8384
2020-11-05 18:33:35,178 - root - INFO - Evaluate: Epoch 0782 | NDCG 0.2817 | MSE 0.3204
2020-11-05 18:33:35,187 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3395 | Iter Mean Loss 5.3395
2020-11-05 18:33:35,195 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4305 | Iter Mean Loss 3.3850
2020-11-05 18:33:35,202 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2584 | Iter Mean Loss 4.0095
2020-11-05 18:33:35,210 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.5054 | Iter Mean Loss 4.1335
2020-11-05 18:33:35,217 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6367 | Iter Mean Loss 3.8341
2020-11-05 18:33:35,219 - root - INFO - Evaluate: Epoch 0783 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:35,228 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3363 | Iter Mean Loss 5.3363
2020-11-05 18:33:35,235 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4288 | Iter Mean Loss 3.3826
2020-11-05 18:33:35,243 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2518 | Iter Mean Loss 4.0057
2020-11-05 18:33:35,250 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4996 | Iter Mean Loss 4.1291
2020-11-05 18:33:35,258 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6326 | Iter Mean Loss 3.8298
2020-11-05 18:33:35,260 - root - INFO - Evaluate: Epoch 0784 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:35,268 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3331 | Iter Mean Loss 5.3331
2020-11-05 18:33:35,275 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4271 | Iter Mean Loss 3.3801
2020-11-05 18:33:35,283 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2453 | Iter Mean Loss 4.0018
2020-11-05 18:33:35,290 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4938 | Iter Mean Loss 4.1248
2020-11-05 18:33:35,297 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6286 | Iter Mean Loss 3.8256
2020-11-05 18:33:35,299 - root - INFO - Evaluate: Epoch 0785 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:35,306 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3299 | Iter Mean Loss 5.3299
2020-11-05 18:33:35,314 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4254 | Iter Mean Loss 3.3777
2020-11-05 18:33:35,323 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2387 | Iter Mean Loss 3.9980
2020-11-05 18:33:35,330 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4880 | Iter Mean Loss 4.1205
2020-11-05 18:33:35,337 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6245 | Iter Mean Loss 3.8213
2020-11-05 18:33:35,339 - root - INFO - Evaluate: Epoch 0786 | NDCG 0.2817 | MSE 0.3205
2020-11-05 18:33:35,347 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3267 | Iter Mean Loss 5.3267
2020-11-05 18:33:35,355 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4237 | Iter Mean Loss 3.3752
2020-11-05 18:33:35,363 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2322 | Iter Mean Loss 3.9942
2020-11-05 18:33:35,370 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4822 | Iter Mean Loss 4.1162
2020-11-05 18:33:35,378 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6205 | Iter Mean Loss 3.8171
2020-11-05 18:33:35,380 - root - INFO - Evaluate: Epoch 0787 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:35,388 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3236 | Iter Mean Loss 5.3236
2020-11-05 18:33:35,396 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4220 | Iter Mean Loss 3.3728
2020-11-05 18:33:35,404 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2256 | Iter Mean Loss 3.9904
2020-11-05 18:33:35,413 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4764 | Iter Mean Loss 4.1119
2020-11-05 18:33:35,423 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6165 | Iter Mean Loss 3.8128
2020-11-05 18:33:35,426 - root - INFO - Evaluate: Epoch 0788 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:35,436 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3204 | Iter Mean Loss 5.3204
2020-11-05 18:33:35,445 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4204 | Iter Mean Loss 3.3704
2020-11-05 18:33:35,453 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2191 | Iter Mean Loss 3.9866
2020-11-05 18:33:35,461 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4707 | Iter Mean Loss 4.1076
2020-11-05 18:33:35,469 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6125 | Iter Mean Loss 3.8086
2020-11-05 18:33:35,471 - root - INFO - Evaluate: Epoch 0789 | NDCG 0.2817 | MSE 0.3206
2020-11-05 18:33:35,479 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3172 | Iter Mean Loss 5.3172
2020-11-05 18:33:35,487 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4187 | Iter Mean Loss 3.3680
2020-11-05 18:33:35,494 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2126 | Iter Mean Loss 3.9829
2020-11-05 18:33:35,502 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4649 | Iter Mean Loss 4.1034
2020-11-05 18:33:35,509 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6085 | Iter Mean Loss 3.8044
2020-11-05 18:33:35,511 - root - INFO - Evaluate: Epoch 0790 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:33:35,519 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3141 | Iter Mean Loss 5.3141
2020-11-05 18:33:35,527 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4171 | Iter Mean Loss 3.3656
2020-11-05 18:33:35,535 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.2062 | Iter Mean Loss 3.9791
2020-11-05 18:33:35,542 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4592 | Iter Mean Loss 4.0991
2020-11-05 18:33:35,551 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6045 | Iter Mean Loss 3.8002
2020-11-05 18:33:35,553 - root - INFO - Evaluate: Epoch 0791 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:33:35,561 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3109 | Iter Mean Loss 5.3109
2020-11-05 18:33:35,569 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 3.3632
2020-11-05 18:33:35,578 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1997 | Iter Mean Loss 3.9753
2020-11-05 18:33:35,586 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4535 | Iter Mean Loss 4.0949
2020-11-05 18:33:35,596 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.6005 | Iter Mean Loss 3.7960
2020-11-05 18:33:35,598 - root - INFO - Evaluate: Epoch 0792 | NDCG 0.2817 | MSE 0.3207
2020-11-05 18:33:35,606 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3078 | Iter Mean Loss 5.3078
2020-11-05 18:33:35,614 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4138 | Iter Mean Loss 3.3608
2020-11-05 18:33:35,621 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1933 | Iter Mean Loss 3.9716
2020-11-05 18:33:35,629 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 4.0907
2020-11-05 18:33:35,636 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5966 | Iter Mean Loss 3.7918
2020-11-05 18:33:35,638 - root - INFO - Evaluate: Epoch 0793 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:33:35,648 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3046 | Iter Mean Loss 5.3046
2020-11-05 18:33:35,655 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4122 | Iter Mean Loss 3.3584
2020-11-05 18:33:35,663 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1868 | Iter Mean Loss 3.9679
2020-11-05 18:33:35,670 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4422 | Iter Mean Loss 4.0864
2020-11-05 18:33:35,677 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5927 | Iter Mean Loss 3.7877
2020-11-05 18:33:35,679 - root - INFO - Evaluate: Epoch 0794 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:33:35,687 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.3015 | Iter Mean Loss 5.3015
2020-11-05 18:33:35,694 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4105 | Iter Mean Loss 3.3560
2020-11-05 18:33:35,701 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1804 | Iter Mean Loss 3.9641
2020-11-05 18:33:35,708 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4365 | Iter Mean Loss 4.0822
2020-11-05 18:33:35,715 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5887 | Iter Mean Loss 3.7835
2020-11-05 18:33:35,717 - root - INFO - Evaluate: Epoch 0795 | NDCG 0.2817 | MSE 0.3208
2020-11-05 18:33:35,725 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2983 | Iter Mean Loss 5.2983
2020-11-05 18:33:35,732 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4089 | Iter Mean Loss 3.3536
2020-11-05 18:33:35,740 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1740 | Iter Mean Loss 3.9604
2020-11-05 18:33:35,747 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4309 | Iter Mean Loss 4.0780
2020-11-05 18:33:35,754 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5848 | Iter Mean Loss 3.7794
2020-11-05 18:33:35,757 - root - INFO - Evaluate: Epoch 0796 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:33:35,765 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2952 | Iter Mean Loss 5.2952
2020-11-05 18:33:35,773 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4073 | Iter Mean Loss 3.3513
2020-11-05 18:33:35,780 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1677 | Iter Mean Loss 3.9567
2020-11-05 18:33:35,788 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4253 | Iter Mean Loss 4.0739
2020-11-05 18:33:35,796 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5809 | Iter Mean Loss 3.7753
2020-11-05 18:33:35,798 - root - INFO - Evaluate: Epoch 0797 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:33:35,806 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2921 | Iter Mean Loss 5.2921
2020-11-05 18:33:35,814 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4057 | Iter Mean Loss 3.3489
2020-11-05 18:33:35,822 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1613 | Iter Mean Loss 3.9530
2020-11-05 18:33:35,829 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4197 | Iter Mean Loss 4.0697
2020-11-05 18:33:35,837 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5771 | Iter Mean Loss 3.7712
2020-11-05 18:33:35,839 - root - INFO - Evaluate: Epoch 0798 | NDCG 0.2817 | MSE 0.3209
2020-11-05 18:33:35,847 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2890 | Iter Mean Loss 5.2890
2020-11-05 18:33:35,855 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4041 | Iter Mean Loss 3.3466
2020-11-05 18:33:35,862 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1549 | Iter Mean Loss 3.9494
2020-11-05 18:33:35,870 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4141 | Iter Mean Loss 4.0655
2020-11-05 18:33:35,877 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5732 | Iter Mean Loss 3.7671
2020-11-05 18:33:35,879 - root - INFO - Evaluate: Epoch 0799 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:33:35,887 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2859 | Iter Mean Loss 5.2859
2020-11-05 18:33:35,894 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4025 | Iter Mean Loss 3.3442
2020-11-05 18:33:35,901 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1486 | Iter Mean Loss 3.9457
2020-11-05 18:33:35,909 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4085 | Iter Mean Loss 4.0614
2020-11-05 18:33:35,916 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5694 | Iter Mean Loss 3.7630
2020-11-05 18:33:35,918 - root - INFO - Evaluate: Epoch 0800 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:33:35,926 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2828 | Iter Mean Loss 5.2828
2020-11-05 18:33:35,933 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4010 | Iter Mean Loss 3.3419
2020-11-05 18:33:35,940 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1423 | Iter Mean Loss 3.9420
2020-11-05 18:33:35,947 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.4029 | Iter Mean Loss 4.0572
2020-11-05 18:33:35,954 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5655 | Iter Mean Loss 3.7589
2020-11-05 18:33:35,957 - root - INFO - Evaluate: Epoch 0801 | NDCG 0.2817 | MSE 0.3210
2020-11-05 18:33:35,965 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2797 | Iter Mean Loss 5.2797
2020-11-05 18:33:35,972 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3994 | Iter Mean Loss 3.3395
2020-11-05 18:33:35,980 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1360 | Iter Mean Loss 3.9383
2020-11-05 18:33:35,988 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3974 | Iter Mean Loss 4.0531
2020-11-05 18:33:35,995 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5617 | Iter Mean Loss 3.7548
2020-11-05 18:33:35,998 - root - INFO - Evaluate: Epoch 0802 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:33:36,005 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2766 | Iter Mean Loss 5.2766
2020-11-05 18:33:36,014 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3978 | Iter Mean Loss 3.3372
2020-11-05 18:33:36,021 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1297 | Iter Mean Loss 3.9347
2020-11-05 18:33:36,029 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3918 | Iter Mean Loss 4.0490
2020-11-05 18:33:36,037 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5579 | Iter Mean Loss 3.7508
2020-11-05 18:33:36,039 - root - INFO - Evaluate: Epoch 0803 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:33:36,048 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2735 | Iter Mean Loss 5.2735
2020-11-05 18:33:36,055 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3963 | Iter Mean Loss 3.3349
2020-11-05 18:33:36,063 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1234 | Iter Mean Loss 3.9311
2020-11-05 18:33:36,071 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3863 | Iter Mean Loss 4.0449
2020-11-05 18:33:36,078 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5541 | Iter Mean Loss 3.7467
2020-11-05 18:33:36,080 - root - INFO - Evaluate: Epoch 0804 | NDCG 0.2817 | MSE 0.3211
2020-11-05 18:33:36,087 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2704 | Iter Mean Loss 5.2704
2020-11-05 18:33:36,095 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3947 | Iter Mean Loss 3.3326
2020-11-05 18:33:36,102 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1172 | Iter Mean Loss 3.9274
2020-11-05 18:33:36,109 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3808 | Iter Mean Loss 4.0408
2020-11-05 18:33:36,116 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5503 | Iter Mean Loss 3.7427
2020-11-05 18:33:36,118 - root - INFO - Evaluate: Epoch 0805 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:33:36,126 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2673 | Iter Mean Loss 5.2673
2020-11-05 18:33:36,133 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3932 | Iter Mean Loss 3.3303
2020-11-05 18:33:36,140 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1109 | Iter Mean Loss 3.9238
2020-11-05 18:33:36,148 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3753 | Iter Mean Loss 4.0367
2020-11-05 18:33:36,156 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5465 | Iter Mean Loss 3.7387
2020-11-05 18:33:36,159 - root - INFO - Evaluate: Epoch 0806 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:33:36,167 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2642 | Iter Mean Loss 5.2642
2020-11-05 18:33:36,175 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3917 | Iter Mean Loss 3.3279
2020-11-05 18:33:36,184 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.1047 | Iter Mean Loss 3.9202
2020-11-05 18:33:36,191 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3698 | Iter Mean Loss 4.0326
2020-11-05 18:33:36,199 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5428 | Iter Mean Loss 3.7346
2020-11-05 18:33:36,201 - root - INFO - Evaluate: Epoch 0807 | NDCG 0.2817 | MSE 0.3212
2020-11-05 18:33:36,210 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2612 | Iter Mean Loss 5.2612
2020-11-05 18:33:36,218 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3901 | Iter Mean Loss 3.3256
2020-11-05 18:33:36,226 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0985 | Iter Mean Loss 3.9166
2020-11-05 18:33:36,234 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3644 | Iter Mean Loss 4.0285
2020-11-05 18:33:36,242 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5390 | Iter Mean Loss 3.7306
2020-11-05 18:33:36,244 - root - INFO - Evaluate: Epoch 0808 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:33:36,253 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2581 | Iter Mean Loss 5.2581
2020-11-05 18:33:36,260 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3886 | Iter Mean Loss 3.3234
2020-11-05 18:33:36,268 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0922 | Iter Mean Loss 3.9130
2020-11-05 18:33:36,276 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 4.0245
2020-11-05 18:33:36,283 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5353 | Iter Mean Loss 3.7266
2020-11-05 18:33:36,285 - root - INFO - Evaluate: Epoch 0809 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:33:36,292 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2550 | Iter Mean Loss 5.2550
2020-11-05 18:33:36,300 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3871 | Iter Mean Loss 3.3211
2020-11-05 18:33:36,307 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0861 | Iter Mean Loss 3.9094
2020-11-05 18:33:36,314 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3535 | Iter Mean Loss 4.0204
2020-11-05 18:33:36,322 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5316 | Iter Mean Loss 3.7227
2020-11-05 18:33:36,325 - root - INFO - Evaluate: Epoch 0810 | NDCG 0.2817 | MSE 0.3213
2020-11-05 18:33:36,332 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2520 | Iter Mean Loss 5.2520
2020-11-05 18:33:36,340 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3856 | Iter Mean Loss 3.3188
2020-11-05 18:33:36,347 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0799 | Iter Mean Loss 3.9058
2020-11-05 18:33:36,355 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3481 | Iter Mean Loss 4.0164
2020-11-05 18:33:36,363 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5279 | Iter Mean Loss 3.7187
2020-11-05 18:33:36,366 - root - INFO - Evaluate: Epoch 0811 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:33:36,374 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2489 | Iter Mean Loss 5.2489
2020-11-05 18:33:36,382 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3841 | Iter Mean Loss 3.3165
2020-11-05 18:33:36,390 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0737 | Iter Mean Loss 3.9022
2020-11-05 18:33:36,398 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3427 | Iter Mean Loss 4.0123
2020-11-05 18:33:36,405 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5242 | Iter Mean Loss 3.7147
2020-11-05 18:33:36,408 - root - INFO - Evaluate: Epoch 0812 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:33:36,416 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2458 | Iter Mean Loss 5.2458
2020-11-05 18:33:36,424 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3826 | Iter Mean Loss 3.3142
2020-11-05 18:33:36,432 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0676 | Iter Mean Loss 3.8987
2020-11-05 18:33:36,440 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3373 | Iter Mean Loss 4.0083
2020-11-05 18:33:36,447 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5205 | Iter Mean Loss 3.7108
2020-11-05 18:33:36,449 - root - INFO - Evaluate: Epoch 0813 | NDCG 0.2817 | MSE 0.3214
2020-11-05 18:33:36,458 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2428 | Iter Mean Loss 5.2428
2020-11-05 18:33:36,466 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3811 | Iter Mean Loss 3.3120
2020-11-05 18:33:36,474 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0614 | Iter Mean Loss 3.8951
2020-11-05 18:33:36,481 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3319 | Iter Mean Loss 4.0043
2020-11-05 18:33:36,488 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5168 | Iter Mean Loss 3.7068
2020-11-05 18:33:36,490 - root - INFO - Evaluate: Epoch 0814 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:33:36,498 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2398 | Iter Mean Loss 5.2398
2020-11-05 18:33:36,505 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3796 | Iter Mean Loss 3.3097
2020-11-05 18:33:36,512 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0553 | Iter Mean Loss 3.8916
2020-11-05 18:33:36,519 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3265 | Iter Mean Loss 4.0003
2020-11-05 18:33:36,526 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5132 | Iter Mean Loss 3.7029
2020-11-05 18:33:36,528 - root - INFO - Evaluate: Epoch 0815 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:33:36,536 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2367 | Iter Mean Loss 5.2367
2020-11-05 18:33:36,543 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 3.3074
2020-11-05 18:33:36,550 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0492 | Iter Mean Loss 3.8880
2020-11-05 18:33:36,558 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3212 | Iter Mean Loss 3.9963
2020-11-05 18:33:36,566 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5095 | Iter Mean Loss 3.6989
2020-11-05 18:33:36,568 - root - INFO - Evaluate: Epoch 0816 | NDCG 0.2817 | MSE 0.3215
2020-11-05 18:33:36,577 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2337 | Iter Mean Loss 5.2337
2020-11-05 18:33:36,584 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3767 | Iter Mean Loss 3.3052
2020-11-05 18:33:36,592 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0431 | Iter Mean Loss 3.8845
2020-11-05 18:33:36,600 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3158 | Iter Mean Loss 3.9923
2020-11-05 18:33:36,609 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5059 | Iter Mean Loss 3.6950
2020-11-05 18:33:36,611 - root - INFO - Evaluate: Epoch 0817 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:33:36,619 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2306 | Iter Mean Loss 5.2306
2020-11-05 18:33:36,628 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3752 | Iter Mean Loss 3.3029
2020-11-05 18:33:36,635 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0370 | Iter Mean Loss 3.8809
2020-11-05 18:33:36,643 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3105 | Iter Mean Loss 3.9883
2020-11-05 18:33:36,651 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.5023 | Iter Mean Loss 3.6911
2020-11-05 18:33:36,653 - root - INFO - Evaluate: Epoch 0818 | NDCG 0.2817 | MSE 0.3216
2020-11-05 18:33:36,662 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2276 | Iter Mean Loss 5.2276
2020-11-05 18:33:36,670 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3737 | Iter Mean Loss 3.3007
2020-11-05 18:33:36,678 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0309 | Iter Mean Loss 3.8774
2020-11-05 18:33:36,685 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.3052 | Iter Mean Loss 3.9844
2020-11-05 18:33:36,692 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4987 | Iter Mean Loss 3.6872
2020-11-05 18:33:36,694 - root - INFO - Evaluate: Epoch 0819 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:33:36,702 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2246 | Iter Mean Loss 5.2246
2020-11-05 18:33:36,709 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3723 | Iter Mean Loss 3.2984
2020-11-05 18:33:36,716 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0248 | Iter Mean Loss 3.8739
2020-11-05 18:33:36,723 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.9804
2020-11-05 18:33:36,730 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4951 | Iter Mean Loss 3.6833
2020-11-05 18:33:36,733 - root - INFO - Evaluate: Epoch 0820 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:33:36,740 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2216 | Iter Mean Loss 5.2216
2020-11-05 18:33:36,747 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3708 | Iter Mean Loss 3.2962
2020-11-05 18:33:36,755 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0188 | Iter Mean Loss 3.8704
2020-11-05 18:33:36,763 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 3.9764
2020-11-05 18:33:36,771 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4915 | Iter Mean Loss 3.6794
2020-11-05 18:33:36,773 - root - INFO - Evaluate: Epoch 0821 | NDCG 0.2817 | MSE 0.3217
2020-11-05 18:33:36,781 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2185 | Iter Mean Loss 5.2185
2020-11-05 18:33:36,790 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3694 | Iter Mean Loss 3.2940
2020-11-05 18:33:36,798 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0128 | Iter Mean Loss 3.8669
2020-11-05 18:33:36,806 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2893 | Iter Mean Loss 3.9725
2020-11-05 18:33:36,814 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4879 | Iter Mean Loss 3.6756
2020-11-05 18:33:36,816 - root - INFO - Evaluate: Epoch 0822 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:33:36,824 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2155 | Iter Mean Loss 5.2155
2020-11-05 18:33:36,832 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3679 | Iter Mean Loss 3.2917
2020-11-05 18:33:36,840 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0067 | Iter Mean Loss 3.8634
2020-11-05 18:33:36,848 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2840 | Iter Mean Loss 3.9686
2020-11-05 18:33:36,855 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4843 | Iter Mean Loss 3.6717
2020-11-05 18:33:36,858 - root - INFO - Evaluate: Epoch 0823 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:33:36,866 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2125 | Iter Mean Loss 5.2125
2020-11-05 18:33:36,874 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3665 | Iter Mean Loss 3.2895
2020-11-05 18:33:36,882 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 5.0007 | Iter Mean Loss 3.8599
2020-11-05 18:33:36,889 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2788 | Iter Mean Loss 3.9646
2020-11-05 18:33:36,897 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4808 | Iter Mean Loss 3.6679
2020-11-05 18:33:36,899 - root - INFO - Evaluate: Epoch 0824 | NDCG 0.2817 | MSE 0.3218
2020-11-05 18:33:36,906 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2095 | Iter Mean Loss 5.2095
2020-11-05 18:33:36,914 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3651 | Iter Mean Loss 3.2873
2020-11-05 18:33:36,921 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9947 | Iter Mean Loss 3.8564
2020-11-05 18:33:36,928 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2735 | Iter Mean Loss 3.9607
2020-11-05 18:33:36,935 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4772 | Iter Mean Loss 3.6640
2020-11-05 18:33:36,937 - root - INFO - Evaluate: Epoch 0825 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:33:36,945 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2065 | Iter Mean Loss 5.2065
2020-11-05 18:33:36,952 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3636 | Iter Mean Loss 3.2851
2020-11-05 18:33:36,959 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9887 | Iter Mean Loss 3.8529
2020-11-05 18:33:36,968 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2683 | Iter Mean Loss 3.9568
2020-11-05 18:33:36,975 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4737 | Iter Mean Loss 3.6602
2020-11-05 18:33:36,978 - root - INFO - Evaluate: Epoch 0826 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:33:36,986 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2035 | Iter Mean Loss 5.2035
2020-11-05 18:33:36,994 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3622 | Iter Mean Loss 3.2828
2020-11-05 18:33:37,002 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9827 | Iter Mean Loss 3.8495
2020-11-05 18:33:37,009 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 3.9529
2020-11-05 18:33:37,018 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4701 | Iter Mean Loss 3.6563
2020-11-05 18:33:37,020 - root - INFO - Evaluate: Epoch 0827 | NDCG 0.2817 | MSE 0.3219
2020-11-05 18:33:37,029 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.2005 | Iter Mean Loss 5.2005
2020-11-05 18:33:37,037 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3608 | Iter Mean Loss 3.2806
2020-11-05 18:33:37,045 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9768 | Iter Mean Loss 3.8460
2020-11-05 18:33:37,052 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2579 | Iter Mean Loss 3.9490
2020-11-05 18:33:37,060 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4666 | Iter Mean Loss 3.6525
2020-11-05 18:33:37,062 - root - INFO - Evaluate: Epoch 0828 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:33:37,071 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1975 | Iter Mean Loss 5.1975
2020-11-05 18:33:37,079 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 3.2784
2020-11-05 18:33:37,087 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9708 | Iter Mean Loss 3.8426
2020-11-05 18:33:37,094 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2527 | Iter Mean Loss 3.9451
2020-11-05 18:33:37,101 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4631 | Iter Mean Loss 3.6487
2020-11-05 18:33:37,103 - root - INFO - Evaluate: Epoch 0829 | NDCG 0.2817 | MSE 0.3220
2020-11-05 18:33:37,111 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1945 | Iter Mean Loss 5.1945
2020-11-05 18:33:37,118 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3580 | Iter Mean Loss 3.2762
2020-11-05 18:33:37,125 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9649 | Iter Mean Loss 3.8391
2020-11-05 18:33:37,132 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2475 | Iter Mean Loss 3.9412
2020-11-05 18:33:37,139 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4596 | Iter Mean Loss 3.6449
2020-11-05 18:33:37,141 - root - INFO - Evaluate: Epoch 0830 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:33:37,149 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1915 | Iter Mean Loss 5.1915
2020-11-05 18:33:37,156 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3566 | Iter Mean Loss 3.2740
2020-11-05 18:33:37,163 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 3.8357
2020-11-05 18:33:37,172 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2423 | Iter Mean Loss 3.9373
2020-11-05 18:33:37,179 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4561 | Iter Mean Loss 3.6411
2020-11-05 18:33:37,182 - root - INFO - Evaluate: Epoch 0831 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:33:37,189 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1885 | Iter Mean Loss 5.1885
2020-11-05 18:33:37,197 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3552 | Iter Mean Loss 3.2718
2020-11-05 18:33:37,205 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9530 | Iter Mean Loss 3.8322
2020-11-05 18:33:37,213 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2372 | Iter Mean Loss 3.9335
2020-11-05 18:33:37,221 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4527 | Iter Mean Loss 3.6373
2020-11-05 18:33:37,223 - root - INFO - Evaluate: Epoch 0832 | NDCG 0.2817 | MSE 0.3221
2020-11-05 18:33:37,232 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1855 | Iter Mean Loss 5.1855
2020-11-05 18:33:37,240 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3538 | Iter Mean Loss 3.2696
2020-11-05 18:33:37,248 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9471 | Iter Mean Loss 3.8288
2020-11-05 18:33:37,256 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2320 | Iter Mean Loss 3.9296
2020-11-05 18:33:37,264 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4492 | Iter Mean Loss 3.6335
2020-11-05 18:33:37,266 - root - INFO - Evaluate: Epoch 0833 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:33:37,275 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1825 | Iter Mean Loss 5.1825
2020-11-05 18:33:37,283 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3524 | Iter Mean Loss 3.2674
2020-11-05 18:33:37,290 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9412 | Iter Mean Loss 3.8254
2020-11-05 18:33:37,298 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2269 | Iter Mean Loss 3.9257
2020-11-05 18:33:37,305 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4457 | Iter Mean Loss 3.6297
2020-11-05 18:33:37,307 - root - INFO - Evaluate: Epoch 0834 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:33:37,315 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1795 | Iter Mean Loss 5.1795
2020-11-05 18:33:37,323 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3510 | Iter Mean Loss 3.2652
2020-11-05 18:33:37,330 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9353 | Iter Mean Loss 3.8219
2020-11-05 18:33:37,338 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 3.9219
2020-11-05 18:33:37,345 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4423 | Iter Mean Loss 3.6260
2020-11-05 18:33:37,347 - root - INFO - Evaluate: Epoch 0835 | NDCG 0.2817 | MSE 0.3222
2020-11-05 18:33:37,354 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1765 | Iter Mean Loss 5.1765
2020-11-05 18:33:37,362 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3496 | Iter Mean Loss 3.2631
2020-11-05 18:33:37,369 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9295 | Iter Mean Loss 3.8185
2020-11-05 18:33:37,377 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2166 | Iter Mean Loss 3.9181
2020-11-05 18:33:37,385 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4389 | Iter Mean Loss 3.6222
2020-11-05 18:33:37,387 - root - INFO - Evaluate: Epoch 0836 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:33:37,395 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1735 | Iter Mean Loss 5.1735
2020-11-05 18:33:37,403 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3482 | Iter Mean Loss 3.2609
2020-11-05 18:33:37,411 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 3.8151
2020-11-05 18:33:37,419 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2115 | Iter Mean Loss 3.9142
2020-11-05 18:33:37,428 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4354 | Iter Mean Loss 3.6185
2020-11-05 18:33:37,430 - root - INFO - Evaluate: Epoch 0837 | NDCG 0.2817 | MSE 0.3223
2020-11-05 18:33:37,438 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1706 | Iter Mean Loss 5.1706
2020-11-05 18:33:37,447 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3468 | Iter Mean Loss 3.2587
2020-11-05 18:33:37,455 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9178 | Iter Mean Loss 3.8117
2020-11-05 18:33:37,463 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2065 | Iter Mean Loss 3.9104
2020-11-05 18:33:37,470 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4320 | Iter Mean Loss 3.6147
2020-11-05 18:33:37,472 - root - INFO - Evaluate: Epoch 0838 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:33:37,482 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1676 | Iter Mean Loss 5.1676
2020-11-05 18:33:37,489 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3454 | Iter Mean Loss 3.2565
2020-11-05 18:33:37,497 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9119 | Iter Mean Loss 3.8083
2020-11-05 18:33:37,504 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.2014 | Iter Mean Loss 3.9066
2020-11-05 18:33:37,511 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4286 | Iter Mean Loss 3.6110
2020-11-05 18:33:37,513 - root - INFO - Evaluate: Epoch 0839 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:33:37,521 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1646 | Iter Mean Loss 5.1646
2020-11-05 18:33:37,528 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3441 | Iter Mean Loss 3.2543
2020-11-05 18:33:37,535 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9061 | Iter Mean Loss 3.8049
2020-11-05 18:33:37,542 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1963 | Iter Mean Loss 3.9028
2020-11-05 18:33:37,549 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4252 | Iter Mean Loss 3.6073
2020-11-05 18:33:37,551 - root - INFO - Evaluate: Epoch 0840 | NDCG 0.2817 | MSE 0.3224
2020-11-05 18:33:37,559 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1616 | Iter Mean Loss 5.1616
2020-11-05 18:33:37,566 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 3.2522
2020-11-05 18:33:37,573 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.9003 | Iter Mean Loss 3.8015
2020-11-05 18:33:37,582 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1913 | Iter Mean Loss 3.8990
2020-11-05 18:33:37,589 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4218 | Iter Mean Loss 3.6035
2020-11-05 18:33:37,592 - root - INFO - Evaluate: Epoch 0841 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:33:37,600 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1586 | Iter Mean Loss 5.1586
2020-11-05 18:33:37,609 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 3.2500
2020-11-05 18:33:37,617 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8945 | Iter Mean Loss 3.7981
2020-11-05 18:33:37,624 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1862 | Iter Mean Loss 3.8952
2020-11-05 18:33:37,632 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4184 | Iter Mean Loss 3.5998
2020-11-05 18:33:37,634 - root - INFO - Evaluate: Epoch 0842 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:33:37,643 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1557 | Iter Mean Loss 5.1557
2020-11-05 18:33:37,651 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3400 | Iter Mean Loss 3.2478
2020-11-05 18:33:37,659 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8887 | Iter Mean Loss 3.7948
2020-11-05 18:33:37,667 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1812 | Iter Mean Loss 3.8914
2020-11-05 18:33:37,674 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4151 | Iter Mean Loss 3.5961
2020-11-05 18:33:37,677 - root - INFO - Evaluate: Epoch 0843 | NDCG 0.2817 | MSE 0.3225
2020-11-05 18:33:37,685 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1527 | Iter Mean Loss 5.1527
2020-11-05 18:33:37,693 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3386 | Iter Mean Loss 3.2456
2020-11-05 18:33:37,700 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8829 | Iter Mean Loss 3.7914
2020-11-05 18:33:37,707 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1761 | Iter Mean Loss 3.8876
2020-11-05 18:33:37,715 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4117 | Iter Mean Loss 3.5924
2020-11-05 18:33:37,717 - root - INFO - Evaluate: Epoch 0844 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:33:37,725 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1497 | Iter Mean Loss 5.1497
2020-11-05 18:33:37,732 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3372 | Iter Mean Loss 3.2435
2020-11-05 18:33:37,739 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8771 | Iter Mean Loss 3.7880
2020-11-05 18:33:37,746 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1711 | Iter Mean Loss 3.8838
2020-11-05 18:33:37,753 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4084 | Iter Mean Loss 3.5887
2020-11-05 18:33:37,755 - root - INFO - Evaluate: Epoch 0845 | NDCG 0.2817 | MSE 0.3226
2020-11-05 18:33:37,763 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1467 | Iter Mean Loss 5.1467
2020-11-05 18:33:37,770 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3359 | Iter Mean Loss 3.2413
2020-11-05 18:33:37,777 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8713 | Iter Mean Loss 3.7846
2020-11-05 18:33:37,786 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1661 | Iter Mean Loss 3.8800
2020-11-05 18:33:37,793 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4050 | Iter Mean Loss 3.5850
2020-11-05 18:33:37,796 - root - INFO - Evaluate: Epoch 0846 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:33:37,804 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1438 | Iter Mean Loss 5.1438
2020-11-05 18:33:37,811 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3345 | Iter Mean Loss 3.2391
2020-11-05 18:33:37,820 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8656 | Iter Mean Loss 3.7813
2020-11-05 18:33:37,827 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1611 | Iter Mean Loss 3.8762
2020-11-05 18:33:37,835 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.4017 | Iter Mean Loss 3.5813
2020-11-05 18:33:37,838 - root - INFO - Evaluate: Epoch 0847 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:33:37,846 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1408 | Iter Mean Loss 5.1408
2020-11-05 18:33:37,854 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3332 | Iter Mean Loss 3.2370
2020-11-05 18:33:37,862 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8598 | Iter Mean Loss 3.7779
2020-11-05 18:33:37,870 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1561 | Iter Mean Loss 3.8725
2020-11-05 18:33:37,878 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3983 | Iter Mean Loss 3.5777
2020-11-05 18:33:37,880 - root - INFO - Evaluate: Epoch 0848 | NDCG 0.2817 | MSE 0.3227
2020-11-05 18:33:37,891 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1378 | Iter Mean Loss 5.1378
2020-11-05 18:33:37,900 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3318 | Iter Mean Loss 3.2348
2020-11-05 18:33:37,908 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8541 | Iter Mean Loss 3.7746
2020-11-05 18:33:37,916 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1512 | Iter Mean Loss 3.8687
2020-11-05 18:33:37,923 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3950 | Iter Mean Loss 3.5740
2020-11-05 18:33:37,925 - root - INFO - Evaluate: Epoch 0849 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:33:37,933 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1348 | Iter Mean Loss 5.1348
2020-11-05 18:33:37,940 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3305 | Iter Mean Loss 3.2327
2020-11-05 18:33:37,947 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8484 | Iter Mean Loss 3.7712
2020-11-05 18:33:37,954 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1462 | Iter Mean Loss 3.8650
2020-11-05 18:33:37,961 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3917 | Iter Mean Loss 3.5703
2020-11-05 18:33:37,963 - root - INFO - Evaluate: Epoch 0850 | NDCG 0.2817 | MSE 0.3228
2020-11-05 18:33:37,971 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1319 | Iter Mean Loss 5.1319
2020-11-05 18:33:37,978 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3292 | Iter Mean Loss 3.2305
2020-11-05 18:33:37,986 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8426 | Iter Mean Loss 3.7679
2020-11-05 18:33:37,993 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1413 | Iter Mean Loss 3.8612
2020-11-05 18:33:38,002 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3884 | Iter Mean Loss 3.5667
2020-11-05 18:33:38,004 - root - INFO - Evaluate: Epoch 0851 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:33:38,012 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1289 | Iter Mean Loss 5.1289
2020-11-05 18:33:38,020 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3278 | Iter Mean Loss 3.2284
2020-11-05 18:33:38,029 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8369 | Iter Mean Loss 3.7645
2020-11-05 18:33:38,037 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1363 | Iter Mean Loss 3.8575
2020-11-05 18:33:38,045 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3851 | Iter Mean Loss 3.5630
2020-11-05 18:33:38,047 - root - INFO - Evaluate: Epoch 0852 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:33:38,057 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1259 | Iter Mean Loss 5.1259
2020-11-05 18:33:38,070 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 3.2262
2020-11-05 18:33:38,083 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 3.7612
2020-11-05 18:33:38,093 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1314 | Iter Mean Loss 3.8538
2020-11-05 18:33:38,101 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3818 | Iter Mean Loss 3.5594
2020-11-05 18:33:38,103 - root - INFO - Evaluate: Epoch 0853 | NDCG 0.2817 | MSE 0.3229
2020-11-05 18:33:38,114 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1230 | Iter Mean Loss 5.1230
2020-11-05 18:33:38,124 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 3.2240
2020-11-05 18:33:38,134 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8255 | Iter Mean Loss 3.7579
2020-11-05 18:33:38,144 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1265 | Iter Mean Loss 3.8500
2020-11-05 18:33:38,153 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3786 | Iter Mean Loss 3.5557
2020-11-05 18:33:38,155 - root - INFO - Evaluate: Epoch 0854 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:33:38,165 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1200 | Iter Mean Loss 5.1200
2020-11-05 18:33:38,174 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3238 | Iter Mean Loss 3.2219
2020-11-05 18:33:38,184 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8199 | Iter Mean Loss 3.7546
2020-11-05 18:33:38,194 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1216 | Iter Mean Loss 3.8463
2020-11-05 18:33:38,203 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3753 | Iter Mean Loss 3.5521
2020-11-05 18:33:38,206 - root - INFO - Evaluate: Epoch 0855 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:33:38,216 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1170 | Iter Mean Loss 5.1170
2020-11-05 18:33:38,225 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3225 | Iter Mean Loss 3.2197
2020-11-05 18:33:38,233 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8142 | Iter Mean Loss 3.7512
2020-11-05 18:33:38,242 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1166 | Iter Mean Loss 3.8426
2020-11-05 18:33:38,250 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3720 | Iter Mean Loss 3.5485
2020-11-05 18:33:38,253 - root - INFO - Evaluate: Epoch 0856 | NDCG 0.2817 | MSE 0.3230
2020-11-05 18:33:38,261 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1140 | Iter Mean Loss 5.1140
2020-11-05 18:33:38,269 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3211 | Iter Mean Loss 3.2176
2020-11-05 18:33:38,277 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8085 | Iter Mean Loss 3.7479
2020-11-05 18:33:38,284 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1118 | Iter Mean Loss 3.8389
2020-11-05 18:33:38,291 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3688 | Iter Mean Loss 3.5448
2020-11-05 18:33:38,294 - root - INFO - Evaluate: Epoch 0857 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:33:38,303 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1111 | Iter Mean Loss 5.1111
2020-11-05 18:33:38,310 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3198 | Iter Mean Loss 3.2154
2020-11-05 18:33:38,319 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.8029 | Iter Mean Loss 3.7446
2020-11-05 18:33:38,327 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1069 | Iter Mean Loss 3.8352
2020-11-05 18:33:38,335 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3655 | Iter Mean Loss 3.5412
2020-11-05 18:33:38,337 - root - INFO - Evaluate: Epoch 0858 | NDCG 0.2817 | MSE 0.3231
2020-11-05 18:33:38,345 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1081 | Iter Mean Loss 5.1081
2020-11-05 18:33:38,352 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3185 | Iter Mean Loss 3.2133
2020-11-05 18:33:38,359 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7973 | Iter Mean Loss 3.7413
2020-11-05 18:33:38,366 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.1020 | Iter Mean Loss 3.8315
2020-11-05 18:33:38,373 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3623 | Iter Mean Loss 3.5376
2020-11-05 18:33:38,375 - root - INFO - Evaluate: Epoch 0859 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:33:38,383 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1051 | Iter Mean Loss 5.1051
2020-11-05 18:33:38,391 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3172 | Iter Mean Loss 3.2111
2020-11-05 18:33:38,398 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7916 | Iter Mean Loss 3.7380
2020-11-05 18:33:38,406 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0971 | Iter Mean Loss 3.8278
2020-11-05 18:33:38,414 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3591 | Iter Mean Loss 3.5340
2020-11-05 18:33:38,416 - root - INFO - Evaluate: Epoch 0860 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:33:38,424 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.1021 | Iter Mean Loss 5.1021
2020-11-05 18:33:38,431 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3158 | Iter Mean Loss 3.2090
2020-11-05 18:33:38,440 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7860 | Iter Mean Loss 3.7347
2020-11-05 18:33:38,447 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0923 | Iter Mean Loss 3.8241
2020-11-05 18:33:38,455 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3558 | Iter Mean Loss 3.5304
2020-11-05 18:33:38,457 - root - INFO - Evaluate: Epoch 0861 | NDCG 0.2817 | MSE 0.3232
2020-11-05 18:33:38,466 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0992 | Iter Mean Loss 5.0992
2020-11-05 18:33:38,474 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3145 | Iter Mean Loss 3.2068
2020-11-05 18:33:38,481 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7804 | Iter Mean Loss 3.7314
2020-11-05 18:33:38,489 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0874 | Iter Mean Loss 3.8204
2020-11-05 18:33:38,497 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3526 | Iter Mean Loss 3.5268
2020-11-05 18:33:38,499 - root - INFO - Evaluate: Epoch 0862 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:33:38,508 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0962 | Iter Mean Loss 5.0962
2020-11-05 18:33:38,516 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3132 | Iter Mean Loss 3.2047
2020-11-05 18:33:38,524 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7748 | Iter Mean Loss 3.7281
2020-11-05 18:33:38,531 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0826 | Iter Mean Loss 3.8167
2020-11-05 18:33:38,538 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3494 | Iter Mean Loss 3.5232
2020-11-05 18:33:38,540 - root - INFO - Evaluate: Epoch 0863 | NDCG 0.2817 | MSE 0.3233
2020-11-05 18:33:38,548 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0932 | Iter Mean Loss 5.0932
2020-11-05 18:33:38,555 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 3.2025
2020-11-05 18:33:38,562 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7692 | Iter Mean Loss 3.7248
2020-11-05 18:33:38,570 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0778 | Iter Mean Loss 3.8130
2020-11-05 18:33:38,577 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3462 | Iter Mean Loss 3.5197
2020-11-05 18:33:38,579 - root - INFO - Evaluate: Epoch 0864 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:33:38,586 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0902 | Iter Mean Loss 5.0902
2020-11-05 18:33:38,594 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3106 | Iter Mean Loss 3.2004
2020-11-05 18:33:38,601 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7636 | Iter Mean Loss 3.7215
2020-11-05 18:33:38,608 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0730 | Iter Mean Loss 3.8093
2020-11-05 18:33:38,616 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3430 | Iter Mean Loss 3.5161
2020-11-05 18:33:38,618 - root - INFO - Evaluate: Epoch 0865 | NDCG 0.2817 | MSE 0.3234
2020-11-05 18:33:38,626 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0872 | Iter Mean Loss 5.0872
2020-11-05 18:33:38,634 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3093 | Iter Mean Loss 3.1982
2020-11-05 18:33:38,642 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7580 | Iter Mean Loss 3.7182
2020-11-05 18:33:38,649 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0682 | Iter Mean Loss 3.8057
2020-11-05 18:33:38,658 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3398 | Iter Mean Loss 3.5125
2020-11-05 18:33:38,660 - root - INFO - Evaluate: Epoch 0866 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:33:38,668 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0843 | Iter Mean Loss 5.0843
2020-11-05 18:33:38,676 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3079 | Iter Mean Loss 3.1961
2020-11-05 18:33:38,684 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7525 | Iter Mean Loss 3.7149
2020-11-05 18:33:38,692 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0634 | Iter Mean Loss 3.8020
2020-11-05 18:33:38,699 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3366 | Iter Mean Loss 3.5089
2020-11-05 18:33:38,701 - root - INFO - Evaluate: Epoch 0867 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:33:38,711 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0813 | Iter Mean Loss 5.0813
2020-11-05 18:33:38,718 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3066 | Iter Mean Loss 3.1939
2020-11-05 18:33:38,726 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7469 | Iter Mean Loss 3.7116
2020-11-05 18:33:38,734 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0586 | Iter Mean Loss 3.7983
2020-11-05 18:33:38,741 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 3.5054
2020-11-05 18:33:38,743 - root - INFO - Evaluate: Epoch 0868 | NDCG 0.2817 | MSE 0.3235
2020-11-05 18:33:38,751 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0783 | Iter Mean Loss 5.0783
2020-11-05 18:33:38,758 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3053 | Iter Mean Loss 3.1918
2020-11-05 18:33:38,765 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7414 | Iter Mean Loss 3.7083
2020-11-05 18:33:38,772 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0538 | Iter Mean Loss 3.7947
2020-11-05 18:33:38,780 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3303 | Iter Mean Loss 3.5018
2020-11-05 18:33:38,782 - root - INFO - Evaluate: Epoch 0869 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:33:38,789 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0753 | Iter Mean Loss 5.0753
2020-11-05 18:33:38,796 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3040 | Iter Mean Loss 3.1896
2020-11-05 18:33:38,804 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7358 | Iter Mean Loss 3.7050
2020-11-05 18:33:38,811 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0490 | Iter Mean Loss 3.7910
2020-11-05 18:33:38,818 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3271 | Iter Mean Loss 3.4983
2020-11-05 18:33:38,821 - root - INFO - Evaluate: Epoch 0870 | NDCG 0.2817 | MSE 0.3236
2020-11-05 18:33:38,829 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0723 | Iter Mean Loss 5.0723
2020-11-05 18:33:38,836 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3027 | Iter Mean Loss 3.1875
2020-11-05 18:33:38,844 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7303 | Iter Mean Loss 3.7018
2020-11-05 18:33:38,852 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0443 | Iter Mean Loss 3.7874
2020-11-05 18:33:38,860 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3240 | Iter Mean Loss 3.4947
2020-11-05 18:33:38,862 - root - INFO - Evaluate: Epoch 0871 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:33:38,870 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0693 | Iter Mean Loss 5.0693
2020-11-05 18:33:38,879 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3014 | Iter Mean Loss 3.1853
2020-11-05 18:33:38,886 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7248 | Iter Mean Loss 3.6985
2020-11-05 18:33:38,895 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0395 | Iter Mean Loss 3.7837
2020-11-05 18:33:38,902 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3208 | Iter Mean Loss 3.4912
2020-11-05 18:33:38,904 - root - INFO - Evaluate: Epoch 0872 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:33:38,913 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0663 | Iter Mean Loss 5.0663
2020-11-05 18:33:38,921 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3001 | Iter Mean Loss 3.1832
2020-11-05 18:33:38,929 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7193 | Iter Mean Loss 3.6952
2020-11-05 18:33:38,936 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 3.7801
2020-11-05 18:33:38,943 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3177 | Iter Mean Loss 3.4876
2020-11-05 18:33:38,946 - root - INFO - Evaluate: Epoch 0873 | NDCG 0.2817 | MSE 0.3237
2020-11-05 18:33:38,953 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0633 | Iter Mean Loss 5.0633
2020-11-05 18:33:38,960 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 3.1810
2020-11-05 18:33:38,968 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7138 | Iter Mean Loss 3.6919
2020-11-05 18:33:38,975 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0300 | Iter Mean Loss 3.7765
2020-11-05 18:33:38,982 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3146 | Iter Mean Loss 3.4841
2020-11-05 18:33:38,984 - root - INFO - Evaluate: Epoch 0874 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:33:38,991 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0603 | Iter Mean Loss 5.0603
2020-11-05 18:33:38,999 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2975 | Iter Mean Loss 3.1789
2020-11-05 18:33:39,006 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7083 | Iter Mean Loss 3.6887
2020-11-05 18:33:39,013 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0253 | Iter Mean Loss 3.7728
2020-11-05 18:33:39,021 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3114 | Iter Mean Loss 3.4806
2020-11-05 18:33:39,024 - root - INFO - Evaluate: Epoch 0875 | NDCG 0.2817 | MSE 0.3238
2020-11-05 18:33:39,032 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0573 | Iter Mean Loss 5.0573
2020-11-05 18:33:39,041 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2961 | Iter Mean Loss 3.1767
2020-11-05 18:33:39,048 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.7028 | Iter Mean Loss 3.6854
2020-11-05 18:33:39,056 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0206 | Iter Mean Loss 3.7692
2020-11-05 18:33:39,064 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3083 | Iter Mean Loss 3.4770
2020-11-05 18:33:39,066 - root - INFO - Evaluate: Epoch 0876 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:33:39,075 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0543 | Iter Mean Loss 5.0543
2020-11-05 18:33:39,082 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2948 | Iter Mean Loss 3.1746
2020-11-05 18:33:39,091 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6973 | Iter Mean Loss 3.6821
2020-11-05 18:33:39,098 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0159 | Iter Mean Loss 3.7656
2020-11-05 18:33:39,105 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3052 | Iter Mean Loss 3.4735
2020-11-05 18:33:39,107 - root - INFO - Evaluate: Epoch 0877 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:33:39,116 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0513 | Iter Mean Loss 5.0513
2020-11-05 18:33:39,124 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2935 | Iter Mean Loss 3.1724
2020-11-05 18:33:39,132 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6918 | Iter Mean Loss 3.6789
2020-11-05 18:33:39,139 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0112 | Iter Mean Loss 3.7620
2020-11-05 18:33:39,146 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.3021 | Iter Mean Loss 3.4700
2020-11-05 18:33:39,148 - root - INFO - Evaluate: Epoch 0878 | NDCG 0.2817 | MSE 0.3239
2020-11-05 18:33:39,156 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0483 | Iter Mean Loss 5.0483
2020-11-05 18:33:39,163 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2922 | Iter Mean Loss 3.1703
2020-11-05 18:33:39,170 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6864 | Iter Mean Loss 3.6756
2020-11-05 18:33:39,178 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0065 | Iter Mean Loss 3.7583
2020-11-05 18:33:39,185 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2990 | Iter Mean Loss 3.4665
2020-11-05 18:33:39,187 - root - INFO - Evaluate: Epoch 0879 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:33:39,194 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0453 | Iter Mean Loss 5.0453
2020-11-05 18:33:39,202 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2909 | Iter Mean Loss 3.1681
2020-11-05 18:33:39,209 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6809 | Iter Mean Loss 3.6724
2020-11-05 18:33:39,216 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 4.0018 | Iter Mean Loss 3.7547
2020-11-05 18:33:39,224 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2959 | Iter Mean Loss 3.4630
2020-11-05 18:33:39,226 - root - INFO - Evaluate: Epoch 0880 | NDCG 0.2817 | MSE 0.3240
2020-11-05 18:33:39,234 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0423 | Iter Mean Loss 5.0423
2020-11-05 18:33:39,242 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2896 | Iter Mean Loss 3.1659
2020-11-05 18:33:39,250 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6755 | Iter Mean Loss 3.6691
2020-11-05 18:33:39,257 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9971 | Iter Mean Loss 3.7511
2020-11-05 18:33:39,265 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2928 | Iter Mean Loss 3.4594
2020-11-05 18:33:39,267 - root - INFO - Evaluate: Epoch 0881 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:33:39,276 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0392 | Iter Mean Loss 5.0392
2020-11-05 18:33:39,284 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2883 | Iter Mean Loss 3.1638
2020-11-05 18:33:39,291 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6700 | Iter Mean Loss 3.6659
2020-11-05 18:33:39,300 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9924 | Iter Mean Loss 3.7475
2020-11-05 18:33:39,307 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2897 | Iter Mean Loss 3.4559
2020-11-05 18:33:39,309 - root - INFO - Evaluate: Epoch 0882 | NDCG 0.2817 | MSE 0.3241
2020-11-05 18:33:39,319 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0362 | Iter Mean Loss 5.0362
2020-11-05 18:33:39,327 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 3.1616
2020-11-05 18:33:39,335 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6646 | Iter Mean Loss 3.6626
2020-11-05 18:33:39,342 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9878 | Iter Mean Loss 3.7439
2020-11-05 18:33:39,349 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2866 | Iter Mean Loss 3.4524
2020-11-05 18:33:39,351 - root - INFO - Evaluate: Epoch 0883 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:33:39,359 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0332 | Iter Mean Loss 5.0332
2020-11-05 18:33:39,366 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2857 | Iter Mean Loss 3.1594
2020-11-05 18:33:39,374 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6592 | Iter Mean Loss 3.6593
2020-11-05 18:33:39,381 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9831 | Iter Mean Loss 3.7403
2020-11-05 18:33:39,388 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2836 | Iter Mean Loss 3.4489
2020-11-05 18:33:39,390 - root - INFO - Evaluate: Epoch 0884 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:33:39,398 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0301 | Iter Mean Loss 5.0301
2020-11-05 18:33:39,406 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2844 | Iter Mean Loss 3.1573
2020-11-05 18:33:39,413 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 3.6561
2020-11-05 18:33:39,420 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9785 | Iter Mean Loss 3.7367
2020-11-05 18:33:39,428 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2805 | Iter Mean Loss 3.4455
2020-11-05 18:33:39,430 - root - INFO - Evaluate: Epoch 0885 | NDCG 0.2817 | MSE 0.3242
2020-11-05 18:33:39,438 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0271 | Iter Mean Loss 5.0271
2020-11-05 18:33:39,447 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2831 | Iter Mean Loss 3.1551
2020-11-05 18:33:39,454 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6483 | Iter Mean Loss 3.6528
2020-11-05 18:33:39,462 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9738 | Iter Mean Loss 3.7331
2020-11-05 18:33:39,470 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2774 | Iter Mean Loss 3.4420
2020-11-05 18:33:39,472 - root - INFO - Evaluate: Epoch 0886 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:33:39,481 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0241 | Iter Mean Loss 5.0241
2020-11-05 18:33:39,489 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2818 | Iter Mean Loss 3.1529
2020-11-05 18:33:39,497 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6429 | Iter Mean Loss 3.6496
2020-11-05 18:33:39,505 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 3.7295
2020-11-05 18:33:39,512 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2744 | Iter Mean Loss 3.4385
2020-11-05 18:33:39,514 - root - INFO - Evaluate: Epoch 0887 | NDCG 0.2817 | MSE 0.3243
2020-11-05 18:33:39,523 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0210 | Iter Mean Loss 5.0210
2020-11-05 18:33:39,531 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2805 | Iter Mean Loss 3.1507
2020-11-05 18:33:39,539 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6375 | Iter Mean Loss 3.6463
2020-11-05 18:33:39,546 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 3.7259
2020-11-05 18:33:39,553 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2713 | Iter Mean Loss 3.4350
2020-11-05 18:33:39,555 - root - INFO - Evaluate: Epoch 0888 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:33:39,563 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0180 | Iter Mean Loss 5.0180
2020-11-05 18:33:39,570 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2791 | Iter Mean Loss 3.1486
2020-11-05 18:33:39,578 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6322 | Iter Mean Loss 3.6431
2020-11-05 18:33:39,585 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9600 | Iter Mean Loss 3.7223
2020-11-05 18:33:39,592 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2683 | Iter Mean Loss 3.4315
2020-11-05 18:33:39,594 - root - INFO - Evaluate: Epoch 0889 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:33:39,602 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0149 | Iter Mean Loss 5.0149
2020-11-05 18:33:39,609 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2778 | Iter Mean Loss 3.1464
2020-11-05 18:33:39,616 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6268 | Iter Mean Loss 3.6398
2020-11-05 18:33:39,623 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9554 | Iter Mean Loss 3.7187
2020-11-05 18:33:39,631 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2652 | Iter Mean Loss 3.4280
2020-11-05 18:33:39,634 - root - INFO - Evaluate: Epoch 0890 | NDCG 0.2817 | MSE 0.3244
2020-11-05 18:33:39,641 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0119 | Iter Mean Loss 5.0119
2020-11-05 18:33:39,649 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2765 | Iter Mean Loss 3.1442
2020-11-05 18:33:39,657 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6214 | Iter Mean Loss 3.6366
2020-11-05 18:33:39,664 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9508 | Iter Mean Loss 3.7151
2020-11-05 18:33:39,673 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2622 | Iter Mean Loss 3.4246
2020-11-05 18:33:39,675 - root - INFO - Evaluate: Epoch 0891 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:33:39,683 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0088 | Iter Mean Loss 5.0088
2020-11-05 18:33:39,691 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2752 | Iter Mean Loss 3.1420
2020-11-05 18:33:39,699 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6160 | Iter Mean Loss 3.6334
2020-11-05 18:33:39,707 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9462 | Iter Mean Loss 3.7116
2020-11-05 18:33:39,715 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2592 | Iter Mean Loss 3.4211
2020-11-05 18:33:39,717 - root - INFO - Evaluate: Epoch 0892 | NDCG 0.2817 | MSE 0.3245
2020-11-05 18:33:39,726 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0057 | Iter Mean Loss 5.0057
2020-11-05 18:33:39,733 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2739 | Iter Mean Loss 3.1398
2020-11-05 18:33:39,741 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6107 | Iter Mean Loss 3.6301
2020-11-05 18:33:39,749 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 3.7080
2020-11-05 18:33:39,756 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2561 | Iter Mean Loss 3.4176
2020-11-05 18:33:39,758 - root - INFO - Evaluate: Epoch 0893 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:33:39,766 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 5.0027 | Iter Mean Loss 5.0027
2020-11-05 18:33:39,773 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2726 | Iter Mean Loss 3.1376
2020-11-05 18:33:39,780 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6053 | Iter Mean Loss 3.6269
2020-11-05 18:33:39,788 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 3.7044
2020-11-05 18:33:39,795 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2531 | Iter Mean Loss 3.4141
2020-11-05 18:33:39,797 - root - INFO - Evaluate: Epoch 0894 | NDCG 0.2817 | MSE 0.3246
2020-11-05 18:33:39,804 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9996 | Iter Mean Loss 4.9996
2020-11-05 18:33:39,812 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2713 | Iter Mean Loss 3.1354
2020-11-05 18:33:39,819 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.6000 | Iter Mean Loss 3.6236
2020-11-05 18:33:39,826 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9324 | Iter Mean Loss 3.7008
2020-11-05 18:33:39,834 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2501 | Iter Mean Loss 3.4107
2020-11-05 18:33:39,837 - root - INFO - Evaluate: Epoch 0895 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:33:39,845 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9965 | Iter Mean Loss 4.9965
2020-11-05 18:33:39,852 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2700 | Iter Mean Loss 3.1332
2020-11-05 18:33:39,860 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5947 | Iter Mean Loss 3.6204
2020-11-05 18:33:39,868 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9279 | Iter Mean Loss 3.6972
2020-11-05 18:33:39,876 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2471 | Iter Mean Loss 3.4072
2020-11-05 18:33:39,878 - root - INFO - Evaluate: Epoch 0896 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:33:39,886 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9934 | Iter Mean Loss 4.9934
2020-11-05 18:33:39,894 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2686 | Iter Mean Loss 3.1310
2020-11-05 18:33:39,902 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5893 | Iter Mean Loss 3.6171
2020-11-05 18:33:39,910 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9233 | Iter Mean Loss 3.6937
2020-11-05 18:33:39,917 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2441 | Iter Mean Loss 3.4038
2020-11-05 18:33:39,919 - root - INFO - Evaluate: Epoch 0897 | NDCG 0.2817 | MSE 0.3247
2020-11-05 18:33:39,929 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9903 | Iter Mean Loss 4.9903
2020-11-05 18:33:39,936 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2673 | Iter Mean Loss 3.1288
2020-11-05 18:33:39,944 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5840 | Iter Mean Loss 3.6139
2020-11-05 18:33:39,951 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9188 | Iter Mean Loss 3.6901
2020-11-05 18:33:39,959 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2411 | Iter Mean Loss 3.4003
2020-11-05 18:33:39,961 - root - INFO - Evaluate: Epoch 0898 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:33:39,968 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9872 | Iter Mean Loss 4.9872
2020-11-05 18:33:39,976 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 3.1266
2020-11-05 18:33:39,983 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5787 | Iter Mean Loss 3.6106
2020-11-05 18:33:39,990 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9142 | Iter Mean Loss 3.6865
2020-11-05 18:33:39,997 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2381 | Iter Mean Loss 3.3968
2020-11-05 18:33:39,999 - root - INFO - Evaluate: Epoch 0899 | NDCG 0.2817 | MSE 0.3248
2020-11-05 18:33:40,007 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9841 | Iter Mean Loss 4.9841
2020-11-05 18:33:40,014 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2647 | Iter Mean Loss 3.1244
2020-11-05 18:33:40,022 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5734 | Iter Mean Loss 3.6074
2020-11-05 18:33:40,029 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9097 | Iter Mean Loss 3.6830
2020-11-05 18:33:40,037 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2351 | Iter Mean Loss 3.3934
2020-11-05 18:33:40,040 - root - INFO - Evaluate: Epoch 0900 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:33:40,048 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9810 | Iter Mean Loss 4.9810
2020-11-05 18:33:40,055 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2634 | Iter Mean Loss 3.1222
2020-11-05 18:33:40,063 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5681 | Iter Mean Loss 3.6041
2020-11-05 18:33:40,071 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9052 | Iter Mean Loss 3.6794
2020-11-05 18:33:40,078 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2321 | Iter Mean Loss 3.3899
2020-11-05 18:33:40,081 - root - INFO - Evaluate: Epoch 0901 | NDCG 0.2817 | MSE 0.3249
2020-11-05 18:33:40,089 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9778 | Iter Mean Loss 4.9778
2020-11-05 18:33:40,097 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2620 | Iter Mean Loss 3.1199
2020-11-05 18:33:40,104 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5628 | Iter Mean Loss 3.6009
2020-11-05 18:33:40,112 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.9007 | Iter Mean Loss 3.6758
2020-11-05 18:33:40,120 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2291 | Iter Mean Loss 3.3865
2020-11-05 18:33:40,122 - root - INFO - Evaluate: Epoch 0902 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:33:40,130 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9747 | Iter Mean Loss 4.9747
2020-11-05 18:33:40,138 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2607 | Iter Mean Loss 3.1177
2020-11-05 18:33:40,145 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5575 | Iter Mean Loss 3.5976
2020-11-05 18:33:40,153 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8961 | Iter Mean Loss 3.6723
2020-11-05 18:33:40,160 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 3.3830
2020-11-05 18:33:40,162 - root - INFO - Evaluate: Epoch 0903 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:33:40,169 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9716 | Iter Mean Loss 4.9716
2020-11-05 18:33:40,177 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2594 | Iter Mean Loss 3.1155
2020-11-05 18:33:40,184 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5522 | Iter Mean Loss 3.5944
2020-11-05 18:33:40,191 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8916 | Iter Mean Loss 3.6687
2020-11-05 18:33:40,198 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2231 | Iter Mean Loss 3.3796
2020-11-05 18:33:40,200 - root - INFO - Evaluate: Epoch 0904 | NDCG 0.2817 | MSE 0.3250
2020-11-05 18:33:40,208 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9684 | Iter Mean Loss 4.9684
2020-11-05 18:33:40,215 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2581 | Iter Mean Loss 3.1132
2020-11-05 18:33:40,222 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5469 | Iter Mean Loss 3.5911
2020-11-05 18:33:40,229 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8871 | Iter Mean Loss 3.6651
2020-11-05 18:33:40,236 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2202 | Iter Mean Loss 3.3761
2020-11-05 18:33:40,238 - root - INFO - Evaluate: Epoch 0905 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:33:40,247 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9653 | Iter Mean Loss 4.9653
2020-11-05 18:33:40,254 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2567 | Iter Mean Loss 3.1110
2020-11-05 18:33:40,261 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5417 | Iter Mean Loss 3.5879
2020-11-05 18:33:40,269 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8826 | Iter Mean Loss 3.6616
2020-11-05 18:33:40,277 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2172 | Iter Mean Loss 3.3727
2020-11-05 18:33:40,279 - root - INFO - Evaluate: Epoch 0906 | NDCG 0.2817 | MSE 0.3251
2020-11-05 18:33:40,287 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9621 | Iter Mean Loss 4.9621
2020-11-05 18:33:40,295 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2554 | Iter Mean Loss 3.1088
2020-11-05 18:33:40,303 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5364 | Iter Mean Loss 3.5846
2020-11-05 18:33:40,311 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8782 | Iter Mean Loss 3.6580
2020-11-05 18:33:40,320 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2142 | Iter Mean Loss 3.3693
2020-11-05 18:33:40,322 - root - INFO - Evaluate: Epoch 0907 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:33:40,331 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9590 | Iter Mean Loss 4.9590
2020-11-05 18:33:40,339 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2541 | Iter Mean Loss 3.1065
2020-11-05 18:33:40,346 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5311 | Iter Mean Loss 3.5814
2020-11-05 18:33:40,354 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8737 | Iter Mean Loss 3.6545
2020-11-05 18:33:40,361 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2113 | Iter Mean Loss 3.3658
2020-11-05 18:33:40,363 - root - INFO - Evaluate: Epoch 0908 | NDCG 0.2817 | MSE 0.3252
2020-11-05 18:33:40,371 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9558 | Iter Mean Loss 4.9558
2020-11-05 18:33:40,378 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2527 | Iter Mean Loss 3.1043
2020-11-05 18:33:40,385 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5259 | Iter Mean Loss 3.5781
2020-11-05 18:33:40,392 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8692 | Iter Mean Loss 3.6509
2020-11-05 18:33:40,400 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2083 | Iter Mean Loss 3.3624
2020-11-05 18:33:40,402 - root - INFO - Evaluate: Epoch 0909 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:33:40,411 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9526 | Iter Mean Loss 4.9526
2020-11-05 18:33:40,418 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2514 | Iter Mean Loss 3.1020
2020-11-05 18:33:40,427 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5207 | Iter Mean Loss 3.5749
2020-11-05 18:33:40,434 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8647 | Iter Mean Loss 3.6473
2020-11-05 18:33:40,443 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2054 | Iter Mean Loss 3.3589
2020-11-05 18:33:40,445 - root - INFO - Evaluate: Epoch 0910 | NDCG 0.2817 | MSE 0.3253
2020-11-05 18:33:40,455 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9494 | Iter Mean Loss 4.9494
2020-11-05 18:33:40,463 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2500 | Iter Mean Loss 3.0997
2020-11-05 18:33:40,473 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5154 | Iter Mean Loss 3.5716
2020-11-05 18:33:40,481 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8603 | Iter Mean Loss 3.6438
2020-11-05 18:33:40,490 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.2024 | Iter Mean Loss 3.3555
2020-11-05 18:33:40,492 - root - INFO - Evaluate: Epoch 0911 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:33:40,502 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9462 | Iter Mean Loss 4.9462
2020-11-05 18:33:40,511 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2487 | Iter Mean Loss 3.0975
2020-11-05 18:33:40,520 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 3.5684
2020-11-05 18:33:40,527 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8558 | Iter Mean Loss 3.6402
2020-11-05 18:33:40,537 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1995 | Iter Mean Loss 3.3521
2020-11-05 18:33:40,539 - root - INFO - Evaluate: Epoch 0912 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:33:40,548 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9430 | Iter Mean Loss 4.9430
2020-11-05 18:33:40,556 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2473 | Iter Mean Loss 3.0952
2020-11-05 18:33:40,564 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 3.5651
2020-11-05 18:33:40,572 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8514 | Iter Mean Loss 3.6367
2020-11-05 18:33:40,579 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1965 | Iter Mean Loss 3.3486
2020-11-05 18:33:40,582 - root - INFO - Evaluate: Epoch 0913 | NDCG 0.2817 | MSE 0.3254
2020-11-05 18:33:40,590 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9398 | Iter Mean Loss 4.9398
2020-11-05 18:33:40,598 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2460 | Iter Mean Loss 3.0929
2020-11-05 18:33:40,605 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4997 | Iter Mean Loss 3.5618
2020-11-05 18:33:40,613 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8469 | Iter Mean Loss 3.6331
2020-11-05 18:33:40,621 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1936 | Iter Mean Loss 3.3452
2020-11-05 18:33:40,623 - root - INFO - Evaluate: Epoch 0914 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:33:40,631 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9366 | Iter Mean Loss 4.9366
2020-11-05 18:33:40,639 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2446 | Iter Mean Loss 3.0906
2020-11-05 18:33:40,648 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4945 | Iter Mean Loss 3.5586
2020-11-05 18:33:40,656 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8425 | Iter Mean Loss 3.6296
2020-11-05 18:33:40,664 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1906 | Iter Mean Loss 3.3418
2020-11-05 18:33:40,666 - root - INFO - Evaluate: Epoch 0915 | NDCG 0.2817 | MSE 0.3255
2020-11-05 18:33:40,675 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9334 | Iter Mean Loss 4.9334
2020-11-05 18:33:40,684 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2433 | Iter Mean Loss 3.0883
2020-11-05 18:33:40,692 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4893 | Iter Mean Loss 3.5553
2020-11-05 18:33:40,701 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8380 | Iter Mean Loss 3.6260
2020-11-05 18:33:40,709 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1877 | Iter Mean Loss 3.3383
2020-11-05 18:33:40,712 - root - INFO - Evaluate: Epoch 0916 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:33:40,722 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9301 | Iter Mean Loss 4.9301
2020-11-05 18:33:40,731 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2419 | Iter Mean Loss 3.0860
2020-11-05 18:33:40,739 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4841 | Iter Mean Loss 3.5520
2020-11-05 18:33:40,748 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8336 | Iter Mean Loss 3.6224
2020-11-05 18:33:40,755 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1848 | Iter Mean Loss 3.3349
2020-11-05 18:33:40,757 - root - INFO - Evaluate: Epoch 0917 | NDCG 0.2817 | MSE 0.3256
2020-11-05 18:33:40,767 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9269 | Iter Mean Loss 4.9269
2020-11-05 18:33:40,774 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2406 | Iter Mean Loss 3.0837
2020-11-05 18:33:40,782 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4789 | Iter Mean Loss 3.5488
2020-11-05 18:33:40,790 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8292 | Iter Mean Loss 3.6189
2020-11-05 18:33:40,797 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1818 | Iter Mean Loss 3.3315
2020-11-05 18:33:40,799 - root - INFO - Evaluate: Epoch 0918 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:33:40,807 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9236 | Iter Mean Loss 4.9236
2020-11-05 18:33:40,815 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2392 | Iter Mean Loss 3.0814
2020-11-05 18:33:40,823 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4737 | Iter Mean Loss 3.5455
2020-11-05 18:33:40,830 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8248 | Iter Mean Loss 3.6153
2020-11-05 18:33:40,838 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1789 | Iter Mean Loss 3.3280
2020-11-05 18:33:40,840 - root - INFO - Evaluate: Epoch 0919 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:33:40,848 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9203 | Iter Mean Loss 4.9203
2020-11-05 18:33:40,857 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2378 | Iter Mean Loss 3.0791
2020-11-05 18:33:40,865 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4685 | Iter Mean Loss 3.5422
2020-11-05 18:33:40,873 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8204 | Iter Mean Loss 3.6118
2020-11-05 18:33:40,881 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1760 | Iter Mean Loss 3.3246
2020-11-05 18:33:40,883 - root - INFO - Evaluate: Epoch 0920 | NDCG 0.2817 | MSE 0.3257
2020-11-05 18:33:40,892 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9171 | Iter Mean Loss 4.9171
2020-11-05 18:33:40,901 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2364 | Iter Mean Loss 3.0767
2020-11-05 18:33:40,910 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4633 | Iter Mean Loss 3.5389
2020-11-05 18:33:40,918 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8160 | Iter Mean Loss 3.6082
2020-11-05 18:33:40,926 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1730 | Iter Mean Loss 3.3212
2020-11-05 18:33:40,929 - root - INFO - Evaluate: Epoch 0921 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:33:40,937 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9138 | Iter Mean Loss 4.9138
2020-11-05 18:33:40,945 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2351 | Iter Mean Loss 3.0744
2020-11-05 18:33:40,953 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4582 | Iter Mean Loss 3.5357
2020-11-05 18:33:40,961 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8116 | Iter Mean Loss 3.6046
2020-11-05 18:33:40,969 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1701 | Iter Mean Loss 3.3177
2020-11-05 18:33:40,971 - root - INFO - Evaluate: Epoch 0922 | NDCG 0.2817 | MSE 0.3258
2020-11-05 18:33:40,979 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9105 | Iter Mean Loss 4.9105
2020-11-05 18:33:40,987 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2337 | Iter Mean Loss 3.0721
2020-11-05 18:33:40,995 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4530 | Iter Mean Loss 3.5324
2020-11-05 18:33:41,002 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8072 | Iter Mean Loss 3.6011
2020-11-05 18:33:41,009 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1672 | Iter Mean Loss 3.3143
2020-11-05 18:33:41,011 - root - INFO - Evaluate: Epoch 0923 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:33:41,019 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9072 | Iter Mean Loss 4.9072
2020-11-05 18:33:41,027 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2323 | Iter Mean Loss 3.0697
2020-11-05 18:33:41,035 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 3.5291
2020-11-05 18:33:41,043 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.8028 | Iter Mean Loss 3.5975
2020-11-05 18:33:41,051 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1643 | Iter Mean Loss 3.3109
2020-11-05 18:33:41,053 - root - INFO - Evaluate: Epoch 0924 | NDCG 0.2817 | MSE 0.3259
2020-11-05 18:33:41,063 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9038 | Iter Mean Loss 4.9038
2020-11-05 18:33:41,070 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2309 | Iter Mean Loss 3.0674
2020-11-05 18:33:41,079 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4427 | Iter Mean Loss 3.5258
2020-11-05 18:33:41,087 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7984 | Iter Mean Loss 3.5940
2020-11-05 18:33:41,096 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1614 | Iter Mean Loss 3.3074
2020-11-05 18:33:41,098 - root - INFO - Evaluate: Epoch 0925 | NDCG 0.2817 | MSE 0.3260
2020-11-05 18:33:41,107 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.9005 | Iter Mean Loss 4.9005
2020-11-05 18:33:41,118 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2295 | Iter Mean Loss 3.0650
2020-11-05 18:33:41,126 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4375 | Iter Mean Loss 3.5225
2020-11-05 18:33:41,134 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7940 | Iter Mean Loss 3.5904
2020-11-05 18:33:41,142 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1585 | Iter Mean Loss 3.3040
2020-11-05 18:33:41,145 - root - INFO - Evaluate: Epoch 0926 | NDCG 0.2817 | MSE 0.3260
2020-11-05 18:33:41,154 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8972 | Iter Mean Loss 4.8972
2020-11-05 18:33:41,162 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2281 | Iter Mean Loss 3.0626
2020-11-05 18:33:41,170 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4324 | Iter Mean Loss 3.5192
2020-11-05 18:33:41,178 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7896 | Iter Mean Loss 3.5868
2020-11-05 18:33:41,185 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1556 | Iter Mean Loss 3.3006
2020-11-05 18:33:41,187 - root - INFO - Evaluate: Epoch 0927 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:33:41,195 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8938 | Iter Mean Loss 4.8938
2020-11-05 18:33:41,202 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2267 | Iter Mean Loss 3.0603
2020-11-05 18:33:41,210 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4272 | Iter Mean Loss 3.5159
2020-11-05 18:33:41,217 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7853 | Iter Mean Loss 3.5833
2020-11-05 18:33:41,224 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1526 | Iter Mean Loss 3.2971
2020-11-05 18:33:41,226 - root - INFO - Evaluate: Epoch 0928 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:33:41,234 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8904 | Iter Mean Loss 4.8904
2020-11-05 18:33:41,242 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2253 | Iter Mean Loss 3.0579
2020-11-05 18:33:41,249 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4221 | Iter Mean Loss 3.5126
2020-11-05 18:33:41,258 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7809 | Iter Mean Loss 3.5797
2020-11-05 18:33:41,266 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1497 | Iter Mean Loss 3.2937
2020-11-05 18:33:41,268 - root - INFO - Evaluate: Epoch 0929 | NDCG 0.2817 | MSE 0.3261
2020-11-05 18:33:41,277 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8871 | Iter Mean Loss 4.8871
2020-11-05 18:33:41,285 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2239 | Iter Mean Loss 3.0555
2020-11-05 18:33:41,293 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4169 | Iter Mean Loss 3.5093
2020-11-05 18:33:41,302 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7765 | Iter Mean Loss 3.5761
2020-11-05 18:33:41,310 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1468 | Iter Mean Loss 3.2903
2020-11-05 18:33:41,313 - root - INFO - Evaluate: Epoch 0930 | NDCG 0.2817 | MSE 0.3262
2020-11-05 18:33:41,323 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8837 | Iter Mean Loss 4.8837
2020-11-05 18:33:41,332 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2225 | Iter Mean Loss 3.0531
2020-11-05 18:33:41,341 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4118 | Iter Mean Loss 3.5060
2020-11-05 18:33:41,349 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7722 | Iter Mean Loss 3.5725
2020-11-05 18:33:41,358 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1439 | Iter Mean Loss 3.2868
2020-11-05 18:33:41,360 - root - INFO - Evaluate: Epoch 0931 | NDCG 0.2817 | MSE 0.3262
2020-11-05 18:33:41,369 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8803 | Iter Mean Loss 4.8803
2020-11-05 18:33:41,377 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2211 | Iter Mean Loss 3.0507
2020-11-05 18:33:41,385 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4067 | Iter Mean Loss 3.5027
2020-11-05 18:33:41,393 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7678 | Iter Mean Loss 3.5690
2020-11-05 18:33:41,402 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1410 | Iter Mean Loss 3.2834
2020-11-05 18:33:41,404 - root - INFO - Evaluate: Epoch 0932 | NDCG 0.2817 | MSE 0.3263
2020-11-05 18:33:41,412 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8768 | Iter Mean Loss 4.8768
2020-11-05 18:33:41,420 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2197 | Iter Mean Loss 3.0483
2020-11-05 18:33:41,427 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.4016 | Iter Mean Loss 3.4994
2020-11-05 18:33:41,435 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7635 | Iter Mean Loss 3.5654
2020-11-05 18:33:41,443 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1381 | Iter Mean Loss 3.2799
2020-11-05 18:33:41,445 - root - INFO - Evaluate: Epoch 0933 | NDCG 0.2817 | MSE 0.3263
2020-11-05 18:33:41,454 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8734 | Iter Mean Loss 4.8734
2020-11-05 18:33:41,462 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 3.0458
2020-11-05 18:33:41,471 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3964 | Iter Mean Loss 3.4960
2020-11-05 18:33:41,478 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7591 | Iter Mean Loss 3.5618
2020-11-05 18:33:41,487 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1352 | Iter Mean Loss 3.2765
2020-11-05 18:33:41,489 - root - INFO - Evaluate: Epoch 0934 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:33:41,498 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8700 | Iter Mean Loss 4.8700
2020-11-05 18:33:41,507 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2168 | Iter Mean Loss 3.0434
2020-11-05 18:33:41,515 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 3.4927
2020-11-05 18:33:41,523 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7548 | Iter Mean Loss 3.5582
2020-11-05 18:33:41,531 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1323 | Iter Mean Loss 3.2731
2020-11-05 18:33:41,533 - root - INFO - Evaluate: Epoch 0935 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:33:41,542 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8665 | Iter Mean Loss 4.8665
2020-11-05 18:33:41,550 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2154 | Iter Mean Loss 3.0410
2020-11-05 18:33:41,559 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3862 | Iter Mean Loss 3.4894
2020-11-05 18:33:41,567 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7505 | Iter Mean Loss 3.5546
2020-11-05 18:33:41,575 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1294 | Iter Mean Loss 3.2696
2020-11-05 18:33:41,578 - root - INFO - Evaluate: Epoch 0936 | NDCG 0.2817 | MSE 0.3264
2020-11-05 18:33:41,586 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8631 | Iter Mean Loss 4.8631
2020-11-05 18:33:41,594 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2140 | Iter Mean Loss 3.0385
2020-11-05 18:33:41,601 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3811 | Iter Mean Loss 3.4860
2020-11-05 18:33:41,609 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7461 | Iter Mean Loss 3.5511
2020-11-05 18:33:41,616 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1265 | Iter Mean Loss 3.2662
2020-11-05 18:33:41,618 - root - INFO - Evaluate: Epoch 0937 | NDCG 0.2817 | MSE 0.3265
2020-11-05 18:33:41,626 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8596 | Iter Mean Loss 4.8596
2020-11-05 18:33:41,634 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2125 | Iter Mean Loss 3.0360
2020-11-05 18:33:41,642 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3760 | Iter Mean Loss 3.4827
2020-11-05 18:33:41,649 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7418 | Iter Mean Loss 3.5475
2020-11-05 18:33:41,657 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1237 | Iter Mean Loss 3.2627
2020-11-05 18:33:41,659 - root - INFO - Evaluate: Epoch 0938 | NDCG 0.2817 | MSE 0.3265
2020-11-05 18:33:41,667 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8561 | Iter Mean Loss 4.8561
2020-11-05 18:33:41,676 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2111 | Iter Mean Loss 3.0336
2020-11-05 18:33:41,683 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3709 | Iter Mean Loss 3.4793
2020-11-05 18:33:41,691 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7375 | Iter Mean Loss 3.5439
2020-11-05 18:33:41,699 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1208 | Iter Mean Loss 3.2593
2020-11-05 18:33:41,701 - root - INFO - Evaluate: Epoch 0939 | NDCG 0.2817 | MSE 0.3266
2020-11-05 18:33:41,710 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8526 | Iter Mean Loss 4.8526
2020-11-05 18:33:41,718 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2096 | Iter Mean Loss 3.0311
2020-11-05 18:33:41,726 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3658 | Iter Mean Loss 3.4760
2020-11-05 18:33:41,734 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7332 | Iter Mean Loss 3.5403
2020-11-05 18:33:41,742 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1179 | Iter Mean Loss 3.2558
2020-11-05 18:33:41,744 - root - INFO - Evaluate: Epoch 0940 | NDCG 0.2817 | MSE 0.3266
2020-11-05 18:33:41,753 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8490 | Iter Mean Loss 4.8490
2020-11-05 18:33:41,761 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 3.0286
2020-11-05 18:33:41,770 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3607 | Iter Mean Loss 3.4726
2020-11-05 18:33:41,777 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7288 | Iter Mean Loss 3.5367
2020-11-05 18:33:41,785 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1150 | Iter Mean Loss 3.2523
2020-11-05 18:33:41,787 - root - INFO - Evaluate: Epoch 0941 | NDCG 0.2817 | MSE 0.3267
2020-11-05 18:33:41,796 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8455 | Iter Mean Loss 4.8455
2020-11-05 18:33:41,803 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2067 | Iter Mean Loss 3.0261
2020-11-05 18:33:41,811 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3556 | Iter Mean Loss 3.4693
2020-11-05 18:33:41,818 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7245 | Iter Mean Loss 3.5331
2020-11-05 18:33:41,825 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1121 | Iter Mean Loss 3.2489
2020-11-05 18:33:41,827 - root - INFO - Evaluate: Epoch 0942 | NDCG 0.2817 | MSE 0.3267
2020-11-05 18:33:41,835 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8420 | Iter Mean Loss 4.8420
2020-11-05 18:33:41,843 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2052 | Iter Mean Loss 3.0236
2020-11-05 18:33:41,850 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3505 | Iter Mean Loss 3.4659
2020-11-05 18:33:41,858 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7202 | Iter Mean Loss 3.5295
2020-11-05 18:33:41,865 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1092 | Iter Mean Loss 3.2454
2020-11-05 18:33:41,867 - root - INFO - Evaluate: Epoch 0943 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:33:41,876 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8384 | Iter Mean Loss 4.8384
2020-11-05 18:33:41,884 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2038 | Iter Mean Loss 3.0211
2020-11-05 18:33:41,892 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3455 | Iter Mean Loss 3.4625
2020-11-05 18:33:41,901 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7159 | Iter Mean Loss 3.5259
2020-11-05 18:33:41,908 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1063 | Iter Mean Loss 3.2420
2020-11-05 18:33:41,912 - root - INFO - Evaluate: Epoch 0944 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:33:41,921 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8348 | Iter Mean Loss 4.8348
2020-11-05 18:33:41,930 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2023 | Iter Mean Loss 3.0185
2020-11-05 18:33:41,937 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3404 | Iter Mean Loss 3.4592
2020-11-05 18:33:41,946 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7116 | Iter Mean Loss 3.5223
2020-11-05 18:33:41,953 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1034 | Iter Mean Loss 3.2385
2020-11-05 18:33:41,956 - root - INFO - Evaluate: Epoch 0945 | NDCG 0.2817 | MSE 0.3268
2020-11-05 18:33:41,964 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8312 | Iter Mean Loss 4.8312
2020-11-05 18:33:41,972 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2008 | Iter Mean Loss 3.0160
2020-11-05 18:33:41,980 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3353 | Iter Mean Loss 3.4558
2020-11-05 18:33:41,988 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7073 | Iter Mean Loss 3.5187
2020-11-05 18:33:41,996 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.1005 | Iter Mean Loss 3.2350
2020-11-05 18:33:41,998 - root - INFO - Evaluate: Epoch 0946 | NDCG 0.2817 | MSE 0.3269
2020-11-05 18:33:42,006 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8276 | Iter Mean Loss 4.8276
2020-11-05 18:33:42,013 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1993 | Iter Mean Loss 3.0134
2020-11-05 18:33:42,020 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3302 | Iter Mean Loss 3.4524
2020-11-05 18:33:42,028 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.7030 | Iter Mean Loss 3.5150
2020-11-05 18:33:42,036 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0976 | Iter Mean Loss 3.2316
2020-11-05 18:33:42,039 - root - INFO - Evaluate: Epoch 0947 | NDCG 0.2817 | MSE 0.3269
2020-11-05 18:33:42,046 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8240 | Iter Mean Loss 4.8240
2020-11-05 18:33:42,054 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1978 | Iter Mean Loss 3.0109
2020-11-05 18:33:42,061 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3252 | Iter Mean Loss 3.4490
2020-11-05 18:33:42,069 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6987 | Iter Mean Loss 3.5114
2020-11-05 18:33:42,076 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0948 | Iter Mean Loss 3.2281
2020-11-05 18:33:42,080 - root - INFO - Evaluate: Epoch 0948 | NDCG 0.2817 | MSE 0.3270
2020-11-05 18:33:42,088 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8203 | Iter Mean Loss 4.8203
2020-11-05 18:33:42,097 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1963 | Iter Mean Loss 3.0083
2020-11-05 18:33:42,104 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3201 | Iter Mean Loss 3.4456
2020-11-05 18:33:42,112 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6945 | Iter Mean Loss 3.5078
2020-11-05 18:33:42,120 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0919 | Iter Mean Loss 3.2246
2020-11-05 18:33:42,123 - root - INFO - Evaluate: Epoch 0949 | NDCG 0.2817 | MSE 0.3270
2020-11-05 18:33:42,132 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8166 | Iter Mean Loss 4.8166
2020-11-05 18:33:42,140 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1948 | Iter Mean Loss 3.0057
2020-11-05 18:33:42,147 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 3.4422
2020-11-05 18:33:42,156 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6902 | Iter Mean Loss 3.5042
2020-11-05 18:33:42,163 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0890 | Iter Mean Loss 3.2211
2020-11-05 18:33:42,166 - root - INFO - Evaluate: Epoch 0950 | NDCG 0.2817 | MSE 0.3271
2020-11-05 18:33:42,175 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8130 | Iter Mean Loss 4.8130
2020-11-05 18:33:42,183 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1933 | Iter Mean Loss 3.0031
2020-11-05 18:33:42,191 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3100 | Iter Mean Loss 3.4387
2020-11-05 18:33:42,198 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6859 | Iter Mean Loss 3.5005
2020-11-05 18:33:42,205 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0861 | Iter Mean Loss 3.2176
2020-11-05 18:33:42,207 - root - INFO - Evaluate: Epoch 0951 | NDCG 0.2817 | MSE 0.3271
2020-11-05 18:33:42,215 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8093 | Iter Mean Loss 4.8093
2020-11-05 18:33:42,223 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1918 | Iter Mean Loss 3.0005
2020-11-05 18:33:42,230 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.3049 | Iter Mean Loss 3.4353
2020-11-05 18:33:42,237 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6816 | Iter Mean Loss 3.4969
2020-11-05 18:33:42,245 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0832 | Iter Mean Loss 3.2142
2020-11-05 18:33:42,248 - root - INFO - Evaluate: Epoch 0952 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:33:42,258 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8055 | Iter Mean Loss 4.8055
2020-11-05 18:33:42,269 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1902 | Iter Mean Loss 2.9979
2020-11-05 18:33:42,278 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 3.4319
2020-11-05 18:33:42,286 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6773 | Iter Mean Loss 3.4933
2020-11-05 18:33:42,294 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0803 | Iter Mean Loss 3.2107
2020-11-05 18:33:42,296 - root - INFO - Evaluate: Epoch 0953 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:33:42,306 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.8018 | Iter Mean Loss 4.8018
2020-11-05 18:33:42,317 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1887 | Iter Mean Loss 2.9953
2020-11-05 18:33:42,328 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2948 | Iter Mean Loss 3.4285
2020-11-05 18:33:42,337 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6731 | Iter Mean Loss 3.4896
2020-11-05 18:33:42,347 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0774 | Iter Mean Loss 3.2072
2020-11-05 18:33:42,349 - root - INFO - Evaluate: Epoch 0954 | NDCG 0.2817 | MSE 0.3272
2020-11-05 18:33:42,360 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7981 | Iter Mean Loss 4.7981
2020-11-05 18:33:42,367 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1872 | Iter Mean Loss 2.9926
2020-11-05 18:33:42,378 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2898 | Iter Mean Loss 3.4250
2020-11-05 18:33:42,385 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6688 | Iter Mean Loss 3.4860
2020-11-05 18:33:42,394 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0745 | Iter Mean Loss 3.2037
2020-11-05 18:33:42,396 - root - INFO - Evaluate: Epoch 0955 | NDCG 0.2817 | MSE 0.3273
2020-11-05 18:33:42,405 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7943 | Iter Mean Loss 4.7943
2020-11-05 18:33:42,413 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1856 | Iter Mean Loss 2.9900
2020-11-05 18:33:42,422 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 3.4216
2020-11-05 18:33:42,429 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6645 | Iter Mean Loss 3.4823
2020-11-05 18:33:42,436 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0716 | Iter Mean Loss 3.2002
2020-11-05 18:33:42,438 - root - INFO - Evaluate: Epoch 0956 | NDCG 0.2817 | MSE 0.3273
2020-11-05 18:33:42,446 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7905 | Iter Mean Loss 4.7905
2020-11-05 18:33:42,453 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1841 | Iter Mean Loss 2.9873
2020-11-05 18:33:42,460 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2797 | Iter Mean Loss 3.4181
2020-11-05 18:33:42,468 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6603 | Iter Mean Loss 3.4786
2020-11-05 18:33:42,476 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0687 | Iter Mean Loss 3.1967
2020-11-05 18:33:42,478 - root - INFO - Evaluate: Epoch 0957 | NDCG 0.2817 | MSE 0.3274
2020-11-05 18:33:42,487 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7867 | Iter Mean Loss 4.7867
2020-11-05 18:33:42,495 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1825 | Iter Mean Loss 2.9846
2020-11-05 18:33:42,503 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2747 | Iter Mean Loss 3.4146
2020-11-05 18:33:42,511 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6560 | Iter Mean Loss 3.4750
2020-11-05 18:33:42,519 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0659 | Iter Mean Loss 3.1931
2020-11-05 18:33:42,522 - root - INFO - Evaluate: Epoch 0958 | NDCG 0.2817 | MSE 0.3274
2020-11-05 18:33:42,530 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7829 | Iter Mean Loss 4.7829
2020-11-05 18:33:42,538 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1809 | Iter Mean Loss 2.9819
2020-11-05 18:33:42,547 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2696 | Iter Mean Loss 3.4112
2020-11-05 18:33:42,555 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6517 | Iter Mean Loss 3.4713
2020-11-05 18:33:42,562 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0630 | Iter Mean Loss 3.1896
2020-11-05 18:33:42,565 - root - INFO - Evaluate: Epoch 0959 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:33:42,574 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7790 | Iter Mean Loss 4.7790
2020-11-05 18:33:42,582 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1794 | Iter Mean Loss 2.9792
2020-11-05 18:33:42,590 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2646 | Iter Mean Loss 3.4077
2020-11-05 18:33:42,597 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6475 | Iter Mean Loss 3.4676
2020-11-05 18:33:42,604 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0601 | Iter Mean Loss 3.1861
2020-11-05 18:33:42,607 - root - INFO - Evaluate: Epoch 0960 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:33:42,614 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7752 | Iter Mean Loss 4.7752
2020-11-05 18:33:42,622 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1778 | Iter Mean Loss 2.9765
2020-11-05 18:33:42,629 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2596 | Iter Mean Loss 3.4042
2020-11-05 18:33:42,636 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 3.4639
2020-11-05 18:33:42,643 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0572 | Iter Mean Loss 3.1826
2020-11-05 18:33:42,645 - root - INFO - Evaluate: Epoch 0961 | NDCG 0.2817 | MSE 0.3275
2020-11-05 18:33:42,653 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7713 | Iter Mean Loss 4.7713
2020-11-05 18:33:42,660 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1762 | Iter Mean Loss 2.9738
2020-11-05 18:33:42,667 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2545 | Iter Mean Loss 3.4007
2020-11-05 18:33:42,674 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6390 | Iter Mean Loss 3.4603
2020-11-05 18:33:42,683 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0543 | Iter Mean Loss 3.1791
2020-11-05 18:33:42,685 - root - INFO - Evaluate: Epoch 0962 | NDCG 0.2817 | MSE 0.3276
2020-11-05 18:33:42,694 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7674 | Iter Mean Loss 4.7674
2020-11-05 18:33:42,701 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1746 | Iter Mean Loss 2.9710
2020-11-05 18:33:42,709 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2495 | Iter Mean Loss 3.3972
2020-11-05 18:33:42,717 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6347 | Iter Mean Loss 3.4566
2020-11-05 18:33:42,724 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0514 | Iter Mean Loss 3.1755
2020-11-05 18:33:42,727 - root - INFO - Evaluate: Epoch 0963 | NDCG 0.2817 | MSE 0.3276
2020-11-05 18:33:42,737 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7635 | Iter Mean Loss 4.7635
2020-11-05 18:33:42,744 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1730 | Iter Mean Loss 2.9682
2020-11-05 18:33:42,753 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2445 | Iter Mean Loss 3.3937
2020-11-05 18:33:42,760 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6305 | Iter Mean Loss 3.4529
2020-11-05 18:33:42,768 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0485 | Iter Mean Loss 3.1720
2020-11-05 18:33:42,770 - root - INFO - Evaluate: Epoch 0964 | NDCG 0.2817 | MSE 0.3277
2020-11-05 18:33:42,778 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7595 | Iter Mean Loss 4.7595
2020-11-05 18:33:42,788 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 2.9655
2020-11-05 18:33:42,795 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2395 | Iter Mean Loss 3.3901
2020-11-05 18:33:42,803 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6262 | Iter Mean Loss 3.4492
2020-11-05 18:33:42,810 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0456 | Iter Mean Loss 3.1684
2020-11-05 18:33:42,812 - root - INFO - Evaluate: Epoch 0965 | NDCG 0.2817 | MSE 0.3277
2020-11-05 18:33:42,820 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7556 | Iter Mean Loss 4.7556
2020-11-05 18:33:42,827 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1698 | Iter Mean Loss 2.9627
2020-11-05 18:33:42,834 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2344 | Iter Mean Loss 3.3866
2020-11-05 18:33:42,841 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6220 | Iter Mean Loss 3.4454
2020-11-05 18:33:42,848 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0427 | Iter Mean Loss 3.1649
2020-11-05 18:33:42,850 - root - INFO - Evaluate: Epoch 0966 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:33:42,858 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7516 | Iter Mean Loss 4.7516
2020-11-05 18:33:42,865 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1682 | Iter Mean Loss 2.9599
2020-11-05 18:33:42,873 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2294 | Iter Mean Loss 3.3831
2020-11-05 18:33:42,880 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6177 | Iter Mean Loss 3.4417
2020-11-05 18:33:42,888 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0398 | Iter Mean Loss 3.1613
2020-11-05 18:33:42,890 - root - INFO - Evaluate: Epoch 0967 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:33:42,899 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7476 | Iter Mean Loss 4.7476
2020-11-05 18:33:42,906 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1665 | Iter Mean Loss 2.9571
2020-11-05 18:33:42,914 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2244 | Iter Mean Loss 3.3795
2020-11-05 18:33:42,922 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6135 | Iter Mean Loss 3.4380
2020-11-05 18:33:42,929 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0369 | Iter Mean Loss 3.1578
2020-11-05 18:33:42,932 - root - INFO - Evaluate: Epoch 0968 | NDCG 0.2817 | MSE 0.3278
2020-11-05 18:33:42,940 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7436 | Iter Mean Loss 4.7436
2020-11-05 18:33:42,948 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1649 | Iter Mean Loss 2.9542
2020-11-05 18:33:42,957 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2194 | Iter Mean Loss 3.3760
2020-11-05 18:33:42,964 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6092 | Iter Mean Loss 3.4343
2020-11-05 18:33:42,972 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0339 | Iter Mean Loss 3.1542
2020-11-05 18:33:42,974 - root - INFO - Evaluate: Epoch 0969 | NDCG 0.2817 | MSE 0.3279
2020-11-05 18:33:42,983 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7395 | Iter Mean Loss 4.7395
2020-11-05 18:33:42,991 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1633 | Iter Mean Loss 2.9514
2020-11-05 18:33:42,998 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2144 | Iter Mean Loss 3.3724
2020-11-05 18:33:43,006 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6050 | Iter Mean Loss 3.4305
2020-11-05 18:33:43,013 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0310 | Iter Mean Loss 3.1506
2020-11-05 18:33:43,015 - root - INFO - Evaluate: Epoch 0970 | NDCG 0.2817 | MSE 0.3279
2020-11-05 18:33:43,023 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7354 | Iter Mean Loss 4.7354
2020-11-05 18:33:43,031 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1616 | Iter Mean Loss 2.9485
2020-11-05 18:33:43,039 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2094 | Iter Mean Loss 3.3688
2020-11-05 18:33:43,046 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.6008 | Iter Mean Loss 3.4268
2020-11-05 18:33:43,053 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0281 | Iter Mean Loss 3.1471
2020-11-05 18:33:43,055 - root - INFO - Evaluate: Epoch 0971 | NDCG 0.2817 | MSE 0.3280
2020-11-05 18:33:43,063 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7313 | Iter Mean Loss 4.7313
2020-11-05 18:33:43,070 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1600 | Iter Mean Loss 2.9457
2020-11-05 18:33:43,077 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.2043 | Iter Mean Loss 3.3652
2020-11-05 18:33:43,084 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5965 | Iter Mean Loss 3.4230
2020-11-05 18:33:43,093 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0252 | Iter Mean Loss 3.1435
2020-11-05 18:33:43,095 - root - INFO - Evaluate: Epoch 0972 | NDCG 0.2817 | MSE 0.3280
2020-11-05 18:33:43,104 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7272 | Iter Mean Loss 4.7272
2020-11-05 18:33:43,111 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1583 | Iter Mean Loss 2.9428
2020-11-05 18:33:43,120 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1993 | Iter Mean Loss 3.3616
2020-11-05 18:33:43,127 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5923 | Iter Mean Loss 3.4193
2020-11-05 18:33:43,135 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0223 | Iter Mean Loss 3.1399
2020-11-05 18:33:43,138 - root - INFO - Evaluate: Epoch 0973 | NDCG 0.2817 | MSE 0.3281
2020-11-05 18:33:43,146 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7231 | Iter Mean Loss 4.7231
2020-11-05 18:33:43,155 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1566 | Iter Mean Loss 2.9399
2020-11-05 18:33:43,163 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1943 | Iter Mean Loss 3.3580
2020-11-05 18:33:43,171 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5881 | Iter Mean Loss 3.4155
2020-11-05 18:33:43,178 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0194 | Iter Mean Loss 3.1363
2020-11-05 18:33:43,180 - root - INFO - Evaluate: Epoch 0974 | NDCG 0.2817 | MSE 0.3281
2020-11-05 18:33:43,189 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7189 | Iter Mean Loss 4.7189
2020-11-05 18:33:43,197 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1549 | Iter Mean Loss 2.9369
2020-11-05 18:33:43,205 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1893 | Iter Mean Loss 3.3544
2020-11-05 18:33:43,212 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5838 | Iter Mean Loss 3.4118
2020-11-05 18:33:43,219 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0164 | Iter Mean Loss 3.1327
2020-11-05 18:33:43,221 - root - INFO - Evaluate: Epoch 0975 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:33:43,229 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7148 | Iter Mean Loss 4.7148
2020-11-05 18:33:43,236 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1533 | Iter Mean Loss 2.9340
2020-11-05 18:33:43,243 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1843 | Iter Mean Loss 3.3508
2020-11-05 18:33:43,250 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5796 | Iter Mean Loss 3.4080
2020-11-05 18:33:43,257 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0135 | Iter Mean Loss 3.1291
2020-11-05 18:33:43,259 - root - INFO - Evaluate: Epoch 0976 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:33:43,267 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7106 | Iter Mean Loss 4.7106
2020-11-05 18:33:43,274 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 2.9311
2020-11-05 18:33:43,282 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1793 | Iter Mean Loss 3.3471
2020-11-05 18:33:43,289 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5754 | Iter Mean Loss 3.4042
2020-11-05 18:33:43,296 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0106 | Iter Mean Loss 3.1255
2020-11-05 18:33:43,298 - root - INFO - Evaluate: Epoch 0977 | NDCG 0.2817 | MSE 0.3282
2020-11-05 18:33:43,307 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7063 | Iter Mean Loss 4.7063
2020-11-05 18:33:43,315 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1499 | Iter Mean Loss 2.9281
2020-11-05 18:33:43,323 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1743 | Iter Mean Loss 3.3435
2020-11-05 18:33:43,331 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5711 | Iter Mean Loss 3.4004
2020-11-05 18:33:43,339 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0076 | Iter Mean Loss 3.1218
2020-11-05 18:33:43,341 - root - INFO - Evaluate: Epoch 0978 | NDCG 0.2817 | MSE 0.3283
2020-11-05 18:33:43,349 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.7021 | Iter Mean Loss 4.7021
2020-11-05 18:33:43,357 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1481 | Iter Mean Loss 2.9251
2020-11-05 18:33:43,365 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1693 | Iter Mean Loss 3.3398
2020-11-05 18:33:43,372 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5669 | Iter Mean Loss 3.3966
2020-11-05 18:33:43,380 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0047 | Iter Mean Loss 3.1182
2020-11-05 18:33:43,382 - root - INFO - Evaluate: Epoch 0979 | NDCG 0.2817 | MSE 0.3283
2020-11-05 18:33:43,390 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6978 | Iter Mean Loss 4.6978
2020-11-05 18:33:43,398 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1464 | Iter Mean Loss 2.9221
2020-11-05 18:33:43,406 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1643 | Iter Mean Loss 3.3362
2020-11-05 18:33:43,413 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5627 | Iter Mean Loss 3.3928
2020-11-05 18:33:43,421 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 2.0018 | Iter Mean Loss 3.1146
2020-11-05 18:33:43,423 - root - INFO - Evaluate: Epoch 0980 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:33:43,430 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6935 | Iter Mean Loss 4.6935
2020-11-05 18:33:43,438 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1447 | Iter Mean Loss 2.9191
2020-11-05 18:33:43,445 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1592 | Iter Mean Loss 3.3325
2020-11-05 18:33:43,452 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5584 | Iter Mean Loss 3.3890
2020-11-05 18:33:43,459 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9988 | Iter Mean Loss 3.1109
2020-11-05 18:33:43,461 - root - INFO - Evaluate: Epoch 0981 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:33:43,469 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6892 | Iter Mean Loss 4.6892
2020-11-05 18:33:43,476 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1430 | Iter Mean Loss 2.9161
2020-11-05 18:33:43,483 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1542 | Iter Mean Loss 3.3288
2020-11-05 18:33:43,490 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5542 | Iter Mean Loss 3.3851
2020-11-05 18:33:43,498 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9959 | Iter Mean Loss 3.1073
2020-11-05 18:33:43,500 - root - INFO - Evaluate: Epoch 0982 | NDCG 0.2817 | MSE 0.3284
2020-11-05 18:33:43,508 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6848 | Iter Mean Loss 4.6848
2020-11-05 18:33:43,516 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1412 | Iter Mean Loss 2.9130
2020-11-05 18:33:43,523 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1492 | Iter Mean Loss 3.3251
2020-11-05 18:33:43,530 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5500 | Iter Mean Loss 3.3813
2020-11-05 18:33:43,538 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9929 | Iter Mean Loss 3.1036
2020-11-05 18:33:43,540 - root - INFO - Evaluate: Epoch 0983 | NDCG 0.2817 | MSE 0.3285
2020-11-05 18:33:43,549 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6805 | Iter Mean Loss 4.6805
2020-11-05 18:33:43,557 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1395 | Iter Mean Loss 2.9100
2020-11-05 18:33:43,564 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1442 | Iter Mean Loss 3.3214
2020-11-05 18:33:43,572 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5458 | Iter Mean Loss 3.3775
2020-11-05 18:33:43,580 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9900 | Iter Mean Loss 3.1000
2020-11-05 18:33:43,582 - root - INFO - Evaluate: Epoch 0984 | NDCG 0.2817 | MSE 0.3285
2020-11-05 18:33:43,591 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6761 | Iter Mean Loss 4.6761
2020-11-05 18:33:43,598 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1377 | Iter Mean Loss 2.9069
2020-11-05 18:33:43,607 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1392 | Iter Mean Loss 3.3177
2020-11-05 18:33:43,614 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5415 | Iter Mean Loss 3.3736
2020-11-05 18:33:43,622 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9870 | Iter Mean Loss 3.0963
2020-11-05 18:33:43,624 - root - INFO - Evaluate: Epoch 0985 | NDCG 0.2817 | MSE 0.3286
2020-11-05 18:33:43,632 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6716 | Iter Mean Loss 4.6716
2020-11-05 18:33:43,639 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1359 | Iter Mean Loss 2.9038
2020-11-05 18:33:43,646 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1342 | Iter Mean Loss 3.3139
2020-11-05 18:33:43,653 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5373 | Iter Mean Loss 3.3698
2020-11-05 18:33:43,660 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9841 | Iter Mean Loss 3.0926
2020-11-05 18:33:43,662 - root - INFO - Evaluate: Epoch 0986 | NDCG 0.2817 | MSE 0.3286
2020-11-05 18:33:43,670 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6672 | Iter Mean Loss 4.6672
2020-11-05 18:33:43,678 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1342 | Iter Mean Loss 2.9007
2020-11-05 18:33:43,685 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1292 | Iter Mean Loss 3.3102
2020-11-05 18:33:43,692 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5331 | Iter Mean Loss 3.3659
2020-11-05 18:33:43,699 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9811 | Iter Mean Loss 3.0889
2020-11-05 18:33:43,701 - root - INFO - Evaluate: Epoch 0987 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:33:43,710 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6627 | Iter Mean Loss 4.6627
2020-11-05 18:33:43,717 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1324 | Iter Mean Loss 2.8975
2020-11-05 18:33:43,725 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1242 | Iter Mean Loss 3.3064
2020-11-05 18:33:43,733 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5289 | Iter Mean Loss 3.3620
2020-11-05 18:33:43,740 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9781 | Iter Mean Loss 3.0853
2020-11-05 18:33:43,742 - root - INFO - Evaluate: Epoch 0988 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:33:43,751 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6582 | Iter Mean Loss 4.6582
2020-11-05 18:33:43,759 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1306 | Iter Mean Loss 2.8944
2020-11-05 18:33:43,767 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1192 | Iter Mean Loss 3.3027
2020-11-05 18:33:43,775 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5246 | Iter Mean Loss 3.3582
2020-11-05 18:33:43,782 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9752 | Iter Mean Loss 3.0816
2020-11-05 18:33:43,785 - root - INFO - Evaluate: Epoch 0989 | NDCG 0.2817 | MSE 0.3287
2020-11-05 18:33:43,794 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6537 | Iter Mean Loss 4.6537
2020-11-05 18:33:43,802 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1288 | Iter Mean Loss 2.8912
2020-11-05 18:33:43,810 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1142 | Iter Mean Loss 3.2989
2020-11-05 18:33:43,817 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5204 | Iter Mean Loss 3.3543
2020-11-05 18:33:43,825 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9722 | Iter Mean Loss 3.0779
2020-11-05 18:33:43,827 - root - INFO - Evaluate: Epoch 0990 | NDCG 0.2817 | MSE 0.3288
2020-11-05 18:33:43,835 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6491 | Iter Mean Loss 4.6491
2020-11-05 18:33:43,842 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1270 | Iter Mean Loss 2.8881
2020-11-05 18:33:43,849 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 3.2951
2020-11-05 18:33:43,856 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5162 | Iter Mean Loss 3.3504
2020-11-05 18:33:43,863 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9692 | Iter Mean Loss 3.0741
2020-11-05 18:33:43,865 - root - INFO - Evaluate: Epoch 0991 | NDCG 0.2817 | MSE 0.3288
2020-11-05 18:33:43,873 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6446 | Iter Mean Loss 4.6446
2020-11-05 18:33:43,880 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1252 | Iter Mean Loss 2.8849
2020-11-05 18:33:43,887 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.1042 | Iter Mean Loss 3.2913
2020-11-05 18:33:43,895 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5120 | Iter Mean Loss 3.3465
2020-11-05 18:33:43,903 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9662 | Iter Mean Loss 3.0704
2020-11-05 18:33:43,905 - root - INFO - Evaluate: Epoch 0992 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:33:43,913 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6400 | Iter Mean Loss 4.6400
2020-11-05 18:33:43,921 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1234 | Iter Mean Loss 2.8817
2020-11-05 18:33:43,928 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0991 | Iter Mean Loss 3.2875
2020-11-05 18:33:43,937 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5077 | Iter Mean Loss 3.3425
2020-11-05 18:33:43,944 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9633 | Iter Mean Loss 3.0667
2020-11-05 18:33:43,946 - root - INFO - Evaluate: Epoch 0993 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:33:43,955 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6353 | Iter Mean Loss 4.6353
2020-11-05 18:33:43,962 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1215 | Iter Mean Loss 2.8784
2020-11-05 18:33:43,971 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0941 | Iter Mean Loss 3.2837
2020-11-05 18:33:43,978 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.5035 | Iter Mean Loss 3.3386
2020-11-05 18:33:43,986 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9603 | Iter Mean Loss 3.0629
2020-11-05 18:33:43,989 - root - INFO - Evaluate: Epoch 0994 | NDCG 0.2817 | MSE 0.3289
2020-11-05 18:33:43,997 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6307 | Iter Mean Loss 4.6307
2020-11-05 18:33:44,005 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1197 | Iter Mean Loss 2.8752
2020-11-05 18:33:44,012 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0891 | Iter Mean Loss 3.2798
2020-11-05 18:33:44,020 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4993 | Iter Mean Loss 3.3347
2020-11-05 18:33:44,028 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9573 | Iter Mean Loss 3.0592
2020-11-05 18:33:44,030 - root - INFO - Evaluate: Epoch 0995 | NDCG 0.2817 | MSE 0.3290
2020-11-05 18:33:44,038 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6260 | Iter Mean Loss 4.6260
2020-11-05 18:33:44,046 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1178 | Iter Mean Loss 2.8719
2020-11-05 18:33:44,053 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0841 | Iter Mean Loss 3.2760
2020-11-05 18:33:44,060 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4950 | Iter Mean Loss 3.3307
2020-11-05 18:33:44,067 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9543 | Iter Mean Loss 3.0555
2020-11-05 18:33:44,069 - root - INFO - Evaluate: Epoch 0996 | NDCG 0.2817 | MSE 0.3290
2020-11-05 18:33:44,077 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6213 | Iter Mean Loss 4.6213
2020-11-05 18:33:44,084 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1160 | Iter Mean Loss 2.8686
2020-11-05 18:33:44,091 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 3.2721
2020-11-05 18:33:44,098 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4908 | Iter Mean Loss 3.3268
2020-11-05 18:33:44,106 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9513 | Iter Mean Loss 3.0517
2020-11-05 18:33:44,108 - root - INFO - Evaluate: Epoch 0997 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:33:44,117 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6166 | Iter Mean Loss 4.6166
2020-11-05 18:33:44,124 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1141 | Iter Mean Loss 2.8653
2020-11-05 18:33:44,132 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0741 | Iter Mean Loss 3.2683
2020-11-05 18:33:44,140 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4866 | Iter Mean Loss 3.3228
2020-11-05 18:33:44,147 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9483 | Iter Mean Loss 3.0479
2020-11-05 18:33:44,150 - root - INFO - Evaluate: Epoch 0998 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:33:44,158 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 4.6118 | Iter Mean Loss 4.6118
2020-11-05 18:33:44,166 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1123 | Iter Mean Loss 2.8620
2020-11-05 18:33:44,174 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 4.0691 | Iter Mean Loss 3.2644
2020-11-05 18:33:44,182 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 3.4824 | Iter Mean Loss 3.3189
2020-11-05 18:33:44,189 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 1.9452 | Iter Mean Loss 3.0441
2020-11-05 18:33:44,192 - root - INFO - Evaluate: Epoch 0999 | NDCG 0.2817 | MSE 0.3291
2020-11-05 18:33:44,192 - root - INFO - [!]-----------training done.
2020-11-05 18:33:44,313 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 18:33:44,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,313 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,314 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 18:33:44,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 18:33:44,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 18:33:44,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 18:33:44,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 18:33:44,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,348 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,349 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,350 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,351 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,352 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,353 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,354 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 18:33:44,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 18:33:44,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,384 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,385 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 18:33:44,386 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,387 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,388 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,389 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,390 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,391 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,392 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 18:33:44,393 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 18:33:44,616 - root - INFO - [!]-----------start testing.
2020-11-05 18:33:44,618 - root - INFO - Real Rank:
2020-11-05 18:33:44,618 - root - INFO - [116 142]
2020-11-05 18:33:44,619 - root - INFO - Pred Rank:
2020-11-05 18:33:44,619 - root - INFO - [142  91 116 135]
