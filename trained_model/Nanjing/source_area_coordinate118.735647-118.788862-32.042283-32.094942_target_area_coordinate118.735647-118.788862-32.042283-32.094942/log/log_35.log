2020-10-29 15:29:50,342 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, city_name='Nanjing', data_dir='datasets/', enterprise=['luckin coffee瑞幸咖啡', 'CoCo都可', '星巴克'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=10000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.735647-118.788862-32.042283-32.094942_target_area_coordinate118.735647-118.788862-32.042283-32.094942/', seed=981125, source_area_coordinate=[118.735647, 118.788862, 32.042283, 32.094942], stopping_steps=10, target_area_coordinate=[118.771352, 118.823537, 32.013759, 32.060615], target_enterprise='luckin coffee瑞幸咖啡')
2020-10-29 15:29:50,342 - root - INFO - --------------parse args and init done.
2020-10-29 15:29:53,393 - root - INFO - [1 /10]       load dianping data done.
2020-10-29 15:29:53,414 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-10-29 15:29:53,414 - root - INFO - n_source_grid: 100, n_target_grid: 90
2020-10-29 15:29:53,414 - root - INFO - [3 /10]       split grid done.
2020-10-29 15:29:54,047 - root - INFO - [4 /10]       distribute data into grids done.
2020-10-29 15:29:54,735 - root - INFO - [8 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-10-29 15:29:54,927 - root - INFO - [5 /10]       extract geographic features done.
2020-10-29 15:29:55,077 - root - INFO - [6 /10]       extract commercial features done.
2020-10-29 15:29:55,078 - root - INFO - [7 /10]       combine features done.
2020-10-29 15:29:55,154 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-10-29 15:29:55,155 - root - INFO - [10/10]       generate training and testing index done.
2020-10-29 15:29:55,183 - root - INFO - --------------load data done.
2020-10-29 15:29:55,186 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-10-29 15:29:55,188 - root - INFO - --------------construct model and optimizer done.
2020-10-29 15:29:55,188 - root - INFO - --------------initialize metrics done.
2020-10-29 15:29:55,188 - root - INFO - [!]-----------start training.
2020-10-29 15:29:55,202 - root - INFO - Training: Epoch 0000 / 10000 | Iter 0000 / 0003 | Time 0.0s | Iter Loss 1539.8765 | Iter Mean Loss 1539.8765
2020-10-29 15:29:55,215 - root - INFO - Training: Epoch 0000 / 10000 | Iter 0001 / 0003 | Time 0.0s | Iter Loss 1321.6040 | Iter Mean Loss 1430.7402
2020-10-29 15:29:55,228 - root - INFO - Training: Epoch 0000 / 10000 | Iter 0002 / 0003 | Time 0.0s | Iter Loss 884.9208 | Iter Mean Loss 1248.8004
2020-10-29 15:29:55,239 - root - INFO - Training: Epoch 0000 / 10000 | Iter 0003 / 0003 | Time 0.0s | Iter Loss 781.8014 | Iter Mean Loss 1132.0507
