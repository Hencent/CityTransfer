2020-11-05 16:36:09,759 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.757457-118.80123-31.975167-32.072533_target_area_coordinate118.757457-118.80123-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], target_enterprise='西西弗书店')
2020-11-05 16:36:09,759 - root - INFO - --------------parse args and init done.
2020-11-05 16:36:11,574 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 16:36:11,586 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 16:36:11,586 - root - INFO - n_source_grid: 152, n_target_grid: 95
2020-11-05 16:36:11,586 - root - INFO - [3 /10]       split grid done.
2020-11-05 16:36:12,404 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 16:36:12,407 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 16:36:12,468 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 16:36:12,545 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 16:36:12,545 - root - INFO - [8 /10]       combine features done.
2020-11-05 16:36:12,596 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 16:36:12,596 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 16:36:12,639 - root - INFO - --------------load data done.
2020-11-05 16:36:12,640 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 16:36:12,640 - root - INFO - --------------construct model and optimizer done.
2020-11-05 16:36:12,641 - root - INFO - --------------initialize metrics done.
2020-11-05 16:36:12,641 - root - INFO - [!]-----------start training.
2020-11-05 16:36:12,648 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 643.9380 | Iter Mean Loss 643.9380
2020-11-05 16:36:12,653 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 554.1745 | Iter Mean Loss 599.0563
2020-11-05 16:36:12,660 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 579.2756 | Iter Mean Loss 592.4627
2020-11-05 16:36:12,666 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 532.0728 | Iter Mean Loss 577.3652
2020-11-05 16:36:12,671 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 241.1393 | Iter Mean Loss 510.1201
2020-11-05 16:36:12,673 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.7708
2020-11-05 16:36:12,679 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 511.6739 | Iter Mean Loss 511.6739
2020-11-05 16:36:12,684 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 431.3048 | Iter Mean Loss 471.4893
2020-11-05 16:36:12,690 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 463.4146 | Iter Mean Loss 468.7978
2020-11-05 16:36:12,697 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 419.4186 | Iter Mean Loss 456.4530
2020-11-05 16:36:12,703 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 182.3454 | Iter Mean Loss 401.6315
2020-11-05 16:36:12,704 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.7723
2020-11-05 16:36:12,710 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 410.9805 | Iter Mean Loss 410.9805
2020-11-05 16:36:12,716 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 337.3170 | Iter Mean Loss 374.1487
2020-11-05 16:36:12,722 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 374.8981 | Iter Mean Loss 374.3985
2020-11-05 16:36:12,728 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 334.1434 | Iter Mean Loss 364.3347
2020-11-05 16:36:12,733 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 138.3126 | Iter Mean Loss 319.1303
2020-11-05 16:36:12,734 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.7636
2020-11-05 16:36:12,739 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 334.9843 | Iter Mean Loss 334.9843
2020-11-05 16:36:12,745 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 266.4191 | Iter Mean Loss 300.7017
2020-11-05 16:36:12,751 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 308.5126 | Iter Mean Loss 303.3053
2020-11-05 16:36:12,757 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 271.0077 | Iter Mean Loss 295.2309
2020-11-05 16:36:12,762 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 106.2549 | Iter Mean Loss 257.4357
2020-11-05 16:36:12,763 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.7419
2020-11-05 16:36:12,769 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 279.1161 | Iter Mean Loss 279.1161
2020-11-05 16:36:12,775 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 214.3517 | Iter Mean Loss 246.7339
2020-11-05 16:36:12,781 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.0327 | Iter Mean Loss 251.1668
2020-11-05 16:36:12,786 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 225.4976 | Iter Mean Loss 244.7495
2020-11-05 16:36:12,791 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 83.6608 | Iter Mean Loss 212.5318
2020-11-05 16:36:12,792 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.7064
2020-11-05 16:36:12,798 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 239.1345 | Iter Mean Loss 239.1345
2020-11-05 16:36:12,804 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 177.0773 | Iter Mean Loss 208.1059
2020-11-05 16:36:12,810 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 225.4448 | Iter Mean Loss 213.8855
2020-11-05 16:36:12,816 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 193.4189 | Iter Mean Loss 208.7689
2020-11-05 16:36:12,822 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 68.1921 | Iter Mean Loss 180.6535
2020-11-05 16:36:12,823 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6605
2020-11-05 16:36:12,829 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 211.0698 | Iter Mean Loss 211.0698
2020-11-05 16:36:12,835 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 150.8522 | Iter Mean Loss 180.9610
2020-11-05 16:36:12,841 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 201.0768 | Iter Mean Loss 187.6662
2020-11-05 16:36:12,847 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 171.0199 | Iter Mean Loss 183.5047
2020-11-05 16:36:12,852 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 57.7462 | Iter Mean Loss 158.3530
2020-11-05 16:36:12,854 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.6101
2020-11-05 16:36:12,860 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 191.3755 | Iter Mean Loss 191.3755
2020-11-05 16:36:12,866 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 132.3766 | Iter Mean Loss 161.8760
2020-11-05 16:36:12,873 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 183.7166 | Iter Mean Loss 169.1562
2020-11-05 16:36:12,879 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 155.0656 | Iter Mean Loss 165.6336
2020-11-05 16:36:12,885 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 50.5262 | Iter Mean Loss 142.6121
2020-11-05 16:36:12,887 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5603
2020-11-05 16:36:12,893 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 177.0382 | Iter Mean Loss 177.0382
2020-11-05 16:36:12,899 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 118.8886 | Iter Mean Loss 147.9634
2020-11-05 16:36:12,906 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 170.7194 | Iter Mean Loss 155.5487
2020-11-05 16:36:12,912 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 142.9588 | Iter Mean Loss 152.4012
2020-11-05 16:36:12,918 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.1404 | Iter Mean Loss 130.9491
2020-11-05 16:36:12,920 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5136
2020-11-05 16:36:12,926 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7476 | Iter Mean Loss 165.7476
2020-11-05 16:36:12,932 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.3027 | Iter Mean Loss 137.0251
2020-11-05 16:36:12,939 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 160.1558 | Iter Mean Loss 144.7353
2020-11-05 16:36:12,945 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 132.8874 | Iter Mean Loss 141.7734
2020-11-05 16:36:12,950 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.6723 | Iter Mean Loss 121.5531
2020-11-05 16:36:12,951 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.4711
2020-11-05 16:36:12,957 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 156.0084 | Iter Mean Loss 156.0084
2020-11-05 16:36:12,963 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 99.2784 | Iter Mean Loss 127.6434
2020-11-05 16:36:12,968 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 150.8555 | Iter Mean Loss 135.3808
2020-11-05 16:36:12,974 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 123.8219 | Iter Mean Loss 132.4910
2020-11-05 16:36:12,979 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6481 | Iter Mean Loss 113.3225
2020-11-05 16:36:12,980 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.4333
2020-11-05 16:36:12,986 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 147.0691 | Iter Mean Loss 147.0691
2020-11-05 16:36:12,992 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 91.1313 | Iter Mean Loss 119.1002
2020-11-05 16:36:12,997 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 142.2802 | Iter Mean Loss 126.8269
2020-11-05 16:36:13,004 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 115.3421 | Iter Mean Loss 123.9557
2020-11-05 16:36:13,011 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9139 | Iter Mean Loss 105.7473
2020-11-05 16:36:13,012 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.4003
2020-11-05 16:36:13,018 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 138.6974 | Iter Mean Loss 138.6974
2020-11-05 16:36:13,024 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 83.6236 | Iter Mean Loss 111.1605
2020-11-05 16:36:13,030 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.2894 | Iter Mean Loss 118.8701
2020-11-05 16:36:13,036 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 107.3825 | Iter Mean Loss 115.9982
2020-11-05 16:36:13,041 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4813 | Iter Mean Loss 98.6949
2020-11-05 16:36:13,042 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.3717
2020-11-05 16:36:13,048 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 130.9130 | Iter Mean Loss 130.9130
2020-11-05 16:36:13,055 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 76.7316 | Iter Mean Loss 103.8223
2020-11-05 16:36:13,061 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 126.9098 | Iter Mean Loss 111.5181
2020-11-05 16:36:13,067 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.0092 | Iter Mean Loss 108.6409
2020-11-05 16:36:13,072 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.4081 | Iter Mean Loss 92.1943
2020-11-05 16:36:13,074 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.3468
2020-11-05 16:36:13,080 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 123.7932 | Iter Mean Loss 123.7932
2020-11-05 16:36:13,086 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 70.4852 | Iter Mean Loss 97.1392
2020-11-05 16:36:13,092 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 120.1906 | Iter Mean Loss 104.8230
2020-11-05 16:36:13,098 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.2886 | Iter Mean Loss 101.9394
2020-11-05 16:36:13,104 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.7358 | Iter Mean Loss 86.2987
2020-11-05 16:36:13,105 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.3250
2020-11-05 16:36:13,111 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 117.3771 | Iter Mean Loss 117.3771
2020-11-05 16:36:13,117 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 64.8879 | Iter Mean Loss 91.1325
2020-11-05 16:36:13,125 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 114.1380 | Iter Mean Loss 98.8010
2020-11-05 16:36:13,131 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.2338 | Iter Mean Loss 95.9092
2020-11-05 16:36:13,137 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.4668 | Iter Mean Loss 81.0207
2020-11-05 16:36:13,138 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.3059
2020-11-05 16:36:13,144 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 111.6401 | Iter Mean Loss 111.6401
2020-11-05 16:36:13,150 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 59.8938 | Iter Mean Loss 85.7670
2020-11-05 16:36:13,157 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 108.7037 | Iter Mean Loss 93.4126
2020-11-05 16:36:13,162 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.8012 | Iter Mean Loss 90.5097
2020-11-05 16:36:13,167 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5673 | Iter Mean Loss 76.3212
2020-11-05 16:36:13,168 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.2894
2020-11-05 16:36:13,174 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 106.5119 | Iter Mean Loss 106.5119
2020-11-05 16:36:13,180 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 55.4229 | Iter Mean Loss 80.9674
2020-11-05 16:36:13,186 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 103.8075 | Iter Mean Loss 88.5808
2020-11-05 16:36:13,192 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.9157 | Iter Mean Loss 85.6645
2020-11-05 16:36:13,197 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9821 | Iter Mean Loss 72.1280
2020-11-05 16:36:13,197 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.2754
2020-11-05 16:36:13,203 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 101.9071 | Iter Mean Loss 101.9071
2020-11-05 16:36:13,209 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 51.3878 | Iter Mean Loss 76.6475
2020-11-05 16:36:13,215 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 99.3647 | Iter Mean Loss 84.2199
2020-11-05 16:36:13,220 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 72.4984 | Iter Mean Loss 81.2895
2020-11-05 16:36:13,225 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6518 | Iter Mean Loss 68.3620
2020-11-05 16:36:13,226 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.2639
2020-11-05 16:36:13,232 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 97.7487 | Iter Mean Loss 97.7487
2020-11-05 16:36:13,238 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 47.7147 | Iter Mean Loss 72.7317
2020-11-05 16:36:13,244 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 95.3059 | Iter Mean Loss 80.2564
2020-11-05 16:36:13,250 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 68.4840 | Iter Mean Loss 77.3133
2020-11-05 16:36:13,255 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5229 | Iter Mean Loss 64.9552
2020-11-05 16:36:13,257 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.2548
2020-11-05 16:36:13,263 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 93.9776 | Iter Mean Loss 93.9776
2020-11-05 16:36:13,269 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.3514 | Iter Mean Loss 69.1645
2020-11-05 16:36:13,275 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 91.5825 | Iter Mean Loss 76.6371
2020-11-05 16:36:13,281 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 64.8261 | Iter Mean Loss 73.6844
2020-11-05 16:36:13,287 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5525 | Iter Mean Loss 61.8580
2020-11-05 16:36:13,288 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.2477
2020-11-05 16:36:13,295 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 90.5528 | Iter Mean Loss 90.5528
2020-11-05 16:36:13,301 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2657 | Iter Mean Loss 65.9093
2020-11-05 16:36:13,308 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 88.1655 | Iter Mean Loss 73.3280
2020-11-05 16:36:13,314 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 61.4953 | Iter Mean Loss 70.3699
2020-11-05 16:36:13,320 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7088 | Iter Mean Loss 59.0376
2020-11-05 16:36:13,322 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.2424
2020-11-05 16:36:13,329 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 87.4472 | Iter Mean Loss 87.4472
2020-11-05 16:36:13,334 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.4413 | Iter Mean Loss 62.9443
2020-11-05 16:36:13,340 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 85.0399 | Iter Mean Loss 70.3095
2020-11-05 16:36:13,347 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 58.4751 | Iter Mean Loss 67.3509
2020-11-05 16:36:13,352 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9689 | Iter Mean Loss 56.4745
2020-11-05 16:36:13,353 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.2384
2020-11-05 16:36:13,359 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 84.6424 | Iter Mean Loss 84.6424
2020-11-05 16:36:13,364 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.8719 | Iter Mean Loss 60.2571
2020-11-05 16:36:13,370 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 82.1986 | Iter Mean Loss 67.5710
2020-11-05 16:36:13,376 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 55.7555 | Iter Mean Loss 64.6171
2020-11-05 16:36:13,381 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3177 | Iter Mean Loss 54.1572
2020-11-05 16:36:13,381 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.2356
2020-11-05 16:36:13,387 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 82.1243 | Iter Mean Loss 82.1243
2020-11-05 16:36:13,393 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 33.5564 | Iter Mean Loss 57.8403
2020-11-05 16:36:13,399 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 79.6385 | Iter Mean Loss 65.1064
2020-11-05 16:36:13,404 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 53.3303 | Iter Mean Loss 62.1624
2020-11-05 16:36:13,409 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7450 | Iter Mean Loss 52.0789
2020-11-05 16:36:13,410 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.2336
2020-11-05 16:36:13,416 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 79.8810 | Iter Mean Loss 79.8810
2020-11-05 16:36:13,421 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 31.4944 | Iter Mean Loss 55.6877
2020-11-05 16:36:13,427 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.3565 | Iter Mean Loss 62.9106
2020-11-05 16:36:13,433 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.1936 | Iter Mean Loss 59.9814
2020-11-05 16:36:13,437 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2443 | Iter Mean Loss 50.2340
2020-11-05 16:36:13,439 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.2323
2020-11-05 16:36:13,445 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 77.9003 | Iter Mean Loss 77.9003
2020-11-05 16:36:13,451 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 29.6825 | Iter Mean Loss 53.7914
2020-11-05 16:36:13,457 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 75.3467 | Iter Mean Loss 60.9765
2020-11-05 16:36:13,464 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.3369 | Iter Mean Loss 58.0666
2020-11-05 16:36:13,469 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 48.6154
2020-11-05 16:36:13,470 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.2314
2020-11-05 16:36:13,477 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 76.1683 | Iter Mean Loss 76.1683
2020-11-05 16:36:13,483 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.1123 | Iter Mean Loss 52.1403
2020-11-05 16:36:13,489 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 73.5987 | Iter Mean Loss 59.2931
2020-11-05 16:36:13,495 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.7475 | Iter Mean Loss 56.4067
2020-11-05 16:36:13,501 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4397 | Iter Mean Loss 47.2133
2020-11-05 16:36:13,501 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.2309
2020-11-05 16:36:13,508 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.6678 | Iter Mean Loss 74.6678
2020-11-05 16:36:13,515 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.7700 | Iter Mean Loss 50.7189
2020-11-05 16:36:13,520 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.0968 | Iter Mean Loss 57.8449
2020-11-05 16:36:13,527 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 46.4071 | Iter Mean Loss 54.9854
2020-11-05 16:36:13,532 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1260 | Iter Mean Loss 46.0135
2020-11-05 16:36:13,533 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.2306
2020-11-05 16:36:13,539 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 73.3779 | Iter Mean Loss 73.3779
2020-11-05 16:36:13,545 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.6369 | Iter Mean Loss 49.5074
2020-11-05 16:36:13,551 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 70.8200 | Iter Mean Loss 56.6116
2020-11-05 16:36:13,557 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.2932 | Iter Mean Loss 53.7820
2020-11-05 16:36:13,562 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8639 | Iter Mean Loss 44.9984
2020-11-05 16:36:13,563 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.2303
2020-11-05 16:36:13,568 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 72.2743 | Iter Mean Loss 72.2743
2020-11-05 16:36:13,574 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 24.6904 | Iter Mean Loss 48.4823
2020-11-05 16:36:13,580 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.7432 | Iter Mean Loss 55.5693
2020-11-05 16:36:13,585 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.3797 | Iter Mean Loss 52.7719
2020-11-05 16:36:13,590 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6470 | Iter Mean Loss 44.1469
2020-11-05 16:36:13,591 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.0000 | MSE 0.2302
2020-11-05 16:36:13,596 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 71.3311 | Iter Mean Loss 71.3311
2020-11-05 16:36:13,602 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.9057 | Iter Mean Loss 47.6184
2020-11-05 16:36:13,608 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 68.8392 | Iter Mean Loss 54.6920
2020-11-05 16:36:13,613 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.6388 | Iter Mean Loss 51.9287
2020-11-05 16:36:13,618 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4683 | Iter Mean Loss 43.4366
2020-11-05 16:36:13,619 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.0000 | MSE 0.2300
2020-11-05 16:36:13,625 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 70.5221 | Iter Mean Loss 70.5221
2020-11-05 16:36:13,630 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.2580 | Iter Mean Loss 46.8900
2020-11-05 16:36:13,636 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 68.0805 | Iter Mean Loss 53.9535
2020-11-05 16:36:13,641 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.0420 | Iter Mean Loss 51.2256
2020-11-05 16:36:13,646 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3212 | Iter Mean Loss 42.8447
2020-11-05 16:36:13,647 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:13,653 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 69.8223 | Iter Mean Loss 69.8223
2020-11-05 16:36:13,660 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7232 | Iter Mean Loss 46.2727
2020-11-05 16:36:13,666 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.4406 | Iter Mean Loss 53.3287
2020-11-05 16:36:13,672 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.5622 | Iter Mean Loss 50.6371
2020-11-05 16:36:13,678 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1993 | Iter Mean Loss 42.3495
2020-11-05 16:36:13,679 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:13,685 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 69.2097 | Iter Mean Loss 69.2097
2020-11-05 16:36:13,691 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.2793 | Iter Mean Loss 45.7445
2020-11-05 16:36:13,698 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.8954 | Iter Mean Loss 52.7948
2020-11-05 16:36:13,703 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1749 | Iter Mean Loss 50.1398
2020-11-05 16:36:13,710 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0968 | Iter Mean Loss 41.9312
2020-11-05 16:36:13,711 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:13,717 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.6652 | Iter Mean Loss 68.6652
2020-11-05 16:36:13,722 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.9074 | Iter Mean Loss 45.2863
2020-11-05 16:36:13,729 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.4241 | Iter Mean Loss 52.3322
2020-11-05 16:36:13,735 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.8588 | Iter Mean Loss 49.7139
2020-11-05 16:36:13,739 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0091 | Iter Mean Loss 41.5729
2020-11-05 16:36:13,740 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:13,746 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.1731 | Iter Mean Loss 68.1731
2020-11-05 16:36:13,752 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.5916 | Iter Mean Loss 44.8824
2020-11-05 16:36:13,758 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0090 | Iter Mean Loss 51.9246
2020-11-05 16:36:13,764 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.5962 | Iter Mean Loss 49.3425
2020-11-05 16:36:13,768 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9322 | Iter Mean Loss 41.2604
2020-11-05 16:36:13,769 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:13,775 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 67.7211 | Iter Mean Loss 67.7211
2020-11-05 16:36:13,780 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.3194 | Iter Mean Loss 44.5203
2020-11-05 16:36:13,786 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 65.6359 | Iter Mean Loss 51.5588
2020-11-05 16:36:13,791 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3730 | Iter Mean Loss 49.0124
2020-11-05 16:36:13,796 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8631 | Iter Mean Loss 40.9825
2020-11-05 16:36:13,797 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:36:13,803 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 67.2996 | Iter Mean Loss 67.2996
2020-11-05 16:36:13,808 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.0812 | Iter Mean Loss 44.1904
2020-11-05 16:36:13,814 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 65.2934 | Iter Mean Loss 51.2248
2020-11-05 16:36:13,820 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.1782 | Iter Mean Loss 48.7131
2020-11-05 16:36:13,825 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7994 | Iter Mean Loss 40.7304
2020-11-05 16:36:13,826 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:36:13,832 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.9013 | Iter Mean Loss 66.9013
2020-11-05 16:36:13,837 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.8694 | Iter Mean Loss 43.8854
2020-11-05 16:36:13,843 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.9730 | Iter Mean Loss 50.9146
2020-11-05 16:36:13,849 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.0034 | Iter Mean Loss 48.4368
2020-11-05 16:36:13,853 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7396 | Iter Mean Loss 40.4973
2020-11-05 16:36:13,854 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:36:13,861 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.5208 | Iter Mean Loss 66.5208
2020-11-05 16:36:13,867 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.6784 | Iter Mean Loss 43.5996
2020-11-05 16:36:13,872 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.6680 | Iter Mean Loss 50.6224
2020-11-05 16:36:13,878 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.8423 | Iter Mean Loss 48.1774
2020-11-05 16:36:13,883 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6824 | Iter Mean Loss 40.2784
2020-11-05 16:36:13,884 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:13,890 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.1540 | Iter Mean Loss 66.1540
2020-11-05 16:36:13,896 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5038 | Iter Mean Loss 43.3289
2020-11-05 16:36:13,903 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.3734 | Iter Mean Loss 50.3438
2020-11-05 16:36:13,908 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.6906 | Iter Mean Loss 47.9305
2020-11-05 16:36:13,914 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6270 | Iter Mean Loss 40.0698
2020-11-05 16:36:13,915 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:13,921 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.7979 | Iter Mean Loss 65.7979
2020-11-05 16:36:13,927 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.3423 | Iter Mean Loss 43.0701
2020-11-05 16:36:13,933 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.0856 | Iter Mean Loss 50.0753
2020-11-05 16:36:13,939 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.5450 | Iter Mean Loss 47.6927
2020-11-05 16:36:13,944 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5729 | Iter Mean Loss 39.8687
2020-11-05 16:36:13,945 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:13,951 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.4502 | Iter Mean Loss 65.4502
2020-11-05 16:36:13,957 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1910 | Iter Mean Loss 42.8206
2020-11-05 16:36:13,963 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.8018 | Iter Mean Loss 49.8143
2020-11-05 16:36:13,968 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.4031 | Iter Mean Loss 47.4615
2020-11-05 16:36:13,973 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5197 | Iter Mean Loss 39.6732
2020-11-05 16:36:13,974 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:13,979 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.1090 | Iter Mean Loss 65.1090
2020-11-05 16:36:13,985 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.0477 | Iter Mean Loss 42.5783
2020-11-05 16:36:13,990 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.5200 | Iter Mean Loss 49.5589
2020-11-05 16:36:13,996 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.2634 | Iter Mean Loss 47.2350
2020-11-05 16:36:14,001 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4670 | Iter Mean Loss 39.4814
2020-11-05 16:36:14,002 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:14,009 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.7725 | Iter Mean Loss 64.7725
2020-11-05 16:36:14,015 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.9105 | Iter Mean Loss 42.3415
2020-11-05 16:36:14,020 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2387 | Iter Mean Loss 49.3073
2020-11-05 16:36:14,027 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1246 | Iter Mean Loss 47.0116
2020-11-05 16:36:14,032 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4148 | Iter Mean Loss 39.2922
2020-11-05 16:36:14,033 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,038 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.4395 | Iter Mean Loss 64.4395
2020-11-05 16:36:14,043 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7780 | Iter Mean Loss 42.1087
2020-11-05 16:36:14,049 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.9569 | Iter Mean Loss 49.0581
2020-11-05 16:36:14,054 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.9860 | Iter Mean Loss 46.7901
2020-11-05 16:36:14,060 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3628 | Iter Mean Loss 39.1046
2020-11-05 16:36:14,062 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,067 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.1087 | Iter Mean Loss 64.1087
2020-11-05 16:36:14,073 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.6487 | Iter Mean Loss 41.8787
2020-11-05 16:36:14,079 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.6736 | Iter Mean Loss 48.8103
2020-11-05 16:36:14,085 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.8470 | Iter Mean Loss 46.5695
2020-11-05 16:36:14,090 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3109 | Iter Mean Loss 38.9178
2020-11-05 16:36:14,091 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,097 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.7791 | Iter Mean Loss 63.7791
2020-11-05 16:36:14,103 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.5214 | Iter Mean Loss 41.6503
2020-11-05 16:36:14,109 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.3885 | Iter Mean Loss 48.5630
2020-11-05 16:36:14,115 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7073 | Iter Mean Loss 46.3491
2020-11-05 16:36:14,120 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2590 | Iter Mean Loss 38.7311
2020-11-05 16:36:14,121 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,127 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.4499 | Iter Mean Loss 63.4499
2020-11-05 16:36:14,133 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.3953 | Iter Mean Loss 41.4226
2020-11-05 16:36:14,139 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.1010 | Iter Mean Loss 48.3154
2020-11-05 16:36:14,144 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.5663 | Iter Mean Loss 46.1281
2020-11-05 16:36:14,150 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2069 | Iter Mean Loss 38.5439
2020-11-05 16:36:14,151 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,157 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.1203 | Iter Mean Loss 63.1203
2020-11-05 16:36:14,162 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.2695 | Iter Mean Loss 41.1949
2020-11-05 16:36:14,168 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.8108 | Iter Mean Loss 48.0669
2020-11-05 16:36:14,173 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4241 | Iter Mean Loss 45.9062
2020-11-05 16:36:14,178 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1544 | Iter Mean Loss 38.3558
2020-11-05 16:36:14,179 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,184 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.7896 | Iter Mean Loss 62.7896
2020-11-05 16:36:14,190 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1433 | Iter Mean Loss 40.9664
2020-11-05 16:36:14,195 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.5176 | Iter Mean Loss 47.8168
2020-11-05 16:36:14,201 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.2802 | Iter Mean Loss 45.6827
2020-11-05 16:36:14,205 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1015 | Iter Mean Loss 38.1664
2020-11-05 16:36:14,206 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,212 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.4573 | Iter Mean Loss 62.4573
2020-11-05 16:36:14,217 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.0160 | Iter Mean Loss 40.7367
2020-11-05 16:36:14,223 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.2214 | Iter Mean Loss 47.5649
2020-11-05 16:36:14,228 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1347 | Iter Mean Loss 45.4573
2020-11-05 16:36:14,233 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0479 | Iter Mean Loss 37.9755
2020-11-05 16:36:14,233 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,239 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.1229 | Iter Mean Loss 62.1229
2020-11-05 16:36:14,244 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8872 | Iter Mean Loss 40.5050
2020-11-05 16:36:14,250 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.9218 | Iter Mean Loss 47.3106
2020-11-05 16:36:14,255 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.9873 | Iter Mean Loss 45.2298
2020-11-05 16:36:14,260 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9935 | Iter Mean Loss 37.7825
2020-11-05 16:36:14,262 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:36:14,267 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.7859 | Iter Mean Loss 61.7859
2020-11-05 16:36:14,273 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.7563 | Iter Mean Loss 40.2711
2020-11-05 16:36:14,279 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.6187 | Iter Mean Loss 47.0536
2020-11-05 16:36:14,285 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8379 | Iter Mean Loss 44.9997
2020-11-05 16:36:14,289 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9382 | Iter Mean Loss 37.5874
2020-11-05 16:36:14,290 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,297 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.4461 | Iter Mean Loss 61.4461
2020-11-05 16:36:14,302 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6228 | Iter Mean Loss 40.0345
2020-11-05 16:36:14,308 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.3120 | Iter Mean Loss 46.7937
2020-11-05 16:36:14,315 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6863 | Iter Mean Loss 44.7668
2020-11-05 16:36:14,321 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8817 | Iter Mean Loss 37.3898
2020-11-05 16:36:14,322 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,327 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.1030 | Iter Mean Loss 61.1030
2020-11-05 16:36:14,334 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.4865 | Iter Mean Loss 39.7948
2020-11-05 16:36:14,340 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.0015 | Iter Mean Loss 46.5304
2020-11-05 16:36:14,345 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.5324 | Iter Mean Loss 44.5309
2020-11-05 16:36:14,350 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8239 | Iter Mean Loss 37.1895
2020-11-05 16:36:14,352 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,358 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.7565 | Iter Mean Loss 60.7565
2020-11-05 16:36:14,364 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3470 | Iter Mean Loss 39.5517
2020-11-05 16:36:14,369 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.6871 | Iter Mean Loss 46.2635
2020-11-05 16:36:14,375 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.3761 | Iter Mean Loss 44.2917
2020-11-05 16:36:14,379 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7647 | Iter Mean Loss 36.9863
2020-11-05 16:36:14,380 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:36:14,386 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.4061 | Iter Mean Loss 60.4061
2020-11-05 16:36:14,391 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.2039 | Iter Mean Loss 39.3050
2020-11-05 16:36:14,396 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3685 | Iter Mean Loss 45.9928
2020-11-05 16:36:14,402 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2173 | Iter Mean Loss 44.0489
2020-11-05 16:36:14,407 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7039 | Iter Mean Loss 36.7799
2020-11-05 16:36:14,408 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:14,418 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.0517 | Iter Mean Loss 60.0517
2020-11-05 16:36:14,427 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0569 | Iter Mean Loss 39.0543
2020-11-05 16:36:14,434 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0457 | Iter Mean Loss 45.7181
2020-11-05 16:36:14,441 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0557 | Iter Mean Loss 43.8025
2020-11-05 16:36:14,446 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6415 | Iter Mean Loss 36.5703
2020-11-05 16:36:14,447 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:14,454 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.6931 | Iter Mean Loss 59.6931
2020-11-05 16:36:14,461 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.9057 | Iter Mean Loss 38.7994
2020-11-05 16:36:14,469 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7184 | Iter Mean Loss 45.4391
2020-11-05 16:36:14,474 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8912 | Iter Mean Loss 43.5521
2020-11-05 16:36:14,481 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5773 | Iter Mean Loss 36.3571
2020-11-05 16:36:14,482 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:14,489 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.3300 | Iter Mean Loss 59.3300
2020-11-05 16:36:14,496 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7502 | Iter Mean Loss 38.5401
2020-11-05 16:36:14,503 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.3865 | Iter Mean Loss 45.1556
2020-11-05 16:36:14,509 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.7237 | Iter Mean Loss 43.2976
2020-11-05 16:36:14,516 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5112 | Iter Mean Loss 36.1403
2020-11-05 16:36:14,517 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:36:14,524 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.9623 | Iter Mean Loss 58.9623
2020-11-05 16:36:14,532 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5899 | Iter Mean Loss 38.2761
2020-11-05 16:36:14,539 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.0499 | Iter Mean Loss 44.8674
2020-11-05 16:36:14,547 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.5531 | Iter Mean Loss 43.0388
2020-11-05 16:36:14,552 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4430 | Iter Mean Loss 35.9197
2020-11-05 16:36:14,555 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,561 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.5898 | Iter Mean Loss 58.5898
2020-11-05 16:36:14,568 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4247 | Iter Mean Loss 38.0072
2020-11-05 16:36:14,576 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.7084 | Iter Mean Loss 44.5743
2020-11-05 16:36:14,583 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.3792 | Iter Mean Loss 42.7755
2020-11-05 16:36:14,589 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3729 | Iter Mean Loss 35.6950
2020-11-05 16:36:14,590 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,597 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.2123 | Iter Mean Loss 58.2123
2020-11-05 16:36:14,604 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.2544 | Iter Mean Loss 37.7334
2020-11-05 16:36:14,610 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3620 | Iter Mean Loss 44.2762
2020-11-05 16:36:14,615 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2020 | Iter Mean Loss 42.5077
2020-11-05 16:36:14,620 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3006 | Iter Mean Loss 35.4662
2020-11-05 16:36:14,621 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,626 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.8298 | Iter Mean Loss 57.8298
2020-11-05 16:36:14,632 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0788 | Iter Mean Loss 37.4543
2020-11-05 16:36:14,637 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.0104 | Iter Mean Loss 43.9730
2020-11-05 16:36:14,642 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0212 | Iter Mean Loss 42.2350
2020-11-05 16:36:14,647 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2261 | Iter Mean Loss 35.2332
2020-11-05 16:36:14,648 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,653 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.4421 | Iter Mean Loss 57.4421
2020-11-05 16:36:14,659 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.8977 | Iter Mean Loss 37.1699
2020-11-05 16:36:14,665 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.6537 | Iter Mean Loss 43.6645
2020-11-05 16:36:14,671 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.8368 | Iter Mean Loss 41.9576
2020-11-05 16:36:14,676 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1494 | Iter Mean Loss 34.9959
2020-11-05 16:36:14,677 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,682 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.0492 | Iter Mean Loss 57.0492
2020-11-05 16:36:14,688 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7109 | Iter Mean Loss 36.8801
2020-11-05 16:36:14,695 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.2917 | Iter Mean Loss 43.3506
2020-11-05 16:36:14,701 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.6487 | Iter Mean Loss 41.6751
2020-11-05 16:36:14,707 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0706 | Iter Mean Loss 34.7542
2020-11-05 16:36:14,709 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:14,714 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 56.6509 | Iter Mean Loss 56.6509
2020-11-05 16:36:14,720 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.5185 | Iter Mean Loss 36.5847
2020-11-05 16:36:14,726 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.9245 | Iter Mean Loss 43.0313
2020-11-05 16:36:14,732 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.4568 | Iter Mean Loss 41.3877
2020-11-05 16:36:14,737 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9895 | Iter Mean Loss 34.5081
2020-11-05 16:36:14,738 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,744 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 56.2474 | Iter Mean Loss 56.2474
2020-11-05 16:36:14,749 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.3203 | Iter Mean Loss 36.2838
2020-11-05 16:36:14,755 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.5521 | Iter Mean Loss 42.7066
2020-11-05 16:36:14,761 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.2611 | Iter Mean Loss 41.0952
2020-11-05 16:36:14,766 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9063 | Iter Mean Loss 34.2574
2020-11-05 16:36:14,767 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,772 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.8385 | Iter Mean Loss 55.8385
2020-11-05 16:36:14,778 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1162 | Iter Mean Loss 35.9773
2020-11-05 16:36:14,783 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.1745 | Iter Mean Loss 42.3764
2020-11-05 16:36:14,788 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.0617 | Iter Mean Loss 40.7977
2020-11-05 16:36:14,793 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8209 | Iter Mean Loss 34.0023
2020-11-05 16:36:14,794 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,799 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.4243 | Iter Mean Loss 55.4243
2020-11-05 16:36:14,805 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9063 | Iter Mean Loss 35.6653
2020-11-05 16:36:14,810 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.7917 | Iter Mean Loss 42.0408
2020-11-05 16:36:14,815 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.8583 | Iter Mean Loss 40.4952
2020-11-05 16:36:14,821 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7335 | Iter Mean Loss 33.7428
2020-11-05 16:36:14,822 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,828 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.0050 | Iter Mean Loss 55.0050
2020-11-05 16:36:14,833 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.6907 | Iter Mean Loss 35.3478
2020-11-05 16:36:14,838 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.4040 | Iter Mean Loss 41.6999
2020-11-05 16:36:14,844 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.6512 | Iter Mean Loss 40.1877
2020-11-05 16:36:14,848 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6441 | Iter Mean Loss 33.4790
2020-11-05 16:36:14,849 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,855 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 54.5805 | Iter Mean Loss 54.5805
2020-11-05 16:36:14,860 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4695 | Iter Mean Loss 35.0250
2020-11-05 16:36:14,866 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0115 | Iter Mean Loss 41.3538
2020-11-05 16:36:14,872 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.4404 | Iter Mean Loss 39.8755
2020-11-05 16:36:14,878 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5530 | Iter Mean Loss 33.2110
2020-11-05 16:36:14,879 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,884 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 54.1511 | Iter Mean Loss 54.1511
2020-11-05 16:36:14,891 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2428 | Iter Mean Loss 34.6969
2020-11-05 16:36:14,897 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.6144 | Iter Mean Loss 41.0028
2020-11-05 16:36:14,902 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.2259 | Iter Mean Loss 39.5585
2020-11-05 16:36:14,908 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4602 | Iter Mean Loss 32.9389
2020-11-05 16:36:14,909 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,915 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 53.7169 | Iter Mean Loss 53.7169
2020-11-05 16:36:14,921 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.0108 | Iter Mean Loss 34.3639
2020-11-05 16:36:14,927 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.2131 | Iter Mean Loss 40.6469
2020-11-05 16:36:14,933 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0080 | Iter Mean Loss 39.2372
2020-11-05 16:36:14,939 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3659 | Iter Mean Loss 32.6629
2020-11-05 16:36:14,940 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,946 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 53.2782 | Iter Mean Loss 53.2782
2020-11-05 16:36:14,952 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7740 | Iter Mean Loss 34.0261
2020-11-05 16:36:14,959 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.8078 | Iter Mean Loss 40.2867
2020-11-05 16:36:14,964 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.7867 | Iter Mean Loss 38.9117
2020-11-05 16:36:14,969 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2705 | Iter Mean Loss 32.3834
2020-11-05 16:36:14,971 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:14,977 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 52.8352 | Iter Mean Loss 52.8352
2020-11-05 16:36:14,983 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5326 | Iter Mean Loss 33.6839
2020-11-05 16:36:14,989 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.3990 | Iter Mean Loss 39.9223
2020-11-05 16:36:14,994 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.5624 | Iter Mean Loss 38.5823
2020-11-05 16:36:14,999 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1741 | Iter Mean Loss 32.1006
2020-11-05 16:36:15,000 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,006 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 52.3883 | Iter Mean Loss 52.3883
2020-11-05 16:36:15,012 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.2870 | Iter Mean Loss 33.3377
2020-11-05 16:36:15,018 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.9872 | Iter Mean Loss 39.5542
2020-11-05 16:36:15,024 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.3351 | Iter Mean Loss 38.2494
2020-11-05 16:36:15,029 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0770 | Iter Mean Loss 31.8149
2020-11-05 16:36:15,030 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,036 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.9377 | Iter Mean Loss 51.9377
2020-11-05 16:36:15,041 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.0379 | Iter Mean Loss 32.9878
2020-11-05 16:36:15,047 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.5728 | Iter Mean Loss 39.1828
2020-11-05 16:36:15,052 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1053 | Iter Mean Loss 37.9134
2020-11-05 16:36:15,057 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9796 | Iter Mean Loss 31.5267
2020-11-05 16:36:15,058 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,064 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.4839 | Iter Mean Loss 51.4839
2020-11-05 16:36:15,070 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.7856 | Iter Mean Loss 32.6347
2020-11-05 16:36:15,076 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1565 | Iter Mean Loss 38.8086
2020-11-05 16:36:15,082 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.8733 | Iter Mean Loss 37.5748
2020-11-05 16:36:15,087 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8822 | Iter Mean Loss 31.2363
2020-11-05 16:36:15,088 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,095 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.0272 | Iter Mean Loss 51.0272
2020-11-05 16:36:15,101 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.5308 | Iter Mean Loss 32.2790
2020-11-05 16:36:15,107 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7388 | Iter Mean Loss 38.4323
2020-11-05 16:36:15,113 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6392 | Iter Mean Loss 37.2340
2020-11-05 16:36:15,118 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7853 | Iter Mean Loss 30.9443
2020-11-05 16:36:15,119 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,126 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 50.5682 | Iter Mean Loss 50.5682
2020-11-05 16:36:15,132 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.2741 | Iter Mean Loss 31.9212
2020-11-05 16:36:15,138 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3205 | Iter Mean Loss 38.0543
2020-11-05 16:36:15,145 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4036 | Iter Mean Loss 36.8916
2020-11-05 16:36:15,150 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6891 | Iter Mean Loss 30.6511
2020-11-05 16:36:15,151 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,157 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 50.1073 | Iter Mean Loss 50.1073
2020-11-05 16:36:15,163 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.0163 | Iter Mean Loss 31.5618
2020-11-05 16:36:15,169 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.9021 | Iter Mean Loss 37.6753
2020-11-05 16:36:15,176 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1668 | Iter Mean Loss 36.5481
2020-11-05 16:36:15,181 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5941 | Iter Mean Loss 30.3573
2020-11-05 16:36:15,182 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,187 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 49.6450 | Iter Mean Loss 49.6450
2020-11-05 16:36:15,193 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.7581 | Iter Mean Loss 31.2015
2020-11-05 16:36:15,199 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.4845 | Iter Mean Loss 37.2958
2020-11-05 16:36:15,204 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9291 | Iter Mean Loss 36.2041
2020-11-05 16:36:15,209 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5008 | Iter Mean Loss 30.0635
2020-11-05 16:36:15,210 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,216 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 49.1817 | Iter Mean Loss 49.1817
2020-11-05 16:36:15,221 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5001 | Iter Mean Loss 30.8409
2020-11-05 16:36:15,227 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.0682 | Iter Mean Loss 36.9167
2020-11-05 16:36:15,232 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6910 | Iter Mean Loss 35.8602
2020-11-05 16:36:15,237 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4094 | Iter Mean Loss 29.7701
2020-11-05 16:36:15,238 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,243 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.7180 | Iter Mean Loss 48.7180
2020-11-05 16:36:15,249 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.2432 | Iter Mean Loss 30.4806
2020-11-05 16:36:15,255 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.6541 | Iter Mean Loss 36.5384
2020-11-05 16:36:15,260 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.4527 | Iter Mean Loss 35.5170
2020-11-05 16:36:15,265 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3206 | Iter Mean Loss 29.4777
2020-11-05 16:36:15,266 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,272 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2543 | Iter Mean Loss 48.2543
2020-11-05 16:36:15,278 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.9879 | Iter Mean Loss 30.1211
2020-11-05 16:36:15,284 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.2427 | Iter Mean Loss 36.1617
2020-11-05 16:36:15,290 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.2148 | Iter Mean Loss 35.1750
2020-11-05 16:36:15,296 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2345 | Iter Mean Loss 29.1869
2020-11-05 16:36:15,297 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,303 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 47.7912 | Iter Mean Loss 47.7912
2020-11-05 16:36:15,309 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7351 | Iter Mean Loss 29.7632
2020-11-05 16:36:15,316 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.8348 | Iter Mean Loss 35.7871
2020-11-05 16:36:15,322 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.9775 | Iter Mean Loss 34.8347
2020-11-05 16:36:15,328 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1517 | Iter Mean Loss 28.8981
2020-11-05 16:36:15,329 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,336 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 47.3292 | Iter Mean Loss 47.3292
2020-11-05 16:36:15,341 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.4854 | Iter Mean Loss 29.4073
2020-11-05 16:36:15,348 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.4309 | Iter Mean Loss 35.4152
2020-11-05 16:36:15,354 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7410 | Iter Mean Loss 34.4966
2020-11-05 16:36:15,360 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0724 | Iter Mean Loss 28.6118
2020-11-05 16:36:15,361 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,367 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 46.8685 | Iter Mean Loss 46.8685
2020-11-05 16:36:15,373 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2394 | Iter Mean Loss 29.0539
2020-11-05 16:36:15,379 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.0316 | Iter Mean Loss 35.0465
2020-11-05 16:36:15,385 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.5058 | Iter Mean Loss 34.1613
2020-11-05 16:36:15,390 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9969 | Iter Mean Loss 28.3284
2020-11-05 16:36:15,391 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,397 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 46.4097 | Iter Mean Loss 46.4097
2020-11-05 16:36:15,402 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.9975 | Iter Mean Loss 28.7036
2020-11-05 16:36:15,408 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.6373 | Iter Mean Loss 34.6815
2020-11-05 16:36:15,413 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.2720 | Iter Mean Loss 33.8291
2020-11-05 16:36:15,418 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9255 | Iter Mean Loss 28.0484
2020-11-05 16:36:15,419 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,425 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.9530 | Iter Mean Loss 45.9530
2020-11-05 16:36:15,430 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7602 | Iter Mean Loss 28.3566
2020-11-05 16:36:15,436 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.2484 | Iter Mean Loss 34.3206
2020-11-05 16:36:15,441 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.0398 | Iter Mean Loss 33.5004
2020-11-05 16:36:15,446 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 27.7720
2020-11-05 16:36:15,447 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,453 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.4989 | Iter Mean Loss 45.4989
2020-11-05 16:36:15,458 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5279 | Iter Mean Loss 28.0134
2020-11-05 16:36:15,464 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.8652 | Iter Mean Loss 33.9640
2020-11-05 16:36:15,470 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 33.1754
2020-11-05 16:36:15,476 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7957 | Iter Mean Loss 27.4994
2020-11-05 16:36:15,477 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,483 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.0475 | Iter Mean Loss 45.0475
2020-11-05 16:36:15,489 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.3009 | Iter Mean Loss 27.6742
2020-11-05 16:36:15,494 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.4880 | Iter Mean Loss 33.6121
2020-11-05 16:36:15,500 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5809 | Iter Mean Loss 32.8543
2020-11-05 16:36:15,505 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7375 | Iter Mean Loss 27.2309
2020-11-05 16:36:15,506 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,512 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 44.5990 | Iter Mean Loss 44.5990
2020-11-05 16:36:15,519 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0792 | Iter Mean Loss 27.3391
2020-11-05 16:36:15,524 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.1168 | Iter Mean Loss 33.2650
2020-11-05 16:36:15,530 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.3542 | Iter Mean Loss 32.5373
2020-11-05 16:36:15,535 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6838 | Iter Mean Loss 26.9666
2020-11-05 16:36:15,536 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,542 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 44.1536 | Iter Mean Loss 44.1536
2020-11-05 16:36:15,549 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8630 | Iter Mean Loss 27.0083
2020-11-05 16:36:15,554 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.7517 | Iter Mean Loss 32.9228
2020-11-05 16:36:15,560 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.1294 | Iter Mean Loss 32.2244
2020-11-05 16:36:15,565 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6346 | Iter Mean Loss 26.7065
2020-11-05 16:36:15,566 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,571 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 43.7115 | Iter Mean Loss 43.7115
2020-11-05 16:36:15,577 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6522 | Iter Mean Loss 26.6818
2020-11-05 16:36:15,583 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.3925 | Iter Mean Loss 32.5854
2020-11-05 16:36:15,589 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9066 | Iter Mean Loss 31.9157
2020-11-05 16:36:15,594 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5899 | Iter Mean Loss 26.4505
2020-11-05 16:36:15,594 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,600 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 43.2726 | Iter Mean Loss 43.2726
2020-11-05 16:36:15,606 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4466 | Iter Mean Loss 26.3596
2020-11-05 16:36:15,611 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0393 | Iter Mean Loss 32.2528
2020-11-05 16:36:15,617 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6854 | Iter Mean Loss 31.6110
2020-11-05 16:36:15,622 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5494 | Iter Mean Loss 26.1987
2020-11-05 16:36:15,622 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,628 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.8370 | Iter Mean Loss 42.8370
2020-11-05 16:36:15,633 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2462 | Iter Mean Loss 26.0416
2020-11-05 16:36:15,639 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6917 | Iter Mean Loss 31.9250
2020-11-05 16:36:15,644 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.4660 | Iter Mean Loss 31.3102
2020-11-05 16:36:15,649 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5130 | Iter Mean Loss 25.9508
2020-11-05 16:36:15,650 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,655 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.4046 | Iter Mean Loss 42.4046
2020-11-05 16:36:15,661 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.0506 | Iter Mean Loss 25.7276
2020-11-05 16:36:15,666 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3496 | Iter Mean Loss 31.6016
2020-11-05 16:36:15,671 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.2481 | Iter Mean Loss 31.0132
2020-11-05 16:36:15,677 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4805 | Iter Mean Loss 25.7067
2020-11-05 16:36:15,678 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,684 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.9754 | Iter Mean Loss 41.9754
2020-11-05 16:36:15,689 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.8594 | Iter Mean Loss 25.4174
2020-11-05 16:36:15,694 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.0125 | Iter Mean Loss 31.2825
2020-11-05 16:36:15,700 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0316 | Iter Mean Loss 30.7197
2020-11-05 16:36:15,705 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4516 | Iter Mean Loss 25.4661
2020-11-05 16:36:15,705 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:36:15,711 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.5494 | Iter Mean Loss 41.5494
2020-11-05 16:36:15,717 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6724 | Iter Mean Loss 25.1109
2020-11-05 16:36:15,724 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6803 | Iter Mean Loss 30.9674
2020-11-05 16:36:15,729 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8163 | Iter Mean Loss 30.4296
2020-11-05 16:36:15,734 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4261 | Iter Mean Loss 25.2289
2020-11-05 16:36:15,735 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,741 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.1264 | Iter Mean Loss 41.1264
2020-11-05 16:36:15,747 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4891 | Iter Mean Loss 24.8078
2020-11-05 16:36:15,753 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.3524 | Iter Mean Loss 30.6560
2020-11-05 16:36:15,758 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.6020 | Iter Mean Loss 30.1425
2020-11-05 16:36:15,763 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4037 | Iter Mean Loss 24.9947
2020-11-05 16:36:15,764 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,770 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.7064 | Iter Mean Loss 40.7064
2020-11-05 16:36:15,775 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3091 | Iter Mean Loss 24.5078
2020-11-05 16:36:15,780 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.0287 | Iter Mean Loss 30.3481
2020-11-05 16:36:15,786 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.3887 | Iter Mean Loss 29.8582
2020-11-05 16:36:15,790 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3840 | Iter Mean Loss 24.7634
2020-11-05 16:36:15,791 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:36:15,797 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.2894 | Iter Mean Loss 40.2894
2020-11-05 16:36:15,802 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.1321 | Iter Mean Loss 24.2107
2020-11-05 16:36:15,808 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.7088 | Iter Mean Loss 30.0434
2020-11-05 16:36:15,813 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.1760 | Iter Mean Loss 29.5766
2020-11-05 16:36:15,818 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3669 | Iter Mean Loss 24.5346
2020-11-05 16:36:15,819 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:36:15,825 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.8751 | Iter Mean Loss 39.8751
2020-11-05 16:36:15,831 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9577 | Iter Mean Loss 23.9164
2020-11-05 16:36:15,836 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3923 | Iter Mean Loss 29.7417
2020-11-05 16:36:15,842 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9641 | Iter Mean Loss 29.2973
2020-11-05 16:36:15,847 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3519 | Iter Mean Loss 24.3082
2020-11-05 16:36:15,848 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:36:15,854 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.4637 | Iter Mean Loss 39.4637
2020-11-05 16:36:15,859 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7855 | Iter Mean Loss 23.6246
2020-11-05 16:36:15,864 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.0789 | Iter Mean Loss 29.4427
2020-11-05 16:36:15,870 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7526 | Iter Mean Loss 29.0202
2020-11-05 16:36:15,875 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3389 | Iter Mean Loss 24.0839
2020-11-05 16:36:15,876 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.0000 | MSE 0.2293
2020-11-05 16:36:15,881 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.0552 | Iter Mean Loss 39.0552
2020-11-05 16:36:15,887 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6153 | Iter Mean Loss 23.3352
2020-11-05 16:36:15,892 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.7686 | Iter Mean Loss 29.1463
2020-11-05 16:36:15,897 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.5416 | Iter Mean Loss 28.7452
2020-11-05 16:36:15,902 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3276 | Iter Mean Loss 23.8617
2020-11-05 16:36:15,903 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.0000 | MSE 0.2292
2020-11-05 16:36:15,908 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 38.6495 | Iter Mean Loss 38.6495
2020-11-05 16:36:15,914 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4468 | Iter Mean Loss 23.0482
2020-11-05 16:36:15,919 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.4610 | Iter Mean Loss 28.8524
2020-11-05 16:36:15,925 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.3311 | Iter Mean Loss 28.4721
2020-11-05 16:36:15,930 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3178 | Iter Mean Loss 23.6412
2020-11-05 16:36:15,931 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.0000 | MSE 0.2291
2020-11-05 16:36:15,936 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 38.2468 | Iter Mean Loss 38.2468
2020-11-05 16:36:15,942 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2799 | Iter Mean Loss 22.7633
2020-11-05 16:36:15,948 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.1560 | Iter Mean Loss 28.5609
2020-11-05 16:36:15,954 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.1211 | Iter Mean Loss 28.2009
2020-11-05 16:36:15,958 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3093 | Iter Mean Loss 23.4226
2020-11-05 16:36:15,959 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.0000 | MSE 0.2290
2020-11-05 16:36:15,965 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.8472 | Iter Mean Loss 37.8472
2020-11-05 16:36:15,970 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1143 | Iter Mean Loss 22.4808
2020-11-05 16:36:15,976 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.8537 | Iter Mean Loss 28.2717
2020-11-05 16:36:15,982 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9117 | Iter Mean Loss 27.9317
2020-11-05 16:36:15,986 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3018 | Iter Mean Loss 23.2057
2020-11-05 16:36:15,987 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.0000 | MSE 0.2289
2020-11-05 16:36:15,993 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.4508 | Iter Mean Loss 37.4508
2020-11-05 16:36:15,999 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9502 | Iter Mean Loss 22.2005
2020-11-05 16:36:16,006 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.5538 | Iter Mean Loss 27.9849
2020-11-05 16:36:16,013 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7029 | Iter Mean Loss 27.6644
2020-11-05 16:36:16,018 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2952 | Iter Mean Loss 22.9906
2020-11-05 16:36:16,019 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.0000 | MSE 0.2288
2020-11-05 16:36:16,027 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.0578 | Iter Mean Loss 37.0578
2020-11-05 16:36:16,033 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7874 | Iter Mean Loss 21.9226
2020-11-05 16:36:16,039 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.2566 | Iter Mean Loss 27.7006
2020-11-05 16:36:16,046 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.4949 | Iter Mean Loss 27.3992
2020-11-05 16:36:16,051 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2894 | Iter Mean Loss 22.7772
2020-11-05 16:36:16,052 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.0000 | MSE 0.2287
2020-11-05 16:36:16,059 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 36.6686 | Iter Mean Loss 36.6686
2020-11-05 16:36:16,066 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6261 | Iter Mean Loss 21.6473
2020-11-05 16:36:16,072 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.9621 | Iter Mean Loss 27.4189
2020-11-05 16:36:16,080 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.2880 | Iter Mean Loss 27.1362
2020-11-05 16:36:16,085 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2842 | Iter Mean Loss 22.5658
2020-11-05 16:36:16,086 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.0000 | MSE 0.2286
2020-11-05 16:36:16,093 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 36.2834 | Iter Mean Loss 36.2834
2020-11-05 16:36:16,099 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4663 | Iter Mean Loss 21.3748
2020-11-05 16:36:16,106 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.6703 | Iter Mean Loss 27.1400
2020-11-05 16:36:16,113 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.0823 | Iter Mean Loss 26.8756
2020-11-05 16:36:16,118 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2796 | Iter Mean Loss 22.3564
2020-11-05 16:36:16,119 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.0000 | MSE 0.2284
2020-11-05 16:36:16,126 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9024 | Iter Mean Loss 35.9024
2020-11-05 16:36:16,132 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3082 | Iter Mean Loss 21.1053
2020-11-05 16:36:16,138 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.3816 | Iter Mean Loss 26.8641
2020-11-05 16:36:16,144 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8782 | Iter Mean Loss 26.6176
2020-11-05 16:36:16,149 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2755 | Iter Mean Loss 22.1492
2020-11-05 16:36:16,150 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.0000 | MSE 0.2283
2020-11-05 16:36:16,157 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.5261 | Iter Mean Loss 35.5261
2020-11-05 16:36:16,163 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1522 | Iter Mean Loss 20.8391
2020-11-05 16:36:16,169 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.0960 | Iter Mean Loss 26.5914
2020-11-05 16:36:16,175 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6759 | Iter Mean Loss 26.3625
2020-11-05 16:36:16,180 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2718 | Iter Mean Loss 21.9444
2020-11-05 16:36:16,181 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.0000 | MSE 0.2281
2020-11-05 16:36:16,187 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.1548 | Iter Mean Loss 35.1548
2020-11-05 16:36:16,193 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9983 | Iter Mean Loss 20.5765
2020-11-05 16:36:16,199 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.8139 | Iter Mean Loss 26.3223
2020-11-05 16:36:16,204 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4758 | Iter Mean Loss 26.1107
2020-11-05 16:36:16,209 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2686 | Iter Mean Loss 21.7423
2020-11-05 16:36:16,210 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.0000 | MSE 0.2280
2020-11-05 16:36:16,216 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.7888 | Iter Mean Loss 34.7888
2020-11-05 16:36:16,222 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 20.3179
2020-11-05 16:36:16,228 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.5354 | Iter Mean Loss 26.0570
2020-11-05 16:36:16,234 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2782 | Iter Mean Loss 25.8623
2020-11-05 16:36:16,239 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2656 | Iter Mean Loss 21.5430
2020-11-05 16:36:16,240 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.0000 | MSE 0.2278
2020-11-05 16:36:16,247 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.4286 | Iter Mean Loss 34.4286
2020-11-05 16:36:16,253 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6984 | Iter Mean Loss 20.0635
2020-11-05 16:36:16,259 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.2609 | Iter Mean Loss 25.7960
2020-11-05 16:36:16,264 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0835 | Iter Mean Loss 25.6179
2020-11-05 16:36:16,270 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 21.3469
2020-11-05 16:36:16,270 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.0000 | MSE 0.2276
2020-11-05 16:36:16,276 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.0746 | Iter Mean Loss 34.0746
2020-11-05 16:36:16,282 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5530 | Iter Mean Loss 19.8138
2020-11-05 16:36:16,288 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.9906 | Iter Mean Loss 25.5394
2020-11-05 16:36:16,294 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.8920 | Iter Mean Loss 25.3776
2020-11-05 16:36:16,299 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2608 | Iter Mean Loss 21.1542
2020-11-05 16:36:16,300 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.0000 | MSE 0.2274
2020-11-05 16:36:16,306 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.7272 | Iter Mean Loss 33.7272
2020-11-05 16:36:16,312 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4111 | Iter Mean Loss 19.5691
2020-11-05 16:36:16,318 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.7249 | Iter Mean Loss 25.2877
2020-11-05 16:36:16,324 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7041 | Iter Mean Loss 25.1418
2020-11-05 16:36:16,329 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2589 | Iter Mean Loss 20.9652
2020-11-05 16:36:16,330 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.0000 | MSE 0.2272
2020-11-05 16:36:16,337 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.3866 | Iter Mean Loss 33.3866
2020-11-05 16:36:16,344 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2730 | Iter Mean Loss 19.3298
2020-11-05 16:36:16,350 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.4640 | Iter Mean Loss 25.0412
2020-11-05 16:36:16,356 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5201 | Iter Mean Loss 24.9109
2020-11-05 16:36:16,361 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2574 | Iter Mean Loss 20.7802
2020-11-05 16:36:16,362 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.0000 | MSE 0.2270
2020-11-05 16:36:16,368 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.0533 | Iter Mean Loss 33.0533
2020-11-05 16:36:16,375 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1391 | Iter Mean Loss 19.0962
2020-11-05 16:36:16,381 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2081 | Iter Mean Loss 24.8002
2020-11-05 16:36:16,386 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3403 | Iter Mean Loss 24.6852
2020-11-05 16:36:16,392 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2562 | Iter Mean Loss 20.5994
2020-11-05 16:36:16,392 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.0000 | MSE 0.2268
2020-11-05 16:36:16,398 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.7276 | Iter Mean Loss 32.7276
2020-11-05 16:36:16,404 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0097 | Iter Mean Loss 18.8687
2020-11-05 16:36:16,410 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9576 | Iter Mean Loss 24.5650
2020-11-05 16:36:16,416 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1651 | Iter Mean Loss 24.4650
2020-11-05 16:36:16,421 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2553 | Iter Mean Loss 20.4231
2020-11-05 16:36:16,422 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.0000 | MSE 0.2265
2020-11-05 16:36:16,427 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.4098 | Iter Mean Loss 32.4098
2020-11-05 16:36:16,433 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8851 | Iter Mean Loss 18.6474
2020-11-05 16:36:16,439 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.7126 | Iter Mean Loss 24.3358
2020-11-05 16:36:16,444 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9946 | Iter Mean Loss 24.2505
2020-11-05 16:36:16,449 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 20.2514
2020-11-05 16:36:16,450 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.0000 | MSE 0.2263
2020-11-05 16:36:16,457 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.1000 | Iter Mean Loss 32.1000
2020-11-05 16:36:16,464 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7654 | Iter Mean Loss 18.4327
2020-11-05 16:36:16,470 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.4734 | Iter Mean Loss 24.1129
2020-11-05 16:36:16,476 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.8292 | Iter Mean Loss 24.0420
2020-11-05 16:36:16,481 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2548 | Iter Mean Loss 20.0846
2020-11-05 16:36:16,482 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.0000 | MSE 0.2260
2020-11-05 16:36:16,488 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.7986 | Iter Mean Loss 31.7986
2020-11-05 16:36:16,494 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6509 | Iter Mean Loss 18.2247
2020-11-05 16:36:16,499 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.2400 | Iter Mean Loss 23.8965
2020-11-05 16:36:16,505 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.6690 | Iter Mean Loss 23.8396
2020-11-05 16:36:16,510 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2551 | Iter Mean Loss 19.9227
2020-11-05 16:36:16,511 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.0000 | MSE 0.2258
2020-11-05 16:36:16,517 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.5055 | Iter Mean Loss 31.5055
2020-11-05 16:36:16,523 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5418 | Iter Mean Loss 18.0237
2020-11-05 16:36:16,529 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0126 | Iter Mean Loss 23.6867
2020-11-05 16:36:16,535 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5141 | Iter Mean Loss 23.6435
2020-11-05 16:36:16,541 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2558 | Iter Mean Loss 19.7660
2020-11-05 16:36:16,542 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.0000 | MSE 0.2255
2020-11-05 16:36:16,548 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.2210 | Iter Mean Loss 31.2210
2020-11-05 16:36:16,554 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4382 | Iter Mean Loss 17.8296
2020-11-05 16:36:16,560 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.7914 | Iter Mean Loss 23.4835
2020-11-05 16:36:16,566 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3646 | Iter Mean Loss 23.4538
2020-11-05 16:36:16,572 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2570 | Iter Mean Loss 19.6144
2020-11-05 16:36:16,573 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.0000 | MSE 0.2253
2020-11-05 16:36:16,580 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.9450 | Iter Mean Loss 30.9450
2020-11-05 16:36:16,586 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3401 | Iter Mean Loss 17.6426
2020-11-05 16:36:16,592 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5762 | Iter Mean Loss 23.2871
2020-11-05 16:36:16,597 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2205 | Iter Mean Loss 23.2705
2020-11-05 16:36:16,602 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2585 | Iter Mean Loss 19.4681
2020-11-05 16:36:16,603 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.0000 | MSE 0.2250
2020-11-05 16:36:16,609 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.6776 | Iter Mean Loss 30.6776
2020-11-05 16:36:16,615 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2476 | Iter Mean Loss 17.4626
2020-11-05 16:36:16,621 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.3671 | Iter Mean Loss 23.0975
2020-11-05 16:36:16,628 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0818 | Iter Mean Loss 23.0935
2020-11-05 16:36:16,634 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2605 | Iter Mean Loss 19.3269
2020-11-05 16:36:16,635 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.0000 | MSE 0.2247
2020-11-05 16:36:16,641 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.4186 | Iter Mean Loss 30.4186
2020-11-05 16:36:16,647 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1607 | Iter Mean Loss 17.2896
2020-11-05 16:36:16,652 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.1642 | Iter Mean Loss 22.9145
2020-11-05 16:36:16,658 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.9485 | Iter Mean Loss 22.9230
2020-11-05 16:36:16,663 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2628 | Iter Mean Loss 19.1910
2020-11-05 16:36:16,664 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.0000 | MSE 0.2244
2020-11-05 16:36:16,670 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1679 | Iter Mean Loss 30.1679
2020-11-05 16:36:16,676 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0792 | Iter Mean Loss 17.1235
2020-11-05 16:36:16,682 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9672 | Iter Mean Loss 22.7381
2020-11-05 16:36:16,687 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8205 | Iter Mean Loss 22.7587
2020-11-05 16:36:16,693 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2656 | Iter Mean Loss 19.0601
2020-11-05 16:36:16,694 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.0000 | MSE 0.2241
2020-11-05 16:36:16,699 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.9254 | Iter Mean Loss 29.9254
2020-11-05 16:36:16,705 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0030 | Iter Mean Loss 16.9642
2020-11-05 16:36:16,711 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7761 | Iter Mean Loss 22.5682
2020-11-05 16:36:16,717 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6975 | Iter Mean Loss 22.6005
2020-11-05 16:36:16,722 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2687 | Iter Mean Loss 18.9341
2020-11-05 16:36:16,723 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.0000 | MSE 0.2238
2020-11-05 16:36:16,729 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.6908 | Iter Mean Loss 29.6908
2020-11-05 16:36:16,735 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9320 | Iter Mean Loss 16.8114
2020-11-05 16:36:16,741 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.5908 | Iter Mean Loss 22.4045
2020-11-05 16:36:16,748 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.5795 | Iter Mean Loss 22.4483
2020-11-05 16:36:16,753 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2723 | Iter Mean Loss 18.8131
2020-11-05 16:36:16,754 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.0000 | MSE 0.2235
2020-11-05 16:36:16,760 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.4639 | Iter Mean Loss 29.4639
2020-11-05 16:36:16,765 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8661 | Iter Mean Loss 16.6650
2020-11-05 16:36:16,771 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4110 | Iter Mean Loss 22.2470
2020-11-05 16:36:16,778 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4662 | Iter Mean Loss 22.3018
2020-11-05 16:36:16,784 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2761 | Iter Mean Loss 18.6967
2020-11-05 16:36:16,785 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.0000 | MSE 0.2232
2020-11-05 16:36:16,791 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.2445 | Iter Mean Loss 29.2445
2020-11-05 16:36:16,797 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8049 | Iter Mean Loss 16.5247
2020-11-05 16:36:16,803 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2367 | Iter Mean Loss 22.0953
2020-11-05 16:36:16,808 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3575 | Iter Mean Loss 22.1609
2020-11-05 16:36:16,813 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2803 | Iter Mean Loss 18.5848
2020-11-05 16:36:16,814 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.0000 | MSE 0.2229
2020-11-05 16:36:16,821 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.0322 | Iter Mean Loss 29.0322
2020-11-05 16:36:16,827 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7482 | Iter Mean Loss 16.3902
2020-11-05 16:36:16,833 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.0675 | Iter Mean Loss 21.9493
2020-11-05 16:36:16,839 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.2529 | Iter Mean Loss 22.0252
2020-11-05 16:36:16,844 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 18.4771
2020-11-05 16:36:16,845 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.0000 | MSE 0.2226
2020-11-05 16:36:16,850 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.8268 | Iter Mean Loss 28.8268
2020-11-05 16:36:16,856 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6959 | Iter Mean Loss 16.2614
2020-11-05 16:36:16,863 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9033 | Iter Mean Loss 21.8087
2020-11-05 16:36:16,869 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1525 | Iter Mean Loss 21.8946
2020-11-05 16:36:16,874 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2896 | Iter Mean Loss 18.3736
2020-11-05 16:36:16,875 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.0000 | MSE 0.2223
2020-11-05 16:36:16,881 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.6279 | Iter Mean Loss 28.6279
2020-11-05 16:36:16,886 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6477 | Iter Mean Loss 16.1378
2020-11-05 16:36:16,892 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7439 | Iter Mean Loss 21.6732
2020-11-05 16:36:16,898 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.0557 | Iter Mean Loss 21.7688
2020-11-05 16:36:16,903 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 18.2740
2020-11-05 16:36:16,904 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.0000 | MSE 0.2220
2020-11-05 16:36:16,910 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4353 | Iter Mean Loss 28.4353
2020-11-05 16:36:16,915 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6032 | Iter Mean Loss 16.0193
2020-11-05 16:36:16,921 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.5890 | Iter Mean Loss 21.5425
2020-11-05 16:36:16,927 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9625 | Iter Mean Loss 21.6475
2020-11-05 16:36:16,932 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 18.1780
2020-11-05 16:36:16,932 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.0000 | MSE 0.2217
2020-11-05 16:36:16,938 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2486 | Iter Mean Loss 28.2486
2020-11-05 16:36:16,944 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5622 | Iter Mean Loss 15.9054
2020-11-05 16:36:16,951 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4383 | Iter Mean Loss 21.4164
2020-11-05 16:36:16,957 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8726 | Iter Mean Loss 21.5304
2020-11-05 16:36:16,962 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3054 | Iter Mean Loss 18.0854
2020-11-05 16:36:16,963 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.0000 | MSE 0.2214
2020-11-05 16:36:16,969 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.0676 | Iter Mean Loss 28.0676
2020-11-05 16:36:16,974 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5245 | Iter Mean Loss 15.7961
2020-11-05 16:36:16,980 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2918 | Iter Mean Loss 21.2946
2020-11-05 16:36:16,987 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.7856 | Iter Mean Loss 21.4174
2020-11-05 16:36:16,992 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3110 | Iter Mean Loss 17.9961
2020-11-05 16:36:16,993 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.0000 | MSE 0.2210
2020-11-05 16:36:16,999 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8919 | Iter Mean Loss 27.8919
2020-11-05 16:36:17,006 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4899 | Iter Mean Loss 15.6909
2020-11-05 16:36:17,011 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.1491 | Iter Mean Loss 21.1769
2020-11-05 16:36:17,018 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.7015 | Iter Mean Loss 21.3081
2020-11-05 16:36:17,023 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3168 | Iter Mean Loss 17.9098
2020-11-05 16:36:17,024 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.0000 | MSE 0.2207
2020-11-05 16:36:17,030 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.7212 | Iter Mean Loss 27.7212
2020-11-05 16:36:17,035 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4579 | Iter Mean Loss 15.5896
2020-11-05 16:36:17,041 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0100 | Iter Mean Loss 21.0631
2020-11-05 16:36:17,046 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6198 | Iter Mean Loss 21.2023
2020-11-05 16:36:17,051 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3226 | Iter Mean Loss 17.8263
2020-11-05 16:36:17,052 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.0000 | MSE 0.2204
2020-11-05 16:36:17,058 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.5554 | Iter Mean Loss 27.5554
2020-11-05 16:36:17,064 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4286 | Iter Mean Loss 15.4920
2020-11-05 16:36:17,069 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8744 | Iter Mean Loss 20.9528
2020-11-05 16:36:17,075 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.5406 | Iter Mean Loss 21.0997
2020-11-05 16:36:17,080 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3286 | Iter Mean Loss 17.7455
2020-11-05 16:36:17,081 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.0000 | MSE 0.2201
2020-11-05 16:36:17,086 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3940 | Iter Mean Loss 27.3940
2020-11-05 16:36:17,092 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4015 | Iter Mean Loss 15.3978
2020-11-05 16:36:17,097 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.7420 | Iter Mean Loss 20.8458
2020-11-05 16:36:17,103 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4634 | Iter Mean Loss 21.0002
2020-11-05 16:36:17,108 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3346 | Iter Mean Loss 17.6671
2020-11-05 16:36:17,109 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.0000 | MSE 0.2198
2020-11-05 16:36:17,114 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.2369 | Iter Mean Loss 27.2369
2020-11-05 16:36:17,120 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3765 | Iter Mean Loss 15.3067
2020-11-05 16:36:17,126 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.6126 | Iter Mean Loss 20.7420
2020-11-05 16:36:17,131 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3882 | Iter Mean Loss 20.9036
2020-11-05 16:36:17,136 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3407 | Iter Mean Loss 17.5910
2020-11-05 16:36:17,137 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.0000 | MSE 0.2195
2020-11-05 16:36:17,143 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0839 | Iter Mean Loss 27.0839
2020-11-05 16:36:17,150 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3535 | Iter Mean Loss 15.2187
2020-11-05 16:36:17,155 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.4860 | Iter Mean Loss 20.6411
2020-11-05 16:36:17,161 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3148 | Iter Mean Loss 20.8096
2020-11-05 16:36:17,166 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3467 | Iter Mean Loss 17.5170
2020-11-05 16:36:17,167 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.0000 | MSE 0.2191
2020-11-05 16:36:17,173 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.9346 | Iter Mean Loss 26.9346
2020-11-05 16:36:17,179 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3322 | Iter Mean Loss 15.1334
2020-11-05 16:36:17,185 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3622 | Iter Mean Loss 20.5430
2020-11-05 16:36:17,191 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.2430 | Iter Mean Loss 20.7180
2020-11-05 16:36:17,195 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3528 | Iter Mean Loss 17.4450
2020-11-05 16:36:17,196 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.0000 | MSE 0.2188
2020-11-05 16:36:17,202 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7890 | Iter Mean Loss 26.7890
2020-11-05 16:36:17,208 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3124 | Iter Mean Loss 15.0507
2020-11-05 16:36:17,213 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.2409 | Iter Mean Loss 20.4475
2020-11-05 16:36:17,219 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1727 | Iter Mean Loss 20.6288
2020-11-05 16:36:17,224 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 17.3748
2020-11-05 16:36:17,224 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.0000 | MSE 0.2185
2020-11-05 16:36:17,230 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6468 | Iter Mean Loss 26.6468
2020-11-05 16:36:17,236 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2941 | Iter Mean Loss 14.9705
2020-11-05 16:36:17,241 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1220 | Iter Mean Loss 20.3543
2020-11-05 16:36:17,247 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1037 | Iter Mean Loss 20.5417
2020-11-05 16:36:17,251 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3649 | Iter Mean Loss 17.3063
2020-11-05 16:36:17,252 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.0000 | MSE 0.2182
2020-11-05 16:36:17,258 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.5079 | Iter Mean Loss 26.5079
2020-11-05 16:36:17,263 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2771 | Iter Mean Loss 14.8925
2020-11-05 16:36:17,269 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.0053 | Iter Mean Loss 20.2634
2020-11-05 16:36:17,274 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0360 | Iter Mean Loss 20.4566
2020-11-05 16:36:17,279 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3708 | Iter Mean Loss 17.2394
2020-11-05 16:36:17,280 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.0000 | MSE 0.2179
2020-11-05 16:36:17,285 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3721 | Iter Mean Loss 26.3721
2020-11-05 16:36:17,291 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2612 | Iter Mean Loss 14.8166
2020-11-05 16:36:17,297 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.8908 | Iter Mean Loss 20.1747
2020-11-05 16:36:17,302 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9693 | Iter Mean Loss 20.3733
2020-11-05 16:36:17,307 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3767 | Iter Mean Loss 17.1740
2020-11-05 16:36:17,308 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.0000 | MSE 0.2176
2020-11-05 16:36:17,315 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.2392 | Iter Mean Loss 26.2392
2020-11-05 16:36:17,322 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2463 | Iter Mean Loss 14.7427
2020-11-05 16:36:17,328 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7782 | Iter Mean Loss 20.0879
2020-11-05 16:36:17,333 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9037 | Iter Mean Loss 20.2919
2020-11-05 16:36:17,338 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3824 | Iter Mean Loss 17.1100
2020-11-05 16:36:17,339 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.0000 | MSE 0.2173
2020-11-05 16:36:17,345 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1091 | Iter Mean Loss 26.1091
2020-11-05 16:36:17,351 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2324 | Iter Mean Loss 14.6707
2020-11-05 16:36:17,357 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.6675 | Iter Mean Loss 20.0030
2020-11-05 16:36:17,362 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.8391 | Iter Mean Loss 20.2120
2020-11-05 16:36:17,367 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3881 | Iter Mean Loss 17.0472
2020-11-05 16:36:17,368 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.0000 | MSE 0.2170
2020-11-05 16:36:17,374 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.9817 | Iter Mean Loss 25.9817
2020-11-05 16:36:17,379 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2193 | Iter Mean Loss 14.6005
2020-11-05 16:36:17,385 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5587 | Iter Mean Loss 19.9199
2020-11-05 16:36:17,390 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7753 | Iter Mean Loss 20.1337
2020-11-05 16:36:17,396 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3937 | Iter Mean Loss 16.9857
2020-11-05 16:36:17,397 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.0000 | MSE 0.2167
2020-11-05 16:36:17,403 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8568 | Iter Mean Loss 25.8568
2020-11-05 16:36:17,410 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 14.5319
2020-11-05 16:36:17,419 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.4515 | Iter Mean Loss 19.8384
2020-11-05 16:36:17,429 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7123 | Iter Mean Loss 20.0569
2020-11-05 16:36:17,436 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3992 | Iter Mean Loss 16.9253
2020-11-05 16:36:17,437 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.0000 | MSE 0.2164
2020-11-05 16:36:17,445 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7344 | Iter Mean Loss 25.7344
2020-11-05 16:36:17,452 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1953 | Iter Mean Loss 14.4648
2020-11-05 16:36:17,460 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3459 | Iter Mean Loss 19.7585
2020-11-05 16:36:17,467 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6500 | Iter Mean Loss 19.9814
2020-11-05 16:36:17,473 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4045 | Iter Mean Loss 16.8660
2020-11-05 16:36:17,474 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.0000 | MSE 0.2161
2020-11-05 16:36:17,481 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.6143 | Iter Mean Loss 25.6143
2020-11-05 16:36:17,488 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1842 | Iter Mean Loss 14.3992
2020-11-05 16:36:17,494 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.2419 | Iter Mean Loss 19.6801
2020-11-05 16:36:17,501 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5884 | Iter Mean Loss 19.9072
2020-11-05 16:36:17,507 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4098 | Iter Mean Loss 16.8077
2020-11-05 16:36:17,508 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.0000 | MSE 0.2158
2020-11-05 16:36:17,514 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.4964 | Iter Mean Loss 25.4964
2020-11-05 16:36:17,520 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1737 | Iter Mean Loss 14.3351
2020-11-05 16:36:17,527 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1393 | Iter Mean Loss 19.6031
2020-11-05 16:36:17,534 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5274 | Iter Mean Loss 19.8342
2020-11-05 16:36:17,539 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4148 | Iter Mean Loss 16.7503
2020-11-05 16:36:17,540 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.0000 | MSE 0.2155
2020-11-05 16:36:17,547 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3807 | Iter Mean Loss 25.3807
2020-11-05 16:36:17,553 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1637 | Iter Mean Loss 14.2722
2020-11-05 16:36:17,560 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.0381 | Iter Mean Loss 19.5275
2020-11-05 16:36:17,566 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.4670 | Iter Mean Loss 19.7624
2020-11-05 16:36:17,572 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4198 | Iter Mean Loss 16.6939
2020-11-05 16:36:17,573 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.0000 | MSE 0.2153
2020-11-05 16:36:17,579 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2670 | Iter Mean Loss 25.2670
2020-11-05 16:36:17,586 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 14.2106
2020-11-05 16:36:17,593 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9382 | Iter Mean Loss 19.4531
2020-11-05 16:36:17,599 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.4072 | Iter Mean Loss 19.6916
2020-11-05 16:36:17,604 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4246 | Iter Mean Loss 16.6382
2020-11-05 16:36:17,605 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.0000 | MSE 0.2150
2020-11-05 16:36:17,610 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.1553 | Iter Mean Loss 25.1553
2020-11-05 16:36:17,616 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1450 | Iter Mean Loss 14.1502
2020-11-05 16:36:17,622 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8396 | Iter Mean Loss 19.3800
2020-11-05 16:36:17,627 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3478 | Iter Mean Loss 19.6220
2020-11-05 16:36:17,632 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4293 | Iter Mean Loss 16.5834
2020-11-05 16:36:17,632 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.0000 | MSE 0.2147
2020-11-05 16:36:17,638 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0455 | Iter Mean Loss 25.0455
2020-11-05 16:36:17,643 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1363 | Iter Mean Loss 14.0909
2020-11-05 16:36:17,649 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.7422 | Iter Mean Loss 19.3080
2020-11-05 16:36:17,654 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2890 | Iter Mean Loss 19.5533
2020-11-05 16:36:17,659 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4338 | Iter Mean Loss 16.5294
2020-11-05 16:36:17,659 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.0000 | MSE 0.2145
2020-11-05 16:36:17,665 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.9376 | Iter Mean Loss 24.9376
2020-11-05 16:36:17,670 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1278 | Iter Mean Loss 14.0327
2020-11-05 16:36:17,676 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6460 | Iter Mean Loss 19.2371
2020-11-05 16:36:17,683 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2306 | Iter Mean Loss 19.4855
2020-11-05 16:36:17,688 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4382 | Iter Mean Loss 16.4761
2020-11-05 16:36:17,689 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.0000 | MSE 0.2142
2020-11-05 16:36:17,695 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8314 | Iter Mean Loss 24.8314
2020-11-05 16:36:17,701 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1197 | Iter Mean Loss 13.9756
2020-11-05 16:36:17,706 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.5509 | Iter Mean Loss 19.1673
2020-11-05 16:36:17,713 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1726 | Iter Mean Loss 19.4187
2020-11-05 16:36:17,718 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4425 | Iter Mean Loss 16.4234
2020-11-05 16:36:17,719 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.0000 | MSE 0.2140
2020-11-05 16:36:17,725 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.7269 | Iter Mean Loss 24.7269
2020-11-05 16:36:17,731 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1119 | Iter Mean Loss 13.9194
2020-11-05 16:36:17,737 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4568 | Iter Mean Loss 19.0985
2020-11-05 16:36:17,743 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1151 | Iter Mean Loss 19.3527
2020-11-05 16:36:17,748 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4466 | Iter Mean Loss 16.3715
2020-11-05 16:36:17,749 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.0000 | MSE 0.2137
2020-11-05 16:36:17,755 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6241 | Iter Mean Loss 24.6241
2020-11-05 16:36:17,761 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1043 | Iter Mean Loss 13.8642
2020-11-05 16:36:17,768 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.3638 | Iter Mean Loss 19.0307
2020-11-05 16:36:17,774 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0579 | Iter Mean Loss 19.2875
2020-11-05 16:36:17,780 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4506 | Iter Mean Loss 16.3201
2020-11-05 16:36:17,781 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.0000 | MSE 0.2135
2020-11-05 16:36:17,787 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.5229 | Iter Mean Loss 24.5229
2020-11-05 16:36:17,793 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0969 | Iter Mean Loss 13.8099
2020-11-05 16:36:17,799 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2717 | Iter Mean Loss 18.9638
2020-11-05 16:36:17,806 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0012 | Iter Mean Loss 19.2232
2020-11-05 16:36:17,811 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4544 | Iter Mean Loss 16.2694
2020-11-05 16:36:17,812 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.0000 | MSE 0.2132
2020-11-05 16:36:17,820 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4232 | Iter Mean Loss 24.4232
2020-11-05 16:36:17,825 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0898 | Iter Mean Loss 13.7565
2020-11-05 16:36:17,831 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1806 | Iter Mean Loss 18.8979
2020-11-05 16:36:17,837 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9447 | Iter Mean Loss 19.1596
2020-11-05 16:36:17,842 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4581 | Iter Mean Loss 16.2193
2020-11-05 16:36:17,843 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.0000 | MSE 0.2130
2020-11-05 16:36:17,849 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.3251 | Iter Mean Loss 24.3251
2020-11-05 16:36:17,855 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0828 | Iter Mean Loss 13.7039
2020-11-05 16:36:17,860 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.0904 | Iter Mean Loss 18.8328
2020-11-05 16:36:17,866 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8887 | Iter Mean Loss 19.0967
2020-11-05 16:36:17,871 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4617 | Iter Mean Loss 16.1697
2020-11-05 16:36:17,872 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.0000 | MSE 0.2128
2020-11-05 16:36:17,878 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2283 | Iter Mean Loss 24.2283
2020-11-05 16:36:17,883 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0761 | Iter Mean Loss 13.6522
2020-11-05 16:36:17,889 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.0011 | Iter Mean Loss 18.7685
2020-11-05 16:36:17,895 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8330 | Iter Mean Loss 19.0346
2020-11-05 16:36:17,900 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4651 | Iter Mean Loss 16.1207
2020-11-05 16:36:17,901 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.0000 | MSE 0.2125
2020-11-05 16:36:17,906 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.1330 | Iter Mean Loss 24.1330
2020-11-05 16:36:17,912 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0695 | Iter Mean Loss 13.6012
2020-11-05 16:36:17,918 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9127 | Iter Mean Loss 18.7050
2020-11-05 16:36:17,924 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7776 | Iter Mean Loss 18.9732
2020-11-05 16:36:17,929 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4684 | Iter Mean Loss 16.0722
2020-11-05 16:36:17,930 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.0000 | MSE 0.2123
2020-11-05 16:36:17,936 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0390 | Iter Mean Loss 24.0390
2020-11-05 16:36:17,942 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0630 | Iter Mean Loss 13.5510
2020-11-05 16:36:17,949 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.8251 | Iter Mean Loss 18.6424
2020-11-05 16:36:17,956 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7226 | Iter Mean Loss 18.9124
2020-11-05 16:36:17,962 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4716 | Iter Mean Loss 16.0242
2020-11-05 16:36:17,963 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.0000 | MSE 0.2121
2020-11-05 16:36:17,969 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.9464 | Iter Mean Loss 23.9464
2020-11-05 16:36:17,975 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0567 | Iter Mean Loss 13.5016
2020-11-05 16:36:17,981 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7382 | Iter Mean Loss 18.5805
2020-11-05 16:36:17,989 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6678 | Iter Mean Loss 18.8523
2020-11-05 16:36:17,994 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4746 | Iter Mean Loss 15.9768
2020-11-05 16:36:17,995 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.0000 | MSE 0.2119
2020-11-05 16:36:18,003 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8550 | Iter Mean Loss 23.8550
2020-11-05 16:36:18,009 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0506 | Iter Mean Loss 13.4528
2020-11-05 16:36:18,016 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6522 | Iter Mean Loss 18.5193
2020-11-05 16:36:18,024 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6134 | Iter Mean Loss 18.7928
2020-11-05 16:36:18,030 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4775 | Iter Mean Loss 15.9297
2020-11-05 16:36:18,032 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.0000 | MSE 0.2117
2020-11-05 16:36:18,041 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.7649 | Iter Mean Loss 23.7649
2020-11-05 16:36:18,048 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0445 | Iter Mean Loss 13.4047
2020-11-05 16:36:18,055 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.5669 | Iter Mean Loss 18.4588
2020-11-05 16:36:18,061 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5593 | Iter Mean Loss 18.7339
2020-11-05 16:36:18,066 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4803 | Iter Mean Loss 15.8832
2020-11-05 16:36:18,067 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.0000 | MSE 0.2115
2020-11-05 16:36:18,073 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6760 | Iter Mean Loss 23.6760
2020-11-05 16:36:18,079 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0386 | Iter Mean Loss 13.3573
2020-11-05 16:36:18,084 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4824 | Iter Mean Loss 18.3990
2020-11-05 16:36:18,090 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5055 | Iter Mean Loss 18.6756
2020-11-05 16:36:18,095 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4829 | Iter Mean Loss 15.8371
2020-11-05 16:36:18,096 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.0000 | MSE 0.2113
2020-11-05 16:36:18,102 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.5883 | Iter Mean Loss 23.5883
2020-11-05 16:36:18,108 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0328 | Iter Mean Loss 13.3106
2020-11-05 16:36:18,114 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.3985 | Iter Mean Loss 18.3399
2020-11-05 16:36:18,120 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4519 | Iter Mean Loss 18.6179
2020-11-05 16:36:18,125 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4854 | Iter Mean Loss 15.7914
2020-11-05 16:36:18,126 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.0000 | MSE 0.2111
2020-11-05 16:36:18,133 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.5018 | Iter Mean Loss 23.5018
2020-11-05 16:36:18,139 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0271 | Iter Mean Loss 13.2644
2020-11-05 16:36:18,145 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.3154 | Iter Mean Loss 18.2814
2020-11-05 16:36:18,152 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3987 | Iter Mean Loss 18.5607
2020-11-05 16:36:18,157 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4879 | Iter Mean Loss 15.7462
2020-11-05 16:36:18,158 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.0000 | MSE 0.2109
2020-11-05 16:36:18,165 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.4163 | Iter Mean Loss 23.4163
2020-11-05 16:36:18,172 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0215 | Iter Mean Loss 13.2189
2020-11-05 16:36:18,178 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2329 | Iter Mean Loss 18.2236
2020-11-05 16:36:18,184 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3457 | Iter Mean Loss 18.5041
2020-11-05 16:36:18,190 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4902 | Iter Mean Loss 15.7013
2020-11-05 16:36:18,191 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.0000 | MSE 0.2107
2020-11-05 16:36:18,197 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3320 | Iter Mean Loss 23.3320
2020-11-05 16:36:18,204 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0160 | Iter Mean Loss 13.1740
2020-11-05 16:36:18,209 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1511 | Iter Mean Loss 18.1664
2020-11-05 16:36:18,216 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2931 | Iter Mean Loss 18.4480
2020-11-05 16:36:18,221 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4924 | Iter Mean Loss 15.6569
2020-11-05 16:36:18,222 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.0000 | MSE 0.2105
2020-11-05 16:36:18,228 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.2487 | Iter Mean Loss 23.2487
2020-11-05 16:36:18,234 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0106 | Iter Mean Loss 13.1296
2020-11-05 16:36:18,240 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.0700 | Iter Mean Loss 18.1097
2020-11-05 16:36:18,246 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2407 | Iter Mean Loss 18.3925
2020-11-05 16:36:18,251 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4944 | Iter Mean Loss 15.6129
2020-11-05 16:36:18,252 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.0000 | MSE 0.2103
2020-11-05 16:36:18,257 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1664 | Iter Mean Loss 23.1664
2020-11-05 16:36:18,263 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0052 | Iter Mean Loss 13.0858
2020-11-05 16:36:18,269 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9894 | Iter Mean Loss 18.0537
2020-11-05 16:36:18,274 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1886 | Iter Mean Loss 18.3374
2020-11-05 16:36:18,279 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4964 | Iter Mean Loss 15.5692
2020-11-05 16:36:18,280 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.0000 | MSE 0.2102
2020-11-05 16:36:18,285 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.0852 | Iter Mean Loss 23.0852
2020-11-05 16:36:18,292 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0000 | Iter Mean Loss 13.0426
2020-11-05 16:36:18,298 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9095 | Iter Mean Loss 17.9982
2020-11-05 16:36:18,304 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1368 | Iter Mean Loss 18.2829
2020-11-05 16:36:18,309 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4983 | Iter Mean Loss 15.5259
2020-11-05 16:36:18,310 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.0000 | MSE 0.2100
2020-11-05 16:36:18,317 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.0049 | Iter Mean Loss 23.0049
2020-11-05 16:36:18,323 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9948 | Iter Mean Loss 12.9999
2020-11-05 16:36:18,329 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.8302 | Iter Mean Loss 17.9433
2020-11-05 16:36:18,336 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0852 | Iter Mean Loss 18.2288
2020-11-05 16:36:18,341 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5000 | Iter Mean Loss 15.4830
2020-11-05 16:36:18,342 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.0000 | MSE 0.2098
2020-11-05 16:36:18,349 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.9256 | Iter Mean Loss 22.9256
2020-11-05 16:36:18,355 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9897 | Iter Mean Loss 12.9576
2020-11-05 16:36:18,361 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7514 | Iter Mean Loss 17.8889
2020-11-05 16:36:18,368 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0339 | Iter Mean Loss 18.1752
2020-11-05 16:36:18,373 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5017 | Iter Mean Loss 15.4405
2020-11-05 16:36:18,374 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.0000 | MSE 0.2097
2020-11-05 16:36:18,381 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8472 | Iter Mean Loss 22.8472
2020-11-05 16:36:18,387 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9846 | Iter Mean Loss 12.9159
2020-11-05 16:36:18,393 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6732 | Iter Mean Loss 17.8350
2020-11-05 16:36:18,400 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9829 | Iter Mean Loss 18.1220
2020-11-05 16:36:18,405 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5032 | Iter Mean Loss 15.3983
2020-11-05 16:36:18,406 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.0000 | MSE 0.2095
2020-11-05 16:36:18,412 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.7698 | Iter Mean Loss 22.7698
2020-11-05 16:36:18,419 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9797 | Iter Mean Loss 12.8747
2020-11-05 16:36:18,425 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.5956 | Iter Mean Loss 17.7817
2020-11-05 16:36:18,432 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9321 | Iter Mean Loss 18.0693
2020-11-05 16:36:18,437 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5047 | Iter Mean Loss 15.3564
2020-11-05 16:36:18,438 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.0000 | MSE 0.2094
2020-11-05 16:36:18,443 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6932 | Iter Mean Loss 22.6932
2020-11-05 16:36:18,450 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9748 | Iter Mean Loss 12.8340
2020-11-05 16:36:18,456 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.5185 | Iter Mean Loss 17.7288
2020-11-05 16:36:18,462 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8816 | Iter Mean Loss 18.0170
2020-11-05 16:36:18,467 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5061 | Iter Mean Loss 15.3148
2020-11-05 16:36:18,468 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.0000 | MSE 0.2092
2020-11-05 16:36:18,474 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6175 | Iter Mean Loss 22.6175
2020-11-05 16:36:18,480 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9699 | Iter Mean Loss 12.7937
2020-11-05 16:36:18,486 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4420 | Iter Mean Loss 17.6765
2020-11-05 16:36:18,491 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8314 | Iter Mean Loss 17.9652
2020-11-05 16:36:18,497 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5074 | Iter Mean Loss 15.2736
2020-11-05 16:36:18,498 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.0000 | MSE 0.2091
2020-11-05 16:36:18,504 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.5427 | Iter Mean Loss 22.5427
2020-11-05 16:36:18,510 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9651 | Iter Mean Loss 12.7539
2020-11-05 16:36:18,516 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3660 | Iter Mean Loss 17.6246
2020-11-05 16:36:18,522 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7814 | Iter Mean Loss 17.9138
2020-11-05 16:36:18,529 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5086 | Iter Mean Loss 15.2328
2020-11-05 16:36:18,530 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.0000 | MSE 0.2089
2020-11-05 16:36:18,536 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.4687 | Iter Mean Loss 22.4687
2020-11-05 16:36:18,542 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9604 | Iter Mean Loss 12.7145
2020-11-05 16:36:18,548 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.2905 | Iter Mean Loss 17.5732
2020-11-05 16:36:18,554 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7317 | Iter Mean Loss 17.8628
2020-11-05 16:36:18,559 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5097 | Iter Mean Loss 15.1922
2020-11-05 16:36:18,561 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.0000 | MSE 0.2088
2020-11-05 16:36:18,568 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3955 | Iter Mean Loss 22.3955
2020-11-05 16:36:18,574 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9557 | Iter Mean Loss 12.6756
2020-11-05 16:36:18,581 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.2155 | Iter Mean Loss 17.5222
2020-11-05 16:36:18,587 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6822 | Iter Mean Loss 17.8122
2020-11-05 16:36:18,592 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5107 | Iter Mean Loss 15.1519
2020-11-05 16:36:18,594 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.0000 | MSE 0.2086
2020-11-05 16:36:18,600 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3231 | Iter Mean Loss 22.3231
2020-11-05 16:36:18,606 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9511 | Iter Mean Loss 12.6371
2020-11-05 16:36:18,613 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1410 | Iter Mean Loss 17.4717
2020-11-05 16:36:18,619 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6330 | Iter Mean Loss 17.7621
2020-11-05 16:36:18,624 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5116 | Iter Mean Loss 15.1120
2020-11-05 16:36:18,626 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.0000 | MSE 0.2085
2020-11-05 16:36:18,632 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.2515 | Iter Mean Loss 22.2515
2020-11-05 16:36:18,638 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9465 | Iter Mean Loss 12.5990
2020-11-05 16:36:18,643 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0670 | Iter Mean Loss 17.4217
2020-11-05 16:36:18,649 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5841 | Iter Mean Loss 17.7123
2020-11-05 16:36:18,653 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5125 | Iter Mean Loss 15.0723
2020-11-05 16:36:18,654 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.0000 | MSE 0.2084
2020-11-05 16:36:18,660 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.1806 | Iter Mean Loss 22.1806
2020-11-05 16:36:18,666 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 12.5613
2020-11-05 16:36:18,671 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.9935 | Iter Mean Loss 17.3720
2020-11-05 16:36:18,676 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5354 | Iter Mean Loss 17.6629
2020-11-05 16:36:18,681 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5133 | Iter Mean Loss 15.0329
2020-11-05 16:36:18,682 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.0000 | MSE 0.2082
2020-11-05 16:36:18,688 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.1105 | Iter Mean Loss 22.1105
2020-11-05 16:36:18,693 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9375 | Iter Mean Loss 12.5240
2020-11-05 16:36:18,699 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.9204 | Iter Mean Loss 17.3228
2020-11-05 16:36:18,705 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4869 | Iter Mean Loss 17.6138
2020-11-05 16:36:18,710 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5140 | Iter Mean Loss 14.9939
2020-11-05 16:36:18,710 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.0000 | MSE 0.2081
2020-11-05 16:36:18,716 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0411 | Iter Mean Loss 22.0411
2020-11-05 16:36:18,722 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9331 | Iter Mean Loss 12.4871
2020-11-05 16:36:18,728 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8479 | Iter Mean Loss 17.2740
2020-11-05 16:36:18,735 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4387 | Iter Mean Loss 17.5652
2020-11-05 16:36:18,740 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5146 | Iter Mean Loss 14.9551
2020-11-05 16:36:18,742 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.0000 | MSE 0.2080
2020-11-05 16:36:18,748 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.9725 | Iter Mean Loss 21.9725
2020-11-05 16:36:18,753 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9287 | Iter Mean Loss 12.4506
2020-11-05 16:36:18,759 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7757 | Iter Mean Loss 17.2256
2020-11-05 16:36:18,765 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3907 | Iter Mean Loss 17.5169
2020-11-05 16:36:18,770 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5151 | Iter Mean Loss 14.9166
2020-11-05 16:36:18,771 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.0000 | MSE 0.2078
2020-11-05 16:36:18,777 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.9045 | Iter Mean Loss 21.9045
2020-11-05 16:36:18,784 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9244 | Iter Mean Loss 12.4144
2020-11-05 16:36:18,790 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7041 | Iter Mean Loss 17.1776
2020-11-05 16:36:18,796 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3430 | Iter Mean Loss 17.4690
2020-11-05 16:36:18,802 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5156 | Iter Mean Loss 14.8783
2020-11-05 16:36:18,803 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.0000 | MSE 0.2077
2020-11-05 16:36:18,808 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.8372 | Iter Mean Loss 21.8372
2020-11-05 16:36:18,815 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9201 | Iter Mean Loss 12.3786
2020-11-05 16:36:18,821 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.6328 | Iter Mean Loss 17.1300
2020-11-05 16:36:18,827 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2955 | Iter Mean Loss 17.4214
2020-11-05 16:36:18,832 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5160 | Iter Mean Loss 14.8403
2020-11-05 16:36:18,833 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.0000 | MSE 0.2076
2020-11-05 16:36:18,839 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7706 | Iter Mean Loss 21.7706
2020-11-05 16:36:18,845 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9158 | Iter Mean Loss 12.3432
2020-11-05 16:36:18,851 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5620 | Iter Mean Loss 17.0828
2020-11-05 16:36:18,856 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2482 | Iter Mean Loss 17.3742
2020-11-05 16:36:18,861 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5164 | Iter Mean Loss 14.8026
2020-11-05 16:36:18,862 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.0000 | MSE 0.2075
2020-11-05 16:36:18,867 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7047 | Iter Mean Loss 21.7047
2020-11-05 16:36:18,873 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9116 | Iter Mean Loss 12.3081
2020-11-05 16:36:18,878 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4916 | Iter Mean Loss 17.0360
2020-11-05 16:36:18,884 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2012 | Iter Mean Loss 17.3273
2020-11-05 16:36:18,888 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5167 | Iter Mean Loss 14.7652
2020-11-05 16:36:18,889 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.0000 | MSE 0.2074
2020-11-05 16:36:18,895 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.6394 | Iter Mean Loss 21.6394
2020-11-05 16:36:18,900 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9074 | Iter Mean Loss 12.2734
2020-11-05 16:36:18,905 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4217 | Iter Mean Loss 16.9895
2020-11-05 16:36:18,911 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1544 | Iter Mean Loss 17.2807
2020-11-05 16:36:18,916 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5169 | Iter Mean Loss 14.7280
2020-11-05 16:36:18,916 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.0000 | MSE 0.2073
2020-11-05 16:36:18,922 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.5747 | Iter Mean Loss 21.5747
2020-11-05 16:36:18,928 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9032 | Iter Mean Loss 12.2390
2020-11-05 16:36:18,933 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.3522 | Iter Mean Loss 16.9434
2020-11-05 16:36:18,939 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1079 | Iter Mean Loss 17.2345
2020-11-05 16:36:18,944 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5170 | Iter Mean Loss 14.6910
2020-11-05 16:36:18,945 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.0000 | MSE 0.2071
2020-11-05 16:36:18,952 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.5107 | Iter Mean Loss 21.5107
2020-11-05 16:36:18,957 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8991 | Iter Mean Loss 12.2049
2020-11-05 16:36:18,965 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2831 | Iter Mean Loss 16.8976
2020-11-05 16:36:18,970 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0616 | Iter Mean Loss 17.1886
2020-11-05 16:36:18,976 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 14.6543
2020-11-05 16:36:18,977 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.0000 | MSE 0.2070
2020-11-05 16:36:18,984 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4472 | Iter Mean Loss 21.4472
2020-11-05 16:36:18,990 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8951 | Iter Mean Loss 12.1711
2020-11-05 16:36:18,995 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2143 | Iter Mean Loss 16.8522
2020-11-05 16:36:19,002 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0155 | Iter Mean Loss 17.1430
2020-11-05 16:36:19,007 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5172 | Iter Mean Loss 14.6179
2020-11-05 16:36:19,008 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.0000 | MSE 0.2069
2020-11-05 16:36:19,014 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.3844 | Iter Mean Loss 21.3844
2020-11-05 16:36:19,021 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8910 | Iter Mean Loss 12.1377
2020-11-05 16:36:19,026 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1460 | Iter Mean Loss 16.8071
2020-11-05 16:36:19,032 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9696 | Iter Mean Loss 17.0978
2020-11-05 16:36:19,037 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5172 | Iter Mean Loss 14.5816
2020-11-05 16:36:19,039 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.0000 | MSE 0.2068
2020-11-05 16:36:19,044 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.3221 | Iter Mean Loss 21.3221
2020-11-05 16:36:19,050 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 12.1046
2020-11-05 16:36:19,055 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.0781 | Iter Mean Loss 16.7624
2020-11-05 16:36:19,061 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9240 | Iter Mean Loss 17.0528
2020-11-05 16:36:19,066 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 14.5457
2020-11-05 16:36:19,066 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.0000 | MSE 0.2067
2020-11-05 16:36:19,072 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2604 | Iter Mean Loss 21.2604
2020-11-05 16:36:19,077 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8830 | Iter Mean Loss 12.0717
2020-11-05 16:36:19,083 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.0106 | Iter Mean Loss 16.7180
2020-11-05 16:36:19,088 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8785 | Iter Mean Loss 17.0081
2020-11-05 16:36:19,093 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5170 | Iter Mean Loss 14.5099
2020-11-05 16:36:19,094 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.0000 | MSE 0.2066
2020-11-05 16:36:19,099 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.1993 | Iter Mean Loss 21.1993
2020-11-05 16:36:19,105 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8791 | Iter Mean Loss 12.0392
2020-11-05 16:36:19,111 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9434 | Iter Mean Loss 16.6739
2020-11-05 16:36:19,118 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8333 | Iter Mean Loss 16.9638
2020-11-05 16:36:19,123 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5168 | Iter Mean Loss 14.4744
2020-11-05 16:36:19,124 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.0000 | MSE 0.2065
2020-11-05 16:36:19,129 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.1387 | Iter Mean Loss 21.1387
2020-11-05 16:36:19,136 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8752 | Iter Mean Loss 12.0069
2020-11-05 16:36:19,142 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8767 | Iter Mean Loss 16.6302
2020-11-05 16:36:19,148 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7884 | Iter Mean Loss 16.9197
2020-11-05 16:36:19,154 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5165 | Iter Mean Loss 14.4391
2020-11-05 16:36:19,155 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.0000 | MSE 0.2064
2020-11-05 16:36:19,160 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.0787 | Iter Mean Loss 21.0787
2020-11-05 16:36:19,166 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8713 | Iter Mean Loss 11.9750
2020-11-05 16:36:19,172 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8103 | Iter Mean Loss 16.5867
2020-11-05 16:36:19,179 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7436 | Iter Mean Loss 16.8760
2020-11-05 16:36:19,184 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5163 | Iter Mean Loss 14.4040
2020-11-05 16:36:19,185 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.0000 | MSE 0.2063
2020-11-05 16:36:19,191 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.0192 | Iter Mean Loss 21.0192
2020-11-05 16:36:19,198 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8674 | Iter Mean Loss 11.9433
2020-11-05 16:36:19,203 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.7443 | Iter Mean Loss 16.5436
2020-11-05 16:36:19,210 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6990 | Iter Mean Loss 16.8325
2020-11-05 16:36:19,216 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5159 | Iter Mean Loss 14.3692
2020-11-05 16:36:19,217 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.0000 | MSE 0.2062
2020-11-05 16:36:19,223 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9602 | Iter Mean Loss 20.9602
2020-11-05 16:36:19,230 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8636 | Iter Mean Loss 11.9119
2020-11-05 16:36:19,235 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6786 | Iter Mean Loss 16.5008
2020-11-05 16:36:19,242 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6547 | Iter Mean Loss 16.7893
2020-11-05 16:36:19,247 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5156 | Iter Mean Loss 14.3345
2020-11-05 16:36:19,248 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.0000 | MSE 0.2061
2020-11-05 16:36:19,254 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9017 | Iter Mean Loss 20.9017
2020-11-05 16:36:19,260 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8598 | Iter Mean Loss 11.8808
2020-11-05 16:36:19,266 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6133 | Iter Mean Loss 16.4583
2020-11-05 16:36:19,271 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6105 | Iter Mean Loss 16.7463
2020-11-05 16:36:19,276 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5151 | Iter Mean Loss 14.3001
2020-11-05 16:36:19,277 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.0000 | MSE 0.2061
2020-11-05 16:36:19,283 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.8438 | Iter Mean Loss 20.8438
2020-11-05 16:36:19,288 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8560 | Iter Mean Loss 11.8499
2020-11-05 16:36:19,294 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5484 | Iter Mean Loss 16.4161
2020-11-05 16:36:19,299 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5666 | Iter Mean Loss 16.7037
2020-11-05 16:36:19,304 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5147 | Iter Mean Loss 14.2659
2020-11-05 16:36:19,305 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.0000 | MSE 0.2060
2020-11-05 16:36:19,311 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.7863 | Iter Mean Loss 20.7863
2020-11-05 16:36:19,317 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8523 | Iter Mean Loss 11.8193
2020-11-05 16:36:19,323 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.4838 | Iter Mean Loss 16.3741
2020-11-05 16:36:19,329 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5228 | Iter Mean Loss 16.6613
2020-11-05 16:36:19,334 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5142 | Iter Mean Loss 14.2319
2020-11-05 16:36:19,335 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.0000 | MSE 0.2059
2020-11-05 16:36:19,340 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.7293 | Iter Mean Loss 20.7293
2020-11-05 16:36:19,346 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8486 | Iter Mean Loss 11.7889
2020-11-05 16:36:19,351 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.4196 | Iter Mean Loss 16.3325
2020-11-05 16:36:19,358 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4793 | Iter Mean Loss 16.6192
2020-11-05 16:36:19,363 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5136 | Iter Mean Loss 14.1981
2020-11-05 16:36:19,364 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.0000 | MSE 0.2058
2020-11-05 16:36:19,370 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6728 | Iter Mean Loss 20.6728
2020-11-05 16:36:19,377 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8449 | Iter Mean Loss 11.7588
2020-11-05 16:36:19,383 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3557 | Iter Mean Loss 16.2911
2020-11-05 16:36:19,389 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4360 | Iter Mean Loss 16.5773
2020-11-05 16:36:19,394 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5130 | Iter Mean Loss 14.1645
2020-11-05 16:36:19,396 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.0000 | MSE 0.2057
2020-11-05 16:36:19,401 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6168 | Iter Mean Loss 20.6168
2020-11-05 16:36:19,408 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8412 | Iter Mean Loss 11.7290
2020-11-05 16:36:19,414 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2921 | Iter Mean Loss 16.2500
2020-11-05 16:36:19,420 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3928 | Iter Mean Loss 16.5357
2020-11-05 16:36:19,426 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5124 | Iter Mean Loss 14.1311
2020-11-05 16:36:19,427 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.0000 | MSE 0.2056
2020-11-05 16:36:19,433 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.5612 | Iter Mean Loss 20.5612
2020-11-05 16:36:19,439 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8375 | Iter Mean Loss 11.6994
2020-11-05 16:36:19,446 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2289 | Iter Mean Loss 16.2092
2020-11-05 16:36:19,451 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3499 | Iter Mean Loss 16.4944
2020-11-05 16:36:19,457 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5117 | Iter Mean Loss 14.0978
2020-11-05 16:36:19,458 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.0000 | MSE 0.2055
2020-11-05 16:36:19,464 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.5061 | Iter Mean Loss 20.5061
2020-11-05 16:36:19,470 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8339 | Iter Mean Loss 11.6700
2020-11-05 16:36:19,476 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1661 | Iter Mean Loss 16.1687
2020-11-05 16:36:19,482 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3071 | Iter Mean Loss 16.4533
2020-11-05 16:36:19,487 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5110 | Iter Mean Loss 14.0648
2020-11-05 16:36:19,489 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.0000 | MSE 0.2054
2020-11-05 16:36:19,495 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.4514 | Iter Mean Loss 20.4514
2020-11-05 16:36:19,501 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 11.6408
2020-11-05 16:36:19,507 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1035 | Iter Mean Loss 16.1284
2020-11-05 16:36:19,513 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2645 | Iter Mean Loss 16.4124
2020-11-05 16:36:19,518 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 14.0320
2020-11-05 16:36:19,519 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.0000 | MSE 0.2054
2020-11-05 16:36:19,526 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3972 | Iter Mean Loss 20.3972
2020-11-05 16:36:19,531 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8267 | Iter Mean Loss 11.6119
2020-11-05 16:36:19,536 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.0413 | Iter Mean Loss 16.0884
2020-11-05 16:36:19,543 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2222 | Iter Mean Loss 16.3718
2020-11-05 16:36:19,548 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5095 | Iter Mean Loss 13.9994
2020-11-05 16:36:19,549 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.0000 | MSE 0.2053
2020-11-05 16:36:19,554 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3434 | Iter Mean Loss 20.3434
2020-11-05 16:36:19,560 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8231 | Iter Mean Loss 11.5832
2020-11-05 16:36:19,566 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9794 | Iter Mean Loss 16.0486
2020-11-05 16:36:19,571 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1800 | Iter Mean Loss 16.3315
2020-11-05 16:36:19,576 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5086 | Iter Mean Loss 13.9669
2020-11-05 16:36:19,577 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.0000 | MSE 0.2052
2020-11-05 16:36:19,583 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.2900 | Iter Mean Loss 20.2900
2020-11-05 16:36:19,588 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 11.5548
2020-11-05 16:36:19,594 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9178 | Iter Mean Loss 16.0091
2020-11-05 16:36:19,599 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1379 | Iter Mean Loss 16.2913
2020-11-05 16:36:19,604 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5078 | Iter Mean Loss 13.9346
2020-11-05 16:36:19,606 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.0000 | MSE 0.2051
2020-11-05 16:36:19,611 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.2370 | Iter Mean Loss 20.2370
2020-11-05 16:36:19,617 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8160 | Iter Mean Loss 11.5265
2020-11-05 16:36:19,623 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8566 | Iter Mean Loss 15.9699
2020-11-05 16:36:19,629 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0961 | Iter Mean Loss 16.2514
2020-11-05 16:36:19,634 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 13.9025
2020-11-05 16:36:19,635 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.0000 | MSE 0.2050
2020-11-05 16:36:19,641 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.1845 | Iter Mean Loss 20.1845
2020-11-05 16:36:19,647 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8125 | Iter Mean Loss 11.4985
2020-11-05 16:36:19,653 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.7956 | Iter Mean Loss 15.9309
2020-11-05 16:36:19,658 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0544 | Iter Mean Loss 16.2118
2020-11-05 16:36:19,663 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5060 | Iter Mean Loss 13.8706
2020-11-05 16:36:19,664 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.0000 | MSE 0.2050
2020-11-05 16:36:19,670 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.1323 | Iter Mean Loss 20.1323
2020-11-05 16:36:19,675 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8090 | Iter Mean Loss 11.4707
2020-11-05 16:36:19,681 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.7350 | Iter Mean Loss 15.8921
2020-11-05 16:36:19,686 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0130 | Iter Mean Loss 16.1723
2020-11-05 16:36:19,691 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 13.8389
2020-11-05 16:36:19,692 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.0000 | MSE 0.2049
2020-11-05 16:36:19,697 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0806 | Iter Mean Loss 20.0806
2020-11-05 16:36:19,702 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8055 | Iter Mean Loss 11.4430
2020-11-05 16:36:19,707 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6747 | Iter Mean Loss 15.8536
2020-11-05 16:36:19,713 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9716 | Iter Mean Loss 16.1331
2020-11-05 16:36:19,718 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5041 | Iter Mean Loss 13.8073
2020-11-05 16:36:19,718 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.0000 | MSE 0.2048
2020-11-05 16:36:19,724 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0292 | Iter Mean Loss 20.0292
2020-11-05 16:36:19,729 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8020 | Iter Mean Loss 11.4156
2020-11-05 16:36:19,734 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6147 | Iter Mean Loss 15.8153
2020-11-05 16:36:19,740 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9305 | Iter Mean Loss 16.0941
2020-11-05 16:36:19,744 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5031 | Iter Mean Loss 13.7759
2020-11-05 16:36:19,745 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.0000 | MSE 0.2047
2020-11-05 16:36:19,751 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.9783 | Iter Mean Loss 19.9783
2020-11-05 16:36:19,756 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7986 | Iter Mean Loss 11.3884
2020-11-05 16:36:19,762 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5549 | Iter Mean Loss 15.7773
2020-11-05 16:36:19,768 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8895 | Iter Mean Loss 16.0553
2020-11-05 16:36:19,772 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5020 | Iter Mean Loss 13.7447
2020-11-05 16:36:19,773 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.0000 | MSE 0.2047
2020-11-05 16:36:19,779 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.9277 | Iter Mean Loss 19.9277
2020-11-05 16:36:19,785 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7951 | Iter Mean Loss 11.3614
2020-11-05 16:36:19,790 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4955 | Iter Mean Loss 15.7394
2020-11-05 16:36:19,796 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8487 | Iter Mean Loss 16.0167
2020-11-05 16:36:19,801 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5009 | Iter Mean Loss 13.7136
2020-11-05 16:36:19,802 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.0000 | MSE 0.2046
2020-11-05 16:36:19,808 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.8775 | Iter Mean Loss 19.8775
2020-11-05 16:36:19,814 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7917 | Iter Mean Loss 11.3346
2020-11-05 16:36:19,820 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4364 | Iter Mean Loss 15.7018
2020-11-05 16:36:19,825 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8081 | Iter Mean Loss 15.9784
2020-11-05 16:36:19,830 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4999 | Iter Mean Loss 13.6827
2020-11-05 16:36:19,831 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.0000 | MSE 0.2045
2020-11-05 16:36:19,837 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.8276 | Iter Mean Loss 19.8276
2020-11-05 16:36:19,842 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7883 | Iter Mean Loss 11.3079
2020-11-05 16:36:19,848 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.3775 | Iter Mean Loss 15.6645
2020-11-05 16:36:19,853 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7676 | Iter Mean Loss 15.9402
2020-11-05 16:36:19,858 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4987 | Iter Mean Loss 13.6519
2020-11-05 16:36:19,859 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.0000 | MSE 0.2045
2020-11-05 16:36:19,865 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7781 | Iter Mean Loss 19.7781
2020-11-05 16:36:19,871 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7849 | Iter Mean Loss 11.2815
2020-11-05 16:36:19,876 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.3190 | Iter Mean Loss 15.6273
2020-11-05 16:36:19,881 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7272 | Iter Mean Loss 15.9023
2020-11-05 16:36:19,886 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4976 | Iter Mean Loss 13.6214
2020-11-05 16:36:19,887 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.0000 | MSE 0.2044
2020-11-05 16:36:19,892 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7290 | Iter Mean Loss 19.7290
2020-11-05 16:36:19,898 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7815 | Iter Mean Loss 11.2552
2020-11-05 16:36:19,903 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2607 | Iter Mean Loss 15.5904
2020-11-05 16:36:19,908 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6871 | Iter Mean Loss 15.8646
2020-11-05 16:36:19,913 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4964 | Iter Mean Loss 13.5909
2020-11-05 16:36:19,914 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.0000 | MSE 0.2043
2020-11-05 16:36:19,919 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.6802 | Iter Mean Loss 19.6802
2020-11-05 16:36:19,924 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7781 | Iter Mean Loss 11.2292
2020-11-05 16:36:19,930 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2027 | Iter Mean Loss 15.5537
2020-11-05 16:36:19,935 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6470 | Iter Mean Loss 15.8270
2020-11-05 16:36:19,939 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4952 | Iter Mean Loss 13.5607
2020-11-05 16:36:19,940 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.0000 | MSE 0.2042
2020-11-05 16:36:19,946 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.6318 | Iter Mean Loss 19.6318
2020-11-05 16:36:19,951 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7748 | Iter Mean Loss 11.2033
2020-11-05 16:36:19,956 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1450 | Iter Mean Loss 15.5172
2020-11-05 16:36:19,962 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6072 | Iter Mean Loss 15.7897
2020-11-05 16:36:19,967 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4940 | Iter Mean Loss 13.5305
2020-11-05 16:36:19,968 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.0000 | MSE 0.2042
2020-11-05 16:36:19,974 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.5837 | Iter Mean Loss 19.5837
2020-11-05 16:36:19,979 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7714 | Iter Mean Loss 11.1775
2020-11-05 16:36:19,985 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0875 | Iter Mean Loss 15.4809
2020-11-05 16:36:19,991 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5674 | Iter Mean Loss 15.7525
2020-11-05 16:36:19,995 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4927 | Iter Mean Loss 13.5006
2020-11-05 16:36:19,997 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.0000 | MSE 0.2041
2020-11-05 16:36:20,003 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.5359 | Iter Mean Loss 19.5359
2020-11-05 16:36:20,009 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7680 | Iter Mean Loss 11.1520
2020-11-05 16:36:20,014 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0304 | Iter Mean Loss 15.4448
2020-11-05 16:36:20,021 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5279 | Iter Mean Loss 15.7156
2020-11-05 16:36:20,025 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4915 | Iter Mean Loss 13.4707
2020-11-05 16:36:20,026 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.0000 | MSE 0.2040
2020-11-05 16:36:20,033 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4885 | Iter Mean Loss 19.4885
2020-11-05 16:36:20,038 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7647 | Iter Mean Loss 11.1266
2020-11-05 16:36:20,044 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.9735 | Iter Mean Loss 15.4089
2020-11-05 16:36:20,049 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4884 | Iter Mean Loss 15.6788
2020-11-05 16:36:20,054 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4902 | Iter Mean Loss 13.4411
2020-11-05 16:36:20,055 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.0000 | MSE 0.2040
2020-11-05 16:36:20,061 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4414 | Iter Mean Loss 19.4414
2020-11-05 16:36:20,066 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7614 | Iter Mean Loss 11.1014
2020-11-05 16:36:20,072 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.9169 | Iter Mean Loss 15.3732
2020-11-05 16:36:20,077 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4491 | Iter Mean Loss 15.6422
2020-11-05 16:36:20,082 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4889 | Iter Mean Loss 13.4115
2020-11-05 16:36:20,082 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.0000 | MSE 0.2039
2020-11-05 16:36:20,088 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3946 | Iter Mean Loss 19.3946
2020-11-05 16:36:20,093 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7581 | Iter Mean Loss 11.0764
2020-11-05 16:36:20,098 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8605 | Iter Mean Loss 15.3377
2020-11-05 16:36:20,104 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4100 | Iter Mean Loss 15.6058
2020-11-05 16:36:20,108 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4875 | Iter Mean Loss 13.3821
2020-11-05 16:36:20,109 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.0000 | MSE 0.2038
2020-11-05 16:36:20,115 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3482 | Iter Mean Loss 19.3482
2020-11-05 16:36:20,120 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7547 | Iter Mean Loss 11.0515
2020-11-05 16:36:20,125 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8044 | Iter Mean Loss 15.3024
2020-11-05 16:36:20,131 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3710 | Iter Mean Loss 15.5696
2020-11-05 16:36:20,135 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4862 | Iter Mean Loss 13.3529
2020-11-05 16:36:20,136 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.0000 | MSE 0.2038
2020-11-05 16:36:20,141 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3021 | Iter Mean Loss 19.3021
2020-11-05 16:36:20,147 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7514 | Iter Mean Loss 11.0267
2020-11-05 16:36:20,152 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7486 | Iter Mean Loss 15.2673
2020-11-05 16:36:20,157 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3321 | Iter Mean Loss 15.5335
2020-11-05 16:36:20,162 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4848 | Iter Mean Loss 13.3238
2020-11-05 16:36:20,163 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.0000 | MSE 0.2037
2020-11-05 16:36:20,169 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.2562 | Iter Mean Loss 19.2562
2020-11-05 16:36:20,175 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7481 | Iter Mean Loss 11.0022
2020-11-05 16:36:20,180 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6930 | Iter Mean Loss 15.2324
2020-11-05 16:36:20,187 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2934 | Iter Mean Loss 15.4977
2020-11-05 16:36:20,192 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4834 | Iter Mean Loss 13.2948
2020-11-05 16:36:20,193 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.0000 | MSE 0.2037
2020-11-05 16:36:20,198 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.2107 | Iter Mean Loss 19.2107
2020-11-05 16:36:20,205 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7448 | Iter Mean Loss 10.9778
2020-11-05 16:36:20,210 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6376 | Iter Mean Loss 15.1977
2020-11-05 16:36:20,216 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2547 | Iter Mean Loss 15.4620
2020-11-05 16:36:20,221 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4819 | Iter Mean Loss 13.2660
2020-11-05 16:36:20,222 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.0000 | MSE 0.2036
2020-11-05 16:36:20,228 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1655 | Iter Mean Loss 19.1655
2020-11-05 16:36:20,233 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7415 | Iter Mean Loss 10.9535
2020-11-05 16:36:20,239 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.5826 | Iter Mean Loss 15.1632
2020-11-05 16:36:20,244 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2163 | Iter Mean Loss 15.4265
2020-11-05 16:36:20,249 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4805 | Iter Mean Loss 13.2373
2020-11-05 16:36:20,250 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.0000 | MSE 0.2035
2020-11-05 16:36:20,256 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1205 | Iter Mean Loss 19.1205
2020-11-05 16:36:20,262 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7383 | Iter Mean Loss 10.9294
2020-11-05 16:36:20,267 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.5278 | Iter Mean Loss 15.1288
2020-11-05 16:36:20,272 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1779 | Iter Mean Loss 15.3911
2020-11-05 16:36:20,277 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4790 | Iter Mean Loss 13.2087
2020-11-05 16:36:20,278 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.0000 | MSE 0.2035
2020-11-05 16:36:20,283 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.0759 | Iter Mean Loss 19.0759
2020-11-05 16:36:20,289 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7350 | Iter Mean Loss 10.9054
2020-11-05 16:36:20,294 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4732 | Iter Mean Loss 15.0947
2020-11-05 16:36:20,299 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1397 | Iter Mean Loss 15.3559
2020-11-05 16:36:20,304 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4776 | Iter Mean Loss 13.1803
2020-11-05 16:36:20,305 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.0000 | MSE 0.2034
2020-11-05 16:36:20,310 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.0315 | Iter Mean Loss 19.0315
2020-11-05 16:36:20,316 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7317 | Iter Mean Loss 10.8816
2020-11-05 16:36:20,322 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4188 | Iter Mean Loss 15.0607
2020-11-05 16:36:20,327 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1016 | Iter Mean Loss 15.3209
2020-11-05 16:36:20,332 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4761 | Iter Mean Loss 13.1519
2020-11-05 16:36:20,332 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.0000 | MSE 0.2033
2020-11-05 16:36:20,338 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9875 | Iter Mean Loss 18.9875
2020-11-05 16:36:20,343 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7284 | Iter Mean Loss 10.8579
2020-11-05 16:36:20,349 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3648 | Iter Mean Loss 15.0269
2020-11-05 16:36:20,354 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0636 | Iter Mean Loss 15.2861
2020-11-05 16:36:20,359 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4745 | Iter Mean Loss 13.1237
2020-11-05 16:36:20,360 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.0000 | MSE 0.2033
2020-11-05 16:36:20,366 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9437 | Iter Mean Loss 18.9437
2020-11-05 16:36:20,372 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7252 | Iter Mean Loss 10.8344
2020-11-05 16:36:20,377 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3109 | Iter Mean Loss 14.9932
2020-11-05 16:36:20,383 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0257 | Iter Mean Loss 15.2514
2020-11-05 16:36:20,387 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4730 | Iter Mean Loss 13.0957
2020-11-05 16:36:20,388 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.0000 | MSE 0.2032
2020-11-05 16:36:20,395 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9002 | Iter Mean Loss 18.9002
2020-11-05 16:36:20,400 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7219 | Iter Mean Loss 10.8110
2020-11-05 16:36:20,405 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2573 | Iter Mean Loss 14.9598
2020-11-05 16:36:20,412 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9879 | Iter Mean Loss 15.2168
2020-11-05 16:36:20,416 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4714 | Iter Mean Loss 13.0677
2020-11-05 16:36:20,417 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.0000 | MSE 0.2032
2020-11-05 16:36:20,423 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8569 | Iter Mean Loss 18.8569
2020-11-05 16:36:20,429 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7186 | Iter Mean Loss 10.7878
2020-11-05 16:36:20,434 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2039 | Iter Mean Loss 14.9265
2020-11-05 16:36:20,440 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9503 | Iter Mean Loss 15.1824
2020-11-05 16:36:20,445 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4699 | Iter Mean Loss 13.0399
2020-11-05 16:36:20,446 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.0000 | MSE 0.2031
2020-11-05 16:36:20,452 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8140 | Iter Mean Loss 18.8140
2020-11-05 16:36:20,458 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7154 | Iter Mean Loss 10.7647
2020-11-05 16:36:20,464 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.1508 | Iter Mean Loss 14.8934
2020-11-05 16:36:20,469 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9128 | Iter Mean Loss 15.1482
2020-11-05 16:36:20,474 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4683 | Iter Mean Loss 13.0122
2020-11-05 16:36:20,475 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.0000 | MSE 0.2030
2020-11-05 16:36:20,480 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.7713 | Iter Mean Loss 18.7713
2020-11-05 16:36:20,486 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7121 | Iter Mean Loss 10.7417
2020-11-05 16:36:20,491 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0979 | Iter Mean Loss 14.8604
2020-11-05 16:36:20,496 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8753 | Iter Mean Loss 15.1141
2020-11-05 16:36:20,501 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4667 | Iter Mean Loss 12.9846
2020-11-05 16:36:20,501 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.0000 | MSE 0.2030
2020-11-05 16:36:20,507 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.7288 | Iter Mean Loss 18.7288
2020-11-05 16:36:20,512 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7088 | Iter Mean Loss 10.7188
2020-11-05 16:36:20,517 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0452 | Iter Mean Loss 14.8276
2020-11-05 16:36:20,523 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8380 | Iter Mean Loss 15.0802
2020-11-05 16:36:20,527 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4650 | Iter Mean Loss 12.9572
2020-11-05 16:36:20,528 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.0000 | MSE 0.2029
2020-11-05 16:36:20,533 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6866 | Iter Mean Loss 18.6866
2020-11-05 16:36:20,539 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7056 | Iter Mean Loss 10.6961
2020-11-05 16:36:20,544 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9927 | Iter Mean Loss 14.7950
2020-11-05 16:36:20,550 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8008 | Iter Mean Loss 15.0464
2020-11-05 16:36:20,554 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4634 | Iter Mean Loss 12.9298
2020-11-05 16:36:20,555 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.0000 | MSE 0.2029
2020-11-05 16:36:20,561 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6447 | Iter Mean Loss 18.6447
2020-11-05 16:36:20,567 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7023 | Iter Mean Loss 10.6735
2020-11-05 16:36:20,572 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9405 | Iter Mean Loss 14.7625
2020-11-05 16:36:20,578 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7637 | Iter Mean Loss 15.0128
2020-11-05 16:36:20,583 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4617 | Iter Mean Loss 12.9026
2020-11-05 16:36:20,584 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.0000 | MSE 0.2028
2020-11-05 16:36:20,590 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6030 | Iter Mean Loss 18.6030
2020-11-05 16:36:20,596 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6991 | Iter Mean Loss 10.6510
2020-11-05 16:36:20,602 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8885 | Iter Mean Loss 14.7302
2020-11-05 16:36:20,608 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7267 | Iter Mean Loss 14.9793
2020-11-05 16:36:20,613 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4600 | Iter Mean Loss 12.8755
2020-11-05 16:36:20,614 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.0000 | MSE 0.2027
2020-11-05 16:36:20,620 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5616 | Iter Mean Loss 18.5616
2020-11-05 16:36:20,626 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6958 | Iter Mean Loss 10.6287
2020-11-05 16:36:20,632 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8367 | Iter Mean Loss 14.6980
2020-11-05 16:36:20,637 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6898 | Iter Mean Loss 14.9460
2020-11-05 16:36:20,643 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4583 | Iter Mean Loss 12.8484
2020-11-05 16:36:20,644 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.0000 | MSE 0.2027
2020-11-05 16:36:20,649 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5204 | Iter Mean Loss 18.5204
2020-11-05 16:36:20,655 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 10.6065
2020-11-05 16:36:20,661 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7851 | Iter Mean Loss 14.6660
2020-11-05 16:36:20,666 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6530 | Iter Mean Loss 14.9128
2020-11-05 16:36:20,671 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4566 | Iter Mean Loss 12.8215
2020-11-05 16:36:20,672 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.0000 | MSE 0.2026
2020-11-05 16:36:20,678 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.4795 | Iter Mean Loss 18.4795
2020-11-05 16:36:20,683 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 10.5844
2020-11-05 16:36:20,689 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7338 | Iter Mean Loss 14.6342
2020-11-05 16:36:20,695 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6163 | Iter Mean Loss 14.8797
2020-11-05 16:36:20,700 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4549 | Iter Mean Loss 12.7947
2020-11-05 16:36:20,700 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.0000 | MSE 0.2026
2020-11-05 16:36:20,706 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.4388 | Iter Mean Loss 18.4388
2020-11-05 16:36:20,711 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6860 | Iter Mean Loss 10.5624
2020-11-05 16:36:20,717 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.6826 | Iter Mean Loss 14.6025
2020-11-05 16:36:20,722 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5796 | Iter Mean Loss 14.8468
2020-11-05 16:36:20,727 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4531 | Iter Mean Loss 12.7680
2020-11-05 16:36:20,728 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.0000 | MSE 0.2025
2020-11-05 16:36:20,733 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3983 | Iter Mean Loss 18.3983
2020-11-05 16:36:20,738 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 10.5405
2020-11-05 16:36:20,744 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.6317 | Iter Mean Loss 14.5709
2020-11-05 16:36:20,749 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5431 | Iter Mean Loss 14.8140
2020-11-05 16:36:20,754 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4514 | Iter Mean Loss 12.7415
2020-11-05 16:36:20,755 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.0000 | MSE 0.2024
2020-11-05 16:36:20,761 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3581 | Iter Mean Loss 18.3581
2020-11-05 16:36:20,767 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6794 | Iter Mean Loss 10.5188
2020-11-05 16:36:20,773 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5810 | Iter Mean Loss 14.5395
2020-11-05 16:36:20,778 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5067 | Iter Mean Loss 14.7813
2020-11-05 16:36:20,783 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4496 | Iter Mean Loss 12.7150
2020-11-05 16:36:20,784 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.0000 | MSE 0.2024
2020-11-05 16:36:20,790 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3181 | Iter Mean Loss 18.3181
2020-11-05 16:36:20,796 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6762 | Iter Mean Loss 10.4971
2020-11-05 16:36:20,801 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5305 | Iter Mean Loss 14.5083
2020-11-05 16:36:20,807 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4703 | Iter Mean Loss 14.7488
2020-11-05 16:36:20,813 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 12.6886
2020-11-05 16:36:20,813 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.0000 | MSE 0.2023
2020-11-05 16:36:20,819 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2784 | Iter Mean Loss 18.2784
2020-11-05 16:36:20,825 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6729 | Iter Mean Loss 10.4756
2020-11-05 16:36:20,831 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4802 | Iter Mean Loss 14.4771
2020-11-05 16:36:20,837 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4341 | Iter Mean Loss 14.7164
2020-11-05 16:36:20,842 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4460 | Iter Mean Loss 12.6623
2020-11-05 16:36:20,843 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.0000 | MSE 0.2023
2020-11-05 16:36:20,848 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2388 | Iter Mean Loss 18.2388
2020-11-05 16:36:20,854 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6696 | Iter Mean Loss 10.4542
2020-11-05 16:36:20,859 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4300 | Iter Mean Loss 14.4462
2020-11-05 16:36:20,865 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3979 | Iter Mean Loss 14.6841
2020-11-05 16:36:20,870 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4442 | Iter Mean Loss 12.6361
2020-11-05 16:36:20,871 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.0000 | MSE 0.2022
2020-11-05 16:36:20,877 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1995 | Iter Mean Loss 18.1995
2020-11-05 16:36:20,882 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6663 | Iter Mean Loss 10.4329
2020-11-05 16:36:20,887 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3801 | Iter Mean Loss 14.4153
2020-11-05 16:36:20,893 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3618 | Iter Mean Loss 14.6519
2020-11-05 16:36:20,897 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4423 | Iter Mean Loss 12.6100
2020-11-05 16:36:20,898 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.0000 | MSE 0.2022
2020-11-05 16:36:20,903 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1604 | Iter Mean Loss 18.1604
2020-11-05 16:36:20,909 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6630 | Iter Mean Loss 10.4117
2020-11-05 16:36:20,914 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3304 | Iter Mean Loss 14.3846
2020-11-05 16:36:20,919 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3258 | Iter Mean Loss 14.6199
2020-11-05 16:36:20,924 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4405 | Iter Mean Loss 12.5840
2020-11-05 16:36:20,925 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.0000 | MSE 0.2021
2020-11-05 16:36:20,930 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1216 | Iter Mean Loss 18.1216
2020-11-05 16:36:20,935 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6597 | Iter Mean Loss 10.3906
2020-11-05 16:36:20,941 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2809 | Iter Mean Loss 14.3541
2020-11-05 16:36:20,946 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2899 | Iter Mean Loss 14.5880
2020-11-05 16:36:20,950 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4386 | Iter Mean Loss 12.5581
2020-11-05 16:36:20,951 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.0000 | MSE 0.2020
2020-11-05 16:36:20,957 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0829 | Iter Mean Loss 18.0829
2020-11-05 16:36:20,962 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6564 | Iter Mean Loss 10.3696
2020-11-05 16:36:20,967 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2316 | Iter Mean Loss 14.3236
2020-11-05 16:36:20,973 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2540 | Iter Mean Loss 14.5562
2020-11-05 16:36:20,978 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4367 | Iter Mean Loss 12.5323
2020-11-05 16:36:20,979 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.0000 | MSE 0.2020
2020-11-05 16:36:20,985 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0445 | Iter Mean Loss 18.0445
2020-11-05 16:36:20,990 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6531 | Iter Mean Loss 10.3488
2020-11-05 16:36:20,995 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.1825 | Iter Mean Loss 14.2933
2020-11-05 16:36:21,001 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2182 | Iter Mean Loss 14.5246
2020-11-05 16:36:21,006 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4348 | Iter Mean Loss 12.5066
2020-11-05 16:36:21,007 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.0000 | MSE 0.2019
2020-11-05 16:36:21,013 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0062 | Iter Mean Loss 18.0062
2020-11-05 16:36:21,019 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6497 | Iter Mean Loss 10.3280
2020-11-05 16:36:21,025 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.1336 | Iter Mean Loss 14.2632
2020-11-05 16:36:21,030 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1825 | Iter Mean Loss 14.4930
2020-11-05 16:36:21,035 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4329 | Iter Mean Loss 12.4810
2020-11-05 16:36:21,037 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.0000 | MSE 0.2019
2020-11-05 16:36:21,043 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.9682 | Iter Mean Loss 17.9682
2020-11-05 16:36:21,048 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6464 | Iter Mean Loss 10.3073
2020-11-05 16:36:21,054 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0848 | Iter Mean Loss 14.2331
2020-11-05 16:36:21,060 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1469 | Iter Mean Loss 14.4616
2020-11-05 16:36:21,065 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4310 | Iter Mean Loss 12.4555
2020-11-05 16:36:21,065 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.0000 | MSE 0.2018
2020-11-05 16:36:21,072 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.9304 | Iter Mean Loss 17.9304
2020-11-05 16:36:21,077 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6431 | Iter Mean Loss 10.2867
2020-11-05 16:36:21,083 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0363 | Iter Mean Loss 14.2032
2020-11-05 16:36:21,088 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1113 | Iter Mean Loss 14.4303
2020-11-05 16:36:21,092 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4290 | Iter Mean Loss 12.4300
2020-11-05 16:36:21,093 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.0000 | MSE 0.2018
2020-11-05 16:36:21,099 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8927 | Iter Mean Loss 17.8927
2020-11-05 16:36:21,104 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6397 | Iter Mean Loss 10.2662
2020-11-05 16:36:21,109 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9879 | Iter Mean Loss 14.1735
2020-11-05 16:36:21,115 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0758 | Iter Mean Loss 14.3991
2020-11-05 16:36:21,119 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4270 | Iter Mean Loss 12.4047
2020-11-05 16:36:21,120 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.0000 | MSE 0.2017
2020-11-05 16:36:21,126 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8553 | Iter Mean Loss 17.8553
2020-11-05 16:36:21,131 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6364 | Iter Mean Loss 10.2459
2020-11-05 16:36:21,136 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9398 | Iter Mean Loss 14.1438
2020-11-05 16:36:21,142 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0404 | Iter Mean Loss 14.3680
2020-11-05 16:36:21,147 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4251 | Iter Mean Loss 12.3794
2020-11-05 16:36:21,148 - root - INFO - Evaluate: Epoch 0285 | NDCG 0.0000 | MSE 0.2017
2020-11-05 16:36:21,153 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8181 | Iter Mean Loss 17.8181
2020-11-05 16:36:21,159 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6330 | Iter Mean Loss 10.2256
2020-11-05 16:36:21,164 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8918 | Iter Mean Loss 14.1143
2020-11-05 16:36:21,169 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0050 | Iter Mean Loss 14.3370
2020-11-05 16:36:21,174 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4231 | Iter Mean Loss 12.3542
2020-11-05 16:36:21,175 - root - INFO - Evaluate: Epoch 0286 | NDCG 0.0000 | MSE 0.2016
2020-11-05 16:36:21,180 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7811 | Iter Mean Loss 17.7811
2020-11-05 16:36:21,186 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6297 | Iter Mean Loss 10.2054
2020-11-05 16:36:21,192 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8440 | Iter Mean Loss 14.0849
2020-11-05 16:36:21,198 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9697 | Iter Mean Loss 14.3061
2020-11-05 16:36:21,203 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4211 | Iter Mean Loss 12.3291
2020-11-05 16:36:21,204 - root - INFO - Evaluate: Epoch 0287 | NDCG 0.0000 | MSE 0.2015
2020-11-05 16:36:21,209 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7442 | Iter Mean Loss 17.7442
2020-11-05 16:36:21,215 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6263 | Iter Mean Loss 10.1853
2020-11-05 16:36:21,221 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7964 | Iter Mean Loss 14.0556
2020-11-05 16:36:21,226 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9345 | Iter Mean Loss 14.2753
2020-11-05 16:36:21,232 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4190 | Iter Mean Loss 12.3041
2020-11-05 16:36:21,233 - root - INFO - Evaluate: Epoch 0288 | NDCG 0.0000 | MSE 0.2015
2020-11-05 16:36:21,238 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7076 | Iter Mean Loss 17.7076
2020-11-05 16:36:21,244 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6229 | Iter Mean Loss 10.1652
2020-11-05 16:36:21,250 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7489 | Iter Mean Loss 14.0265
2020-11-05 16:36:21,255 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8993 | Iter Mean Loss 14.2447
2020-11-05 16:36:21,260 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4170 | Iter Mean Loss 12.2791
2020-11-05 16:36:21,261 - root - INFO - Evaluate: Epoch 0289 | NDCG 0.0000 | MSE 0.2014
2020-11-05 16:36:21,266 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.6711 | Iter Mean Loss 17.6711
2020-11-05 16:36:21,272 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6195 | Iter Mean Loss 10.1453
2020-11-05 16:36:21,278 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7016 | Iter Mean Loss 13.9974
2020-11-05 16:36:21,283 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8642 | Iter Mean Loss 14.2141
2020-11-05 16:36:21,288 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4149 | Iter Mean Loss 12.2543
2020-11-05 16:36:21,289 - root - INFO - Evaluate: Epoch 0290 | NDCG 0.0000 | MSE 0.2014
2020-11-05 16:36:21,294 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.6349 | Iter Mean Loss 17.6349
2020-11-05 16:36:21,299 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6161 | Iter Mean Loss 10.1255
2020-11-05 16:36:21,305 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6545 | Iter Mean Loss 13.9685
2020-11-05 16:36:21,310 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8292 | Iter Mean Loss 14.1837
2020-11-05 16:36:21,315 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4129 | Iter Mean Loss 12.2295
2020-11-05 16:36:21,316 - root - INFO - Evaluate: Epoch 0291 | NDCG 0.0000 | MSE 0.2013
2020-11-05 16:36:21,322 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5988 | Iter Mean Loss 17.5988
2020-11-05 16:36:21,328 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6127 | Iter Mean Loss 10.1057
2020-11-05 16:36:21,334 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6076 | Iter Mean Loss 13.9397
2020-11-05 16:36:21,339 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7942 | Iter Mean Loss 14.1533
2020-11-05 16:36:21,345 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4108 | Iter Mean Loss 12.2048
2020-11-05 16:36:21,345 - root - INFO - Evaluate: Epoch 0292 | NDCG 0.0000 | MSE 0.2013
2020-11-05 16:36:21,351 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5629 | Iter Mean Loss 17.5629
2020-11-05 16:36:21,357 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6092 | Iter Mean Loss 10.0861
2020-11-05 16:36:21,362 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 13.9110
2020-11-05 16:36:21,367 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7592 | Iter Mean Loss 14.1231
2020-11-05 16:36:21,373 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4087 | Iter Mean Loss 12.1802
2020-11-05 16:36:21,373 - root - INFO - Evaluate: Epoch 0293 | NDCG 0.0000 | MSE 0.2012
2020-11-05 16:36:21,379 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5272 | Iter Mean Loss 17.5272
2020-11-05 16:36:21,385 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6058 | Iter Mean Loss 10.0665
2020-11-05 16:36:21,391 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.5143 | Iter Mean Loss 13.8824
2020-11-05 16:36:21,397 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7244 | Iter Mean Loss 14.0929
2020-11-05 16:36:21,402 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4066 | Iter Mean Loss 12.1556
2020-11-05 16:36:21,403 - root - INFO - Evaluate: Epoch 0294 | NDCG 0.0000 | MSE 0.2012
2020-11-05 16:36:21,409 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4917 | Iter Mean Loss 17.4917
2020-11-05 16:36:21,414 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6024 | Iter Mean Loss 10.0470
2020-11-05 16:36:21,421 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4679 | Iter Mean Loss 13.8540
2020-11-05 16:36:21,426 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6895 | Iter Mean Loss 14.0629
2020-11-05 16:36:21,432 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4044 | Iter Mean Loss 12.1312
2020-11-05 16:36:21,434 - root - INFO - Evaluate: Epoch 0295 | NDCG 0.0000 | MSE 0.2011
2020-11-05 16:36:21,439 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4563 | Iter Mean Loss 17.4563
2020-11-05 16:36:21,445 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5989 | Iter Mean Loss 10.0276
2020-11-05 16:36:21,450 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4216 | Iter Mean Loss 13.8256
2020-11-05 16:36:21,457 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6548 | Iter Mean Loss 14.0329
2020-11-05 16:36:21,462 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4023 | Iter Mean Loss 12.1068
2020-11-05 16:36:21,463 - root - INFO - Evaluate: Epoch 0296 | NDCG 0.0000 | MSE 0.2011
2020-11-05 16:36:21,469 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4211 | Iter Mean Loss 17.4211
2020-11-05 16:36:21,475 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5954 | Iter Mean Loss 10.0083
2020-11-05 16:36:21,480 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3755 | Iter Mean Loss 13.7974
2020-11-05 16:36:21,486 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6200 | Iter Mean Loss 14.0030
2020-11-05 16:36:21,490 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 12.0824
2020-11-05 16:36:21,491 - root - INFO - Evaluate: Epoch 0297 | NDCG 0.0000 | MSE 0.2010
2020-11-05 16:36:21,497 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3861 | Iter Mean Loss 17.3861
2020-11-05 16:36:21,503 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5919 | Iter Mean Loss 9.9890
2020-11-05 16:36:21,508 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3296 | Iter Mean Loss 13.7692
2020-11-05 16:36:21,514 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5854 | Iter Mean Loss 13.9733
2020-11-05 16:36:21,518 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3980 | Iter Mean Loss 12.0582
2020-11-05 16:36:21,519 - root - INFO - Evaluate: Epoch 0298 | NDCG 0.0000 | MSE 0.2009
2020-11-05 16:36:21,525 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3513 | Iter Mean Loss 17.3513
2020-11-05 16:36:21,530 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5884 | Iter Mean Loss 9.9698
2020-11-05 16:36:21,536 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2839 | Iter Mean Loss 13.7412
2020-11-05 16:36:21,541 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5507 | Iter Mean Loss 13.9436
2020-11-05 16:36:21,546 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3958 | Iter Mean Loss 12.0340
2020-11-05 16:36:21,546 - root - INFO - Evaluate: Epoch 0299 | NDCG 0.0000 | MSE 0.2009
2020-11-05 16:36:21,552 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3166 | Iter Mean Loss 17.3166
2020-11-05 16:36:21,557 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5849 | Iter Mean Loss 9.9508
2020-11-05 16:36:21,562 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2383 | Iter Mean Loss 13.7133
2020-11-05 16:36:21,568 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5162 | Iter Mean Loss 13.9140
2020-11-05 16:36:21,572 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3936 | Iter Mean Loss 12.0099
2020-11-05 16:36:21,573 - root - INFO - Evaluate: Epoch 0300 | NDCG 0.0000 | MSE 0.2008
2020-11-05 16:36:21,579 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2821 | Iter Mean Loss 17.2821
2020-11-05 16:36:21,584 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5814 | Iter Mean Loss 9.9317
2020-11-05 16:36:21,590 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1928 | Iter Mean Loss 13.6854
2020-11-05 16:36:21,596 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4816 | Iter Mean Loss 13.8845
2020-11-05 16:36:21,600 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 11.9859
2020-11-05 16:36:21,601 - root - INFO - Evaluate: Epoch 0301 | NDCG 0.0000 | MSE 0.2008
2020-11-05 16:36:21,607 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2478 | Iter Mean Loss 17.2478
2020-11-05 16:36:21,614 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5779 | Iter Mean Loss 9.9128
2020-11-05 16:36:21,620 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1476 | Iter Mean Loss 13.6577
2020-11-05 16:36:21,627 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4472 | Iter Mean Loss 13.8551
2020-11-05 16:36:21,632 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3891 | Iter Mean Loss 11.9619
2020-11-05 16:36:21,633 - root - INFO - Evaluate: Epoch 0302 | NDCG 0.0000 | MSE 0.2007
2020-11-05 16:36:21,640 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2136 | Iter Mean Loss 17.2136
2020-11-05 16:36:21,647 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5743 | Iter Mean Loss 9.8940
2020-11-05 16:36:21,653 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1025 | Iter Mean Loss 13.6301
2020-11-05 16:36:21,659 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4127 | Iter Mean Loss 13.8258
2020-11-05 16:36:21,664 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3868 | Iter Mean Loss 11.9380
2020-11-05 16:36:21,665 - root - INFO - Evaluate: Epoch 0303 | NDCG 0.0000 | MSE 0.2007
2020-11-05 16:36:21,672 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1796 | Iter Mean Loss 17.1796
2020-11-05 16:36:21,678 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5708 | Iter Mean Loss 9.8752
2020-11-05 16:36:21,684 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0575 | Iter Mean Loss 13.6026
2020-11-05 16:36:21,690 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3783 | Iter Mean Loss 13.7965
2020-11-05 16:36:21,695 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3846 | Iter Mean Loss 11.9141
2020-11-05 16:36:21,696 - root - INFO - Evaluate: Epoch 0304 | NDCG 0.0000 | MSE 0.2006
2020-11-05 16:36:21,702 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1457 | Iter Mean Loss 17.1457
2020-11-05 16:36:21,708 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5672 | Iter Mean Loss 9.8565
2020-11-05 16:36:21,714 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0127 | Iter Mean Loss 13.5752
2020-11-05 16:36:21,720 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3440 | Iter Mean Loss 13.7674
2020-11-05 16:36:21,725 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3823 | Iter Mean Loss 11.8904
2020-11-05 16:36:21,726 - root - INFO - Evaluate: Epoch 0305 | NDCG 0.0000 | MSE 0.2006
2020-11-05 16:36:21,732 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1120 | Iter Mean Loss 17.1120
2020-11-05 16:36:21,738 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5636 | Iter Mean Loss 9.8378
2020-11-05 16:36:21,743 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9681 | Iter Mean Loss 13.5479
2020-11-05 16:36:21,749 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3097 | Iter Mean Loss 13.7383
2020-11-05 16:36:21,754 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3800 | Iter Mean Loss 11.8667
2020-11-05 16:36:21,755 - root - INFO - Evaluate: Epoch 0306 | NDCG 0.0000 | MSE 0.2005
2020-11-05 16:36:21,761 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0785 | Iter Mean Loss 17.0785
2020-11-05 16:36:21,766 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5600 | Iter Mean Loss 9.8192
2020-11-05 16:36:21,772 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9236 | Iter Mean Loss 13.5207
2020-11-05 16:36:21,778 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2754 | Iter Mean Loss 13.7094
2020-11-05 16:36:21,783 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3777 | Iter Mean Loss 11.8430
2020-11-05 16:36:21,785 - root - INFO - Evaluate: Epoch 0307 | NDCG 0.0000 | MSE 0.2005
2020-11-05 16:36:21,791 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0451 | Iter Mean Loss 17.0451
2020-11-05 16:36:21,797 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5564 | Iter Mean Loss 9.8008
2020-11-05 16:36:21,803 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8792 | Iter Mean Loss 13.4936
2020-11-05 16:36:21,810 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2412 | Iter Mean Loss 13.6805
2020-11-05 16:36:21,815 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3754 | Iter Mean Loss 11.8195
2020-11-05 16:36:21,816 - root - INFO - Evaluate: Epoch 0308 | NDCG 0.0000 | MSE 0.2004
2020-11-05 16:36:21,823 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0119 | Iter Mean Loss 17.0119
2020-11-05 16:36:21,829 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5528 | Iter Mean Loss 9.7823
2020-11-05 16:36:21,835 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8350 | Iter Mean Loss 13.4666
2020-11-05 16:36:21,842 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2070 | Iter Mean Loss 13.6517
2020-11-05 16:36:21,847 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3730 | Iter Mean Loss 11.7959
2020-11-05 16:36:21,848 - root - INFO - Evaluate: Epoch 0309 | NDCG 0.0000 | MSE 0.2004
2020-11-05 16:36:21,855 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9788 | Iter Mean Loss 16.9788
2020-11-05 16:36:21,861 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5491 | Iter Mean Loss 9.7640
2020-11-05 16:36:21,866 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7910 | Iter Mean Loss 13.4396
2020-11-05 16:36:21,872 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1729 | Iter Mean Loss 13.6229
2020-11-05 16:36:21,878 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3707 | Iter Mean Loss 11.7725
2020-11-05 16:36:21,879 - root - INFO - Evaluate: Epoch 0310 | NDCG 0.0000 | MSE 0.2003
2020-11-05 16:36:21,885 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9459 | Iter Mean Loss 16.9459
2020-11-05 16:36:21,891 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5455 | Iter Mean Loss 9.7457
2020-11-05 16:36:21,897 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7471 | Iter Mean Loss 13.4128
2020-11-05 16:36:21,903 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1388 | Iter Mean Loss 13.5943
2020-11-05 16:36:21,908 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3683 | Iter Mean Loss 11.7491
2020-11-05 16:36:21,909 - root - INFO - Evaluate: Epoch 0311 | NDCG 0.0000 | MSE 0.2002
2020-11-05 16:36:21,915 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9131 | Iter Mean Loss 16.9131
2020-11-05 16:36:21,921 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5418 | Iter Mean Loss 9.7275
2020-11-05 16:36:21,926 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7033 | Iter Mean Loss 13.3861
2020-11-05 16:36:21,932 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1047 | Iter Mean Loss 13.5657
2020-11-05 16:36:21,937 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3659 | Iter Mean Loss 11.7258
2020-11-05 16:36:21,938 - root - INFO - Evaluate: Epoch 0312 | NDCG 0.0000 | MSE 0.2002
2020-11-05 16:36:21,943 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8805 | Iter Mean Loss 16.8805
2020-11-05 16:36:21,949 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5381 | Iter Mean Loss 9.7093
2020-11-05 16:36:21,955 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.6597 | Iter Mean Loss 13.3594
2020-11-05 16:36:21,961 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0707 | Iter Mean Loss 13.5373
2020-11-05 16:36:21,966 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3635 | Iter Mean Loss 11.7025
2020-11-05 16:36:21,967 - root - INFO - Evaluate: Epoch 0313 | NDCG 0.0000 | MSE 0.2001
2020-11-05 16:36:21,972 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8481 | Iter Mean Loss 16.8481
2020-11-05 16:36:21,978 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5344 | Iter Mean Loss 9.6912
2020-11-05 16:36:21,984 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.6162 | Iter Mean Loss 13.3329
2020-11-05 16:36:21,991 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0368 | Iter Mean Loss 13.5089
2020-11-05 16:36:21,997 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3611 | Iter Mean Loss 11.6793
2020-11-05 16:36:21,998 - root - INFO - Evaluate: Epoch 0314 | NDCG 0.0000 | MSE 0.2001
2020-11-05 16:36:22,004 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8157 | Iter Mean Loss 16.8157
2020-11-05 16:36:22,011 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5307 | Iter Mean Loss 9.6732
2020-11-05 16:36:22,017 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5729 | Iter Mean Loss 13.3064
2020-11-05 16:36:22,024 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0028 | Iter Mean Loss 13.4805
2020-11-05 16:36:22,030 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3586 | Iter Mean Loss 11.6562
2020-11-05 16:36:22,031 - root - INFO - Evaluate: Epoch 0315 | NDCG 0.0000 | MSE 0.2000
2020-11-05 16:36:22,037 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7835 | Iter Mean Loss 16.7835
2020-11-05 16:36:22,044 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5270 | Iter Mean Loss 9.6552
2020-11-05 16:36:22,050 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5297 | Iter Mean Loss 13.2801
2020-11-05 16:36:22,056 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9689 | Iter Mean Loss 13.4523
2020-11-05 16:36:22,062 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3562 | Iter Mean Loss 11.6331
2020-11-05 16:36:22,063 - root - INFO - Evaluate: Epoch 0316 | NDCG 0.0000 | MSE 0.2000
2020-11-05 16:36:22,070 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7515 | Iter Mean Loss 16.7515
2020-11-05 16:36:22,077 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5232 | Iter Mean Loss 9.6374
2020-11-05 16:36:22,083 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4867 | Iter Mean Loss 13.2538
2020-11-05 16:36:22,089 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9351 | Iter Mean Loss 13.4241
2020-11-05 16:36:22,095 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3537 | Iter Mean Loss 11.6100
2020-11-05 16:36:22,096 - root - INFO - Evaluate: Epoch 0317 | NDCG 0.0000 | MSE 0.1999
2020-11-05 16:36:22,102 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7196 | Iter Mean Loss 16.7196
2020-11-05 16:36:22,108 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5195 | Iter Mean Loss 9.6195
2020-11-05 16:36:22,114 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4438 | Iter Mean Loss 13.2276
2020-11-05 16:36:22,120 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9012 | Iter Mean Loss 13.3960
2020-11-05 16:36:22,125 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3513 | Iter Mean Loss 11.5871
2020-11-05 16:36:22,126 - root - INFO - Evaluate: Epoch 0318 | NDCG 0.0000 | MSE 0.1999
2020-11-05 16:36:22,132 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6878 | Iter Mean Loss 16.6878
2020-11-05 16:36:22,139 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5157 | Iter Mean Loss 9.6018
2020-11-05 16:36:22,145 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4010 | Iter Mean Loss 13.2015
2020-11-05 16:36:22,150 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8675 | Iter Mean Loss 13.3680
2020-11-05 16:36:22,155 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3488 | Iter Mean Loss 11.5641
2020-11-05 16:36:22,156 - root - INFO - Evaluate: Epoch 0319 | NDCG 0.0000 | MSE 0.1998
2020-11-05 16:36:22,162 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6562 | Iter Mean Loss 16.6562
2020-11-05 16:36:22,168 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5119 | Iter Mean Loss 9.5840
2020-11-05 16:36:22,174 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3584 | Iter Mean Loss 13.1755
2020-11-05 16:36:22,179 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8337 | Iter Mean Loss 13.3400
2020-11-05 16:36:22,184 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3463 | Iter Mean Loss 11.5413
2020-11-05 16:36:22,186 - root - INFO - Evaluate: Epoch 0320 | NDCG 0.0000 | MSE 0.1998
2020-11-05 16:36:22,192 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6247 | Iter Mean Loss 16.6247
2020-11-05 16:36:22,198 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5081 | Iter Mean Loss 9.5664
2020-11-05 16:36:22,204 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3159 | Iter Mean Loss 13.1496
2020-11-05 16:36:22,210 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8000 | Iter Mean Loss 13.3122
2020-11-05 16:36:22,215 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3437 | Iter Mean Loss 11.5185
2020-11-05 16:36:22,216 - root - INFO - Evaluate: Epoch 0321 | NDCG 0.0000 | MSE 0.1997
2020-11-05 16:36:22,223 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5934 | Iter Mean Loss 16.5934
2020-11-05 16:36:22,229 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5043 | Iter Mean Loss 9.5488
2020-11-05 16:36:22,236 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2735 | Iter Mean Loss 13.1237
2020-11-05 16:36:22,242 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7664 | Iter Mean Loss 13.2844
2020-11-05 16:36:22,248 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3412 | Iter Mean Loss 11.4958
2020-11-05 16:36:22,250 - root - INFO - Evaluate: Epoch 0322 | NDCG 0.0000 | MSE 0.1997
2020-11-05 16:36:22,262 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5622 | Iter Mean Loss 16.5622
2020-11-05 16:36:22,272 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5004 | Iter Mean Loss 9.5313
2020-11-05 16:36:22,279 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2313 | Iter Mean Loss 13.0980
2020-11-05 16:36:22,288 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7327 | Iter Mean Loss 13.2567
2020-11-05 16:36:22,293 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3387 | Iter Mean Loss 11.4731
2020-11-05 16:36:22,294 - root - INFO - Evaluate: Epoch 0323 | NDCG 0.0000 | MSE 0.1996
2020-11-05 16:36:22,301 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5311 | Iter Mean Loss 16.5311
2020-11-05 16:36:22,308 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4966 | Iter Mean Loss 9.5138
2020-11-05 16:36:22,315 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1892 | Iter Mean Loss 13.0723
2020-11-05 16:36:22,323 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6992 | Iter Mean Loss 13.2290
2020-11-05 16:36:22,329 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3361 | Iter Mean Loss 11.4504
2020-11-05 16:36:22,330 - root - INFO - Evaluate: Epoch 0324 | NDCG 0.0000 | MSE 0.1995
2020-11-05 16:36:22,338 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5001 | Iter Mean Loss 16.5001
2020-11-05 16:36:22,345 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4927 | Iter Mean Loss 9.4964
2020-11-05 16:36:22,353 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1473 | Iter Mean Loss 13.0467
2020-11-05 16:36:22,360 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6656 | Iter Mean Loss 13.2014
2020-11-05 16:36:22,367 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3335 | Iter Mean Loss 11.4279
2020-11-05 16:36:22,369 - root - INFO - Evaluate: Epoch 0325 | NDCG 0.0000 | MSE 0.1995
2020-11-05 16:36:22,376 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4693 | Iter Mean Loss 16.4693
2020-11-05 16:36:22,383 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4889 | Iter Mean Loss 9.4791
2020-11-05 16:36:22,391 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1055 | Iter Mean Loss 13.0212
2020-11-05 16:36:22,399 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6321 | Iter Mean Loss 13.1739
2020-11-05 16:36:22,405 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3309 | Iter Mean Loss 11.4053
2020-11-05 16:36:22,406 - root - INFO - Evaluate: Epoch 0326 | NDCG 0.0000 | MSE 0.1994
2020-11-05 16:36:22,413 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4386 | Iter Mean Loss 16.4386
2020-11-05 16:36:22,420 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4850 | Iter Mean Loss 9.4618
2020-11-05 16:36:22,427 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0638 | Iter Mean Loss 12.9958
2020-11-05 16:36:22,433 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5986 | Iter Mean Loss 13.1465
2020-11-05 16:36:22,440 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3283 | Iter Mean Loss 11.3829
2020-11-05 16:36:22,441 - root - INFO - Evaluate: Epoch 0327 | NDCG 0.0000 | MSE 0.1994
2020-11-05 16:36:22,447 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4081 | Iter Mean Loss 16.4081
2020-11-05 16:36:22,454 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4811 | Iter Mean Loss 9.4446
2020-11-05 16:36:22,460 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0222 | Iter Mean Loss 12.9705
2020-11-05 16:36:22,466 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5652 | Iter Mean Loss 13.1191
2020-11-05 16:36:22,472 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3257 | Iter Mean Loss 11.3605
2020-11-05 16:36:22,473 - root - INFO - Evaluate: Epoch 0328 | NDCG 0.0000 | MSE 0.1993
2020-11-05 16:36:22,479 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3776 | Iter Mean Loss 16.3776
2020-11-05 16:36:22,485 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4771 | Iter Mean Loss 9.4274
2020-11-05 16:36:22,491 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9808 | Iter Mean Loss 12.9452
2020-11-05 16:36:22,497 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5319 | Iter Mean Loss 13.0919
2020-11-05 16:36:22,502 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3231 | Iter Mean Loss 11.3381
2020-11-05 16:36:22,503 - root - INFO - Evaluate: Epoch 0329 | NDCG 0.0000 | MSE 0.1993
2020-11-05 16:36:22,509 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3473 | Iter Mean Loss 16.3473
2020-11-05 16:36:22,515 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4732 | Iter Mean Loss 9.4103
2020-11-05 16:36:22,522 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9395 | Iter Mean Loss 12.9200
2020-11-05 16:36:22,527 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4985 | Iter Mean Loss 13.0646
2020-11-05 16:36:22,532 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3205 | Iter Mean Loss 11.3158
2020-11-05 16:36:22,533 - root - INFO - Evaluate: Epoch 0330 | NDCG 0.0000 | MSE 0.1992
2020-11-05 16:36:22,539 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3172 | Iter Mean Loss 16.3172
2020-11-05 16:36:22,545 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4693 | Iter Mean Loss 9.3932
2020-11-05 16:36:22,550 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8983 | Iter Mean Loss 12.8949
2020-11-05 16:36:22,556 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4652 | Iter Mean Loss 13.0375
2020-11-05 16:36:22,561 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3178 | Iter Mean Loss 11.2936
2020-11-05 16:36:22,562 - root - INFO - Evaluate: Epoch 0331 | NDCG 0.0000 | MSE 0.1992
2020-11-05 16:36:22,568 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2871 | Iter Mean Loss 16.2871
2020-11-05 16:36:22,573 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4653 | Iter Mean Loss 9.3762
2020-11-05 16:36:22,579 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8573 | Iter Mean Loss 12.8699
2020-11-05 16:36:22,585 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4320 | Iter Mean Loss 13.0104
2020-11-05 16:36:22,590 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 11.2714
2020-11-05 16:36:22,591 - root - INFO - Evaluate: Epoch 0332 | NDCG 0.0000 | MSE 0.1991
2020-11-05 16:36:22,597 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2572 | Iter Mean Loss 16.2572
2020-11-05 16:36:22,603 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4613 | Iter Mean Loss 9.3593
2020-11-05 16:36:22,610 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8164 | Iter Mean Loss 12.8450
2020-11-05 16:36:22,615 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3988 | Iter Mean Loss 12.9834
2020-11-05 16:36:22,621 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3125 | Iter Mean Loss 11.2492
2020-11-05 16:36:22,623 - root - INFO - Evaluate: Epoch 0333 | NDCG 0.0000 | MSE 0.1991
2020-11-05 16:36:22,629 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2274 | Iter Mean Loss 16.2274
2020-11-05 16:36:22,635 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4574 | Iter Mean Loss 9.3424
2020-11-05 16:36:22,642 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7756 | Iter Mean Loss 12.8201
2020-11-05 16:36:22,647 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3657 | Iter Mean Loss 12.9565
2020-11-05 16:36:22,653 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3098 | Iter Mean Loss 11.2272
2020-11-05 16:36:22,655 - root - INFO - Evaluate: Epoch 0334 | NDCG 0.0000 | MSE 0.1990
2020-11-05 16:36:22,661 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1977 | Iter Mean Loss 16.1977
2020-11-05 16:36:22,667 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 9.3255
2020-11-05 16:36:22,673 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7349 | Iter Mean Loss 12.7953
2020-11-05 16:36:22,679 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3326 | Iter Mean Loss 12.9296
2020-11-05 16:36:22,684 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3071 | Iter Mean Loss 11.2051
2020-11-05 16:36:22,685 - root - INFO - Evaluate: Epoch 0335 | NDCG 0.0000 | MSE 0.1990
2020-11-05 16:36:22,691 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1681 | Iter Mean Loss 16.1681
2020-11-05 16:36:22,698 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4494 | Iter Mean Loss 9.3087
2020-11-05 16:36:22,704 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6944 | Iter Mean Loss 12.7706
2020-11-05 16:36:22,710 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2995 | Iter Mean Loss 12.9029
2020-11-05 16:36:22,714 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3044 | Iter Mean Loss 11.1832
2020-11-05 16:36:22,715 - root - INFO - Evaluate: Epoch 0336 | NDCG 0.0000 | MSE 0.1989
2020-11-05 16:36:22,721 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1387 | Iter Mean Loss 16.1387
2020-11-05 16:36:22,728 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4453 | Iter Mean Loss 9.2920
2020-11-05 16:36:22,733 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6540 | Iter Mean Loss 12.7460
2020-11-05 16:36:22,739 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2665 | Iter Mean Loss 12.8761
2020-11-05 16:36:22,744 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3016 | Iter Mean Loss 11.1612
2020-11-05 16:36:22,745 - root - INFO - Evaluate: Epoch 0337 | NDCG 0.0000 | MSE 0.1988
2020-11-05 16:36:22,751 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1094 | Iter Mean Loss 16.1094
2020-11-05 16:36:22,756 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4413 | Iter Mean Loss 9.2753
2020-11-05 16:36:22,762 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6137 | Iter Mean Loss 12.7215
2020-11-05 16:36:22,768 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2336 | Iter Mean Loss 12.8495
2020-11-05 16:36:22,772 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 11.1394
2020-11-05 16:36:22,773 - root - INFO - Evaluate: Epoch 0338 | NDCG 0.0000 | MSE 0.1988
2020-11-05 16:36:22,779 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0802 | Iter Mean Loss 16.0802
2020-11-05 16:36:22,785 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4373 | Iter Mean Loss 9.2587
2020-11-05 16:36:22,790 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5736 | Iter Mean Loss 12.6970
2020-11-05 16:36:22,796 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2007 | Iter Mean Loss 12.8229
2020-11-05 16:36:22,801 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2961 | Iter Mean Loss 11.1176
2020-11-05 16:36:22,803 - root - INFO - Evaluate: Epoch 0339 | NDCG 0.0000 | MSE 0.1987
2020-11-05 16:36:22,809 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0511 | Iter Mean Loss 16.0511
2020-11-05 16:36:22,815 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4332 | Iter Mean Loss 9.2422
2020-11-05 16:36:22,822 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5335 | Iter Mean Loss 12.6726
2020-11-05 16:36:22,827 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1679 | Iter Mean Loss 12.7964
2020-11-05 16:36:22,833 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2934 | Iter Mean Loss 11.0958
2020-11-05 16:36:22,834 - root - INFO - Evaluate: Epoch 0340 | NDCG 0.0000 | MSE 0.1987
2020-11-05 16:36:22,840 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0222 | Iter Mean Loss 16.0222
2020-11-05 16:36:22,846 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4291 | Iter Mean Loss 9.2256
2020-11-05 16:36:22,852 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4936 | Iter Mean Loss 12.6483
2020-11-05 16:36:22,858 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1351 | Iter Mean Loss 12.7700
2020-11-05 16:36:22,863 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2906 | Iter Mean Loss 11.0741
2020-11-05 16:36:22,864 - root - INFO - Evaluate: Epoch 0341 | NDCG 0.0000 | MSE 0.1986
2020-11-05 16:36:22,870 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9933 | Iter Mean Loss 15.9933
2020-11-05 16:36:22,877 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4250 | Iter Mean Loss 9.2092
2020-11-05 16:36:22,883 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4538 | Iter Mean Loss 12.6241
2020-11-05 16:36:22,888 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1024 | Iter Mean Loss 12.7436
2020-11-05 16:36:22,893 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2878 | Iter Mean Loss 11.0525
2020-11-05 16:36:22,895 - root - INFO - Evaluate: Epoch 0342 | NDCG 0.0000 | MSE 0.1986
2020-11-05 16:36:22,901 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9646 | Iter Mean Loss 15.9646
2020-11-05 16:36:22,907 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4210 | Iter Mean Loss 9.1928
2020-11-05 16:36:22,912 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4142 | Iter Mean Loss 12.5999
2020-11-05 16:36:22,918 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0697 | Iter Mean Loss 12.7174
2020-11-05 16:36:22,923 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2850 | Iter Mean Loss 11.0309
2020-11-05 16:36:22,925 - root - INFO - Evaluate: Epoch 0343 | NDCG 0.0000 | MSE 0.1985
2020-11-05 16:36:22,931 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9360 | Iter Mean Loss 15.9360
2020-11-05 16:36:22,936 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4169 | Iter Mean Loss 9.1764
2020-11-05 16:36:22,942 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3746 | Iter Mean Loss 12.5758
2020-11-05 16:36:22,948 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0371 | Iter Mean Loss 12.6911
2020-11-05 16:36:22,952 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2822 | Iter Mean Loss 11.0094
2020-11-05 16:36:22,953 - root - INFO - Evaluate: Epoch 0344 | NDCG 0.0000 | MSE 0.1985
2020-11-05 16:36:22,959 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9075 | Iter Mean Loss 15.9075
2020-11-05 16:36:22,965 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4128 | Iter Mean Loss 9.1601
2020-11-05 16:36:22,971 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3352 | Iter Mean Loss 12.5518
2020-11-05 16:36:22,977 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0046 | Iter Mean Loss 12.6650
2020-11-05 16:36:22,982 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2794 | Iter Mean Loss 10.9879
2020-11-05 16:36:22,983 - root - INFO - Evaluate: Epoch 0345 | NDCG 0.0000 | MSE 0.1984
2020-11-05 16:36:22,988 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8791 | Iter Mean Loss 15.8791
2020-11-05 16:36:22,994 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4086 | Iter Mean Loss 9.1439
2020-11-05 16:36:22,999 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2959 | Iter Mean Loss 12.5279
2020-11-05 16:36:23,005 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9721 | Iter Mean Loss 12.6389
2020-11-05 16:36:23,012 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2766 | Iter Mean Loss 10.9665
2020-11-05 16:36:23,013 - root - INFO - Evaluate: Epoch 0346 | NDCG 0.0000 | MSE 0.1984
2020-11-05 16:36:23,019 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8508 | Iter Mean Loss 15.8508
2020-11-05 16:36:23,026 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4045 | Iter Mean Loss 9.1277
2020-11-05 16:36:23,032 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2567 | Iter Mean Loss 12.5040
2020-11-05 16:36:23,038 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9397 | Iter Mean Loss 12.6129
2020-11-05 16:36:23,044 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2738 | Iter Mean Loss 10.9451
2020-11-05 16:36:23,045 - root - INFO - Evaluate: Epoch 0347 | NDCG 0.0000 | MSE 0.1983
2020-11-05 16:36:23,051 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8227 | Iter Mean Loss 15.8227
2020-11-05 16:36:23,057 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4004 | Iter Mean Loss 9.1115
2020-11-05 16:36:23,064 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2177 | Iter Mean Loss 12.4802
2020-11-05 16:36:23,069 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9074 | Iter Mean Loss 12.5870
2020-11-05 16:36:23,075 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2710 | Iter Mean Loss 10.9238
2020-11-05 16:36:23,076 - root - INFO - Evaluate: Epoch 0348 | NDCG 0.0000 | MSE 0.1983
2020-11-05 16:36:23,082 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7946 | Iter Mean Loss 15.7946
2020-11-05 16:36:23,088 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3962 | Iter Mean Loss 9.0954
2020-11-05 16:36:23,093 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1787 | Iter Mean Loss 12.4565
2020-11-05 16:36:23,099 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8751 | Iter Mean Loss 12.5612
2020-11-05 16:36:23,105 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2681 | Iter Mean Loss 10.9026
2020-11-05 16:36:23,106 - root - INFO - Evaluate: Epoch 0349 | NDCG 0.0000 | MSE 0.1982
2020-11-05 16:36:23,111 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7667 | Iter Mean Loss 15.7667
2020-11-05 16:36:23,117 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3921 | Iter Mean Loss 9.0794
2020-11-05 16:36:23,123 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1399 | Iter Mean Loss 12.4329
2020-11-05 16:36:23,128 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8429 | Iter Mean Loss 12.5354
2020-11-05 16:36:23,133 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2653 | Iter Mean Loss 10.8814
2020-11-05 16:36:23,134 - root - INFO - Evaluate: Epoch 0350 | NDCG 0.0000 | MSE 0.1981
2020-11-05 16:36:23,140 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7389 | Iter Mean Loss 15.7389
2020-11-05 16:36:23,146 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3879 | Iter Mean Loss 9.0634
2020-11-05 16:36:23,151 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1012 | Iter Mean Loss 12.4093
2020-11-05 16:36:23,157 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8108 | Iter Mean Loss 12.5097
2020-11-05 16:36:23,162 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2624 | Iter Mean Loss 10.8602
2020-11-05 16:36:23,163 - root - INFO - Evaluate: Epoch 0351 | NDCG 0.0000 | MSE 0.1981
2020-11-05 16:36:23,168 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7112 | Iter Mean Loss 15.7112
2020-11-05 16:36:23,174 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3838 | Iter Mean Loss 9.0475
2020-11-05 16:36:23,179 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0626 | Iter Mean Loss 12.3858
2020-11-05 16:36:23,185 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7788 | Iter Mean Loss 12.4841
2020-11-05 16:36:23,190 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2595 | Iter Mean Loss 10.8392
2020-11-05 16:36:23,191 - root - INFO - Evaluate: Epoch 0352 | NDCG 0.0000 | MSE 0.1980
2020-11-05 16:36:23,196 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6836 | Iter Mean Loss 15.6836
2020-11-05 16:36:23,202 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3796 | Iter Mean Loss 9.0316
2020-11-05 16:36:23,207 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0241 | Iter Mean Loss 12.3624
2020-11-05 16:36:23,213 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7469 | Iter Mean Loss 12.4585
2020-11-05 16:36:23,219 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2567 | Iter Mean Loss 10.8182
2020-11-05 16:36:23,220 - root - INFO - Evaluate: Epoch 0353 | NDCG 0.0000 | MSE 0.1980
2020-11-05 16:36:23,225 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6561 | Iter Mean Loss 15.6561
2020-11-05 16:36:23,231 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3754 | Iter Mean Loss 9.0158
2020-11-05 16:36:23,237 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9858 | Iter Mean Loss 12.3391
2020-11-05 16:36:23,243 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7150 | Iter Mean Loss 12.4331
2020-11-05 16:36:23,248 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2538 | Iter Mean Loss 10.7972
2020-11-05 16:36:23,250 - root - INFO - Evaluate: Epoch 0354 | NDCG 0.0000 | MSE 0.1979
2020-11-05 16:36:23,256 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6287 | Iter Mean Loss 15.6287
2020-11-05 16:36:23,262 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3713 | Iter Mean Loss 9.0000
2020-11-05 16:36:23,268 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9476 | Iter Mean Loss 12.3158
2020-11-05 16:36:23,274 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6832 | Iter Mean Loss 12.4077
2020-11-05 16:36:23,279 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2509 | Iter Mean Loss 10.7763
2020-11-05 16:36:23,280 - root - INFO - Evaluate: Epoch 0355 | NDCG 0.0000 | MSE 0.1979
2020-11-05 16:36:23,287 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6014 | Iter Mean Loss 15.6014
2020-11-05 16:36:23,292 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3671 | Iter Mean Loss 8.9842
2020-11-05 16:36:23,298 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9095 | Iter Mean Loss 12.2927
2020-11-05 16:36:23,305 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6515 | Iter Mean Loss 12.3824
2020-11-05 16:36:23,309 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2480 | Iter Mean Loss 10.7555
2020-11-05 16:36:23,311 - root - INFO - Evaluate: Epoch 0356 | NDCG 0.0000 | MSE 0.1978
2020-11-05 16:36:23,316 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5743 | Iter Mean Loss 15.5743
2020-11-05 16:36:23,322 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3629 | Iter Mean Loss 8.9686
2020-11-05 16:36:23,328 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8715 | Iter Mean Loss 12.2695
2020-11-05 16:36:23,333 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6199 | Iter Mean Loss 12.3571
2020-11-05 16:36:23,338 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2451 | Iter Mean Loss 10.7347
2020-11-05 16:36:23,339 - root - INFO - Evaluate: Epoch 0357 | NDCG 0.0000 | MSE 0.1978
2020-11-05 16:36:23,344 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5472 | Iter Mean Loss 15.5472
2020-11-05 16:36:23,350 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3587 | Iter Mean Loss 8.9529
2020-11-05 16:36:23,355 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8336 | Iter Mean Loss 12.2465
2020-11-05 16:36:23,362 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5884 | Iter Mean Loss 12.3320
2020-11-05 16:36:23,366 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2422 | Iter Mean Loss 10.7140
2020-11-05 16:36:23,367 - root - INFO - Evaluate: Epoch 0358 | NDCG 0.0000 | MSE 0.1977
2020-11-05 16:36:23,373 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5203 | Iter Mean Loss 15.5203
2020-11-05 16:36:23,378 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3545 | Iter Mean Loss 8.9374
2020-11-05 16:36:23,384 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7959 | Iter Mean Loss 12.2235
2020-11-05 16:36:23,389 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5570 | Iter Mean Loss 12.3069
2020-11-05 16:36:23,394 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2393 | Iter Mean Loss 10.6934
2020-11-05 16:36:23,395 - root - INFO - Evaluate: Epoch 0359 | NDCG 0.0000 | MSE 0.1977
2020-11-05 16:36:23,400 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4934 | Iter Mean Loss 15.4934
2020-11-05 16:36:23,406 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3503 | Iter Mean Loss 8.9219
2020-11-05 16:36:23,411 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7582 | Iter Mean Loss 12.2006
2020-11-05 16:36:23,418 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5257 | Iter Mean Loss 12.2819
2020-11-05 16:36:23,423 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 10.6728
2020-11-05 16:36:23,424 - root - INFO - Evaluate: Epoch 0360 | NDCG 0.0000 | MSE 0.1976
2020-11-05 16:36:23,430 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4667 | Iter Mean Loss 15.4667
2020-11-05 16:36:23,437 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3461 | Iter Mean Loss 8.9064
2020-11-05 16:36:23,443 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7207 | Iter Mean Loss 12.1778
2020-11-05 16:36:23,450 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4944 | Iter Mean Loss 12.2570
2020-11-05 16:36:23,456 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2335 | Iter Mean Loss 10.6523
2020-11-05 16:36:23,457 - root - INFO - Evaluate: Epoch 0361 | NDCG 0.0000 | MSE 0.1975
2020-11-05 16:36:23,466 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4400 | Iter Mean Loss 15.4400
2020-11-05 16:36:23,474 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3419 | Iter Mean Loss 8.8910
2020-11-05 16:36:23,481 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6833 | Iter Mean Loss 12.1551
2020-11-05 16:36:23,487 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4633 | Iter Mean Loss 12.2321
2020-11-05 16:36:23,494 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2306 | Iter Mean Loss 10.6318
2020-11-05 16:36:23,495 - root - INFO - Evaluate: Epoch 0362 | NDCG 0.0000 | MSE 0.1975
2020-11-05 16:36:23,504 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4135 | Iter Mean Loss 15.4135
2020-11-05 16:36:23,510 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3377 | Iter Mean Loss 8.8756
2020-11-05 16:36:23,517 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6460 | Iter Mean Loss 12.1324
2020-11-05 16:36:23,524 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4323 | Iter Mean Loss 12.2074
2020-11-05 16:36:23,529 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2276 | Iter Mean Loss 10.6114
2020-11-05 16:36:23,530 - root - INFO - Evaluate: Epoch 0363 | NDCG 0.0000 | MSE 0.1974
2020-11-05 16:36:23,535 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3871 | Iter Mean Loss 15.3871
2020-11-05 16:36:23,542 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 8.8603
2020-11-05 16:36:23,550 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6089 | Iter Mean Loss 12.1098
2020-11-05 16:36:23,557 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4014 | Iter Mean Loss 12.1827
2020-11-05 16:36:23,563 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2247 | Iter Mean Loss 10.5911
2020-11-05 16:36:23,564 - root - INFO - Evaluate: Epoch 0364 | NDCG 0.0000 | MSE 0.1974
2020-11-05 16:36:23,571 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3608 | Iter Mean Loss 15.3608
2020-11-05 16:36:23,577 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3293 | Iter Mean Loss 8.8450
2020-11-05 16:36:23,583 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5718 | Iter Mean Loss 12.0873
2020-11-05 16:36:23,589 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3706 | Iter Mean Loss 12.1581
2020-11-05 16:36:23,594 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 10.5709
2020-11-05 16:36:23,595 - root - INFO - Evaluate: Epoch 0365 | NDCG 0.0000 | MSE 0.1973
2020-11-05 16:36:23,601 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3346 | Iter Mean Loss 15.3346
2020-11-05 16:36:23,608 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3251 | Iter Mean Loss 8.8298
2020-11-05 16:36:23,614 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5349 | Iter Mean Loss 12.0649
2020-11-05 16:36:23,620 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3399 | Iter Mean Loss 12.1336
2020-11-05 16:36:23,624 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2188 | Iter Mean Loss 10.5507
2020-11-05 16:36:23,625 - root - INFO - Evaluate: Epoch 0366 | NDCG 0.0000 | MSE 0.1973
2020-11-05 16:36:23,631 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3085 | Iter Mean Loss 15.3085
2020-11-05 16:36:23,636 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3209 | Iter Mean Loss 8.8147
2020-11-05 16:36:23,642 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4981 | Iter Mean Loss 12.0425
2020-11-05 16:36:23,647 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3093 | Iter Mean Loss 12.1092
2020-11-05 16:36:23,654 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2159 | Iter Mean Loss 10.5305
2020-11-05 16:36:23,655 - root - INFO - Evaluate: Epoch 0367 | NDCG 0.0000 | MSE 0.1972
2020-11-05 16:36:23,661 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2825 | Iter Mean Loss 15.2825
2020-11-05 16:36:23,666 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3167 | Iter Mean Loss 8.7996
2020-11-05 16:36:23,672 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4613 | Iter Mean Loss 12.0202
2020-11-05 16:36:23,677 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2788 | Iter Mean Loss 12.0848
2020-11-05 16:36:23,682 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2130 | Iter Mean Loss 10.5105
2020-11-05 16:36:23,683 - root - INFO - Evaluate: Epoch 0368 | NDCG 0.0000 | MSE 0.1972
2020-11-05 16:36:23,690 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2566 | Iter Mean Loss 15.2566
2020-11-05 16:36:23,696 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3125 | Iter Mean Loss 8.7846
2020-11-05 16:36:23,703 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4248 | Iter Mean Loss 11.9980
2020-11-05 16:36:23,709 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2485 | Iter Mean Loss 12.0606
2020-11-05 16:36:23,714 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2100 | Iter Mean Loss 10.4905
2020-11-05 16:36:23,715 - root - INFO - Evaluate: Epoch 0369 | NDCG 0.0000 | MSE 0.1971
2020-11-05 16:36:23,721 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2308 | Iter Mean Loss 15.2308
2020-11-05 16:36:23,726 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3084 | Iter Mean Loss 8.7696
2020-11-05 16:36:23,732 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3883 | Iter Mean Loss 11.9758
2020-11-05 16:36:23,737 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2182 | Iter Mean Loss 12.0364
2020-11-05 16:36:23,742 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2071 | Iter Mean Loss 10.4706
2020-11-05 16:36:23,743 - root - INFO - Evaluate: Epoch 0370 | NDCG 0.0000 | MSE 0.1970
2020-11-05 16:36:23,749 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2051 | Iter Mean Loss 15.2051
2020-11-05 16:36:23,754 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3042 | Iter Mean Loss 8.7546
2020-11-05 16:36:23,760 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3519 | Iter Mean Loss 11.9537
2020-11-05 16:36:23,765 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1881 | Iter Mean Loss 12.0123
2020-11-05 16:36:23,770 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2042 | Iter Mean Loss 10.4507
2020-11-05 16:36:23,771 - root - INFO - Evaluate: Epoch 0371 | NDCG 0.0000 | MSE 0.1970
2020-11-05 16:36:23,776 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1795 | Iter Mean Loss 15.1795
2020-11-05 16:36:23,782 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3000 | Iter Mean Loss 8.7397
2020-11-05 16:36:23,788 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3157 | Iter Mean Loss 11.9317
2020-11-05 16:36:23,793 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1581 | Iter Mean Loss 11.9883
2020-11-05 16:36:23,798 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2012 | Iter Mean Loss 10.4309
2020-11-05 16:36:23,798 - root - INFO - Evaluate: Epoch 0372 | NDCG 0.0000 | MSE 0.1969
2020-11-05 16:36:23,804 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1540 | Iter Mean Loss 15.1540
2020-11-05 16:36:23,810 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2958 | Iter Mean Loss 8.7249
2020-11-05 16:36:23,815 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2796 | Iter Mean Loss 11.9098
2020-11-05 16:36:23,821 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1283 | Iter Mean Loss 11.9644
2020-11-05 16:36:23,826 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1983 | Iter Mean Loss 10.4112
2020-11-05 16:36:23,827 - root - INFO - Evaluate: Epoch 0373 | NDCG 0.0000 | MSE 0.1969
2020-11-05 16:36:23,833 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1286 | Iter Mean Loss 15.1286
2020-11-05 16:36:23,838 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 8.7101
2020-11-05 16:36:23,846 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.8879
2020-11-05 16:36:23,852 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0985 | Iter Mean Loss 11.9406
2020-11-05 16:36:23,857 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1954 | Iter Mean Loss 10.3915
2020-11-05 16:36:23,858 - root - INFO - Evaluate: Epoch 0374 | NDCG 0.0000 | MSE 0.1968
2020-11-05 16:36:23,864 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1033 | Iter Mean Loss 15.1033
2020-11-05 16:36:23,870 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2875 | Iter Mean Loss 8.6954
2020-11-05 16:36:23,877 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2077 | Iter Mean Loss 11.8661
2020-11-05 16:36:23,884 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0689 | Iter Mean Loss 11.9168
2020-11-05 16:36:23,889 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1924 | Iter Mean Loss 10.3720
2020-11-05 16:36:23,890 - root - INFO - Evaluate: Epoch 0375 | NDCG 0.0000 | MSE 0.1968
2020-11-05 16:36:23,896 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0781 | Iter Mean Loss 15.0781
2020-11-05 16:36:23,902 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2833 | Iter Mean Loss 8.6807
2020-11-05 16:36:23,908 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1719 | Iter Mean Loss 11.8444
2020-11-05 16:36:23,914 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0395 | Iter Mean Loss 11.8932
2020-11-05 16:36:23,919 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1895 | Iter Mean Loss 10.3525
2020-11-05 16:36:23,920 - root - INFO - Evaluate: Epoch 0376 | NDCG 0.0000 | MSE 0.1967
2020-11-05 16:36:23,926 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0530 | Iter Mean Loss 15.0530
2020-11-05 16:36:23,932 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2792 | Iter Mean Loss 8.6661
2020-11-05 16:36:23,937 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1362 | Iter Mean Loss 11.8228
2020-11-05 16:36:23,943 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0101 | Iter Mean Loss 11.8696
2020-11-05 16:36:23,948 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1866 | Iter Mean Loss 10.3330
2020-11-05 16:36:23,949 - root - INFO - Evaluate: Epoch 0377 | NDCG 0.0000 | MSE 0.1967
2020-11-05 16:36:23,955 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0280 | Iter Mean Loss 15.0280
2020-11-05 16:36:23,961 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2750 | Iter Mean Loss 8.6515
2020-11-05 16:36:23,966 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1007 | Iter Mean Loss 11.8012
2020-11-05 16:36:23,972 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9809 | Iter Mean Loss 11.8462
2020-11-05 16:36:23,977 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 10.3137
2020-11-05 16:36:23,978 - root - INFO - Evaluate: Epoch 0378 | NDCG 0.0000 | MSE 0.1966
2020-11-05 16:36:23,984 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0031 | Iter Mean Loss 15.0031
2020-11-05 16:36:23,990 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2709 | Iter Mean Loss 8.6370
2020-11-05 16:36:23,995 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 11.7798
2020-11-05 16:36:24,001 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9519 | Iter Mean Loss 11.8228
2020-11-05 16:36:24,006 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1807 | Iter Mean Loss 10.2944
2020-11-05 16:36:24,007 - root - INFO - Evaluate: Epoch 0379 | NDCG 0.0000 | MSE 0.1965
2020-11-05 16:36:24,013 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9784 | Iter Mean Loss 14.9784
2020-11-05 16:36:24,019 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2668 | Iter Mean Loss 8.6226
2020-11-05 16:36:24,027 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0299 | Iter Mean Loss 11.7583
2020-11-05 16:36:24,033 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9229 | Iter Mean Loss 11.7995
2020-11-05 16:36:24,038 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1778 | Iter Mean Loss 10.2752
2020-11-05 16:36:24,039 - root - INFO - Evaluate: Epoch 0380 | NDCG 0.0000 | MSE 0.1965
2020-11-05 16:36:24,045 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9537 | Iter Mean Loss 14.9537
2020-11-05 16:36:24,051 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2627 | Iter Mean Loss 8.6082
2020-11-05 16:36:24,058 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9947 | Iter Mean Loss 11.7370
2020-11-05 16:36:24,064 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8941 | Iter Mean Loss 11.7763
2020-11-05 16:36:24,070 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1749 | Iter Mean Loss 10.2560
2020-11-05 16:36:24,071 - root - INFO - Evaluate: Epoch 0381 | NDCG 0.0000 | MSE 0.1964
2020-11-05 16:36:24,076 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9291 | Iter Mean Loss 14.9291
2020-11-05 16:36:24,082 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2586 | Iter Mean Loss 8.5938
2020-11-05 16:36:24,088 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9596 | Iter Mean Loss 11.7157
2020-11-05 16:36:24,095 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8655 | Iter Mean Loss 11.7532
2020-11-05 16:36:24,101 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1720 | Iter Mean Loss 10.2369
2020-11-05 16:36:24,102 - root - INFO - Evaluate: Epoch 0382 | NDCG 0.0000 | MSE 0.1964
2020-11-05 16:36:24,108 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9046 | Iter Mean Loss 14.9046
2020-11-05 16:36:24,114 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2545 | Iter Mean Loss 8.5795
2020-11-05 16:36:24,119 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9246 | Iter Mean Loss 11.6945
2020-11-05 16:36:24,126 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8370 | Iter Mean Loss 11.7302
2020-11-05 16:36:24,131 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1691 | Iter Mean Loss 10.2179
2020-11-05 16:36:24,132 - root - INFO - Evaluate: Epoch 0383 | NDCG 0.0000 | MSE 0.1963
2020-11-05 16:36:24,139 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8802 | Iter Mean Loss 14.8802
2020-11-05 16:36:24,145 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2504 | Iter Mean Loss 8.5653
2020-11-05 16:36:24,150 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8897 | Iter Mean Loss 11.6734
2020-11-05 16:36:24,157 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8086 | Iter Mean Loss 11.7072
2020-11-05 16:36:24,162 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1662 | Iter Mean Loss 10.1990
2020-11-05 16:36:24,163 - root - INFO - Evaluate: Epoch 0384 | NDCG 0.0000 | MSE 0.1963
2020-11-05 16:36:24,169 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8559 | Iter Mean Loss 14.8559
2020-11-05 16:36:24,175 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2463 | Iter Mean Loss 8.5511
2020-11-05 16:36:24,181 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8549 | Iter Mean Loss 11.6524
2020-11-05 16:36:24,188 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7804 | Iter Mean Loss 11.6844
2020-11-05 16:36:24,193 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1632 | Iter Mean Loss 10.1802
2020-11-05 16:36:24,194 - root - INFO - Evaluate: Epoch 0385 | NDCG 0.0000 | MSE 0.1962
2020-11-05 16:36:24,200 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8317 | Iter Mean Loss 14.8317
2020-11-05 16:36:24,207 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2422 | Iter Mean Loss 8.5369
2020-11-05 16:36:24,213 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8203 | Iter Mean Loss 11.6314
2020-11-05 16:36:24,221 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7524 | Iter Mean Loss 11.6616
2020-11-05 16:36:24,226 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1603 | Iter Mean Loss 10.1614
2020-11-05 16:36:24,228 - root - INFO - Evaluate: Epoch 0386 | NDCG 0.0000 | MSE 0.1962
2020-11-05 16:36:24,234 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8075 | Iter Mean Loss 14.8075
2020-11-05 16:36:24,242 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2382 | Iter Mean Loss 8.5229
2020-11-05 16:36:24,248 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7857 | Iter Mean Loss 11.6105
2020-11-05 16:36:24,256 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7245 | Iter Mean Loss 11.6390
2020-11-05 16:36:24,261 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1575 | Iter Mean Loss 10.1427
2020-11-05 16:36:24,262 - root - INFO - Evaluate: Epoch 0387 | NDCG 0.0000 | MSE 0.1961
2020-11-05 16:36:24,268 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7835 | Iter Mean Loss 14.7835
2020-11-05 16:36:24,274 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2341 | Iter Mean Loss 8.5088
2020-11-05 16:36:24,279 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7513 | Iter Mean Loss 11.5897
2020-11-05 16:36:24,287 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6967 | Iter Mean Loss 11.6164
2020-11-05 16:36:24,292 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1546 | Iter Mean Loss 10.1240
2020-11-05 16:36:24,293 - root - INFO - Evaluate: Epoch 0388 | NDCG 0.0000 | MSE 0.1960
2020-11-05 16:36:24,299 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7596 | Iter Mean Loss 14.7596
2020-11-05 16:36:24,305 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2301 | Iter Mean Loss 8.4949
2020-11-05 16:36:24,311 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7170 | Iter Mean Loss 11.5689
2020-11-05 16:36:24,317 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6691 | Iter Mean Loss 11.5940
2020-11-05 16:36:24,323 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1517 | Iter Mean Loss 10.1055
2020-11-05 16:36:24,324 - root - INFO - Evaluate: Epoch 0389 | NDCG 0.0000 | MSE 0.1960
2020-11-05 16:36:24,329 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7358 | Iter Mean Loss 14.7358
2020-11-05 16:36:24,335 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 8.4809
2020-11-05 16:36:24,341 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6828 | Iter Mean Loss 11.5482
2020-11-05 16:36:24,346 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6417 | Iter Mean Loss 11.5716
2020-11-05 16:36:24,351 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1488 | Iter Mean Loss 10.0870
2020-11-05 16:36:24,352 - root - INFO - Evaluate: Epoch 0390 | NDCG 0.0000 | MSE 0.1959
2020-11-05 16:36:24,358 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7120 | Iter Mean Loss 14.7120
2020-11-05 16:36:24,364 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2221 | Iter Mean Loss 8.4671
2020-11-05 16:36:24,370 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6487 | Iter Mean Loss 11.5276
2020-11-05 16:36:24,376 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6144 | Iter Mean Loss 11.5493
2020-11-05 16:36:24,381 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1459 | Iter Mean Loss 10.0686
2020-11-05 16:36:24,382 - root - INFO - Evaluate: Epoch 0391 | NDCG 0.0000 | MSE 0.1959
2020-11-05 16:36:24,387 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6884 | Iter Mean Loss 14.6884
2020-11-05 16:36:24,393 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2181 | Iter Mean Loss 8.4532
2020-11-05 16:36:24,399 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6147 | Iter Mean Loss 11.5071
2020-11-05 16:36:24,404 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5872 | Iter Mean Loss 11.5271
2020-11-05 16:36:24,409 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1431 | Iter Mean Loss 10.0503
2020-11-05 16:36:24,410 - root - INFO - Evaluate: Epoch 0392 | NDCG 0.0000 | MSE 0.1958
2020-11-05 16:36:24,416 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6649 | Iter Mean Loss 14.6649
2020-11-05 16:36:24,422 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2141 | Iter Mean Loss 8.4395
2020-11-05 16:36:24,428 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5808 | Iter Mean Loss 11.4866
2020-11-05 16:36:24,434 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5603 | Iter Mean Loss 11.5050
2020-11-05 16:36:24,439 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1402 | Iter Mean Loss 10.0320
2020-11-05 16:36:24,440 - root - INFO - Evaluate: Epoch 0393 | NDCG 0.0000 | MSE 0.1958
2020-11-05 16:36:24,446 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6414 | Iter Mean Loss 14.6414
2020-11-05 16:36:24,452 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2101 | Iter Mean Loss 8.4258
2020-11-05 16:36:24,458 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5470 | Iter Mean Loss 11.4662
2020-11-05 16:36:24,465 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5334 | Iter Mean Loss 11.4830
2020-11-05 16:36:24,471 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1373 | Iter Mean Loss 10.0139
2020-11-05 16:36:24,472 - root - INFO - Evaluate: Epoch 0394 | NDCG 0.0000 | MSE 0.1957
2020-11-05 16:36:24,478 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6180 | Iter Mean Loss 14.6180
2020-11-05 16:36:24,485 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2062 | Iter Mean Loss 8.4121
2020-11-05 16:36:24,490 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5133 | Iter Mean Loss 11.4459
2020-11-05 16:36:24,496 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5068 | Iter Mean Loss 11.4611
2020-11-05 16:36:24,501 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1345 | Iter Mean Loss 9.9958
2020-11-05 16:36:24,502 - root - INFO - Evaluate: Epoch 0395 | NDCG 0.0000 | MSE 0.1956
2020-11-05 16:36:24,508 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5948 | Iter Mean Loss 14.5948
2020-11-05 16:36:24,514 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2023 | Iter Mean Loss 8.3985
2020-11-05 16:36:24,520 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4798 | Iter Mean Loss 11.4256
2020-11-05 16:36:24,526 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4803 | Iter Mean Loss 11.4393
2020-11-05 16:36:24,531 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1316 | Iter Mean Loss 9.9777
2020-11-05 16:36:24,531 - root - INFO - Evaluate: Epoch 0396 | NDCG 0.0000 | MSE 0.1956
2020-11-05 16:36:24,537 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5716 | Iter Mean Loss 14.5716
2020-11-05 16:36:24,543 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1983 | Iter Mean Loss 8.3850
2020-11-05 16:36:24,548 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4463 | Iter Mean Loss 11.4054
2020-11-05 16:36:24,554 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4539 | Iter Mean Loss 11.4175
2020-11-05 16:36:24,559 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 9.9598
2020-11-05 16:36:24,559 - root - INFO - Evaluate: Epoch 0397 | NDCG 0.0000 | MSE 0.1955
2020-11-05 16:36:24,565 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5485 | Iter Mean Loss 14.5485
2020-11-05 16:36:24,571 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1944 | Iter Mean Loss 8.3715
2020-11-05 16:36:24,576 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4130 | Iter Mean Loss 11.3853
2020-11-05 16:36:24,582 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4277 | Iter Mean Loss 11.3959
2020-11-05 16:36:24,587 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1260 | Iter Mean Loss 9.9419
2020-11-05 16:36:24,588 - root - INFO - Evaluate: Epoch 0398 | NDCG 0.0000 | MSE 0.1955
2020-11-05 16:36:24,593 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5255 | Iter Mean Loss 14.5255
2020-11-05 16:36:24,599 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1905 | Iter Mean Loss 8.3580
2020-11-05 16:36:24,604 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3797 | Iter Mean Loss 11.3653
2020-11-05 16:36:24,610 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4017 | Iter Mean Loss 11.3744
2020-11-05 16:36:24,615 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1232 | Iter Mean Loss 9.9241
2020-11-05 16:36:24,615 - root - INFO - Evaluate: Epoch 0399 | NDCG 0.0000 | MSE 0.1954
2020-11-05 16:36:24,621 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5026 | Iter Mean Loss 14.5026
2020-11-05 16:36:24,627 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1867 | Iter Mean Loss 8.3446
2020-11-05 16:36:24,632 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3466 | Iter Mean Loss 11.3453
2020-11-05 16:36:24,638 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3759 | Iter Mean Loss 11.3529
2020-11-05 16:36:24,643 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1203 | Iter Mean Loss 9.9064
2020-11-05 16:36:24,644 - root - INFO - Evaluate: Epoch 0400 | NDCG 0.0000 | MSE 0.1954
2020-11-05 16:36:24,649 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4798 | Iter Mean Loss 14.4798
2020-11-05 16:36:24,655 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1828 | Iter Mean Loss 8.3313
2020-11-05 16:36:24,662 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3136 | Iter Mean Loss 11.3254
2020-11-05 16:36:24,667 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3502 | Iter Mean Loss 11.3316
2020-11-05 16:36:24,673 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1175 | Iter Mean Loss 9.8888
2020-11-05 16:36:24,674 - root - INFO - Evaluate: Epoch 0401 | NDCG 0.0000 | MSE 0.1953
2020-11-05 16:36:24,680 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4571 | Iter Mean Loss 14.4571
2020-11-05 16:36:24,686 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1790 | Iter Mean Loss 8.3180
2020-11-05 16:36:24,693 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2806 | Iter Mean Loss 11.3056
2020-11-05 16:36:24,698 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3246 | Iter Mean Loss 11.3103
2020-11-05 16:36:24,704 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1147 | Iter Mean Loss 9.8712
2020-11-05 16:36:24,705 - root - INFO - Evaluate: Epoch 0402 | NDCG 0.0000 | MSE 0.1953
2020-11-05 16:36:24,712 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4344 | Iter Mean Loss 14.4344
2020-11-05 16:36:24,718 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1751 | Iter Mean Loss 8.3048
2020-11-05 16:36:24,724 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2478 | Iter Mean Loss 11.2858
2020-11-05 16:36:24,730 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2992 | Iter Mean Loss 11.2892
2020-11-05 16:36:24,735 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1120 | Iter Mean Loss 9.8537
2020-11-05 16:36:24,736 - root - INFO - Evaluate: Epoch 0403 | NDCG 0.0000 | MSE 0.1952
2020-11-05 16:36:24,742 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4119 | Iter Mean Loss 14.4119
2020-11-05 16:36:24,747 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1713 | Iter Mean Loss 8.2916
2020-11-05 16:36:24,753 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2151 | Iter Mean Loss 11.2661
2020-11-05 16:36:24,759 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2740 | Iter Mean Loss 11.2681
2020-11-05 16:36:24,764 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 9.8363
2020-11-05 16:36:24,765 - root - INFO - Evaluate: Epoch 0404 | NDCG 0.0000 | MSE 0.1951
2020-11-05 16:36:24,771 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3894 | Iter Mean Loss 14.3894
2020-11-05 16:36:24,776 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1675 | Iter Mean Loss 8.2785
2020-11-05 16:36:24,782 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1825 | Iter Mean Loss 11.2465
2020-11-05 16:36:24,788 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2490 | Iter Mean Loss 11.2471
2020-11-05 16:36:24,793 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1064 | Iter Mean Loss 9.8190
2020-11-05 16:36:24,794 - root - INFO - Evaluate: Epoch 0405 | NDCG 0.0000 | MSE 0.1951
2020-11-05 16:36:24,800 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3670 | Iter Mean Loss 14.3670
2020-11-05 16:36:24,805 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1637 | Iter Mean Loss 8.2654
2020-11-05 16:36:24,811 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1499 | Iter Mean Loss 11.2269
2020-11-05 16:36:24,817 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2241 | Iter Mean Loss 11.2262
2020-11-05 16:36:24,823 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1036 | Iter Mean Loss 9.8017
2020-11-05 16:36:24,824 - root - INFO - Evaluate: Epoch 0406 | NDCG 0.0000 | MSE 0.1950
2020-11-05 16:36:24,830 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3448 | Iter Mean Loss 14.3448
2020-11-05 16:36:24,836 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1600 | Iter Mean Loss 8.2524
2020-11-05 16:36:24,841 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1175 | Iter Mean Loss 11.2074
2020-11-05 16:36:24,847 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1994 | Iter Mean Loss 11.2054
2020-11-05 16:36:24,852 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1009 | Iter Mean Loss 9.7845
2020-11-05 16:36:24,853 - root - INFO - Evaluate: Epoch 0407 | NDCG 0.0000 | MSE 0.1950
2020-11-05 16:36:24,859 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3225 | Iter Mean Loss 14.3225
2020-11-05 16:36:24,866 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1562 | Iter Mean Loss 8.2394
2020-11-05 16:36:24,872 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0852 | Iter Mean Loss 11.1880
2020-11-05 16:36:24,878 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1748 | Iter Mean Loss 11.1847
2020-11-05 16:36:24,883 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0981 | Iter Mean Loss 9.7674
2020-11-05 16:36:24,884 - root - INFO - Evaluate: Epoch 0408 | NDCG 0.0000 | MSE 0.1949
2020-11-05 16:36:24,890 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3004 | Iter Mean Loss 14.3004
2020-11-05 16:36:24,896 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1525 | Iter Mean Loss 8.2265
2020-11-05 16:36:24,902 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0530 | Iter Mean Loss 11.1686
2020-11-05 16:36:24,908 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1504 | Iter Mean Loss 11.1641
2020-11-05 16:36:24,913 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0954 | Iter Mean Loss 9.7503
2020-11-05 16:36:24,914 - root - INFO - Evaluate: Epoch 0409 | NDCG 0.0000 | MSE 0.1949
2020-11-05 16:36:24,920 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2784 | Iter Mean Loss 14.2784
2020-11-05 16:36:24,925 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1488 | Iter Mean Loss 8.2136
2020-11-05 16:36:24,931 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0209 | Iter Mean Loss 11.1494
2020-11-05 16:36:24,937 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1262 | Iter Mean Loss 11.1436
2020-11-05 16:36:24,942 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0926 | Iter Mean Loss 9.7334
2020-11-05 16:36:24,943 - root - INFO - Evaluate: Epoch 0410 | NDCG 0.0000 | MSE 0.1948
2020-11-05 16:36:24,949 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2564 | Iter Mean Loss 14.2564
2020-11-05 16:36:24,954 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1451 | Iter Mean Loss 8.2008
2020-11-05 16:36:24,960 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9889 | Iter Mean Loss 11.1301
2020-11-05 16:36:24,966 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1021 | Iter Mean Loss 11.1231
2020-11-05 16:36:24,971 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 9.7165
2020-11-05 16:36:24,972 - root - INFO - Evaluate: Epoch 0411 | NDCG 0.0000 | MSE 0.1947
2020-11-05 16:36:24,978 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2346 | Iter Mean Loss 14.2346
2020-11-05 16:36:24,983 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1414 | Iter Mean Loss 8.1880
2020-11-05 16:36:24,989 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9569 | Iter Mean Loss 11.1110
2020-11-05 16:36:24,995 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0782 | Iter Mean Loss 11.1028
2020-11-05 16:36:24,999 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0872 | Iter Mean Loss 9.6997
2020-11-05 16:36:25,000 - root - INFO - Evaluate: Epoch 0412 | NDCG 0.0000 | MSE 0.1947
2020-11-05 16:36:25,006 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2128 | Iter Mean Loss 14.2128
2020-11-05 16:36:25,012 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1378 | Iter Mean Loss 8.1753
2020-11-05 16:36:25,018 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9251 | Iter Mean Loss 11.0919
2020-11-05 16:36:25,024 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0545 | Iter Mean Loss 11.0825
2020-11-05 16:36:25,030 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0845 | Iter Mean Loss 9.6829
2020-11-05 16:36:25,031 - root - INFO - Evaluate: Epoch 0413 | NDCG 0.0000 | MSE 0.1946
2020-11-05 16:36:25,038 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1911 | Iter Mean Loss 14.1911
2020-11-05 16:36:25,046 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1341 | Iter Mean Loss 8.1626
2020-11-05 16:36:25,052 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8934 | Iter Mean Loss 11.0729
2020-11-05 16:36:25,058 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0309 | Iter Mean Loss 11.0624
2020-11-05 16:36:25,063 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0818 | Iter Mean Loss 9.6663
2020-11-05 16:36:25,064 - root - INFO - Evaluate: Epoch 0414 | NDCG 0.0000 | MSE 0.1946
2020-11-05 16:36:25,070 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1695 | Iter Mean Loss 14.1695
2020-11-05 16:36:25,077 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1305 | Iter Mean Loss 8.1500
2020-11-05 16:36:25,084 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8618 | Iter Mean Loss 11.0539
2020-11-05 16:36:25,089 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0074 | Iter Mean Loss 11.0423
2020-11-05 16:36:25,094 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 9.6497
2020-11-05 16:36:25,095 - root - INFO - Evaluate: Epoch 0415 | NDCG 0.0000 | MSE 0.1945
2020-11-05 16:36:25,102 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1479 | Iter Mean Loss 14.1479
2020-11-05 16:36:25,108 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1269 | Iter Mean Loss 8.1374
2020-11-05 16:36:25,114 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8302 | Iter Mean Loss 11.0350
2020-11-05 16:36:25,120 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9842 | Iter Mean Loss 11.0223
2020-11-05 16:36:25,127 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0764 | Iter Mean Loss 9.6331
2020-11-05 16:36:25,128 - root - INFO - Evaluate: Epoch 0416 | NDCG 0.0000 | MSE 0.1945
2020-11-05 16:36:25,134 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1265 | Iter Mean Loss 14.1265
2020-11-05 16:36:25,141 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1233 | Iter Mean Loss 8.1249
2020-11-05 16:36:25,147 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7988 | Iter Mean Loss 11.0162
2020-11-05 16:36:25,153 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9611 | Iter Mean Loss 11.0024
2020-11-05 16:36:25,158 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0738 | Iter Mean Loss 9.6167
2020-11-05 16:36:25,159 - root - INFO - Evaluate: Epoch 0417 | NDCG 0.0000 | MSE 0.1944
2020-11-05 16:36:25,165 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1051 | Iter Mean Loss 14.1051
2020-11-05 16:36:25,171 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1197 | Iter Mean Loss 8.1124
2020-11-05 16:36:25,177 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7675 | Iter Mean Loss 10.9974
2020-11-05 16:36:25,182 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9381 | Iter Mean Loss 10.9826
2020-11-05 16:36:25,187 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 9.6003
2020-11-05 16:36:25,188 - root - INFO - Evaluate: Epoch 0418 | NDCG 0.0000 | MSE 0.1944
2020-11-05 16:36:25,194 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0838 | Iter Mean Loss 14.0838
2020-11-05 16:36:25,200 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1161 | Iter Mean Loss 8.1000
2020-11-05 16:36:25,206 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7362 | Iter Mean Loss 10.9787
2020-11-05 16:36:25,212 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9153 | Iter Mean Loss 10.9629
2020-11-05 16:36:25,217 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0685 | Iter Mean Loss 9.5840
2020-11-05 16:36:25,217 - root - INFO - Evaluate: Epoch 0419 | NDCG 0.0000 | MSE 0.1943
2020-11-05 16:36:25,223 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0626 | Iter Mean Loss 14.0626
2020-11-05 16:36:25,229 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1126 | Iter Mean Loss 8.0876
2020-11-05 16:36:25,235 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7051 | Iter Mean Loss 10.9601
2020-11-05 16:36:25,240 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8927 | Iter Mean Loss 10.9432
2020-11-05 16:36:25,245 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 9.5678
2020-11-05 16:36:25,246 - root - INFO - Evaluate: Epoch 0420 | NDCG 0.0000 | MSE 0.1942
2020-11-05 16:36:25,252 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0415 | Iter Mean Loss 14.0415
2020-11-05 16:36:25,258 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1091 | Iter Mean Loss 8.0753
2020-11-05 16:36:25,264 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6740 | Iter Mean Loss 10.9415
2020-11-05 16:36:25,270 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8702 | Iter Mean Loss 10.9237
2020-11-05 16:36:25,275 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0632 | Iter Mean Loss 9.5516
2020-11-05 16:36:25,277 - root - INFO - Evaluate: Epoch 0421 | NDCG 0.0000 | MSE 0.1942
2020-11-05 16:36:25,284 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0204 | Iter Mean Loss 14.0204
2020-11-05 16:36:25,289 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1055 | Iter Mean Loss 8.0630
2020-11-05 16:36:25,295 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6430 | Iter Mean Loss 10.9230
2020-11-05 16:36:25,301 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8479 | Iter Mean Loss 10.9042
2020-11-05 16:36:25,306 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0605 | Iter Mean Loss 9.5355
2020-11-05 16:36:25,307 - root - INFO - Evaluate: Epoch 0422 | NDCG 0.0000 | MSE 0.1941
2020-11-05 16:36:25,315 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9995 | Iter Mean Loss 13.9995
2020-11-05 16:36:25,321 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1020 | Iter Mean Loss 8.0508
2020-11-05 16:36:25,327 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6121 | Iter Mean Loss 10.9045
2020-11-05 16:36:25,333 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8258 | Iter Mean Loss 10.8849
2020-11-05 16:36:25,338 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0579 | Iter Mean Loss 9.5195
2020-11-05 16:36:25,339 - root - INFO - Evaluate: Epoch 0423 | NDCG 0.0000 | MSE 0.1941
2020-11-05 16:36:25,345 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9786 | Iter Mean Loss 13.9786
2020-11-05 16:36:25,350 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0986 | Iter Mean Loss 8.0386
2020-11-05 16:36:25,356 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5813 | Iter Mean Loss 10.8862
2020-11-05 16:36:25,362 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8038 | Iter Mean Loss 10.8656
2020-11-05 16:36:25,367 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0553 | Iter Mean Loss 9.5035
2020-11-05 16:36:25,368 - root - INFO - Evaluate: Epoch 0424 | NDCG 0.0000 | MSE 0.1940
2020-11-05 16:36:25,374 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9577 | Iter Mean Loss 13.9577
2020-11-05 16:36:25,379 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0951 | Iter Mean Loss 8.0264
2020-11-05 16:36:25,385 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5506 | Iter Mean Loss 10.8678
2020-11-05 16:36:25,391 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7819 | Iter Mean Loss 10.8464
2020-11-05 16:36:25,396 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0527 | Iter Mean Loss 9.4876
2020-11-05 16:36:25,396 - root - INFO - Evaluate: Epoch 0425 | NDCG 0.0000 | MSE 0.1940
2020-11-05 16:36:25,402 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9370 | Iter Mean Loss 13.9370
2020-11-05 16:36:25,408 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0917 | Iter Mean Loss 8.0143
2020-11-05 16:36:25,414 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5200 | Iter Mean Loss 10.8496
2020-11-05 16:36:25,419 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7602 | Iter Mean Loss 10.8272
2020-11-05 16:36:25,424 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0501 | Iter Mean Loss 9.4718
2020-11-05 16:36:25,425 - root - INFO - Evaluate: Epoch 0426 | NDCG 0.0000 | MSE 0.1939
2020-11-05 16:36:25,431 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9163 | Iter Mean Loss 13.9163
2020-11-05 16:36:25,436 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0882 | Iter Mean Loss 8.0023
2020-11-05 16:36:25,442 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4895 | Iter Mean Loss 10.8314
2020-11-05 16:36:25,448 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7387 | Iter Mean Loss 10.8082
2020-11-05 16:36:25,453 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0476 | Iter Mean Loss 9.4561
2020-11-05 16:36:25,454 - root - INFO - Evaluate: Epoch 0427 | NDCG 0.0000 | MSE 0.1938
2020-11-05 16:36:25,460 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8957 | Iter Mean Loss 13.8957
2020-11-05 16:36:25,466 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0848 | Iter Mean Loss 7.9903
2020-11-05 16:36:25,473 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4591 | Iter Mean Loss 10.8132
2020-11-05 16:36:25,479 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7173 | Iter Mean Loss 10.7892
2020-11-05 16:36:25,484 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0450 | Iter Mean Loss 9.4404
2020-11-05 16:36:25,485 - root - INFO - Evaluate: Epoch 0428 | NDCG 0.0000 | MSE 0.1938
2020-11-05 16:36:25,491 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8752 | Iter Mean Loss 13.8752
2020-11-05 16:36:25,497 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0814 | Iter Mean Loss 7.9783
2020-11-05 16:36:25,503 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4287 | Iter Mean Loss 10.7951
2020-11-05 16:36:25,510 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6961 | Iter Mean Loss 10.7704
2020-11-05 16:36:25,515 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0424 | Iter Mean Loss 9.4248
2020-11-05 16:36:25,516 - root - INFO - Evaluate: Epoch 0429 | NDCG 0.0000 | MSE 0.1937
2020-11-05 16:36:25,521 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8548 | Iter Mean Loss 13.8548
2020-11-05 16:36:25,527 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0780 | Iter Mean Loss 7.9664
2020-11-05 16:36:25,533 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3985 | Iter Mean Loss 10.7771
2020-11-05 16:36:25,538 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6750 | Iter Mean Loss 10.7516
2020-11-05 16:36:25,543 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0399 | Iter Mean Loss 9.4092
2020-11-05 16:36:25,544 - root - INFO - Evaluate: Epoch 0430 | NDCG 0.0000 | MSE 0.1937
2020-11-05 16:36:25,550 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8344 | Iter Mean Loss 13.8344
2020-11-05 16:36:25,555 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0747 | Iter Mean Loss 7.9545
2020-11-05 16:36:25,561 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3683 | Iter Mean Loss 10.7591
2020-11-05 16:36:25,566 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6540 | Iter Mean Loss 10.7328
2020-11-05 16:36:25,571 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0373 | Iter Mean Loss 9.3937
2020-11-05 16:36:25,572 - root - INFO - Evaluate: Epoch 0431 | NDCG 0.0000 | MSE 0.1936
2020-11-05 16:36:25,578 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8141 | Iter Mean Loss 13.8141
2020-11-05 16:36:25,584 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0713 | Iter Mean Loss 7.9427
2020-11-05 16:36:25,589 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3382 | Iter Mean Loss 10.7412
2020-11-05 16:36:25,595 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6332 | Iter Mean Loss 10.7142
2020-11-05 16:36:25,600 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 9.3783
2020-11-05 16:36:25,601 - root - INFO - Evaluate: Epoch 0432 | NDCG 0.0000 | MSE 0.1936
2020-11-05 16:36:25,606 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.7939
2020-11-05 16:36:25,612 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0680 | Iter Mean Loss 7.9309
2020-11-05 16:36:25,617 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3082 | Iter Mean Loss 10.7234
2020-11-05 16:36:25,623 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6126 | Iter Mean Loss 10.6957
2020-11-05 16:36:25,628 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0323 | Iter Mean Loss 9.3630
2020-11-05 16:36:25,629 - root - INFO - Evaluate: Epoch 0433 | NDCG 0.0000 | MSE 0.1935
2020-11-05 16:36:25,635 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7737 | Iter Mean Loss 13.7737
2020-11-05 16:36:25,642 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0647 | Iter Mean Loss 7.9192
2020-11-05 16:36:25,648 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2783 | Iter Mean Loss 10.7056
2020-11-05 16:36:25,654 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5921 | Iter Mean Loss 10.6772
2020-11-05 16:36:25,659 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0297 | Iter Mean Loss 9.3477
2020-11-05 16:36:25,660 - root - INFO - Evaluate: Epoch 0434 | NDCG 0.0000 | MSE 0.1935
2020-11-05 16:36:25,666 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7536 | Iter Mean Loss 13.7536
2020-11-05 16:36:25,672 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0613 | Iter Mean Loss 7.9075
2020-11-05 16:36:25,677 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2484 | Iter Mean Loss 10.6878
2020-11-05 16:36:25,683 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5717 | Iter Mean Loss 10.6588
2020-11-05 16:36:25,689 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 9.3325
2020-11-05 16:36:25,690 - root - INFO - Evaluate: Epoch 0435 | NDCG 0.0000 | MSE 0.1934
2020-11-05 16:36:25,697 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7336 | Iter Mean Loss 13.7336
2020-11-05 16:36:25,703 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0581 | Iter Mean Loss 7.8958
2020-11-05 16:36:25,709 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2187 | Iter Mean Loss 10.6701
2020-11-05 16:36:25,715 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5515 | Iter Mean Loss 10.6405
2020-11-05 16:36:25,720 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0247 | Iter Mean Loss 9.3173
2020-11-05 16:36:25,721 - root - INFO - Evaluate: Epoch 0436 | NDCG 0.0000 | MSE 0.1933
2020-11-05 16:36:25,728 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7137 | Iter Mean Loss 13.7137
2020-11-05 16:36:25,735 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0548 | Iter Mean Loss 7.8842
2020-11-05 16:36:25,741 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1890 | Iter Mean Loss 10.6525
2020-11-05 16:36:25,747 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5314 | Iter Mean Loss 10.6222
2020-11-05 16:36:25,752 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0222 | Iter Mean Loss 9.3022
2020-11-05 16:36:25,753 - root - INFO - Evaluate: Epoch 0437 | NDCG 0.0000 | MSE 0.1933
2020-11-05 16:36:25,758 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6938 | Iter Mean Loss 13.6938
2020-11-05 16:36:25,764 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0515 | Iter Mean Loss 7.8727
2020-11-05 16:36:25,770 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1594 | Iter Mean Loss 10.6349
2020-11-05 16:36:25,776 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5115 | Iter Mean Loss 10.6041
2020-11-05 16:36:25,781 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0197 | Iter Mean Loss 9.2872
2020-11-05 16:36:25,782 - root - INFO - Evaluate: Epoch 0438 | NDCG 0.0000 | MSE 0.1932
2020-11-05 16:36:25,788 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6741 | Iter Mean Loss 13.6741
2020-11-05 16:36:25,793 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0483 | Iter Mean Loss 7.8612
2020-11-05 16:36:25,799 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1299 | Iter Mean Loss 10.6174
2020-11-05 16:36:25,805 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4917 | Iter Mean Loss 10.5860
2020-11-05 16:36:25,810 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0173 | Iter Mean Loss 9.2722
2020-11-05 16:36:25,811 - root - INFO - Evaluate: Epoch 0439 | NDCG 0.0000 | MSE 0.1932
2020-11-05 16:36:25,817 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6543 | Iter Mean Loss 13.6543
2020-11-05 16:36:25,823 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0450 | Iter Mean Loss 7.8497
2020-11-05 16:36:25,829 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1005 | Iter Mean Loss 10.5999
2020-11-05 16:36:25,835 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4721 | Iter Mean Loss 10.5680
2020-11-05 16:36:25,840 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0148 | Iter Mean Loss 9.2573
2020-11-05 16:36:25,841 - root - INFO - Evaluate: Epoch 0440 | NDCG 0.0000 | MSE 0.1931
2020-11-05 16:36:25,847 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6347 | Iter Mean Loss 13.6347
2020-11-05 16:36:25,853 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0418 | Iter Mean Loss 7.8383
2020-11-05 16:36:25,858 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0711 | Iter Mean Loss 10.5825
2020-11-05 16:36:25,864 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4525 | Iter Mean Loss 10.5500
2020-11-05 16:36:25,869 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0123 | Iter Mean Loss 9.2425
2020-11-05 16:36:25,870 - root - INFO - Evaluate: Epoch 0441 | NDCG 0.0000 | MSE 0.1931
2020-11-05 16:36:25,877 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6151 | Iter Mean Loss 13.6151
2020-11-05 16:36:25,883 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0386 | Iter Mean Loss 7.8269
2020-11-05 16:36:25,889 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0418 | Iter Mean Loss 10.5652
2020-11-05 16:36:25,895 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4332 | Iter Mean Loss 10.5322
2020-11-05 16:36:25,900 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0099 | Iter Mean Loss 9.2277
2020-11-05 16:36:25,901 - root - INFO - Evaluate: Epoch 0442 | NDCG 0.0000 | MSE 0.1930
2020-11-05 16:36:25,907 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5956 | Iter Mean Loss 13.5956
2020-11-05 16:36:25,914 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0354 | Iter Mean Loss 7.8155
2020-11-05 16:36:25,920 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0126 | Iter Mean Loss 10.5479
2020-11-05 16:36:25,926 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4139 | Iter Mean Loss 10.5144
2020-11-05 16:36:25,931 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0074 | Iter Mean Loss 9.2130
2020-11-05 16:36:25,932 - root - INFO - Evaluate: Epoch 0443 | NDCG 0.0000 | MSE 0.1929
2020-11-05 16:36:25,938 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5761 | Iter Mean Loss 13.5761
2020-11-05 16:36:25,943 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0322 | Iter Mean Loss 7.8042
2020-11-05 16:36:25,949 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9835 | Iter Mean Loss 10.5306
2020-11-05 16:36:25,955 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3948 | Iter Mean Loss 10.4967
2020-11-05 16:36:25,960 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0050 | Iter Mean Loss 9.1983
2020-11-05 16:36:25,961 - root - INFO - Evaluate: Epoch 0444 | NDCG 0.0000 | MSE 0.1929
2020-11-05 16:36:25,967 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5568 | Iter Mean Loss 13.5568
2020-11-05 16:36:25,972 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0291 | Iter Mean Loss 7.7929
2020-11-05 16:36:25,978 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9544 | Iter Mean Loss 10.5134
2020-11-05 16:36:25,984 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3758 | Iter Mean Loss 10.4790
2020-11-05 16:36:25,989 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0026 | Iter Mean Loss 9.1837
2020-11-05 16:36:25,990 - root - INFO - Evaluate: Epoch 0445 | NDCG 0.0000 | MSE 0.1928
2020-11-05 16:36:25,995 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5374 | Iter Mean Loss 13.5374
2020-11-05 16:36:26,001 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0259 | Iter Mean Loss 7.7817
2020-11-05 16:36:26,007 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9254 | Iter Mean Loss 10.4963
2020-11-05 16:36:26,012 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3570 | Iter Mean Loss 10.4614
2020-11-05 16:36:26,017 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0001 | Iter Mean Loss 9.1692
2020-11-05 16:36:26,018 - root - INFO - Evaluate: Epoch 0446 | NDCG 0.0000 | MSE 0.1928
2020-11-05 16:36:26,026 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5182 | Iter Mean Loss 13.5182
2020-11-05 16:36:26,032 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0228 | Iter Mean Loss 7.7705
2020-11-05 16:36:26,038 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8965 | Iter Mean Loss 10.4791
2020-11-05 16:36:26,044 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3382 | Iter Mean Loss 10.4439
2020-11-05 16:36:26,049 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9977 | Iter Mean Loss 9.1547
2020-11-05 16:36:26,050 - root - INFO - Evaluate: Epoch 0447 | NDCG 0.0000 | MSE 0.1927
2020-11-05 16:36:26,056 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4990 | Iter Mean Loss 13.4990
2020-11-05 16:36:26,063 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0196 | Iter Mean Loss 7.7593
2020-11-05 16:36:26,069 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8677 | Iter Mean Loss 10.4621
2020-11-05 16:36:26,075 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3197 | Iter Mean Loss 10.4265
2020-11-05 16:36:26,080 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9953 | Iter Mean Loss 9.1402
2020-11-05 16:36:26,081 - root - INFO - Evaluate: Epoch 0448 | NDCG 0.0000 | MSE 0.1927
2020-11-05 16:36:26,087 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4798 | Iter Mean Loss 13.4798
2020-11-05 16:36:26,095 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0165 | Iter Mean Loss 7.7482
2020-11-05 16:36:26,103 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8389 | Iter Mean Loss 10.4451
2020-11-05 16:36:26,110 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3012 | Iter Mean Loss 10.4091
2020-11-05 16:36:26,117 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9929 | Iter Mean Loss 9.1259
2020-11-05 16:36:26,119 - root - INFO - Evaluate: Epoch 0449 | NDCG 0.0000 | MSE 0.1926
2020-11-05 16:36:26,126 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4608 | Iter Mean Loss 13.4608
2020-11-05 16:36:26,135 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0134 | Iter Mean Loss 7.7371
2020-11-05 16:36:26,143 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.4281
2020-11-05 16:36:26,153 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2828 | Iter Mean Loss 10.3918
2020-11-05 16:36:26,159 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9905 | Iter Mean Loss 9.1116
2020-11-05 16:36:26,160 - root - INFO - Evaluate: Epoch 0450 | NDCG 0.0000 | MSE 0.1925
2020-11-05 16:36:26,167 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4418 | Iter Mean Loss 13.4418
2020-11-05 16:36:26,173 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0103 | Iter Mean Loss 7.7260
2020-11-05 16:36:26,179 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7816 | Iter Mean Loss 10.4112
2020-11-05 16:36:26,185 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2646 | Iter Mean Loss 10.3746
2020-11-05 16:36:26,191 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9881 | Iter Mean Loss 9.0973
2020-11-05 16:36:26,191 - root - INFO - Evaluate: Epoch 0451 | NDCG 0.0000 | MSE 0.1925
2020-11-05 16:36:26,199 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4229 | Iter Mean Loss 13.4229
2020-11-05 16:36:26,206 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0072 | Iter Mean Loss 7.7150
2020-11-05 16:36:26,213 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7531 | Iter Mean Loss 10.3944
2020-11-05 16:36:26,219 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2465 | Iter Mean Loss 10.3574
2020-11-05 16:36:26,225 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9857 | Iter Mean Loss 9.0831
2020-11-05 16:36:26,226 - root - INFO - Evaluate: Epoch 0452 | NDCG 0.0000 | MSE 0.1924
2020-11-05 16:36:26,232 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4040 | Iter Mean Loss 13.4040
2020-11-05 16:36:26,238 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0041 | Iter Mean Loss 7.7041
2020-11-05 16:36:26,247 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7246 | Iter Mean Loss 10.3776
2020-11-05 16:36:26,255 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2286 | Iter Mean Loss 10.3403
2020-11-05 16:36:26,260 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9834 | Iter Mean Loss 9.0689
2020-11-05 16:36:26,261 - root - INFO - Evaluate: Epoch 0453 | NDCG 0.0000 | MSE 0.1924
2020-11-05 16:36:26,268 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3852 | Iter Mean Loss 13.3852
2020-11-05 16:36:26,274 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0010 | Iter Mean Loss 7.6931
2020-11-05 16:36:26,280 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6962 | Iter Mean Loss 10.3608
2020-11-05 16:36:26,286 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2107 | Iter Mean Loss 10.3233
2020-11-05 16:36:26,291 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9810 | Iter Mean Loss 9.0548
2020-11-05 16:36:26,292 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.0000 | MSE 0.1923
2020-11-05 16:36:26,299 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3665 | Iter Mean Loss 13.3665
2020-11-05 16:36:26,305 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9980 | Iter Mean Loss 7.6822
2020-11-05 16:36:26,313 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6679 | Iter Mean Loss 10.3441
2020-11-05 16:36:26,319 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1930 | Iter Mean Loss 10.3063
2020-11-05 16:36:26,325 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9786 | Iter Mean Loss 9.0408
2020-11-05 16:36:26,326 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.0000 | MSE 0.1923
2020-11-05 16:36:26,333 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3478 | Iter Mean Loss 13.3478
2020-11-05 16:36:26,339 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9949 | Iter Mean Loss 7.6714
2020-11-05 16:36:26,345 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6396 | Iter Mean Loss 10.3274
2020-11-05 16:36:26,351 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1754 | Iter Mean Loss 10.2894
2020-11-05 16:36:26,357 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9763 | Iter Mean Loss 9.0268
2020-11-05 16:36:26,358 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.0000 | MSE 0.1922
2020-11-05 16:36:26,364 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3292 | Iter Mean Loss 13.3292
2020-11-05 16:36:26,369 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9919 | Iter Mean Loss 7.6605
2020-11-05 16:36:26,375 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6114 | Iter Mean Loss 10.3108
2020-11-05 16:36:26,381 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1579 | Iter Mean Loss 10.2726
2020-11-05 16:36:26,386 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9739 | Iter Mean Loss 9.0129
2020-11-05 16:36:26,387 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.0000 | MSE 0.1921
2020-11-05 16:36:26,393 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3106 | Iter Mean Loss 13.3106
2020-11-05 16:36:26,399 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9889 | Iter Mean Loss 7.6497
2020-11-05 16:36:26,404 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5833 | Iter Mean Loss 10.2943
2020-11-05 16:36:26,410 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1405 | Iter Mean Loss 10.2558
2020-11-05 16:36:26,415 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9716 | Iter Mean Loss 8.9990
2020-11-05 16:36:26,416 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.0000 | MSE 0.1921
2020-11-05 16:36:26,422 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2921 | Iter Mean Loss 13.2921
2020-11-05 16:36:26,427 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9859 | Iter Mean Loss 7.6390
2020-11-05 16:36:26,433 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5552 | Iter Mean Loss 10.2777
2020-11-05 16:36:26,439 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1233 | Iter Mean Loss 10.2391
2020-11-05 16:36:26,444 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 8.9851
2020-11-05 16:36:26,445 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.0000 | MSE 0.1920
2020-11-05 16:36:26,451 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2737 | Iter Mean Loss 13.2737
2020-11-05 16:36:26,457 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9829 | Iter Mean Loss 7.6283
2020-11-05 16:36:26,463 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5272 | Iter Mean Loss 10.2613
2020-11-05 16:36:26,469 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1061 | Iter Mean Loss 10.2225
2020-11-05 16:36:26,474 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9669 | Iter Mean Loss 8.9714
2020-11-05 16:36:26,475 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.0000 | MSE 0.1920
2020-11-05 16:36:26,481 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2553 | Iter Mean Loss 13.2553
2020-11-05 16:36:26,487 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9799 | Iter Mean Loss 7.6176
2020-11-05 16:36:26,494 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4993 | Iter Mean Loss 10.2448
2020-11-05 16:36:26,500 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0891 | Iter Mean Loss 10.2059
2020-11-05 16:36:26,505 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 8.9576
2020-11-05 16:36:26,506 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.0000 | MSE 0.1919
2020-11-05 16:36:26,512 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2370 | Iter Mean Loss 13.2370
2020-11-05 16:36:26,519 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9769 | Iter Mean Loss 7.6069
2020-11-05 16:36:26,525 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4714 | Iter Mean Loss 10.2284
2020-11-05 16:36:26,532 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0721 | Iter Mean Loss 10.1894
2020-11-05 16:36:26,537 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9623 | Iter Mean Loss 8.9439
2020-11-05 16:36:26,538 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.0000 | MSE 0.1919
2020-11-05 16:36:26,544 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2187 | Iter Mean Loss 13.2187
2020-11-05 16:36:26,550 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9739 | Iter Mean Loss 7.5963
2020-11-05 16:36:26,556 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4436 | Iter Mean Loss 10.2121
2020-11-05 16:36:26,562 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0553 | Iter Mean Loss 10.1729
2020-11-05 16:36:26,567 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9599 | Iter Mean Loss 8.9303
2020-11-05 16:36:26,568 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.0000 | MSE 0.1918
2020-11-05 16:36:26,574 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2005 | Iter Mean Loss 13.2005
2020-11-05 16:36:26,580 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9709 | Iter Mean Loss 7.5857
2020-11-05 16:36:26,586 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4158 | Iter Mean Loss 10.1958
2020-11-05 16:36:26,592 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0386 | Iter Mean Loss 10.1565
2020-11-05 16:36:26,597 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9576 | Iter Mean Loss 8.9167
2020-11-05 16:36:26,598 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.0000 | MSE 0.1917
2020-11-05 16:36:26,604 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1824 | Iter Mean Loss 13.1824
2020-11-05 16:36:26,609 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9679 | Iter Mean Loss 7.5752
2020-11-05 16:36:26,615 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3882 | Iter Mean Loss 10.1795
2020-11-05 16:36:26,621 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0220 | Iter Mean Loss 10.1401
2020-11-05 16:36:26,626 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9553 | Iter Mean Loss 8.9032
2020-11-05 16:36:26,627 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.0000 | MSE 0.1917
2020-11-05 16:36:26,633 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1643 | Iter Mean Loss 13.1643
2020-11-05 16:36:26,639 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9650 | Iter Mean Loss 7.5647
2020-11-05 16:36:26,646 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3605 | Iter Mean Loss 10.1633
2020-11-05 16:36:26,652 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0055 | Iter Mean Loss 10.1238
2020-11-05 16:36:26,657 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9530 | Iter Mean Loss 8.8897
2020-11-05 16:36:26,658 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.0000 | MSE 0.1916
2020-11-05 16:36:26,664 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1463 | Iter Mean Loss 13.1463
2020-11-05 16:36:26,670 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9620 | Iter Mean Loss 7.5542
2020-11-05 16:36:26,676 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3330 | Iter Mean Loss 10.1471
2020-11-05 16:36:26,682 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9891 | Iter Mean Loss 10.1076
2020-11-05 16:36:26,687 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9507 | Iter Mean Loss 8.8762
2020-11-05 16:36:26,688 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.0000 | MSE 0.1916
2020-11-05 16:36:26,694 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1283 | Iter Mean Loss 13.1283
2020-11-05 16:36:26,700 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9591 | Iter Mean Loss 7.5437
2020-11-05 16:36:26,706 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3055 | Iter Mean Loss 10.1310
2020-11-05 16:36:26,712 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9728 | Iter Mean Loss 10.0914
2020-11-05 16:36:26,719 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9484 | Iter Mean Loss 8.8628
2020-11-05 16:36:26,720 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.0000 | MSE 0.1915
2020-11-05 16:36:26,726 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1104 | Iter Mean Loss 13.1104
2020-11-05 16:36:26,732 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9561 | Iter Mean Loss 7.5333
2020-11-05 16:36:26,739 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2780 | Iter Mean Loss 10.1149
2020-11-05 16:36:26,745 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9566 | Iter Mean Loss 10.0753
2020-11-05 16:36:26,751 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9461 | Iter Mean Loss 8.8495
2020-11-05 16:36:26,753 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.0000 | MSE 0.1914
2020-11-05 16:36:26,759 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0926 | Iter Mean Loss 13.0926
2020-11-05 16:36:26,765 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9532 | Iter Mean Loss 7.5229
2020-11-05 16:36:26,771 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2507 | Iter Mean Loss 10.0988
2020-11-05 16:36:26,778 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9406 | Iter Mean Loss 10.0593
2020-11-05 16:36:26,784 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9439 | Iter Mean Loss 8.8362
2020-11-05 16:36:26,785 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.0000 | MSE 0.1914
2020-11-05 16:36:26,791 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0748 | Iter Mean Loss 13.0748
2020-11-05 16:36:26,798 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9503 | Iter Mean Loss 7.5125
2020-11-05 16:36:26,804 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2233 | Iter Mean Loss 10.0828
2020-11-05 16:36:26,811 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9246 | Iter Mean Loss 10.0432
2020-11-05 16:36:26,816 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 8.8229
2020-11-05 16:36:26,817 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.0000 | MSE 0.1913
2020-11-05 16:36:26,823 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0570 | Iter Mean Loss 13.0570
2020-11-05 16:36:26,830 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9474 | Iter Mean Loss 7.5022
2020-11-05 16:36:26,836 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1961 | Iter Mean Loss 10.0668
2020-11-05 16:36:26,842 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9087 | Iter Mean Loss 10.0273
2020-11-05 16:36:26,848 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9393 | Iter Mean Loss 8.8097
2020-11-05 16:36:26,849 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.0000 | MSE 0.1913
2020-11-05 16:36:26,854 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0394 | Iter Mean Loss 13.0394
2020-11-05 16:36:26,862 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9444 | Iter Mean Loss 7.4919
2020-11-05 16:36:26,868 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1689 | Iter Mean Loss 10.0509
2020-11-05 16:36:26,874 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8929 | Iter Mean Loss 10.0114
2020-11-05 16:36:26,880 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 8.7965
2020-11-05 16:36:26,881 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.0000 | MSE 0.1912
2020-11-05 16:36:26,887 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0217 | Iter Mean Loss 13.0217
2020-11-05 16:36:26,894 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9415 | Iter Mean Loss 7.4816
2020-11-05 16:36:26,900 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1417 | Iter Mean Loss 10.0350
2020-11-05 16:36:26,906 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8772 | Iter Mean Loss 9.9955
2020-11-05 16:36:26,913 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9348 | Iter Mean Loss 8.7834
2020-11-05 16:36:26,914 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.0000 | MSE 0.1912
2020-11-05 16:36:26,922 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0041 | Iter Mean Loss 13.0041
2020-11-05 16:36:26,928 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9386 | Iter Mean Loss 7.4714
2020-11-05 16:36:26,934 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1146 | Iter Mean Loss 10.0191
2020-11-05 16:36:26,939 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8616 | Iter Mean Loss 9.9797
2020-11-05 16:36:26,947 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9325 | Iter Mean Loss 8.7703
2020-11-05 16:36:26,949 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.0000 | MSE 0.1911
2020-11-05 16:36:26,955 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9866 | Iter Mean Loss 12.9866
2020-11-05 16:36:26,963 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9357 | Iter Mean Loss 7.4612
2020-11-05 16:36:26,970 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0876 | Iter Mean Loss 10.0033
2020-11-05 16:36:26,977 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8461 | Iter Mean Loss 9.9640
2020-11-05 16:36:26,983 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9302 | Iter Mean Loss 8.7573
2020-11-05 16:36:26,984 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.0000 | MSE 0.1910
2020-11-05 16:36:26,991 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9691 | Iter Mean Loss 12.9691
2020-11-05 16:36:26,998 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9328 | Iter Mean Loss 7.4510
2020-11-05 16:36:27,004 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0606 | Iter Mean Loss 9.9875
2020-11-05 16:36:27,010 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8307 | Iter Mean Loss 9.9483
2020-11-05 16:36:27,016 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9280 | Iter Mean Loss 8.7442
2020-11-05 16:36:27,017 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.0000 | MSE 0.1910
2020-11-05 16:36:27,023 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9517 | Iter Mean Loss 12.9517
2020-11-05 16:36:27,030 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9299 | Iter Mean Loss 7.4408
2020-11-05 16:36:27,036 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0337 | Iter Mean Loss 9.9718
2020-11-05 16:36:27,042 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8153 | Iter Mean Loss 9.9327
2020-11-05 16:36:27,048 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9257 | Iter Mean Loss 8.7313
2020-11-05 16:36:27,049 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.0000 | MSE 0.1909
2020-11-05 16:36:27,055 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9344 | Iter Mean Loss 12.9344
2020-11-05 16:36:27,062 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9271 | Iter Mean Loss 7.4307
2020-11-05 16:36:27,068 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0068 | Iter Mean Loss 9.9561
2020-11-05 16:36:27,074 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8001 | Iter Mean Loss 9.9171
2020-11-05 16:36:27,080 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9235 | Iter Mean Loss 8.7184
2020-11-05 16:36:27,081 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.0000 | MSE 0.1909
2020-11-05 16:36:27,087 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9170 | Iter Mean Loss 12.9170
2020-11-05 16:36:27,094 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9242 | Iter Mean Loss 7.4206
2020-11-05 16:36:27,101 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9800 | Iter Mean Loss 9.9404
2020-11-05 16:36:27,107 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7850 | Iter Mean Loss 9.9015
2020-11-05 16:36:27,113 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9212 | Iter Mean Loss 8.7055
2020-11-05 16:36:27,114 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.0000 | MSE 0.1908
2020-11-05 16:36:27,120 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8998 | Iter Mean Loss 12.8998
2020-11-05 16:36:27,126 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9213 | Iter Mean Loss 7.4105
2020-11-05 16:36:27,132 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9532 | Iter Mean Loss 9.9248
2020-11-05 16:36:27,138 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7699 | Iter Mean Loss 9.8861
2020-11-05 16:36:27,143 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9190 | Iter Mean Loss 8.6926
2020-11-05 16:36:27,143 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.0000 | MSE 0.1907
2020-11-05 16:36:27,149 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8826 | Iter Mean Loss 12.8826
2020-11-05 16:36:27,156 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9184 | Iter Mean Loss 7.4005
2020-11-05 16:36:27,162 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9265 | Iter Mean Loss 9.9092
2020-11-05 16:36:27,168 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 9.8706
2020-11-05 16:36:27,174 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9168 | Iter Mean Loss 8.6798
2020-11-05 16:36:27,175 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.0000 | MSE 0.1907
2020-11-05 16:36:27,181 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8654 | Iter Mean Loss 12.8654
2020-11-05 16:36:27,187 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9156 | Iter Mean Loss 7.3905
2020-11-05 16:36:27,193 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8998 | Iter Mean Loss 9.8936
2020-11-05 16:36:27,198 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7401 | Iter Mean Loss 9.8552
2020-11-05 16:36:27,203 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9145 | Iter Mean Loss 8.6671
2020-11-05 16:36:27,204 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.0000 | MSE 0.1906
2020-11-05 16:36:27,210 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8483 | Iter Mean Loss 12.8483
2020-11-05 16:36:27,216 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9127 | Iter Mean Loss 7.3805
2020-11-05 16:36:27,221 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8732 | Iter Mean Loss 9.8781
2020-11-05 16:36:27,227 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7253 | Iter Mean Loss 9.8399
2020-11-05 16:36:27,232 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9123 | Iter Mean Loss 8.6544
2020-11-05 16:36:27,233 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.0000 | MSE 0.1906
2020-11-05 16:36:27,239 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8312 | Iter Mean Loss 12.8312
2020-11-05 16:36:27,245 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9098 | Iter Mean Loss 7.3705
2020-11-05 16:36:27,251 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8467 | Iter Mean Loss 9.8626
2020-11-05 16:36:27,257 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7106 | Iter Mean Loss 9.8246
2020-11-05 16:36:27,262 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9100 | Iter Mean Loss 8.6417
2020-11-05 16:36:27,263 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.0000 | MSE 0.1905
2020-11-05 16:36:27,269 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8142 | Iter Mean Loss 12.8142
2020-11-05 16:36:27,276 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9070 | Iter Mean Loss 7.3606
2020-11-05 16:36:27,282 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8202 | Iter Mean Loss 9.8471
2020-11-05 16:36:27,288 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6959 | Iter Mean Loss 9.8093
2020-11-05 16:36:27,293 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9078 | Iter Mean Loss 8.6290
2020-11-05 16:36:27,294 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.0000 | MSE 0.1905
2020-11-05 16:36:27,300 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7973 | Iter Mean Loss 12.7973
2020-11-05 16:36:27,306 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9041 | Iter Mean Loss 7.3507
2020-11-05 16:36:27,316 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7937 | Iter Mean Loss 9.8317
2020-11-05 16:36:27,323 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6814 | Iter Mean Loss 9.7941
2020-11-05 16:36:27,330 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9056 | Iter Mean Loss 8.6164
2020-11-05 16:36:27,331 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.0000 | MSE 0.1904
2020-11-05 16:36:27,338 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7804 | Iter Mean Loss 12.7804
2020-11-05 16:36:27,345 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9013 | Iter Mean Loss 7.3408
2020-11-05 16:36:27,352 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7673 | Iter Mean Loss 9.8163
2020-11-05 16:36:27,359 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6669 | Iter Mean Loss 9.7790
2020-11-05 16:36:27,366 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 8.6038
2020-11-05 16:36:27,367 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.0000 | MSE 0.1903
2020-11-05 16:36:27,373 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7635 | Iter Mean Loss 12.7635
2020-11-05 16:36:27,381 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8984 | Iter Mean Loss 7.3310
2020-11-05 16:36:27,387 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7410 | Iter Mean Loss 9.8010
2020-11-05 16:36:27,393 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6525 | Iter Mean Loss 9.7639
2020-11-05 16:36:27,398 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9011 | Iter Mean Loss 8.5913
2020-11-05 16:36:27,399 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.0000 | MSE 0.1903
2020-11-05 16:36:27,405 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7467 | Iter Mean Loss 12.7467
2020-11-05 16:36:27,411 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8955 | Iter Mean Loss 7.3211
2020-11-05 16:36:27,420 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7147 | Iter Mean Loss 9.7856
2020-11-05 16:36:27,431 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6382 | Iter Mean Loss 9.7488
2020-11-05 16:36:27,440 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8989 | Iter Mean Loss 8.5788
2020-11-05 16:36:27,441 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.0000 | MSE 0.1902
2020-11-05 16:36:27,448 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7299 | Iter Mean Loss 12.7299
2020-11-05 16:36:27,455 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8927 | Iter Mean Loss 7.3113
2020-11-05 16:36:27,461 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6884 | Iter Mean Loss 9.7703
2020-11-05 16:36:27,469 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6240 | Iter Mean Loss 9.7338
2020-11-05 16:36:27,476 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8967 | Iter Mean Loss 8.5663
2020-11-05 16:36:27,477 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.0000 | MSE 0.1902
2020-11-05 16:36:27,484 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7132 | Iter Mean Loss 12.7132
2020-11-05 16:36:27,492 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8898 | Iter Mean Loss 7.3015
2020-11-05 16:36:27,500 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6622 | Iter Mean Loss 9.7551
2020-11-05 16:36:27,507 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6099 | Iter Mean Loss 9.7188
2020-11-05 16:36:27,515 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8945 | Iter Mean Loss 8.5539
2020-11-05 16:36:27,516 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.0000 | MSE 0.1901
2020-11-05 16:36:27,523 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6966 | Iter Mean Loss 12.6966
2020-11-05 16:36:27,533 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8870 | Iter Mean Loss 7.2918
2020-11-05 16:36:27,540 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6360 | Iter Mean Loss 9.7399
2020-11-05 16:36:27,548 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.7038
2020-11-05 16:36:27,553 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8922 | Iter Mean Loss 8.5415
2020-11-05 16:36:27,554 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.0000 | MSE 0.1900
2020-11-05 16:36:27,560 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6799 | Iter Mean Loss 12.6799
2020-11-05 16:36:27,566 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8842 | Iter Mean Loss 7.2820
2020-11-05 16:36:27,574 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6099 | Iter Mean Loss 9.7247
2020-11-05 16:36:27,581 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5818 | Iter Mean Loss 9.6890
2020-11-05 16:36:27,589 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8900 | Iter Mean Loss 8.5292
2020-11-05 16:36:27,590 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.0000 | MSE 0.1900
2020-11-05 16:36:27,596 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6634 | Iter Mean Loss 12.6634
2020-11-05 16:36:27,603 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8813 | Iter Mean Loss 7.2723
2020-11-05 16:36:27,611 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5839 | Iter Mean Loss 9.7095
2020-11-05 16:36:27,619 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5679 | Iter Mean Loss 9.6741
2020-11-05 16:36:27,625 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8878 | Iter Mean Loss 8.5168
2020-11-05 16:36:27,626 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.0000 | MSE 0.1899
2020-11-05 16:36:27,632 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6468 | Iter Mean Loss 12.6468
2020-11-05 16:36:27,638 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8785 | Iter Mean Loss 7.2627
2020-11-05 16:36:27,643 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5578 | Iter Mean Loss 9.6944
2020-11-05 16:36:27,649 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5540 | Iter Mean Loss 9.6593
2020-11-05 16:36:27,654 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8856 | Iter Mean Loss 8.5046
2020-11-05 16:36:27,655 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.0000 | MSE 0.1899
2020-11-05 16:36:27,660 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6304 | Iter Mean Loss 12.6304
2020-11-05 16:36:27,666 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8756 | Iter Mean Loss 7.2530
2020-11-05 16:36:27,671 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5319 | Iter Mean Loss 9.6793
2020-11-05 16:36:27,677 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5402 | Iter Mean Loss 9.6445
2020-11-05 16:36:27,682 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8834 | Iter Mean Loss 8.4923
2020-11-05 16:36:27,683 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.0000 | MSE 0.1898
2020-11-05 16:36:27,689 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6139 | Iter Mean Loss 12.6139
2020-11-05 16:36:27,694 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8728 | Iter Mean Loss 7.2434
2020-11-05 16:36:27,701 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5060 | Iter Mean Loss 9.6642
2020-11-05 16:36:27,707 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5265 | Iter Mean Loss 9.6298
2020-11-05 16:36:27,712 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8812 | Iter Mean Loss 8.4801
2020-11-05 16:36:27,713 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.0000 | MSE 0.1897
2020-11-05 16:36:27,719 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5976 | Iter Mean Loss 12.5976
2020-11-05 16:36:27,725 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8699 | Iter Mean Loss 7.2337
2020-11-05 16:36:27,730 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4801 | Iter Mean Loss 9.6492
2020-11-05 16:36:27,736 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5129 | Iter Mean Loss 9.6151
2020-11-05 16:36:27,742 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8789 | Iter Mean Loss 8.4679
2020-11-05 16:36:27,743 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.0000 | MSE 0.1897
2020-11-05 16:36:27,750 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5812 | Iter Mean Loss 12.5812
2020-11-05 16:36:27,756 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8671 | Iter Mean Loss 7.2242
2020-11-05 16:36:27,763 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4542 | Iter Mean Loss 9.6342
2020-11-05 16:36:27,769 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4993 | Iter Mean Loss 9.6005
2020-11-05 16:36:27,774 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8767 | Iter Mean Loss 8.4557
2020-11-05 16:36:27,775 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.0000 | MSE 0.1896
2020-11-05 16:36:27,781 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5649 | Iter Mean Loss 12.5649
2020-11-05 16:36:27,787 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8643 | Iter Mean Loss 7.2146
2020-11-05 16:36:27,792 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4285 | Iter Mean Loss 9.6192
2020-11-05 16:36:27,798 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4859 | Iter Mean Loss 9.5859
2020-11-05 16:36:27,803 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8745 | Iter Mean Loss 8.4436
2020-11-05 16:36:27,804 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.0000 | MSE 0.1896
2020-11-05 16:36:27,810 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5487 | Iter Mean Loss 12.5487
2020-11-05 16:36:27,816 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8614 | Iter Mean Loss 7.2051
2020-11-05 16:36:27,823 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4027 | Iter Mean Loss 9.6043
2020-11-05 16:36:27,829 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4724 | Iter Mean Loss 9.5713
2020-11-05 16:36:27,834 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8723 | Iter Mean Loss 8.4315
2020-11-05 16:36:27,835 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.0000 | MSE 0.1895
2020-11-05 16:36:27,841 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5325 | Iter Mean Loss 12.5325
2020-11-05 16:36:27,846 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8586 | Iter Mean Loss 7.1955
2020-11-05 16:36:27,853 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3770 | Iter Mean Loss 9.5894
2020-11-05 16:36:27,860 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4591 | Iter Mean Loss 9.5568
2020-11-05 16:36:27,865 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8701 | Iter Mean Loss 8.4194
2020-11-05 16:36:27,866 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.0000 | MSE 0.1894
2020-11-05 16:36:27,872 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5163 | Iter Mean Loss 12.5163
2020-11-05 16:36:27,877 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8557 | Iter Mean Loss 7.1860
2020-11-05 16:36:27,883 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3514 | Iter Mean Loss 9.5745
2020-11-05 16:36:27,889 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4458 | Iter Mean Loss 9.5423
2020-11-05 16:36:27,894 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8679 | Iter Mean Loss 8.4074
2020-11-05 16:36:27,895 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.0000 | MSE 0.1894
2020-11-05 16:36:27,901 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5002 | Iter Mean Loss 12.5002
2020-11-05 16:36:27,906 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 7.1766
2020-11-05 16:36:27,912 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3258 | Iter Mean Loss 9.5596
2020-11-05 16:36:27,918 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4326 | Iter Mean Loss 9.5279
2020-11-05 16:36:27,924 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8657 | Iter Mean Loss 8.3954
2020-11-05 16:36:27,925 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.0000 | MSE 0.1893
2020-11-05 16:36:27,931 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4842 | Iter Mean Loss 12.4842
2020-11-05 16:36:27,937 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8500 | Iter Mean Loss 7.1671
2020-11-05 16:36:27,943 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3002 | Iter Mean Loss 9.5448
2020-11-05 16:36:27,949 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4194 | Iter Mean Loss 9.5135
2020-11-05 16:36:27,954 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8634 | Iter Mean Loss 8.3835
2020-11-05 16:36:27,955 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.0000 | MSE 0.1893
2020-11-05 16:36:27,962 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4681 | Iter Mean Loss 12.4681
2020-11-05 16:36:27,968 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8472 | Iter Mean Loss 7.1577
2020-11-05 16:36:27,973 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2747 | Iter Mean Loss 9.5300
2020-11-05 16:36:27,979 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4063 | Iter Mean Loss 9.4991
2020-11-05 16:36:27,984 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8612 | Iter Mean Loss 8.3715
2020-11-05 16:36:27,984 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.0000 | MSE 0.1892
2020-11-05 16:36:27,990 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4522 | Iter Mean Loss 12.4522
2020-11-05 16:36:27,995 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8444 | Iter Mean Loss 7.1483
2020-11-05 16:36:28,001 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2492 | Iter Mean Loss 9.5153
2020-11-05 16:36:28,006 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3933 | Iter Mean Loss 9.4848
2020-11-05 16:36:28,011 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8590 | Iter Mean Loss 8.3596
2020-11-05 16:36:28,012 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.0000 | MSE 0.1891
2020-11-05 16:36:28,017 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4362 | Iter Mean Loss 12.4362
2020-11-05 16:36:28,023 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8415 | Iter Mean Loss 7.1389
2020-11-05 16:36:28,029 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2238 | Iter Mean Loss 9.5005
2020-11-05 16:36:28,035 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3803 | Iter Mean Loss 9.4705
2020-11-05 16:36:28,039 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8568 | Iter Mean Loss 8.3477
2020-11-05 16:36:28,040 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.0000 | MSE 0.1891
2020-11-05 16:36:28,046 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4204 | Iter Mean Loss 12.4204
2020-11-05 16:36:28,051 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8387 | Iter Mean Loss 7.1295
2020-11-05 16:36:28,057 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1984 | Iter Mean Loss 9.4858
2020-11-05 16:36:28,062 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3674 | Iter Mean Loss 9.4562
2020-11-05 16:36:28,067 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8546 | Iter Mean Loss 8.3359
2020-11-05 16:36:28,068 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.0000 | MSE 0.1890
2020-11-05 16:36:28,073 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4045 | Iter Mean Loss 12.4045
2020-11-05 16:36:28,078 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8358 | Iter Mean Loss 7.1202
2020-11-05 16:36:28,084 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1731 | Iter Mean Loss 9.4711
2020-11-05 16:36:28,089 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3546 | Iter Mean Loss 9.4420
2020-11-05 16:36:28,095 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8524 | Iter Mean Loss 8.3241
2020-11-05 16:36:28,097 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.0000 | MSE 0.1890
2020-11-05 16:36:28,103 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3887 | Iter Mean Loss 12.3887
2020-11-05 16:36:28,109 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8330 | Iter Mean Loss 7.1108
2020-11-05 16:36:28,115 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1478 | Iter Mean Loss 9.4565
2020-11-05 16:36:28,120 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3418 | Iter Mean Loss 9.4278
2020-11-05 16:36:28,125 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8501 | Iter Mean Loss 8.3123
2020-11-05 16:36:28,126 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.0000 | MSE 0.1889
2020-11-05 16:36:28,131 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3730 | Iter Mean Loss 12.3730
2020-11-05 16:36:28,137 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8301 | Iter Mean Loss 7.1015
2020-11-05 16:36:28,142 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1226 | Iter Mean Loss 9.4419
2020-11-05 16:36:28,149 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3291 | Iter Mean Loss 9.4137
2020-11-05 16:36:28,154 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8479 | Iter Mean Loss 8.3005
2020-11-05 16:36:28,155 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.0000 | MSE 0.1888
2020-11-05 16:36:28,161 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3573 | Iter Mean Loss 12.3573
2020-11-05 16:36:28,166 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8273 | Iter Mean Loss 7.0923
2020-11-05 16:36:28,172 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0974 | Iter Mean Loss 9.4273
2020-11-05 16:36:28,178 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3164 | Iter Mean Loss 9.3996
2020-11-05 16:36:28,183 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8457 | Iter Mean Loss 8.2888
2020-11-05 16:36:28,184 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.0000 | MSE 0.1888
2020-11-05 16:36:28,190 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3416 | Iter Mean Loss 12.3416
2020-11-05 16:36:28,196 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8244 | Iter Mean Loss 7.0830
2020-11-05 16:36:28,201 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0722 | Iter Mean Loss 9.4127
2020-11-05 16:36:28,206 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3038 | Iter Mean Loss 9.3855
2020-11-05 16:36:28,211 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8435 | Iter Mean Loss 8.2771
2020-11-05 16:36:28,212 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.0000 | MSE 0.1887
2020-11-05 16:36:28,218 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 12.3260
2020-11-05 16:36:28,223 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8216 | Iter Mean Loss 7.0738
2020-11-05 16:36:28,228 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0471 | Iter Mean Loss 9.3982
2020-11-05 16:36:28,234 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2913 | Iter Mean Loss 9.3715
2020-11-05 16:36:28,239 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8413 | Iter Mean Loss 8.2654
2020-11-05 16:36:28,239 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.0000 | MSE 0.1886
2020-11-05 16:36:28,245 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3104 | Iter Mean Loss 12.3104
2020-11-05 16:36:28,250 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8187 | Iter Mean Loss 7.0645
2020-11-05 16:36:28,256 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0220 | Iter Mean Loss 9.3837
2020-11-05 16:36:28,261 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2788 | Iter Mean Loss 9.3575
2020-11-05 16:36:28,267 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8390 | Iter Mean Loss 8.2538
2020-11-05 16:36:28,268 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.0000 | MSE 0.1886
2020-11-05 16:36:28,274 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2948 | Iter Mean Loss 12.2948
2020-11-05 16:36:28,280 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8158 | Iter Mean Loss 7.0553
2020-11-05 16:36:28,285 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9970 | Iter Mean Loss 9.3692
2020-11-05 16:36:28,291 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 9.3435
2020-11-05 16:36:28,296 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8368 | Iter Mean Loss 8.2422
2020-11-05 16:36:28,297 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.0000 | MSE 0.1885
2020-11-05 16:36:28,302 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2793 | Iter Mean Loss 12.2793
2020-11-05 16:36:28,308 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8130 | Iter Mean Loss 7.0462
2020-11-05 16:36:28,316 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9720 | Iter Mean Loss 9.3548
2020-11-05 16:36:28,321 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2541 | Iter Mean Loss 9.3296
2020-11-05 16:36:28,326 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8346 | Iter Mean Loss 8.2306
2020-11-05 16:36:28,327 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.0000 | MSE 0.1885
2020-11-05 16:36:28,333 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2639 | Iter Mean Loss 12.2639
2020-11-05 16:36:28,340 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8101 | Iter Mean Loss 7.0370
2020-11-05 16:36:28,345 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9470 | Iter Mean Loss 9.3404
2020-11-05 16:36:28,351 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2418 | Iter Mean Loss 9.3157
2020-11-05 16:36:28,356 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8323 | Iter Mean Loss 8.2190
2020-11-05 16:36:28,357 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.0000 | MSE 0.1884
2020-11-05 16:36:28,362 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2485 | Iter Mean Loss 12.2485
2020-11-05 16:36:28,368 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8073 | Iter Mean Loss 7.0279
2020-11-05 16:36:28,374 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9221 | Iter Mean Loss 9.3260
2020-11-05 16:36:28,380 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2295 | Iter Mean Loss 9.3019
2020-11-05 16:36:28,385 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8301 | Iter Mean Loss 8.2075
2020-11-05 16:36:28,386 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.0000 | MSE 0.1883
2020-11-05 16:36:28,391 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2331 | Iter Mean Loss 12.2331
2020-11-05 16:36:28,397 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8044 | Iter Mean Loss 7.0188
2020-11-05 16:36:28,402 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8973 | Iter Mean Loss 9.3116
2020-11-05 16:36:28,407 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2173 | Iter Mean Loss 9.2880
2020-11-05 16:36:28,412 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8279 | Iter Mean Loss 8.1960
2020-11-05 16:36:28,413 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.0000 | MSE 0.1883
2020-11-05 16:36:28,418 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2178 | Iter Mean Loss 12.2178
2020-11-05 16:36:28,424 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8015 | Iter Mean Loss 7.0097
2020-11-05 16:36:28,429 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8725 | Iter Mean Loss 9.2973
2020-11-05 16:36:28,435 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2052 | Iter Mean Loss 9.2742
2020-11-05 16:36:28,439 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8257 | Iter Mean Loss 8.1845
2020-11-05 16:36:28,440 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.0000 | MSE 0.1882
2020-11-05 16:36:28,446 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2025 | Iter Mean Loss 12.2025
2020-11-05 16:36:28,451 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7987 | Iter Mean Loss 7.0006
2020-11-05 16:36:28,456 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8477 | Iter Mean Loss 9.2830
2020-11-05 16:36:28,462 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1931 | Iter Mean Loss 9.2605
2020-11-05 16:36:28,466 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8234 | Iter Mean Loss 8.1731
2020-11-05 16:36:28,467 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.0000 | MSE 0.1882
2020-11-05 16:36:28,473 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1873 | Iter Mean Loss 12.1873
2020-11-05 16:36:28,479 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7958 | Iter Mean Loss 6.9915
2020-11-05 16:36:28,485 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8230 | Iter Mean Loss 9.2687
2020-11-05 16:36:28,491 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1811 | Iter Mean Loss 9.2468
2020-11-05 16:36:28,496 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8212 | Iter Mean Loss 8.1617
2020-11-05 16:36:28,497 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.0000 | MSE 0.1881
2020-11-05 16:36:28,502 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1721 | Iter Mean Loss 12.1721
2020-11-05 16:36:28,508 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7929 | Iter Mean Loss 6.9825
2020-11-05 16:36:28,513 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7983 | Iter Mean Loss 9.2544
2020-11-05 16:36:28,518 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1691 | Iter Mean Loss 9.2331
2020-11-05 16:36:28,523 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8189 | Iter Mean Loss 8.1503
2020-11-05 16:36:28,524 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.0000 | MSE 0.1880
2020-11-05 16:36:28,529 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1569 | Iter Mean Loss 12.1569
2020-11-05 16:36:28,535 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7901 | Iter Mean Loss 6.9735
2020-11-05 16:36:28,541 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7737 | Iter Mean Loss 9.2402
2020-11-05 16:36:28,547 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1572 | Iter Mean Loss 9.2195
2020-11-05 16:36:28,552 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8167 | Iter Mean Loss 8.1389
2020-11-05 16:36:28,552 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.0000 | MSE 0.1880
2020-11-05 16:36:28,558 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1418 | Iter Mean Loss 12.1418
2020-11-05 16:36:28,563 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7872 | Iter Mean Loss 6.9645
2020-11-05 16:36:28,569 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7491 | Iter Mean Loss 9.2260
2020-11-05 16:36:28,576 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1453 | Iter Mean Loss 9.2058
2020-11-05 16:36:28,581 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8145 | Iter Mean Loss 8.1276
2020-11-05 16:36:28,582 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.0000 | MSE 0.1879
2020-11-05 16:36:28,590 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1267 | Iter Mean Loss 12.1267
2020-11-05 16:36:28,597 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7843 | Iter Mean Loss 6.9555
2020-11-05 16:36:28,604 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7245 | Iter Mean Loss 9.2119
2020-11-05 16:36:28,610 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1335 | Iter Mean Loss 9.1923
2020-11-05 16:36:28,615 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8122 | Iter Mean Loss 8.1163
2020-11-05 16:36:28,616 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.0000 | MSE 0.1879
2020-11-05 16:36:28,622 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1117 | Iter Mean Loss 12.1117
2020-11-05 16:36:28,627 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7814 | Iter Mean Loss 6.9466
2020-11-05 16:36:28,633 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7000 | Iter Mean Loss 9.1977
2020-11-05 16:36:28,638 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1218 | Iter Mean Loss 9.1787
2020-11-05 16:36:28,643 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8100 | Iter Mean Loss 8.1050
2020-11-05 16:36:28,644 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.0000 | MSE 0.1878
2020-11-05 16:36:28,649 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0967 | Iter Mean Loss 12.0967
2020-11-05 16:36:28,655 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7786 | Iter Mean Loss 6.9376
2020-11-05 16:36:28,661 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6756 | Iter Mean Loss 9.1836
2020-11-05 16:36:28,666 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1101 | Iter Mean Loss 9.1652
2020-11-05 16:36:28,672 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8077 | Iter Mean Loss 8.0937
2020-11-05 16:36:28,672 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.0000 | MSE 0.1877
2020-11-05 16:36:28,678 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0817 | Iter Mean Loss 12.0817
2020-11-05 16:36:28,684 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7757 | Iter Mean Loss 6.9287
2020-11-05 16:36:28,690 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6512 | Iter Mean Loss 9.1695
2020-11-05 16:36:28,696 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 9.1517
2020-11-05 16:36:28,702 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8055 | Iter Mean Loss 8.0825
2020-11-05 16:36:28,703 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.0000 | MSE 0.1877
2020-11-05 16:36:28,709 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0668 | Iter Mean Loss 12.0668
2020-11-05 16:36:28,715 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7728 | Iter Mean Loss 6.9198
2020-11-05 16:36:28,721 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6268 | Iter Mean Loss 9.1555
2020-11-05 16:36:28,727 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0868 | Iter Mean Loss 9.1383
2020-11-05 16:36:28,733 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8032 | Iter Mean Loss 8.0713
2020-11-05 16:36:28,734 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.0000 | MSE 0.1876
2020-11-05 16:36:28,740 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0520 | Iter Mean Loss 12.0520
2020-11-05 16:36:28,747 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7699 | Iter Mean Loss 6.9109
2020-11-05 16:36:28,752 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6025 | Iter Mean Loss 9.1414
2020-11-05 16:36:28,758 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0753 | Iter Mean Loss 9.1249
2020-11-05 16:36:28,763 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8010 | Iter Mean Loss 8.0601
2020-11-05 16:36:28,765 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.0000 | MSE 0.1875
2020-11-05 16:36:28,772 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0371 | Iter Mean Loss 12.0371
2020-11-05 16:36:28,778 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7670 | Iter Mean Loss 6.9021
2020-11-05 16:36:28,783 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5782 | Iter Mean Loss 9.1274
2020-11-05 16:36:28,789 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0638 | Iter Mean Loss 9.1115
2020-11-05 16:36:28,794 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7987 | Iter Mean Loss 8.0490
2020-11-05 16:36:28,795 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.0000 | MSE 0.1875
2020-11-05 16:36:28,801 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0223 | Iter Mean Loss 12.0223
2020-11-05 16:36:28,807 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7641 | Iter Mean Loss 6.8932
2020-11-05 16:36:28,813 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5539 | Iter Mean Loss 9.1135
2020-11-05 16:36:28,820 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0523 | Iter Mean Loss 9.0982
2020-11-05 16:36:28,825 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7965 | Iter Mean Loss 8.0378
2020-11-05 16:36:28,826 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.0000 | MSE 0.1874
2020-11-05 16:36:28,833 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0076 | Iter Mean Loss 12.0076
2020-11-05 16:36:28,839 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7613 | Iter Mean Loss 6.8844
2020-11-05 16:36:28,845 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5298 | Iter Mean Loss 9.0995
2020-11-05 16:36:28,850 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0409 | Iter Mean Loss 9.0849
2020-11-05 16:36:28,855 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7942 | Iter Mean Loss 8.0267
2020-11-05 16:36:28,856 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.0000 | MSE 0.1874
2020-11-05 16:36:28,862 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9929 | Iter Mean Loss 11.9929
2020-11-05 16:36:28,868 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7584 | Iter Mean Loss 6.8756
2020-11-05 16:36:28,874 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5056 | Iter Mean Loss 9.0856
2020-11-05 16:36:28,879 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0296 | Iter Mean Loss 9.0716
2020-11-05 16:36:28,884 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7919 | Iter Mean Loss 8.0157
2020-11-05 16:36:28,885 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.0000 | MSE 0.1873
2020-11-05 16:36:28,891 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9782 | Iter Mean Loss 11.9782
2020-11-05 16:36:28,897 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7555 | Iter Mean Loss 6.8669
2020-11-05 16:36:28,902 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4815 | Iter Mean Loss 9.0717
2020-11-05 16:36:28,908 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0183 | Iter Mean Loss 9.0584
2020-11-05 16:36:28,913 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7897 | Iter Mean Loss 8.0046
2020-11-05 16:36:28,914 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.0000 | MSE 0.1872
2020-11-05 16:36:28,920 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 11.9636
2020-11-05 16:36:28,926 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7526 | Iter Mean Loss 6.8581
2020-11-05 16:36:28,932 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4575 | Iter Mean Loss 9.0579
2020-11-05 16:36:28,937 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0070 | Iter Mean Loss 9.0452
2020-11-05 16:36:28,942 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7874 | Iter Mean Loss 7.9936
2020-11-05 16:36:28,943 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.0000 | MSE 0.1872
2020-11-05 16:36:28,951 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9490 | Iter Mean Loss 11.9490
2020-11-05 16:36:28,957 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7497 | Iter Mean Loss 6.8494
2020-11-05 16:36:28,962 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4335 | Iter Mean Loss 9.0441
2020-11-05 16:36:28,968 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9958 | Iter Mean Loss 9.0320
2020-11-05 16:36:28,973 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7851 | Iter Mean Loss 7.9826
2020-11-05 16:36:28,974 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.0000 | MSE 0.1871
2020-11-05 16:36:28,980 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9345 | Iter Mean Loss 11.9345
2020-11-05 16:36:28,986 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7468 | Iter Mean Loss 6.8406
2020-11-05 16:36:28,992 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4095 | Iter Mean Loss 9.0303
2020-11-05 16:36:28,999 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9847 | Iter Mean Loss 9.0189
2020-11-05 16:36:29,004 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7829 | Iter Mean Loss 7.9717
2020-11-05 16:36:29,005 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.0000 | MSE 0.1870
2020-11-05 16:36:29,011 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9200 | Iter Mean Loss 11.9200
2020-11-05 16:36:29,017 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7439 | Iter Mean Loss 6.8319
2020-11-05 16:36:29,023 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3856 | Iter Mean Loss 9.0165
2020-11-05 16:36:29,030 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9736 | Iter Mean Loss 9.0058
2020-11-05 16:36:29,035 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7806 | Iter Mean Loss 7.9607
2020-11-05 16:36:29,036 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.0000 | MSE 0.1870
2020-11-05 16:36:29,042 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9055 | Iter Mean Loss 11.9055
2020-11-05 16:36:29,049 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7410 | Iter Mean Loss 6.8233
2020-11-05 16:36:29,055 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3617 | Iter Mean Loss 9.0028
2020-11-05 16:36:29,061 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9625 | Iter Mean Loss 8.9927
2020-11-05 16:36:29,066 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7783 | Iter Mean Loss 7.9498
2020-11-05 16:36:29,067 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.0000 | MSE 0.1869
2020-11-05 16:36:29,074 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8911 | Iter Mean Loss 11.8911
2020-11-05 16:36:29,080 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7381 | Iter Mean Loss 6.8146
2020-11-05 16:36:29,085 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3379 | Iter Mean Loss 8.9890
2020-11-05 16:36:29,091 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9515 | Iter Mean Loss 8.9797
2020-11-05 16:36:29,097 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7760 | Iter Mean Loss 7.9389
2020-11-05 16:36:29,097 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.0000 | MSE 0.1869
2020-11-05 16:36:29,103 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8767 | Iter Mean Loss 11.8767
2020-11-05 16:36:29,110 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7352 | Iter Mean Loss 6.8060
2020-11-05 16:36:29,117 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3141 | Iter Mean Loss 8.9754
2020-11-05 16:36:29,123 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9405 | Iter Mean Loss 8.9667
2020-11-05 16:36:29,128 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7738 | Iter Mean Loss 7.9281
2020-11-05 16:36:29,129 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.0000 | MSE 0.1868
2020-11-05 16:36:29,135 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8624 | Iter Mean Loss 11.8624
2020-11-05 16:36:29,141 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7323 | Iter Mean Loss 6.7974
2020-11-05 16:36:29,147 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2904 | Iter Mean Loss 8.9617
2020-11-05 16:36:29,155 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9296 | Iter Mean Loss 8.9537
2020-11-05 16:36:29,160 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7715 | Iter Mean Loss 7.9173
2020-11-05 16:36:29,161 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.0000 | MSE 0.1867
2020-11-05 16:36:29,169 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8481 | Iter Mean Loss 11.8481
2020-11-05 16:36:29,176 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7294 | Iter Mean Loss 6.7888
2020-11-05 16:36:29,181 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2668 | Iter Mean Loss 8.9481
2020-11-05 16:36:29,187 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9188 | Iter Mean Loss 8.9408
2020-11-05 16:36:29,192 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7692 | Iter Mean Loss 7.9064
2020-11-05 16:36:29,194 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.0000 | MSE 0.1867
2020-11-05 16:36:29,201 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8339 | Iter Mean Loss 11.8339
2020-11-05 16:36:29,207 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7265 | Iter Mean Loss 6.7802
2020-11-05 16:36:29,213 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2431 | Iter Mean Loss 8.9345
2020-11-05 16:36:29,219 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9079 | Iter Mean Loss 8.9279
2020-11-05 16:36:29,224 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7669 | Iter Mean Loss 7.8957
2020-11-05 16:36:29,225 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.0000 | MSE 0.1866
2020-11-05 16:36:29,231 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8197 | Iter Mean Loss 11.8197
2020-11-05 16:36:29,237 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7236 | Iter Mean Loss 6.7716
2020-11-05 16:36:29,242 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2196 | Iter Mean Loss 8.9209
2020-11-05 16:36:29,248 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8972 | Iter Mean Loss 8.9150
2020-11-05 16:36:29,253 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7646 | Iter Mean Loss 7.8849
2020-11-05 16:36:29,254 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.0000 | MSE 0.1866
2020-11-05 16:36:29,260 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8055 | Iter Mean Loss 11.8055
2020-11-05 16:36:29,265 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7207 | Iter Mean Loss 6.7631
2020-11-05 16:36:29,271 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1961 | Iter Mean Loss 8.9074
2020-11-05 16:36:29,277 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8865 | Iter Mean Loss 8.9022
2020-11-05 16:36:29,282 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7623 | Iter Mean Loss 7.8742
2020-11-05 16:36:29,283 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.0000 | MSE 0.1865
2020-11-05 16:36:29,289 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7914 | Iter Mean Loss 11.7914
2020-11-05 16:36:29,295 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7178 | Iter Mean Loss 6.7546
2020-11-05 16:36:29,301 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1726 | Iter Mean Loss 8.8939
2020-11-05 16:36:29,307 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8758 | Iter Mean Loss 8.8894
2020-11-05 16:36:29,313 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7600 | Iter Mean Loss 7.8635
2020-11-05 16:36:29,314 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.0000 | MSE 0.1864
2020-11-05 16:36:29,320 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7773 | Iter Mean Loss 11.7773
2020-11-05 16:36:29,326 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7149 | Iter Mean Loss 6.7461
2020-11-05 16:36:29,331 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1492 | Iter Mean Loss 8.8804
2020-11-05 16:36:29,337 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8651 | Iter Mean Loss 8.8766
2020-11-05 16:36:29,341 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7578 | Iter Mean Loss 7.8528
2020-11-05 16:36:29,342 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.0000 | MSE 0.1864
2020-11-05 16:36:29,348 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7632 | Iter Mean Loss 11.7632
2020-11-05 16:36:29,353 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7120 | Iter Mean Loss 6.7376
2020-11-05 16:36:29,359 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1258 | Iter Mean Loss 8.8670
2020-11-05 16:36:29,366 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8546 | Iter Mean Loss 8.8639
2020-11-05 16:36:29,371 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7555 | Iter Mean Loss 7.8422
2020-11-05 16:36:29,372 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.0000 | MSE 0.1863
2020-11-05 16:36:29,378 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7492 | Iter Mean Loss 11.7492
2020-11-05 16:36:29,384 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7091 | Iter Mean Loss 6.7292
2020-11-05 16:36:29,390 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1025 | Iter Mean Loss 8.8536
2020-11-05 16:36:29,397 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8440 | Iter Mean Loss 8.8512
2020-11-05 16:36:29,402 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7532 | Iter Mean Loss 7.8316
2020-11-05 16:36:29,403 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.0000 | MSE 0.1862
2020-11-05 16:36:29,409 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7352 | Iter Mean Loss 11.7352
2020-11-05 16:36:29,414 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7062 | Iter Mean Loss 6.7207
2020-11-05 16:36:29,420 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0792 | Iter Mean Loss 8.8402
2020-11-05 16:36:29,426 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8335 | Iter Mean Loss 8.8385
2020-11-05 16:36:29,431 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7509 | Iter Mean Loss 7.8210
2020-11-05 16:36:29,432 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.0000 | MSE 0.1862
2020-11-05 16:36:29,438 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7213 | Iter Mean Loss 11.7213
2020-11-05 16:36:29,444 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7033 | Iter Mean Loss 6.7123
2020-11-05 16:36:29,450 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0560 | Iter Mean Loss 8.8269
2020-11-05 16:36:29,456 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8231 | Iter Mean Loss 8.8259
2020-11-05 16:36:29,462 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7486 | Iter Mean Loss 7.8105
2020-11-05 16:36:29,463 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.0000 | MSE 0.1861
2020-11-05 16:36:29,469 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7074 | Iter Mean Loss 11.7074
2020-11-05 16:36:29,475 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7004 | Iter Mean Loss 6.7039
2020-11-05 16:36:29,481 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0328 | Iter Mean Loss 8.8136
2020-11-05 16:36:29,487 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8127 | Iter Mean Loss 8.8133
2020-11-05 16:36:29,494 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7463 | Iter Mean Loss 7.7999
2020-11-05 16:36:29,495 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.0000 | MSE 0.1861
2020-11-05 16:36:29,501 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6936 | Iter Mean Loss 11.6936
2020-11-05 16:36:29,507 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6975 | Iter Mean Loss 6.6955
2020-11-05 16:36:29,513 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0097 | Iter Mean Loss 8.8003
2020-11-05 16:36:29,521 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8023 | Iter Mean Loss 8.8008
2020-11-05 16:36:29,527 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7440 | Iter Mean Loss 7.7894
2020-11-05 16:36:29,528 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.0000 | MSE 0.1860
2020-11-05 16:36:29,534 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6798 | Iter Mean Loss 11.6798
2020-11-05 16:36:29,540 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6946 | Iter Mean Loss 6.6872
2020-11-05 16:36:29,546 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9867 | Iter Mean Loss 8.7870
2020-11-05 16:36:29,553 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7920 | Iter Mean Loss 8.7883
2020-11-05 16:36:29,560 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7417 | Iter Mean Loss 7.7790
2020-11-05 16:36:29,561 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.0000 | MSE 0.1859
2020-11-05 16:36:29,567 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6660 | Iter Mean Loss 11.6660
2020-11-05 16:36:29,573 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6917 | Iter Mean Loss 6.6789
2020-11-05 16:36:29,579 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9637 | Iter Mean Loss 8.7738
2020-11-05 16:36:29,585 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7818 | Iter Mean Loss 8.7758
2020-11-05 16:36:29,592 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7394 | Iter Mean Loss 7.7685
2020-11-05 16:36:29,593 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.0000 | MSE 0.1859
2020-11-05 16:36:29,600 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6523 | Iter Mean Loss 11.6523
2020-11-05 16:36:29,606 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6888 | Iter Mean Loss 6.6705
2020-11-05 16:36:29,611 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9407 | Iter Mean Loss 8.7606
2020-11-05 16:36:29,617 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7716 | Iter Mean Loss 8.7633
2020-11-05 16:36:29,623 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7371 | Iter Mean Loss 7.7581
2020-11-05 16:36:29,624 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.0000 | MSE 0.1858
2020-11-05 16:36:29,631 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6386 | Iter Mean Loss 11.6386
2020-11-05 16:36:29,638 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6859 | Iter Mean Loss 6.6623
2020-11-05 16:36:29,644 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9178 | Iter Mean Loss 8.7475
2020-11-05 16:36:29,650 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7614 | Iter Mean Loss 8.7509
2020-11-05 16:36:29,655 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7348 | Iter Mean Loss 7.7477
2020-11-05 16:36:29,656 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.0000 | MSE 0.1857
2020-11-05 16:36:29,662 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6249 | Iter Mean Loss 11.6249
2020-11-05 16:36:29,668 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6830 | Iter Mean Loss 6.6540
2020-11-05 16:36:29,674 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8950 | Iter Mean Loss 8.7343
2020-11-05 16:36:29,680 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7513 | Iter Mean Loss 8.7386
2020-11-05 16:36:29,685 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7325 | Iter Mean Loss 7.7373
2020-11-05 16:36:29,686 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.0000 | MSE 0.1857
2020-11-05 16:36:29,692 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6113 | Iter Mean Loss 11.6113
2020-11-05 16:36:29,698 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6802 | Iter Mean Loss 6.6457
2020-11-05 16:36:29,704 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8722 | Iter Mean Loss 8.7212
2020-11-05 16:36:29,711 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7412 | Iter Mean Loss 8.7262
2020-11-05 16:36:29,717 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7302 | Iter Mean Loss 7.7270
2020-11-05 16:36:29,718 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.0000 | MSE 0.1856
2020-11-05 16:36:29,725 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5978 | Iter Mean Loss 11.5978
2020-11-05 16:36:29,732 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6773 | Iter Mean Loss 6.6375
2020-11-05 16:36:29,738 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8495 | Iter Mean Loss 8.7082
2020-11-05 16:36:29,744 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7312 | Iter Mean Loss 8.7139
2020-11-05 16:36:29,750 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7278 | Iter Mean Loss 7.7167
2020-11-05 16:36:29,751 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.0000 | MSE 0.1856
2020-11-05 16:36:29,757 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5842 | Iter Mean Loss 11.5842
2020-11-05 16:36:29,763 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6744 | Iter Mean Loss 6.6293
2020-11-05 16:36:29,771 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8268 | Iter Mean Loss 8.6952
2020-11-05 16:36:29,777 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7212 | Iter Mean Loss 8.7017
2020-11-05 16:36:29,783 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7255 | Iter Mean Loss 7.7064
2020-11-05 16:36:29,784 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.0000 | MSE 0.1855
2020-11-05 16:36:29,790 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 11.5708
2020-11-05 16:36:29,796 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6715 | Iter Mean Loss 6.6211
2020-11-05 16:36:29,803 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8042 | Iter Mean Loss 8.6822
2020-11-05 16:36:29,809 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7112 | Iter Mean Loss 8.6894
2020-11-05 16:36:29,816 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7232 | Iter Mean Loss 7.6962
2020-11-05 16:36:29,817 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.0000 | MSE 0.1854
2020-11-05 16:36:29,823 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5573 | Iter Mean Loss 11.5573
2020-11-05 16:36:29,829 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6686 | Iter Mean Loss 6.6130
2020-11-05 16:36:29,835 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7817 | Iter Mean Loss 8.6692
2020-11-05 16:36:29,841 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7013 | Iter Mean Loss 8.6772
2020-11-05 16:36:29,846 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7209 | Iter Mean Loss 7.6860
2020-11-05 16:36:29,847 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.0000 | MSE 0.1854
2020-11-05 16:36:29,853 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5439 | Iter Mean Loss 11.5439
2020-11-05 16:36:29,858 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6658 | Iter Mean Loss 6.6048
2020-11-05 16:36:29,864 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7592 | Iter Mean Loss 8.6563
2020-11-05 16:36:29,870 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6915 | Iter Mean Loss 8.6651
2020-11-05 16:36:29,875 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7186 | Iter Mean Loss 7.6758
2020-11-05 16:36:29,876 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.0000 | MSE 0.1853
2020-11-05 16:36:29,881 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5305 | Iter Mean Loss 11.5305
2020-11-05 16:36:29,887 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6629 | Iter Mean Loss 6.5967
2020-11-05 16:36:29,893 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7367 | Iter Mean Loss 8.6434
2020-11-05 16:36:29,898 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6817 | Iter Mean Loss 8.6530
2020-11-05 16:36:29,903 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7163 | Iter Mean Loss 7.6656
2020-11-05 16:36:29,904 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.0000 | MSE 0.1852
2020-11-05 16:36:29,910 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5172 | Iter Mean Loss 11.5172
2020-11-05 16:36:29,915 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6600 | Iter Mean Loss 6.5886
2020-11-05 16:36:29,921 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7143 | Iter Mean Loss 8.6305
2020-11-05 16:36:29,927 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6719 | Iter Mean Loss 8.6409
2020-11-05 16:36:29,931 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7140 | Iter Mean Loss 7.6555
2020-11-05 16:36:29,932 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.0000 | MSE 0.1852
2020-11-05 16:36:29,938 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5039 | Iter Mean Loss 11.5039
2020-11-05 16:36:29,943 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6572 | Iter Mean Loss 6.5805
2020-11-05 16:36:29,949 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6920 | Iter Mean Loss 8.6177
2020-11-05 16:36:29,955 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6622 | Iter Mean Loss 8.6288
2020-11-05 16:36:29,961 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7117 | Iter Mean Loss 7.6454
2020-11-05 16:36:29,962 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.0000 | MSE 0.1851
2020-11-05 16:36:29,968 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4907 | Iter Mean Loss 11.4907
2020-11-05 16:36:29,974 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 6.5725
2020-11-05 16:36:29,979 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6698 | Iter Mean Loss 8.6049
2020-11-05 16:36:29,985 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6525 | Iter Mean Loss 8.6168
2020-11-05 16:36:29,991 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7094 | Iter Mean Loss 7.6353
2020-11-05 16:36:29,992 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.0000 | MSE 0.1851
2020-11-05 16:36:29,998 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4775 | Iter Mean Loss 11.4775
2020-11-05 16:36:30,004 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6514 | Iter Mean Loss 6.5645
2020-11-05 16:36:30,010 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6475 | Iter Mean Loss 8.5922
2020-11-05 16:36:30,016 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6429 | Iter Mean Loss 8.6048
2020-11-05 16:36:30,022 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7071 | Iter Mean Loss 7.6253
2020-11-05 16:36:30,025 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.0000 | MSE 0.1850
2020-11-05 16:36:30,031 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4643 | Iter Mean Loss 11.4643
2020-11-05 16:36:30,037 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6486 | Iter Mean Loss 6.5565
2020-11-05 16:36:30,043 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6254 | Iter Mean Loss 8.5794
2020-11-05 16:36:30,049 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6333 | Iter Mean Loss 8.5929
2020-11-05 16:36:30,054 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7048 | Iter Mean Loss 7.6153
2020-11-05 16:36:30,055 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.0000 | MSE 0.1849
2020-11-05 16:36:30,060 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4512 | Iter Mean Loss 11.4512
2020-11-05 16:36:30,066 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6457 | Iter Mean Loss 6.5485
2020-11-05 16:36:30,071 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6033 | Iter Mean Loss 8.5667
2020-11-05 16:36:30,077 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6237 | Iter Mean Loss 8.5810
2020-11-05 16:36:30,082 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7025 | Iter Mean Loss 7.6053
2020-11-05 16:36:30,082 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.0000 | MSE 0.1849
2020-11-05 16:36:30,088 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4381 | Iter Mean Loss 11.4381
2020-11-05 16:36:30,093 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6429 | Iter Mean Loss 6.5405
2020-11-05 16:36:30,099 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5813 | Iter Mean Loss 8.5541
2020-11-05 16:36:30,105 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6142 | Iter Mean Loss 8.5691
2020-11-05 16:36:30,109 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7002 | Iter Mean Loss 7.5953
2020-11-05 16:36:30,110 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.0000 | MSE 0.1848
2020-11-05 16:36:30,116 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4251 | Iter Mean Loss 11.4251
2020-11-05 16:36:30,122 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6400 | Iter Mean Loss 6.5326
2020-11-05 16:36:30,129 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5593 | Iter Mean Loss 8.5415
2020-11-05 16:36:30,137 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6048 | Iter Mean Loss 8.5573
2020-11-05 16:36:30,142 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6978 | Iter Mean Loss 7.5854
2020-11-05 16:36:30,143 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.0000 | MSE 0.1847
2020-11-05 16:36:30,150 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4121 | Iter Mean Loss 11.4121
2020-11-05 16:36:30,156 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6372 | Iter Mean Loss 6.5246
2020-11-05 16:36:30,162 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5374 | Iter Mean Loss 8.5289
2020-11-05 16:36:30,168 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5954 | Iter Mean Loss 8.5455
2020-11-05 16:36:30,173 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6955 | Iter Mean Loss 7.5755
2020-11-05 16:36:30,175 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.0000 | MSE 0.1847
2020-11-05 16:36:30,181 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3991 | Iter Mean Loss 11.3991
2020-11-05 16:36:30,189 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6344 | Iter Mean Loss 6.5167
2020-11-05 16:36:30,196 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5156 | Iter Mean Loss 8.5164
2020-11-05 16:36:30,203 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5860 | Iter Mean Loss 8.5338
2020-11-05 16:36:30,210 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6932 | Iter Mean Loss 7.5657
2020-11-05 16:36:30,211 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.0000 | MSE 0.1846
2020-11-05 16:36:30,219 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3862 | Iter Mean Loss 11.3862
2020-11-05 16:36:30,226 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6316 | Iter Mean Loss 6.5089
2020-11-05 16:36:30,233 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4938 | Iter Mean Loss 8.5038
2020-11-05 16:36:30,240 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5221
2020-11-05 16:36:30,246 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6909 | Iter Mean Loss 7.5558
2020-11-05 16:36:30,247 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.0000 | MSE 0.1846
2020-11-05 16:36:30,254 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3733 | Iter Mean Loss 11.3733
2020-11-05 16:36:30,260 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6287 | Iter Mean Loss 6.5010
2020-11-05 16:36:30,266 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4721 | Iter Mean Loss 8.4914
2020-11-05 16:36:30,272 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5674 | Iter Mean Loss 8.5104
2020-11-05 16:36:30,277 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6886 | Iter Mean Loss 7.5460
2020-11-05 16:36:30,278 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.0000 | MSE 0.1845
2020-11-05 16:36:30,284 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3604 | Iter Mean Loss 11.3604
2020-11-05 16:36:30,290 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6259 | Iter Mean Loss 6.4932
2020-11-05 16:36:30,297 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4505 | Iter Mean Loss 8.4789
2020-11-05 16:36:30,303 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5582 | Iter Mean Loss 8.4987
2020-11-05 16:36:30,309 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6863 | Iter Mean Loss 7.5363
2020-11-05 16:36:30,311 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.0000 | MSE 0.1844
2020-11-05 16:36:30,321 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3476 | Iter Mean Loss 11.3476
2020-11-05 16:36:30,329 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6231 | Iter Mean Loss 6.4854
2020-11-05 16:36:30,337 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4289 | Iter Mean Loss 8.4665
2020-11-05 16:36:30,344 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5490 | Iter Mean Loss 8.4871
2020-11-05 16:36:30,351 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6840 | Iter Mean Loss 7.5265
2020-11-05 16:36:30,353 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.0000 | MSE 0.1844
2020-11-05 16:36:30,361 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3349 | Iter Mean Loss 11.3349
2020-11-05 16:36:30,371 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6203 | Iter Mean Loss 6.4776
2020-11-05 16:36:30,377 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4073 | Iter Mean Loss 8.4542
2020-11-05 16:36:30,387 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5398 | Iter Mean Loss 8.4756
2020-11-05 16:36:30,393 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6818 | Iter Mean Loss 7.5168
2020-11-05 16:36:30,394 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.0000 | MSE 0.1843
2020-11-05 16:36:30,401 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3221 | Iter Mean Loss 11.3221
2020-11-05 16:36:30,408 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6175 | Iter Mean Loss 6.4698
2020-11-05 16:36:30,414 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3859 | Iter Mean Loss 8.4418
2020-11-05 16:36:30,420 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5307 | Iter Mean Loss 8.4641
2020-11-05 16:36:30,426 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6795 | Iter Mean Loss 7.5071
2020-11-05 16:36:30,427 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.0000 | MSE 0.1842
2020-11-05 16:36:30,434 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3094 | Iter Mean Loss 11.3094
2020-11-05 16:36:30,440 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6147 | Iter Mean Loss 6.4621
2020-11-05 16:36:30,447 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3645 | Iter Mean Loss 8.4296
2020-11-05 16:36:30,453 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5217 | Iter Mean Loss 8.4526
2020-11-05 16:36:30,458 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6772 | Iter Mean Loss 7.4975
2020-11-05 16:36:30,459 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.0000 | MSE 0.1842
2020-11-05 16:36:30,465 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2968 | Iter Mean Loss 11.2968
2020-11-05 16:36:30,471 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6119 | Iter Mean Loss 6.4544
2020-11-05 16:36:30,477 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3432 | Iter Mean Loss 8.4173
2020-11-05 16:36:30,483 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5127 | Iter Mean Loss 8.4411
2020-11-05 16:36:30,488 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6749 | Iter Mean Loss 7.4879
2020-11-05 16:36:30,489 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.0000 | MSE 0.1841
2020-11-05 16:36:30,495 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2842 | Iter Mean Loss 11.2842
2020-11-05 16:36:30,501 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6092 | Iter Mean Loss 6.4467
2020-11-05 16:36:30,507 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3219 | Iter Mean Loss 8.4051
2020-11-05 16:36:30,513 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5037 | Iter Mean Loss 8.4297
2020-11-05 16:36:30,519 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6726 | Iter Mean Loss 7.4783
2020-11-05 16:36:30,520 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.0000 | MSE 0.1841
2020-11-05 16:36:30,526 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2716 | Iter Mean Loss 11.2716
2020-11-05 16:36:30,532 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6064 | Iter Mean Loss 6.4390
2020-11-05 16:36:30,538 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3007 | Iter Mean Loss 8.3929
2020-11-05 16:36:30,545 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 8.4184
2020-11-05 16:36:30,551 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6703 | Iter Mean Loss 7.4688
2020-11-05 16:36:30,552 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.0000 | MSE 0.1840
2020-11-05 16:36:30,558 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2591 | Iter Mean Loss 11.2591
2020-11-05 16:36:30,564 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6036 | Iter Mean Loss 6.4314
2020-11-05 16:36:30,570 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2796 | Iter Mean Loss 8.3808
2020-11-05 16:36:30,576 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4859 | Iter Mean Loss 8.4070
2020-11-05 16:36:30,583 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6680 | Iter Mean Loss 7.4592
2020-11-05 16:36:30,584 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.0000 | MSE 0.1839
2020-11-05 16:36:30,591 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2466 | Iter Mean Loss 11.2466
2020-11-05 16:36:30,597 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6009 | Iter Mean Loss 6.4237
2020-11-05 16:36:30,603 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2585 | Iter Mean Loss 8.3687
2020-11-05 16:36:30,611 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4771 | Iter Mean Loss 8.3958
2020-11-05 16:36:30,617 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6658 | Iter Mean Loss 7.4498
2020-11-05 16:36:30,617 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.0000 | MSE 0.1839
2020-11-05 16:36:30,624 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2341 | Iter Mean Loss 11.2341
2020-11-05 16:36:30,630 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5981 | Iter Mean Loss 6.4161
2020-11-05 16:36:30,636 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2375 | Iter Mean Loss 8.3566
2020-11-05 16:36:30,642 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4683 | Iter Mean Loss 8.3845
2020-11-05 16:36:30,648 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6635 | Iter Mean Loss 7.4403
2020-11-05 16:36:30,649 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.0000 | MSE 0.1838
2020-11-05 16:36:30,655 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2217 | Iter Mean Loss 11.2217
2020-11-05 16:36:30,661 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5954 | Iter Mean Loss 6.4086
2020-11-05 16:36:30,667 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2166 | Iter Mean Loss 8.3446
2020-11-05 16:36:30,673 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4595 | Iter Mean Loss 8.3733
2020-11-05 16:36:30,678 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6612 | Iter Mean Loss 7.4309
2020-11-05 16:36:30,679 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.0000 | MSE 0.1838
2020-11-05 16:36:30,685 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2093 | Iter Mean Loss 11.2093
2020-11-05 16:36:30,691 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5927 | Iter Mean Loss 6.4010
2020-11-05 16:36:30,697 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1957 | Iter Mean Loss 8.3326
2020-11-05 16:36:30,703 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4508 | Iter Mean Loss 8.3621
2020-11-05 16:36:30,708 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6590 | Iter Mean Loss 7.4215
2020-11-05 16:36:30,709 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.0000 | MSE 0.1837
2020-11-05 16:36:30,715 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1970 | Iter Mean Loss 11.1970
2020-11-05 16:36:30,721 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5900 | Iter Mean Loss 6.3935
2020-11-05 16:36:30,727 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1749 | Iter Mean Loss 8.3206
2020-11-05 16:36:30,733 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4421 | Iter Mean Loss 8.3510
2020-11-05 16:36:30,738 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6567 | Iter Mean Loss 7.4121
2020-11-05 16:36:30,739 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.0000 | MSE 0.1836
2020-11-05 16:36:30,746 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1847 | Iter Mean Loss 11.1847
2020-11-05 16:36:30,752 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 6.3860
2020-11-05 16:36:30,758 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1542 | Iter Mean Loss 8.3087
2020-11-05 16:36:30,765 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4335 | Iter Mean Loss 8.3399
2020-11-05 16:36:30,770 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6544 | Iter Mean Loss 7.4028
2020-11-05 16:36:30,771 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.0000 | MSE 0.1836
2020-11-05 16:36:30,777 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1724 | Iter Mean Loss 11.1724
2020-11-05 16:36:30,783 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5845 | Iter Mean Loss 6.3785
2020-11-05 16:36:30,789 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1335 | Iter Mean Loss 8.2968
2020-11-05 16:36:30,796 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4250 | Iter Mean Loss 8.3289
2020-11-05 16:36:30,801 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6522 | Iter Mean Loss 7.3935
2020-11-05 16:36:30,802 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.0000 | MSE 0.1835
2020-11-05 16:36:30,808 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1602 | Iter Mean Loss 11.1602
2020-11-05 16:36:30,814 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5818 | Iter Mean Loss 6.3710
2020-11-05 16:36:30,820 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1129 | Iter Mean Loss 8.2850
2020-11-05 16:36:30,827 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4164 | Iter Mean Loss 8.3178
2020-11-05 16:36:30,832 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6499 | Iter Mean Loss 7.3843
2020-11-05 16:36:30,833 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.0000 | MSE 0.1834
2020-11-05 16:36:30,839 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1480 | Iter Mean Loss 11.1480
2020-11-05 16:36:30,844 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5792 | Iter Mean Loss 6.3636
2020-11-05 16:36:30,850 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0924 | Iter Mean Loss 8.2732
2020-11-05 16:36:30,855 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4079 | Iter Mean Loss 8.3069
2020-11-05 16:36:30,860 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6477 | Iter Mean Loss 7.3750
2020-11-05 16:36:30,861 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.0000 | MSE 0.1834
2020-11-05 16:36:30,867 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1358 | Iter Mean Loss 11.1358
2020-11-05 16:36:30,872 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5765 | Iter Mean Loss 6.3562
2020-11-05 16:36:30,878 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0720 | Iter Mean Loss 8.2614
2020-11-05 16:36:30,883 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3995 | Iter Mean Loss 8.2959
2020-11-05 16:36:30,888 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6455 | Iter Mean Loss 7.3658
2020-11-05 16:36:30,889 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.0000 | MSE 0.1833
2020-11-05 16:36:30,895 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1237 | Iter Mean Loss 11.1237
2020-11-05 16:36:30,901 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5738 | Iter Mean Loss 6.3488
2020-11-05 16:36:30,906 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0516 | Iter Mean Loss 8.2497
2020-11-05 16:36:30,912 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3911 | Iter Mean Loss 8.2850
2020-11-05 16:36:30,917 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 7.3567
2020-11-05 16:36:30,918 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.0000 | MSE 0.1833
2020-11-05 16:36:30,924 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1116 | Iter Mean Loss 11.1116
2020-11-05 16:36:30,930 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5712 | Iter Mean Loss 6.3414
2020-11-05 16:36:30,936 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0313 | Iter Mean Loss 8.2380
2020-11-05 16:36:30,941 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3827 | Iter Mean Loss 8.2742
2020-11-05 16:36:30,946 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6410 | Iter Mean Loss 7.3476
2020-11-05 16:36:30,947 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.0000 | MSE 0.1832
2020-11-05 16:36:30,953 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0996 | Iter Mean Loss 11.0996
2020-11-05 16:36:30,959 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5685 | Iter Mean Loss 6.3341
2020-11-05 16:36:30,964 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0110 | Iter Mean Loss 8.2264
2020-11-05 16:36:30,970 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3744 | Iter Mean Loss 8.2634
2020-11-05 16:36:30,976 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6388 | Iter Mean Loss 7.3385
2020-11-05 16:36:30,978 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.0000 | MSE 0.1831
2020-11-05 16:36:30,988 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0876 | Iter Mean Loss 11.0876
2020-11-05 16:36:30,997 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5659 | Iter Mean Loss 6.3267
2020-11-05 16:36:31,007 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9908 | Iter Mean Loss 8.2148
2020-11-05 16:36:31,018 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3661 | Iter Mean Loss 8.2526
2020-11-05 16:36:31,028 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6366 | Iter Mean Loss 7.3294
2020-11-05 16:36:31,029 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.0000 | MSE 0.1831
2020-11-05 16:36:31,038 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0756 | Iter Mean Loss 11.0756
2020-11-05 16:36:31,047 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 6.3194
2020-11-05 16:36:31,055 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9707 | Iter Mean Loss 8.2032
2020-11-05 16:36:31,063 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3579 | Iter Mean Loss 8.2419
2020-11-05 16:36:31,071 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6344 | Iter Mean Loss 7.3204
2020-11-05 16:36:31,072 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.0000 | MSE 0.1830
2020-11-05 16:36:31,080 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0637 | Iter Mean Loss 11.0637
2020-11-05 16:36:31,087 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5606 | Iter Mean Loss 6.3122
2020-11-05 16:36:31,092 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9507 | Iter Mean Loss 8.1917
2020-11-05 16:36:31,098 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3497 | Iter Mean Loss 8.2312
2020-11-05 16:36:31,103 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 7.3114
2020-11-05 16:36:31,104 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.0000 | MSE 0.1830
2020-11-05 16:36:31,109 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0518 | Iter Mean Loss 11.0518
2020-11-05 16:36:31,115 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5580 | Iter Mean Loss 6.3049
2020-11-05 16:36:31,121 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9307 | Iter Mean Loss 8.1802
2020-11-05 16:36:31,126 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3416 | Iter Mean Loss 8.2205
2020-11-05 16:36:31,131 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6300 | Iter Mean Loss 7.3024
2020-11-05 16:36:31,132 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.0000 | MSE 0.1829
2020-11-05 16:36:31,138 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0400 | Iter Mean Loss 11.0400
2020-11-05 16:36:31,143 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5554 | Iter Mean Loss 6.2977
2020-11-05 16:36:31,149 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9108 | Iter Mean Loss 8.1687
2020-11-05 16:36:31,155 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.2099
2020-11-05 16:36:31,159 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6278 | Iter Mean Loss 7.2935
2020-11-05 16:36:31,160 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.0000 | MSE 0.1828
2020-11-05 16:36:31,167 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0281 | Iter Mean Loss 11.0281
2020-11-05 16:36:31,173 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5529 | Iter Mean Loss 6.2905
2020-11-05 16:36:31,178 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8910 | Iter Mean Loss 8.1573
2020-11-05 16:36:31,184 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3254 | Iter Mean Loss 8.1994
2020-11-05 16:36:31,189 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 7.2846
2020-11-05 16:36:31,190 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.0000 | MSE 0.1828
2020-11-05 16:36:31,196 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0164 | Iter Mean Loss 11.0164
2020-11-05 16:36:31,204 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5503 | Iter Mean Loss 6.2833
2020-11-05 16:36:31,210 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8713 | Iter Mean Loss 8.1460
2020-11-05 16:36:31,215 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3174 | Iter Mean Loss 8.1888
2020-11-05 16:36:31,221 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6234 | Iter Mean Loss 7.2757
2020-11-05 16:36:31,222 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.0000 | MSE 0.1827
2020-11-05 16:36:31,228 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0046 | Iter Mean Loss 11.0046
2020-11-05 16:36:31,234 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5477 | Iter Mean Loss 6.2762
2020-11-05 16:36:31,239 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8516 | Iter Mean Loss 8.1346
2020-11-05 16:36:31,245 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3094 | Iter Mean Loss 8.1783
2020-11-05 16:36:31,250 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6212 | Iter Mean Loss 7.2669
2020-11-05 16:36:31,251 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.0000 | MSE 0.1827
2020-11-05 16:36:31,258 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9929 | Iter Mean Loss 10.9929
2020-11-05 16:36:31,265 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5452 | Iter Mean Loss 6.2690
2020-11-05 16:36:31,271 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8320 | Iter Mean Loss 8.1234
2020-11-05 16:36:31,278 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3015 | Iter Mean Loss 8.1679
2020-11-05 16:36:31,283 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6190 | Iter Mean Loss 7.2581
2020-11-05 16:36:31,284 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.0000 | MSE 0.1826
2020-11-05 16:36:31,290 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9812 | Iter Mean Loss 10.9812
2020-11-05 16:36:31,295 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5426 | Iter Mean Loss 6.2619
2020-11-05 16:36:31,302 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8124 | Iter Mean Loss 8.1121
2020-11-05 16:36:31,310 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2936 | Iter Mean Loss 8.1575
2020-11-05 16:36:31,316 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6169 | Iter Mean Loss 7.2494
2020-11-05 16:36:31,317 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.0000 | MSE 0.1825
2020-11-05 16:36:31,325 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9696 | Iter Mean Loss 10.9696
2020-11-05 16:36:31,331 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5401 | Iter Mean Loss 6.2549
2020-11-05 16:36:31,338 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7930 | Iter Mean Loss 8.1009
2020-11-05 16:36:31,343 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2857 | Iter Mean Loss 8.1471
2020-11-05 16:36:31,349 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6147 | Iter Mean Loss 7.2406
2020-11-05 16:36:31,350 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.0000 | MSE 0.1825
2020-11-05 16:36:31,356 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9580 | Iter Mean Loss 10.9580
2020-11-05 16:36:31,362 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5376 | Iter Mean Loss 6.2478
2020-11-05 16:36:31,368 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7736 | Iter Mean Loss 8.0897
2020-11-05 16:36:31,375 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2779 | Iter Mean Loss 8.1368
2020-11-05 16:36:31,379 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6126 | Iter Mean Loss 7.2319
2020-11-05 16:36:31,380 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.0000 | MSE 0.1824
2020-11-05 16:36:31,386 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9464 | Iter Mean Loss 10.9464
2020-11-05 16:36:31,391 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5351 | Iter Mean Loss 6.2408
2020-11-05 16:36:31,397 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7543 | Iter Mean Loss 8.0786
2020-11-05 16:36:31,403 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2702 | Iter Mean Loss 8.1265
2020-11-05 16:36:31,409 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6104 | Iter Mean Loss 7.2233
2020-11-05 16:36:31,410 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.0000 | MSE 0.1824
2020-11-05 16:36:31,415 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9349 | Iter Mean Loss 10.9349
2020-11-05 16:36:31,421 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5326 | Iter Mean Loss 6.2338
2020-11-05 16:36:31,427 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7350 | Iter Mean Loss 8.0675
2020-11-05 16:36:31,433 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2624 | Iter Mean Loss 8.1162
2020-11-05 16:36:31,438 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6083 | Iter Mean Loss 7.2147
2020-11-05 16:36:31,440 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.0000 | MSE 0.1823
2020-11-05 16:36:31,446 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9234 | Iter Mean Loss 10.9234
2020-11-05 16:36:31,452 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5301 | Iter Mean Loss 6.2268
2020-11-05 16:36:31,457 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7158 | Iter Mean Loss 8.0565
2020-11-05 16:36:31,464 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2548 | Iter Mean Loss 8.1060
2020-11-05 16:36:31,470 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6062 | Iter Mean Loss 7.2061
2020-11-05 16:36:31,471 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.0000 | MSE 0.1822
2020-11-05 16:36:31,477 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9120 | Iter Mean Loss 10.9120
2020-11-05 16:36:31,482 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5277 | Iter Mean Loss 6.2198
2020-11-05 16:36:31,488 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6967 | Iter Mean Loss 8.0454
2020-11-05 16:36:31,493 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2471 | Iter Mean Loss 8.0959
2020-11-05 16:36:31,498 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6041 | Iter Mean Loss 7.1975
2020-11-05 16:36:31,499 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.0000 | MSE 0.1822
2020-11-05 16:36:31,504 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9005 | Iter Mean Loss 10.9005
2020-11-05 16:36:31,509 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5252 | Iter Mean Loss 6.2129
2020-11-05 16:36:31,515 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6777 | Iter Mean Loss 8.0345
2020-11-05 16:36:31,520 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2395 | Iter Mean Loss 8.0857
2020-11-05 16:36:31,525 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6020 | Iter Mean Loss 7.1890
2020-11-05 16:36:31,526 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.0000 | MSE 0.1821
2020-11-05 16:36:31,532 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8891 | Iter Mean Loss 10.8891
2020-11-05 16:36:31,538 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5228 | Iter Mean Loss 6.2060
2020-11-05 16:36:31,545 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6587 | Iter Mean Loss 8.0235
2020-11-05 16:36:31,551 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2320 | Iter Mean Loss 8.0756
2020-11-05 16:36:31,558 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5999 | Iter Mean Loss 7.1805
2020-11-05 16:36:31,559 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.0000 | MSE 0.1821
2020-11-05 16:36:31,565 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8778 | Iter Mean Loss 10.8778
2020-11-05 16:36:31,571 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5203 | Iter Mean Loss 6.1991
2020-11-05 16:36:31,577 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6398 | Iter Mean Loss 8.0126
2020-11-05 16:36:31,583 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2244 | Iter Mean Loss 8.0656
2020-11-05 16:36:31,588 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5978 | Iter Mean Loss 7.1720
2020-11-05 16:36:31,589 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.0000 | MSE 0.1820
2020-11-05 16:36:31,596 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8665 | Iter Mean Loss 10.8665
2020-11-05 16:36:31,602 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5179 | Iter Mean Loss 6.1922
2020-11-05 16:36:31,608 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6210 | Iter Mean Loss 8.0018
2020-11-05 16:36:31,613 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2170 | Iter Mean Loss 8.0556
2020-11-05 16:36:31,618 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5957 | Iter Mean Loss 7.1636
2020-11-05 16:36:31,619 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.0000 | MSE 0.1819
2020-11-05 16:36:31,625 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8552 | Iter Mean Loss 10.8552
2020-11-05 16:36:31,632 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5155 | Iter Mean Loss 6.1854
2020-11-05 16:36:31,638 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6023 | Iter Mean Loss 7.9910
2020-11-05 16:36:31,644 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2095 | Iter Mean Loss 8.0456
2020-11-05 16:36:31,650 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5936 | Iter Mean Loss 7.1552
2020-11-05 16:36:31,651 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.0000 | MSE 0.1819
2020-11-05 16:36:31,657 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8439 | Iter Mean Loss 10.8439
2020-11-05 16:36:31,663 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5131 | Iter Mean Loss 6.1785
2020-11-05 16:36:31,670 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5836 | Iter Mean Loss 7.9802
2020-11-05 16:36:31,675 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2021 | Iter Mean Loss 8.0357
2020-11-05 16:36:31,680 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5916 | Iter Mean Loss 7.1469
2020-11-05 16:36:31,681 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.0000 | MSE 0.1818
2020-11-05 16:36:31,687 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8327 | Iter Mean Loss 10.8327
2020-11-05 16:36:31,692 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5107 | Iter Mean Loss 6.1717
2020-11-05 16:36:31,698 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5650 | Iter Mean Loss 7.9695
2020-11-05 16:36:31,703 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1948 | Iter Mean Loss 8.0258
2020-11-05 16:36:31,708 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5895 | Iter Mean Loss 7.1385
2020-11-05 16:36:31,709 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.0000 | MSE 0.1818
2020-11-05 16:36:31,714 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8215 | Iter Mean Loss 10.8215
2020-11-05 16:36:31,719 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5084 | Iter Mean Loss 6.1650
2020-11-05 16:36:31,725 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5464 | Iter Mean Loss 7.9588
2020-11-05 16:36:31,733 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1874 | Iter Mean Loss 8.0160
2020-11-05 16:36:31,738 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5874 | Iter Mean Loss 7.1303
2020-11-05 16:36:31,739 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.0000 | MSE 0.1817
2020-11-05 16:36:31,745 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8104 | Iter Mean Loss 10.8104
2020-11-05 16:36:31,750 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5060 | Iter Mean Loss 6.1582
2020-11-05 16:36:31,756 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5280 | Iter Mean Loss 7.9481
2020-11-05 16:36:31,761 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1802 | Iter Mean Loss 8.0061
2020-11-05 16:36:31,768 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5854 | Iter Mean Loss 7.1220
2020-11-05 16:36:31,769 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.0000 | MSE 0.1816
2020-11-05 16:36:31,775 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7993 | Iter Mean Loss 10.7993
2020-11-05 16:36:31,780 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5037 | Iter Mean Loss 6.1515
2020-11-05 16:36:31,786 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5096 | Iter Mean Loss 7.9375
2020-11-05 16:36:31,792 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1729 | Iter Mean Loss 7.9964
2020-11-05 16:36:31,797 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5834 | Iter Mean Loss 7.1138
2020-11-05 16:36:31,798 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.0000 | MSE 0.1816
2020-11-05 16:36:31,803 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7882 | Iter Mean Loss 10.7882
2020-11-05 16:36:31,810 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5014 | Iter Mean Loss 6.1448
2020-11-05 16:36:31,816 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4913 | Iter Mean Loss 7.9269
2020-11-05 16:36:31,822 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1657 | Iter Mean Loss 7.9866
2020-11-05 16:36:31,828 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5814 | Iter Mean Loss 7.1056
2020-11-05 16:36:31,828 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.0000 | MSE 0.1815
2020-11-05 16:36:31,834 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7772 | Iter Mean Loss 10.7772
2020-11-05 16:36:31,840 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4991 | Iter Mean Loss 6.1381
2020-11-05 16:36:31,845 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4730 | Iter Mean Loss 7.9164
2020-11-05 16:36:31,850 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1586 | Iter Mean Loss 7.9770
2020-11-05 16:36:31,856 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5793 | Iter Mean Loss 7.0974
2020-11-05 16:36:31,857 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.0000 | MSE 0.1815
2020-11-05 16:36:31,863 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7662 | Iter Mean Loss 10.7662
2020-11-05 16:36:31,869 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4968 | Iter Mean Loss 6.1315
2020-11-05 16:36:31,874 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4548 | Iter Mean Loss 7.9059
2020-11-05 16:36:31,879 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1514 | Iter Mean Loss 7.9673
2020-11-05 16:36:31,884 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5773 | Iter Mean Loss 7.0893
2020-11-05 16:36:31,885 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.0000 | MSE 0.1814
2020-11-05 16:36:31,890 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7552 | Iter Mean Loss 10.7552
2020-11-05 16:36:31,896 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4945 | Iter Mean Loss 6.1248
2020-11-05 16:36:31,901 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4367 | Iter Mean Loss 7.8955
2020-11-05 16:36:31,906 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1444 | Iter Mean Loss 7.9577
2020-11-05 16:36:31,911 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5753 | Iter Mean Loss 7.0812
2020-11-05 16:36:31,912 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.0000 | MSE 0.1813
2020-11-05 16:36:31,917 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7442 | Iter Mean Loss 10.7442
2020-11-05 16:36:31,923 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4922 | Iter Mean Loss 6.1182
2020-11-05 16:36:31,928 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4187 | Iter Mean Loss 7.8850
2020-11-05 16:36:31,933 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1373 | Iter Mean Loss 7.9481
2020-11-05 16:36:31,938 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5734 | Iter Mean Loss 7.0732
2020-11-05 16:36:31,939 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.0000 | MSE 0.1813
2020-11-05 16:36:31,944 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7333 | Iter Mean Loss 10.7333
2020-11-05 16:36:31,950 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4899 | Iter Mean Loss 6.1116
2020-11-05 16:36:31,955 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4007 | Iter Mean Loss 7.8747
2020-11-05 16:36:31,961 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1303 | Iter Mean Loss 7.9386
2020-11-05 16:36:31,966 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5714 | Iter Mean Loss 7.0651
2020-11-05 16:36:31,967 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.0000 | MSE 0.1812
2020-11-05 16:36:31,976 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7224 | Iter Mean Loss 10.7224
2020-11-05 16:36:31,986 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4877 | Iter Mean Loss 6.1051
2020-11-05 16:36:31,993 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3829 | Iter Mean Loss 7.8643
2020-11-05 16:36:31,999 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1233 | Iter Mean Loss 7.9291
2020-11-05 16:36:32,005 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5694 | Iter Mean Loss 7.0571
2020-11-05 16:36:32,006 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.0000 | MSE 0.1812
2020-11-05 16:36:32,011 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7116 | Iter Mean Loss 10.7116
2020-11-05 16:36:32,017 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 6.0985
2020-11-05 16:36:32,022 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3650 | Iter Mean Loss 7.8540
2020-11-05 16:36:32,028 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1164 | Iter Mean Loss 7.9196
2020-11-05 16:36:32,033 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5675 | Iter Mean Loss 7.0492
2020-11-05 16:36:32,034 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.0000 | MSE 0.1811
2020-11-05 16:36:32,040 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7008 | Iter Mean Loss 10.7008
2020-11-05 16:36:32,046 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4832 | Iter Mean Loss 6.0920
2020-11-05 16:36:32,052 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3473 | Iter Mean Loss 7.8438
2020-11-05 16:36:32,057 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 7.9102
2020-11-05 16:36:32,063 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5655 | Iter Mean Loss 7.0413
2020-11-05 16:36:32,064 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.0000 | MSE 0.1811
2020-11-05 16:36:32,069 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6900 | Iter Mean Loss 10.6900
2020-11-05 16:36:32,075 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4810 | Iter Mean Loss 6.0855
2020-11-05 16:36:32,082 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3296 | Iter Mean Loss 7.8335
2020-11-05 16:36:32,088 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1026 | Iter Mean Loss 7.9008
2020-11-05 16:36:32,093 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5636 | Iter Mean Loss 7.0334
2020-11-05 16:36:32,094 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.0000 | MSE 0.1810
2020-11-05 16:36:32,101 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6792 | Iter Mean Loss 10.6792
2020-11-05 16:36:32,106 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4788 | Iter Mean Loss 6.0790
2020-11-05 16:36:32,112 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3120 | Iter Mean Loss 7.8234
2020-11-05 16:36:32,118 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0958 | Iter Mean Loss 7.8915
2020-11-05 16:36:32,124 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5617 | Iter Mean Loss 7.0255
2020-11-05 16:36:32,125 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.0000 | MSE 0.1809
2020-11-05 16:36:32,133 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6685 | Iter Mean Loss 10.6685
2020-11-05 16:36:32,139 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4767 | Iter Mean Loss 6.0726
2020-11-05 16:36:32,147 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 7.8132
2020-11-05 16:36:32,154 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0890 | Iter Mean Loss 7.8822
2020-11-05 16:36:32,160 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5597 | Iter Mean Loss 7.0177
2020-11-05 16:36:32,162 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.0000 | MSE 0.1809
2020-11-05 16:36:32,170 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6578 | Iter Mean Loss 10.6578
2020-11-05 16:36:32,177 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4745 | Iter Mean Loss 6.0662
2020-11-05 16:36:32,185 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2770 | Iter Mean Loss 7.8031
2020-11-05 16:36:32,191 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0823 | Iter Mean Loss 7.8729
2020-11-05 16:36:32,199 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5578 | Iter Mean Loss 7.0099
2020-11-05 16:36:32,200 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.0000 | MSE 0.1808
2020-11-05 16:36:32,206 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6472 | Iter Mean Loss 10.6472
2020-11-05 16:36:32,214 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4723 | Iter Mean Loss 6.0598
2020-11-05 16:36:32,221 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2596 | Iter Mean Loss 7.7930
2020-11-05 16:36:32,227 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0756 | Iter Mean Loss 7.8637
2020-11-05 16:36:32,234 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5559 | Iter Mean Loss 7.0021
2020-11-05 16:36:32,235 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.0000 | MSE 0.1808
2020-11-05 16:36:32,241 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6366 | Iter Mean Loss 10.6366
2020-11-05 16:36:32,249 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4702 | Iter Mean Loss 6.0534
2020-11-05 16:36:32,255 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2422 | Iter Mean Loss 7.7830
2020-11-05 16:36:32,263 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0689 | Iter Mean Loss 7.8545
2020-11-05 16:36:32,269 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5540 | Iter Mean Loss 6.9944
2020-11-05 16:36:32,270 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.0000 | MSE 0.1807
2020-11-05 16:36:32,276 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6260 | Iter Mean Loss 10.6260
2020-11-05 16:36:32,284 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4681 | Iter Mean Loss 6.0470
2020-11-05 16:36:32,290 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2250 | Iter Mean Loss 7.7730
2020-11-05 16:36:32,298 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0622 | Iter Mean Loss 7.8453
2020-11-05 16:36:32,303 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5522 | Iter Mean Loss 6.9867
2020-11-05 16:36:32,304 - root - INFO - Evaluate: Epoch 0647 | NDCG 1.0000 | MSE 0.1807
2020-11-05 16:36:32,312 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6154 | Iter Mean Loss 10.6154
2020-11-05 16:36:32,319 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4660 | Iter Mean Loss 6.0407
2020-11-05 16:36:32,325 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2078 | Iter Mean Loss 7.7630
2020-11-05 16:36:32,331 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0556 | Iter Mean Loss 7.8362
2020-11-05 16:36:32,336 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5503 | Iter Mean Loss 6.9790
2020-11-05 16:36:32,337 - root - INFO - Evaluate: Epoch 0648 | NDCG 1.0000 | MSE 0.1806
2020-11-05 16:36:32,344 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6049 | Iter Mean Loss 10.6049
2020-11-05 16:36:32,350 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4639 | Iter Mean Loss 6.0344
2020-11-05 16:36:32,358 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1907 | Iter Mean Loss 7.7531
2020-11-05 16:36:32,364 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0491 | Iter Mean Loss 7.8271
2020-11-05 16:36:32,369 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5484 | Iter Mean Loss 6.9714
2020-11-05 16:36:32,370 - root - INFO - Evaluate: Epoch 0649 | NDCG 1.0000 | MSE 0.1806
2020-11-05 16:36:32,378 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5944 | Iter Mean Loss 10.5944
2020-11-05 16:36:32,386 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4618 | Iter Mean Loss 6.0281
2020-11-05 16:36:32,396 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1736 | Iter Mean Loss 7.7432
2020-11-05 16:36:32,403 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0425 | Iter Mean Loss 7.8181
2020-11-05 16:36:32,409 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5466 | Iter Mean Loss 6.9638
2020-11-05 16:36:32,410 - root - INFO - Evaluate: Epoch 0650 | NDCG 1.0000 | MSE 0.1805
2020-11-05 16:36:32,417 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5839 | Iter Mean Loss 10.5839
2020-11-05 16:36:32,425 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4597 | Iter Mean Loss 6.0218
2020-11-05 16:36:32,432 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1566 | Iter Mean Loss 7.7334
2020-11-05 16:36:32,439 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0360 | Iter Mean Loss 7.8091
2020-11-05 16:36:32,445 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5448 | Iter Mean Loss 6.9562
2020-11-05 16:36:32,447 - root - INFO - Evaluate: Epoch 0651 | NDCG 1.0000 | MSE 0.1804
2020-11-05 16:36:32,454 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 10.5734
2020-11-05 16:36:32,461 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 6.0155
2020-11-05 16:36:32,467 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1397 | Iter Mean Loss 7.7236
2020-11-05 16:36:32,473 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0295 | Iter Mean Loss 7.8001
2020-11-05 16:36:32,478 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5429 | Iter Mean Loss 6.9486
2020-11-05 16:36:32,479 - root - INFO - Evaluate: Epoch 0652 | NDCG 1.0000 | MSE 0.1804
2020-11-05 16:36:32,485 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5630 | Iter Mean Loss 10.5630
2020-11-05 16:36:32,491 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4556 | Iter Mean Loss 6.0093
2020-11-05 16:36:32,497 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1228 | Iter Mean Loss 7.7138
2020-11-05 16:36:32,503 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0231 | Iter Mean Loss 7.7911
2020-11-05 16:36:32,508 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5411 | Iter Mean Loss 6.9411
2020-11-05 16:36:32,509 - root - INFO - Evaluate: Epoch 0653 | NDCG 1.0000 | MSE 0.1803
2020-11-05 16:36:32,515 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5526 | Iter Mean Loss 10.5526
2020-11-05 16:36:32,521 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4536 | Iter Mean Loss 6.0031
2020-11-05 16:36:32,527 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1060 | Iter Mean Loss 7.7041
2020-11-05 16:36:32,534 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0167 | Iter Mean Loss 7.7822
2020-11-05 16:36:32,539 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5393 | Iter Mean Loss 6.9336
2020-11-05 16:36:32,541 - root - INFO - Evaluate: Epoch 0654 | NDCG 1.0000 | MSE 0.1803
2020-11-05 16:36:32,548 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5423 | Iter Mean Loss 10.5423
2020-11-05 16:36:32,554 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4515 | Iter Mean Loss 5.9969
2020-11-05 16:36:32,562 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0893 | Iter Mean Loss 7.6944
2020-11-05 16:36:32,568 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0103 | Iter Mean Loss 7.7734
2020-11-05 16:36:32,574 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5375 | Iter Mean Loss 6.9262
2020-11-05 16:36:32,577 - root - INFO - Evaluate: Epoch 0655 | NDCG 1.0000 | MSE 0.1802
2020-11-05 16:36:32,583 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5320 | Iter Mean Loss 10.5320
2020-11-05 16:36:32,590 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4495 | Iter Mean Loss 5.9907
2020-11-05 16:36:32,601 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0726 | Iter Mean Loss 7.6847
2020-11-05 16:36:32,610 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0040 | Iter Mean Loss 7.7645
2020-11-05 16:36:32,616 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5357 | Iter Mean Loss 6.9188
2020-11-05 16:36:32,617 - root - INFO - Evaluate: Epoch 0656 | NDCG 1.0000 | MSE 0.1802
2020-11-05 16:36:32,624 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5217 | Iter Mean Loss 10.5217
2020-11-05 16:36:32,631 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4475 | Iter Mean Loss 5.9846
2020-11-05 16:36:32,637 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0560 | Iter Mean Loss 7.6751
2020-11-05 16:36:32,645 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9977 | Iter Mean Loss 7.7557
2020-11-05 16:36:32,650 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5339 | Iter Mean Loss 6.9114
2020-11-05 16:36:32,651 - root - INFO - Evaluate: Epoch 0657 | NDCG 1.0000 | MSE 0.1801
2020-11-05 16:36:32,658 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5114 | Iter Mean Loss 10.5114
2020-11-05 16:36:32,664 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4455 | Iter Mean Loss 5.9785
2020-11-05 16:36:32,670 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0395 | Iter Mean Loss 7.6655
2020-11-05 16:36:32,676 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9914 | Iter Mean Loss 7.7470
2020-11-05 16:36:32,681 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5322 | Iter Mean Loss 6.9040
2020-11-05 16:36:32,682 - root - INFO - Evaluate: Epoch 0658 | NDCG 1.0000 | MSE 0.1801
2020-11-05 16:36:32,689 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5012 | Iter Mean Loss 10.5012
2020-11-05 16:36:32,698 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4436 | Iter Mean Loss 5.9724
2020-11-05 16:36:32,706 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0231 | Iter Mean Loss 7.6559
2020-11-05 16:36:32,716 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9852 | Iter Mean Loss 7.7382
2020-11-05 16:36:32,725 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5304 | Iter Mean Loss 6.8967
2020-11-05 16:36:32,727 - root - INFO - Evaluate: Epoch 0659 | NDCG 1.0000 | MSE 0.1800
2020-11-05 16:36:32,734 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4909 | Iter Mean Loss 10.4909
2020-11-05 16:36:32,741 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4416 | Iter Mean Loss 5.9663
2020-11-05 16:36:32,747 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0067 | Iter Mean Loss 7.6464
2020-11-05 16:36:32,754 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9790 | Iter Mean Loss 7.7295
2020-11-05 16:36:32,766 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5287 | Iter Mean Loss 6.8894
2020-11-05 16:36:32,768 - root - INFO - Evaluate: Epoch 0660 | NDCG 1.0000 | MSE 0.1800
2020-11-05 16:36:32,777 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4808 | Iter Mean Loss 10.4808
2020-11-05 16:36:32,788 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4397 | Iter Mean Loss 5.9602
2020-11-05 16:36:32,799 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9903 | Iter Mean Loss 7.6369
2020-11-05 16:36:32,812 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9728 | Iter Mean Loss 7.7209
2020-11-05 16:36:32,821 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5269 | Iter Mean Loss 6.8821
2020-11-05 16:36:32,822 - root - INFO - Evaluate: Epoch 0661 | NDCG 1.0000 | MSE 0.1799
2020-11-05 16:36:32,829 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4706 | Iter Mean Loss 10.4706
2020-11-05 16:36:32,837 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4377 | Iter Mean Loss 5.9542
2020-11-05 16:36:32,843 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9741 | Iter Mean Loss 7.6275
2020-11-05 16:36:32,850 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9666 | Iter Mean Loss 7.7123
2020-11-05 16:36:32,856 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5252 | Iter Mean Loss 6.8748
2020-11-05 16:36:32,857 - root - INFO - Evaluate: Epoch 0662 | NDCG 1.0000 | MSE 0.1799
2020-11-05 16:36:32,863 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4605 | Iter Mean Loss 10.4605
2020-11-05 16:36:32,869 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 5.9481
2020-11-05 16:36:32,875 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9578 | Iter Mean Loss 7.6180
2020-11-05 16:36:32,881 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9605 | Iter Mean Loss 7.7037
2020-11-05 16:36:32,886 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5235 | Iter Mean Loss 6.8676
2020-11-05 16:36:32,887 - root - INFO - Evaluate: Epoch 0663 | NDCG 1.0000 | MSE 0.1798
2020-11-05 16:36:32,893 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4504 | Iter Mean Loss 10.4504
2020-11-05 16:36:32,899 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4339 | Iter Mean Loss 5.9421
2020-11-05 16:36:32,906 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9417 | Iter Mean Loss 7.6087
2020-11-05 16:36:32,913 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9544 | Iter Mean Loss 7.6951
2020-11-05 16:36:32,918 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5218 | Iter Mean Loss 6.8604
2020-11-05 16:36:32,919 - root - INFO - Evaluate: Epoch 0664 | NDCG 1.0000 | MSE 0.1797
2020-11-05 16:36:32,927 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4403 | Iter Mean Loss 10.4403
2020-11-05 16:36:32,932 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4320 | Iter Mean Loss 5.9361
2020-11-05 16:36:32,939 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9256 | Iter Mean Loss 7.5993
2020-11-05 16:36:32,945 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9483 | Iter Mean Loss 7.6866
2020-11-05 16:36:32,950 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5201 | Iter Mean Loss 6.8533
2020-11-05 16:36:32,951 - root - INFO - Evaluate: Epoch 0665 | NDCG 1.0000 | MSE 0.1797
2020-11-05 16:36:32,959 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4303 | Iter Mean Loss 10.4303
2020-11-05 16:36:32,964 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4301 | Iter Mean Loss 5.9302
2020-11-05 16:36:32,971 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9096 | Iter Mean Loss 7.5900
2020-11-05 16:36:32,979 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9423 | Iter Mean Loss 7.6781
2020-11-05 16:36:32,984 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5184 | Iter Mean Loss 6.8461
2020-11-05 16:36:32,987 - root - INFO - Evaluate: Epoch 0666 | NDCG 1.0000 | MSE 0.1796
2020-11-05 16:36:32,995 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4202 | Iter Mean Loss 10.4202
2020-11-05 16:36:33,004 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4282 | Iter Mean Loss 5.9242
2020-11-05 16:36:33,014 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8936 | Iter Mean Loss 7.5807
2020-11-05 16:36:33,024 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9363 | Iter Mean Loss 7.6696
2020-11-05 16:36:33,033 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5167 | Iter Mean Loss 6.8390
2020-11-05 16:36:33,034 - root - INFO - Evaluate: Epoch 0667 | NDCG 1.0000 | MSE 0.1796
2020-11-05 16:36:33,041 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4103 | Iter Mean Loss 10.4103
2020-11-05 16:36:33,049 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4263 | Iter Mean Loss 5.9183
2020-11-05 16:36:33,055 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8777 | Iter Mean Loss 7.5714
2020-11-05 16:36:33,063 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9303 | Iter Mean Loss 7.6612
2020-11-05 16:36:33,069 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5150 | Iter Mean Loss 6.8319
2020-11-05 16:36:33,070 - root - INFO - Evaluate: Epoch 0668 | NDCG 1.0000 | MSE 0.1795
2020-11-05 16:36:33,078 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4003 | Iter Mean Loss 10.4003
2020-11-05 16:36:33,084 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4245 | Iter Mean Loss 5.9124
2020-11-05 16:36:33,091 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8619 | Iter Mean Loss 7.5622
2020-11-05 16:36:33,099 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9244 | Iter Mean Loss 7.6528
2020-11-05 16:36:33,104 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5134 | Iter Mean Loss 6.8249
2020-11-05 16:36:33,105 - root - INFO - Evaluate: Epoch 0669 | NDCG 1.0000 | MSE 0.1795
2020-11-05 16:36:33,113 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3903 | Iter Mean Loss 10.3903
2020-11-05 16:36:33,119 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4227 | Iter Mean Loss 5.9065
2020-11-05 16:36:33,128 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 7.5530
2020-11-05 16:36:33,138 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9185 | Iter Mean Loss 7.6444
2020-11-05 16:36:33,147 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5117 | Iter Mean Loss 6.8179
2020-11-05 16:36:33,148 - root - INFO - Evaluate: Epoch 0670 | NDCG 1.0000 | MSE 0.1794
2020-11-05 16:36:33,154 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3804 | Iter Mean Loss 10.3804
2020-11-05 16:36:33,161 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4208 | Iter Mean Loss 5.9006
2020-11-05 16:36:33,167 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8304 | Iter Mean Loss 7.5439
2020-11-05 16:36:33,173 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9126 | Iter Mean Loss 7.6361
2020-11-05 16:36:33,179 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5101 | Iter Mean Loss 6.8109
2020-11-05 16:36:33,180 - root - INFO - Evaluate: Epoch 0671 | NDCG 1.0000 | MSE 0.1794
2020-11-05 16:36:33,186 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3705 | Iter Mean Loss 10.3705
2020-11-05 16:36:33,193 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4190 | Iter Mean Loss 5.8948
2020-11-05 16:36:33,201 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8148 | Iter Mean Loss 7.5348
2020-11-05 16:36:33,208 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9067 | Iter Mean Loss 7.6278
2020-11-05 16:36:33,215 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5084 | Iter Mean Loss 6.8039
2020-11-05 16:36:33,216 - root - INFO - Evaluate: Epoch 0672 | NDCG 1.0000 | MSE 0.1793
2020-11-05 16:36:33,222 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3607 | Iter Mean Loss 10.3607
2020-11-05 16:36:33,229 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4172 | Iter Mean Loss 5.8889
2020-11-05 16:36:33,235 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7992 | Iter Mean Loss 7.5257
2020-11-05 16:36:33,241 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 7.6195
2020-11-05 16:36:33,248 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5068 | Iter Mean Loss 6.7969
2020-11-05 16:36:33,249 - root - INFO - Evaluate: Epoch 0673 | NDCG 1.0000 | MSE 0.1793
2020-11-05 16:36:33,256 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3508 | Iter Mean Loss 10.3508
2020-11-05 16:36:33,265 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 5.8831
2020-11-05 16:36:33,273 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7836 | Iter Mean Loss 7.5166
2020-11-05 16:36:33,281 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8950 | Iter Mean Loss 7.6112
2020-11-05 16:36:33,288 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5052 | Iter Mean Loss 6.7900
2020-11-05 16:36:33,290 - root - INFO - Evaluate: Epoch 0674 | NDCG 1.0000 | MSE 0.1792
2020-11-05 16:36:33,299 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3410 | Iter Mean Loss 10.3410
2020-11-05 16:36:33,306 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4136 | Iter Mean Loss 5.8773
2020-11-05 16:36:33,313 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7681 | Iter Mean Loss 7.5076
2020-11-05 16:36:33,320 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8893 | Iter Mean Loss 7.6030
2020-11-05 16:36:33,325 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5036 | Iter Mean Loss 6.7831
2020-11-05 16:36:33,327 - root - INFO - Evaluate: Epoch 0675 | NDCG 1.0000 | MSE 0.1792
2020-11-05 16:36:33,336 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3312 | Iter Mean Loss 10.3312
2020-11-05 16:36:33,346 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4118 | Iter Mean Loss 5.8715
2020-11-05 16:36:33,354 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7527 | Iter Mean Loss 7.4986
2020-11-05 16:36:33,362 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8835 | Iter Mean Loss 7.5948
2020-11-05 16:36:33,369 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5020 | Iter Mean Loss 6.7763
2020-11-05 16:36:33,370 - root - INFO - Evaluate: Epoch 0676 | NDCG 1.0000 | MSE 0.1791
2020-11-05 16:36:33,380 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3215 | Iter Mean Loss 10.3215
2020-11-05 16:36:33,388 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4100 | Iter Mean Loss 5.8658
2020-11-05 16:36:33,398 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7374 | Iter Mean Loss 7.4896
2020-11-05 16:36:33,408 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8778 | Iter Mean Loss 7.5867
2020-11-05 16:36:33,415 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5004 | Iter Mean Loss 6.7694
2020-11-05 16:36:33,416 - root - INFO - Evaluate: Epoch 0677 | NDCG 1.0000 | MSE 0.1791
2020-11-05 16:36:33,425 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3117 | Iter Mean Loss 10.3117
2020-11-05 16:36:33,434 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4083 | Iter Mean Loss 5.8600
2020-11-05 16:36:33,443 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7221 | Iter Mean Loss 7.4807
2020-11-05 16:36:33,451 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8720 | Iter Mean Loss 7.5785
2020-11-05 16:36:33,458 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4988 | Iter Mean Loss 6.7626
2020-11-05 16:36:33,460 - root - INFO - Evaluate: Epoch 0678 | NDCG 1.0000 | MSE 0.1790
2020-11-05 16:36:33,467 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3020 | Iter Mean Loss 10.3020
2020-11-05 16:36:33,473 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4065 | Iter Mean Loss 5.8543
2020-11-05 16:36:33,480 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7068 | Iter Mean Loss 7.4718
2020-11-05 16:36:33,487 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8664 | Iter Mean Loss 7.5704
2020-11-05 16:36:33,492 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4973 | Iter Mean Loss 6.7558
2020-11-05 16:36:33,493 - root - INFO - Evaluate: Epoch 0679 | NDCG 1.0000 | MSE 0.1790
2020-11-05 16:36:33,499 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2923 | Iter Mean Loss 10.2923
2020-11-05 16:36:33,505 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4048 | Iter Mean Loss 5.8486
2020-11-05 16:36:33,511 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6916 | Iter Mean Loss 7.4629
2020-11-05 16:36:33,517 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8607 | Iter Mean Loss 7.5624
2020-11-05 16:36:33,522 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4957 | Iter Mean Loss 6.7490
2020-11-05 16:36:33,523 - root - INFO - Evaluate: Epoch 0680 | NDCG 1.0000 | MSE 0.1789
2020-11-05 16:36:33,529 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2827 | Iter Mean Loss 10.2827
2020-11-05 16:36:33,535 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4031 | Iter Mean Loss 5.8429
2020-11-05 16:36:33,541 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6765 | Iter Mean Loss 7.4541
2020-11-05 16:36:33,547 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8550 | Iter Mean Loss 7.5543
2020-11-05 16:36:33,554 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4941 | Iter Mean Loss 6.7423
2020-11-05 16:36:33,555 - root - INFO - Evaluate: Epoch 0681 | NDCG 1.0000 | MSE 0.1789
2020-11-05 16:36:33,561 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2730 | Iter Mean Loss 10.2730
2020-11-05 16:36:33,567 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4013 | Iter Mean Loss 5.8372
2020-11-05 16:36:33,574 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6614 | Iter Mean Loss 7.4453
2020-11-05 16:36:33,582 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 7.5463
2020-11-05 16:36:33,588 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4926 | Iter Mean Loss 6.7356
2020-11-05 16:36:33,590 - root - INFO - Evaluate: Epoch 0682 | NDCG 1.0000 | MSE 0.1788
2020-11-05 16:36:33,598 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2634 | Iter Mean Loss 10.2634
2020-11-05 16:36:33,604 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3996 | Iter Mean Loss 5.8315
2020-11-05 16:36:33,612 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6464 | Iter Mean Loss 7.4365
2020-11-05 16:36:33,618 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8438 | Iter Mean Loss 7.5383
2020-11-05 16:36:33,624 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4911 | Iter Mean Loss 6.7289
2020-11-05 16:36:33,626 - root - INFO - Evaluate: Epoch 0683 | NDCG 1.0000 | MSE 0.1788
2020-11-05 16:36:33,633 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2538 | Iter Mean Loss 10.2538
2020-11-05 16:36:33,640 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3979 | Iter Mean Loss 5.8259
2020-11-05 16:36:33,648 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6314 | Iter Mean Loss 7.4277
2020-11-05 16:36:33,654 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8383 | Iter Mean Loss 7.5303
2020-11-05 16:36:33,660 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4895 | Iter Mean Loss 6.7222
2020-11-05 16:36:33,662 - root - INFO - Evaluate: Epoch 0684 | NDCG 1.0000 | MSE 0.1787
2020-11-05 16:36:33,668 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2442 | Iter Mean Loss 10.2442
2020-11-05 16:36:33,675 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3962 | Iter Mean Loss 5.8202
2020-11-05 16:36:33,682 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6165 | Iter Mean Loss 7.4190
2020-11-05 16:36:33,688 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8327 | Iter Mean Loss 7.5224
2020-11-05 16:36:33,693 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4880 | Iter Mean Loss 6.7155
2020-11-05 16:36:33,694 - root - INFO - Evaluate: Epoch 0685 | NDCG 1.0000 | MSE 0.1787
2020-11-05 16:36:33,702 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2347 | Iter Mean Loss 10.2347
2020-11-05 16:36:33,708 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3946 | Iter Mean Loss 5.8146
2020-11-05 16:36:33,714 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6016 | Iter Mean Loss 7.4103
2020-11-05 16:36:33,721 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8272 | Iter Mean Loss 7.5145
2020-11-05 16:36:33,730 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4865 | Iter Mean Loss 6.7089
2020-11-05 16:36:33,731 - root - INFO - Evaluate: Epoch 0686 | NDCG 1.0000 | MSE 0.1786
2020-11-05 16:36:33,741 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2252 | Iter Mean Loss 10.2252
2020-11-05 16:36:33,750 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3929 | Iter Mean Loss 5.8090
2020-11-05 16:36:33,759 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5868 | Iter Mean Loss 7.4016
2020-11-05 16:36:33,769 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8217 | Iter Mean Loss 7.5066
2020-11-05 16:36:33,779 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4850 | Iter Mean Loss 6.7023
2020-11-05 16:36:33,780 - root - INFO - Evaluate: Epoch 0687 | NDCG 1.0000 | MSE 0.1786
2020-11-05 16:36:33,790 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2157 | Iter Mean Loss 10.2157
2020-11-05 16:36:33,799 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3912 | Iter Mean Loss 5.8034
2020-11-05 16:36:33,805 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5720 | Iter Mean Loss 7.3930
2020-11-05 16:36:33,811 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8162 | Iter Mean Loss 7.4988
2020-11-05 16:36:33,817 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4835 | Iter Mean Loss 6.6957
2020-11-05 16:36:33,818 - root - INFO - Evaluate: Epoch 0688 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:36:33,823 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2062 | Iter Mean Loss 10.2062
2020-11-05 16:36:33,829 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3895 | Iter Mean Loss 5.7979
2020-11-05 16:36:33,835 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5573 | Iter Mean Loss 7.3843
2020-11-05 16:36:33,842 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8107 | Iter Mean Loss 7.4909
2020-11-05 16:36:33,847 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4820 | Iter Mean Loss 6.6892
2020-11-05 16:36:33,848 - root - INFO - Evaluate: Epoch 0689 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:36:33,854 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1967 | Iter Mean Loss 10.1967
2020-11-05 16:36:33,861 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3879 | Iter Mean Loss 5.7923
2020-11-05 16:36:33,867 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5427 | Iter Mean Loss 7.3758
2020-11-05 16:36:33,873 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8053 | Iter Mean Loss 7.4831
2020-11-05 16:36:33,879 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4805 | Iter Mean Loss 6.6826
2020-11-05 16:36:33,880 - root - INFO - Evaluate: Epoch 0690 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:36:33,886 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1873 | Iter Mean Loss 10.1873
2020-11-05 16:36:33,892 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3863 | Iter Mean Loss 5.7868
2020-11-05 16:36:33,898 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5281 | Iter Mean Loss 7.3672
2020-11-05 16:36:33,906 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7998 | Iter Mean Loss 7.4754
2020-11-05 16:36:33,916 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4790 | Iter Mean Loss 6.6761
2020-11-05 16:36:33,918 - root - INFO - Evaluate: Epoch 0691 | NDCG 1.0000 | MSE 0.1784
2020-11-05 16:36:33,929 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1778 | Iter Mean Loss 10.1778
2020-11-05 16:36:33,936 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3846 | Iter Mean Loss 5.7812
2020-11-05 16:36:33,942 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5135 | Iter Mean Loss 7.3587
2020-11-05 16:36:33,948 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7944 | Iter Mean Loss 7.4676
2020-11-05 16:36:33,953 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4776 | Iter Mean Loss 6.6696
2020-11-05 16:36:33,954 - root - INFO - Evaluate: Epoch 0692 | NDCG 1.0000 | MSE 0.1784
2020-11-05 16:36:33,960 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1684 | Iter Mean Loss 10.1684
2020-11-05 16:36:33,966 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3830 | Iter Mean Loss 5.7757
2020-11-05 16:36:33,972 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4990 | Iter Mean Loss 7.3501
2020-11-05 16:36:33,978 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7891 | Iter Mean Loss 7.4599
2020-11-05 16:36:33,983 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4761 | Iter Mean Loss 6.6631
2020-11-05 16:36:33,984 - root - INFO - Evaluate: Epoch 0693 | NDCG 1.0000 | MSE 0.1783
2020-11-05 16:36:33,991 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1591 | Iter Mean Loss 10.1591
2020-11-05 16:36:33,996 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3814 | Iter Mean Loss 5.7702
2020-11-05 16:36:34,002 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4846 | Iter Mean Loss 7.3417
2020-11-05 16:36:34,008 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7837 | Iter Mean Loss 7.4522
2020-11-05 16:36:34,015 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4747 | Iter Mean Loss 6.6567
2020-11-05 16:36:34,016 - root - INFO - Evaluate: Epoch 0694 | NDCG 1.0000 | MSE 0.1783
2020-11-05 16:36:34,023 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1497 | Iter Mean Loss 10.1497
2020-11-05 16:36:34,030 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3798 | Iter Mean Loss 5.7647
2020-11-05 16:36:34,037 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4702 | Iter Mean Loss 7.3332
2020-11-05 16:36:34,043 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7783 | Iter Mean Loss 7.4445
2020-11-05 16:36:34,050 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4732 | Iter Mean Loss 6.6502
2020-11-05 16:36:34,051 - root - INFO - Evaluate: Epoch 0695 | NDCG 1.0000 | MSE 0.1782
2020-11-05 16:36:34,058 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1404 | Iter Mean Loss 10.1404
2020-11-05 16:36:34,065 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 5.7593
2020-11-05 16:36:34,072 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4558 | Iter Mean Loss 7.3248
2020-11-05 16:36:34,079 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7730 | Iter Mean Loss 7.4368
2020-11-05 16:36:34,085 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4718 | Iter Mean Loss 6.6438
2020-11-05 16:36:34,086 - root - INFO - Evaluate: Epoch 0696 | NDCG 1.0000 | MSE 0.1782
2020-11-05 16:36:34,093 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1311 | Iter Mean Loss 10.1311
2020-11-05 16:36:34,100 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3765 | Iter Mean Loss 5.7538
2020-11-05 16:36:34,106 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4415 | Iter Mean Loss 7.3164
2020-11-05 16:36:34,114 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7677 | Iter Mean Loss 7.4292
2020-11-05 16:36:34,122 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4703 | Iter Mean Loss 6.6374
2020-11-05 16:36:34,124 - root - INFO - Evaluate: Epoch 0697 | NDCG 1.0000 | MSE 0.1781
2020-11-05 16:36:34,134 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1218 | Iter Mean Loss 10.1218
2020-11-05 16:36:34,143 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3750 | Iter Mean Loss 5.7484
2020-11-05 16:36:34,153 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4272 | Iter Mean Loss 7.3080
2020-11-05 16:36:34,162 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7624 | Iter Mean Loss 7.4216
2020-11-05 16:36:34,170 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4689 | Iter Mean Loss 6.6311
2020-11-05 16:36:34,171 - root - INFO - Evaluate: Epoch 0698 | NDCG 1.0000 | MSE 0.1781
2020-11-05 16:36:34,180 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1125 | Iter Mean Loss 10.1125
2020-11-05 16:36:34,189 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3734 | Iter Mean Loss 5.7429
2020-11-05 16:36:34,198 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4130 | Iter Mean Loss 7.2996
2020-11-05 16:36:34,206 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7571 | Iter Mean Loss 7.4140
2020-11-05 16:36:34,211 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4675 | Iter Mean Loss 6.6247
2020-11-05 16:36:34,212 - root - INFO - Evaluate: Epoch 0699 | NDCG 1.0000 | MSE 0.1780
2020-11-05 16:36:34,219 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1032 | Iter Mean Loss 10.1032
2020-11-05 16:36:34,225 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3718 | Iter Mean Loss 5.7375
2020-11-05 16:36:34,231 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3989 | Iter Mean Loss 7.2913
2020-11-05 16:36:34,237 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7519 | Iter Mean Loss 7.4064
2020-11-05 16:36:34,244 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4661 | Iter Mean Loss 6.6184
2020-11-05 16:36:34,245 - root - INFO - Evaluate: Epoch 0700 | NDCG 1.0000 | MSE 0.1780
2020-11-05 16:36:34,251 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0940 | Iter Mean Loss 10.0940
2020-11-05 16:36:34,258 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3702 | Iter Mean Loss 5.7321
2020-11-05 16:36:34,265 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3848 | Iter Mean Loss 7.2830
2020-11-05 16:36:34,271 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7466 | Iter Mean Loss 7.3989
2020-11-05 16:36:34,278 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4647 | Iter Mean Loss 6.6120
2020-11-05 16:36:34,279 - root - INFO - Evaluate: Epoch 0701 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:36:34,285 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0848 | Iter Mean Loss 10.0848
2020-11-05 16:36:34,292 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3686 | Iter Mean Loss 5.7267
2020-11-05 16:36:34,298 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3707 | Iter Mean Loss 7.2747
2020-11-05 16:36:34,304 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7414 | Iter Mean Loss 7.3914
2020-11-05 16:36:34,310 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4633 | Iter Mean Loss 6.6057
2020-11-05 16:36:34,311 - root - INFO - Evaluate: Epoch 0702 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:36:34,318 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0756 | Iter Mean Loss 10.0756
2020-11-05 16:36:34,326 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3671 | Iter Mean Loss 5.7213
2020-11-05 16:36:34,332 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3567 | Iter Mean Loss 7.2664
2020-11-05 16:36:34,338 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7362 | Iter Mean Loss 7.3839
2020-11-05 16:36:34,343 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4619 | Iter Mean Loss 6.5995
2020-11-05 16:36:34,344 - root - INFO - Evaluate: Epoch 0703 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:36:34,350 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 10.0664
2020-11-05 16:36:34,355 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3655 | Iter Mean Loss 5.7160
2020-11-05 16:36:34,361 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3427 | Iter Mean Loss 7.2582
2020-11-05 16:36:34,367 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7310 | Iter Mean Loss 7.3764
2020-11-05 16:36:34,372 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4605 | Iter Mean Loss 6.5932
2020-11-05 16:36:34,373 - root - INFO - Evaluate: Epoch 0704 | NDCG 1.0000 | MSE 0.1778
2020-11-05 16:36:34,378 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0572 | Iter Mean Loss 10.0572
2020-11-05 16:36:34,384 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3640 | Iter Mean Loss 5.7106
2020-11-05 16:36:34,389 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3288 | Iter Mean Loss 7.2500
2020-11-05 16:36:34,395 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7258 | Iter Mean Loss 7.3689
2020-11-05 16:36:34,400 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4591 | Iter Mean Loss 6.5870
2020-11-05 16:36:34,401 - root - INFO - Evaluate: Epoch 0705 | NDCG 1.0000 | MSE 0.1778
2020-11-05 16:36:34,406 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0481 | Iter Mean Loss 10.0481
2020-11-05 16:36:34,412 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3624 | Iter Mean Loss 5.7052
2020-11-05 16:36:34,419 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3149 | Iter Mean Loss 7.2418
2020-11-05 16:36:34,425 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7206 | Iter Mean Loss 7.3615
2020-11-05 16:36:34,430 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4577 | Iter Mean Loss 6.5807
2020-11-05 16:36:34,431 - root - INFO - Evaluate: Epoch 0706 | NDCG 1.0000 | MSE 0.1777
2020-11-05 16:36:34,438 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0389 | Iter Mean Loss 10.0389
2020-11-05 16:36:34,444 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3609 | Iter Mean Loss 5.6999
2020-11-05 16:36:34,451 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3010 | Iter Mean Loss 7.2336
2020-11-05 16:36:34,458 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7155 | Iter Mean Loss 7.3541
2020-11-05 16:36:34,463 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4563 | Iter Mean Loss 6.5745
2020-11-05 16:36:34,464 - root - INFO - Evaluate: Epoch 0707 | NDCG 1.0000 | MSE 0.1777
2020-11-05 16:36:34,471 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0298 | Iter Mean Loss 10.0298
2020-11-05 16:36:34,477 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 5.6946
2020-11-05 16:36:34,483 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2872 | Iter Mean Loss 7.2255
2020-11-05 16:36:34,489 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7103 | Iter Mean Loss 7.3467
2020-11-05 16:36:34,494 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4550 | Iter Mean Loss 6.5683
2020-11-05 16:36:34,495 - root - INFO - Evaluate: Epoch 0708 | NDCG 1.0000 | MSE 0.1776
2020-11-05 16:36:34,502 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0207 | Iter Mean Loss 10.0207
2020-11-05 16:36:34,509 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3578 | Iter Mean Loss 5.6893
2020-11-05 16:36:34,514 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2735 | Iter Mean Loss 7.2173
2020-11-05 16:36:34,521 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7052 | Iter Mean Loss 7.3393
2020-11-05 16:36:34,526 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4536 | Iter Mean Loss 6.5622
2020-11-05 16:36:34,527 - root - INFO - Evaluate: Epoch 0709 | NDCG 1.0000 | MSE 0.1776
2020-11-05 16:36:34,533 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0117 | Iter Mean Loss 10.0117
2020-11-05 16:36:34,540 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3563 | Iter Mean Loss 5.6840
2020-11-05 16:36:34,545 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2598 | Iter Mean Loss 7.2092
2020-11-05 16:36:34,551 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7001 | Iter Mean Loss 7.3320
2020-11-05 16:36:34,556 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4523 | Iter Mean Loss 6.5560
2020-11-05 16:36:34,556 - root - INFO - Evaluate: Epoch 0710 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:36:34,562 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0026 | Iter Mean Loss 10.0026
2020-11-05 16:36:34,568 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3548 | Iter Mean Loss 5.6787
2020-11-05 16:36:34,573 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2461 | Iter Mean Loss 7.2012
2020-11-05 16:36:34,579 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6950 | Iter Mean Loss 7.3246
2020-11-05 16:36:34,584 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4509 | Iter Mean Loss 6.5499
2020-11-05 16:36:34,585 - root - INFO - Evaluate: Epoch 0711 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:36:34,590 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9936 | Iter Mean Loss 9.9936
2020-11-05 16:36:34,596 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3533 | Iter Mean Loss 5.6734
2020-11-05 16:36:34,602 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2325 | Iter Mean Loss 7.1931
2020-11-05 16:36:34,607 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6899 | Iter Mean Loss 7.3173
2020-11-05 16:36:34,612 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4495 | Iter Mean Loss 6.5437
2020-11-05 16:36:34,613 - root - INFO - Evaluate: Epoch 0712 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:36:34,619 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9845 | Iter Mean Loss 9.9845
2020-11-05 16:36:34,625 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3517 | Iter Mean Loss 5.6681
2020-11-05 16:36:34,631 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2189 | Iter Mean Loss 7.1851
2020-11-05 16:36:34,637 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6848 | Iter Mean Loss 7.3100
2020-11-05 16:36:34,642 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4482 | Iter Mean Loss 6.5376
2020-11-05 16:36:34,644 - root - INFO - Evaluate: Epoch 0713 | NDCG 1.0000 | MSE 0.1774
2020-11-05 16:36:34,649 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9755 | Iter Mean Loss 9.9755
2020-11-05 16:36:34,655 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3502 | Iter Mean Loss 5.6629
2020-11-05 16:36:34,662 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2054 | Iter Mean Loss 7.1770
2020-11-05 16:36:34,668 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6797 | Iter Mean Loss 7.3027
2020-11-05 16:36:34,673 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4469 | Iter Mean Loss 6.5315
2020-11-05 16:36:34,674 - root - INFO - Evaluate: Epoch 0714 | NDCG 1.0000 | MSE 0.1774
2020-11-05 16:36:34,681 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9665 | Iter Mean Loss 9.9665
2020-11-05 16:36:34,687 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3487 | Iter Mean Loss 5.6576
2020-11-05 16:36:34,693 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1919 | Iter Mean Loss 7.1690
2020-11-05 16:36:34,699 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6747 | Iter Mean Loss 7.2955
2020-11-05 16:36:34,705 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4455 | Iter Mean Loss 6.5255
2020-11-05 16:36:34,706 - root - INFO - Evaluate: Epoch 0715 | NDCG 1.0000 | MSE 0.1773
2020-11-05 16:36:34,712 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9576 | Iter Mean Loss 9.9576
2020-11-05 16:36:34,718 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3472 | Iter Mean Loss 5.6524
2020-11-05 16:36:34,724 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1784 | Iter Mean Loss 7.1611
2020-11-05 16:36:34,729 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6696 | Iter Mean Loss 7.2882
2020-11-05 16:36:34,734 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4442 | Iter Mean Loss 6.5194
2020-11-05 16:36:34,735 - root - INFO - Evaluate: Epoch 0716 | NDCG 1.0000 | MSE 0.1773
2020-11-05 16:36:34,741 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9486 | Iter Mean Loss 9.9486
2020-11-05 16:36:34,746 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3457 | Iter Mean Loss 5.6472
2020-11-05 16:36:34,752 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1650 | Iter Mean Loss 7.1531
2020-11-05 16:36:34,757 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6646 | Iter Mean Loss 7.2810
2020-11-05 16:36:34,762 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4429 | Iter Mean Loss 6.5134
2020-11-05 16:36:34,763 - root - INFO - Evaluate: Epoch 0717 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:36:34,769 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9397 | Iter Mean Loss 9.9397
2020-11-05 16:36:34,774 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3442 | Iter Mean Loss 5.6419
2020-11-05 16:36:34,781 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1516 | Iter Mean Loss 7.1452
2020-11-05 16:36:34,786 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6596 | Iter Mean Loss 7.2738
2020-11-05 16:36:34,791 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4416 | Iter Mean Loss 6.5073
2020-11-05 16:36:34,792 - root - INFO - Evaluate: Epoch 0718 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:36:34,798 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9307 | Iter Mean Loss 9.9307
2020-11-05 16:36:34,803 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 5.6367
2020-11-05 16:36:34,809 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1383 | Iter Mean Loss 7.1373
2020-11-05 16:36:34,815 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6546 | Iter Mean Loss 7.2666
2020-11-05 16:36:34,821 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4402 | Iter Mean Loss 6.5013
2020-11-05 16:36:34,822 - root - INFO - Evaluate: Epoch 0719 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:36:34,828 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9218 | Iter Mean Loss 9.9218
2020-11-05 16:36:34,834 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 5.6315
2020-11-05 16:36:34,841 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1250 | Iter Mean Loss 7.1294
2020-11-05 16:36:34,847 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6496 | Iter Mean Loss 7.2594
2020-11-05 16:36:34,852 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4389 | Iter Mean Loss 6.4953
2020-11-05 16:36:34,854 - root - INFO - Evaluate: Epoch 0720 | NDCG 1.0000 | MSE 0.1771
2020-11-05 16:36:34,861 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9129 | Iter Mean Loss 9.9129
2020-11-05 16:36:34,866 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3398 | Iter Mean Loss 5.6263
2020-11-05 16:36:34,873 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1117 | Iter Mean Loss 7.1215
2020-11-05 16:36:34,879 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6446 | Iter Mean Loss 7.2522
2020-11-05 16:36:34,884 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4376 | Iter Mean Loss 6.4893
2020-11-05 16:36:34,886 - root - INFO - Evaluate: Epoch 0721 | NDCG 1.0000 | MSE 0.1771
2020-11-05 16:36:34,892 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9040 | Iter Mean Loss 9.9040
2020-11-05 16:36:34,898 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3383 | Iter Mean Loss 5.6212
2020-11-05 16:36:34,904 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0985 | Iter Mean Loss 7.1136
2020-11-05 16:36:34,909 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6396 | Iter Mean Loss 7.2451
2020-11-05 16:36:34,915 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4363 | Iter Mean Loss 6.4833
2020-11-05 16:36:34,916 - root - INFO - Evaluate: Epoch 0722 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:36:34,922 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8952 | Iter Mean Loss 9.8952
2020-11-05 16:36:34,927 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3368 | Iter Mean Loss 5.6160
2020-11-05 16:36:34,933 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0853 | Iter Mean Loss 7.1058
2020-11-05 16:36:34,938 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6346 | Iter Mean Loss 7.2380
2020-11-05 16:36:34,943 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4350 | Iter Mean Loss 6.4774
2020-11-05 16:36:34,944 - root - INFO - Evaluate: Epoch 0723 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:36:34,950 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 9.8863
2020-11-05 16:36:34,955 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3353 | Iter Mean Loss 5.6108
2020-11-05 16:36:34,961 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0722 | Iter Mean Loss 7.0979
2020-11-05 16:36:34,966 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6296 | Iter Mean Loss 7.2309
2020-11-05 16:36:34,971 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4337 | Iter Mean Loss 6.4714
2020-11-05 16:36:34,972 - root - INFO - Evaluate: Epoch 0724 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:36:34,978 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8774 | Iter Mean Loss 9.8774
2020-11-05 16:36:34,984 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3339 | Iter Mean Loss 5.6057
2020-11-05 16:36:34,990 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0591 | Iter Mean Loss 7.0901
2020-11-05 16:36:34,995 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6247 | Iter Mean Loss 7.2238
2020-11-05 16:36:35,000 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4324 | Iter Mean Loss 6.4655
2020-11-05 16:36:35,001 - root - INFO - Evaluate: Epoch 0725 | NDCG 1.0000 | MSE 0.1769
2020-11-05 16:36:35,007 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8686 | Iter Mean Loss 9.8686
2020-11-05 16:36:35,012 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3324 | Iter Mean Loss 5.6005
2020-11-05 16:36:35,018 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0460 | Iter Mean Loss 7.0823
2020-11-05 16:36:35,026 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6197 | Iter Mean Loss 7.2167
2020-11-05 16:36:35,031 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4311 | Iter Mean Loss 6.4596
2020-11-05 16:36:35,032 - root - INFO - Evaluate: Epoch 0726 | NDCG 1.0000 | MSE 0.1769
2020-11-05 16:36:35,038 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8598 | Iter Mean Loss 9.8598
2020-11-05 16:36:35,045 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3309 | Iter Mean Loss 5.5954
2020-11-05 16:36:35,050 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0330 | Iter Mean Loss 7.0746
2020-11-05 16:36:35,057 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6148 | Iter Mean Loss 7.2096
2020-11-05 16:36:35,062 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4298 | Iter Mean Loss 6.4537
2020-11-05 16:36:35,063 - root - INFO - Evaluate: Epoch 0727 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:36:35,069 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8510 | Iter Mean Loss 9.8510
2020-11-05 16:36:35,076 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3295 | Iter Mean Loss 5.5902
2020-11-05 16:36:35,082 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0200 | Iter Mean Loss 7.0668
2020-11-05 16:36:35,088 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6099 | Iter Mean Loss 7.2026
2020-11-05 16:36:35,094 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4285 | Iter Mean Loss 6.4478
2020-11-05 16:36:35,094 - root - INFO - Evaluate: Epoch 0728 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:36:35,100 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8422 | Iter Mean Loss 9.8422
2020-11-05 16:36:35,106 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3280 | Iter Mean Loss 5.5851
2020-11-05 16:36:35,111 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0070 | Iter Mean Loss 7.0591
2020-11-05 16:36:35,118 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6049 | Iter Mean Loss 7.1955
2020-11-05 16:36:35,123 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4272 | Iter Mean Loss 6.4419
2020-11-05 16:36:35,124 - root - INFO - Evaluate: Epoch 0729 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:36:35,129 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8334 | Iter Mean Loss 9.8334
2020-11-05 16:36:35,135 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 5.5800
2020-11-05 16:36:35,140 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9941 | Iter Mean Loss 7.0514
2020-11-05 16:36:35,145 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6000 | Iter Mean Loss 7.1885
2020-11-05 16:36:35,150 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4259 | Iter Mean Loss 6.4360
2020-11-05 16:36:35,151 - root - INFO - Evaluate: Epoch 0730 | NDCG 1.0000 | MSE 0.1767
2020-11-05 16:36:35,156 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8247 | Iter Mean Loss 9.8247
2020-11-05 16:36:35,162 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 5.5749
2020-11-05 16:36:35,167 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9812 | Iter Mean Loss 7.0437
2020-11-05 16:36:35,172 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5951 | Iter Mean Loss 7.1815
2020-11-05 16:36:35,177 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4247 | Iter Mean Loss 6.4301
2020-11-05 16:36:35,178 - root - INFO - Evaluate: Epoch 0731 | NDCG 1.0000 | MSE 0.1767
2020-11-05 16:36:35,184 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8159 | Iter Mean Loss 9.8159
2020-11-05 16:36:35,189 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3236 | Iter Mean Loss 5.5698
2020-11-05 16:36:35,196 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9684 | Iter Mean Loss 7.0360
2020-11-05 16:36:35,201 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5902 | Iter Mean Loss 7.1745
2020-11-05 16:36:35,206 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4234 | Iter Mean Loss 6.4243
2020-11-05 16:36:35,207 - root - INFO - Evaluate: Epoch 0732 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:36:35,212 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8072 | Iter Mean Loss 9.8072
2020-11-05 16:36:35,218 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3221 | Iter Mean Loss 5.5647
2020-11-05 16:36:35,224 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9556 | Iter Mean Loss 7.0283
2020-11-05 16:36:35,230 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5853 | Iter Mean Loss 7.1675
2020-11-05 16:36:35,235 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4221 | Iter Mean Loss 6.4184
2020-11-05 16:36:35,236 - root - INFO - Evaluate: Epoch 0733 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:36:35,243 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7984 | Iter Mean Loss 9.7984
2020-11-05 16:36:35,249 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3207 | Iter Mean Loss 5.5596
2020-11-05 16:36:35,255 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9428 | Iter Mean Loss 7.0206
2020-11-05 16:36:35,262 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5804 | Iter Mean Loss 7.1606
2020-11-05 16:36:35,267 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4208 | Iter Mean Loss 6.4126
2020-11-05 16:36:35,268 - root - INFO - Evaluate: Epoch 0734 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:36:35,274 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7897 | Iter Mean Loss 9.7897
2020-11-05 16:36:35,280 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3192 | Iter Mean Loss 5.5545
2020-11-05 16:36:35,286 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9300 | Iter Mean Loss 7.0130
2020-11-05 16:36:35,292 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5755 | Iter Mean Loss 7.1536
2020-11-05 16:36:35,298 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4195 | Iter Mean Loss 6.4068
2020-11-05 16:36:35,299 - root - INFO - Evaluate: Epoch 0735 | NDCG 1.0000 | MSE 0.1765
2020-11-05 16:36:35,305 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7810 | Iter Mean Loss 9.7810
2020-11-05 16:36:35,311 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3178 | Iter Mean Loss 5.5494
2020-11-05 16:36:35,321 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9173 | Iter Mean Loss 7.0054
2020-11-05 16:36:35,328 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5706 | Iter Mean Loss 7.1467
2020-11-05 16:36:35,333 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4183 | Iter Mean Loss 6.4010
2020-11-05 16:36:35,334 - root - INFO - Evaluate: Epoch 0736 | NDCG 1.0000 | MSE 0.1765
2020-11-05 16:36:35,339 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7723 | Iter Mean Loss 9.7723
2020-11-05 16:36:35,345 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3163 | Iter Mean Loss 5.5443
2020-11-05 16:36:35,350 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9047 | Iter Mean Loss 6.9978
2020-11-05 16:36:35,355 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5657 | Iter Mean Loss 7.1397
2020-11-05 16:36:35,360 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4170 | Iter Mean Loss 6.3952
2020-11-05 16:36:35,361 - root - INFO - Evaluate: Epoch 0737 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:36:35,367 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7637 | Iter Mean Loss 9.7637
2020-11-05 16:36:35,372 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3148 | Iter Mean Loss 5.5392
2020-11-05 16:36:35,378 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8920 | Iter Mean Loss 6.9902
2020-11-05 16:36:35,383 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5608 | Iter Mean Loss 7.1328
2020-11-05 16:36:35,388 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4157 | Iter Mean Loss 6.3894
2020-11-05 16:36:35,388 - root - INFO - Evaluate: Epoch 0738 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:36:35,394 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 9.7550
2020-11-05 16:36:35,400 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3134 | Iter Mean Loss 5.5342
2020-11-05 16:36:35,405 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8794 | Iter Mean Loss 6.9826
2020-11-05 16:36:35,413 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5559 | Iter Mean Loss 7.1259
2020-11-05 16:36:35,419 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.3836
2020-11-05 16:36:35,420 - root - INFO - Evaluate: Epoch 0739 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:36:35,429 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7463 | Iter Mean Loss 9.7463
2020-11-05 16:36:35,436 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 5.5291
2020-11-05 16:36:35,444 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8668 | Iter Mean Loss 6.9750
2020-11-05 16:36:35,450 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5510 | Iter Mean Loss 7.1190
2020-11-05 16:36:35,456 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4132 | Iter Mean Loss 6.3779
2020-11-05 16:36:35,458 - root - INFO - Evaluate: Epoch 0740 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:36:35,465 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7377 | Iter Mean Loss 9.7377
2020-11-05 16:36:35,471 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3105 | Iter Mean Loss 5.5241
2020-11-05 16:36:35,478 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8543 | Iter Mean Loss 6.9675
2020-11-05 16:36:35,486 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5462 | Iter Mean Loss 7.1121
2020-11-05 16:36:35,494 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4119 | Iter Mean Loss 6.3721
2020-11-05 16:36:35,495 - root - INFO - Evaluate: Epoch 0741 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:36:35,503 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7290 | Iter Mean Loss 9.7290
2020-11-05 16:36:35,510 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3090 | Iter Mean Loss 5.5190
2020-11-05 16:36:35,517 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8418 | Iter Mean Loss 6.9599
2020-11-05 16:36:35,522 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5413 | Iter Mean Loss 7.1053
2020-11-05 16:36:35,529 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4107 | Iter Mean Loss 6.3663
2020-11-05 16:36:35,530 - root - INFO - Evaluate: Epoch 0742 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:36:35,535 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7204 | Iter Mean Loss 9.7204
2020-11-05 16:36:35,541 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3075 | Iter Mean Loss 5.5140
2020-11-05 16:36:35,547 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8293 | Iter Mean Loss 6.9524
2020-11-05 16:36:35,554 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5364 | Iter Mean Loss 7.0984
2020-11-05 16:36:35,560 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4094 | Iter Mean Loss 6.3606
2020-11-05 16:36:35,561 - root - INFO - Evaluate: Epoch 0743 | NDCG 1.0000 | MSE 0.1762
2020-11-05 16:36:35,568 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7118 | Iter Mean Loss 9.7118
2020-11-05 16:36:35,574 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3061 | Iter Mean Loss 5.5089
2020-11-05 16:36:35,582 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8168 | Iter Mean Loss 6.9449
2020-11-05 16:36:35,588 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5315 | Iter Mean Loss 7.0916
2020-11-05 16:36:35,592 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4081 | Iter Mean Loss 6.3549
2020-11-05 16:36:35,593 - root - INFO - Evaluate: Epoch 0744 | NDCG 1.0000 | MSE 0.1762
2020-11-05 16:36:35,599 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7032 | Iter Mean Loss 9.7032
2020-11-05 16:36:35,604 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3046 | Iter Mean Loss 5.5039
2020-11-05 16:36:35,610 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8044 | Iter Mean Loss 6.9374
2020-11-05 16:36:35,615 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5267 | Iter Mean Loss 7.0847
2020-11-05 16:36:35,620 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4069 | Iter Mean Loss 6.3491
2020-11-05 16:36:35,622 - root - INFO - Evaluate: Epoch 0745 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:36:35,627 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6946 | Iter Mean Loss 9.6946
2020-11-05 16:36:35,633 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3032 | Iter Mean Loss 5.4989
2020-11-05 16:36:35,639 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7920 | Iter Mean Loss 6.9299
2020-11-05 16:36:35,645 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5218 | Iter Mean Loss 7.0779
2020-11-05 16:36:35,650 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4056 | Iter Mean Loss 6.3434
2020-11-05 16:36:35,651 - root - INFO - Evaluate: Epoch 0746 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:36:35,657 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 9.6860
2020-11-05 16:36:35,663 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3017 | Iter Mean Loss 5.4938
2020-11-05 16:36:35,669 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7796 | Iter Mean Loss 6.9224
2020-11-05 16:36:35,675 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5169 | Iter Mean Loss 7.0711
2020-11-05 16:36:35,680 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4044 | Iter Mean Loss 6.3377
2020-11-05 16:36:35,681 - root - INFO - Evaluate: Epoch 0747 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:36:35,687 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6774 | Iter Mean Loss 9.6774
2020-11-05 16:36:35,693 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3002 | Iter Mean Loss 5.4888
2020-11-05 16:36:35,699 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7673 | Iter Mean Loss 6.9150
2020-11-05 16:36:35,705 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5121 | Iter Mean Loss 7.0643
2020-11-05 16:36:35,710 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4031 | Iter Mean Loss 6.3320
2020-11-05 16:36:35,711 - root - INFO - Evaluate: Epoch 0748 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:36:35,717 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6688 | Iter Mean Loss 9.6688
2020-11-05 16:36:35,723 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 5.4838
2020-11-05 16:36:35,729 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 6.9075
2020-11-05 16:36:35,735 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5072 | Iter Mean Loss 7.0575
2020-11-05 16:36:35,739 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4018 | Iter Mean Loss 6.3263
2020-11-05 16:36:35,740 - root - INFO - Evaluate: Epoch 0749 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:36:35,746 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6603 | Iter Mean Loss 9.6603
2020-11-05 16:36:35,751 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2973 | Iter Mean Loss 5.4788
2020-11-05 16:36:35,756 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7427 | Iter Mean Loss 6.9001
2020-11-05 16:36:35,762 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5023 | Iter Mean Loss 7.0507
2020-11-05 16:36:35,767 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4006 | Iter Mean Loss 6.3206
2020-11-05 16:36:35,768 - root - INFO - Evaluate: Epoch 0750 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:36:35,773 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6517 | Iter Mean Loss 9.6517
2020-11-05 16:36:35,778 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2958 | Iter Mean Loss 5.4738
2020-11-05 16:36:35,784 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7305 | Iter Mean Loss 6.8927
2020-11-05 16:36:35,789 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4975 | Iter Mean Loss 7.0439
2020-11-05 16:36:35,794 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3993 | Iter Mean Loss 6.3150
2020-11-05 16:36:35,795 - root - INFO - Evaluate: Epoch 0751 | NDCG 1.0000 | MSE 0.1759
2020-11-05 16:36:35,800 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6432 | Iter Mean Loss 9.6432
2020-11-05 16:36:35,806 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2944 | Iter Mean Loss 5.4688
2020-11-05 16:36:35,811 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7183 | Iter Mean Loss 6.8853
2020-11-05 16:36:35,817 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4926 | Iter Mean Loss 7.0371
2020-11-05 16:36:35,822 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3980 | Iter Mean Loss 6.3093
2020-11-05 16:36:35,824 - root - INFO - Evaluate: Epoch 0752 | NDCG 1.0000 | MSE 0.1759
2020-11-05 16:36:35,830 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6346 | Iter Mean Loss 9.6346
2020-11-05 16:36:35,835 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2929 | Iter Mean Loss 5.4638
2020-11-05 16:36:35,841 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7061 | Iter Mean Loss 6.8779
2020-11-05 16:36:35,847 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4877 | Iter Mean Loss 7.0303
2020-11-05 16:36:35,852 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3968 | Iter Mean Loss 6.3036
2020-11-05 16:36:35,853 - root - INFO - Evaluate: Epoch 0753 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:36:35,860 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6261 | Iter Mean Loss 9.6261
2020-11-05 16:36:35,865 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2914 | Iter Mean Loss 5.4588
2020-11-05 16:36:35,872 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6940 | Iter Mean Loss 6.8705
2020-11-05 16:36:35,878 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4828 | Iter Mean Loss 7.0236
2020-11-05 16:36:35,883 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3955 | Iter Mean Loss 6.2980
2020-11-05 16:36:35,884 - root - INFO - Evaluate: Epoch 0754 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:36:35,890 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6176 | Iter Mean Loss 9.6176
2020-11-05 16:36:35,896 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2900 | Iter Mean Loss 5.4538
2020-11-05 16:36:35,902 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6818 | Iter Mean Loss 6.8631
2020-11-05 16:36:35,908 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4780 | Iter Mean Loss 7.0168
2020-11-05 16:36:35,913 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3943 | Iter Mean Loss 6.2923
2020-11-05 16:36:35,914 - root - INFO - Evaluate: Epoch 0755 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:36:35,920 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6090 | Iter Mean Loss 9.6090
2020-11-05 16:36:35,926 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2885 | Iter Mean Loss 5.4488
2020-11-05 16:36:35,932 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6697 | Iter Mean Loss 6.8558
2020-11-05 16:36:35,937 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4731 | Iter Mean Loss 7.0101
2020-11-05 16:36:35,942 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3930 | Iter Mean Loss 6.2867
2020-11-05 16:36:35,943 - root - INFO - Evaluate: Epoch 0756 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:36:35,948 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6005 | Iter Mean Loss 9.6005
2020-11-05 16:36:35,954 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 5.4438
2020-11-05 16:36:35,959 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6577 | Iter Mean Loss 6.8484
2020-11-05 16:36:35,965 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4682 | Iter Mean Loss 7.0034
2020-11-05 16:36:35,969 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 6.2810
2020-11-05 16:36:35,970 - root - INFO - Evaluate: Epoch 0757 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:36:35,976 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5920 | Iter Mean Loss 9.5920
2020-11-05 16:36:35,981 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2855 | Iter Mean Loss 5.4388
2020-11-05 16:36:35,987 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6456 | Iter Mean Loss 6.8411
2020-11-05 16:36:35,992 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4633 | Iter Mean Loss 6.9966
2020-11-05 16:36:35,997 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3905 | Iter Mean Loss 6.2754
2020-11-05 16:36:35,998 - root - INFO - Evaluate: Epoch 0758 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:36:36,003 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5835 | Iter Mean Loss 9.5835
2020-11-05 16:36:36,008 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2840 | Iter Mean Loss 5.4338
2020-11-05 16:36:36,014 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6336 | Iter Mean Loss 6.8337
2020-11-05 16:36:36,020 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4584 | Iter Mean Loss 6.9899
2020-11-05 16:36:36,026 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3892 | Iter Mean Loss 6.2698
2020-11-05 16:36:36,027 - root - INFO - Evaluate: Epoch 0759 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:36:36,034 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5750 | Iter Mean Loss 9.5750
2020-11-05 16:36:36,040 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2826 | Iter Mean Loss 5.4288
2020-11-05 16:36:36,045 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6216 | Iter Mean Loss 6.8264
2020-11-05 16:36:36,052 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4535 | Iter Mean Loss 6.9832
2020-11-05 16:36:36,057 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3879 | Iter Mean Loss 6.2641
2020-11-05 16:36:36,058 - root - INFO - Evaluate: Epoch 0760 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:36:36,064 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5666 | Iter Mean Loss 9.5666
2020-11-05 16:36:36,070 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2811 | Iter Mean Loss 5.4238
2020-11-05 16:36:36,076 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6097 | Iter Mean Loss 6.8191
2020-11-05 16:36:36,083 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4486 | Iter Mean Loss 6.9765
2020-11-05 16:36:36,088 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3867 | Iter Mean Loss 6.2585
2020-11-05 16:36:36,089 - root - INFO - Evaluate: Epoch 0761 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:36:36,095 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5581 | Iter Mean Loss 9.5581
2020-11-05 16:36:36,101 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2796 | Iter Mean Loss 5.4188
2020-11-05 16:36:36,107 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5977 | Iter Mean Loss 6.8118
2020-11-05 16:36:36,113 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4437 | Iter Mean Loss 6.9698
2020-11-05 16:36:36,119 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3854 | Iter Mean Loss 6.2529
2020-11-05 16:36:36,120 - root - INFO - Evaluate: Epoch 0762 | NDCG 1.0000 | MSE 0.1755
2020-11-05 16:36:36,125 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5496 | Iter Mean Loss 9.5496
2020-11-05 16:36:36,131 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2781 | Iter Mean Loss 5.4139
2020-11-05 16:36:36,137 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5858 | Iter Mean Loss 6.8045
2020-11-05 16:36:36,142 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4388 | Iter Mean Loss 6.9631
2020-11-05 16:36:36,147 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3841 | Iter Mean Loss 6.2473
2020-11-05 16:36:36,148 - root - INFO - Evaluate: Epoch 0763 | NDCG 1.0000 | MSE 0.1755
2020-11-05 16:36:36,153 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5412 | Iter Mean Loss 9.5412
2020-11-05 16:36:36,159 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2766 | Iter Mean Loss 5.4089
2020-11-05 16:36:36,164 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5739 | Iter Mean Loss 6.7972
2020-11-05 16:36:36,169 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4339 | Iter Mean Loss 6.9564
2020-11-05 16:36:36,174 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3829 | Iter Mean Loss 6.2417
2020-11-05 16:36:36,175 - root - INFO - Evaluate: Epoch 0764 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:36:36,180 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5327 | Iter Mean Loss 9.5327
2020-11-05 16:36:36,186 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2751 | Iter Mean Loss 5.4039
2020-11-05 16:36:36,191 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5621 | Iter Mean Loss 6.7900
2020-11-05 16:36:36,197 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4290 | Iter Mean Loss 6.9497
2020-11-05 16:36:36,201 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3816 | Iter Mean Loss 6.2361
2020-11-05 16:36:36,202 - root - INFO - Evaluate: Epoch 0765 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:36:36,208 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5242 | Iter Mean Loss 9.5242
2020-11-05 16:36:36,213 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2736 | Iter Mean Loss 5.3989
2020-11-05 16:36:36,219 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5502 | Iter Mean Loss 6.7827
2020-11-05 16:36:36,224 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4241 | Iter Mean Loss 6.9430
2020-11-05 16:36:36,230 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3803 | Iter Mean Loss 6.2305
2020-11-05 16:36:36,230 - root - INFO - Evaluate: Epoch 0766 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:36:36,236 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 9.5158
2020-11-05 16:36:36,242 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2721 | Iter Mean Loss 5.3939
2020-11-05 16:36:36,248 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5384 | Iter Mean Loss 6.7754
2020-11-05 16:36:36,253 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4191 | Iter Mean Loss 6.9364
2020-11-05 16:36:36,258 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3790 | Iter Mean Loss 6.2249
2020-11-05 16:36:36,259 - root - INFO - Evaluate: Epoch 0767 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:36:36,266 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5073 | Iter Mean Loss 9.5073
2020-11-05 16:36:36,272 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2706 | Iter Mean Loss 5.3890
2020-11-05 16:36:36,278 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5267 | Iter Mean Loss 6.7682
2020-11-05 16:36:36,285 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4142 | Iter Mean Loss 6.9297
2020-11-05 16:36:36,290 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3778 | Iter Mean Loss 6.2193
2020-11-05 16:36:36,291 - root - INFO - Evaluate: Epoch 0768 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:36:36,297 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4989 | Iter Mean Loss 9.4989
2020-11-05 16:36:36,303 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2691 | Iter Mean Loss 5.3840
2020-11-05 16:36:36,309 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5149 | Iter Mean Loss 6.7610
2020-11-05 16:36:36,319 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4093 | Iter Mean Loss 6.9230
2020-11-05 16:36:36,326 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3765 | Iter Mean Loss 6.2137
2020-11-05 16:36:36,327 - root - INFO - Evaluate: Epoch 0769 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:36:36,334 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4905 | Iter Mean Loss 9.4905
2020-11-05 16:36:36,339 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2675 | Iter Mean Loss 5.3790
2020-11-05 16:36:36,345 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5032 | Iter Mean Loss 6.7537
2020-11-05 16:36:36,350 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4043 | Iter Mean Loss 6.9164
2020-11-05 16:36:36,355 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3752 | Iter Mean Loss 6.2081
2020-11-05 16:36:36,356 - root - INFO - Evaluate: Epoch 0770 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:36:36,361 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 9.4821
2020-11-05 16:36:36,367 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 5.3740
2020-11-05 16:36:36,372 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4915 | Iter Mean Loss 6.7465
2020-11-05 16:36:36,377 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3993 | Iter Mean Loss 6.9097
2020-11-05 16:36:36,382 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3739 | Iter Mean Loss 6.2026
2020-11-05 16:36:36,383 - root - INFO - Evaluate: Epoch 0771 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:36:36,388 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4736 | Iter Mean Loss 9.4736
2020-11-05 16:36:36,394 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2645 | Iter Mean Loss 5.3691
2020-11-05 16:36:36,399 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4798 | Iter Mean Loss 6.7393
2020-11-05 16:36:36,404 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3944 | Iter Mean Loss 6.9031
2020-11-05 16:36:36,409 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3726 | Iter Mean Loss 6.1970
2020-11-05 16:36:36,410 - root - INFO - Evaluate: Epoch 0772 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:36:36,415 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4652 | Iter Mean Loss 9.4652
2020-11-05 16:36:36,421 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2630 | Iter Mean Loss 5.3641
2020-11-05 16:36:36,426 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4681 | Iter Mean Loss 6.7321
2020-11-05 16:36:36,432 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3894 | Iter Mean Loss 6.8964
2020-11-05 16:36:36,438 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3713 | Iter Mean Loss 6.1914
2020-11-05 16:36:36,439 - root - INFO - Evaluate: Epoch 0773 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:36:36,444 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4568 | Iter Mean Loss 9.4568
2020-11-05 16:36:36,450 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2614 | Iter Mean Loss 5.3591
2020-11-05 16:36:36,456 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4565 | Iter Mean Loss 6.7249
2020-11-05 16:36:36,461 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3844 | Iter Mean Loss 6.8898
2020-11-05 16:36:36,467 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3700 | Iter Mean Loss 6.1858
2020-11-05 16:36:36,469 - root - INFO - Evaluate: Epoch 0774 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:36:36,474 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4484 | Iter Mean Loss 9.4484
2020-11-05 16:36:36,480 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2599 | Iter Mean Loss 5.3541
2020-11-05 16:36:36,486 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4449 | Iter Mean Loss 6.7177
2020-11-05 16:36:36,492 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3794 | Iter Mean Loss 6.8831
2020-11-05 16:36:36,497 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3687 | Iter Mean Loss 6.1803
2020-11-05 16:36:36,498 - root - INFO - Evaluate: Epoch 0775 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:36:36,504 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4400 | Iter Mean Loss 9.4400
2020-11-05 16:36:36,510 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2584 | Iter Mean Loss 5.3492
2020-11-05 16:36:36,515 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4333 | Iter Mean Loss 6.7105
2020-11-05 16:36:36,522 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3744 | Iter Mean Loss 6.8765
2020-11-05 16:36:36,527 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3674 | Iter Mean Loss 6.1747
2020-11-05 16:36:36,528 - root - INFO - Evaluate: Epoch 0776 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:36:36,533 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4316 | Iter Mean Loss 9.4316
2020-11-05 16:36:36,540 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2568 | Iter Mean Loss 5.3442
2020-11-05 16:36:36,545 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4217 | Iter Mean Loss 6.7034
2020-11-05 16:36:36,550 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3694 | Iter Mean Loss 6.8699
2020-11-05 16:36:36,555 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3661 | Iter Mean Loss 6.1691
2020-11-05 16:36:36,556 - root - INFO - Evaluate: Epoch 0777 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:36:36,562 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4232 | Iter Mean Loss 9.4232
2020-11-05 16:36:36,567 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2553 | Iter Mean Loss 5.3392
2020-11-05 16:36:36,572 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4102 | Iter Mean Loss 6.6962
2020-11-05 16:36:36,578 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3643 | Iter Mean Loss 6.8632
2020-11-05 16:36:36,582 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 6.1636
2020-11-05 16:36:36,583 - root - INFO - Evaluate: Epoch 0778 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:36:36,589 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4148 | Iter Mean Loss 9.4148
2020-11-05 16:36:36,594 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2537 | Iter Mean Loss 5.3342
2020-11-05 16:36:36,599 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3986 | Iter Mean Loss 6.6890
2020-11-05 16:36:36,605 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3593 | Iter Mean Loss 6.8566
2020-11-05 16:36:36,609 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3635 | Iter Mean Loss 6.1580
2020-11-05 16:36:36,610 - root - INFO - Evaluate: Epoch 0779 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:36:36,616 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4064 | Iter Mean Loss 9.4064
2020-11-05 16:36:36,621 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2522 | Iter Mean Loss 5.3293
2020-11-05 16:36:36,626 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3871 | Iter Mean Loss 6.6819
2020-11-05 16:36:36,632 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3543 | Iter Mean Loss 6.8500
2020-11-05 16:36:36,637 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3622 | Iter Mean Loss 6.1524
2020-11-05 16:36:36,638 - root - INFO - Evaluate: Epoch 0780 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:36:36,643 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3980 | Iter Mean Loss 9.3980
2020-11-05 16:36:36,649 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2506 | Iter Mean Loss 5.3243
2020-11-05 16:36:36,655 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3756 | Iter Mean Loss 6.6747
2020-11-05 16:36:36,660 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3492 | Iter Mean Loss 6.8434
2020-11-05 16:36:36,665 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3609 | Iter Mean Loss 6.1469
2020-11-05 16:36:36,666 - root - INFO - Evaluate: Epoch 0781 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:36:36,673 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3896 | Iter Mean Loss 9.3896
2020-11-05 16:36:36,678 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2490 | Iter Mean Loss 5.3193
2020-11-05 16:36:36,684 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3642 | Iter Mean Loss 6.6676
2020-11-05 16:36:36,690 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.8367
2020-11-05 16:36:36,695 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3596 | Iter Mean Loss 6.1413
2020-11-05 16:36:36,696 - root - INFO - Evaluate: Epoch 0782 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:36:36,702 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3812 | Iter Mean Loss 9.3812
2020-11-05 16:36:36,708 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2475 | Iter Mean Loss 5.3143
2020-11-05 16:36:36,713 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3528 | Iter Mean Loss 6.6605
2020-11-05 16:36:36,719 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3390 | Iter Mean Loss 6.8301
2020-11-05 16:36:36,724 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3583 | Iter Mean Loss 6.1357
2020-11-05 16:36:36,725 - root - INFO - Evaluate: Epoch 0783 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:36:36,731 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3728 | Iter Mean Loss 9.3728
2020-11-05 16:36:36,737 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2459 | Iter Mean Loss 5.3094
2020-11-05 16:36:36,743 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3413 | Iter Mean Loss 6.6533
2020-11-05 16:36:36,748 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3339 | Iter Mean Loss 6.8235
2020-11-05 16:36:36,753 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3570 | Iter Mean Loss 6.1302
2020-11-05 16:36:36,754 - root - INFO - Evaluate: Epoch 0784 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:36:36,759 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3644 | Iter Mean Loss 9.3644
2020-11-05 16:36:36,765 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2443 | Iter Mean Loss 5.3044
2020-11-05 16:36:36,770 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3299 | Iter Mean Loss 6.6462
2020-11-05 16:36:36,775 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3288 | Iter Mean Loss 6.8169
2020-11-05 16:36:36,780 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.1246
2020-11-05 16:36:36,781 - root - INFO - Evaluate: Epoch 0785 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:36:36,786 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3561 | Iter Mean Loss 9.3561
2020-11-05 16:36:36,792 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2427 | Iter Mean Loss 5.2994
2020-11-05 16:36:36,797 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3186 | Iter Mean Loss 6.6391
2020-11-05 16:36:36,803 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3237 | Iter Mean Loss 6.8103
2020-11-05 16:36:36,807 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3543 | Iter Mean Loss 6.1191
2020-11-05 16:36:36,808 - root - INFO - Evaluate: Epoch 0786 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:36:36,814 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3477 | Iter Mean Loss 9.3477
2020-11-05 16:36:36,819 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2411 | Iter Mean Loss 5.2944
2020-11-05 16:36:36,825 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3072 | Iter Mean Loss 6.6320
2020-11-05 16:36:36,830 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3186 | Iter Mean Loss 6.8037
2020-11-05 16:36:36,835 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3530 | Iter Mean Loss 6.1135
2020-11-05 16:36:36,836 - root - INFO - Evaluate: Epoch 0787 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:36:36,842 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3393 | Iter Mean Loss 9.3393
2020-11-05 16:36:36,847 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2395 | Iter Mean Loss 5.2894
2020-11-05 16:36:36,853 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2959 | Iter Mean Loss 6.6249
2020-11-05 16:36:36,859 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3134 | Iter Mean Loss 6.7970
2020-11-05 16:36:36,864 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3517 | Iter Mean Loss 6.1080
2020-11-05 16:36:36,866 - root - INFO - Evaluate: Epoch 0788 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:36:36,871 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3309 | Iter Mean Loss 9.3309
2020-11-05 16:36:36,877 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2379 | Iter Mean Loss 5.2844
2020-11-05 16:36:36,883 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2846 | Iter Mean Loss 6.6178
2020-11-05 16:36:36,889 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3082 | Iter Mean Loss 6.7904
2020-11-05 16:36:36,893 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3503 | Iter Mean Loss 6.1024
2020-11-05 16:36:36,894 - root - INFO - Evaluate: Epoch 0789 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:36:36,901 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3226 | Iter Mean Loss 9.3226
2020-11-05 16:36:36,906 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2363 | Iter Mean Loss 5.2794
2020-11-05 16:36:36,912 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2733 | Iter Mean Loss 6.6107
2020-11-05 16:36:36,918 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3031 | Iter Mean Loss 6.7838
2020-11-05 16:36:36,923 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3490 | Iter Mean Loss 6.0968
2020-11-05 16:36:36,924 - root - INFO - Evaluate: Epoch 0790 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:36:36,930 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3142 | Iter Mean Loss 9.3142
2020-11-05 16:36:36,936 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2347 | Iter Mean Loss 5.2744
2020-11-05 16:36:36,942 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2620 | Iter Mean Loss 6.6036
2020-11-05 16:36:36,947 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2979 | Iter Mean Loss 6.7772
2020-11-05 16:36:36,952 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3476 | Iter Mean Loss 6.0913
2020-11-05 16:36:36,953 - root - INFO - Evaluate: Epoch 0791 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:36:36,958 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3058 | Iter Mean Loss 9.3058
2020-11-05 16:36:36,963 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2331 | Iter Mean Loss 5.2695
2020-11-05 16:36:36,969 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2508 | Iter Mean Loss 6.5966
2020-11-05 16:36:36,974 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2927 | Iter Mean Loss 6.7706
2020-11-05 16:36:36,979 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3463 | Iter Mean Loss 6.0857
2020-11-05 16:36:36,980 - root - INFO - Evaluate: Epoch 0792 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:36:36,985 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2975 | Iter Mean Loss 9.2975
2020-11-05 16:36:36,991 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2315 | Iter Mean Loss 5.2645
2020-11-05 16:36:36,996 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2396 | Iter Mean Loss 6.5895
2020-11-05 16:36:37,001 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2874 | Iter Mean Loss 6.7640
2020-11-05 16:36:37,006 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3449 | Iter Mean Loss 6.0802
2020-11-05 16:36:37,007 - root - INFO - Evaluate: Epoch 0793 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:36:37,012 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2891 | Iter Mean Loss 9.2891
2020-11-05 16:36:37,017 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2298 | Iter Mean Loss 5.2595
2020-11-05 16:36:37,023 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2284 | Iter Mean Loss 6.5824
2020-11-05 16:36:37,028 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2822 | Iter Mean Loss 6.7574
2020-11-05 16:36:37,033 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3436 | Iter Mean Loss 6.0746
2020-11-05 16:36:37,035 - root - INFO - Evaluate: Epoch 0794 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:36:37,040 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2807 | Iter Mean Loss 9.2807
2020-11-05 16:36:37,046 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2282 | Iter Mean Loss 5.2545
2020-11-05 16:36:37,053 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2172 | Iter Mean Loss 6.5754
2020-11-05 16:36:37,058 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2769 | Iter Mean Loss 6.7508
2020-11-05 16:36:37,063 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3422 | Iter Mean Loss 6.0690
2020-11-05 16:36:37,064 - root - INFO - Evaluate: Epoch 0795 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:36:37,071 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2724 | Iter Mean Loss 9.2724
2020-11-05 16:36:37,076 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2266 | Iter Mean Loss 5.2495
2020-11-05 16:36:37,082 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2060 | Iter Mean Loss 6.5683
2020-11-05 16:36:37,088 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2716 | Iter Mean Loss 6.7441
2020-11-05 16:36:37,093 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3408 | Iter Mean Loss 6.0635
2020-11-05 16:36:37,094 - root - INFO - Evaluate: Epoch 0796 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:36:37,100 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2640 | Iter Mean Loss 9.2640
2020-11-05 16:36:37,106 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2249 | Iter Mean Loss 5.2445
2020-11-05 16:36:37,112 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1949 | Iter Mean Loss 6.5613
2020-11-05 16:36:37,118 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2664 | Iter Mean Loss 6.7375
2020-11-05 16:36:37,123 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3395 | Iter Mean Loss 6.0579
2020-11-05 16:36:37,124 - root - INFO - Evaluate: Epoch 0797 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:36:37,130 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2556 | Iter Mean Loss 9.2556
2020-11-05 16:36:37,136 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2233 | Iter Mean Loss 5.2395
2020-11-05 16:36:37,142 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1837 | Iter Mean Loss 6.5542
2020-11-05 16:36:37,147 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2610 | Iter Mean Loss 6.7309
2020-11-05 16:36:37,153 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3381 | Iter Mean Loss 6.0524
2020-11-05 16:36:37,154 - root - INFO - Evaluate: Epoch 0798 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:36:37,159 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2473 | Iter Mean Loss 9.2473
2020-11-05 16:36:37,165 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2216 | Iter Mean Loss 5.2345
2020-11-05 16:36:37,170 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1726 | Iter Mean Loss 6.5472
2020-11-05 16:36:37,175 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2557 | Iter Mean Loss 6.7243
2020-11-05 16:36:37,180 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3367 | Iter Mean Loss 6.0468
2020-11-05 16:36:37,181 - root - INFO - Evaluate: Epoch 0799 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:36:37,186 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2389 | Iter Mean Loss 9.2389
2020-11-05 16:36:37,191 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2200 | Iter Mean Loss 5.2294
2020-11-05 16:36:37,197 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1615 | Iter Mean Loss 6.5401
2020-11-05 16:36:37,202 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2504 | Iter Mean Loss 6.7177
2020-11-05 16:36:37,207 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3354 | Iter Mean Loss 6.0412
2020-11-05 16:36:37,208 - root - INFO - Evaluate: Epoch 0800 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:36:37,213 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2306 | Iter Mean Loss 9.2306
2020-11-05 16:36:37,219 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 5.2244
2020-11-05 16:36:37,224 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1505 | Iter Mean Loss 6.5331
2020-11-05 16:36:37,229 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2450 | Iter Mean Loss 6.7111
2020-11-05 16:36:37,234 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3340 | Iter Mean Loss 6.0357
2020-11-05 16:36:37,235 - root - INFO - Evaluate: Epoch 0801 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:36:37,241 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2222 | Iter Mean Loss 9.2222
2020-11-05 16:36:37,246 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2166 | Iter Mean Loss 5.2194
2020-11-05 16:36:37,251 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1394 | Iter Mean Loss 6.5261
2020-11-05 16:36:37,257 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2396 | Iter Mean Loss 6.7045
2020-11-05 16:36:37,262 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3326 | Iter Mean Loss 6.0301
2020-11-05 16:36:37,263 - root - INFO - Evaluate: Epoch 0802 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:36:37,269 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2138 | Iter Mean Loss 9.2138
2020-11-05 16:36:37,274 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2150 | Iter Mean Loss 5.2144
2020-11-05 16:36:37,280 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1284 | Iter Mean Loss 6.5191
2020-11-05 16:36:37,286 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2342 | Iter Mean Loss 6.6978
2020-11-05 16:36:37,291 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3312 | Iter Mean Loss 6.0245
2020-11-05 16:36:37,292 - root - INFO - Evaluate: Epoch 0803 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:36:37,298 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2055 | Iter Mean Loss 9.2055
2020-11-05 16:36:37,304 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2133 | Iter Mean Loss 5.2094
2020-11-05 16:36:37,310 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1174 | Iter Mean Loss 6.5120
2020-11-05 16:36:37,316 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2288 | Iter Mean Loss 6.6912
2020-11-05 16:36:37,322 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 6.0189
2020-11-05 16:36:37,323 - root - INFO - Evaluate: Epoch 0804 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:36:37,329 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1971 | Iter Mean Loss 9.1971
2020-11-05 16:36:37,335 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2116 | Iter Mean Loss 5.2044
2020-11-05 16:36:37,341 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1064 | Iter Mean Loss 6.5050
2020-11-05 16:36:37,347 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2234 | Iter Mean Loss 6.6846
2020-11-05 16:36:37,353 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3284 | Iter Mean Loss 6.0134
2020-11-05 16:36:37,353 - root - INFO - Evaluate: Epoch 0805 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:36:37,359 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1888 | Iter Mean Loss 9.1888
2020-11-05 16:36:37,364 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2099 | Iter Mean Loss 5.1993
2020-11-05 16:36:37,370 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0954 | Iter Mean Loss 6.4980
2020-11-05 16:36:37,375 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2179 | Iter Mean Loss 6.6780
2020-11-05 16:36:37,380 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3270 | Iter Mean Loss 6.0078
2020-11-05 16:36:37,381 - root - INFO - Evaluate: Epoch 0806 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:36:37,386 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1804 | Iter Mean Loss 9.1804
2020-11-05 16:36:37,392 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 5.1943
2020-11-05 16:36:37,397 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0844 | Iter Mean Loss 6.4910
2020-11-05 16:36:37,402 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2124 | Iter Mean Loss 6.6714
2020-11-05 16:36:37,407 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3256 | Iter Mean Loss 6.0022
2020-11-05 16:36:37,408 - root - INFO - Evaluate: Epoch 0807 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:36:37,416 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1721 | Iter Mean Loss 9.1721
2020-11-05 16:36:37,425 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2065 | Iter Mean Loss 5.1893
2020-11-05 16:36:37,434 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0735 | Iter Mean Loss 6.4840
2020-11-05 16:36:37,443 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2069 | Iter Mean Loss 6.6647
2020-11-05 16:36:37,449 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3242 | Iter Mean Loss 5.9966
2020-11-05 16:36:37,450 - root - INFO - Evaluate: Epoch 0808 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:36:37,457 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1637 | Iter Mean Loss 9.1637
2020-11-05 16:36:37,463 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2048 | Iter Mean Loss 5.1842
2020-11-05 16:36:37,471 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0626 | Iter Mean Loss 6.4770
2020-11-05 16:36:37,479 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2014 | Iter Mean Loss 6.6581
2020-11-05 16:36:37,485 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3228 | Iter Mean Loss 5.9910
2020-11-05 16:36:37,486 - root - INFO - Evaluate: Epoch 0809 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:36:37,493 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1553 | Iter Mean Loss 9.1553
2020-11-05 16:36:37,500 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2031 | Iter Mean Loss 5.1792
2020-11-05 16:36:37,508 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0517 | Iter Mean Loss 6.4700
2020-11-05 16:36:37,516 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1959 | Iter Mean Loss 6.6515
2020-11-05 16:36:37,523 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3213 | Iter Mean Loss 5.9855
2020-11-05 16:36:37,524 - root - INFO - Evaluate: Epoch 0810 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:36:37,532 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1470 | Iter Mean Loss 9.1470
2020-11-05 16:36:37,540 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2014 | Iter Mean Loss 5.1742
2020-11-05 16:36:37,548 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0408 | Iter Mean Loss 6.4630
2020-11-05 16:36:37,556 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1903 | Iter Mean Loss 6.6449
2020-11-05 16:36:37,563 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3199 | Iter Mean Loss 5.9799
2020-11-05 16:36:37,564 - root - INFO - Evaluate: Epoch 0811 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:36:37,572 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1386 | Iter Mean Loss 9.1386
2020-11-05 16:36:37,579 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1996 | Iter Mean Loss 5.1691
2020-11-05 16:36:37,586 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0299 | Iter Mean Loss 6.4561
2020-11-05 16:36:37,592 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1847 | Iter Mean Loss 6.6382
2020-11-05 16:36:37,598 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3185 | Iter Mean Loss 5.9743
2020-11-05 16:36:37,599 - root - INFO - Evaluate: Epoch 0812 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:36:37,604 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1303 | Iter Mean Loss 9.1303
2020-11-05 16:36:37,609 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1979 | Iter Mean Loss 5.1641
2020-11-05 16:36:37,615 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0191 | Iter Mean Loss 6.4491
2020-11-05 16:36:37,620 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1791 | Iter Mean Loss 6.6316
2020-11-05 16:36:37,625 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3171 | Iter Mean Loss 5.9687
2020-11-05 16:36:37,625 - root - INFO - Evaluate: Epoch 0813 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:36:37,631 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1219 | Iter Mean Loss 9.1219
2020-11-05 16:36:37,636 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1962 | Iter Mean Loss 5.1591
2020-11-05 16:36:37,642 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0082 | Iter Mean Loss 6.4421
2020-11-05 16:36:37,647 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1735 | Iter Mean Loss 6.6250
2020-11-05 16:36:37,652 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3156 | Iter Mean Loss 5.9631
2020-11-05 16:36:37,652 - root - INFO - Evaluate: Epoch 0814 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:36:37,658 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1136 | Iter Mean Loss 9.1136
2020-11-05 16:36:37,663 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1944 | Iter Mean Loss 5.1540
2020-11-05 16:36:37,669 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9974 | Iter Mean Loss 6.4351
2020-11-05 16:36:37,675 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1679 | Iter Mean Loss 6.6183
2020-11-05 16:36:37,679 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3142 | Iter Mean Loss 5.9575
2020-11-05 16:36:37,680 - root - INFO - Evaluate: Epoch 0815 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:36:37,686 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1052 | Iter Mean Loss 9.1052
2020-11-05 16:36:37,691 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1927 | Iter Mean Loss 5.1490
2020-11-05 16:36:37,698 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9866 | Iter Mean Loss 6.4282
2020-11-05 16:36:37,703 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1622 | Iter Mean Loss 6.6117
2020-11-05 16:36:37,708 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3127 | Iter Mean Loss 5.9519
2020-11-05 16:36:37,710 - root - INFO - Evaluate: Epoch 0816 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:36:37,716 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0969 | Iter Mean Loss 9.0969
2020-11-05 16:36:37,721 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1909 | Iter Mean Loss 5.1439
2020-11-05 16:36:37,727 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9758 | Iter Mean Loss 6.4212
2020-11-05 16:36:37,733 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1565 | Iter Mean Loss 6.6050
2020-11-05 16:36:37,738 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3113 | Iter Mean Loss 5.9463
2020-11-05 16:36:37,739 - root - INFO - Evaluate: Epoch 0817 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:36:37,745 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0885 | Iter Mean Loss 9.0885
2020-11-05 16:36:37,750 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1892 | Iter Mean Loss 5.1389
2020-11-05 16:36:37,756 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9651 | Iter Mean Loss 6.4143
2020-11-05 16:36:37,762 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1508 | Iter Mean Loss 6.5984
2020-11-05 16:36:37,767 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3098 | Iter Mean Loss 5.9407
2020-11-05 16:36:37,768 - root - INFO - Evaluate: Epoch 0818 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:36:37,773 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0802 | Iter Mean Loss 9.0802
2020-11-05 16:36:37,779 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1874 | Iter Mean Loss 5.1338
2020-11-05 16:36:37,784 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9543 | Iter Mean Loss 6.4073
2020-11-05 16:36:37,789 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1451 | Iter Mean Loss 6.5918
2020-11-05 16:36:37,794 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3084 | Iter Mean Loss 5.9351
2020-11-05 16:36:37,795 - root - INFO - Evaluate: Epoch 0819 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:36:37,800 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0718 | Iter Mean Loss 9.0718
2020-11-05 16:36:37,806 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1857 | Iter Mean Loss 5.1288
2020-11-05 16:36:37,811 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9436 | Iter Mean Loss 6.4004
2020-11-05 16:36:37,817 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1393 | Iter Mean Loss 6.5851
2020-11-05 16:36:37,822 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3069 | Iter Mean Loss 5.9295
2020-11-05 16:36:37,823 - root - INFO - Evaluate: Epoch 0820 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:36:37,829 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0635 | Iter Mean Loss 9.0635
2020-11-05 16:36:37,834 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1839 | Iter Mean Loss 5.1237
2020-11-05 16:36:37,839 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9329 | Iter Mean Loss 6.3934
2020-11-05 16:36:37,845 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1335 | Iter Mean Loss 6.5785
2020-11-05 16:36:37,850 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3055 | Iter Mean Loss 5.9239
2020-11-05 16:36:37,850 - root - INFO - Evaluate: Epoch 0821 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:36:37,856 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0551 | Iter Mean Loss 9.0551
2020-11-05 16:36:37,861 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1821 | Iter Mean Loss 5.1186
2020-11-05 16:36:37,867 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9222 | Iter Mean Loss 6.3865
2020-11-05 16:36:37,873 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1277 | Iter Mean Loss 6.5718
2020-11-05 16:36:37,878 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3040 | Iter Mean Loss 5.9182
2020-11-05 16:36:37,879 - root - INFO - Evaluate: Epoch 0822 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:36:37,885 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0468 | Iter Mean Loss 9.0468
2020-11-05 16:36:37,893 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1804 | Iter Mean Loss 5.1136
2020-11-05 16:36:37,901 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9115 | Iter Mean Loss 6.3796
2020-11-05 16:36:37,909 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1219 | Iter Mean Loss 6.5652
2020-11-05 16:36:37,914 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3025 | Iter Mean Loss 5.9126
2020-11-05 16:36:37,915 - root - INFO - Evaluate: Epoch 0823 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:36:37,923 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0385 | Iter Mean Loss 9.0385
2020-11-05 16:36:37,928 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1786 | Iter Mean Loss 5.1085
2020-11-05 16:36:37,934 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9009 | Iter Mean Loss 6.3726
2020-11-05 16:36:37,940 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1161 | Iter Mean Loss 6.5585
2020-11-05 16:36:37,945 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3011 | Iter Mean Loss 5.9070
2020-11-05 16:36:37,946 - root - INFO - Evaluate: Epoch 0824 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:36:37,951 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0301 | Iter Mean Loss 9.0301
2020-11-05 16:36:37,957 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1768 | Iter Mean Loss 5.1035
2020-11-05 16:36:37,963 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8903 | Iter Mean Loss 6.3657
2020-11-05 16:36:37,969 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1102 | Iter Mean Loss 6.5518
2020-11-05 16:36:37,973 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2996 | Iter Mean Loss 5.9014
2020-11-05 16:36:37,974 - root - INFO - Evaluate: Epoch 0825 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:36:37,980 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0218 | Iter Mean Loss 9.0218
2020-11-05 16:36:37,985 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1750 | Iter Mean Loss 5.0984
2020-11-05 16:36:37,991 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8796 | Iter Mean Loss 6.3588
2020-11-05 16:36:37,996 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1043 | Iter Mean Loss 6.5452
2020-11-05 16:36:38,001 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2981 | Iter Mean Loss 5.8958
2020-11-05 16:36:38,002 - root - INFO - Evaluate: Epoch 0826 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:36:38,007 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0134 | Iter Mean Loss 9.0134
2020-11-05 16:36:38,014 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1732 | Iter Mean Loss 5.0933
2020-11-05 16:36:38,019 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8690 | Iter Mean Loss 6.3519
2020-11-05 16:36:38,024 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0984 | Iter Mean Loss 6.5385
2020-11-05 16:36:38,029 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2966 | Iter Mean Loss 5.8902
2020-11-05 16:36:38,030 - root - INFO - Evaluate: Epoch 0827 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:36:38,036 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0051 | Iter Mean Loss 9.0051
2020-11-05 16:36:38,042 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 5.0883
2020-11-05 16:36:38,047 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8585 | Iter Mean Loss 6.3450
2020-11-05 16:36:38,053 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0925 | Iter Mean Loss 6.5319
2020-11-05 16:36:38,057 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2951 | Iter Mean Loss 5.8845
2020-11-05 16:36:38,058 - root - INFO - Evaluate: Epoch 0828 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:36:38,064 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9968 | Iter Mean Loss 8.9968
2020-11-05 16:36:38,070 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1696 | Iter Mean Loss 5.0832
2020-11-05 16:36:38,076 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8479 | Iter Mean Loss 6.3381
2020-11-05 16:36:38,082 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0866 | Iter Mean Loss 6.5252
2020-11-05 16:36:38,086 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2936 | Iter Mean Loss 5.8789
2020-11-05 16:36:38,088 - root - INFO - Evaluate: Epoch 0829 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:36:38,094 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9884 | Iter Mean Loss 8.9884
2020-11-05 16:36:38,099 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1678 | Iter Mean Loss 5.0781
2020-11-05 16:36:38,105 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8373 | Iter Mean Loss 6.3312
2020-11-05 16:36:38,112 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0806 | Iter Mean Loss 6.5186
2020-11-05 16:36:38,116 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2922 | Iter Mean Loss 5.8733
2020-11-05 16:36:38,117 - root - INFO - Evaluate: Epoch 0830 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:36:38,124 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9801 | Iter Mean Loss 8.9801
2020-11-05 16:36:38,129 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1660 | Iter Mean Loss 5.0731
2020-11-05 16:36:38,135 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8268 | Iter Mean Loss 6.3243
2020-11-05 16:36:38,141 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0746 | Iter Mean Loss 6.5119
2020-11-05 16:36:38,146 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2907 | Iter Mean Loss 5.8676
2020-11-05 16:36:38,147 - root - INFO - Evaluate: Epoch 0831 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:36:38,152 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9718 | Iter Mean Loss 8.9718
2020-11-05 16:36:38,158 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1642 | Iter Mean Loss 5.0680
2020-11-05 16:36:38,163 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8163 | Iter Mean Loss 6.3174
2020-11-05 16:36:38,169 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0686 | Iter Mean Loss 6.5052
2020-11-05 16:36:38,174 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2892 | Iter Mean Loss 5.8620
2020-11-05 16:36:38,175 - root - INFO - Evaluate: Epoch 0832 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:36:38,181 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9635 | Iter Mean Loss 8.9635
2020-11-05 16:36:38,186 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1624 | Iter Mean Loss 5.0629
2020-11-05 16:36:38,191 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8058 | Iter Mean Loss 6.3106
2020-11-05 16:36:38,197 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0625 | Iter Mean Loss 6.4986
2020-11-05 16:36:38,201 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2877 | Iter Mean Loss 5.8564
2020-11-05 16:36:38,202 - root - INFO - Evaluate: Epoch 0833 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:36:38,208 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9551 | Iter Mean Loss 8.9551
2020-11-05 16:36:38,213 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1606 | Iter Mean Loss 5.0579
2020-11-05 16:36:38,218 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7953 | Iter Mean Loss 6.3037
2020-11-05 16:36:38,224 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0565 | Iter Mean Loss 6.4919
2020-11-05 16:36:38,229 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2862 | Iter Mean Loss 5.8508
2020-11-05 16:36:38,229 - root - INFO - Evaluate: Epoch 0834 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:36:38,235 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 8.9468
2020-11-05 16:36:38,240 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1588 | Iter Mean Loss 5.0528
2020-11-05 16:36:38,246 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7849 | Iter Mean Loss 6.2968
2020-11-05 16:36:38,251 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0504 | Iter Mean Loss 6.4852
2020-11-05 16:36:38,256 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2847 | Iter Mean Loss 5.8451
2020-11-05 16:36:38,257 - root - INFO - Evaluate: Epoch 0835 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:36:38,262 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9385 | Iter Mean Loss 8.9385
2020-11-05 16:36:38,268 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1570 | Iter Mean Loss 5.0478
2020-11-05 16:36:38,273 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7744 | Iter Mean Loss 6.2900
2020-11-05 16:36:38,279 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0443 | Iter Mean Loss 6.4786
2020-11-05 16:36:38,284 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2832 | Iter Mean Loss 5.8395
2020-11-05 16:36:38,285 - root - INFO - Evaluate: Epoch 0836 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:36:38,291 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9302 | Iter Mean Loss 8.9302
2020-11-05 16:36:38,297 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1552 | Iter Mean Loss 5.0427
2020-11-05 16:36:38,303 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7640 | Iter Mean Loss 6.2831
2020-11-05 16:36:38,310 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0382 | Iter Mean Loss 6.4719
2020-11-05 16:36:38,316 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2817 | Iter Mean Loss 5.8339
2020-11-05 16:36:38,317 - root - INFO - Evaluate: Epoch 0837 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:36:38,323 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9219 | Iter Mean Loss 8.9219
2020-11-05 16:36:38,330 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1534 | Iter Mean Loss 5.0376
2020-11-05 16:36:38,335 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7536 | Iter Mean Loss 6.2763
2020-11-05 16:36:38,341 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0320 | Iter Mean Loss 6.4652
2020-11-05 16:36:38,347 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2802 | Iter Mean Loss 5.8282
2020-11-05 16:36:38,348 - root - INFO - Evaluate: Epoch 0838 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:36:38,353 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9136 | Iter Mean Loss 8.9136
2020-11-05 16:36:38,359 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 5.0326
2020-11-05 16:36:38,364 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7432 | Iter Mean Loss 6.2695
2020-11-05 16:36:38,371 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0259 | Iter Mean Loss 6.4586
2020-11-05 16:36:38,376 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2786 | Iter Mean Loss 5.8226
2020-11-05 16:36:38,377 - root - INFO - Evaluate: Epoch 0839 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:36:38,382 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9053 | Iter Mean Loss 8.9053
2020-11-05 16:36:38,388 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1498 | Iter Mean Loss 5.0275
2020-11-05 16:36:38,393 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7329 | Iter Mean Loss 6.2626
2020-11-05 16:36:38,398 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0197 | Iter Mean Loss 6.4519
2020-11-05 16:36:38,403 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2771 | Iter Mean Loss 5.8170
2020-11-05 16:36:38,404 - root - INFO - Evaluate: Epoch 0840 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:36:38,409 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8970 | Iter Mean Loss 8.8970
2020-11-05 16:36:38,415 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1479 | Iter Mean Loss 5.0225
2020-11-05 16:36:38,420 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7225 | Iter Mean Loss 6.2558
2020-11-05 16:36:38,426 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 6.4452
2020-11-05 16:36:38,430 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2756 | Iter Mean Loss 5.8113
2020-11-05 16:36:38,431 - root - INFO - Evaluate: Epoch 0841 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:36:38,438 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8887 | Iter Mean Loss 8.8887
2020-11-05 16:36:38,443 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1461 | Iter Mean Loss 5.0174
2020-11-05 16:36:38,449 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7122 | Iter Mean Loss 6.2490
2020-11-05 16:36:38,454 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0073 | Iter Mean Loss 6.4386
2020-11-05 16:36:38,459 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2741 | Iter Mean Loss 5.8057
2020-11-05 16:36:38,460 - root - INFO - Evaluate: Epoch 0842 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:36:38,465 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8805 | Iter Mean Loss 8.8805
2020-11-05 16:36:38,471 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1443 | Iter Mean Loss 5.0124
2020-11-05 16:36:38,476 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7019 | Iter Mean Loss 6.2422
2020-11-05 16:36:38,483 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0011 | Iter Mean Loss 6.4319
2020-11-05 16:36:38,488 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2726 | Iter Mean Loss 5.8001
2020-11-05 16:36:38,489 - root - INFO - Evaluate: Epoch 0843 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:36:38,495 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8722 | Iter Mean Loss 8.8722
2020-11-05 16:36:38,501 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1425 | Iter Mean Loss 5.0073
2020-11-05 16:36:38,507 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6916 | Iter Mean Loss 6.2354
2020-11-05 16:36:38,512 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9948 | Iter Mean Loss 6.4253
2020-11-05 16:36:38,518 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2711 | Iter Mean Loss 5.7944
2020-11-05 16:36:38,519 - root - INFO - Evaluate: Epoch 0844 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:36:38,525 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8639 | Iter Mean Loss 8.8639
2020-11-05 16:36:38,531 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1407 | Iter Mean Loss 5.0023
2020-11-05 16:36:38,537 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6814 | Iter Mean Loss 6.2286
2020-11-05 16:36:38,542 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9885 | Iter Mean Loss 6.4186
2020-11-05 16:36:38,548 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2696 | Iter Mean Loss 5.7888
2020-11-05 16:36:38,549 - root - INFO - Evaluate: Epoch 0845 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:36:38,555 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8557 | Iter Mean Loss 8.8557
2020-11-05 16:36:38,560 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1388 | Iter Mean Loss 4.9973
2020-11-05 16:36:38,566 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6711 | Iter Mean Loss 6.2219
2020-11-05 16:36:38,572 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9822 | Iter Mean Loss 6.4120
2020-11-05 16:36:38,578 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2681 | Iter Mean Loss 5.7832
2020-11-05 16:36:38,579 - root - INFO - Evaluate: Epoch 0846 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:36:38,585 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8474 | Iter Mean Loss 8.8474
2020-11-05 16:36:38,592 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1370 | Iter Mean Loss 4.9922
2020-11-05 16:36:38,598 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6609 | Iter Mean Loss 6.2151
2020-11-05 16:36:38,604 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9759 | Iter Mean Loss 6.4053
2020-11-05 16:36:38,610 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2666 | Iter Mean Loss 5.7776
2020-11-05 16:36:38,611 - root - INFO - Evaluate: Epoch 0847 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:36:38,616 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8392 | Iter Mean Loss 8.8392
2020-11-05 16:36:38,622 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1352 | Iter Mean Loss 4.9872
2020-11-05 16:36:38,627 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6507 | Iter Mean Loss 6.2083
2020-11-05 16:36:38,633 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9696 | Iter Mean Loss 6.3987
2020-11-05 16:36:38,638 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2651 | Iter Mean Loss 5.7719
2020-11-05 16:36:38,639 - root - INFO - Evaluate: Epoch 0848 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:36:38,645 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8309 | Iter Mean Loss 8.8309
2020-11-05 16:36:38,651 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1334 | Iter Mean Loss 4.9822
2020-11-05 16:36:38,657 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6405 | Iter Mean Loss 6.2016
2020-11-05 16:36:38,663 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9633 | Iter Mean Loss 6.3920
2020-11-05 16:36:38,668 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2635 | Iter Mean Loss 5.7663
2020-11-05 16:36:38,669 - root - INFO - Evaluate: Epoch 0849 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:36:38,675 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8227 | Iter Mean Loss 8.8227
2020-11-05 16:36:38,680 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1316 | Iter Mean Loss 4.9771
2020-11-05 16:36:38,687 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6303 | Iter Mean Loss 6.1949
2020-11-05 16:36:38,693 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9569 | Iter Mean Loss 6.3854
2020-11-05 16:36:38,698 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2620 | Iter Mean Loss 5.7607
2020-11-05 16:36:38,699 - root - INFO - Evaluate: Epoch 0850 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:36:38,706 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8145 | Iter Mean Loss 8.8145
2020-11-05 16:36:38,712 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1298 | Iter Mean Loss 4.9721
2020-11-05 16:36:38,718 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1881
2020-11-05 16:36:38,725 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9505 | Iter Mean Loss 6.3787
2020-11-05 16:36:38,730 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2605 | Iter Mean Loss 5.7551
2020-11-05 16:36:38,731 - root - INFO - Evaluate: Epoch 0851 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:36:38,738 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8063 | Iter Mean Loss 8.8063
2020-11-05 16:36:38,744 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1280 | Iter Mean Loss 4.9671
2020-11-05 16:36:38,751 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6100 | Iter Mean Loss 6.1814
2020-11-05 16:36:38,757 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9442 | Iter Mean Loss 6.3721
2020-11-05 16:36:38,762 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2590 | Iter Mean Loss 5.7495
2020-11-05 16:36:38,763 - root - INFO - Evaluate: Epoch 0852 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:36:38,770 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7981 | Iter Mean Loss 8.7981
2020-11-05 16:36:38,776 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1262 | Iter Mean Loss 4.9621
2020-11-05 16:36:38,782 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5999 | Iter Mean Loss 6.1747
2020-11-05 16:36:38,788 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9378 | Iter Mean Loss 6.3655
2020-11-05 16:36:38,793 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2575 | Iter Mean Loss 5.7439
2020-11-05 16:36:38,794 - root - INFO - Evaluate: Epoch 0853 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:36:38,801 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7899 | Iter Mean Loss 8.7899
2020-11-05 16:36:38,807 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1244 | Iter Mean Loss 4.9571
2020-11-05 16:36:38,813 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5898 | Iter Mean Loss 6.1680
2020-11-05 16:36:38,819 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9313 | Iter Mean Loss 6.3589
2020-11-05 16:36:38,824 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2560 | Iter Mean Loss 5.7383
2020-11-05 16:36:38,825 - root - INFO - Evaluate: Epoch 0854 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:36:38,830 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7817 | Iter Mean Loss 8.7817
2020-11-05 16:36:38,836 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1226 | Iter Mean Loss 4.9521
2020-11-05 16:36:38,842 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5797 | Iter Mean Loss 6.1613
2020-11-05 16:36:38,849 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9249 | Iter Mean Loss 6.3522
2020-11-05 16:36:38,854 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 5.7327
2020-11-05 16:36:38,855 - root - INFO - Evaluate: Epoch 0855 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:36:38,860 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7735 | Iter Mean Loss 8.7735
2020-11-05 16:36:38,866 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1208 | Iter Mean Loss 4.9472
2020-11-05 16:36:38,871 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5697 | Iter Mean Loss 6.1547
2020-11-05 16:36:38,877 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9185 | Iter Mean Loss 6.3456
2020-11-05 16:36:38,882 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2530 | Iter Mean Loss 5.7271
2020-11-05 16:36:38,883 - root - INFO - Evaluate: Epoch 0856 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:36:38,890 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7654 | Iter Mean Loss 8.7654
2020-11-05 16:36:38,896 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1190 | Iter Mean Loss 4.9422
2020-11-05 16:36:38,902 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5597 | Iter Mean Loss 6.1480
2020-11-05 16:36:38,909 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9120 | Iter Mean Loss 6.3390
2020-11-05 16:36:38,914 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2515 | Iter Mean Loss 5.7215
2020-11-05 16:36:38,915 - root - INFO - Evaluate: Epoch 0857 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:36:38,922 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7572 | Iter Mean Loss 8.7572
2020-11-05 16:36:38,928 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1172 | Iter Mean Loss 4.9372
2020-11-05 16:36:38,934 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5497 | Iter Mean Loss 6.1414
2020-11-05 16:36:38,941 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9056 | Iter Mean Loss 6.3324
2020-11-05 16:36:38,946 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2500 | Iter Mean Loss 5.7159
2020-11-05 16:36:38,947 - root - INFO - Evaluate: Epoch 0858 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:36:38,953 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7491 | Iter Mean Loss 8.7491
2020-11-05 16:36:38,959 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1154 | Iter Mean Loss 4.9323
2020-11-05 16:36:38,965 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5397 | Iter Mean Loss 6.1347
2020-11-05 16:36:38,971 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8991 | Iter Mean Loss 6.3258
2020-11-05 16:36:38,977 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2485 | Iter Mean Loss 5.7104
2020-11-05 16:36:38,978 - root - INFO - Evaluate: Epoch 0859 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:36:38,984 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7409 | Iter Mean Loss 8.7409
2020-11-05 16:36:38,991 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1137 | Iter Mean Loss 4.9273
2020-11-05 16:36:38,997 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5297 | Iter Mean Loss 6.1281
2020-11-05 16:36:39,003 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8926 | Iter Mean Loss 6.3192
2020-11-05 16:36:39,009 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2470 | Iter Mean Loss 5.7048
2020-11-05 16:36:39,010 - root - INFO - Evaluate: Epoch 0860 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:36:39,016 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7328 | Iter Mean Loss 8.7328
2020-11-05 16:36:39,021 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1119 | Iter Mean Loss 4.9224
2020-11-05 16:36:39,027 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5197 | Iter Mean Loss 6.1215
2020-11-05 16:36:39,033 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8861 | Iter Mean Loss 6.3127
2020-11-05 16:36:39,039 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2456 | Iter Mean Loss 5.6992
2020-11-05 16:36:39,040 - root - INFO - Evaluate: Epoch 0861 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:36:39,046 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7247 | Iter Mean Loss 8.7247
2020-11-05 16:36:39,052 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1101 | Iter Mean Loss 4.9174
2020-11-05 16:36:39,058 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5098 | Iter Mean Loss 6.1149
2020-11-05 16:36:39,064 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8796 | Iter Mean Loss 6.3061
2020-11-05 16:36:39,069 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2441 | Iter Mean Loss 5.6937
2020-11-05 16:36:39,070 - root - INFO - Evaluate: Epoch 0862 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:36:39,076 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7167 | Iter Mean Loss 8.7167
2020-11-05 16:36:39,081 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1084 | Iter Mean Loss 4.9125
2020-11-05 16:36:39,087 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4999 | Iter Mean Loss 6.1083
2020-11-05 16:36:39,094 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8731 | Iter Mean Loss 6.2995
2020-11-05 16:36:39,099 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2426 | Iter Mean Loss 5.6881
2020-11-05 16:36:39,100 - root - INFO - Evaluate: Epoch 0863 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:36:39,105 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7086 | Iter Mean Loss 8.7086
2020-11-05 16:36:39,112 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1066 | Iter Mean Loss 4.9076
2020-11-05 16:36:39,118 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4900 | Iter Mean Loss 6.1017
2020-11-05 16:36:39,125 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8666 | Iter Mean Loss 6.2930
2020-11-05 16:36:39,130 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2411 | Iter Mean Loss 5.6826
2020-11-05 16:36:39,132 - root - INFO - Evaluate: Epoch 0864 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:36:39,137 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7005 | Iter Mean Loss 8.7005
2020-11-05 16:36:39,144 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1049 | Iter Mean Loss 4.9027
2020-11-05 16:36:39,151 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4802 | Iter Mean Loss 6.0952
2020-11-05 16:36:39,157 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8601 | Iter Mean Loss 6.2864
2020-11-05 16:36:39,163 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2397 | Iter Mean Loss 5.6771
2020-11-05 16:36:39,164 - root - INFO - Evaluate: Epoch 0865 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:36:39,170 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6925 | Iter Mean Loss 8.6925
2020-11-05 16:36:39,177 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1031 | Iter Mean Loss 4.8978
2020-11-05 16:36:39,183 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4703 | Iter Mean Loss 6.0886
2020-11-05 16:36:39,189 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8536 | Iter Mean Loss 6.2799
2020-11-05 16:36:39,194 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2382 | Iter Mean Loss 5.6716
2020-11-05 16:36:39,195 - root - INFO - Evaluate: Epoch 0866 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:36:39,201 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6844 | Iter Mean Loss 8.6844
2020-11-05 16:36:39,207 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1014 | Iter Mean Loss 4.8929
2020-11-05 16:36:39,212 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4605 | Iter Mean Loss 6.0821
2020-11-05 16:36:39,218 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8471 | Iter Mean Loss 6.2734
2020-11-05 16:36:39,223 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2367 | Iter Mean Loss 5.6660
2020-11-05 16:36:39,224 - root - INFO - Evaluate: Epoch 0867 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:36:39,230 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6764 | Iter Mean Loss 8.6764
2020-11-05 16:36:39,235 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0997 | Iter Mean Loss 4.8881
2020-11-05 16:36:39,241 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4507 | Iter Mean Loss 6.0756
2020-11-05 16:36:39,247 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8405 | Iter Mean Loss 6.2668
2020-11-05 16:36:39,253 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2353 | Iter Mean Loss 5.6605
2020-11-05 16:36:39,254 - root - INFO - Evaluate: Epoch 0868 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:36:39,259 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6684 | Iter Mean Loss 8.6684
2020-11-05 16:36:39,265 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0980 | Iter Mean Loss 4.8832
2020-11-05 16:36:39,271 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4409 | Iter Mean Loss 6.0691
2020-11-05 16:36:39,276 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8340 | Iter Mean Loss 6.2603
2020-11-05 16:36:39,281 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2339 | Iter Mean Loss 5.6550
2020-11-05 16:36:39,282 - root - INFO - Evaluate: Epoch 0869 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:36:39,288 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6605 | Iter Mean Loss 8.6605
2020-11-05 16:36:39,294 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0963 | Iter Mean Loss 4.8784
2020-11-05 16:36:39,301 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4312 | Iter Mean Loss 6.0626
2020-11-05 16:36:39,307 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8275 | Iter Mean Loss 6.2538
2020-11-05 16:36:39,314 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2324 | Iter Mean Loss 5.6496
2020-11-05 16:36:39,315 - root - INFO - Evaluate: Epoch 0870 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:36:39,321 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6525 | Iter Mean Loss 8.6525
2020-11-05 16:36:39,328 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0946 | Iter Mean Loss 4.8735
2020-11-05 16:36:39,335 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4215 | Iter Mean Loss 6.0562
2020-11-05 16:36:39,340 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8210 | Iter Mean Loss 6.2474
2020-11-05 16:36:39,346 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2310 | Iter Mean Loss 5.6441
2020-11-05 16:36:39,347 - root - INFO - Evaluate: Epoch 0871 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:36:39,354 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6445 | Iter Mean Loss 8.6445
2020-11-05 16:36:39,359 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0929 | Iter Mean Loss 4.8687
2020-11-05 16:36:39,366 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4118 | Iter Mean Loss 6.0497
2020-11-05 16:36:39,372 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8144 | Iter Mean Loss 6.2409
2020-11-05 16:36:39,378 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2296 | Iter Mean Loss 5.6386
2020-11-05 16:36:39,379 - root - INFO - Evaluate: Epoch 0872 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:36:39,385 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 8.6366
2020-11-05 16:36:39,391 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0912 | Iter Mean Loss 4.8639
2020-11-05 16:36:39,398 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4021 | Iter Mean Loss 6.0433
2020-11-05 16:36:39,404 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8079 | Iter Mean Loss 6.2344
2020-11-05 16:36:39,409 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2281 | Iter Mean Loss 5.6332
2020-11-05 16:36:39,411 - root - INFO - Evaluate: Epoch 0873 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:36:39,417 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6287 | Iter Mean Loss 8.6287
2020-11-05 16:36:39,423 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0895 | Iter Mean Loss 4.8591
2020-11-05 16:36:39,429 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3924 | Iter Mean Loss 6.0369
2020-11-05 16:36:39,435 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8014 | Iter Mean Loss 6.2280
2020-11-05 16:36:39,440 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2267 | Iter Mean Loss 5.6277
2020-11-05 16:36:39,441 - root - INFO - Evaluate: Epoch 0874 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:36:39,446 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6208 | Iter Mean Loss 8.6208
2020-11-05 16:36:39,452 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0878 | Iter Mean Loss 4.8543
2020-11-05 16:36:39,457 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3828 | Iter Mean Loss 6.0305
2020-11-05 16:36:39,463 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7948 | Iter Mean Loss 6.2216
2020-11-05 16:36:39,467 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2253 | Iter Mean Loss 5.6223
2020-11-05 16:36:39,468 - root - INFO - Evaluate: Epoch 0875 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:36:39,473 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6129 | Iter Mean Loss 8.6129
2020-11-05 16:36:39,479 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0862 | Iter Mean Loss 4.8496
2020-11-05 16:36:39,485 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3731 | Iter Mean Loss 6.0241
2020-11-05 16:36:39,490 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7883 | Iter Mean Loss 6.2151
2020-11-05 16:36:39,495 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2239 | Iter Mean Loss 5.6169
2020-11-05 16:36:39,496 - root - INFO - Evaluate: Epoch 0876 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:36:39,502 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6051 | Iter Mean Loss 8.6051
2020-11-05 16:36:39,507 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0845 | Iter Mean Loss 4.8448
2020-11-05 16:36:39,513 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3635 | Iter Mean Loss 6.0177
2020-11-05 16:36:39,518 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7818 | Iter Mean Loss 6.2087
2020-11-05 16:36:39,523 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 5.6115
2020-11-05 16:36:39,524 - root - INFO - Evaluate: Epoch 0877 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:36:39,530 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5972 | Iter Mean Loss 8.5972
2020-11-05 16:36:39,536 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0829 | Iter Mean Loss 4.8401
2020-11-05 16:36:39,542 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3540 | Iter Mean Loss 6.0114
2020-11-05 16:36:39,547 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7753 | Iter Mean Loss 6.2024
2020-11-05 16:36:39,552 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2211 | Iter Mean Loss 5.6061
2020-11-05 16:36:39,553 - root - INFO - Evaluate: Epoch 0878 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:36:39,559 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5894 | Iter Mean Loss 8.5894
2020-11-05 16:36:39,564 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0813 | Iter Mean Loss 4.8353
2020-11-05 16:36:39,570 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3444 | Iter Mean Loss 6.0050
2020-11-05 16:36:39,576 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7688 | Iter Mean Loss 6.1960
2020-11-05 16:36:39,582 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2198 | Iter Mean Loss 5.6007
2020-11-05 16:36:39,583 - root - INFO - Evaluate: Epoch 0879 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:36:39,589 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5816 | Iter Mean Loss 8.5816
2020-11-05 16:36:39,594 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0797 | Iter Mean Loss 4.8306
2020-11-05 16:36:39,599 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3349 | Iter Mean Loss 5.9987
2020-11-05 16:36:39,605 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7623 | Iter Mean Loss 6.1896
2020-11-05 16:36:39,610 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2184 | Iter Mean Loss 5.5954
2020-11-05 16:36:39,611 - root - INFO - Evaluate: Epoch 0880 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:36:39,617 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5738 | Iter Mean Loss 8.5738
2020-11-05 16:36:39,623 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0781 | Iter Mean Loss 4.8260
2020-11-05 16:36:39,628 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3254 | Iter Mean Loss 5.9924
2020-11-05 16:36:39,634 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7558 | Iter Mean Loss 6.1833
2020-11-05 16:36:39,639 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2170 | Iter Mean Loss 5.5900
2020-11-05 16:36:39,640 - root - INFO - Evaluate: Epoch 0881 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:36:39,645 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5661 | Iter Mean Loss 8.5661
2020-11-05 16:36:39,651 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0765 | Iter Mean Loss 4.8213
2020-11-05 16:36:39,656 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3159 | Iter Mean Loss 5.9862
2020-11-05 16:36:39,662 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7493 | Iter Mean Loss 6.1769
2020-11-05 16:36:39,667 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2157 | Iter Mean Loss 5.5847
2020-11-05 16:36:39,667 - root - INFO - Evaluate: Epoch 0882 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:36:39,673 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5583 | Iter Mean Loss 8.5583
2020-11-05 16:36:39,678 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0749 | Iter Mean Loss 4.8166
2020-11-05 16:36:39,684 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3064 | Iter Mean Loss 5.9799
2020-11-05 16:36:39,689 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7429 | Iter Mean Loss 6.1706
2020-11-05 16:36:39,694 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2143 | Iter Mean Loss 5.5794
2020-11-05 16:36:39,695 - root - INFO - Evaluate: Epoch 0883 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:36:39,701 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5506 | Iter Mean Loss 8.5506
2020-11-05 16:36:39,706 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0733 | Iter Mean Loss 4.8120
2020-11-05 16:36:39,712 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9736
2020-11-05 16:36:39,717 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7364 | Iter Mean Loss 6.1643
2020-11-05 16:36:39,722 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2130 | Iter Mean Loss 5.5741
2020-11-05 16:36:39,723 - root - INFO - Evaluate: Epoch 0884 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:36:39,729 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5429 | Iter Mean Loss 8.5429
2020-11-05 16:36:39,734 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0718 | Iter Mean Loss 4.8073
2020-11-05 16:36:39,740 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2876 | Iter Mean Loss 5.9674
2020-11-05 16:36:39,746 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7299 | Iter Mean Loss 6.1581
2020-11-05 16:36:39,751 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2117 | Iter Mean Loss 5.5688
2020-11-05 16:36:39,752 - root - INFO - Evaluate: Epoch 0885 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:36:39,758 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5352 | Iter Mean Loss 8.5352
2020-11-05 16:36:39,763 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0702 | Iter Mean Loss 4.8027
2020-11-05 16:36:39,768 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2782 | Iter Mean Loss 5.9612
2020-11-05 16:36:39,774 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7235 | Iter Mean Loss 6.1518
2020-11-05 16:36:39,780 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2104 | Iter Mean Loss 5.5635
2020-11-05 16:36:39,781 - root - INFO - Evaluate: Epoch 0886 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:36:39,787 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5276 | Iter Mean Loss 8.5276
2020-11-05 16:36:39,792 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0687 | Iter Mean Loss 4.7981
2020-11-05 16:36:39,797 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2688 | Iter Mean Loss 5.9550
2020-11-05 16:36:39,803 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7171 | Iter Mean Loss 6.1455
2020-11-05 16:36:39,808 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2090 | Iter Mean Loss 5.5582
2020-11-05 16:36:39,809 - root - INFO - Evaluate: Epoch 0887 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:36:39,814 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5199 | Iter Mean Loss 8.5199
2020-11-05 16:36:39,820 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0672 | Iter Mean Loss 4.7936
2020-11-05 16:36:39,825 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2595 | Iter Mean Loss 5.9489
2020-11-05 16:36:39,831 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7107 | Iter Mean Loss 6.1393
2020-11-05 16:36:39,836 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2077 | Iter Mean Loss 5.5530
2020-11-05 16:36:39,837 - root - INFO - Evaluate: Epoch 0888 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:36:39,842 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5123 | Iter Mean Loss 8.5123
2020-11-05 16:36:39,848 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0657 | Iter Mean Loss 4.7890
2020-11-05 16:36:39,854 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2502 | Iter Mean Loss 5.9427
2020-11-05 16:36:39,859 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7043 | Iter Mean Loss 6.1331
2020-11-05 16:36:39,864 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2065 | Iter Mean Loss 5.5478
2020-11-05 16:36:39,865 - root - INFO - Evaluate: Epoch 0889 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:36:39,870 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5047 | Iter Mean Loss 8.5047
2020-11-05 16:36:39,876 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0642 | Iter Mean Loss 4.7845
2020-11-05 16:36:39,881 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2409 | Iter Mean Loss 5.9366
2020-11-05 16:36:39,886 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6979 | Iter Mean Loss 6.1269
2020-11-05 16:36:39,892 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2052 | Iter Mean Loss 5.5426
2020-11-05 16:36:39,893 - root - INFO - Evaluate: Epoch 0890 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:36:39,898 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4972 | Iter Mean Loss 8.4972
2020-11-05 16:36:39,905 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0627 | Iter Mean Loss 4.7799
2020-11-05 16:36:39,910 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2316 | Iter Mean Loss 5.9305
2020-11-05 16:36:39,916 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6915 | Iter Mean Loss 6.1208
2020-11-05 16:36:39,921 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2039 | Iter Mean Loss 5.5374
2020-11-05 16:36:39,922 - root - INFO - Evaluate: Epoch 0891 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:36:39,928 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4896 | Iter Mean Loss 8.4896
2020-11-05 16:36:39,935 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0612 | Iter Mean Loss 4.7754
2020-11-05 16:36:39,942 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2223 | Iter Mean Loss 5.9244
2020-11-05 16:36:39,947 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6852 | Iter Mean Loss 6.1146
2020-11-05 16:36:39,953 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2026 | Iter Mean Loss 5.5322
2020-11-05 16:36:39,955 - root - INFO - Evaluate: Epoch 0892 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:36:39,960 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4821 | Iter Mean Loss 8.4821
2020-11-05 16:36:39,966 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0598 | Iter Mean Loss 4.7709
2020-11-05 16:36:39,972 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2131 | Iter Mean Loss 5.9183
2020-11-05 16:36:39,978 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6789 | Iter Mean Loss 6.1085
2020-11-05 16:36:39,984 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2014 | Iter Mean Loss 5.5270
2020-11-05 16:36:39,985 - root - INFO - Evaluate: Epoch 0893 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:36:39,991 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4746 | Iter Mean Loss 8.4746
2020-11-05 16:36:39,996 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0583 | Iter Mean Loss 4.7665
2020-11-05 16:36:40,003 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2039 | Iter Mean Loss 5.9123
2020-11-05 16:36:40,008 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6726 | Iter Mean Loss 6.1023
2020-11-05 16:36:40,013 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2001 | Iter Mean Loss 5.5219
2020-11-05 16:36:40,014 - root - INFO - Evaluate: Epoch 0894 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:36:40,019 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4671 | Iter Mean Loss 8.4671
2020-11-05 16:36:40,025 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0569 | Iter Mean Loss 4.7620
2020-11-05 16:36:40,031 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1947 | Iter Mean Loss 5.9062
2020-11-05 16:36:40,037 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6663 | Iter Mean Loss 6.0963
2020-11-05 16:36:40,042 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1989 | Iter Mean Loss 5.5168
2020-11-05 16:36:40,043 - root - INFO - Evaluate: Epoch 0895 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:36:40,048 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4597 | Iter Mean Loss 8.4597
2020-11-05 16:36:40,054 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0555 | Iter Mean Loss 4.7576
2020-11-05 16:36:40,059 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1855 | Iter Mean Loss 5.9002
2020-11-05 16:36:40,065 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 6.0902
2020-11-05 16:36:40,069 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1977 | Iter Mean Loss 5.5117
2020-11-05 16:36:40,070 - root - INFO - Evaluate: Epoch 0896 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:36:40,076 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 16:36:40,083 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0541 | Iter Mean Loss 4.7532
2020-11-05 16:36:40,088 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1764 | Iter Mean Loss 5.8942
2020-11-05 16:36:40,094 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6538 | Iter Mean Loss 6.0841
2020-11-05 16:36:40,101 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1965 | Iter Mean Loss 5.5066
2020-11-05 16:36:40,102 - root - INFO - Evaluate: Epoch 0897 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:36:40,108 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4448 | Iter Mean Loss 8.4448
2020-11-05 16:36:40,114 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0527 | Iter Mean Loss 4.7488
2020-11-05 16:36:40,120 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1673 | Iter Mean Loss 5.8883
2020-11-05 16:36:40,125 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6475 | Iter Mean Loss 6.0781
2020-11-05 16:36:40,132 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1953 | Iter Mean Loss 5.5015
2020-11-05 16:36:40,133 - root - INFO - Evaluate: Epoch 0898 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:36:40,139 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4375 | Iter Mean Loss 8.4375
2020-11-05 16:36:40,147 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0513 | Iter Mean Loss 4.7444
2020-11-05 16:36:40,154 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1582 | Iter Mean Loss 5.8823
2020-11-05 16:36:40,160 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6413 | Iter Mean Loss 6.0721
2020-11-05 16:36:40,166 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1941 | Iter Mean Loss 5.4965
2020-11-05 16:36:40,167 - root - INFO - Evaluate: Epoch 0899 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:36:40,174 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4301 | Iter Mean Loss 8.4301
2020-11-05 16:36:40,181 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0500 | Iter Mean Loss 4.7400
2020-11-05 16:36:40,187 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1491 | Iter Mean Loss 5.8764
2020-11-05 16:36:40,194 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6352 | Iter Mean Loss 6.0661
2020-11-05 16:36:40,200 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1929 | Iter Mean Loss 5.4914
2020-11-05 16:36:40,201 - root - INFO - Evaluate: Epoch 0900 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:36:40,207 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4227 | Iter Mean Loss 8.4227
2020-11-05 16:36:40,214 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0486 | Iter Mean Loss 4.7357
2020-11-05 16:36:40,220 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1400 | Iter Mean Loss 5.8705
2020-11-05 16:36:40,227 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6290 | Iter Mean Loss 6.0601
2020-11-05 16:36:40,233 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1917 | Iter Mean Loss 5.4864
2020-11-05 16:36:40,234 - root - INFO - Evaluate: Epoch 0901 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:36:40,240 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 8.4154
2020-11-05 16:36:40,246 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0473 | Iter Mean Loss 4.7314
2020-11-05 16:36:40,252 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1310 | Iter Mean Loss 5.8646
2020-11-05 16:36:40,258 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6229 | Iter Mean Loss 6.0541
2020-11-05 16:36:40,263 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1906 | Iter Mean Loss 5.4814
2020-11-05 16:36:40,264 - root - INFO - Evaluate: Epoch 0902 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:36:40,270 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4081 | Iter Mean Loss 8.4081
2020-11-05 16:36:40,275 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0460 | Iter Mean Loss 4.7271
2020-11-05 16:36:40,281 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1220 | Iter Mean Loss 5.8587
2020-11-05 16:36:40,287 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6168 | Iter Mean Loss 6.0482
2020-11-05 16:36:40,292 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1894 | Iter Mean Loss 5.4765
2020-11-05 16:36:40,292 - root - INFO - Evaluate: Epoch 0903 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:36:40,298 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4009 | Iter Mean Loss 8.4009
2020-11-05 16:36:40,304 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0446 | Iter Mean Loss 4.7228
2020-11-05 16:36:40,310 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1130 | Iter Mean Loss 5.8528
2020-11-05 16:36:40,316 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6107 | Iter Mean Loss 6.0423
2020-11-05 16:36:40,321 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1883 | Iter Mean Loss 5.4715
2020-11-05 16:36:40,322 - root - INFO - Evaluate: Epoch 0904 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:36:40,329 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3936 | Iter Mean Loss 8.3936
2020-11-05 16:36:40,336 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0434 | Iter Mean Loss 4.7185
2020-11-05 16:36:40,342 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1040 | Iter Mean Loss 5.8470
2020-11-05 16:36:40,349 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.0364
2020-11-05 16:36:40,355 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1872 | Iter Mean Loss 5.4666
2020-11-05 16:36:40,356 - root - INFO - Evaluate: Epoch 0905 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:36:40,362 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3864 | Iter Mean Loss 8.3864
2020-11-05 16:36:40,368 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0421 | Iter Mean Loss 4.7142
2020-11-05 16:36:40,374 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0951 | Iter Mean Loss 5.8412
2020-11-05 16:36:40,380 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5986 | Iter Mean Loss 6.0305
2020-11-05 16:36:40,385 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1861 | Iter Mean Loss 5.4616
2020-11-05 16:36:40,388 - root - INFO - Evaluate: Epoch 0906 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:36:40,394 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 8.3792
2020-11-05 16:36:40,400 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0408 | Iter Mean Loss 4.7100
2020-11-05 16:36:40,407 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0862 | Iter Mean Loss 5.8354
2020-11-05 16:36:40,413 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5926 | Iter Mean Loss 6.0247
2020-11-05 16:36:40,418 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1849 | Iter Mean Loss 5.4567
2020-11-05 16:36:40,419 - root - INFO - Evaluate: Epoch 0907 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:36:40,425 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3720 | Iter Mean Loss 8.3720
2020-11-05 16:36:40,431 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0395 | Iter Mean Loss 4.7058
2020-11-05 16:36:40,438 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0773 | Iter Mean Loss 5.8296
2020-11-05 16:36:40,444 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5866 | Iter Mean Loss 6.0189
2020-11-05 16:36:40,449 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1838 | Iter Mean Loss 5.4519
2020-11-05 16:36:40,450 - root - INFO - Evaluate: Epoch 0908 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:36:40,456 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3649 | Iter Mean Loss 8.3649
2020-11-05 16:36:40,462 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0383 | Iter Mean Loss 4.7016
2020-11-05 16:36:40,469 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0684 | Iter Mean Loss 5.8239
2020-11-05 16:36:40,475 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5806 | Iter Mean Loss 6.0131
2020-11-05 16:36:40,480 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1828 | Iter Mean Loss 5.4470
2020-11-05 16:36:40,481 - root - INFO - Evaluate: Epoch 0909 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:36:40,487 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3578 | Iter Mean Loss 8.3578
2020-11-05 16:36:40,492 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0371 | Iter Mean Loss 4.6974
2020-11-05 16:36:40,498 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0595 | Iter Mean Loss 5.8181
2020-11-05 16:36:40,504 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5747 | Iter Mean Loss 6.0073
2020-11-05 16:36:40,509 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1817 | Iter Mean Loss 5.4422
2020-11-05 16:36:40,510 - root - INFO - Evaluate: Epoch 0910 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:36:40,516 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3506 | Iter Mean Loss 8.3506
2020-11-05 16:36:40,521 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0359 | Iter Mean Loss 4.6933
2020-11-05 16:36:40,529 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0507 | Iter Mean Loss 5.8124
2020-11-05 16:36:40,537 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5688 | Iter Mean Loss 6.0015
2020-11-05 16:36:40,544 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1806 | Iter Mean Loss 5.4373
2020-11-05 16:36:40,545 - root - INFO - Evaluate: Epoch 0911 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:36:40,552 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3436 | Iter Mean Loss 8.3436
2020-11-05 16:36:40,561 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0347 | Iter Mean Loss 4.6891
2020-11-05 16:36:40,567 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0419 | Iter Mean Loss 5.8067
2020-11-05 16:36:40,574 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5630 | Iter Mean Loss 5.9958
2020-11-05 16:36:40,581 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1796 | Iter Mean Loss 5.4325
2020-11-05 16:36:40,582 - root - INFO - Evaluate: Epoch 0912 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:36:40,592 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3365 | Iter Mean Loss 8.3365
2020-11-05 16:36:40,599 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0335 | Iter Mean Loss 4.6850
2020-11-05 16:36:40,605 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0331 | Iter Mean Loss 5.8010
2020-11-05 16:36:40,611 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5571 | Iter Mean Loss 5.9900
2020-11-05 16:36:40,616 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1785 | Iter Mean Loss 5.4277
2020-11-05 16:36:40,617 - root - INFO - Evaluate: Epoch 0913 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:36:40,623 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3295 | Iter Mean Loss 8.3295
2020-11-05 16:36:40,629 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0323 | Iter Mean Loss 4.6809
2020-11-05 16:36:40,635 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0243 | Iter Mean Loss 5.7953
2020-11-05 16:36:40,642 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5513 | Iter Mean Loss 5.9843
2020-11-05 16:36:40,647 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1775 | Iter Mean Loss 5.4230
2020-11-05 16:36:40,648 - root - INFO - Evaluate: Epoch 0914 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:36:40,654 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3224 | Iter Mean Loss 8.3224
2020-11-05 16:36:40,662 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0311 | Iter Mean Loss 4.6768
2020-11-05 16:36:40,667 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0155 | Iter Mean Loss 5.7897
2020-11-05 16:36:40,673 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5456 | Iter Mean Loss 5.9787
2020-11-05 16:36:40,679 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1764 | Iter Mean Loss 5.4182
2020-11-05 16:36:40,679 - root - INFO - Evaluate: Epoch 0915 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:36:40,685 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3155 | Iter Mean Loss 8.3155
2020-11-05 16:36:40,691 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0300 | Iter Mean Loss 4.6727
2020-11-05 16:36:40,697 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0068 | Iter Mean Loss 5.7841
2020-11-05 16:36:40,703 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5398 | Iter Mean Loss 5.9730
2020-11-05 16:36:40,709 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1754 | Iter Mean Loss 5.4135
2020-11-05 16:36:40,710 - root - INFO - Evaluate: Epoch 0916 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:36:40,716 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3085 | Iter Mean Loss 8.3085
2020-11-05 16:36:40,724 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0288 | Iter Mean Loss 4.6687
2020-11-05 16:36:40,731 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9981 | Iter Mean Loss 5.7785
2020-11-05 16:36:40,737 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5341 | Iter Mean Loss 5.9674
2020-11-05 16:36:40,743 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1744 | Iter Mean Loss 5.4088
2020-11-05 16:36:40,744 - root - INFO - Evaluate: Epoch 0917 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:36:40,750 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3015 | Iter Mean Loss 8.3015
2020-11-05 16:36:40,757 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0277 | Iter Mean Loss 4.6646
2020-11-05 16:36:40,763 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9894 | Iter Mean Loss 5.7729
2020-11-05 16:36:40,768 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5284 | Iter Mean Loss 5.9618
2020-11-05 16:36:40,773 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.4041
2020-11-05 16:36:40,774 - root - INFO - Evaluate: Epoch 0918 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:36:40,780 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2946 | Iter Mean Loss 8.2946
2020-11-05 16:36:40,787 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0266 | Iter Mean Loss 4.6606
2020-11-05 16:36:40,793 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9807 | Iter Mean Loss 5.7673
2020-11-05 16:36:40,798 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5228 | Iter Mean Loss 5.9562
2020-11-05 16:36:40,804 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1724 | Iter Mean Loss 5.3994
2020-11-05 16:36:40,805 - root - INFO - Evaluate: Epoch 0919 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:36:40,811 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 8.2877
2020-11-05 16:36:40,817 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0255 | Iter Mean Loss 4.6566
2020-11-05 16:36:40,824 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9720 | Iter Mean Loss 5.7617
2020-11-05 16:36:40,830 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5172 | Iter Mean Loss 5.9506
2020-11-05 16:36:40,834 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1715 | Iter Mean Loss 5.3948
2020-11-05 16:36:40,835 - root - INFO - Evaluate: Epoch 0920 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:36:40,841 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2808 | Iter Mean Loss 8.2808
2020-11-05 16:36:40,847 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0244 | Iter Mean Loss 4.6526
2020-11-05 16:36:40,852 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9634 | Iter Mean Loss 5.7562
2020-11-05 16:36:40,858 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5116 | Iter Mean Loss 5.9451
2020-11-05 16:36:40,864 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1705 | Iter Mean Loss 5.3901
2020-11-05 16:36:40,865 - root - INFO - Evaluate: Epoch 0921 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:36:40,871 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2740 | Iter Mean Loss 8.2740
2020-11-05 16:36:40,876 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0234 | Iter Mean Loss 4.6487
2020-11-05 16:36:40,882 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9548 | Iter Mean Loss 5.7507
2020-11-05 16:36:40,887 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5060 | Iter Mean Loss 5.9395
2020-11-05 16:36:40,892 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1695 | Iter Mean Loss 5.3855
2020-11-05 16:36:40,893 - root - INFO - Evaluate: Epoch 0922 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:36:40,898 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2671 | Iter Mean Loss 8.2671
2020-11-05 16:36:40,904 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0223 | Iter Mean Loss 4.6447
2020-11-05 16:36:40,909 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9462 | Iter Mean Loss 5.7452
2020-11-05 16:36:40,915 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5005 | Iter Mean Loss 5.9340
2020-11-05 16:36:40,920 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1686 | Iter Mean Loss 5.3809
2020-11-05 16:36:40,921 - root - INFO - Evaluate: Epoch 0923 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:36:40,926 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2603 | Iter Mean Loss 8.2603
2020-11-05 16:36:40,932 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0212 | Iter Mean Loss 4.6408
2020-11-05 16:36:40,937 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9376 | Iter Mean Loss 5.7397
2020-11-05 16:36:40,943 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4950 | Iter Mean Loss 5.9285
2020-11-05 16:36:40,948 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1676 | Iter Mean Loss 5.3764
2020-11-05 16:36:40,949 - root - INFO - Evaluate: Epoch 0924 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:36:40,955 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2535 | Iter Mean Loss 8.2535
2020-11-05 16:36:40,962 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0202 | Iter Mean Loss 4.6369
2020-11-05 16:36:40,967 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9290 | Iter Mean Loss 5.7342
2020-11-05 16:36:40,973 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4896 | Iter Mean Loss 5.9231
2020-11-05 16:36:40,978 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1667 | Iter Mean Loss 5.3718
2020-11-05 16:36:40,979 - root - INFO - Evaluate: Epoch 0925 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:36:40,984 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2467 | Iter Mean Loss 8.2467
2020-11-05 16:36:40,991 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0192 | Iter Mean Loss 4.6330
2020-11-05 16:36:40,997 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9205 | Iter Mean Loss 5.7288
2020-11-05 16:36:41,002 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4842 | Iter Mean Loss 5.9176
2020-11-05 16:36:41,007 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1658 | Iter Mean Loss 5.3673
2020-11-05 16:36:41,008 - root - INFO - Evaluate: Epoch 0926 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:36:41,013 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2400 | Iter Mean Loss 8.2400
2020-11-05 16:36:41,019 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0182 | Iter Mean Loss 4.6291
2020-11-05 16:36:41,025 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9119 | Iter Mean Loss 5.7234
2020-11-05 16:36:41,031 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4788 | Iter Mean Loss 5.9122
2020-11-05 16:36:41,036 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1649 | Iter Mean Loss 5.3627
2020-11-05 16:36:41,038 - root - INFO - Evaluate: Epoch 0927 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:36:41,044 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2332 | Iter Mean Loss 8.2332
2020-11-05 16:36:41,049 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0171 | Iter Mean Loss 4.6252
2020-11-05 16:36:41,055 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9034 | Iter Mean Loss 5.7179
2020-11-05 16:36:41,060 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4734 | Iter Mean Loss 5.9068
2020-11-05 16:36:41,065 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1640 | Iter Mean Loss 5.3582
2020-11-05 16:36:41,066 - root - INFO - Evaluate: Epoch 0928 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:36:41,072 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 8.2265
2020-11-05 16:36:41,078 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0162 | Iter Mean Loss 4.6213
2020-11-05 16:36:41,083 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8949 | Iter Mean Loss 5.7125
2020-11-05 16:36:41,089 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4681 | Iter Mean Loss 5.9014
2020-11-05 16:36:41,094 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1631 | Iter Mean Loss 5.3538
2020-11-05 16:36:41,095 - root - INFO - Evaluate: Epoch 0929 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:36:41,101 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2198 | Iter Mean Loss 8.2198
2020-11-05 16:36:41,106 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0152 | Iter Mean Loss 4.6175
2020-11-05 16:36:41,115 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8865 | Iter Mean Loss 5.7072
2020-11-05 16:36:41,121 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4628 | Iter Mean Loss 5.8961
2020-11-05 16:36:41,128 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1622 | Iter Mean Loss 5.3493
2020-11-05 16:36:41,129 - root - INFO - Evaluate: Epoch 0930 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:36:41,135 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2132 | Iter Mean Loss 8.2132
2020-11-05 16:36:41,142 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0142 | Iter Mean Loss 4.6137
2020-11-05 16:36:41,149 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8780 | Iter Mean Loss 5.7018
2020-11-05 16:36:41,154 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4575 | Iter Mean Loss 5.8907
2020-11-05 16:36:41,161 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1613 | Iter Mean Loss 5.3448
2020-11-05 16:36:41,163 - root - INFO - Evaluate: Epoch 0931 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:36:41,169 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2065 | Iter Mean Loss 8.2065
2020-11-05 16:36:41,175 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0132 | Iter Mean Loss 4.6099
2020-11-05 16:36:41,182 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8696 | Iter Mean Loss 5.6964
2020-11-05 16:36:41,189 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4523 | Iter Mean Loss 5.8854
2020-11-05 16:36:41,195 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1604 | Iter Mean Loss 5.3404
2020-11-05 16:36:41,196 - root - INFO - Evaluate: Epoch 0932 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:36:41,202 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1999 | Iter Mean Loss 8.1999
2020-11-05 16:36:41,208 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0123 | Iter Mean Loss 4.6061
2020-11-05 16:36:41,215 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8611 | Iter Mean Loss 5.6911
2020-11-05 16:36:41,221 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4471 | Iter Mean Loss 5.8801
2020-11-05 16:36:41,226 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1595 | Iter Mean Loss 5.3360
2020-11-05 16:36:41,229 - root - INFO - Evaluate: Epoch 0933 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:36:41,235 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1932 | Iter Mean Loss 8.1932
2020-11-05 16:36:41,241 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0113 | Iter Mean Loss 4.6023
2020-11-05 16:36:41,248 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8527 | Iter Mean Loss 5.6858
2020-11-05 16:36:41,255 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4420 | Iter Mean Loss 5.8748
2020-11-05 16:36:41,260 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1587 | Iter Mean Loss 5.3316
2020-11-05 16:36:41,262 - root - INFO - Evaluate: Epoch 0934 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:36:41,269 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1867 | Iter Mean Loss 8.1867
2020-11-05 16:36:41,275 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0104 | Iter Mean Loss 4.5985
2020-11-05 16:36:41,282 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8443 | Iter Mean Loss 5.6805
2020-11-05 16:36:41,288 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4369 | Iter Mean Loss 5.8696
2020-11-05 16:36:41,295 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1578 | Iter Mean Loss 5.3272
2020-11-05 16:36:41,296 - root - INFO - Evaluate: Epoch 0935 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:36:41,302 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1801 | Iter Mean Loss 8.1801
2020-11-05 16:36:41,309 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0095 | Iter Mean Loss 4.5948
2020-11-05 16:36:41,317 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8360 | Iter Mean Loss 5.6752
2020-11-05 16:36:41,323 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4318 | Iter Mean Loss 5.8643
2020-11-05 16:36:41,330 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1570 | Iter Mean Loss 5.3229
2020-11-05 16:36:41,331 - root - INFO - Evaluate: Epoch 0936 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:36:41,337 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1735 | Iter Mean Loss 8.1735
2020-11-05 16:36:41,344 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0086 | Iter Mean Loss 4.5910
2020-11-05 16:36:41,350 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 5.6699
2020-11-05 16:36:41,356 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4267 | Iter Mean Loss 5.8591
2020-11-05 16:36:41,361 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1562 | Iter Mean Loss 5.3185
2020-11-05 16:36:41,362 - root - INFO - Evaluate: Epoch 0937 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:36:41,368 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1670 | Iter Mean Loss 8.1670
2020-11-05 16:36:41,374 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0077 | Iter Mean Loss 4.5873
2020-11-05 16:36:41,380 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8193 | Iter Mean Loss 5.6646
2020-11-05 16:36:41,387 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4217 | Iter Mean Loss 5.8539
2020-11-05 16:36:41,392 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1553 | Iter Mean Loss 5.3142
2020-11-05 16:36:41,393 - root - INFO - Evaluate: Epoch 0938 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:36:41,399 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 8.1604
2020-11-05 16:36:41,405 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0068 | Iter Mean Loss 4.5836
2020-11-05 16:36:41,411 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8110 | Iter Mean Loss 5.6594
2020-11-05 16:36:41,416 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4167 | Iter Mean Loss 5.8487
2020-11-05 16:36:41,423 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1545 | Iter Mean Loss 5.3099
2020-11-05 16:36:41,424 - root - INFO - Evaluate: Epoch 0939 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:36:41,430 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1539 | Iter Mean Loss 8.1539
2020-11-05 16:36:41,436 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0059 | Iter Mean Loss 4.5799
2020-11-05 16:36:41,442 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8027 | Iter Mean Loss 5.6542
2020-11-05 16:36:41,448 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4117 | Iter Mean Loss 5.8436
2020-11-05 16:36:41,452 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1537 | Iter Mean Loss 5.3056
2020-11-05 16:36:41,453 - root - INFO - Evaluate: Epoch 0940 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:36:41,459 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1475 | Iter Mean Loss 8.1475
2020-11-05 16:36:41,465 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0050 | Iter Mean Loss 4.5762
2020-11-05 16:36:41,470 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7944 | Iter Mean Loss 5.6490
2020-11-05 16:36:41,476 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4068 | Iter Mean Loss 5.8384
2020-11-05 16:36:41,481 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1529 | Iter Mean Loss 5.3013
2020-11-05 16:36:41,482 - root - INFO - Evaluate: Epoch 0941 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:36:41,487 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1410 | Iter Mean Loss 8.1410
2020-11-05 16:36:41,493 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0042 | Iter Mean Loss 4.5726
2020-11-05 16:36:41,498 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7861 | Iter Mean Loss 5.6438
2020-11-05 16:36:41,504 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4019 | Iter Mean Loss 5.8333
2020-11-05 16:36:41,509 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1521 | Iter Mean Loss 5.2971
2020-11-05 16:36:41,510 - root - INFO - Evaluate: Epoch 0942 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:36:41,515 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1345 | Iter Mean Loss 8.1345
2020-11-05 16:36:41,522 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0033 | Iter Mean Loss 4.5689
2020-11-05 16:36:41,527 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7778 | Iter Mean Loss 5.6386
2020-11-05 16:36:41,533 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3971 | Iter Mean Loss 5.8282
2020-11-05 16:36:41,537 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1513 | Iter Mean Loss 5.2928
2020-11-05 16:36:41,538 - root - INFO - Evaluate: Epoch 0943 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:36:41,544 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1281 | Iter Mean Loss 8.1281
2020-11-05 16:36:41,550 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0025 | Iter Mean Loss 4.5653
2020-11-05 16:36:41,556 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7696 | Iter Mean Loss 5.6334
2020-11-05 16:36:41,562 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3923 | Iter Mean Loss 5.8231
2020-11-05 16:36:41,568 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1505 | Iter Mean Loss 5.2886
2020-11-05 16:36:41,568 - root - INFO - Evaluate: Epoch 0944 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:36:41,575 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1217 | Iter Mean Loss 8.1217
2020-11-05 16:36:41,582 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0016 | Iter Mean Loss 4.5616
2020-11-05 16:36:41,588 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7614 | Iter Mean Loss 5.6282
2020-11-05 16:36:41,594 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3875 | Iter Mean Loss 5.8180
2020-11-05 16:36:41,600 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1497 | Iter Mean Loss 5.2844
2020-11-05 16:36:41,601 - root - INFO - Evaluate: Epoch 0945 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:36:41,608 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1153 | Iter Mean Loss 8.1153
2020-11-05 16:36:41,615 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0008 | Iter Mean Loss 4.5580
2020-11-05 16:36:41,620 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7532 | Iter Mean Loss 5.6231
2020-11-05 16:36:41,626 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3827 | Iter Mean Loss 5.8130
2020-11-05 16:36:41,631 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1489 | Iter Mean Loss 5.2802
2020-11-05 16:36:41,632 - root - INFO - Evaluate: Epoch 0946 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:36:41,638 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1089 | Iter Mean Loss 8.1089
2020-11-05 16:36:41,643 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0000 | Iter Mean Loss 4.5544
2020-11-05 16:36:41,649 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7450 | Iter Mean Loss 5.6179
2020-11-05 16:36:41,655 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3780 | Iter Mean Loss 5.8080
2020-11-05 16:36:41,660 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1482 | Iter Mean Loss 5.2760
2020-11-05 16:36:41,660 - root - INFO - Evaluate: Epoch 0947 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:36:41,666 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1025 | Iter Mean Loss 8.1025
2020-11-05 16:36:41,672 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9992 | Iter Mean Loss 4.5508
2020-11-05 16:36:41,677 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7368 | Iter Mean Loss 5.6128
2020-11-05 16:36:41,683 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3733 | Iter Mean Loss 5.8029
2020-11-05 16:36:41,687 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1474 | Iter Mean Loss 5.2718
2020-11-05 16:36:41,688 - root - INFO - Evaluate: Epoch 0948 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:36:41,694 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0962 | Iter Mean Loss 8.0962
2020-11-05 16:36:41,700 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9983 | Iter Mean Loss 4.5473
2020-11-05 16:36:41,706 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7286 | Iter Mean Loss 5.6077
2020-11-05 16:36:41,712 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3686 | Iter Mean Loss 5.7979
2020-11-05 16:36:41,716 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1466 | Iter Mean Loss 5.2677
2020-11-05 16:36:41,717 - root - INFO - Evaluate: Epoch 0949 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:36:41,723 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0898 | Iter Mean Loss 8.0898
2020-11-05 16:36:41,728 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9976 | Iter Mean Loss 4.5437
2020-11-05 16:36:41,734 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7205 | Iter Mean Loss 5.6026
2020-11-05 16:36:41,739 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3640 | Iter Mean Loss 5.7930
2020-11-05 16:36:41,744 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1459 | Iter Mean Loss 5.2635
2020-11-05 16:36:41,745 - root - INFO - Evaluate: Epoch 0950 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:36:41,751 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0835 | Iter Mean Loss 8.0835
2020-11-05 16:36:41,756 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9968 | Iter Mean Loss 4.5401
2020-11-05 16:36:41,762 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7123 | Iter Mean Loss 5.5975
2020-11-05 16:36:41,767 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3594 | Iter Mean Loss 5.7880
2020-11-05 16:36:41,773 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1451 | Iter Mean Loss 5.2594
2020-11-05 16:36:41,774 - root - INFO - Evaluate: Epoch 0951 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:36:41,780 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0772 | Iter Mean Loss 8.0772
2020-11-05 16:36:41,785 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9960 | Iter Mean Loss 4.5366
2020-11-05 16:36:41,791 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7042 | Iter Mean Loss 5.5925
2020-11-05 16:36:41,796 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3548 | Iter Mean Loss 5.7831
2020-11-05 16:36:41,801 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1444 | Iter Mean Loss 5.2553
2020-11-05 16:36:41,803 - root - INFO - Evaluate: Epoch 0952 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:36:41,809 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0709 | Iter Mean Loss 8.0709
2020-11-05 16:36:41,815 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9952 | Iter Mean Loss 4.5331
2020-11-05 16:36:41,820 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6961 | Iter Mean Loss 5.5874
2020-11-05 16:36:41,826 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3503 | Iter Mean Loss 5.7781
2020-11-05 16:36:41,831 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1436 | Iter Mean Loss 5.2512
2020-11-05 16:36:41,832 - root - INFO - Evaluate: Epoch 0953 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:36:41,838 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0646 | Iter Mean Loss 8.0646
2020-11-05 16:36:41,844 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9944 | Iter Mean Loss 4.5295
2020-11-05 16:36:41,849 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6880 | Iter Mean Loss 5.5824
2020-11-05 16:36:41,855 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3458 | Iter Mean Loss 5.7732
2020-11-05 16:36:41,859 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1429 | Iter Mean Loss 5.2472
2020-11-05 16:36:41,860 - root - INFO - Evaluate: Epoch 0954 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:36:41,866 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0584 | Iter Mean Loss 8.0584
2020-11-05 16:36:41,871 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9937 | Iter Mean Loss 4.5260
2020-11-05 16:36:41,876 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6800 | Iter Mean Loss 5.5773
2020-11-05 16:36:41,882 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3413 | Iter Mean Loss 5.7683
2020-11-05 16:36:41,887 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1422 | Iter Mean Loss 5.2431
2020-11-05 16:36:41,888 - root - INFO - Evaluate: Epoch 0955 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:36:41,893 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0521 | Iter Mean Loss 8.0521
2020-11-05 16:36:41,899 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9929 | Iter Mean Loss 4.5225
2020-11-05 16:36:41,904 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6719 | Iter Mean Loss 5.5723
2020-11-05 16:36:41,910 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3369 | Iter Mean Loss 5.7634
2020-11-05 16:36:41,914 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1414 | Iter Mean Loss 5.2390
2020-11-05 16:36:41,915 - root - INFO - Evaluate: Epoch 0956 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:36:41,921 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0459 | Iter Mean Loss 8.0459
2020-11-05 16:36:41,926 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9922 | Iter Mean Loss 4.5190
2020-11-05 16:36:41,932 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6638 | Iter Mean Loss 5.5673
2020-11-05 16:36:41,937 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3324 | Iter Mean Loss 5.7586
2020-11-05 16:36:41,942 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1407 | Iter Mean Loss 5.2350
2020-11-05 16:36:41,943 - root - INFO - Evaluate: Epoch 0957 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:36:41,948 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0397 | Iter Mean Loss 8.0397
2020-11-05 16:36:41,954 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9914 | Iter Mean Loss 4.5155
2020-11-05 16:36:41,960 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6558 | Iter Mean Loss 5.5623
2020-11-05 16:36:41,965 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3281 | Iter Mean Loss 5.7537
2020-11-05 16:36:41,971 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1400 | Iter Mean Loss 5.2310
2020-11-05 16:36:41,972 - root - INFO - Evaluate: Epoch 0958 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:36:41,977 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0334 | Iter Mean Loss 8.0334
2020-11-05 16:36:41,983 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9907 | Iter Mean Loss 4.5121
2020-11-05 16:36:41,988 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6478 | Iter Mean Loss 5.5573
2020-11-05 16:36:41,994 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3237 | Iter Mean Loss 5.7489
2020-11-05 16:36:41,999 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1393 | Iter Mean Loss 5.2270
2020-11-05 16:36:42,000 - root - INFO - Evaluate: Epoch 0959 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:36:42,006 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0273 | Iter Mean Loss 8.0273
2020-11-05 16:36:42,012 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9899 | Iter Mean Loss 4.5086
2020-11-05 16:36:42,017 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6398 | Iter Mean Loss 5.5523
2020-11-05 16:36:42,023 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3194 | Iter Mean Loss 5.7441
2020-11-05 16:36:42,028 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1386 | Iter Mean Loss 5.2230
2020-11-05 16:36:42,029 - root - INFO - Evaluate: Epoch 0960 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:36:42,034 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0211 | Iter Mean Loss 8.0211
2020-11-05 16:36:42,040 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9892 | Iter Mean Loss 4.5052
2020-11-05 16:36:42,046 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5474
2020-11-05 16:36:42,051 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3151 | Iter Mean Loss 5.7393
2020-11-05 16:36:42,056 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1379 | Iter Mean Loss 5.2190
2020-11-05 16:36:42,057 - root - INFO - Evaluate: Epoch 0961 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:36:42,062 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0149 | Iter Mean Loss 8.0149
2020-11-05 16:36:42,068 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9885 | Iter Mean Loss 4.5017
2020-11-05 16:36:42,073 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6238 | Iter Mean Loss 5.5424
2020-11-05 16:36:42,079 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3109 | Iter Mean Loss 5.7345
2020-11-05 16:36:42,084 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1372 | Iter Mean Loss 5.2151
2020-11-05 16:36:42,085 - root - INFO - Evaluate: Epoch 0962 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:36:42,090 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0088 | Iter Mean Loss 8.0088
2020-11-05 16:36:42,096 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9878 | Iter Mean Loss 4.4983
2020-11-05 16:36:42,102 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6158 | Iter Mean Loss 5.5375
2020-11-05 16:36:42,107 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3066 | Iter Mean Loss 5.7298
2020-11-05 16:36:42,112 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1365 | Iter Mean Loss 5.2111
2020-11-05 16:36:42,113 - root - INFO - Evaluate: Epoch 0963 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:36:42,118 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0026 | Iter Mean Loss 8.0026
2020-11-05 16:36:42,124 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9871 | Iter Mean Loss 4.4949
2020-11-05 16:36:42,130 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6079 | Iter Mean Loss 5.5325
2020-11-05 16:36:42,135 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3024 | Iter Mean Loss 5.7250
2020-11-05 16:36:42,140 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1358 | Iter Mean Loss 5.2072
2020-11-05 16:36:42,141 - root - INFO - Evaluate: Epoch 0964 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:36:42,147 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9965 | Iter Mean Loss 7.9965
2020-11-05 16:36:42,154 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9864 | Iter Mean Loss 4.4914
2020-11-05 16:36:42,161 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5999 | Iter Mean Loss 5.5276
2020-11-05 16:36:42,167 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2982 | Iter Mean Loss 5.7203
2020-11-05 16:36:42,172 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1351 | Iter Mean Loss 5.2032
2020-11-05 16:36:42,173 - root - INFO - Evaluate: Epoch 0965 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:36:42,179 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9904 | Iter Mean Loss 7.9904
2020-11-05 16:36:42,184 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9857 | Iter Mean Loss 4.4880
2020-11-05 16:36:42,190 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5920 | Iter Mean Loss 5.5227
2020-11-05 16:36:42,197 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 5.7155
2020-11-05 16:36:42,203 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1344 | Iter Mean Loss 5.1993
2020-11-05 16:36:42,204 - root - INFO - Evaluate: Epoch 0966 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:36:42,210 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9842 | Iter Mean Loss 7.9842
2020-11-05 16:36:42,217 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9850 | Iter Mean Loss 4.4846
2020-11-05 16:36:42,225 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5841 | Iter Mean Loss 5.5178
2020-11-05 16:36:42,232 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2899 | Iter Mean Loss 5.7108
2020-11-05 16:36:42,238 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1337 | Iter Mean Loss 5.1954
2020-11-05 16:36:42,239 - root - INFO - Evaluate: Epoch 0967 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:36:42,245 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9781 | Iter Mean Loss 7.9781
2020-11-05 16:36:42,250 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9843 | Iter Mean Loss 4.4812
2020-11-05 16:36:42,256 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5762 | Iter Mean Loss 5.5129
2020-11-05 16:36:42,261 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2858 | Iter Mean Loss 5.7061
2020-11-05 16:36:42,266 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1330 | Iter Mean Loss 5.1915
2020-11-05 16:36:42,267 - root - INFO - Evaluate: Epoch 0968 | NDCG 1.0000 | MSE 0.1689
2020-11-05 16:36:42,273 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9721 | Iter Mean Loss 7.9721
2020-11-05 16:36:42,278 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9836 | Iter Mean Loss 4.4778
2020-11-05 16:36:42,284 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5683 | Iter Mean Loss 5.5080
2020-11-05 16:36:42,291 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2817 | Iter Mean Loss 5.7014
2020-11-05 16:36:42,296 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1323 | Iter Mean Loss 5.1876
2020-11-05 16:36:42,297 - root - INFO - Evaluate: Epoch 0969 | NDCG 1.0000 | MSE 0.1689
2020-11-05 16:36:42,303 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9660 | Iter Mean Loss 7.9660
2020-11-05 16:36:42,309 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9829 | Iter Mean Loss 4.4745
2020-11-05 16:36:42,315 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5604 | Iter Mean Loss 5.5031
2020-11-05 16:36:42,324 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2777 | Iter Mean Loss 5.6968
2020-11-05 16:36:42,331 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1316 | Iter Mean Loss 5.1837
2020-11-05 16:36:42,332 - root - INFO - Evaluate: Epoch 0970 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:36:42,342 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9600 | Iter Mean Loss 7.9600
2020-11-05 16:36:42,350 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9823 | Iter Mean Loss 4.4711
2020-11-05 16:36:42,356 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5525 | Iter Mean Loss 5.4983
2020-11-05 16:36:42,362 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2737 | Iter Mean Loss 5.6921
2020-11-05 16:36:42,367 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1309 | Iter Mean Loss 5.1799
2020-11-05 16:36:42,368 - root - INFO - Evaluate: Epoch 0971 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:36:42,374 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9540 | Iter Mean Loss 7.9540
2020-11-05 16:36:42,385 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9816 | Iter Mean Loss 4.4678
2020-11-05 16:36:42,393 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5446 | Iter Mean Loss 5.4934
2020-11-05 16:36:42,401 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2698 | Iter Mean Loss 5.6875
2020-11-05 16:36:42,407 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1302 | Iter Mean Loss 5.1761
2020-11-05 16:36:42,408 - root - INFO - Evaluate: Epoch 0972 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:36:42,417 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9480 | Iter Mean Loss 7.9480
2020-11-05 16:36:42,424 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9810 | Iter Mean Loss 4.4645
2020-11-05 16:36:42,432 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5368 | Iter Mean Loss 5.4886
2020-11-05 16:36:42,438 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2659 | Iter Mean Loss 5.6829
2020-11-05 16:36:42,444 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1296 | Iter Mean Loss 5.1723
2020-11-05 16:36:42,447 - root - INFO - Evaluate: Epoch 0973 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:36:42,454 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9420 | Iter Mean Loss 7.9420
2020-11-05 16:36:42,461 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9803 | Iter Mean Loss 4.4612
2020-11-05 16:36:42,468 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5289 | Iter Mean Loss 5.4838
2020-11-05 16:36:42,474 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2621 | Iter Mean Loss 5.6783
2020-11-05 16:36:42,480 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1290 | Iter Mean Loss 5.1685
2020-11-05 16:36:42,481 - root - INFO - Evaluate: Epoch 0974 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:36:42,487 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9360 | Iter Mean Loss 7.9360
2020-11-05 16:36:42,493 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9797 | Iter Mean Loss 4.4579
2020-11-05 16:36:42,500 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5211 | Iter Mean Loss 5.4790
2020-11-05 16:36:42,506 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2582 | Iter Mean Loss 5.6738
2020-11-05 16:36:42,512 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1284 | Iter Mean Loss 5.1647
2020-11-05 16:36:42,513 - root - INFO - Evaluate: Epoch 0975 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:36:42,519 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9300 | Iter Mean Loss 7.9300
2020-11-05 16:36:42,526 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9791 | Iter Mean Loss 4.4546
2020-11-05 16:36:42,533 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5134 | Iter Mean Loss 5.4742
2020-11-05 16:36:42,539 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2543 | Iter Mean Loss 5.6692
2020-11-05 16:36:42,545 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1278 | Iter Mean Loss 5.1609
2020-11-05 16:36:42,546 - root - INFO - Evaluate: Epoch 0976 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:36:42,552 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9240 | Iter Mean Loss 7.9240
2020-11-05 16:36:42,558 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9785 | Iter Mean Loss 4.4513
2020-11-05 16:36:42,566 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 5.4694
2020-11-05 16:36:42,572 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2504 | Iter Mean Loss 5.6646
2020-11-05 16:36:42,577 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1273 | Iter Mean Loss 5.1572
2020-11-05 16:36:42,579 - root - INFO - Evaluate: Epoch 0977 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:36:42,585 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9179 | Iter Mean Loss 7.9179
2020-11-05 16:36:42,592 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9779 | Iter Mean Loss 4.4479
2020-11-05 16:36:42,599 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4980 | Iter Mean Loss 5.4646
2020-11-05 16:36:42,605 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2464 | Iter Mean Loss 5.6600
2020-11-05 16:36:42,611 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1267 | Iter Mean Loss 5.1534
2020-11-05 16:36:42,613 - root - INFO - Evaluate: Epoch 0978 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:36:42,619 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9118 | Iter Mean Loss 7.9118
2020-11-05 16:36:42,625 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9772 | Iter Mean Loss 4.4445
2020-11-05 16:36:42,632 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4904 | Iter Mean Loss 5.4598
2020-11-05 16:36:42,638 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2424 | Iter Mean Loss 5.6555
2020-11-05 16:36:42,645 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1261 | Iter Mean Loss 5.1496
2020-11-05 16:36:42,646 - root - INFO - Evaluate: Epoch 0979 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:36:42,652 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9058 | Iter Mean Loss 7.9058
2020-11-05 16:36:42,658 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9764 | Iter Mean Loss 4.4411
2020-11-05 16:36:42,665 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4827 | Iter Mean Loss 5.4550
2020-11-05 16:36:42,671 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2385 | Iter Mean Loss 5.6509
2020-11-05 16:36:42,677 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1253 | Iter Mean Loss 5.1457
2020-11-05 16:36:42,679 - root - INFO - Evaluate: Epoch 0980 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:36:42,686 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8997 | Iter Mean Loss 7.8997
2020-11-05 16:36:42,692 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9757 | Iter Mean Loss 4.4377
2020-11-05 16:36:42,700 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4750 | Iter Mean Loss 5.4501
2020-11-05 16:36:42,706 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2346 | Iter Mean Loss 5.6463
2020-11-05 16:36:42,712 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1245 | Iter Mean Loss 5.1419
2020-11-05 16:36:42,713 - root - INFO - Evaluate: Epoch 0981 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:36:42,720 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8938 | Iter Mean Loss 7.8938
2020-11-05 16:36:42,726 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9750 | Iter Mean Loss 4.4344
2020-11-05 16:36:42,733 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4672 | Iter Mean Loss 5.4453
2020-11-05 16:36:42,739 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2309 | Iter Mean Loss 5.6417
2020-11-05 16:36:42,747 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1236 | Iter Mean Loss 5.1381
2020-11-05 16:36:42,748 - root - INFO - Evaluate: Epoch 0982 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:36:42,754 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8879 | Iter Mean Loss 7.8879
2020-11-05 16:36:42,761 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9743 | Iter Mean Loss 4.4311
2020-11-05 16:36:42,768 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4592 | Iter Mean Loss 5.4405
2020-11-05 16:36:42,774 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2273 | Iter Mean Loss 5.6372
2020-11-05 16:36:42,781 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1226 | Iter Mean Loss 5.1343
2020-11-05 16:36:42,782 - root - INFO - Evaluate: Epoch 0983 | NDCG 1.0000 | MSE 0.1684
2020-11-05 16:36:42,788 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8822 | Iter Mean Loss 7.8822
2020-11-05 16:36:42,796 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9737 | Iter Mean Loss 4.4279
2020-11-05 16:36:42,802 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4513 | Iter Mean Loss 5.4357
2020-11-05 16:36:42,808 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2239 | Iter Mean Loss 5.6328
2020-11-05 16:36:42,815 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1217 | Iter Mean Loss 5.1305
2020-11-05 16:36:42,816 - root - INFO - Evaluate: Epoch 0984 | NDCG 1.0000 | MSE 0.1684
2020-11-05 16:36:42,822 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8768 | Iter Mean Loss 7.8768
2020-11-05 16:36:42,829 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9731 | Iter Mean Loss 4.4250
2020-11-05 16:36:42,836 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4434 | Iter Mean Loss 5.4311
2020-11-05 16:36:42,842 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2208 | Iter Mean Loss 5.6285
2020-11-05 16:36:42,850 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1209 | Iter Mean Loss 5.1270
2020-11-05 16:36:42,851 - root - INFO - Evaluate: Epoch 0985 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:36:42,858 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8718 | Iter Mean Loss 7.8718
2020-11-05 16:36:42,867 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9727 | Iter Mean Loss 4.4223
2020-11-05 16:36:42,875 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4355 | Iter Mean Loss 5.4267
2020-11-05 16:36:42,883 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2181 | Iter Mean Loss 5.6245
2020-11-05 16:36:42,889 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1202 | Iter Mean Loss 5.1237
2020-11-05 16:36:42,890 - root - INFO - Evaluate: Epoch 0986 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:42,897 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8669 | Iter Mean Loss 7.8669
2020-11-05 16:36:42,903 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9726 | Iter Mean Loss 4.4197
2020-11-05 16:36:42,910 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4277 | Iter Mean Loss 5.4224
2020-11-05 16:36:42,919 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2157 | Iter Mean Loss 5.6207
2020-11-05 16:36:42,924 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1199 | Iter Mean Loss 5.1206
2020-11-05 16:36:42,926 - root - INFO - Evaluate: Epoch 0987 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:42,933 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8616 | Iter Mean Loss 7.8616
2020-11-05 16:36:42,939 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9728 | Iter Mean Loss 4.4172
2020-11-05 16:36:42,946 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4199 | Iter Mean Loss 5.4181
2020-11-05 16:36:42,952 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.6168
2020-11-05 16:36:42,957 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1201 | Iter Mean Loss 5.1175
2020-11-05 16:36:42,958 - root - INFO - Evaluate: Epoch 0988 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:42,964 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8554 | Iter Mean Loss 7.8554
2020-11-05 16:36:42,970 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9731 | Iter Mean Loss 4.4143
2020-11-05 16:36:42,976 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4124 | Iter Mean Loss 5.4137
2020-11-05 16:36:42,983 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2096 | Iter Mean Loss 5.6127
2020-11-05 16:36:42,988 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1209 | Iter Mean Loss 5.1143
2020-11-05 16:36:42,989 - root - INFO - Evaluate: Epoch 0989 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:42,995 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8484 | Iter Mean Loss 7.8484
2020-11-05 16:36:43,000 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9733 | Iter Mean Loss 4.4108
2020-11-05 16:36:43,006 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4059 | Iter Mean Loss 5.4092
2020-11-05 16:36:43,012 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2049 | Iter Mean Loss 5.6081
2020-11-05 16:36:43,018 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1222 | Iter Mean Loss 5.1109
2020-11-05 16:36:43,019 - root - INFO - Evaluate: Epoch 0990 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:43,025 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8416 | Iter Mean Loss 7.8416
2020-11-05 16:36:43,031 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9725 | Iter Mean Loss 4.4071
2020-11-05 16:36:43,037 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4012 | Iter Mean Loss 5.4051
2020-11-05 16:36:43,044 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 5.6036
2020-11-05 16:36:43,049 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1235 | Iter Mean Loss 5.1076
2020-11-05 16:36:43,050 - root - INFO - Evaluate: Epoch 0991 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:43,057 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8367 | Iter Mean Loss 7.8367
2020-11-05 16:36:43,063 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9708 | Iter Mean Loss 4.4038
2020-11-05 16:36:43,068 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3981 | Iter Mean Loss 5.4019
2020-11-05 16:36:43,074 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1944 | Iter Mean Loss 5.6000
2020-11-05 16:36:43,079 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1237 | Iter Mean Loss 5.1047
2020-11-05 16:36:43,080 - root - INFO - Evaluate: Epoch 0992 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:36:43,086 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8348 | Iter Mean Loss 7.8348
2020-11-05 16:36:43,091 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9688 | Iter Mean Loss 4.4018
2020-11-05 16:36:43,097 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3949 | Iter Mean Loss 5.3995
2020-11-05 16:36:43,102 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1928 | Iter Mean Loss 5.5978
2020-11-05 16:36:43,107 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1218 | Iter Mean Loss 5.1026
2020-11-05 16:36:43,108 - root - INFO - Evaluate: Epoch 0993 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:36:43,114 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8340 | Iter Mean Loss 7.8340
2020-11-05 16:36:43,119 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9684 | Iter Mean Loss 4.4012
2020-11-05 16:36:43,125 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3881 | Iter Mean Loss 5.3968
2020-11-05 16:36:43,131 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1950 | Iter Mean Loss 5.5964
2020-11-05 16:36:43,136 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1181 | Iter Mean Loss 5.1007
2020-11-05 16:36:43,136 - root - INFO - Evaluate: Epoch 0994 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:36:43,142 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8294 | Iter Mean Loss 7.8294
2020-11-05 16:36:43,148 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9713 | Iter Mean Loss 4.4004
2020-11-05 16:36:43,154 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3759 | Iter Mean Loss 5.3922
2020-11-05 16:36:43,159 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1973 | Iter Mean Loss 5.5935
2020-11-05 16:36:43,165 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1151 | Iter Mean Loss 5.0978
2020-11-05 16:36:43,166 - root - INFO - Evaluate: Epoch 0995 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:36:43,172 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8177 | Iter Mean Loss 7.8177
2020-11-05 16:36:43,178 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9766 | Iter Mean Loss 4.3971
2020-11-05 16:36:43,183 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3625 | Iter Mean Loss 5.3856
2020-11-05 16:36:43,189 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1935 | Iter Mean Loss 5.5876
2020-11-05 16:36:43,194 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1161 | Iter Mean Loss 5.0933
2020-11-05 16:36:43,195 - root - INFO - Evaluate: Epoch 0996 | NDCG 1.0000 | MSE 0.1680
2020-11-05 16:36:43,200 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8062 | Iter Mean Loss 7.8062
2020-11-05 16:36:43,206 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9791 | Iter Mean Loss 4.3927
2020-11-05 16:36:43,213 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3595 | Iter Mean Loss 5.3816
2020-11-05 16:36:43,219 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 5.5820
2020-11-05 16:36:43,224 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1215 | Iter Mean Loss 5.0899
2020-11-05 16:36:43,225 - root - INFO - Evaluate: Epoch 0997 | NDCG 1.0000 | MSE 0.1677
2020-11-05 16:36:43,230 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8169 | Iter Mean Loss 7.8169
2020-11-05 16:36:43,236 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9740 | Iter Mean Loss 4.3954
2020-11-05 16:36:43,242 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 5.3893
2020-11-05 16:36:43,247 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1819 | Iter Mean Loss 5.5875
2020-11-05 16:36:43,252 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1257 | Iter Mean Loss 5.0951
2020-11-05 16:36:43,253 - root - INFO - Evaluate: Epoch 0998 | NDCG 1.0000 | MSE 0.1675
2020-11-05 16:36:43,259 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8720 | Iter Mean Loss 7.8720
2020-11-05 16:36:43,264 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9659 | Iter Mean Loss 4.4190
2020-11-05 16:36:43,270 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4073 | Iter Mean Loss 5.4151
2020-11-05 16:36:43,275 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2211 | Iter Mean Loss 5.6166
2020-11-05 16:36:43,280 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1193 | Iter Mean Loss 5.1171
2020-11-05 16:36:43,281 - root - INFO - Evaluate: Epoch 0999 | NDCG 1.0000 | MSE 0.1673
2020-11-05 16:36:43,281 - root - INFO - [!]-----------training done.
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,315 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,316 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,317 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,318 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,319 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,320 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,321 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,322 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,323 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,324 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,325 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,326 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,327 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,328 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,329 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,330 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,331 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,332 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,333 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,334 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,335 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,336 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,337 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,338 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,339 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,340 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,341 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,342 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,343 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,344 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,345 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,346 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:36:43,347 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 16:36:43,500 - root - INFO - [!]-----------start testing.
2020-11-05 16:36:43,501 - root - INFO - Real Rank:
2020-11-05 16:36:43,501 - root - INFO - [0]
2020-11-05 16:36:43,502 - root - INFO - Pred Rank:
2020-11-05 16:36:43,502 - root - INFO - [ 0 74]
2020-11-05 16:36:43,502 - root - INFO - Test Result: NDCG 1.0000 | MSE 0.1673
