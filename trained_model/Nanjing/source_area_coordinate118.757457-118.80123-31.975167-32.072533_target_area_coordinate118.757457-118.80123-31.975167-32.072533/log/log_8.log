2020-11-05 16:37:47,078 - root - INFO - Namespace(K=10, O1_print_every=1, O2_print_every=1, O3_print_every=1, O4_print_every=1, auto_encoder_dim=9, batch_size=32, circle_size=500, city_name='Nanjing', data_dir='datasets/', enterprise=['大众书局', '西西弗书店'], eps=1e-09, evaluate_every=1, gamma=8, grid_size_latitude_degree=0.005, grid_size_longitude_degree=0.005, lambda_1=1, lambda_2=0.5, lambda_3=0.5, lambda_4=0.025, lr=0.001, mess_dropout=0.1, n_epoch=1000, print_every=1, save_dir='trained_model/Nanjing/source_area_coordinate118.757457-118.80123-31.975167-32.072533_target_area_coordinate118.757457-118.80123-31.975167-32.072533/', score_norm_max=400, seed=981125, source_area_coordinate=[118.757457, 118.80123, 31.975167, 32.072533], stopping_steps=10, target_area_coordinate=[118.730506, 118.757457, 31.975167, 32.072533], target_enterprise='西西弗书店')
2020-11-05 16:37:47,078 - root - INFO - --------------parse args and init done.
2020-11-05 16:37:48,887 - root - INFO - [1 /10]       load dianping data done.
2020-11-05 16:37:48,900 - root - INFO - [2 /10]       check enterprise and get small category set.
2020-11-05 16:37:48,900 - root - INFO - n_source_grid: 152, n_target_grid: 95
2020-11-05 16:37:48,900 - root - INFO - [3 /10]       split grid done.
2020-11-05 16:37:49,742 - root - INFO - [4 /10]       distribute data into grids done.
2020-11-05 16:37:49,745 - root - INFO - [5 /10]       generate rating matrix for Transfer Rating Prediction Model done.
2020-11-05 16:37:49,803 - root - INFO - [6 /10]       extract geographic features done.
2020-11-05 16:37:49,877 - root - INFO - [7 /10]       extract commercial features done.
2020-11-05 16:37:49,877 - root - INFO - [8 /10]       combine features done.
2020-11-05 16:37:49,925 - root - INFO - [9 /10]       get PCCS and generate delta set done.
2020-11-05 16:37:49,925 - root - INFO - [10/10]       generate training and testing index done.
2020-11-05 16:37:49,961 - root - INFO - --------------load data done.
2020-11-05 16:37:49,962 - root - INFO - CityTransfer(
  (auto_encoder): ModuleList(
    (0): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
    (1): AutoEncoder(
      (encoder): Sequential(
        (0): Linear(in_features=21, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=9, bias=True)
      )
      (decoder): Sequential(
        (0): Linear(in_features=9, out_features=14, bias=True)
        (1): Tanh()
        (2): Linear(in_features=14, out_features=21, bias=True)
      )
    )
  )
)
2020-11-05 16:37:49,962 - root - INFO - --------------construct model and optimizer done.
2020-11-05 16:37:49,962 - root - INFO - --------------initialize metrics done.
2020-11-05 16:37:49,962 - root - INFO - [!]-----------start training.
2020-11-05 16:37:49,969 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 643.9380 | Iter Mean Loss 643.9380
2020-11-05 16:37:49,975 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 554.1745 | Iter Mean Loss 599.0563
2020-11-05 16:37:49,980 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 579.2756 | Iter Mean Loss 592.4627
2020-11-05 16:37:49,986 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 532.0728 | Iter Mean Loss 577.3652
2020-11-05 16:37:49,990 - root - INFO - Training: Epoch 0000 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 241.1393 | Iter Mean Loss 510.1201
2020-11-05 16:37:49,992 - root - INFO - Evaluate: Epoch 0000 | NDCG 0.0000 | MSE 0.7708
2020-11-05 16:37:49,998 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 511.6739 | Iter Mean Loss 511.6739
2020-11-05 16:37:50,003 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 431.3048 | Iter Mean Loss 471.4893
2020-11-05 16:37:50,009 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 463.4146 | Iter Mean Loss 468.7978
2020-11-05 16:37:50,014 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 419.4186 | Iter Mean Loss 456.4530
2020-11-05 16:37:50,019 - root - INFO - Training: Epoch 0001 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 182.3454 | Iter Mean Loss 401.6315
2020-11-05 16:37:50,020 - root - INFO - Evaluate: Epoch 0001 | NDCG 0.0000 | MSE 0.7723
2020-11-05 16:37:50,025 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 410.9805 | Iter Mean Loss 410.9805
2020-11-05 16:37:50,031 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 337.3170 | Iter Mean Loss 374.1487
2020-11-05 16:37:50,036 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 374.8981 | Iter Mean Loss 374.3985
2020-11-05 16:37:50,042 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 334.1434 | Iter Mean Loss 364.3347
2020-11-05 16:37:50,047 - root - INFO - Training: Epoch 0002 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 138.3126 | Iter Mean Loss 319.1303
2020-11-05 16:37:50,048 - root - INFO - Evaluate: Epoch 0002 | NDCG 0.0000 | MSE 0.7636
2020-11-05 16:37:50,053 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 334.9843 | Iter Mean Loss 334.9843
2020-11-05 16:37:50,059 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 266.4191 | Iter Mean Loss 300.7017
2020-11-05 16:37:50,064 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 308.5126 | Iter Mean Loss 303.3053
2020-11-05 16:37:50,069 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 271.0077 | Iter Mean Loss 295.2309
2020-11-05 16:37:50,074 - root - INFO - Training: Epoch 0003 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 106.2549 | Iter Mean Loss 257.4357
2020-11-05 16:37:50,075 - root - INFO - Evaluate: Epoch 0003 | NDCG 0.0000 | MSE 0.7419
2020-11-05 16:37:50,080 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 279.1161 | Iter Mean Loss 279.1161
2020-11-05 16:37:50,086 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 214.3517 | Iter Mean Loss 246.7339
2020-11-05 16:37:50,091 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 260.0327 | Iter Mean Loss 251.1668
2020-11-05 16:37:50,097 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 225.4976 | Iter Mean Loss 244.7495
2020-11-05 16:37:50,102 - root - INFO - Training: Epoch 0004 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 83.6608 | Iter Mean Loss 212.5318
2020-11-05 16:37:50,103 - root - INFO - Evaluate: Epoch 0004 | NDCG 0.0000 | MSE 0.7064
2020-11-05 16:37:50,108 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 239.1345 | Iter Mean Loss 239.1345
2020-11-05 16:37:50,114 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 177.0773 | Iter Mean Loss 208.1059
2020-11-05 16:37:50,119 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 225.4448 | Iter Mean Loss 213.8855
2020-11-05 16:37:50,125 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 193.4189 | Iter Mean Loss 208.7689
2020-11-05 16:37:50,130 - root - INFO - Training: Epoch 0005 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 68.1921 | Iter Mean Loss 180.6535
2020-11-05 16:37:50,131 - root - INFO - Evaluate: Epoch 0005 | NDCG 0.0000 | MSE 0.6605
2020-11-05 16:37:50,137 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 211.0698 | Iter Mean Loss 211.0698
2020-11-05 16:37:50,142 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 150.8522 | Iter Mean Loss 180.9610
2020-11-05 16:37:50,147 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 201.0768 | Iter Mean Loss 187.6662
2020-11-05 16:37:50,153 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 171.0199 | Iter Mean Loss 183.5047
2020-11-05 16:37:50,157 - root - INFO - Training: Epoch 0006 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 57.7462 | Iter Mean Loss 158.3530
2020-11-05 16:37:50,158 - root - INFO - Evaluate: Epoch 0006 | NDCG 0.0000 | MSE 0.6101
2020-11-05 16:37:50,164 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 191.3755 | Iter Mean Loss 191.3755
2020-11-05 16:37:50,169 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 132.3766 | Iter Mean Loss 161.8760
2020-11-05 16:37:50,175 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 183.7166 | Iter Mean Loss 169.1562
2020-11-05 16:37:50,181 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 155.0656 | Iter Mean Loss 165.6336
2020-11-05 16:37:50,185 - root - INFO - Training: Epoch 0007 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 50.5262 | Iter Mean Loss 142.6121
2020-11-05 16:37:50,186 - root - INFO - Evaluate: Epoch 0007 | NDCG 0.0000 | MSE 0.5603
2020-11-05 16:37:50,192 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 177.0382 | Iter Mean Loss 177.0382
2020-11-05 16:37:50,198 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 118.8886 | Iter Mean Loss 147.9634
2020-11-05 16:37:50,203 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 170.7194 | Iter Mean Loss 155.5487
2020-11-05 16:37:50,209 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 142.9588 | Iter Mean Loss 152.4012
2020-11-05 16:37:50,214 - root - INFO - Training: Epoch 0008 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 45.1404 | Iter Mean Loss 130.9491
2020-11-05 16:37:50,215 - root - INFO - Evaluate: Epoch 0008 | NDCG 0.0000 | MSE 0.5136
2020-11-05 16:37:50,221 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 165.7476 | Iter Mean Loss 165.7476
2020-11-05 16:37:50,226 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 108.3027 | Iter Mean Loss 137.0251
2020-11-05 16:37:50,232 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 160.1558 | Iter Mean Loss 144.7353
2020-11-05 16:37:50,238 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 132.8874 | Iter Mean Loss 141.7734
2020-11-05 16:37:50,242 - root - INFO - Training: Epoch 0009 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 40.6723 | Iter Mean Loss 121.5531
2020-11-05 16:37:50,243 - root - INFO - Evaluate: Epoch 0009 | NDCG 0.0000 | MSE 0.4711
2020-11-05 16:37:50,250 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 156.0084 | Iter Mean Loss 156.0084
2020-11-05 16:37:50,255 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 99.2784 | Iter Mean Loss 127.6434
2020-11-05 16:37:50,260 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 150.8555 | Iter Mean Loss 135.3808
2020-11-05 16:37:50,266 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 123.8219 | Iter Mean Loss 132.4910
2020-11-05 16:37:50,270 - root - INFO - Training: Epoch 0010 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 36.6481 | Iter Mean Loss 113.3225
2020-11-05 16:37:50,271 - root - INFO - Evaluate: Epoch 0010 | NDCG 0.0000 | MSE 0.4333
2020-11-05 16:37:50,277 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 147.0691 | Iter Mean Loss 147.0691
2020-11-05 16:37:50,282 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 91.1313 | Iter Mean Loss 119.1002
2020-11-05 16:37:50,287 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 142.2802 | Iter Mean Loss 126.8269
2020-11-05 16:37:50,293 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 115.3421 | Iter Mean Loss 123.9557
2020-11-05 16:37:50,297 - root - INFO - Training: Epoch 0011 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 32.9139 | Iter Mean Loss 105.7473
2020-11-05 16:37:50,298 - root - INFO - Evaluate: Epoch 0011 | NDCG 0.0000 | MSE 0.4003
2020-11-05 16:37:50,304 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 138.6974 | Iter Mean Loss 138.6974
2020-11-05 16:37:50,309 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 83.6236 | Iter Mean Loss 111.1605
2020-11-05 16:37:50,315 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 134.2894 | Iter Mean Loss 118.8701
2020-11-05 16:37:50,322 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 107.3825 | Iter Mean Loss 115.9982
2020-11-05 16:37:50,327 - root - INFO - Training: Epoch 0012 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 29.4813 | Iter Mean Loss 98.6949
2020-11-05 16:37:50,328 - root - INFO - Evaluate: Epoch 0012 | NDCG 0.0000 | MSE 0.3717
2020-11-05 16:37:50,333 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 130.9130 | Iter Mean Loss 130.9130
2020-11-05 16:37:50,338 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 76.7316 | Iter Mean Loss 103.8223
2020-11-05 16:37:50,344 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 126.9098 | Iter Mean Loss 111.5181
2020-11-05 16:37:50,349 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 100.0092 | Iter Mean Loss 108.6409
2020-11-05 16:37:50,354 - root - INFO - Training: Epoch 0013 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 26.4081 | Iter Mean Loss 92.1943
2020-11-05 16:37:50,355 - root - INFO - Evaluate: Epoch 0013 | NDCG 0.0000 | MSE 0.3468
2020-11-05 16:37:50,360 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 123.7932 | Iter Mean Loss 123.7932
2020-11-05 16:37:50,366 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 70.4852 | Iter Mean Loss 97.1392
2020-11-05 16:37:50,371 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 120.1906 | Iter Mean Loss 104.8230
2020-11-05 16:37:50,377 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 93.2886 | Iter Mean Loss 101.9394
2020-11-05 16:37:50,382 - root - INFO - Training: Epoch 0014 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 23.7358 | Iter Mean Loss 86.2987
2020-11-05 16:37:50,383 - root - INFO - Evaluate: Epoch 0014 | NDCG 0.0000 | MSE 0.3250
2020-11-05 16:37:50,388 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 117.3771 | Iter Mean Loss 117.3771
2020-11-05 16:37:50,394 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 64.8879 | Iter Mean Loss 91.1325
2020-11-05 16:37:50,400 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 114.1380 | Iter Mean Loss 98.8010
2020-11-05 16:37:50,406 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 87.2338 | Iter Mean Loss 95.9092
2020-11-05 16:37:50,411 - root - INFO - Training: Epoch 0015 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 21.4668 | Iter Mean Loss 81.0207
2020-11-05 16:37:50,411 - root - INFO - Evaluate: Epoch 0015 | NDCG 0.0000 | MSE 0.3059
2020-11-05 16:37:50,418 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 111.6401 | Iter Mean Loss 111.6401
2020-11-05 16:37:50,424 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 59.8938 | Iter Mean Loss 85.7670
2020-11-05 16:37:50,429 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 108.7037 | Iter Mean Loss 93.4126
2020-11-05 16:37:50,435 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 81.8012 | Iter Mean Loss 90.5097
2020-11-05 16:37:50,440 - root - INFO - Training: Epoch 0016 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 19.5673 | Iter Mean Loss 76.3212
2020-11-05 16:37:50,441 - root - INFO - Evaluate: Epoch 0016 | NDCG 0.0000 | MSE 0.2894
2020-11-05 16:37:50,447 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 106.5119 | Iter Mean Loss 106.5119
2020-11-05 16:37:50,453 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 55.4229 | Iter Mean Loss 80.9674
2020-11-05 16:37:50,459 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 103.8075 | Iter Mean Loss 88.5808
2020-11-05 16:37:50,465 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 76.9157 | Iter Mean Loss 85.6645
2020-11-05 16:37:50,470 - root - INFO - Training: Epoch 0017 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 17.9821 | Iter Mean Loss 72.1280
2020-11-05 16:37:50,471 - root - INFO - Evaluate: Epoch 0017 | NDCG 0.0000 | MSE 0.2754
2020-11-05 16:37:50,477 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 101.9071 | Iter Mean Loss 101.9071
2020-11-05 16:37:50,482 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 51.3878 | Iter Mean Loss 76.6475
2020-11-05 16:37:50,487 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 99.3647 | Iter Mean Loss 84.2199
2020-11-05 16:37:50,493 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 72.4984 | Iter Mean Loss 81.2895
2020-11-05 16:37:50,497 - root - INFO - Training: Epoch 0018 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 16.6518 | Iter Mean Loss 68.3620
2020-11-05 16:37:50,498 - root - INFO - Evaluate: Epoch 0018 | NDCG 0.0000 | MSE 0.2639
2020-11-05 16:37:50,504 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 97.7487 | Iter Mean Loss 97.7487
2020-11-05 16:37:50,509 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 47.7147 | Iter Mean Loss 72.7317
2020-11-05 16:37:50,514 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 95.3059 | Iter Mean Loss 80.2564
2020-11-05 16:37:50,520 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 68.4840 | Iter Mean Loss 77.3133
2020-11-05 16:37:50,524 - root - INFO - Training: Epoch 0019 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 15.5229 | Iter Mean Loss 64.9552
2020-11-05 16:37:50,525 - root - INFO - Evaluate: Epoch 0019 | NDCG 0.0000 | MSE 0.2548
2020-11-05 16:37:50,531 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 93.9776 | Iter Mean Loss 93.9776
2020-11-05 16:37:50,536 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 44.3514 | Iter Mean Loss 69.1645
2020-11-05 16:37:50,541 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 91.5825 | Iter Mean Loss 76.6371
2020-11-05 16:37:50,547 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 64.8261 | Iter Mean Loss 73.6844
2020-11-05 16:37:50,551 - root - INFO - Training: Epoch 0020 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 14.5525 | Iter Mean Loss 61.8580
2020-11-05 16:37:50,552 - root - INFO - Evaluate: Epoch 0020 | NDCG 0.0000 | MSE 0.2477
2020-11-05 16:37:50,558 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 90.5528 | Iter Mean Loss 90.5528
2020-11-05 16:37:50,563 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 41.2657 | Iter Mean Loss 65.9093
2020-11-05 16:37:50,568 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 88.1655 | Iter Mean Loss 73.3280
2020-11-05 16:37:50,574 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 61.4953 | Iter Mean Loss 70.3699
2020-11-05 16:37:50,579 - root - INFO - Training: Epoch 0021 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 13.7088 | Iter Mean Loss 59.0376
2020-11-05 16:37:50,580 - root - INFO - Evaluate: Epoch 0021 | NDCG 0.0000 | MSE 0.2424
2020-11-05 16:37:50,586 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 87.4472 | Iter Mean Loss 87.4472
2020-11-05 16:37:50,591 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 38.4413 | Iter Mean Loss 62.9443
2020-11-05 16:37:50,597 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 85.0399 | Iter Mean Loss 70.3095
2020-11-05 16:37:50,603 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 58.4751 | Iter Mean Loss 67.3509
2020-11-05 16:37:50,608 - root - INFO - Training: Epoch 0022 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.9689 | Iter Mean Loss 56.4745
2020-11-05 16:37:50,609 - root - INFO - Evaluate: Epoch 0022 | NDCG 0.0000 | MSE 0.2384
2020-11-05 16:37:50,615 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 84.6424 | Iter Mean Loss 84.6424
2020-11-05 16:37:50,621 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 35.8719 | Iter Mean Loss 60.2571
2020-11-05 16:37:50,627 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 82.1986 | Iter Mean Loss 67.5710
2020-11-05 16:37:50,633 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 55.7555 | Iter Mean Loss 64.6171
2020-11-05 16:37:50,638 - root - INFO - Training: Epoch 0023 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 12.3177 | Iter Mean Loss 54.1572
2020-11-05 16:37:50,639 - root - INFO - Evaluate: Epoch 0023 | NDCG 0.0000 | MSE 0.2356
2020-11-05 16:37:50,644 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 82.1243 | Iter Mean Loss 82.1243
2020-11-05 16:37:50,650 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 33.5564 | Iter Mean Loss 57.8403
2020-11-05 16:37:50,656 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 79.6385 | Iter Mean Loss 65.1064
2020-11-05 16:37:50,661 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 53.3303 | Iter Mean Loss 62.1624
2020-11-05 16:37:50,666 - root - INFO - Training: Epoch 0024 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.7450 | Iter Mean Loss 52.0789
2020-11-05 16:37:50,668 - root - INFO - Evaluate: Epoch 0024 | NDCG 0.0000 | MSE 0.2336
2020-11-05 16:37:50,673 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 79.8810 | Iter Mean Loss 79.8810
2020-11-05 16:37:50,679 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 31.4944 | Iter Mean Loss 55.6877
2020-11-05 16:37:50,684 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 77.3565 | Iter Mean Loss 62.9106
2020-11-05 16:37:50,689 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 51.1936 | Iter Mean Loss 59.9814
2020-11-05 16:37:50,694 - root - INFO - Training: Epoch 0025 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 11.2443 | Iter Mean Loss 50.2340
2020-11-05 16:37:50,695 - root - INFO - Evaluate: Epoch 0025 | NDCG 0.0000 | MSE 0.2323
2020-11-05 16:37:50,700 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 77.9003 | Iter Mean Loss 77.9003
2020-11-05 16:37:50,705 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 29.6825 | Iter Mean Loss 53.7914
2020-11-05 16:37:50,711 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 75.3467 | Iter Mean Loss 60.9765
2020-11-05 16:37:50,716 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 49.3369 | Iter Mean Loss 58.0666
2020-11-05 16:37:50,721 - root - INFO - Training: Epoch 0026 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.8107 | Iter Mean Loss 48.6154
2020-11-05 16:37:50,721 - root - INFO - Evaluate: Epoch 0026 | NDCG 0.0000 | MSE 0.2314
2020-11-05 16:37:50,727 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 76.1683 | Iter Mean Loss 76.1683
2020-11-05 16:37:50,732 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 28.1123 | Iter Mean Loss 52.1403
2020-11-05 16:37:50,738 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 73.5987 | Iter Mean Loss 59.2931
2020-11-05 16:37:50,743 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 47.7475 | Iter Mean Loss 56.4067
2020-11-05 16:37:50,748 - root - INFO - Training: Epoch 0027 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.4397 | Iter Mean Loss 47.2133
2020-11-05 16:37:50,749 - root - INFO - Evaluate: Epoch 0027 | NDCG 0.0000 | MSE 0.2309
2020-11-05 16:37:50,754 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 74.6678 | Iter Mean Loss 74.6678
2020-11-05 16:37:50,759 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 26.7700 | Iter Mean Loss 50.7189
2020-11-05 16:37:50,765 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 72.0968 | Iter Mean Loss 57.8449
2020-11-05 16:37:50,770 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 46.4071 | Iter Mean Loss 54.9854
2020-11-05 16:37:50,775 - root - INFO - Training: Epoch 0028 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 10.1260 | Iter Mean Loss 46.0135
2020-11-05 16:37:50,776 - root - INFO - Evaluate: Epoch 0028 | NDCG 0.0000 | MSE 0.2306
2020-11-05 16:37:50,782 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 73.3779 | Iter Mean Loss 73.3779
2020-11-05 16:37:50,787 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 25.6369 | Iter Mean Loss 49.5074
2020-11-05 16:37:50,793 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 70.8200 | Iter Mean Loss 56.6116
2020-11-05 16:37:50,799 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 45.2932 | Iter Mean Loss 53.7820
2020-11-05 16:37:50,804 - root - INFO - Training: Epoch 0029 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.8639 | Iter Mean Loss 44.9984
2020-11-05 16:37:50,805 - root - INFO - Evaluate: Epoch 0029 | NDCG 0.0000 | MSE 0.2303
2020-11-05 16:37:50,810 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 72.2743 | Iter Mean Loss 72.2743
2020-11-05 16:37:50,817 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 24.6904 | Iter Mean Loss 48.4823
2020-11-05 16:37:50,822 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 69.7432 | Iter Mean Loss 55.5693
2020-11-05 16:37:50,827 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 44.3797 | Iter Mean Loss 52.7719
2020-11-05 16:37:50,833 - root - INFO - Training: Epoch 0030 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.6470 | Iter Mean Loss 44.1469
2020-11-05 16:37:50,834 - root - INFO - Evaluate: Epoch 0030 | NDCG 0.0000 | MSE 0.2302
2020-11-05 16:37:50,839 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 71.3311 | Iter Mean Loss 71.3311
2020-11-05 16:37:50,845 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.9057 | Iter Mean Loss 47.6184
2020-11-05 16:37:50,851 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 68.8392 | Iter Mean Loss 54.6920
2020-11-05 16:37:50,856 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.6388 | Iter Mean Loss 51.9287
2020-11-05 16:37:50,861 - root - INFO - Training: Epoch 0031 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.4683 | Iter Mean Loss 43.4366
2020-11-05 16:37:50,862 - root - INFO - Evaluate: Epoch 0031 | NDCG 0.0000 | MSE 0.2300
2020-11-05 16:37:50,867 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 70.5221 | Iter Mean Loss 70.5221
2020-11-05 16:37:50,873 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 23.2580 | Iter Mean Loss 46.8900
2020-11-05 16:37:50,879 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 68.0805 | Iter Mean Loss 53.9535
2020-11-05 16:37:50,884 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 43.0420 | Iter Mean Loss 51.2256
2020-11-05 16:37:50,889 - root - INFO - Training: Epoch 0032 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.3212 | Iter Mean Loss 42.8447
2020-11-05 16:37:50,889 - root - INFO - Evaluate: Epoch 0032 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:50,895 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 69.8223 | Iter Mean Loss 69.8223
2020-11-05 16:37:50,900 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.7232 | Iter Mean Loss 46.2727
2020-11-05 16:37:50,906 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 67.4406 | Iter Mean Loss 53.3287
2020-11-05 16:37:50,911 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.5622 | Iter Mean Loss 50.6371
2020-11-05 16:37:50,916 - root - INFO - Training: Epoch 0033 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.1993 | Iter Mean Loss 42.3495
2020-11-05 16:37:50,917 - root - INFO - Evaluate: Epoch 0033 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:50,922 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 69.2097 | Iter Mean Loss 69.2097
2020-11-05 16:37:50,927 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 22.2793 | Iter Mean Loss 45.7445
2020-11-05 16:37:50,932 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.8954 | Iter Mean Loss 52.7948
2020-11-05 16:37:50,938 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 42.1749 | Iter Mean Loss 50.1398
2020-11-05 16:37:50,942 - root - INFO - Training: Epoch 0034 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0968 | Iter Mean Loss 41.9312
2020-11-05 16:37:50,943 - root - INFO - Evaluate: Epoch 0034 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:50,949 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.6652 | Iter Mean Loss 68.6652
2020-11-05 16:37:50,954 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.9074 | Iter Mean Loss 45.2863
2020-11-05 16:37:50,959 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.4241 | Iter Mean Loss 52.3322
2020-11-05 16:37:50,964 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.8588 | Iter Mean Loss 49.7139
2020-11-05 16:37:50,969 - root - INFO - Training: Epoch 0035 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 9.0091 | Iter Mean Loss 41.5729
2020-11-05 16:37:50,970 - root - INFO - Evaluate: Epoch 0035 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:50,975 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 68.1731 | Iter Mean Loss 68.1731
2020-11-05 16:37:50,981 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.5916 | Iter Mean Loss 44.8824
2020-11-05 16:37:50,987 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 66.0090 | Iter Mean Loss 51.9246
2020-11-05 16:37:50,992 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.5962 | Iter Mean Loss 49.3425
2020-11-05 16:37:50,997 - root - INFO - Training: Epoch 0036 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.9322 | Iter Mean Loss 41.2604
2020-11-05 16:37:50,998 - root - INFO - Evaluate: Epoch 0036 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,004 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 67.7211 | Iter Mean Loss 67.7211
2020-11-05 16:37:51,010 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.3194 | Iter Mean Loss 44.5203
2020-11-05 16:37:51,015 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 65.6359 | Iter Mean Loss 51.5588
2020-11-05 16:37:51,021 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.3730 | Iter Mean Loss 49.0124
2020-11-05 16:37:51,026 - root - INFO - Training: Epoch 0037 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.8631 | Iter Mean Loss 40.9825
2020-11-05 16:37:51,027 - root - INFO - Evaluate: Epoch 0037 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:37:51,033 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 67.2996 | Iter Mean Loss 67.2996
2020-11-05 16:37:51,039 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 21.0812 | Iter Mean Loss 44.1904
2020-11-05 16:37:51,044 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 65.2934 | Iter Mean Loss 51.2248
2020-11-05 16:37:51,050 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.1782 | Iter Mean Loss 48.7131
2020-11-05 16:37:51,055 - root - INFO - Training: Epoch 0038 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7994 | Iter Mean Loss 40.7304
2020-11-05 16:37:51,056 - root - INFO - Evaluate: Epoch 0038 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:37:51,062 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.9013 | Iter Mean Loss 66.9013
2020-11-05 16:37:51,067 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.8694 | Iter Mean Loss 43.8854
2020-11-05 16:37:51,073 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.9730 | Iter Mean Loss 50.9146
2020-11-05 16:37:51,079 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 41.0034 | Iter Mean Loss 48.4368
2020-11-05 16:37:51,083 - root - INFO - Training: Epoch 0039 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.7396 | Iter Mean Loss 40.4973
2020-11-05 16:37:51,084 - root - INFO - Evaluate: Epoch 0039 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:37:51,090 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.5208 | Iter Mean Loss 66.5208
2020-11-05 16:37:51,095 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.6784 | Iter Mean Loss 43.5996
2020-11-05 16:37:51,101 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.6680 | Iter Mean Loss 50.6224
2020-11-05 16:37:51,106 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.8423 | Iter Mean Loss 48.1774
2020-11-05 16:37:51,111 - root - INFO - Training: Epoch 0040 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6824 | Iter Mean Loss 40.2784
2020-11-05 16:37:51,112 - root - INFO - Evaluate: Epoch 0040 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,118 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 66.1540 | Iter Mean Loss 66.1540
2020-11-05 16:37:51,123 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.5038 | Iter Mean Loss 43.3289
2020-11-05 16:37:51,129 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.3734 | Iter Mean Loss 50.3438
2020-11-05 16:37:51,134 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.6906 | Iter Mean Loss 47.9305
2020-11-05 16:37:51,139 - root - INFO - Training: Epoch 0041 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.6270 | Iter Mean Loss 40.0698
2020-11-05 16:37:51,140 - root - INFO - Evaluate: Epoch 0041 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,145 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.7979 | Iter Mean Loss 65.7979
2020-11-05 16:37:51,151 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.3423 | Iter Mean Loss 43.0701
2020-11-05 16:37:51,156 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 64.0856 | Iter Mean Loss 50.0753
2020-11-05 16:37:51,161 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.5450 | Iter Mean Loss 47.6927
2020-11-05 16:37:51,166 - root - INFO - Training: Epoch 0042 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5729 | Iter Mean Loss 39.8687
2020-11-05 16:37:51,167 - root - INFO - Evaluate: Epoch 0042 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,172 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.4502 | Iter Mean Loss 65.4502
2020-11-05 16:37:51,177 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.1910 | Iter Mean Loss 42.8206
2020-11-05 16:37:51,183 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.8018 | Iter Mean Loss 49.8143
2020-11-05 16:37:51,188 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.4031 | Iter Mean Loss 47.4615
2020-11-05 16:37:51,193 - root - INFO - Training: Epoch 0043 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.5197 | Iter Mean Loss 39.6732
2020-11-05 16:37:51,194 - root - INFO - Evaluate: Epoch 0043 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,200 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 65.1090 | Iter Mean Loss 65.1090
2020-11-05 16:37:51,205 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 20.0477 | Iter Mean Loss 42.5783
2020-11-05 16:37:51,211 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.5200 | Iter Mean Loss 49.5589
2020-11-05 16:37:51,217 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.2634 | Iter Mean Loss 47.2350
2020-11-05 16:37:51,221 - root - INFO - Training: Epoch 0044 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4670 | Iter Mean Loss 39.4814
2020-11-05 16:37:51,222 - root - INFO - Evaluate: Epoch 0044 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:51,229 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.7725 | Iter Mean Loss 64.7725
2020-11-05 16:37:51,234 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.9105 | Iter Mean Loss 42.3415
2020-11-05 16:37:51,239 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 63.2387 | Iter Mean Loss 49.3073
2020-11-05 16:37:51,246 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 40.1246 | Iter Mean Loss 47.0116
2020-11-05 16:37:51,251 - root - INFO - Training: Epoch 0045 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.4148 | Iter Mean Loss 39.2922
2020-11-05 16:37:51,251 - root - INFO - Evaluate: Epoch 0045 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,257 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.4395 | Iter Mean Loss 64.4395
2020-11-05 16:37:51,263 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.7780 | Iter Mean Loss 42.1087
2020-11-05 16:37:51,269 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.9569 | Iter Mean Loss 49.0581
2020-11-05 16:37:51,274 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.9860 | Iter Mean Loss 46.7901
2020-11-05 16:37:51,279 - root - INFO - Training: Epoch 0046 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3628 | Iter Mean Loss 39.1046
2020-11-05 16:37:51,280 - root - INFO - Evaluate: Epoch 0046 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,286 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 64.1087 | Iter Mean Loss 64.1087
2020-11-05 16:37:51,291 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.6487 | Iter Mean Loss 41.8787
2020-11-05 16:37:51,297 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.6736 | Iter Mean Loss 48.8103
2020-11-05 16:37:51,302 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.8470 | Iter Mean Loss 46.5695
2020-11-05 16:37:51,306 - root - INFO - Training: Epoch 0047 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.3109 | Iter Mean Loss 38.9178
2020-11-05 16:37:51,307 - root - INFO - Evaluate: Epoch 0047 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,313 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.7791 | Iter Mean Loss 63.7791
2020-11-05 16:37:51,319 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.5214 | Iter Mean Loss 41.6503
2020-11-05 16:37:51,325 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.3885 | Iter Mean Loss 48.5630
2020-11-05 16:37:51,331 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.7073 | Iter Mean Loss 46.3491
2020-11-05 16:37:51,335 - root - INFO - Training: Epoch 0048 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2590 | Iter Mean Loss 38.7311
2020-11-05 16:37:51,336 - root - INFO - Evaluate: Epoch 0048 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,342 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.4499 | Iter Mean Loss 63.4499
2020-11-05 16:37:51,347 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.3953 | Iter Mean Loss 41.4226
2020-11-05 16:37:51,352 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 62.1010 | Iter Mean Loss 48.3154
2020-11-05 16:37:51,358 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.5663 | Iter Mean Loss 46.1281
2020-11-05 16:37:51,362 - root - INFO - Training: Epoch 0049 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.2069 | Iter Mean Loss 38.5439
2020-11-05 16:37:51,363 - root - INFO - Evaluate: Epoch 0049 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,368 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 63.1203 | Iter Mean Loss 63.1203
2020-11-05 16:37:51,374 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.2695 | Iter Mean Loss 41.1949
2020-11-05 16:37:51,379 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.8108 | Iter Mean Loss 48.0669
2020-11-05 16:37:51,384 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.4241 | Iter Mean Loss 45.9062
2020-11-05 16:37:51,390 - root - INFO - Training: Epoch 0050 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1544 | Iter Mean Loss 38.3558
2020-11-05 16:37:51,391 - root - INFO - Evaluate: Epoch 0050 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,396 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.7896 | Iter Mean Loss 62.7896
2020-11-05 16:37:51,402 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.1433 | Iter Mean Loss 40.9664
2020-11-05 16:37:51,407 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.5176 | Iter Mean Loss 47.8168
2020-11-05 16:37:51,413 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.2802 | Iter Mean Loss 45.6827
2020-11-05 16:37:51,418 - root - INFO - Training: Epoch 0051 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.1015 | Iter Mean Loss 38.1664
2020-11-05 16:37:51,419 - root - INFO - Evaluate: Epoch 0051 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,424 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.4573 | Iter Mean Loss 62.4573
2020-11-05 16:37:51,430 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 19.0160 | Iter Mean Loss 40.7367
2020-11-05 16:37:51,436 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 61.2214 | Iter Mean Loss 47.5649
2020-11-05 16:37:51,441 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 39.1347 | Iter Mean Loss 45.4573
2020-11-05 16:37:51,446 - root - INFO - Training: Epoch 0052 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 8.0479 | Iter Mean Loss 37.9755
2020-11-05 16:37:51,448 - root - INFO - Evaluate: Epoch 0052 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,454 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 62.1229 | Iter Mean Loss 62.1229
2020-11-05 16:37:51,459 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.8872 | Iter Mean Loss 40.5050
2020-11-05 16:37:51,465 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.9218 | Iter Mean Loss 47.3106
2020-11-05 16:37:51,470 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.9873 | Iter Mean Loss 45.2298
2020-11-05 16:37:51,475 - root - INFO - Training: Epoch 0053 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9935 | Iter Mean Loss 37.7825
2020-11-05 16:37:51,476 - root - INFO - Evaluate: Epoch 0053 | NDCG 0.0000 | MSE 0.2299
2020-11-05 16:37:51,482 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.7859 | Iter Mean Loss 61.7859
2020-11-05 16:37:51,488 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.7563 | Iter Mean Loss 40.2711
2020-11-05 16:37:51,493 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.6187 | Iter Mean Loss 47.0536
2020-11-05 16:37:51,498 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.8379 | Iter Mean Loss 44.9997
2020-11-05 16:37:51,503 - root - INFO - Training: Epoch 0054 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.9382 | Iter Mean Loss 37.5874
2020-11-05 16:37:51,504 - root - INFO - Evaluate: Epoch 0054 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,510 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.4461 | Iter Mean Loss 61.4461
2020-11-05 16:37:51,515 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.6228 | Iter Mean Loss 40.0345
2020-11-05 16:37:51,520 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.3120 | Iter Mean Loss 46.7937
2020-11-05 16:37:51,526 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.6863 | Iter Mean Loss 44.7668
2020-11-05 16:37:51,530 - root - INFO - Training: Epoch 0055 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8817 | Iter Mean Loss 37.3898
2020-11-05 16:37:51,531 - root - INFO - Evaluate: Epoch 0055 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,536 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 61.1030 | Iter Mean Loss 61.1030
2020-11-05 16:37:51,542 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.4865 | Iter Mean Loss 39.7948
2020-11-05 16:37:51,547 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 60.0015 | Iter Mean Loss 46.5304
2020-11-05 16:37:51,552 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.5324 | Iter Mean Loss 44.5309
2020-11-05 16:37:51,557 - root - INFO - Training: Epoch 0056 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.8239 | Iter Mean Loss 37.1895
2020-11-05 16:37:51,558 - root - INFO - Evaluate: Epoch 0056 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,563 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.7565 | Iter Mean Loss 60.7565
2020-11-05 16:37:51,569 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.3470 | Iter Mean Loss 39.5517
2020-11-05 16:37:51,574 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.6871 | Iter Mean Loss 46.2635
2020-11-05 16:37:51,579 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.3761 | Iter Mean Loss 44.2917
2020-11-05 16:37:51,585 - root - INFO - Training: Epoch 0057 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7647 | Iter Mean Loss 36.9863
2020-11-05 16:37:51,586 - root - INFO - Evaluate: Epoch 0057 | NDCG 0.0000 | MSE 0.2298
2020-11-05 16:37:51,591 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.4061 | Iter Mean Loss 60.4061
2020-11-05 16:37:51,597 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.2039 | Iter Mean Loss 39.3050
2020-11-05 16:37:51,602 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.3685 | Iter Mean Loss 45.9928
2020-11-05 16:37:51,609 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.2173 | Iter Mean Loss 44.0489
2020-11-05 16:37:51,613 - root - INFO - Training: Epoch 0058 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.7039 | Iter Mean Loss 36.7799
2020-11-05 16:37:51,614 - root - INFO - Evaluate: Epoch 0058 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:51,620 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 60.0517 | Iter Mean Loss 60.0517
2020-11-05 16:37:51,626 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 18.0569 | Iter Mean Loss 39.0543
2020-11-05 16:37:51,632 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 59.0457 | Iter Mean Loss 45.7181
2020-11-05 16:37:51,638 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 38.0557 | Iter Mean Loss 43.8025
2020-11-05 16:37:51,643 - root - INFO - Training: Epoch 0059 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.6415 | Iter Mean Loss 36.5703
2020-11-05 16:37:51,644 - root - INFO - Evaluate: Epoch 0059 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:51,650 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.6931 | Iter Mean Loss 59.6931
2020-11-05 16:37:51,656 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.9057 | Iter Mean Loss 38.7994
2020-11-05 16:37:51,662 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.7184 | Iter Mean Loss 45.4391
2020-11-05 16:37:51,667 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.8912 | Iter Mean Loss 43.5521
2020-11-05 16:37:51,672 - root - INFO - Training: Epoch 0060 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5773 | Iter Mean Loss 36.3571
2020-11-05 16:37:51,673 - root - INFO - Evaluate: Epoch 0060 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:51,679 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 59.3300 | Iter Mean Loss 59.3300
2020-11-05 16:37:51,685 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.7502 | Iter Mean Loss 38.5401
2020-11-05 16:37:51,690 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.3865 | Iter Mean Loss 45.1556
2020-11-05 16:37:51,696 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.7237 | Iter Mean Loss 43.2976
2020-11-05 16:37:51,700 - root - INFO - Training: Epoch 0061 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.5112 | Iter Mean Loss 36.1403
2020-11-05 16:37:51,701 - root - INFO - Evaluate: Epoch 0061 | NDCG 0.0000 | MSE 0.2297
2020-11-05 16:37:51,707 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.9623 | Iter Mean Loss 58.9623
2020-11-05 16:37:51,712 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.5899 | Iter Mean Loss 38.2761
2020-11-05 16:37:51,717 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 58.0499 | Iter Mean Loss 44.8674
2020-11-05 16:37:51,722 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.5531 | Iter Mean Loss 43.0388
2020-11-05 16:37:51,727 - root - INFO - Training: Epoch 0062 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.4430 | Iter Mean Loss 35.9197
2020-11-05 16:37:51,728 - root - INFO - Evaluate: Epoch 0062 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,733 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.5898 | Iter Mean Loss 58.5898
2020-11-05 16:37:51,739 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.4247 | Iter Mean Loss 38.0072
2020-11-05 16:37:51,744 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.7084 | Iter Mean Loss 44.5743
2020-11-05 16:37:51,749 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.3792 | Iter Mean Loss 42.7755
2020-11-05 16:37:51,754 - root - INFO - Training: Epoch 0063 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3729 | Iter Mean Loss 35.6950
2020-11-05 16:37:51,755 - root - INFO - Evaluate: Epoch 0063 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,760 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 58.2123 | Iter Mean Loss 58.2123
2020-11-05 16:37:51,766 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.2544 | Iter Mean Loss 37.7334
2020-11-05 16:37:51,771 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.3620 | Iter Mean Loss 44.2762
2020-11-05 16:37:51,776 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.2020 | Iter Mean Loss 42.5077
2020-11-05 16:37:51,781 - root - INFO - Training: Epoch 0064 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.3006 | Iter Mean Loss 35.4662
2020-11-05 16:37:51,782 - root - INFO - Evaluate: Epoch 0064 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,787 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.8298 | Iter Mean Loss 57.8298
2020-11-05 16:37:51,794 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 17.0788 | Iter Mean Loss 37.4543
2020-11-05 16:37:51,799 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 57.0104 | Iter Mean Loss 43.9730
2020-11-05 16:37:51,805 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 37.0212 | Iter Mean Loss 42.2350
2020-11-05 16:37:51,809 - root - INFO - Training: Epoch 0065 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.2261 | Iter Mean Loss 35.2332
2020-11-05 16:37:51,810 - root - INFO - Evaluate: Epoch 0065 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,817 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.4421 | Iter Mean Loss 57.4421
2020-11-05 16:37:51,822 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.8977 | Iter Mean Loss 37.1699
2020-11-05 16:37:51,828 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.6537 | Iter Mean Loss 43.6645
2020-11-05 16:37:51,834 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.8368 | Iter Mean Loss 41.9576
2020-11-05 16:37:51,839 - root - INFO - Training: Epoch 0066 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.1494 | Iter Mean Loss 34.9959
2020-11-05 16:37:51,840 - root - INFO - Evaluate: Epoch 0066 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,846 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 57.0492 | Iter Mean Loss 57.0492
2020-11-05 16:37:51,852 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.7109 | Iter Mean Loss 36.8801
2020-11-05 16:37:51,858 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 56.2917 | Iter Mean Loss 43.3506
2020-11-05 16:37:51,864 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.6487 | Iter Mean Loss 41.6751
2020-11-05 16:37:51,869 - root - INFO - Training: Epoch 0067 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 7.0706 | Iter Mean Loss 34.7542
2020-11-05 16:37:51,870 - root - INFO - Evaluate: Epoch 0067 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:51,875 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 56.6509 | Iter Mean Loss 56.6509
2020-11-05 16:37:51,881 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.5185 | Iter Mean Loss 36.5847
2020-11-05 16:37:51,887 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.9245 | Iter Mean Loss 43.0313
2020-11-05 16:37:51,892 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.4568 | Iter Mean Loss 41.3877
2020-11-05 16:37:51,897 - root - INFO - Training: Epoch 0068 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9895 | Iter Mean Loss 34.5081
2020-11-05 16:37:51,898 - root - INFO - Evaluate: Epoch 0068 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,903 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 56.2474 | Iter Mean Loss 56.2474
2020-11-05 16:37:51,909 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.3203 | Iter Mean Loss 36.2838
2020-11-05 16:37:51,914 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.5521 | Iter Mean Loss 42.7066
2020-11-05 16:37:51,919 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.2611 | Iter Mean Loss 41.0952
2020-11-05 16:37:51,924 - root - INFO - Training: Epoch 0069 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.9063 | Iter Mean Loss 34.2574
2020-11-05 16:37:51,925 - root - INFO - Evaluate: Epoch 0069 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,930 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.8385 | Iter Mean Loss 55.8385
2020-11-05 16:37:51,936 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 16.1162 | Iter Mean Loss 35.9773
2020-11-05 16:37:51,941 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 55.1745 | Iter Mean Loss 42.3764
2020-11-05 16:37:51,946 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 36.0617 | Iter Mean Loss 40.7977
2020-11-05 16:37:51,951 - root - INFO - Training: Epoch 0070 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.8209 | Iter Mean Loss 34.0023
2020-11-05 16:37:51,952 - root - INFO - Evaluate: Epoch 0070 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,957 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.4243 | Iter Mean Loss 55.4243
2020-11-05 16:37:51,963 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.9063 | Iter Mean Loss 35.6653
2020-11-05 16:37:51,968 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.7917 | Iter Mean Loss 42.0408
2020-11-05 16:37:51,973 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.8583 | Iter Mean Loss 40.4952
2020-11-05 16:37:51,978 - root - INFO - Training: Epoch 0071 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.7335 | Iter Mean Loss 33.7428
2020-11-05 16:37:51,979 - root - INFO - Evaluate: Epoch 0071 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:51,984 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 55.0050 | Iter Mean Loss 55.0050
2020-11-05 16:37:51,990 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.6907 | Iter Mean Loss 35.3478
2020-11-05 16:37:51,996 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.4040 | Iter Mean Loss 41.6999
2020-11-05 16:37:52,001 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.6512 | Iter Mean Loss 40.1877
2020-11-05 16:37:52,007 - root - INFO - Training: Epoch 0072 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.6441 | Iter Mean Loss 33.4790
2020-11-05 16:37:52,008 - root - INFO - Evaluate: Epoch 0072 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,014 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 54.5805 | Iter Mean Loss 54.5805
2020-11-05 16:37:52,020 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.4695 | Iter Mean Loss 35.0250
2020-11-05 16:37:52,026 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 54.0115 | Iter Mean Loss 41.3538
2020-11-05 16:37:52,032 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.4404 | Iter Mean Loss 39.8755
2020-11-05 16:37:52,037 - root - INFO - Training: Epoch 0073 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.5530 | Iter Mean Loss 33.2110
2020-11-05 16:37:52,038 - root - INFO - Evaluate: Epoch 0073 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,044 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 54.1511 | Iter Mean Loss 54.1511
2020-11-05 16:37:52,050 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.2428 | Iter Mean Loss 34.6969
2020-11-05 16:37:52,058 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.6144 | Iter Mean Loss 41.0028
2020-11-05 16:37:52,066 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.2259 | Iter Mean Loss 39.5585
2020-11-05 16:37:52,071 - root - INFO - Training: Epoch 0074 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.4602 | Iter Mean Loss 32.9389
2020-11-05 16:37:52,073 - root - INFO - Evaluate: Epoch 0074 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,079 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 53.7169 | Iter Mean Loss 53.7169
2020-11-05 16:37:52,087 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 15.0108 | Iter Mean Loss 34.3639
2020-11-05 16:37:52,095 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 53.2131 | Iter Mean Loss 40.6469
2020-11-05 16:37:52,103 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 35.0080 | Iter Mean Loss 39.2372
2020-11-05 16:37:52,108 - root - INFO - Training: Epoch 0075 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.3659 | Iter Mean Loss 32.6629
2020-11-05 16:37:52,109 - root - INFO - Evaluate: Epoch 0075 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,116 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 53.2782 | Iter Mean Loss 53.2782
2020-11-05 16:37:52,122 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.7740 | Iter Mean Loss 34.0261
2020-11-05 16:37:52,128 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.8078 | Iter Mean Loss 40.2867
2020-11-05 16:37:52,135 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.7867 | Iter Mean Loss 38.9117
2020-11-05 16:37:52,140 - root - INFO - Training: Epoch 0076 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.2705 | Iter Mean Loss 32.3834
2020-11-05 16:37:52,141 - root - INFO - Evaluate: Epoch 0076 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,146 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 52.8352 | Iter Mean Loss 52.8352
2020-11-05 16:37:52,152 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.5326 | Iter Mean Loss 33.6839
2020-11-05 16:37:52,158 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 52.3990 | Iter Mean Loss 39.9223
2020-11-05 16:37:52,163 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.5624 | Iter Mean Loss 38.5823
2020-11-05 16:37:52,170 - root - INFO - Training: Epoch 0077 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.1741 | Iter Mean Loss 32.1006
2020-11-05 16:37:52,171 - root - INFO - Evaluate: Epoch 0077 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,179 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 52.3883 | Iter Mean Loss 52.3883
2020-11-05 16:37:52,186 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.2870 | Iter Mean Loss 33.3377
2020-11-05 16:37:52,194 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.9872 | Iter Mean Loss 39.5542
2020-11-05 16:37:52,202 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.3351 | Iter Mean Loss 38.2494
2020-11-05 16:37:52,207 - root - INFO - Training: Epoch 0078 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 6.0770 | Iter Mean Loss 31.8149
2020-11-05 16:37:52,208 - root - INFO - Evaluate: Epoch 0078 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,214 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.9377 | Iter Mean Loss 51.9377
2020-11-05 16:37:52,221 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 14.0379 | Iter Mean Loss 32.9878
2020-11-05 16:37:52,227 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.5728 | Iter Mean Loss 39.1828
2020-11-05 16:37:52,233 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 34.1053 | Iter Mean Loss 37.9134
2020-11-05 16:37:52,239 - root - INFO - Training: Epoch 0079 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.9796 | Iter Mean Loss 31.5267
2020-11-05 16:37:52,240 - root - INFO - Evaluate: Epoch 0079 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,246 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.4839 | Iter Mean Loss 51.4839
2020-11-05 16:37:52,252 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.7856 | Iter Mean Loss 32.6347
2020-11-05 16:37:52,259 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 51.1565 | Iter Mean Loss 38.8086
2020-11-05 16:37:52,266 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.8733 | Iter Mean Loss 37.5748
2020-11-05 16:37:52,275 - root - INFO - Training: Epoch 0080 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.8822 | Iter Mean Loss 31.2363
2020-11-05 16:37:52,276 - root - INFO - Evaluate: Epoch 0080 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,282 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 51.0272 | Iter Mean Loss 51.0272
2020-11-05 16:37:52,289 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.5308 | Iter Mean Loss 32.2790
2020-11-05 16:37:52,294 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.7388 | Iter Mean Loss 38.4323
2020-11-05 16:37:52,300 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.6392 | Iter Mean Loss 37.2340
2020-11-05 16:37:52,304 - root - INFO - Training: Epoch 0081 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.7853 | Iter Mean Loss 30.9443
2020-11-05 16:37:52,305 - root - INFO - Evaluate: Epoch 0081 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,311 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 50.5682 | Iter Mean Loss 50.5682
2020-11-05 16:37:52,317 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.2741 | Iter Mean Loss 31.9212
2020-11-05 16:37:52,324 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 50.3205 | Iter Mean Loss 38.0543
2020-11-05 16:37:52,330 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.4036 | Iter Mean Loss 36.8916
2020-11-05 16:37:52,335 - root - INFO - Training: Epoch 0082 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.6891 | Iter Mean Loss 30.6511
2020-11-05 16:37:52,335 - root - INFO - Evaluate: Epoch 0082 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,341 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 50.1073 | Iter Mean Loss 50.1073
2020-11-05 16:37:52,346 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 13.0163 | Iter Mean Loss 31.5618
2020-11-05 16:37:52,352 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.9021 | Iter Mean Loss 37.6753
2020-11-05 16:37:52,357 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 33.1668 | Iter Mean Loss 36.5481
2020-11-05 16:37:52,362 - root - INFO - Training: Epoch 0083 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5941 | Iter Mean Loss 30.3573
2020-11-05 16:37:52,363 - root - INFO - Evaluate: Epoch 0083 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,368 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 49.6450 | Iter Mean Loss 49.6450
2020-11-05 16:37:52,373 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.7581 | Iter Mean Loss 31.2015
2020-11-05 16:37:52,379 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.4845 | Iter Mean Loss 37.2958
2020-11-05 16:37:52,384 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.9291 | Iter Mean Loss 36.2041
2020-11-05 16:37:52,389 - root - INFO - Training: Epoch 0084 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.5008 | Iter Mean Loss 30.0635
2020-11-05 16:37:52,390 - root - INFO - Evaluate: Epoch 0084 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,395 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 49.1817 | Iter Mean Loss 49.1817
2020-11-05 16:37:52,402 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.5001 | Iter Mean Loss 30.8409
2020-11-05 16:37:52,407 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 49.0682 | Iter Mean Loss 36.9167
2020-11-05 16:37:52,412 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.6910 | Iter Mean Loss 35.8602
2020-11-05 16:37:52,417 - root - INFO - Training: Epoch 0085 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.4094 | Iter Mean Loss 29.7701
2020-11-05 16:37:52,418 - root - INFO - Evaluate: Epoch 0085 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,424 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.7180 | Iter Mean Loss 48.7180
2020-11-05 16:37:52,430 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 12.2432 | Iter Mean Loss 30.4806
2020-11-05 16:37:52,435 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.6541 | Iter Mean Loss 36.5384
2020-11-05 16:37:52,442 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.4527 | Iter Mean Loss 35.5170
2020-11-05 16:37:52,446 - root - INFO - Training: Epoch 0086 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.3206 | Iter Mean Loss 29.4777
2020-11-05 16:37:52,447 - root - INFO - Evaluate: Epoch 0086 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,453 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 48.2543 | Iter Mean Loss 48.2543
2020-11-05 16:37:52,459 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.9879 | Iter Mean Loss 30.1211
2020-11-05 16:37:52,465 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 48.2427 | Iter Mean Loss 36.1617
2020-11-05 16:37:52,470 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 32.2148 | Iter Mean Loss 35.1750
2020-11-05 16:37:52,476 - root - INFO - Training: Epoch 0087 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.2345 | Iter Mean Loss 29.1869
2020-11-05 16:37:52,477 - root - INFO - Evaluate: Epoch 0087 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,482 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 47.7912 | Iter Mean Loss 47.7912
2020-11-05 16:37:52,488 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.7351 | Iter Mean Loss 29.7632
2020-11-05 16:37:52,494 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.8348 | Iter Mean Loss 35.7871
2020-11-05 16:37:52,499 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.9775 | Iter Mean Loss 34.8347
2020-11-05 16:37:52,504 - root - INFO - Training: Epoch 0088 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.1517 | Iter Mean Loss 28.8981
2020-11-05 16:37:52,505 - root - INFO - Evaluate: Epoch 0088 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,510 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 47.3292 | Iter Mean Loss 47.3292
2020-11-05 16:37:52,516 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.4854 | Iter Mean Loss 29.4073
2020-11-05 16:37:52,521 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.4309 | Iter Mean Loss 35.4152
2020-11-05 16:37:52,526 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.7410 | Iter Mean Loss 34.4966
2020-11-05 16:37:52,531 - root - INFO - Training: Epoch 0089 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 5.0724 | Iter Mean Loss 28.6118
2020-11-05 16:37:52,532 - root - INFO - Evaluate: Epoch 0089 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,537 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 46.8685 | Iter Mean Loss 46.8685
2020-11-05 16:37:52,543 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 11.2394 | Iter Mean Loss 29.0539
2020-11-05 16:37:52,548 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 47.0316 | Iter Mean Loss 35.0465
2020-11-05 16:37:52,553 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.5058 | Iter Mean Loss 34.1613
2020-11-05 16:37:52,558 - root - INFO - Training: Epoch 0090 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9969 | Iter Mean Loss 28.3284
2020-11-05 16:37:52,559 - root - INFO - Evaluate: Epoch 0090 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,565 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 46.4097 | Iter Mean Loss 46.4097
2020-11-05 16:37:52,570 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.9975 | Iter Mean Loss 28.7036
2020-11-05 16:37:52,575 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.6373 | Iter Mean Loss 34.6815
2020-11-05 16:37:52,581 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.2720 | Iter Mean Loss 33.8291
2020-11-05 16:37:52,585 - root - INFO - Training: Epoch 0091 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.9255 | Iter Mean Loss 28.0484
2020-11-05 16:37:52,586 - root - INFO - Evaluate: Epoch 0091 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,592 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.9530 | Iter Mean Loss 45.9530
2020-11-05 16:37:52,597 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.7602 | Iter Mean Loss 28.3566
2020-11-05 16:37:52,603 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 46.2484 | Iter Mean Loss 34.3206
2020-11-05 16:37:52,609 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 31.0398 | Iter Mean Loss 33.5004
2020-11-05 16:37:52,614 - root - INFO - Training: Epoch 0092 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.8584 | Iter Mean Loss 27.7720
2020-11-05 16:37:52,615 - root - INFO - Evaluate: Epoch 0092 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,621 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.4989 | Iter Mean Loss 45.4989
2020-11-05 16:37:52,626 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.5279 | Iter Mean Loss 28.0134
2020-11-05 16:37:52,632 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.8652 | Iter Mean Loss 33.9640
2020-11-05 16:37:52,638 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.8094 | Iter Mean Loss 33.1754
2020-11-05 16:37:52,643 - root - INFO - Training: Epoch 0093 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7957 | Iter Mean Loss 27.4994
2020-11-05 16:37:52,644 - root - INFO - Evaluate: Epoch 0093 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,650 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 45.0475 | Iter Mean Loss 45.0475
2020-11-05 16:37:52,656 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.3009 | Iter Mean Loss 27.6742
2020-11-05 16:37:52,661 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.4880 | Iter Mean Loss 33.6121
2020-11-05 16:37:52,667 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.5809 | Iter Mean Loss 32.8543
2020-11-05 16:37:52,672 - root - INFO - Training: Epoch 0094 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.7375 | Iter Mean Loss 27.2309
2020-11-05 16:37:52,673 - root - INFO - Evaluate: Epoch 0094 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,679 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 44.5990 | Iter Mean Loss 44.5990
2020-11-05 16:37:52,684 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 10.0792 | Iter Mean Loss 27.3391
2020-11-05 16:37:52,690 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 45.1168 | Iter Mean Loss 33.2650
2020-11-05 16:37:52,696 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.3542 | Iter Mean Loss 32.5373
2020-11-05 16:37:52,701 - root - INFO - Training: Epoch 0095 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6838 | Iter Mean Loss 26.9666
2020-11-05 16:37:52,702 - root - INFO - Evaluate: Epoch 0095 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,707 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 44.1536 | Iter Mean Loss 44.1536
2020-11-05 16:37:52,712 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.8630 | Iter Mean Loss 27.0083
2020-11-05 16:37:52,718 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.7517 | Iter Mean Loss 32.9228
2020-11-05 16:37:52,723 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 30.1294 | Iter Mean Loss 32.2244
2020-11-05 16:37:52,728 - root - INFO - Training: Epoch 0096 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.6346 | Iter Mean Loss 26.7065
2020-11-05 16:37:52,729 - root - INFO - Evaluate: Epoch 0096 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,734 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 43.7115 | Iter Mean Loss 43.7115
2020-11-05 16:37:52,739 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.6522 | Iter Mean Loss 26.6818
2020-11-05 16:37:52,745 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.3925 | Iter Mean Loss 32.5854
2020-11-05 16:37:52,750 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.9066 | Iter Mean Loss 31.9157
2020-11-05 16:37:52,755 - root - INFO - Training: Epoch 0097 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5899 | Iter Mean Loss 26.4505
2020-11-05 16:37:52,756 - root - INFO - Evaluate: Epoch 0097 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,761 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 43.2726 | Iter Mean Loss 43.2726
2020-11-05 16:37:52,767 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.4466 | Iter Mean Loss 26.3596
2020-11-05 16:37:52,772 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 44.0393 | Iter Mean Loss 32.2528
2020-11-05 16:37:52,777 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.6854 | Iter Mean Loss 31.6110
2020-11-05 16:37:52,782 - root - INFO - Training: Epoch 0098 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5494 | Iter Mean Loss 26.1987
2020-11-05 16:37:52,783 - root - INFO - Evaluate: Epoch 0098 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,788 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.8370 | Iter Mean Loss 42.8370
2020-11-05 16:37:52,794 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.2462 | Iter Mean Loss 26.0416
2020-11-05 16:37:52,799 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.6917 | Iter Mean Loss 31.9250
2020-11-05 16:37:52,805 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.4660 | Iter Mean Loss 31.3102
2020-11-05 16:37:52,810 - root - INFO - Training: Epoch 0099 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5130 | Iter Mean Loss 25.9508
2020-11-05 16:37:52,811 - root - INFO - Evaluate: Epoch 0099 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,817 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 42.4046 | Iter Mean Loss 42.4046
2020-11-05 16:37:52,823 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 9.0506 | Iter Mean Loss 25.7276
2020-11-05 16:37:52,828 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.3496 | Iter Mean Loss 31.6016
2020-11-05 16:37:52,834 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.2481 | Iter Mean Loss 31.0132
2020-11-05 16:37:52,839 - root - INFO - Training: Epoch 0100 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4805 | Iter Mean Loss 25.7067
2020-11-05 16:37:52,840 - root - INFO - Evaluate: Epoch 0100 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,846 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.9754 | Iter Mean Loss 41.9754
2020-11-05 16:37:52,851 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.8594 | Iter Mean Loss 25.4174
2020-11-05 16:37:52,857 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 43.0125 | Iter Mean Loss 31.2825
2020-11-05 16:37:52,863 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 29.0316 | Iter Mean Loss 30.7197
2020-11-05 16:37:52,868 - root - INFO - Training: Epoch 0101 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4516 | Iter Mean Loss 25.4661
2020-11-05 16:37:52,869 - root - INFO - Evaluate: Epoch 0101 | NDCG 0.0000 | MSE 0.2296
2020-11-05 16:37:52,875 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.5494 | Iter Mean Loss 41.5494
2020-11-05 16:37:52,881 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.6724 | Iter Mean Loss 25.1109
2020-11-05 16:37:52,886 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.6803 | Iter Mean Loss 30.9674
2020-11-05 16:37:52,892 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.8163 | Iter Mean Loss 30.4296
2020-11-05 16:37:52,897 - root - INFO - Training: Epoch 0102 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4261 | Iter Mean Loss 25.2289
2020-11-05 16:37:52,898 - root - INFO - Evaluate: Epoch 0102 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,904 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 41.1264 | Iter Mean Loss 41.1264
2020-11-05 16:37:52,909 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.4891 | Iter Mean Loss 24.8078
2020-11-05 16:37:52,914 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.3524 | Iter Mean Loss 30.6560
2020-11-05 16:37:52,920 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.6020 | Iter Mean Loss 30.1425
2020-11-05 16:37:52,924 - root - INFO - Training: Epoch 0103 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4037 | Iter Mean Loss 24.9947
2020-11-05 16:37:52,925 - root - INFO - Evaluate: Epoch 0103 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,931 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.7064 | Iter Mean Loss 40.7064
2020-11-05 16:37:52,936 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.3091 | Iter Mean Loss 24.5078
2020-11-05 16:37:52,941 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 42.0287 | Iter Mean Loss 30.3481
2020-11-05 16:37:52,947 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.3887 | Iter Mean Loss 29.8582
2020-11-05 16:37:52,951 - root - INFO - Training: Epoch 0104 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3840 | Iter Mean Loss 24.7634
2020-11-05 16:37:52,952 - root - INFO - Evaluate: Epoch 0104 | NDCG 0.0000 | MSE 0.2295
2020-11-05 16:37:52,958 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 40.2894 | Iter Mean Loss 40.2894
2020-11-05 16:37:52,963 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 8.1321 | Iter Mean Loss 24.2107
2020-11-05 16:37:52,969 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.7088 | Iter Mean Loss 30.0434
2020-11-05 16:37:52,974 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 28.1760 | Iter Mean Loss 29.5766
2020-11-05 16:37:52,979 - root - INFO - Training: Epoch 0105 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3669 | Iter Mean Loss 24.5346
2020-11-05 16:37:52,979 - root - INFO - Evaluate: Epoch 0105 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:37:52,985 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.8751 | Iter Mean Loss 39.8751
2020-11-05 16:37:52,990 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.9577 | Iter Mean Loss 23.9164
2020-11-05 16:37:52,996 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.3923 | Iter Mean Loss 29.7417
2020-11-05 16:37:53,001 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.9641 | Iter Mean Loss 29.2973
2020-11-05 16:37:53,006 - root - INFO - Training: Epoch 0106 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3519 | Iter Mean Loss 24.3082
2020-11-05 16:37:53,007 - root - INFO - Evaluate: Epoch 0106 | NDCG 0.0000 | MSE 0.2294
2020-11-05 16:37:53,013 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.4637 | Iter Mean Loss 39.4637
2020-11-05 16:37:53,018 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.7855 | Iter Mean Loss 23.6246
2020-11-05 16:37:53,024 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 41.0789 | Iter Mean Loss 29.4427
2020-11-05 16:37:53,030 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.7526 | Iter Mean Loss 29.0202
2020-11-05 16:37:53,035 - root - INFO - Training: Epoch 0107 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3389 | Iter Mean Loss 24.0839
2020-11-05 16:37:53,036 - root - INFO - Evaluate: Epoch 0107 | NDCG 0.0000 | MSE 0.2293
2020-11-05 16:37:53,041 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 39.0552 | Iter Mean Loss 39.0552
2020-11-05 16:37:53,047 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.6153 | Iter Mean Loss 23.3352
2020-11-05 16:37:53,053 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.7686 | Iter Mean Loss 29.1463
2020-11-05 16:37:53,058 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.5416 | Iter Mean Loss 28.7452
2020-11-05 16:37:53,064 - root - INFO - Training: Epoch 0108 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3276 | Iter Mean Loss 23.8617
2020-11-05 16:37:53,065 - root - INFO - Evaluate: Epoch 0108 | NDCG 0.0000 | MSE 0.2292
2020-11-05 16:37:53,071 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 38.6495 | Iter Mean Loss 38.6495
2020-11-05 16:37:53,076 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.4468 | Iter Mean Loss 23.0482
2020-11-05 16:37:53,082 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.4610 | Iter Mean Loss 28.8524
2020-11-05 16:37:53,088 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.3311 | Iter Mean Loss 28.4721
2020-11-05 16:37:53,093 - root - INFO - Training: Epoch 0109 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3178 | Iter Mean Loss 23.6412
2020-11-05 16:37:53,094 - root - INFO - Evaluate: Epoch 0109 | NDCG 0.0000 | MSE 0.2291
2020-11-05 16:37:53,100 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 38.2468 | Iter Mean Loss 38.2468
2020-11-05 16:37:53,106 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.2799 | Iter Mean Loss 22.7633
2020-11-05 16:37:53,111 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 40.1560 | Iter Mean Loss 28.5609
2020-11-05 16:37:53,116 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 27.1211 | Iter Mean Loss 28.2009
2020-11-05 16:37:53,121 - root - INFO - Training: Epoch 0110 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3093 | Iter Mean Loss 23.4226
2020-11-05 16:37:53,122 - root - INFO - Evaluate: Epoch 0110 | NDCG 0.0000 | MSE 0.2290
2020-11-05 16:37:53,128 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.8472 | Iter Mean Loss 37.8472
2020-11-05 16:37:53,134 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 7.1143 | Iter Mean Loss 22.4808
2020-11-05 16:37:53,139 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.8537 | Iter Mean Loss 28.2717
2020-11-05 16:37:53,144 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.9117 | Iter Mean Loss 27.9317
2020-11-05 16:37:53,149 - root - INFO - Training: Epoch 0111 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3018 | Iter Mean Loss 23.2057
2020-11-05 16:37:53,150 - root - INFO - Evaluate: Epoch 0111 | NDCG 0.0000 | MSE 0.2289
2020-11-05 16:37:53,156 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.4508 | Iter Mean Loss 37.4508
2020-11-05 16:37:53,161 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.9502 | Iter Mean Loss 22.2005
2020-11-05 16:37:53,166 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.5538 | Iter Mean Loss 27.9849
2020-11-05 16:37:53,172 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.7029 | Iter Mean Loss 27.6644
2020-11-05 16:37:53,176 - root - INFO - Training: Epoch 0112 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2952 | Iter Mean Loss 22.9906
2020-11-05 16:37:53,177 - root - INFO - Evaluate: Epoch 0112 | NDCG 0.0000 | MSE 0.2288
2020-11-05 16:37:53,183 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 37.0578 | Iter Mean Loss 37.0578
2020-11-05 16:37:53,188 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.7874 | Iter Mean Loss 21.9226
2020-11-05 16:37:53,194 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 39.2566 | Iter Mean Loss 27.7006
2020-11-05 16:37:53,199 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.4949 | Iter Mean Loss 27.3992
2020-11-05 16:37:53,204 - root - INFO - Training: Epoch 0113 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2894 | Iter Mean Loss 22.7772
2020-11-05 16:37:53,204 - root - INFO - Evaluate: Epoch 0113 | NDCG 0.0000 | MSE 0.2287
2020-11-05 16:37:53,210 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 36.6686 | Iter Mean Loss 36.6686
2020-11-05 16:37:53,216 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.6261 | Iter Mean Loss 21.6473
2020-11-05 16:37:53,222 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.9621 | Iter Mean Loss 27.4189
2020-11-05 16:37:53,228 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.2880 | Iter Mean Loss 27.1362
2020-11-05 16:37:53,233 - root - INFO - Training: Epoch 0114 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2842 | Iter Mean Loss 22.5658
2020-11-05 16:37:53,234 - root - INFO - Evaluate: Epoch 0114 | NDCG 0.0000 | MSE 0.2286
2020-11-05 16:37:53,239 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 36.2834 | Iter Mean Loss 36.2834
2020-11-05 16:37:53,245 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.4663 | Iter Mean Loss 21.3748
2020-11-05 16:37:53,251 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.6703 | Iter Mean Loss 27.1400
2020-11-05 16:37:53,256 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 26.0823 | Iter Mean Loss 26.8756
2020-11-05 16:37:53,262 - root - INFO - Training: Epoch 0115 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2796 | Iter Mean Loss 22.3564
2020-11-05 16:37:53,263 - root - INFO - Evaluate: Epoch 0115 | NDCG 0.0000 | MSE 0.2284
2020-11-05 16:37:53,268 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.9024 | Iter Mean Loss 35.9024
2020-11-05 16:37:53,274 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.3082 | Iter Mean Loss 21.1053
2020-11-05 16:37:53,280 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.3816 | Iter Mean Loss 26.8641
2020-11-05 16:37:53,285 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.8782 | Iter Mean Loss 26.6176
2020-11-05 16:37:53,290 - root - INFO - Training: Epoch 0116 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2755 | Iter Mean Loss 22.1492
2020-11-05 16:37:53,291 - root - INFO - Evaluate: Epoch 0116 | NDCG 0.0000 | MSE 0.2283
2020-11-05 16:37:53,297 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.5261 | Iter Mean Loss 35.5261
2020-11-05 16:37:53,303 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 6.1522 | Iter Mean Loss 20.8391
2020-11-05 16:37:53,308 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 38.0960 | Iter Mean Loss 26.5914
2020-11-05 16:37:53,316 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.6759 | Iter Mean Loss 26.3625
2020-11-05 16:37:53,322 - root - INFO - Training: Epoch 0117 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2718 | Iter Mean Loss 21.9444
2020-11-05 16:37:53,323 - root - INFO - Evaluate: Epoch 0117 | NDCG 0.0000 | MSE 0.2281
2020-11-05 16:37:53,328 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 35.1548 | Iter Mean Loss 35.1548
2020-11-05 16:37:53,334 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.9983 | Iter Mean Loss 20.5765
2020-11-05 16:37:53,339 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.8139 | Iter Mean Loss 26.3223
2020-11-05 16:37:53,345 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.4758 | Iter Mean Loss 26.1107
2020-11-05 16:37:53,349 - root - INFO - Training: Epoch 0118 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2686 | Iter Mean Loss 21.7423
2020-11-05 16:37:53,350 - root - INFO - Evaluate: Epoch 0118 | NDCG 0.0000 | MSE 0.2280
2020-11-05 16:37:53,356 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.7888 | Iter Mean Loss 34.7888
2020-11-05 16:37:53,361 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.8469 | Iter Mean Loss 20.3179
2020-11-05 16:37:53,366 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.5354 | Iter Mean Loss 26.0570
2020-11-05 16:37:53,372 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.2782 | Iter Mean Loss 25.8623
2020-11-05 16:37:53,377 - root - INFO - Training: Epoch 0119 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2656 | Iter Mean Loss 21.5430
2020-11-05 16:37:53,377 - root - INFO - Evaluate: Epoch 0119 | NDCG 0.0000 | MSE 0.2278
2020-11-05 16:37:53,383 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.4286 | Iter Mean Loss 34.4286
2020-11-05 16:37:53,388 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.6984 | Iter Mean Loss 20.0635
2020-11-05 16:37:53,394 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 37.2609 | Iter Mean Loss 25.7960
2020-11-05 16:37:53,399 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 25.0835 | Iter Mean Loss 25.6179
2020-11-05 16:37:53,404 - root - INFO - Training: Epoch 0120 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2631 | Iter Mean Loss 21.3469
2020-11-05 16:37:53,405 - root - INFO - Evaluate: Epoch 0120 | NDCG 0.0000 | MSE 0.2276
2020-11-05 16:37:53,411 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 34.0746 | Iter Mean Loss 34.0746
2020-11-05 16:37:53,417 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.5530 | Iter Mean Loss 19.8138
2020-11-05 16:37:53,422 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.9906 | Iter Mean Loss 25.5394
2020-11-05 16:37:53,428 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.8920 | Iter Mean Loss 25.3776
2020-11-05 16:37:53,433 - root - INFO - Training: Epoch 0121 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2608 | Iter Mean Loss 21.1542
2020-11-05 16:37:53,434 - root - INFO - Evaluate: Epoch 0121 | NDCG 0.0000 | MSE 0.2274
2020-11-05 16:37:53,440 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.7272 | Iter Mean Loss 33.7272
2020-11-05 16:37:53,446 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.4111 | Iter Mean Loss 19.5691
2020-11-05 16:37:53,452 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.7249 | Iter Mean Loss 25.2877
2020-11-05 16:37:53,457 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.7041 | Iter Mean Loss 25.1418
2020-11-05 16:37:53,463 - root - INFO - Training: Epoch 0122 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2589 | Iter Mean Loss 20.9652
2020-11-05 16:37:53,464 - root - INFO - Evaluate: Epoch 0122 | NDCG 0.0000 | MSE 0.2272
2020-11-05 16:37:53,469 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.3866 | Iter Mean Loss 33.3866
2020-11-05 16:37:53,475 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.2730 | Iter Mean Loss 19.3298
2020-11-05 16:37:53,481 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.4640 | Iter Mean Loss 25.0412
2020-11-05 16:37:53,486 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.5201 | Iter Mean Loss 24.9109
2020-11-05 16:37:53,491 - root - INFO - Training: Epoch 0123 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2574 | Iter Mean Loss 20.7802
2020-11-05 16:37:53,492 - root - INFO - Evaluate: Epoch 0123 | NDCG 0.0000 | MSE 0.2270
2020-11-05 16:37:53,498 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 33.0533 | Iter Mean Loss 33.0533
2020-11-05 16:37:53,504 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.1391 | Iter Mean Loss 19.0962
2020-11-05 16:37:53,509 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 36.2081 | Iter Mean Loss 24.8002
2020-11-05 16:37:53,515 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.3403 | Iter Mean Loss 24.6852
2020-11-05 16:37:53,519 - root - INFO - Training: Epoch 0124 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2562 | Iter Mean Loss 20.5994
2020-11-05 16:37:53,520 - root - INFO - Evaluate: Epoch 0124 | NDCG 0.0000 | MSE 0.2268
2020-11-05 16:37:53,526 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.7276 | Iter Mean Loss 32.7276
2020-11-05 16:37:53,531 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 5.0097 | Iter Mean Loss 18.8687
2020-11-05 16:37:53,536 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.9576 | Iter Mean Loss 24.5650
2020-11-05 16:37:53,542 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 24.1651 | Iter Mean Loss 24.4650
2020-11-05 16:37:53,546 - root - INFO - Training: Epoch 0125 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2553 | Iter Mean Loss 20.4231
2020-11-05 16:37:53,547 - root - INFO - Evaluate: Epoch 0125 | NDCG 0.0000 | MSE 0.2265
2020-11-05 16:37:53,553 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.4098 | Iter Mean Loss 32.4098
2020-11-05 16:37:53,558 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.8851 | Iter Mean Loss 18.6474
2020-11-05 16:37:53,564 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.7126 | Iter Mean Loss 24.3358
2020-11-05 16:37:53,569 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.9946 | Iter Mean Loss 24.2505
2020-11-05 16:37:53,574 - root - INFO - Training: Epoch 0126 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2549 | Iter Mean Loss 20.2514
2020-11-05 16:37:53,575 - root - INFO - Evaluate: Epoch 0126 | NDCG 0.0000 | MSE 0.2263
2020-11-05 16:37:53,580 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 32.1000 | Iter Mean Loss 32.1000
2020-11-05 16:37:53,586 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.7654 | Iter Mean Loss 18.4327
2020-11-05 16:37:53,591 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.4734 | Iter Mean Loss 24.1129
2020-11-05 16:37:53,597 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.8292 | Iter Mean Loss 24.0420
2020-11-05 16:37:53,602 - root - INFO - Training: Epoch 0127 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2548 | Iter Mean Loss 20.0846
2020-11-05 16:37:53,602 - root - INFO - Evaluate: Epoch 0127 | NDCG 0.0000 | MSE 0.2260
2020-11-05 16:37:53,608 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.7986 | Iter Mean Loss 31.7986
2020-11-05 16:37:53,614 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.6509 | Iter Mean Loss 18.2247
2020-11-05 16:37:53,619 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.2400 | Iter Mean Loss 23.8965
2020-11-05 16:37:53,625 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.6690 | Iter Mean Loss 23.8396
2020-11-05 16:37:53,630 - root - INFO - Training: Epoch 0128 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2551 | Iter Mean Loss 19.9227
2020-11-05 16:37:53,631 - root - INFO - Evaluate: Epoch 0128 | NDCG 0.0000 | MSE 0.2258
2020-11-05 16:37:53,638 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.5055 | Iter Mean Loss 31.5055
2020-11-05 16:37:53,645 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.5418 | Iter Mean Loss 18.0237
2020-11-05 16:37:53,652 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 35.0126 | Iter Mean Loss 23.6867
2020-11-05 16:37:53,659 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.5141 | Iter Mean Loss 23.6435
2020-11-05 16:37:53,664 - root - INFO - Training: Epoch 0129 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2558 | Iter Mean Loss 19.7660
2020-11-05 16:37:53,665 - root - INFO - Evaluate: Epoch 0129 | NDCG 0.0000 | MSE 0.2255
2020-11-05 16:37:53,672 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 31.2210 | Iter Mean Loss 31.2210
2020-11-05 16:37:53,678 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.4382 | Iter Mean Loss 17.8296
2020-11-05 16:37:53,684 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.7914 | Iter Mean Loss 23.4835
2020-11-05 16:37:53,691 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.3646 | Iter Mean Loss 23.4538
2020-11-05 16:37:53,696 - root - INFO - Training: Epoch 0130 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2570 | Iter Mean Loss 19.6144
2020-11-05 16:37:53,697 - root - INFO - Evaluate: Epoch 0130 | NDCG 0.0000 | MSE 0.2253
2020-11-05 16:37:53,703 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.9450 | Iter Mean Loss 30.9450
2020-11-05 16:37:53,709 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.3401 | Iter Mean Loss 17.6426
2020-11-05 16:37:53,715 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.5762 | Iter Mean Loss 23.2871
2020-11-05 16:37:53,722 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.2205 | Iter Mean Loss 23.2705
2020-11-05 16:37:53,727 - root - INFO - Training: Epoch 0131 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2585 | Iter Mean Loss 19.4681
2020-11-05 16:37:53,728 - root - INFO - Evaluate: Epoch 0131 | NDCG 0.0000 | MSE 0.2250
2020-11-05 16:37:53,735 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.6776 | Iter Mean Loss 30.6776
2020-11-05 16:37:53,741 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.2476 | Iter Mean Loss 17.4626
2020-11-05 16:37:53,747 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.3671 | Iter Mean Loss 23.0975
2020-11-05 16:37:53,754 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 23.0818 | Iter Mean Loss 23.0935
2020-11-05 16:37:53,759 - root - INFO - Training: Epoch 0132 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2605 | Iter Mean Loss 19.3269
2020-11-05 16:37:53,760 - root - INFO - Evaluate: Epoch 0132 | NDCG 0.0000 | MSE 0.2247
2020-11-05 16:37:53,767 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.4186 | Iter Mean Loss 30.4186
2020-11-05 16:37:53,774 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.1607 | Iter Mean Loss 17.2896
2020-11-05 16:37:53,780 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 34.1642 | Iter Mean Loss 22.9145
2020-11-05 16:37:53,787 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.9485 | Iter Mean Loss 22.9230
2020-11-05 16:37:53,792 - root - INFO - Training: Epoch 0133 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2628 | Iter Mean Loss 19.1910
2020-11-05 16:37:53,793 - root - INFO - Evaluate: Epoch 0133 | NDCG 0.0000 | MSE 0.2244
2020-11-05 16:37:53,800 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 30.1679 | Iter Mean Loss 30.1679
2020-11-05 16:37:53,806 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0792 | Iter Mean Loss 17.1235
2020-11-05 16:37:53,812 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.9672 | Iter Mean Loss 22.7381
2020-11-05 16:37:53,818 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.8205 | Iter Mean Loss 22.7587
2020-11-05 16:37:53,823 - root - INFO - Training: Epoch 0134 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2656 | Iter Mean Loss 19.0601
2020-11-05 16:37:53,824 - root - INFO - Evaluate: Epoch 0134 | NDCG 0.0000 | MSE 0.2241
2020-11-05 16:37:53,830 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.9254 | Iter Mean Loss 29.9254
2020-11-05 16:37:53,836 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 4.0030 | Iter Mean Loss 16.9642
2020-11-05 16:37:53,841 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.7761 | Iter Mean Loss 22.5682
2020-11-05 16:37:53,847 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.6975 | Iter Mean Loss 22.6005
2020-11-05 16:37:53,852 - root - INFO - Training: Epoch 0135 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2687 | Iter Mean Loss 18.9341
2020-11-05 16:37:53,853 - root - INFO - Evaluate: Epoch 0135 | NDCG 0.0000 | MSE 0.2238
2020-11-05 16:37:53,859 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.6908 | Iter Mean Loss 29.6908
2020-11-05 16:37:53,865 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.9320 | Iter Mean Loss 16.8114
2020-11-05 16:37:53,870 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.5908 | Iter Mean Loss 22.4045
2020-11-05 16:37:53,876 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.5795 | Iter Mean Loss 22.4483
2020-11-05 16:37:53,881 - root - INFO - Training: Epoch 0136 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2723 | Iter Mean Loss 18.8131
2020-11-05 16:37:53,882 - root - INFO - Evaluate: Epoch 0136 | NDCG 0.0000 | MSE 0.2235
2020-11-05 16:37:53,888 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.4639 | Iter Mean Loss 29.4639
2020-11-05 16:37:53,893 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8661 | Iter Mean Loss 16.6650
2020-11-05 16:37:53,899 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.4110 | Iter Mean Loss 22.2470
2020-11-05 16:37:53,904 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.4662 | Iter Mean Loss 22.3018
2020-11-05 16:37:53,910 - root - INFO - Training: Epoch 0137 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2761 | Iter Mean Loss 18.6967
2020-11-05 16:37:53,911 - root - INFO - Evaluate: Epoch 0137 | NDCG 0.0000 | MSE 0.2232
2020-11-05 16:37:53,916 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.2445 | Iter Mean Loss 29.2445
2020-11-05 16:37:53,921 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.8049 | Iter Mean Loss 16.5247
2020-11-05 16:37:53,927 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.2367 | Iter Mean Loss 22.0953
2020-11-05 16:37:53,932 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.3575 | Iter Mean Loss 22.1609
2020-11-05 16:37:53,937 - root - INFO - Training: Epoch 0138 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2803 | Iter Mean Loss 18.5848
2020-11-05 16:37:53,938 - root - INFO - Evaluate: Epoch 0138 | NDCG 0.0000 | MSE 0.2229
2020-11-05 16:37:53,943 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 29.0322 | Iter Mean Loss 29.0322
2020-11-05 16:37:53,948 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.7482 | Iter Mean Loss 16.3902
2020-11-05 16:37:53,954 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 33.0675 | Iter Mean Loss 21.9493
2020-11-05 16:37:53,959 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.2529 | Iter Mean Loss 22.0252
2020-11-05 16:37:53,964 - root - INFO - Training: Epoch 0139 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2848 | Iter Mean Loss 18.4771
2020-11-05 16:37:53,965 - root - INFO - Evaluate: Epoch 0139 | NDCG 0.0000 | MSE 0.2226
2020-11-05 16:37:53,970 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.8268 | Iter Mean Loss 28.8268
2020-11-05 16:37:53,976 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6959 | Iter Mean Loss 16.2614
2020-11-05 16:37:53,981 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.9033 | Iter Mean Loss 21.8087
2020-11-05 16:37:53,986 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.1525 | Iter Mean Loss 21.8946
2020-11-05 16:37:53,991 - root - INFO - Training: Epoch 0140 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2896 | Iter Mean Loss 18.3736
2020-11-05 16:37:53,992 - root - INFO - Evaluate: Epoch 0140 | NDCG 0.0000 | MSE 0.2223
2020-11-05 16:37:53,997 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.6279 | Iter Mean Loss 28.6279
2020-11-05 16:37:54,002 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6477 | Iter Mean Loss 16.1378
2020-11-05 16:37:54,008 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.7439 | Iter Mean Loss 21.6732
2020-11-05 16:37:54,013 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 22.0557 | Iter Mean Loss 21.7688
2020-11-05 16:37:54,018 - root - INFO - Training: Epoch 0141 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2946 | Iter Mean Loss 18.2740
2020-11-05 16:37:54,020 - root - INFO - Evaluate: Epoch 0141 | NDCG 0.0000 | MSE 0.2220
2020-11-05 16:37:54,025 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.4353 | Iter Mean Loss 28.4353
2020-11-05 16:37:54,030 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.6032 | Iter Mean Loss 16.0193
2020-11-05 16:37:54,036 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.5890 | Iter Mean Loss 21.5425
2020-11-05 16:37:54,042 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.9625 | Iter Mean Loss 21.6475
2020-11-05 16:37:54,047 - root - INFO - Training: Epoch 0142 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2999 | Iter Mean Loss 18.1780
2020-11-05 16:37:54,048 - root - INFO - Evaluate: Epoch 0142 | NDCG 0.0000 | MSE 0.2217
2020-11-05 16:37:54,054 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.2486 | Iter Mean Loss 28.2486
2020-11-05 16:37:54,060 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5622 | Iter Mean Loss 15.9054
2020-11-05 16:37:54,065 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.4383 | Iter Mean Loss 21.4164
2020-11-05 16:37:54,071 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.8726 | Iter Mean Loss 21.5304
2020-11-05 16:37:54,076 - root - INFO - Training: Epoch 0143 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3054 | Iter Mean Loss 18.0854
2020-11-05 16:37:54,077 - root - INFO - Evaluate: Epoch 0143 | NDCG 0.0000 | MSE 0.2214
2020-11-05 16:37:54,082 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 28.0676 | Iter Mean Loss 28.0676
2020-11-05 16:37:54,088 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.5245 | Iter Mean Loss 15.7961
2020-11-05 16:37:54,094 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.2918 | Iter Mean Loss 21.2946
2020-11-05 16:37:54,100 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.7856 | Iter Mean Loss 21.4174
2020-11-05 16:37:54,105 - root - INFO - Training: Epoch 0144 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3110 | Iter Mean Loss 17.9961
2020-11-05 16:37:54,106 - root - INFO - Evaluate: Epoch 0144 | NDCG 0.0000 | MSE 0.2210
2020-11-05 16:37:54,112 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.8919 | Iter Mean Loss 27.8919
2020-11-05 16:37:54,117 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4899 | Iter Mean Loss 15.6909
2020-11-05 16:37:54,123 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.1491 | Iter Mean Loss 21.1769
2020-11-05 16:37:54,128 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.7015 | Iter Mean Loss 21.3081
2020-11-05 16:37:54,133 - root - INFO - Training: Epoch 0145 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3168 | Iter Mean Loss 17.9098
2020-11-05 16:37:54,134 - root - INFO - Evaluate: Epoch 0145 | NDCG 0.0000 | MSE 0.2207
2020-11-05 16:37:54,140 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.7212 | Iter Mean Loss 27.7212
2020-11-05 16:37:54,145 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4579 | Iter Mean Loss 15.5896
2020-11-05 16:37:54,150 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 32.0100 | Iter Mean Loss 21.0631
2020-11-05 16:37:54,156 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.6198 | Iter Mean Loss 21.2023
2020-11-05 16:37:54,160 - root - INFO - Training: Epoch 0146 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3226 | Iter Mean Loss 17.8263
2020-11-05 16:37:54,161 - root - INFO - Evaluate: Epoch 0146 | NDCG 0.0000 | MSE 0.2204
2020-11-05 16:37:54,167 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.5554 | Iter Mean Loss 27.5554
2020-11-05 16:37:54,172 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4286 | Iter Mean Loss 15.4920
2020-11-05 16:37:54,177 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.8744 | Iter Mean Loss 20.9528
2020-11-05 16:37:54,182 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.5406 | Iter Mean Loss 21.0997
2020-11-05 16:37:54,187 - root - INFO - Training: Epoch 0147 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3286 | Iter Mean Loss 17.7455
2020-11-05 16:37:54,188 - root - INFO - Evaluate: Epoch 0147 | NDCG 0.0000 | MSE 0.2201
2020-11-05 16:37:54,193 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.3940 | Iter Mean Loss 27.3940
2020-11-05 16:37:54,199 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.4015 | Iter Mean Loss 15.3978
2020-11-05 16:37:54,204 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.7420 | Iter Mean Loss 20.8458
2020-11-05 16:37:54,210 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.4634 | Iter Mean Loss 21.0002
2020-11-05 16:37:54,215 - root - INFO - Training: Epoch 0148 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3346 | Iter Mean Loss 17.6671
2020-11-05 16:37:54,216 - root - INFO - Evaluate: Epoch 0148 | NDCG 0.0000 | MSE 0.2198
2020-11-05 16:37:54,222 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.2369 | Iter Mean Loss 27.2369
2020-11-05 16:37:54,227 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3765 | Iter Mean Loss 15.3067
2020-11-05 16:37:54,233 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.6126 | Iter Mean Loss 20.7420
2020-11-05 16:37:54,239 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3882 | Iter Mean Loss 20.9036
2020-11-05 16:37:54,244 - root - INFO - Training: Epoch 0149 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3407 | Iter Mean Loss 17.5910
2020-11-05 16:37:54,245 - root - INFO - Evaluate: Epoch 0149 | NDCG 0.0000 | MSE 0.2195
2020-11-05 16:37:54,250 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 27.0839 | Iter Mean Loss 27.0839
2020-11-05 16:37:54,256 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3535 | Iter Mean Loss 15.2187
2020-11-05 16:37:54,262 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.4860 | Iter Mean Loss 20.6411
2020-11-05 16:37:54,267 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.3148 | Iter Mean Loss 20.8096
2020-11-05 16:37:54,273 - root - INFO - Training: Epoch 0150 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3467 | Iter Mean Loss 17.5170
2020-11-05 16:37:54,274 - root - INFO - Evaluate: Epoch 0150 | NDCG 0.0000 | MSE 0.2191
2020-11-05 16:37:54,280 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.9346 | Iter Mean Loss 26.9346
2020-11-05 16:37:54,285 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3322 | Iter Mean Loss 15.1334
2020-11-05 16:37:54,291 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.3622 | Iter Mean Loss 20.5430
2020-11-05 16:37:54,297 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.2430 | Iter Mean Loss 20.7180
2020-11-05 16:37:54,302 - root - INFO - Training: Epoch 0151 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3528 | Iter Mean Loss 17.4450
2020-11-05 16:37:54,303 - root - INFO - Evaluate: Epoch 0151 | NDCG 0.0000 | MSE 0.2188
2020-11-05 16:37:54,308 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.7890 | Iter Mean Loss 26.7890
2020-11-05 16:37:54,315 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.3124 | Iter Mean Loss 15.0507
2020-11-05 16:37:54,321 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.2409 | Iter Mean Loss 20.4475
2020-11-05 16:37:54,328 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1727 | Iter Mean Loss 20.6288
2020-11-05 16:37:54,334 - root - INFO - Training: Epoch 0152 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3589 | Iter Mean Loss 17.3748
2020-11-05 16:37:54,335 - root - INFO - Evaluate: Epoch 0152 | NDCG 0.0000 | MSE 0.2185
2020-11-05 16:37:54,341 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.6468 | Iter Mean Loss 26.6468
2020-11-05 16:37:54,347 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2941 | Iter Mean Loss 14.9705
2020-11-05 16:37:54,353 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.1220 | Iter Mean Loss 20.3543
2020-11-05 16:37:54,358 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.1037 | Iter Mean Loss 20.5417
2020-11-05 16:37:54,363 - root - INFO - Training: Epoch 0153 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3649 | Iter Mean Loss 17.3063
2020-11-05 16:37:54,364 - root - INFO - Evaluate: Epoch 0153 | NDCG 0.0000 | MSE 0.2182
2020-11-05 16:37:54,370 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.5079 | Iter Mean Loss 26.5079
2020-11-05 16:37:54,376 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2771 | Iter Mean Loss 14.8925
2020-11-05 16:37:54,382 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 31.0053 | Iter Mean Loss 20.2634
2020-11-05 16:37:54,388 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 21.0360 | Iter Mean Loss 20.4566
2020-11-05 16:37:54,393 - root - INFO - Training: Epoch 0154 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3708 | Iter Mean Loss 17.2394
2020-11-05 16:37:54,394 - root - INFO - Evaluate: Epoch 0154 | NDCG 0.0000 | MSE 0.2179
2020-11-05 16:37:54,400 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.3721 | Iter Mean Loss 26.3721
2020-11-05 16:37:54,406 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2612 | Iter Mean Loss 14.8166
2020-11-05 16:37:54,412 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.8908 | Iter Mean Loss 20.1747
2020-11-05 16:37:54,418 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9693 | Iter Mean Loss 20.3733
2020-11-05 16:37:54,425 - root - INFO - Training: Epoch 0155 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3767 | Iter Mean Loss 17.1740
2020-11-05 16:37:54,426 - root - INFO - Evaluate: Epoch 0155 | NDCG 0.0000 | MSE 0.2176
2020-11-05 16:37:54,432 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.2392 | Iter Mean Loss 26.2392
2020-11-05 16:37:54,439 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2463 | Iter Mean Loss 14.7427
2020-11-05 16:37:54,445 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.7782 | Iter Mean Loss 20.0879
2020-11-05 16:37:54,452 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.9037 | Iter Mean Loss 20.2919
2020-11-05 16:37:54,458 - root - INFO - Training: Epoch 0156 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3824 | Iter Mean Loss 17.1100
2020-11-05 16:37:54,459 - root - INFO - Evaluate: Epoch 0156 | NDCG 0.0000 | MSE 0.2173
2020-11-05 16:37:54,465 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 26.1091 | Iter Mean Loss 26.1091
2020-11-05 16:37:54,472 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2324 | Iter Mean Loss 14.6707
2020-11-05 16:37:54,478 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.6675 | Iter Mean Loss 20.0030
2020-11-05 16:37:54,485 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.8391 | Iter Mean Loss 20.2120
2020-11-05 16:37:54,491 - root - INFO - Training: Epoch 0157 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3881 | Iter Mean Loss 17.0472
2020-11-05 16:37:54,492 - root - INFO - Evaluate: Epoch 0157 | NDCG 0.0000 | MSE 0.2170
2020-11-05 16:37:54,498 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.9817 | Iter Mean Loss 25.9817
2020-11-05 16:37:54,504 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2193 | Iter Mean Loss 14.6005
2020-11-05 16:37:54,510 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.5587 | Iter Mean Loss 19.9199
2020-11-05 16:37:54,517 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7753 | Iter Mean Loss 20.1337
2020-11-05 16:37:54,522 - root - INFO - Training: Epoch 0158 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3937 | Iter Mean Loss 16.9857
2020-11-05 16:37:54,523 - root - INFO - Evaluate: Epoch 0158 | NDCG 0.0000 | MSE 0.2167
2020-11-05 16:37:54,529 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.8568 | Iter Mean Loss 25.8568
2020-11-05 16:37:54,535 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.2069 | Iter Mean Loss 14.5319
2020-11-05 16:37:54,541 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.4515 | Iter Mean Loss 19.8384
2020-11-05 16:37:54,547 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.7123 | Iter Mean Loss 20.0569
2020-11-05 16:37:54,552 - root - INFO - Training: Epoch 0159 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3992 | Iter Mean Loss 16.9253
2020-11-05 16:37:54,553 - root - INFO - Evaluate: Epoch 0159 | NDCG 0.0000 | MSE 0.2164
2020-11-05 16:37:54,559 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.7344 | Iter Mean Loss 25.7344
2020-11-05 16:37:54,565 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1953 | Iter Mean Loss 14.4648
2020-11-05 16:37:54,570 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.3459 | Iter Mean Loss 19.7585
2020-11-05 16:37:54,576 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.6500 | Iter Mean Loss 19.9814
2020-11-05 16:37:54,581 - root - INFO - Training: Epoch 0160 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4045 | Iter Mean Loss 16.8660
2020-11-05 16:37:54,582 - root - INFO - Evaluate: Epoch 0160 | NDCG 0.0000 | MSE 0.2161
2020-11-05 16:37:54,588 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.6143 | Iter Mean Loss 25.6143
2020-11-05 16:37:54,594 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1842 | Iter Mean Loss 14.3992
2020-11-05 16:37:54,600 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.2419 | Iter Mean Loss 19.6801
2020-11-05 16:37:54,606 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5884 | Iter Mean Loss 19.9072
2020-11-05 16:37:54,610 - root - INFO - Training: Epoch 0161 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4098 | Iter Mean Loss 16.8077
2020-11-05 16:37:54,611 - root - INFO - Evaluate: Epoch 0161 | NDCG 0.0000 | MSE 0.2158
2020-11-05 16:37:54,618 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.4964 | Iter Mean Loss 25.4964
2020-11-05 16:37:54,624 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1737 | Iter Mean Loss 14.3351
2020-11-05 16:37:54,631 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.1393 | Iter Mean Loss 19.6031
2020-11-05 16:37:54,637 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.5274 | Iter Mean Loss 19.8342
2020-11-05 16:37:54,643 - root - INFO - Training: Epoch 0162 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4148 | Iter Mean Loss 16.7503
2020-11-05 16:37:54,644 - root - INFO - Evaluate: Epoch 0162 | NDCG 0.0000 | MSE 0.2155
2020-11-05 16:37:54,650 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.3807 | Iter Mean Loss 25.3807
2020-11-05 16:37:54,656 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1637 | Iter Mean Loss 14.2722
2020-11-05 16:37:54,662 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 30.0381 | Iter Mean Loss 19.5275
2020-11-05 16:37:54,668 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.4670 | Iter Mean Loss 19.7624
2020-11-05 16:37:54,673 - root - INFO - Training: Epoch 0163 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4198 | Iter Mean Loss 16.6939
2020-11-05 16:37:54,674 - root - INFO - Evaluate: Epoch 0163 | NDCG 0.0000 | MSE 0.2153
2020-11-05 16:37:54,681 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.2670 | Iter Mean Loss 25.2670
2020-11-05 16:37:54,687 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1542 | Iter Mean Loss 14.2106
2020-11-05 16:37:54,693 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.9382 | Iter Mean Loss 19.4531
2020-11-05 16:37:54,700 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.4072 | Iter Mean Loss 19.6916
2020-11-05 16:37:54,705 - root - INFO - Training: Epoch 0164 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4246 | Iter Mean Loss 16.6382
2020-11-05 16:37:54,706 - root - INFO - Evaluate: Epoch 0164 | NDCG 0.0000 | MSE 0.2150
2020-11-05 16:37:54,713 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.1553 | Iter Mean Loss 25.1553
2020-11-05 16:37:54,719 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1450 | Iter Mean Loss 14.1502
2020-11-05 16:37:54,725 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.8396 | Iter Mean Loss 19.3800
2020-11-05 16:37:54,731 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.3478 | Iter Mean Loss 19.6220
2020-11-05 16:37:54,736 - root - INFO - Training: Epoch 0165 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4293 | Iter Mean Loss 16.5834
2020-11-05 16:37:54,737 - root - INFO - Evaluate: Epoch 0165 | NDCG 0.0000 | MSE 0.2147
2020-11-05 16:37:54,743 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 25.0455 | Iter Mean Loss 25.0455
2020-11-05 16:37:54,749 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1363 | Iter Mean Loss 14.0909
2020-11-05 16:37:54,755 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.7422 | Iter Mean Loss 19.3080
2020-11-05 16:37:54,760 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2890 | Iter Mean Loss 19.5533
2020-11-05 16:37:54,766 - root - INFO - Training: Epoch 0166 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4338 | Iter Mean Loss 16.5294
2020-11-05 16:37:54,766 - root - INFO - Evaluate: Epoch 0166 | NDCG 0.0000 | MSE 0.2145
2020-11-05 16:37:54,772 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.9376 | Iter Mean Loss 24.9376
2020-11-05 16:37:54,778 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1278 | Iter Mean Loss 14.0327
2020-11-05 16:37:54,784 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.6460 | Iter Mean Loss 19.2371
2020-11-05 16:37:54,790 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.2306 | Iter Mean Loss 19.4855
2020-11-05 16:37:54,795 - root - INFO - Training: Epoch 0167 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4382 | Iter Mean Loss 16.4761
2020-11-05 16:37:54,796 - root - INFO - Evaluate: Epoch 0167 | NDCG 0.0000 | MSE 0.2142
2020-11-05 16:37:54,802 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.8314 | Iter Mean Loss 24.8314
2020-11-05 16:37:54,808 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1197 | Iter Mean Loss 13.9756
2020-11-05 16:37:54,814 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.5509 | Iter Mean Loss 19.1673
2020-11-05 16:37:54,820 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1726 | Iter Mean Loss 19.4187
2020-11-05 16:37:54,826 - root - INFO - Training: Epoch 0168 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4425 | Iter Mean Loss 16.4234
2020-11-05 16:37:54,827 - root - INFO - Evaluate: Epoch 0168 | NDCG 0.0000 | MSE 0.2140
2020-11-05 16:37:54,834 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.7269 | Iter Mean Loss 24.7269
2020-11-05 16:37:54,840 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1119 | Iter Mean Loss 13.9194
2020-11-05 16:37:54,846 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.4568 | Iter Mean Loss 19.0985
2020-11-05 16:37:54,853 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.1151 | Iter Mean Loss 19.3527
2020-11-05 16:37:54,858 - root - INFO - Training: Epoch 0169 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4466 | Iter Mean Loss 16.3715
2020-11-05 16:37:54,859 - root - INFO - Evaluate: Epoch 0169 | NDCG 0.0000 | MSE 0.2137
2020-11-05 16:37:54,866 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.6241 | Iter Mean Loss 24.6241
2020-11-05 16:37:54,872 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.1043 | Iter Mean Loss 13.8642
2020-11-05 16:37:54,879 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.3638 | Iter Mean Loss 19.0307
2020-11-05 16:37:54,885 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0579 | Iter Mean Loss 19.2875
2020-11-05 16:37:54,891 - root - INFO - Training: Epoch 0170 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4506 | Iter Mean Loss 16.3201
2020-11-05 16:37:54,892 - root - INFO - Evaluate: Epoch 0170 | NDCG 0.0000 | MSE 0.2135
2020-11-05 16:37:54,898 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.5229 | Iter Mean Loss 24.5229
2020-11-05 16:37:54,904 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0969 | Iter Mean Loss 13.8099
2020-11-05 16:37:54,910 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.2717 | Iter Mean Loss 18.9638
2020-11-05 16:37:54,916 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 20.0012 | Iter Mean Loss 19.2232
2020-11-05 16:37:54,922 - root - INFO - Training: Epoch 0171 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4544 | Iter Mean Loss 16.2694
2020-11-05 16:37:54,923 - root - INFO - Evaluate: Epoch 0171 | NDCG 0.0000 | MSE 0.2132
2020-11-05 16:37:54,929 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.4232 | Iter Mean Loss 24.4232
2020-11-05 16:37:54,935 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0898 | Iter Mean Loss 13.7565
2020-11-05 16:37:54,941 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.1806 | Iter Mean Loss 18.8979
2020-11-05 16:37:54,947 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.9447 | Iter Mean Loss 19.1596
2020-11-05 16:37:54,952 - root - INFO - Training: Epoch 0172 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4581 | Iter Mean Loss 16.2193
2020-11-05 16:37:54,953 - root - INFO - Evaluate: Epoch 0172 | NDCG 0.0000 | MSE 0.2130
2020-11-05 16:37:54,959 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.3251 | Iter Mean Loss 24.3251
2020-11-05 16:37:54,965 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0828 | Iter Mean Loss 13.7039
2020-11-05 16:37:54,971 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.0904 | Iter Mean Loss 18.8328
2020-11-05 16:37:54,976 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8887 | Iter Mean Loss 19.0967
2020-11-05 16:37:54,981 - root - INFO - Training: Epoch 0173 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4617 | Iter Mean Loss 16.1697
2020-11-05 16:37:54,982 - root - INFO - Evaluate: Epoch 0173 | NDCG 0.0000 | MSE 0.2128
2020-11-05 16:37:54,988 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.2283 | Iter Mean Loss 24.2283
2020-11-05 16:37:54,994 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0761 | Iter Mean Loss 13.6522
2020-11-05 16:37:55,000 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 29.0011 | Iter Mean Loss 18.7685
2020-11-05 16:37:55,006 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.8330 | Iter Mean Loss 19.0346
2020-11-05 16:37:55,011 - root - INFO - Training: Epoch 0174 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4651 | Iter Mean Loss 16.1207
2020-11-05 16:37:55,012 - root - INFO - Evaluate: Epoch 0174 | NDCG 0.0000 | MSE 0.2125
2020-11-05 16:37:55,017 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.1330 | Iter Mean Loss 24.1330
2020-11-05 16:37:55,023 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0695 | Iter Mean Loss 13.6012
2020-11-05 16:37:55,029 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.9127 | Iter Mean Loss 18.7050
2020-11-05 16:37:55,036 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7776 | Iter Mean Loss 18.9732
2020-11-05 16:37:55,041 - root - INFO - Training: Epoch 0175 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4684 | Iter Mean Loss 16.0722
2020-11-05 16:37:55,042 - root - INFO - Evaluate: Epoch 0175 | NDCG 0.0000 | MSE 0.2123
2020-11-05 16:37:55,048 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 24.0390 | Iter Mean Loss 24.0390
2020-11-05 16:37:55,054 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0630 | Iter Mean Loss 13.5510
2020-11-05 16:37:55,061 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.8251 | Iter Mean Loss 18.6424
2020-11-05 16:37:55,067 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.7226 | Iter Mean Loss 18.9124
2020-11-05 16:37:55,073 - root - INFO - Training: Epoch 0176 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4716 | Iter Mean Loss 16.0242
2020-11-05 16:37:55,074 - root - INFO - Evaluate: Epoch 0176 | NDCG 0.0000 | MSE 0.2121
2020-11-05 16:37:55,080 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.9464 | Iter Mean Loss 23.9464
2020-11-05 16:37:55,086 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0567 | Iter Mean Loss 13.5016
2020-11-05 16:37:55,094 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.7382 | Iter Mean Loss 18.5805
2020-11-05 16:37:55,100 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6678 | Iter Mean Loss 18.8523
2020-11-05 16:37:55,106 - root - INFO - Training: Epoch 0177 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4746 | Iter Mean Loss 15.9768
2020-11-05 16:37:55,107 - root - INFO - Evaluate: Epoch 0177 | NDCG 0.0000 | MSE 0.2119
2020-11-05 16:37:55,113 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.8550 | Iter Mean Loss 23.8550
2020-11-05 16:37:55,119 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0506 | Iter Mean Loss 13.4528
2020-11-05 16:37:55,126 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.6522 | Iter Mean Loss 18.5193
2020-11-05 16:37:55,132 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.6134 | Iter Mean Loss 18.7928
2020-11-05 16:37:55,138 - root - INFO - Training: Epoch 0178 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4775 | Iter Mean Loss 15.9297
2020-11-05 16:37:55,139 - root - INFO - Evaluate: Epoch 0178 | NDCG 0.0000 | MSE 0.2117
2020-11-05 16:37:55,146 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.7649 | Iter Mean Loss 23.7649
2020-11-05 16:37:55,151 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0445 | Iter Mean Loss 13.4047
2020-11-05 16:37:55,157 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.5669 | Iter Mean Loss 18.4588
2020-11-05 16:37:55,163 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5593 | Iter Mean Loss 18.7339
2020-11-05 16:37:55,168 - root - INFO - Training: Epoch 0179 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4803 | Iter Mean Loss 15.8832
2020-11-05 16:37:55,169 - root - INFO - Evaluate: Epoch 0179 | NDCG 0.0000 | MSE 0.2115
2020-11-05 16:37:55,175 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.6760 | Iter Mean Loss 23.6760
2020-11-05 16:37:55,181 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0386 | Iter Mean Loss 13.3573
2020-11-05 16:37:55,187 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.4824 | Iter Mean Loss 18.3990
2020-11-05 16:37:55,193 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.5055 | Iter Mean Loss 18.6756
2020-11-05 16:37:55,198 - root - INFO - Training: Epoch 0180 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4829 | Iter Mean Loss 15.8371
2020-11-05 16:37:55,198 - root - INFO - Evaluate: Epoch 0180 | NDCG 0.0000 | MSE 0.2113
2020-11-05 16:37:55,204 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.5883 | Iter Mean Loss 23.5883
2020-11-05 16:37:55,210 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0328 | Iter Mean Loss 13.3106
2020-11-05 16:37:55,216 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.3985 | Iter Mean Loss 18.3399
2020-11-05 16:37:55,222 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.4519 | Iter Mean Loss 18.6179
2020-11-05 16:37:55,227 - root - INFO - Training: Epoch 0181 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4854 | Iter Mean Loss 15.7914
2020-11-05 16:37:55,228 - root - INFO - Evaluate: Epoch 0181 | NDCG 0.0000 | MSE 0.2111
2020-11-05 16:37:55,234 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.5018 | Iter Mean Loss 23.5018
2020-11-05 16:37:55,241 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0271 | Iter Mean Loss 13.2644
2020-11-05 16:37:55,246 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.3154 | Iter Mean Loss 18.2814
2020-11-05 16:37:55,252 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3987 | Iter Mean Loss 18.5607
2020-11-05 16:37:55,258 - root - INFO - Training: Epoch 0182 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4879 | Iter Mean Loss 15.7462
2020-11-05 16:37:55,260 - root - INFO - Evaluate: Epoch 0182 | NDCG 0.0000 | MSE 0.2109
2020-11-05 16:37:55,266 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.4163 | Iter Mean Loss 23.4163
2020-11-05 16:37:55,272 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0215 | Iter Mean Loss 13.2189
2020-11-05 16:37:55,279 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.2329 | Iter Mean Loss 18.2236
2020-11-05 16:37:55,285 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.3457 | Iter Mean Loss 18.5041
2020-11-05 16:37:55,290 - root - INFO - Training: Epoch 0183 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4902 | Iter Mean Loss 15.7013
2020-11-05 16:37:55,291 - root - INFO - Evaluate: Epoch 0183 | NDCG 0.0000 | MSE 0.2107
2020-11-05 16:37:55,298 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.3320 | Iter Mean Loss 23.3320
2020-11-05 16:37:55,304 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0160 | Iter Mean Loss 13.1740
2020-11-05 16:37:55,310 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.1511 | Iter Mean Loss 18.1664
2020-11-05 16:37:55,318 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2931 | Iter Mean Loss 18.4480
2020-11-05 16:37:55,323 - root - INFO - Training: Epoch 0184 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4924 | Iter Mean Loss 15.6569
2020-11-05 16:37:55,324 - root - INFO - Evaluate: Epoch 0184 | NDCG 0.0000 | MSE 0.2105
2020-11-05 16:37:55,331 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.2487 | Iter Mean Loss 23.2487
2020-11-05 16:37:55,337 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0106 | Iter Mean Loss 13.1296
2020-11-05 16:37:55,343 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 28.0700 | Iter Mean Loss 18.1097
2020-11-05 16:37:55,348 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.2407 | Iter Mean Loss 18.3925
2020-11-05 16:37:55,353 - root - INFO - Training: Epoch 0185 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4944 | Iter Mean Loss 15.6129
2020-11-05 16:37:55,354 - root - INFO - Evaluate: Epoch 0185 | NDCG 0.0000 | MSE 0.2103
2020-11-05 16:37:55,360 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.1664 | Iter Mean Loss 23.1664
2020-11-05 16:37:55,366 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0052 | Iter Mean Loss 13.0858
2020-11-05 16:37:55,372 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9894 | Iter Mean Loss 18.0537
2020-11-05 16:37:55,377 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1886 | Iter Mean Loss 18.3374
2020-11-05 16:37:55,382 - root - INFO - Training: Epoch 0186 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4964 | Iter Mean Loss 15.5692
2020-11-05 16:37:55,383 - root - INFO - Evaluate: Epoch 0186 | NDCG 0.0000 | MSE 0.2102
2020-11-05 16:37:55,389 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.0852 | Iter Mean Loss 23.0852
2020-11-05 16:37:55,395 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 3.0000 | Iter Mean Loss 13.0426
2020-11-05 16:37:55,400 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.9095 | Iter Mean Loss 17.9982
2020-11-05 16:37:55,406 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.1368 | Iter Mean Loss 18.2829
2020-11-05 16:37:55,411 - root - INFO - Training: Epoch 0187 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4983 | Iter Mean Loss 15.5259
2020-11-05 16:37:55,412 - root - INFO - Evaluate: Epoch 0187 | NDCG 0.0000 | MSE 0.2100
2020-11-05 16:37:55,418 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 23.0049 | Iter Mean Loss 23.0049
2020-11-05 16:37:55,423 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9948 | Iter Mean Loss 12.9999
2020-11-05 16:37:55,429 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.8302 | Iter Mean Loss 17.9433
2020-11-05 16:37:55,435 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0852 | Iter Mean Loss 18.2288
2020-11-05 16:37:55,441 - root - INFO - Training: Epoch 0188 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5000 | Iter Mean Loss 15.4830
2020-11-05 16:37:55,442 - root - INFO - Evaluate: Epoch 0188 | NDCG 0.0000 | MSE 0.2098
2020-11-05 16:37:55,448 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.9256 | Iter Mean Loss 22.9256
2020-11-05 16:37:55,454 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9897 | Iter Mean Loss 12.9576
2020-11-05 16:37:55,460 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.7514 | Iter Mean Loss 17.8889
2020-11-05 16:37:55,466 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 19.0339 | Iter Mean Loss 18.1752
2020-11-05 16:37:55,471 - root - INFO - Training: Epoch 0189 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5017 | Iter Mean Loss 15.4405
2020-11-05 16:37:55,473 - root - INFO - Evaluate: Epoch 0189 | NDCG 0.0000 | MSE 0.2097
2020-11-05 16:37:55,480 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.8472 | Iter Mean Loss 22.8472
2020-11-05 16:37:55,485 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9846 | Iter Mean Loss 12.9159
2020-11-05 16:37:55,492 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.6732 | Iter Mean Loss 17.8350
2020-11-05 16:37:55,498 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9829 | Iter Mean Loss 18.1220
2020-11-05 16:37:55,503 - root - INFO - Training: Epoch 0190 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5032 | Iter Mean Loss 15.3983
2020-11-05 16:37:55,504 - root - INFO - Evaluate: Epoch 0190 | NDCG 0.0000 | MSE 0.2095
2020-11-05 16:37:55,511 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.7698 | Iter Mean Loss 22.7698
2020-11-05 16:37:55,516 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9797 | Iter Mean Loss 12.8747
2020-11-05 16:37:55,522 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.5956 | Iter Mean Loss 17.7817
2020-11-05 16:37:55,528 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.9321 | Iter Mean Loss 18.0693
2020-11-05 16:37:55,534 - root - INFO - Training: Epoch 0191 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5047 | Iter Mean Loss 15.3564
2020-11-05 16:37:55,535 - root - INFO - Evaluate: Epoch 0191 | NDCG 0.0000 | MSE 0.2094
2020-11-05 16:37:55,541 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6932 | Iter Mean Loss 22.6932
2020-11-05 16:37:55,546 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9748 | Iter Mean Loss 12.8340
2020-11-05 16:37:55,552 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.5185 | Iter Mean Loss 17.7288
2020-11-05 16:37:55,557 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8816 | Iter Mean Loss 18.0170
2020-11-05 16:37:55,562 - root - INFO - Training: Epoch 0192 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5061 | Iter Mean Loss 15.3148
2020-11-05 16:37:55,563 - root - INFO - Evaluate: Epoch 0192 | NDCG 0.0000 | MSE 0.2092
2020-11-05 16:37:55,569 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.6175 | Iter Mean Loss 22.6175
2020-11-05 16:37:55,574 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9699 | Iter Mean Loss 12.7937
2020-11-05 16:37:55,580 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.4420 | Iter Mean Loss 17.6765
2020-11-05 16:37:55,585 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.8314 | Iter Mean Loss 17.9652
2020-11-05 16:37:55,590 - root - INFO - Training: Epoch 0193 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5074 | Iter Mean Loss 15.2736
2020-11-05 16:37:55,591 - root - INFO - Evaluate: Epoch 0193 | NDCG 0.0000 | MSE 0.2091
2020-11-05 16:37:55,597 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.5427 | Iter Mean Loss 22.5427
2020-11-05 16:37:55,602 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9651 | Iter Mean Loss 12.7539
2020-11-05 16:37:55,608 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.3660 | Iter Mean Loss 17.6246
2020-11-05 16:37:55,613 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7814 | Iter Mean Loss 17.9138
2020-11-05 16:37:55,618 - root - INFO - Training: Epoch 0194 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5086 | Iter Mean Loss 15.2328
2020-11-05 16:37:55,619 - root - INFO - Evaluate: Epoch 0194 | NDCG 0.0000 | MSE 0.2089
2020-11-05 16:37:55,625 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.4687 | Iter Mean Loss 22.4687
2020-11-05 16:37:55,631 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9604 | Iter Mean Loss 12.7145
2020-11-05 16:37:55,638 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.2905 | Iter Mean Loss 17.5732
2020-11-05 16:37:55,643 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.7317 | Iter Mean Loss 17.8628
2020-11-05 16:37:55,649 - root - INFO - Training: Epoch 0195 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5097 | Iter Mean Loss 15.1922
2020-11-05 16:37:55,650 - root - INFO - Evaluate: Epoch 0195 | NDCG 0.0000 | MSE 0.2088
2020-11-05 16:37:55,656 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3955 | Iter Mean Loss 22.3955
2020-11-05 16:37:55,662 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9557 | Iter Mean Loss 12.6756
2020-11-05 16:37:55,669 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.2155 | Iter Mean Loss 17.5222
2020-11-05 16:37:55,674 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6822 | Iter Mean Loss 17.8122
2020-11-05 16:37:55,679 - root - INFO - Training: Epoch 0196 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5107 | Iter Mean Loss 15.1519
2020-11-05 16:37:55,681 - root - INFO - Evaluate: Epoch 0196 | NDCG 0.0000 | MSE 0.2086
2020-11-05 16:37:55,688 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.3231 | Iter Mean Loss 22.3231
2020-11-05 16:37:55,693 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9511 | Iter Mean Loss 12.6371
2020-11-05 16:37:55,700 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.1410 | Iter Mean Loss 17.4717
2020-11-05 16:37:55,705 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.6330 | Iter Mean Loss 17.7621
2020-11-05 16:37:55,710 - root - INFO - Training: Epoch 0197 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5116 | Iter Mean Loss 15.1120
2020-11-05 16:37:55,712 - root - INFO - Evaluate: Epoch 0197 | NDCG 0.0000 | MSE 0.2085
2020-11-05 16:37:55,718 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.2515 | Iter Mean Loss 22.2515
2020-11-05 16:37:55,724 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9465 | Iter Mean Loss 12.5990
2020-11-05 16:37:55,730 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 27.0670 | Iter Mean Loss 17.4217
2020-11-05 16:37:55,737 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5841 | Iter Mean Loss 17.7123
2020-11-05 16:37:55,742 - root - INFO - Training: Epoch 0198 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5125 | Iter Mean Loss 15.0723
2020-11-05 16:37:55,743 - root - INFO - Evaluate: Epoch 0198 | NDCG 0.0000 | MSE 0.2084
2020-11-05 16:37:55,748 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.1806 | Iter Mean Loss 22.1806
2020-11-05 16:37:55,754 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9420 | Iter Mean Loss 12.5613
2020-11-05 16:37:55,759 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.9935 | Iter Mean Loss 17.3720
2020-11-05 16:37:55,765 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.5354 | Iter Mean Loss 17.6629
2020-11-05 16:37:55,769 - root - INFO - Training: Epoch 0199 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5133 | Iter Mean Loss 15.0329
2020-11-05 16:37:55,770 - root - INFO - Evaluate: Epoch 0199 | NDCG 0.0000 | MSE 0.2082
2020-11-05 16:37:55,776 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.1105 | Iter Mean Loss 22.1105
2020-11-05 16:37:55,781 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9375 | Iter Mean Loss 12.5240
2020-11-05 16:37:55,787 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.9204 | Iter Mean Loss 17.3228
2020-11-05 16:37:55,792 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4869 | Iter Mean Loss 17.6138
2020-11-05 16:37:55,797 - root - INFO - Training: Epoch 0200 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5140 | Iter Mean Loss 14.9939
2020-11-05 16:37:55,798 - root - INFO - Evaluate: Epoch 0200 | NDCG 0.0000 | MSE 0.2081
2020-11-05 16:37:55,804 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 22.0411 | Iter Mean Loss 22.0411
2020-11-05 16:37:55,809 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9331 | Iter Mean Loss 12.4871
2020-11-05 16:37:55,815 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.8479 | Iter Mean Loss 17.2740
2020-11-05 16:37:55,820 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.4387 | Iter Mean Loss 17.5652
2020-11-05 16:37:55,825 - root - INFO - Training: Epoch 0201 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5146 | Iter Mean Loss 14.9551
2020-11-05 16:37:55,826 - root - INFO - Evaluate: Epoch 0201 | NDCG 0.0000 | MSE 0.2080
2020-11-05 16:37:55,831 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.9725 | Iter Mean Loss 21.9725
2020-11-05 16:37:55,837 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9287 | Iter Mean Loss 12.4506
2020-11-05 16:37:55,842 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7757 | Iter Mean Loss 17.2256
2020-11-05 16:37:55,849 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3907 | Iter Mean Loss 17.5169
2020-11-05 16:37:55,854 - root - INFO - Training: Epoch 0202 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5151 | Iter Mean Loss 14.9166
2020-11-05 16:37:55,854 - root - INFO - Evaluate: Epoch 0202 | NDCG 0.0000 | MSE 0.2078
2020-11-05 16:37:55,860 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.9045 | Iter Mean Loss 21.9045
2020-11-05 16:37:55,866 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9244 | Iter Mean Loss 12.4144
2020-11-05 16:37:55,873 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.7041 | Iter Mean Loss 17.1776
2020-11-05 16:37:55,878 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.3430 | Iter Mean Loss 17.4690
2020-11-05 16:37:55,884 - root - INFO - Training: Epoch 0203 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5156 | Iter Mean Loss 14.8783
2020-11-05 16:37:55,885 - root - INFO - Evaluate: Epoch 0203 | NDCG 0.0000 | MSE 0.2077
2020-11-05 16:37:55,891 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.8372 | Iter Mean Loss 21.8372
2020-11-05 16:37:55,896 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9201 | Iter Mean Loss 12.3786
2020-11-05 16:37:55,903 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.6328 | Iter Mean Loss 17.1300
2020-11-05 16:37:55,909 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2955 | Iter Mean Loss 17.4214
2020-11-05 16:37:55,914 - root - INFO - Training: Epoch 0204 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5160 | Iter Mean Loss 14.8403
2020-11-05 16:37:55,916 - root - INFO - Evaluate: Epoch 0204 | NDCG 0.0000 | MSE 0.2076
2020-11-05 16:37:55,922 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7706 | Iter Mean Loss 21.7706
2020-11-05 16:37:55,927 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9158 | Iter Mean Loss 12.3432
2020-11-05 16:37:55,933 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.5620 | Iter Mean Loss 17.0828
2020-11-05 16:37:55,939 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2482 | Iter Mean Loss 17.3742
2020-11-05 16:37:55,944 - root - INFO - Training: Epoch 0205 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5164 | Iter Mean Loss 14.8026
2020-11-05 16:37:55,945 - root - INFO - Evaluate: Epoch 0205 | NDCG 0.0000 | MSE 0.2075
2020-11-05 16:37:55,950 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.7047 | Iter Mean Loss 21.7047
2020-11-05 16:37:55,956 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9116 | Iter Mean Loss 12.3081
2020-11-05 16:37:55,961 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4916 | Iter Mean Loss 17.0360
2020-11-05 16:37:55,967 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.2012 | Iter Mean Loss 17.3273
2020-11-05 16:37:55,972 - root - INFO - Training: Epoch 0206 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5167 | Iter Mean Loss 14.7652
2020-11-05 16:37:55,972 - root - INFO - Evaluate: Epoch 0206 | NDCG 0.0000 | MSE 0.2074
2020-11-05 16:37:55,978 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.6394 | Iter Mean Loss 21.6394
2020-11-05 16:37:55,983 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9074 | Iter Mean Loss 12.2734
2020-11-05 16:37:55,989 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.4217 | Iter Mean Loss 16.9895
2020-11-05 16:37:55,994 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1544 | Iter Mean Loss 17.2807
2020-11-05 16:37:55,999 - root - INFO - Training: Epoch 0207 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5169 | Iter Mean Loss 14.7280
2020-11-05 16:37:56,000 - root - INFO - Evaluate: Epoch 0207 | NDCG 0.0000 | MSE 0.2073
2020-11-05 16:37:56,005 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.5747 | Iter Mean Loss 21.5747
2020-11-05 16:37:56,011 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.9032 | Iter Mean Loss 12.2390
2020-11-05 16:37:56,016 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.3522 | Iter Mean Loss 16.9434
2020-11-05 16:37:56,022 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.1079 | Iter Mean Loss 17.2345
2020-11-05 16:37:56,026 - root - INFO - Training: Epoch 0208 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5170 | Iter Mean Loss 14.6910
2020-11-05 16:37:56,027 - root - INFO - Evaluate: Epoch 0208 | NDCG 0.0000 | MSE 0.2071
2020-11-05 16:37:56,033 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.5107 | Iter Mean Loss 21.5107
2020-11-05 16:37:56,038 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8991 | Iter Mean Loss 12.2049
2020-11-05 16:37:56,044 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2831 | Iter Mean Loss 16.8976
2020-11-05 16:37:56,050 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0616 | Iter Mean Loss 17.1886
2020-11-05 16:37:56,055 - root - INFO - Training: Epoch 0209 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 14.6543
2020-11-05 16:37:56,056 - root - INFO - Evaluate: Epoch 0209 | NDCG 0.0000 | MSE 0.2070
2020-11-05 16:37:56,061 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.4472 | Iter Mean Loss 21.4472
2020-11-05 16:37:56,067 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8951 | Iter Mean Loss 12.1711
2020-11-05 16:37:56,074 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.2143 | Iter Mean Loss 16.8522
2020-11-05 16:37:56,079 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 18.0155 | Iter Mean Loss 17.1430
2020-11-05 16:37:56,084 - root - INFO - Training: Epoch 0210 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5172 | Iter Mean Loss 14.6179
2020-11-05 16:37:56,086 - root - INFO - Evaluate: Epoch 0210 | NDCG 0.0000 | MSE 0.2069
2020-11-05 16:37:56,093 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.3844 | Iter Mean Loss 21.3844
2020-11-05 16:37:56,099 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8910 | Iter Mean Loss 12.1377
2020-11-05 16:37:56,105 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.1460 | Iter Mean Loss 16.8071
2020-11-05 16:37:56,111 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9696 | Iter Mean Loss 17.0978
2020-11-05 16:37:56,115 - root - INFO - Training: Epoch 0211 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5172 | Iter Mean Loss 14.5816
2020-11-05 16:37:56,116 - root - INFO - Evaluate: Epoch 0211 | NDCG 0.0000 | MSE 0.2068
2020-11-05 16:37:56,123 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.3221 | Iter Mean Loss 21.3221
2020-11-05 16:37:56,129 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8870 | Iter Mean Loss 12.1046
2020-11-05 16:37:56,134 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.0781 | Iter Mean Loss 16.7624
2020-11-05 16:37:56,141 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.9240 | Iter Mean Loss 17.0528
2020-11-05 16:37:56,146 - root - INFO - Training: Epoch 0212 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5171 | Iter Mean Loss 14.5457
2020-11-05 16:37:56,146 - root - INFO - Evaluate: Epoch 0212 | NDCG 0.0000 | MSE 0.2067
2020-11-05 16:37:56,152 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.2604 | Iter Mean Loss 21.2604
2020-11-05 16:37:56,157 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8830 | Iter Mean Loss 12.0717
2020-11-05 16:37:56,163 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 26.0106 | Iter Mean Loss 16.7180
2020-11-05 16:37:56,168 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8785 | Iter Mean Loss 17.0081
2020-11-05 16:37:56,173 - root - INFO - Training: Epoch 0213 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5170 | Iter Mean Loss 14.5099
2020-11-05 16:37:56,174 - root - INFO - Evaluate: Epoch 0213 | NDCG 0.0000 | MSE 0.2066
2020-11-05 16:37:56,179 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.1993 | Iter Mean Loss 21.1993
2020-11-05 16:37:56,184 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8791 | Iter Mean Loss 12.0392
2020-11-05 16:37:56,190 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.9434 | Iter Mean Loss 16.6739
2020-11-05 16:37:56,195 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.8333 | Iter Mean Loss 16.9638
2020-11-05 16:37:56,200 - root - INFO - Training: Epoch 0214 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5168 | Iter Mean Loss 14.4744
2020-11-05 16:37:56,200 - root - INFO - Evaluate: Epoch 0214 | NDCG 0.0000 | MSE 0.2065
2020-11-05 16:37:56,206 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.1387 | Iter Mean Loss 21.1387
2020-11-05 16:37:56,211 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8752 | Iter Mean Loss 12.0069
2020-11-05 16:37:56,217 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8767 | Iter Mean Loss 16.6302
2020-11-05 16:37:56,222 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7884 | Iter Mean Loss 16.9197
2020-11-05 16:37:56,227 - root - INFO - Training: Epoch 0215 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5165 | Iter Mean Loss 14.4391
2020-11-05 16:37:56,227 - root - INFO - Evaluate: Epoch 0215 | NDCG 0.0000 | MSE 0.2064
2020-11-05 16:37:56,233 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.0787 | Iter Mean Loss 21.0787
2020-11-05 16:37:56,238 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8713 | Iter Mean Loss 11.9750
2020-11-05 16:37:56,243 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.8103 | Iter Mean Loss 16.5867
2020-11-05 16:37:56,249 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.7436 | Iter Mean Loss 16.8760
2020-11-05 16:37:56,255 - root - INFO - Training: Epoch 0216 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5163 | Iter Mean Loss 14.4040
2020-11-05 16:37:56,256 - root - INFO - Evaluate: Epoch 0216 | NDCG 0.0000 | MSE 0.2063
2020-11-05 16:37:56,261 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 21.0192 | Iter Mean Loss 21.0192
2020-11-05 16:37:56,267 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8674 | Iter Mean Loss 11.9433
2020-11-05 16:37:56,273 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.7443 | Iter Mean Loss 16.5436
2020-11-05 16:37:56,279 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6990 | Iter Mean Loss 16.8325
2020-11-05 16:37:56,284 - root - INFO - Training: Epoch 0217 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5159 | Iter Mean Loss 14.3692
2020-11-05 16:37:56,285 - root - INFO - Evaluate: Epoch 0217 | NDCG 0.0000 | MSE 0.2062
2020-11-05 16:37:56,291 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9602 | Iter Mean Loss 20.9602
2020-11-05 16:37:56,297 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8636 | Iter Mean Loss 11.9119
2020-11-05 16:37:56,303 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6786 | Iter Mean Loss 16.5008
2020-11-05 16:37:56,309 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6547 | Iter Mean Loss 16.7893
2020-11-05 16:37:56,314 - root - INFO - Training: Epoch 0218 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5156 | Iter Mean Loss 14.3345
2020-11-05 16:37:56,315 - root - INFO - Evaluate: Epoch 0218 | NDCG 0.0000 | MSE 0.2061
2020-11-05 16:37:56,323 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.9017 | Iter Mean Loss 20.9017
2020-11-05 16:37:56,329 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8598 | Iter Mean Loss 11.8808
2020-11-05 16:37:56,334 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.6133 | Iter Mean Loss 16.4583
2020-11-05 16:37:56,340 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.6105 | Iter Mean Loss 16.7463
2020-11-05 16:37:56,346 - root - INFO - Training: Epoch 0219 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5151 | Iter Mean Loss 14.3001
2020-11-05 16:37:56,346 - root - INFO - Evaluate: Epoch 0219 | NDCG 0.0000 | MSE 0.2061
2020-11-05 16:37:56,352 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.8438 | Iter Mean Loss 20.8438
2020-11-05 16:37:56,358 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8560 | Iter Mean Loss 11.8499
2020-11-05 16:37:56,363 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.5484 | Iter Mean Loss 16.4161
2020-11-05 16:37:56,368 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5666 | Iter Mean Loss 16.7037
2020-11-05 16:37:56,373 - root - INFO - Training: Epoch 0220 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5147 | Iter Mean Loss 14.2659
2020-11-05 16:37:56,374 - root - INFO - Evaluate: Epoch 0220 | NDCG 0.0000 | MSE 0.2060
2020-11-05 16:37:56,379 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.7863 | Iter Mean Loss 20.7863
2020-11-05 16:37:56,385 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8523 | Iter Mean Loss 11.8193
2020-11-05 16:37:56,390 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.4838 | Iter Mean Loss 16.3741
2020-11-05 16:37:56,399 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.5228 | Iter Mean Loss 16.6613
2020-11-05 16:37:56,407 - root - INFO - Training: Epoch 0221 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5142 | Iter Mean Loss 14.2319
2020-11-05 16:37:56,408 - root - INFO - Evaluate: Epoch 0221 | NDCG 0.0000 | MSE 0.2059
2020-11-05 16:37:56,417 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.7293 | Iter Mean Loss 20.7293
2020-11-05 16:37:56,425 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8486 | Iter Mean Loss 11.7889
2020-11-05 16:37:56,433 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.4196 | Iter Mean Loss 16.3325
2020-11-05 16:37:56,440 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4793 | Iter Mean Loss 16.6192
2020-11-05 16:37:56,446 - root - INFO - Training: Epoch 0222 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5136 | Iter Mean Loss 14.1981
2020-11-05 16:37:56,447 - root - INFO - Evaluate: Epoch 0222 | NDCG 0.0000 | MSE 0.2058
2020-11-05 16:37:56,453 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6728 | Iter Mean Loss 20.6728
2020-11-05 16:37:56,460 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8449 | Iter Mean Loss 11.7588
2020-11-05 16:37:56,465 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.3557 | Iter Mean Loss 16.2911
2020-11-05 16:37:56,471 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.4360 | Iter Mean Loss 16.5773
2020-11-05 16:37:56,476 - root - INFO - Training: Epoch 0223 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5130 | Iter Mean Loss 14.1645
2020-11-05 16:37:56,478 - root - INFO - Evaluate: Epoch 0223 | NDCG 0.0000 | MSE 0.2057
2020-11-05 16:37:56,484 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.6168 | Iter Mean Loss 20.6168
2020-11-05 16:37:56,490 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8412 | Iter Mean Loss 11.7290
2020-11-05 16:37:56,497 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2921 | Iter Mean Loss 16.2500
2020-11-05 16:37:56,503 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3928 | Iter Mean Loss 16.5357
2020-11-05 16:37:56,508 - root - INFO - Training: Epoch 0224 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5124 | Iter Mean Loss 14.1311
2020-11-05 16:37:56,509 - root - INFO - Evaluate: Epoch 0224 | NDCG 0.0000 | MSE 0.2056
2020-11-05 16:37:56,516 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.5612 | Iter Mean Loss 20.5612
2020-11-05 16:37:56,522 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8375 | Iter Mean Loss 11.6994
2020-11-05 16:37:56,528 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.2289 | Iter Mean Loss 16.2092
2020-11-05 16:37:56,534 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3499 | Iter Mean Loss 16.4944
2020-11-05 16:37:56,540 - root - INFO - Training: Epoch 0225 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5117 | Iter Mean Loss 14.0978
2020-11-05 16:37:56,541 - root - INFO - Evaluate: Epoch 0225 | NDCG 0.0000 | MSE 0.2055
2020-11-05 16:37:56,548 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.5061 | Iter Mean Loss 20.5061
2020-11-05 16:37:56,553 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8339 | Iter Mean Loss 11.6700
2020-11-05 16:37:56,559 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1661 | Iter Mean Loss 16.1687
2020-11-05 16:37:56,565 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.3071 | Iter Mean Loss 16.4533
2020-11-05 16:37:56,569 - root - INFO - Training: Epoch 0226 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5110 | Iter Mean Loss 14.0648
2020-11-05 16:37:56,570 - root - INFO - Evaluate: Epoch 0226 | NDCG 0.0000 | MSE 0.2054
2020-11-05 16:37:56,576 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.4514 | Iter Mean Loss 20.4514
2020-11-05 16:37:56,582 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8303 | Iter Mean Loss 11.6408
2020-11-05 16:37:56,588 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.1035 | Iter Mean Loss 16.1284
2020-11-05 16:37:56,593 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2645 | Iter Mean Loss 16.4124
2020-11-05 16:37:56,598 - root - INFO - Training: Epoch 0227 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5102 | Iter Mean Loss 14.0320
2020-11-05 16:37:56,598 - root - INFO - Evaluate: Epoch 0227 | NDCG 0.0000 | MSE 0.2054
2020-11-05 16:37:56,604 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3972 | Iter Mean Loss 20.3972
2020-11-05 16:37:56,609 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8267 | Iter Mean Loss 11.6119
2020-11-05 16:37:56,614 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 25.0413 | Iter Mean Loss 16.0884
2020-11-05 16:37:56,620 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.2222 | Iter Mean Loss 16.3718
2020-11-05 16:37:56,624 - root - INFO - Training: Epoch 0228 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5095 | Iter Mean Loss 13.9994
2020-11-05 16:37:56,625 - root - INFO - Evaluate: Epoch 0228 | NDCG 0.0000 | MSE 0.2053
2020-11-05 16:37:56,631 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.3434 | Iter Mean Loss 20.3434
2020-11-05 16:37:56,637 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8231 | Iter Mean Loss 11.5832
2020-11-05 16:37:56,642 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9794 | Iter Mean Loss 16.0486
2020-11-05 16:37:56,647 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1800 | Iter Mean Loss 16.3315
2020-11-05 16:37:56,652 - root - INFO - Training: Epoch 0229 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5086 | Iter Mean Loss 13.9669
2020-11-05 16:37:56,653 - root - INFO - Evaluate: Epoch 0229 | NDCG 0.0000 | MSE 0.2052
2020-11-05 16:37:56,659 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.2900 | Iter Mean Loss 20.2900
2020-11-05 16:37:56,665 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8196 | Iter Mean Loss 11.5548
2020-11-05 16:37:56,670 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.9178 | Iter Mean Loss 16.0091
2020-11-05 16:37:56,676 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.1379 | Iter Mean Loss 16.2913
2020-11-05 16:37:56,681 - root - INFO - Training: Epoch 0230 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5078 | Iter Mean Loss 13.9346
2020-11-05 16:37:56,682 - root - INFO - Evaluate: Epoch 0230 | NDCG 0.0000 | MSE 0.2051
2020-11-05 16:37:56,687 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.2370 | Iter Mean Loss 20.2370
2020-11-05 16:37:56,693 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8160 | Iter Mean Loss 11.5265
2020-11-05 16:37:56,699 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.8566 | Iter Mean Loss 15.9699
2020-11-05 16:37:56,704 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0961 | Iter Mean Loss 16.2514
2020-11-05 16:37:56,710 - root - INFO - Training: Epoch 0231 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5069 | Iter Mean Loss 13.9025
2020-11-05 16:37:56,711 - root - INFO - Evaluate: Epoch 0231 | NDCG 0.0000 | MSE 0.2050
2020-11-05 16:37:56,717 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.1845 | Iter Mean Loss 20.1845
2020-11-05 16:37:56,722 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8125 | Iter Mean Loss 11.4985
2020-11-05 16:37:56,728 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.7956 | Iter Mean Loss 15.9309
2020-11-05 16:37:56,734 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0544 | Iter Mean Loss 16.2118
2020-11-05 16:37:56,739 - root - INFO - Training: Epoch 0232 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5060 | Iter Mean Loss 13.8706
2020-11-05 16:37:56,739 - root - INFO - Evaluate: Epoch 0232 | NDCG 0.0000 | MSE 0.2050
2020-11-05 16:37:56,745 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.1323 | Iter Mean Loss 20.1323
2020-11-05 16:37:56,751 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8090 | Iter Mean Loss 11.4707
2020-11-05 16:37:56,756 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.7350 | Iter Mean Loss 15.8921
2020-11-05 16:37:56,762 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 17.0130 | Iter Mean Loss 16.1723
2020-11-05 16:37:56,766 - root - INFO - Training: Epoch 0233 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5050 | Iter Mean Loss 13.8389
2020-11-05 16:37:56,767 - root - INFO - Evaluate: Epoch 0233 | NDCG 0.0000 | MSE 0.2049
2020-11-05 16:37:56,773 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0806 | Iter Mean Loss 20.0806
2020-11-05 16:37:56,778 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8055 | Iter Mean Loss 11.4430
2020-11-05 16:37:56,784 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6747 | Iter Mean Loss 15.8536
2020-11-05 16:37:56,789 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9716 | Iter Mean Loss 16.1331
2020-11-05 16:37:56,793 - root - INFO - Training: Epoch 0234 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5041 | Iter Mean Loss 13.8073
2020-11-05 16:37:56,794 - root - INFO - Evaluate: Epoch 0234 | NDCG 0.0000 | MSE 0.2048
2020-11-05 16:37:56,800 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 20.0292 | Iter Mean Loss 20.0292
2020-11-05 16:37:56,805 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.8020 | Iter Mean Loss 11.4156
2020-11-05 16:37:56,810 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.6147 | Iter Mean Loss 15.8153
2020-11-05 16:37:56,816 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.9305 | Iter Mean Loss 16.0941
2020-11-05 16:37:56,820 - root - INFO - Training: Epoch 0235 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5031 | Iter Mean Loss 13.7759
2020-11-05 16:37:56,821 - root - INFO - Evaluate: Epoch 0235 | NDCG 0.0000 | MSE 0.2047
2020-11-05 16:37:56,827 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.9783 | Iter Mean Loss 19.9783
2020-11-05 16:37:56,832 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7986 | Iter Mean Loss 11.3884
2020-11-05 16:37:56,837 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.5549 | Iter Mean Loss 15.7773
2020-11-05 16:37:56,842 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8895 | Iter Mean Loss 16.0553
2020-11-05 16:37:56,847 - root - INFO - Training: Epoch 0236 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5020 | Iter Mean Loss 13.7447
2020-11-05 16:37:56,848 - root - INFO - Evaluate: Epoch 0236 | NDCG 0.0000 | MSE 0.2047
2020-11-05 16:37:56,854 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.9277 | Iter Mean Loss 19.9277
2020-11-05 16:37:56,860 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7951 | Iter Mean Loss 11.3614
2020-11-05 16:37:56,866 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4955 | Iter Mean Loss 15.7394
2020-11-05 16:37:56,872 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8487 | Iter Mean Loss 16.0167
2020-11-05 16:37:56,878 - root - INFO - Training: Epoch 0237 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.5009 | Iter Mean Loss 13.7136
2020-11-05 16:37:56,879 - root - INFO - Evaluate: Epoch 0237 | NDCG 0.0000 | MSE 0.2046
2020-11-05 16:37:56,886 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.8775 | Iter Mean Loss 19.8775
2020-11-05 16:37:56,892 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7917 | Iter Mean Loss 11.3346
2020-11-05 16:37:56,899 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.4364 | Iter Mean Loss 15.7018
2020-11-05 16:37:56,906 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.8081 | Iter Mean Loss 15.9784
2020-11-05 16:37:56,911 - root - INFO - Training: Epoch 0238 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4999 | Iter Mean Loss 13.6827
2020-11-05 16:37:56,913 - root - INFO - Evaluate: Epoch 0238 | NDCG 0.0000 | MSE 0.2045
2020-11-05 16:37:56,920 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.8276 | Iter Mean Loss 19.8276
2020-11-05 16:37:56,926 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7883 | Iter Mean Loss 11.3079
2020-11-05 16:37:56,933 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.3775 | Iter Mean Loss 15.6645
2020-11-05 16:37:56,939 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7676 | Iter Mean Loss 15.9402
2020-11-05 16:37:56,945 - root - INFO - Training: Epoch 0239 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4987 | Iter Mean Loss 13.6519
2020-11-05 16:37:56,947 - root - INFO - Evaluate: Epoch 0239 | NDCG 0.0000 | MSE 0.2045
2020-11-05 16:37:56,953 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7781 | Iter Mean Loss 19.7781
2020-11-05 16:37:56,959 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7849 | Iter Mean Loss 11.2815
2020-11-05 16:37:56,965 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.3190 | Iter Mean Loss 15.6273
2020-11-05 16:37:56,971 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.7272 | Iter Mean Loss 15.9023
2020-11-05 16:37:56,976 - root - INFO - Training: Epoch 0240 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4976 | Iter Mean Loss 13.6214
2020-11-05 16:37:56,976 - root - INFO - Evaluate: Epoch 0240 | NDCG 0.0000 | MSE 0.2044
2020-11-05 16:37:56,982 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.7290 | Iter Mean Loss 19.7290
2020-11-05 16:37:56,988 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7815 | Iter Mean Loss 11.2552
2020-11-05 16:37:56,994 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2607 | Iter Mean Loss 15.5904
2020-11-05 16:37:56,999 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6871 | Iter Mean Loss 15.8646
2020-11-05 16:37:57,004 - root - INFO - Training: Epoch 0241 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4964 | Iter Mean Loss 13.5909
2020-11-05 16:37:57,005 - root - INFO - Evaluate: Epoch 0241 | NDCG 0.0000 | MSE 0.2043
2020-11-05 16:37:57,011 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.6802 | Iter Mean Loss 19.6802
2020-11-05 16:37:57,017 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7781 | Iter Mean Loss 11.2292
2020-11-05 16:37:57,023 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.2027 | Iter Mean Loss 15.5537
2020-11-05 16:37:57,028 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6470 | Iter Mean Loss 15.8270
2020-11-05 16:37:57,033 - root - INFO - Training: Epoch 0242 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4952 | Iter Mean Loss 13.5607
2020-11-05 16:37:57,034 - root - INFO - Evaluate: Epoch 0242 | NDCG 0.0000 | MSE 0.2042
2020-11-05 16:37:57,040 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.6318 | Iter Mean Loss 19.6318
2020-11-05 16:37:57,046 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7748 | Iter Mean Loss 11.2033
2020-11-05 16:37:57,052 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.1450 | Iter Mean Loss 15.5172
2020-11-05 16:37:57,058 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.6072 | Iter Mean Loss 15.7897
2020-11-05 16:37:57,064 - root - INFO - Training: Epoch 0243 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4940 | Iter Mean Loss 13.5305
2020-11-05 16:37:57,065 - root - INFO - Evaluate: Epoch 0243 | NDCG 0.0000 | MSE 0.2042
2020-11-05 16:37:57,071 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.5837 | Iter Mean Loss 19.5837
2020-11-05 16:37:57,078 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7714 | Iter Mean Loss 11.1775
2020-11-05 16:37:57,084 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0875 | Iter Mean Loss 15.4809
2020-11-05 16:37:57,090 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5674 | Iter Mean Loss 15.7525
2020-11-05 16:37:57,098 - root - INFO - Training: Epoch 0244 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4927 | Iter Mean Loss 13.5006
2020-11-05 16:37:57,099 - root - INFO - Evaluate: Epoch 0244 | NDCG 0.0000 | MSE 0.2041
2020-11-05 16:37:57,105 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.5359 | Iter Mean Loss 19.5359
2020-11-05 16:37:57,112 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7680 | Iter Mean Loss 11.1520
2020-11-05 16:37:57,118 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 24.0304 | Iter Mean Loss 15.4448
2020-11-05 16:37:57,124 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.5279 | Iter Mean Loss 15.7156
2020-11-05 16:37:57,130 - root - INFO - Training: Epoch 0245 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4915 | Iter Mean Loss 13.4707
2020-11-05 16:37:57,131 - root - INFO - Evaluate: Epoch 0245 | NDCG 0.0000 | MSE 0.2040
2020-11-05 16:37:57,137 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4885 | Iter Mean Loss 19.4885
2020-11-05 16:37:57,143 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7647 | Iter Mean Loss 11.1266
2020-11-05 16:37:57,148 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.9735 | Iter Mean Loss 15.4089
2020-11-05 16:37:57,155 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4884 | Iter Mean Loss 15.6788
2020-11-05 16:37:57,160 - root - INFO - Training: Epoch 0246 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4902 | Iter Mean Loss 13.4411
2020-11-05 16:37:57,161 - root - INFO - Evaluate: Epoch 0246 | NDCG 0.0000 | MSE 0.2040
2020-11-05 16:37:57,167 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.4414 | Iter Mean Loss 19.4414
2020-11-05 16:37:57,172 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7614 | Iter Mean Loss 11.1014
2020-11-05 16:37:57,178 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.9169 | Iter Mean Loss 15.3732
2020-11-05 16:37:57,184 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4491 | Iter Mean Loss 15.6422
2020-11-05 16:37:57,189 - root - INFO - Training: Epoch 0247 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4889 | Iter Mean Loss 13.4115
2020-11-05 16:37:57,190 - root - INFO - Evaluate: Epoch 0247 | NDCG 0.0000 | MSE 0.2039
2020-11-05 16:37:57,195 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3946 | Iter Mean Loss 19.3946
2020-11-05 16:37:57,201 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7581 | Iter Mean Loss 11.0764
2020-11-05 16:37:57,207 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8605 | Iter Mean Loss 15.3377
2020-11-05 16:37:57,212 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.4100 | Iter Mean Loss 15.6058
2020-11-05 16:37:57,217 - root - INFO - Training: Epoch 0248 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4875 | Iter Mean Loss 13.3821
2020-11-05 16:37:57,218 - root - INFO - Evaluate: Epoch 0248 | NDCG 0.0000 | MSE 0.2038
2020-11-05 16:37:57,224 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3482 | Iter Mean Loss 19.3482
2020-11-05 16:37:57,229 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7547 | Iter Mean Loss 11.0515
2020-11-05 16:37:57,235 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.8044 | Iter Mean Loss 15.3024
2020-11-05 16:37:57,241 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3710 | Iter Mean Loss 15.5696
2020-11-05 16:37:57,245 - root - INFO - Training: Epoch 0249 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4862 | Iter Mean Loss 13.3529
2020-11-05 16:37:57,246 - root - INFO - Evaluate: Epoch 0249 | NDCG 0.0000 | MSE 0.2038
2020-11-05 16:37:57,252 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.3021 | Iter Mean Loss 19.3021
2020-11-05 16:37:57,258 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7514 | Iter Mean Loss 11.0267
2020-11-05 16:37:57,264 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.7486 | Iter Mean Loss 15.2673
2020-11-05 16:37:57,270 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.3321 | Iter Mean Loss 15.5335
2020-11-05 16:37:57,275 - root - INFO - Training: Epoch 0250 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4848 | Iter Mean Loss 13.3238
2020-11-05 16:37:57,276 - root - INFO - Evaluate: Epoch 0250 | NDCG 0.0000 | MSE 0.2037
2020-11-05 16:37:57,282 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.2562 | Iter Mean Loss 19.2562
2020-11-05 16:37:57,289 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7481 | Iter Mean Loss 11.0022
2020-11-05 16:37:57,295 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6930 | Iter Mean Loss 15.2324
2020-11-05 16:37:57,300 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2934 | Iter Mean Loss 15.4977
2020-11-05 16:37:57,306 - root - INFO - Training: Epoch 0251 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4834 | Iter Mean Loss 13.2948
2020-11-05 16:37:57,307 - root - INFO - Evaluate: Epoch 0251 | NDCG 0.0000 | MSE 0.2037
2020-11-05 16:37:57,314 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.2107 | Iter Mean Loss 19.2107
2020-11-05 16:37:57,323 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7448 | Iter Mean Loss 10.9778
2020-11-05 16:37:57,329 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.6376 | Iter Mean Loss 15.1977
2020-11-05 16:37:57,335 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2547 | Iter Mean Loss 15.4620
2020-11-05 16:37:57,341 - root - INFO - Training: Epoch 0252 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4819 | Iter Mean Loss 13.2660
2020-11-05 16:37:57,342 - root - INFO - Evaluate: Epoch 0252 | NDCG 0.0000 | MSE 0.2036
2020-11-05 16:37:57,348 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1655 | Iter Mean Loss 19.1655
2020-11-05 16:37:57,355 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7415 | Iter Mean Loss 10.9535
2020-11-05 16:37:57,361 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.5826 | Iter Mean Loss 15.1632
2020-11-05 16:37:57,367 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.2163 | Iter Mean Loss 15.4265
2020-11-05 16:37:57,372 - root - INFO - Training: Epoch 0253 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4805 | Iter Mean Loss 13.2373
2020-11-05 16:37:57,373 - root - INFO - Evaluate: Epoch 0253 | NDCG 0.0000 | MSE 0.2035
2020-11-05 16:37:57,378 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.1205 | Iter Mean Loss 19.1205
2020-11-05 16:37:57,384 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7383 | Iter Mean Loss 10.9294
2020-11-05 16:37:57,390 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.5278 | Iter Mean Loss 15.1288
2020-11-05 16:37:57,395 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1779 | Iter Mean Loss 15.3911
2020-11-05 16:37:57,400 - root - INFO - Training: Epoch 0254 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4790 | Iter Mean Loss 13.2087
2020-11-05 16:37:57,401 - root - INFO - Evaluate: Epoch 0254 | NDCG 0.0000 | MSE 0.2035
2020-11-05 16:37:57,407 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.0759 | Iter Mean Loss 19.0759
2020-11-05 16:37:57,412 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7350 | Iter Mean Loss 10.9054
2020-11-05 16:37:57,418 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4732 | Iter Mean Loss 15.0947
2020-11-05 16:37:57,423 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1397 | Iter Mean Loss 15.3559
2020-11-05 16:37:57,428 - root - INFO - Training: Epoch 0255 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4776 | Iter Mean Loss 13.1803
2020-11-05 16:37:57,429 - root - INFO - Evaluate: Epoch 0255 | NDCG 0.0000 | MSE 0.2034
2020-11-05 16:37:57,435 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 19.0315 | Iter Mean Loss 19.0315
2020-11-05 16:37:57,440 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7317 | Iter Mean Loss 10.8816
2020-11-05 16:37:57,446 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.4188 | Iter Mean Loss 15.0607
2020-11-05 16:37:57,452 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.1016 | Iter Mean Loss 15.3209
2020-11-05 16:37:57,456 - root - INFO - Training: Epoch 0256 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4761 | Iter Mean Loss 13.1519
2020-11-05 16:37:57,457 - root - INFO - Evaluate: Epoch 0256 | NDCG 0.0000 | MSE 0.2033
2020-11-05 16:37:57,463 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9875 | Iter Mean Loss 18.9875
2020-11-05 16:37:57,469 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7284 | Iter Mean Loss 10.8579
2020-11-05 16:37:57,476 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3648 | Iter Mean Loss 15.0269
2020-11-05 16:37:57,482 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0636 | Iter Mean Loss 15.2861
2020-11-05 16:37:57,489 - root - INFO - Training: Epoch 0257 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4745 | Iter Mean Loss 13.1237
2020-11-05 16:37:57,490 - root - INFO - Evaluate: Epoch 0257 | NDCG 0.0000 | MSE 0.2033
2020-11-05 16:37:57,495 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9437 | Iter Mean Loss 18.9437
2020-11-05 16:37:57,502 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7252 | Iter Mean Loss 10.8344
2020-11-05 16:37:57,508 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.3109 | Iter Mean Loss 14.9932
2020-11-05 16:37:57,514 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 16.0257 | Iter Mean Loss 15.2514
2020-11-05 16:37:57,520 - root - INFO - Training: Epoch 0258 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4730 | Iter Mean Loss 13.0957
2020-11-05 16:37:57,522 - root - INFO - Evaluate: Epoch 0258 | NDCG 0.0000 | MSE 0.2032
2020-11-05 16:37:57,528 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.9002 | Iter Mean Loss 18.9002
2020-11-05 16:37:57,534 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7219 | Iter Mean Loss 10.8110
2020-11-05 16:37:57,540 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2573 | Iter Mean Loss 14.9598
2020-11-05 16:37:57,546 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9879 | Iter Mean Loss 15.2168
2020-11-05 16:37:57,551 - root - INFO - Training: Epoch 0259 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4714 | Iter Mean Loss 13.0677
2020-11-05 16:37:57,552 - root - INFO - Evaluate: Epoch 0259 | NDCG 0.0000 | MSE 0.2032
2020-11-05 16:37:57,558 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8569 | Iter Mean Loss 18.8569
2020-11-05 16:37:57,564 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7186 | Iter Mean Loss 10.7878
2020-11-05 16:37:57,570 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.2039 | Iter Mean Loss 14.9265
2020-11-05 16:37:57,576 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9503 | Iter Mean Loss 15.1824
2020-11-05 16:37:57,581 - root - INFO - Training: Epoch 0260 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4699 | Iter Mean Loss 13.0399
2020-11-05 16:37:57,582 - root - INFO - Evaluate: Epoch 0260 | NDCG 0.0000 | MSE 0.2031
2020-11-05 16:37:57,587 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.8140 | Iter Mean Loss 18.8140
2020-11-05 16:37:57,593 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7154 | Iter Mean Loss 10.7647
2020-11-05 16:37:57,598 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.1508 | Iter Mean Loss 14.8934
2020-11-05 16:37:57,604 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.9128 | Iter Mean Loss 15.1482
2020-11-05 16:37:57,609 - root - INFO - Training: Epoch 0261 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4683 | Iter Mean Loss 13.0122
2020-11-05 16:37:57,609 - root - INFO - Evaluate: Epoch 0261 | NDCG 0.0000 | MSE 0.2030
2020-11-05 16:37:57,615 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.7713 | Iter Mean Loss 18.7713
2020-11-05 16:37:57,621 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7121 | Iter Mean Loss 10.7417
2020-11-05 16:37:57,626 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0979 | Iter Mean Loss 14.8604
2020-11-05 16:37:57,632 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8753 | Iter Mean Loss 15.1141
2020-11-05 16:37:57,638 - root - INFO - Training: Epoch 0262 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4667 | Iter Mean Loss 12.9846
2020-11-05 16:37:57,639 - root - INFO - Evaluate: Epoch 0262 | NDCG 0.0000 | MSE 0.2030
2020-11-05 16:37:57,644 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.7288 | Iter Mean Loss 18.7288
2020-11-05 16:37:57,650 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7088 | Iter Mean Loss 10.7188
2020-11-05 16:37:57,656 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 23.0452 | Iter Mean Loss 14.8276
2020-11-05 16:37:57,661 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8380 | Iter Mean Loss 15.0802
2020-11-05 16:37:57,666 - root - INFO - Training: Epoch 0263 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4650 | Iter Mean Loss 12.9572
2020-11-05 16:37:57,667 - root - INFO - Evaluate: Epoch 0263 | NDCG 0.0000 | MSE 0.2029
2020-11-05 16:37:57,673 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6866 | Iter Mean Loss 18.6866
2020-11-05 16:37:57,680 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7056 | Iter Mean Loss 10.6961
2020-11-05 16:37:57,685 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9927 | Iter Mean Loss 14.7950
2020-11-05 16:37:57,691 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.8008 | Iter Mean Loss 15.0464
2020-11-05 16:37:57,696 - root - INFO - Training: Epoch 0264 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4634 | Iter Mean Loss 12.9298
2020-11-05 16:37:57,698 - root - INFO - Evaluate: Epoch 0264 | NDCG 0.0000 | MSE 0.2029
2020-11-05 16:37:57,704 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6447 | Iter Mean Loss 18.6447
2020-11-05 16:37:57,710 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.7023 | Iter Mean Loss 10.6735
2020-11-05 16:37:57,717 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.9405 | Iter Mean Loss 14.7625
2020-11-05 16:37:57,723 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7637 | Iter Mean Loss 15.0128
2020-11-05 16:37:57,728 - root - INFO - Training: Epoch 0265 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4617 | Iter Mean Loss 12.9026
2020-11-05 16:37:57,729 - root - INFO - Evaluate: Epoch 0265 | NDCG 0.0000 | MSE 0.2028
2020-11-05 16:37:57,736 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.6030 | Iter Mean Loss 18.6030
2020-11-05 16:37:57,741 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6991 | Iter Mean Loss 10.6510
2020-11-05 16:37:57,747 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8885 | Iter Mean Loss 14.7302
2020-11-05 16:37:57,754 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.7267 | Iter Mean Loss 14.9793
2020-11-05 16:37:57,759 - root - INFO - Training: Epoch 0266 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4600 | Iter Mean Loss 12.8755
2020-11-05 16:37:57,760 - root - INFO - Evaluate: Epoch 0266 | NDCG 0.0000 | MSE 0.2027
2020-11-05 16:37:57,767 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5616 | Iter Mean Loss 18.5616
2020-11-05 16:37:57,773 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6958 | Iter Mean Loss 10.6287
2020-11-05 16:37:57,778 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.8367 | Iter Mean Loss 14.6980
2020-11-05 16:37:57,784 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6898 | Iter Mean Loss 14.9460
2020-11-05 16:37:57,789 - root - INFO - Training: Epoch 0267 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4583 | Iter Mean Loss 12.8484
2020-11-05 16:37:57,790 - root - INFO - Evaluate: Epoch 0267 | NDCG 0.0000 | MSE 0.2027
2020-11-05 16:37:57,795 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.5204 | Iter Mean Loss 18.5204
2020-11-05 16:37:57,801 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6925 | Iter Mean Loss 10.6065
2020-11-05 16:37:57,806 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7851 | Iter Mean Loss 14.6660
2020-11-05 16:37:57,812 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6530 | Iter Mean Loss 14.9128
2020-11-05 16:37:57,817 - root - INFO - Training: Epoch 0268 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4566 | Iter Mean Loss 12.8215
2020-11-05 16:37:57,817 - root - INFO - Evaluate: Epoch 0268 | NDCG 0.0000 | MSE 0.2026
2020-11-05 16:37:57,823 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.4795 | Iter Mean Loss 18.4795
2020-11-05 16:37:57,829 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6893 | Iter Mean Loss 10.5844
2020-11-05 16:37:57,834 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.7338 | Iter Mean Loss 14.6342
2020-11-05 16:37:57,840 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.6163 | Iter Mean Loss 14.8797
2020-11-05 16:37:57,844 - root - INFO - Training: Epoch 0269 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4549 | Iter Mean Loss 12.7947
2020-11-05 16:37:57,845 - root - INFO - Evaluate: Epoch 0269 | NDCG 0.0000 | MSE 0.2026
2020-11-05 16:37:57,851 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.4388 | Iter Mean Loss 18.4388
2020-11-05 16:37:57,856 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6860 | Iter Mean Loss 10.5624
2020-11-05 16:37:57,861 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.6826 | Iter Mean Loss 14.6025
2020-11-05 16:37:57,867 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5796 | Iter Mean Loss 14.8468
2020-11-05 16:37:57,872 - root - INFO - Training: Epoch 0270 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4531 | Iter Mean Loss 12.7680
2020-11-05 16:37:57,873 - root - INFO - Evaluate: Epoch 0270 | NDCG 0.0000 | MSE 0.2025
2020-11-05 16:37:57,879 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3983 | Iter Mean Loss 18.3983
2020-11-05 16:37:57,885 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6827 | Iter Mean Loss 10.5405
2020-11-05 16:37:57,891 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.6317 | Iter Mean Loss 14.5709
2020-11-05 16:37:57,896 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5431 | Iter Mean Loss 14.8140
2020-11-05 16:37:57,901 - root - INFO - Training: Epoch 0271 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4514 | Iter Mean Loss 12.7415
2020-11-05 16:37:57,903 - root - INFO - Evaluate: Epoch 0271 | NDCG 0.0000 | MSE 0.2024
2020-11-05 16:37:57,909 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3581 | Iter Mean Loss 18.3581
2020-11-05 16:37:57,915 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6794 | Iter Mean Loss 10.5188
2020-11-05 16:37:57,921 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5810 | Iter Mean Loss 14.5395
2020-11-05 16:37:57,927 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.5067 | Iter Mean Loss 14.7813
2020-11-05 16:37:57,932 - root - INFO - Training: Epoch 0272 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4496 | Iter Mean Loss 12.7150
2020-11-05 16:37:57,934 - root - INFO - Evaluate: Epoch 0272 | NDCG 0.0000 | MSE 0.2024
2020-11-05 16:37:57,940 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.3181 | Iter Mean Loss 18.3181
2020-11-05 16:37:57,945 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6762 | Iter Mean Loss 10.4971
2020-11-05 16:37:57,952 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.5305 | Iter Mean Loss 14.5083
2020-11-05 16:37:57,957 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4703 | Iter Mean Loss 14.7488
2020-11-05 16:37:57,962 - root - INFO - Training: Epoch 0273 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4478 | Iter Mean Loss 12.6886
2020-11-05 16:37:57,963 - root - INFO - Evaluate: Epoch 0273 | NDCG 0.0000 | MSE 0.2023
2020-11-05 16:37:57,970 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2784 | Iter Mean Loss 18.2784
2020-11-05 16:37:57,975 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6729 | Iter Mean Loss 10.4756
2020-11-05 16:37:57,981 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4802 | Iter Mean Loss 14.4771
2020-11-05 16:37:57,986 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.4341 | Iter Mean Loss 14.7164
2020-11-05 16:37:57,991 - root - INFO - Training: Epoch 0274 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4460 | Iter Mean Loss 12.6623
2020-11-05 16:37:57,992 - root - INFO - Evaluate: Epoch 0274 | NDCG 0.0000 | MSE 0.2023
2020-11-05 16:37:57,997 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.2388 | Iter Mean Loss 18.2388
2020-11-05 16:37:58,003 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6696 | Iter Mean Loss 10.4542
2020-11-05 16:37:58,008 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.4300 | Iter Mean Loss 14.4462
2020-11-05 16:37:58,013 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3979 | Iter Mean Loss 14.6841
2020-11-05 16:37:58,018 - root - INFO - Training: Epoch 0275 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4442 | Iter Mean Loss 12.6361
2020-11-05 16:37:58,019 - root - INFO - Evaluate: Epoch 0275 | NDCG 0.0000 | MSE 0.2022
2020-11-05 16:37:58,025 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1995 | Iter Mean Loss 18.1995
2020-11-05 16:37:58,030 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6663 | Iter Mean Loss 10.4329
2020-11-05 16:37:58,035 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3801 | Iter Mean Loss 14.4153
2020-11-05 16:37:58,041 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3618 | Iter Mean Loss 14.6519
2020-11-05 16:37:58,045 - root - INFO - Training: Epoch 0276 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4423 | Iter Mean Loss 12.6100
2020-11-05 16:37:58,046 - root - INFO - Evaluate: Epoch 0276 | NDCG 0.0000 | MSE 0.2022
2020-11-05 16:37:58,052 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1604 | Iter Mean Loss 18.1604
2020-11-05 16:37:58,057 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6630 | Iter Mean Loss 10.4117
2020-11-05 16:37:58,063 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.3304 | Iter Mean Loss 14.3846
2020-11-05 16:37:58,068 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.3258 | Iter Mean Loss 14.6199
2020-11-05 16:37:58,073 - root - INFO - Training: Epoch 0277 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4405 | Iter Mean Loss 12.5840
2020-11-05 16:37:58,074 - root - INFO - Evaluate: Epoch 0277 | NDCG 0.0000 | MSE 0.2021
2020-11-05 16:37:58,081 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.1216 | Iter Mean Loss 18.1216
2020-11-05 16:37:58,086 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6597 | Iter Mean Loss 10.3906
2020-11-05 16:37:58,092 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2809 | Iter Mean Loss 14.3541
2020-11-05 16:37:58,099 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2899 | Iter Mean Loss 14.5880
2020-11-05 16:37:58,104 - root - INFO - Training: Epoch 0278 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4386 | Iter Mean Loss 12.5581
2020-11-05 16:37:58,105 - root - INFO - Evaluate: Epoch 0278 | NDCG 0.0000 | MSE 0.2020
2020-11-05 16:37:58,111 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0829 | Iter Mean Loss 18.0829
2020-11-05 16:37:58,118 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6564 | Iter Mean Loss 10.3696
2020-11-05 16:37:58,124 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.2316 | Iter Mean Loss 14.3236
2020-11-05 16:37:58,130 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2540 | Iter Mean Loss 14.5562
2020-11-05 16:37:58,135 - root - INFO - Training: Epoch 0279 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4367 | Iter Mean Loss 12.5323
2020-11-05 16:37:58,136 - root - INFO - Evaluate: Epoch 0279 | NDCG 0.0000 | MSE 0.2020
2020-11-05 16:37:58,142 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0445 | Iter Mean Loss 18.0445
2020-11-05 16:37:58,148 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6531 | Iter Mean Loss 10.3488
2020-11-05 16:37:58,154 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.1825 | Iter Mean Loss 14.2933
2020-11-05 16:37:58,159 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.2182 | Iter Mean Loss 14.5246
2020-11-05 16:37:58,164 - root - INFO - Training: Epoch 0280 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4348 | Iter Mean Loss 12.5066
2020-11-05 16:37:58,165 - root - INFO - Evaluate: Epoch 0280 | NDCG 0.0000 | MSE 0.2019
2020-11-05 16:37:58,172 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 18.0062 | Iter Mean Loss 18.0062
2020-11-05 16:37:58,178 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6497 | Iter Mean Loss 10.3280
2020-11-05 16:37:58,183 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.1336 | Iter Mean Loss 14.2632
2020-11-05 16:37:58,188 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1825 | Iter Mean Loss 14.4930
2020-11-05 16:37:58,193 - root - INFO - Training: Epoch 0281 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4329 | Iter Mean Loss 12.4810
2020-11-05 16:37:58,194 - root - INFO - Evaluate: Epoch 0281 | NDCG 0.0000 | MSE 0.2019
2020-11-05 16:37:58,199 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.9682 | Iter Mean Loss 17.9682
2020-11-05 16:37:58,205 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6464 | Iter Mean Loss 10.3073
2020-11-05 16:37:58,210 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0848 | Iter Mean Loss 14.2331
2020-11-05 16:37:58,216 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1469 | Iter Mean Loss 14.4616
2020-11-05 16:37:58,220 - root - INFO - Training: Epoch 0282 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4310 | Iter Mean Loss 12.4555
2020-11-05 16:37:58,221 - root - INFO - Evaluate: Epoch 0282 | NDCG 0.0000 | MSE 0.2018
2020-11-05 16:37:58,227 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.9304 | Iter Mean Loss 17.9304
2020-11-05 16:37:58,232 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6431 | Iter Mean Loss 10.2867
2020-11-05 16:37:58,238 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 22.0363 | Iter Mean Loss 14.2032
2020-11-05 16:37:58,243 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.1113 | Iter Mean Loss 14.4303
2020-11-05 16:37:58,247 - root - INFO - Training: Epoch 0283 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4290 | Iter Mean Loss 12.4300
2020-11-05 16:37:58,248 - root - INFO - Evaluate: Epoch 0283 | NDCG 0.0000 | MSE 0.2018
2020-11-05 16:37:58,254 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8927 | Iter Mean Loss 17.8927
2020-11-05 16:37:58,259 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6397 | Iter Mean Loss 10.2662
2020-11-05 16:37:58,264 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9879 | Iter Mean Loss 14.1735
2020-11-05 16:37:58,270 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0758 | Iter Mean Loss 14.3991
2020-11-05 16:37:58,275 - root - INFO - Training: Epoch 0284 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4270 | Iter Mean Loss 12.4047
2020-11-05 16:37:58,276 - root - INFO - Evaluate: Epoch 0284 | NDCG 0.0000 | MSE 0.2017
2020-11-05 16:37:58,282 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8553 | Iter Mean Loss 17.8553
2020-11-05 16:37:58,287 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6364 | Iter Mean Loss 10.2459
2020-11-05 16:37:58,293 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.9398 | Iter Mean Loss 14.1438
2020-11-05 16:37:58,299 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0404 | Iter Mean Loss 14.3680
2020-11-05 16:37:58,304 - root - INFO - Training: Epoch 0285 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4251 | Iter Mean Loss 12.3794
2020-11-05 16:37:58,305 - root - INFO - Evaluate: Epoch 0285 | NDCG 0.0000 | MSE 0.2017
2020-11-05 16:37:58,311 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.8181 | Iter Mean Loss 17.8181
2020-11-05 16:37:58,318 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6330 | Iter Mean Loss 10.2256
2020-11-05 16:37:58,324 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8918 | Iter Mean Loss 14.1143
2020-11-05 16:37:58,330 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 15.0050 | Iter Mean Loss 14.3370
2020-11-05 16:37:58,335 - root - INFO - Training: Epoch 0286 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4231 | Iter Mean Loss 12.3542
2020-11-05 16:37:58,336 - root - INFO - Evaluate: Epoch 0286 | NDCG 0.0000 | MSE 0.2016
2020-11-05 16:37:58,342 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7811 | Iter Mean Loss 17.7811
2020-11-05 16:37:58,348 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6297 | Iter Mean Loss 10.2054
2020-11-05 16:37:58,353 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.8440 | Iter Mean Loss 14.0849
2020-11-05 16:37:58,359 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9697 | Iter Mean Loss 14.3061
2020-11-05 16:37:58,364 - root - INFO - Training: Epoch 0287 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4211 | Iter Mean Loss 12.3291
2020-11-05 16:37:58,365 - root - INFO - Evaluate: Epoch 0287 | NDCG 0.0000 | MSE 0.2015
2020-11-05 16:37:58,370 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7442 | Iter Mean Loss 17.7442
2020-11-05 16:37:58,377 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6263 | Iter Mean Loss 10.1853
2020-11-05 16:37:58,382 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7964 | Iter Mean Loss 14.0556
2020-11-05 16:37:58,388 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.9345 | Iter Mean Loss 14.2753
2020-11-05 16:37:58,392 - root - INFO - Training: Epoch 0288 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4190 | Iter Mean Loss 12.3041
2020-11-05 16:37:58,393 - root - INFO - Evaluate: Epoch 0288 | NDCG 0.0000 | MSE 0.2015
2020-11-05 16:37:58,399 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.7076 | Iter Mean Loss 17.7076
2020-11-05 16:37:58,404 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6229 | Iter Mean Loss 10.1652
2020-11-05 16:37:58,409 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7489 | Iter Mean Loss 14.0265
2020-11-05 16:37:58,415 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8993 | Iter Mean Loss 14.2447
2020-11-05 16:37:58,419 - root - INFO - Training: Epoch 0289 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4170 | Iter Mean Loss 12.2791
2020-11-05 16:37:58,420 - root - INFO - Evaluate: Epoch 0289 | NDCG 0.0000 | MSE 0.2014
2020-11-05 16:37:58,426 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.6711 | Iter Mean Loss 17.6711
2020-11-05 16:37:58,431 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6195 | Iter Mean Loss 10.1453
2020-11-05 16:37:58,436 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.7016 | Iter Mean Loss 13.9974
2020-11-05 16:37:58,442 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8642 | Iter Mean Loss 14.2141
2020-11-05 16:37:58,446 - root - INFO - Training: Epoch 0290 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4149 | Iter Mean Loss 12.2543
2020-11-05 16:37:58,447 - root - INFO - Evaluate: Epoch 0290 | NDCG 0.0000 | MSE 0.2014
2020-11-05 16:37:58,452 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.6349 | Iter Mean Loss 17.6349
2020-11-05 16:37:58,458 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6161 | Iter Mean Loss 10.1255
2020-11-05 16:37:58,463 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6545 | Iter Mean Loss 13.9685
2020-11-05 16:37:58,468 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.8292 | Iter Mean Loss 14.1837
2020-11-05 16:37:58,474 - root - INFO - Training: Epoch 0291 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4129 | Iter Mean Loss 12.2295
2020-11-05 16:37:58,474 - root - INFO - Evaluate: Epoch 0291 | NDCG 0.0000 | MSE 0.2013
2020-11-05 16:37:58,480 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5988 | Iter Mean Loss 17.5988
2020-11-05 16:37:58,486 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6127 | Iter Mean Loss 10.1057
2020-11-05 16:37:58,492 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.6076 | Iter Mean Loss 13.9397
2020-11-05 16:37:58,498 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7942 | Iter Mean Loss 14.1533
2020-11-05 16:37:58,503 - root - INFO - Training: Epoch 0292 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4108 | Iter Mean Loss 12.2048
2020-11-05 16:37:58,504 - root - INFO - Evaluate: Epoch 0292 | NDCG 0.0000 | MSE 0.2013
2020-11-05 16:37:58,509 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5629 | Iter Mean Loss 17.5629
2020-11-05 16:37:58,515 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6092 | Iter Mean Loss 10.0861
2020-11-05 16:37:58,521 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.5609 | Iter Mean Loss 13.9110
2020-11-05 16:37:58,527 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7592 | Iter Mean Loss 14.1231
2020-11-05 16:37:58,532 - root - INFO - Training: Epoch 0293 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4087 | Iter Mean Loss 12.1802
2020-11-05 16:37:58,533 - root - INFO - Evaluate: Epoch 0293 | NDCG 0.0000 | MSE 0.2012
2020-11-05 16:37:58,539 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.5272 | Iter Mean Loss 17.5272
2020-11-05 16:37:58,545 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6058 | Iter Mean Loss 10.0665
2020-11-05 16:37:58,551 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.5143 | Iter Mean Loss 13.8824
2020-11-05 16:37:58,556 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.7244 | Iter Mean Loss 14.0929
2020-11-05 16:37:58,561 - root - INFO - Training: Epoch 0294 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4066 | Iter Mean Loss 12.1556
2020-11-05 16:37:58,562 - root - INFO - Evaluate: Epoch 0294 | NDCG 0.0000 | MSE 0.2012
2020-11-05 16:37:58,568 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4917 | Iter Mean Loss 17.4917
2020-11-05 16:37:58,574 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.6024 | Iter Mean Loss 10.0470
2020-11-05 16:37:58,579 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4679 | Iter Mean Loss 13.8540
2020-11-05 16:37:58,585 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6895 | Iter Mean Loss 14.0629
2020-11-05 16:37:58,589 - root - INFO - Training: Epoch 0295 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4044 | Iter Mean Loss 12.1312
2020-11-05 16:37:58,590 - root - INFO - Evaluate: Epoch 0295 | NDCG 0.0000 | MSE 0.2011
2020-11-05 16:37:58,596 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4563 | Iter Mean Loss 17.4563
2020-11-05 16:37:58,601 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5989 | Iter Mean Loss 10.0276
2020-11-05 16:37:58,606 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.4216 | Iter Mean Loss 13.8256
2020-11-05 16:37:58,612 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6548 | Iter Mean Loss 14.0329
2020-11-05 16:37:58,616 - root - INFO - Training: Epoch 0296 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4023 | Iter Mean Loss 12.1068
2020-11-05 16:37:58,617 - root - INFO - Evaluate: Epoch 0296 | NDCG 0.0000 | MSE 0.2011
2020-11-05 16:37:58,623 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.4211 | Iter Mean Loss 17.4211
2020-11-05 16:37:58,628 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5954 | Iter Mean Loss 10.0083
2020-11-05 16:37:58,634 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3755 | Iter Mean Loss 13.7974
2020-11-05 16:37:58,640 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.6200 | Iter Mean Loss 14.0030
2020-11-05 16:37:58,644 - root - INFO - Training: Epoch 0297 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.4001 | Iter Mean Loss 12.0824
2020-11-05 16:37:58,645 - root - INFO - Evaluate: Epoch 0297 | NDCG 0.0000 | MSE 0.2010
2020-11-05 16:37:58,651 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3861 | Iter Mean Loss 17.3861
2020-11-05 16:37:58,656 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5919 | Iter Mean Loss 9.9890
2020-11-05 16:37:58,661 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.3296 | Iter Mean Loss 13.7692
2020-11-05 16:37:58,667 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5854 | Iter Mean Loss 13.9733
2020-11-05 16:37:58,671 - root - INFO - Training: Epoch 0298 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3980 | Iter Mean Loss 12.0582
2020-11-05 16:37:58,672 - root - INFO - Evaluate: Epoch 0298 | NDCG 0.0000 | MSE 0.2009
2020-11-05 16:37:58,678 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3513 | Iter Mean Loss 17.3513
2020-11-05 16:37:58,684 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5884 | Iter Mean Loss 9.9698
2020-11-05 16:37:58,689 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2839 | Iter Mean Loss 13.7412
2020-11-05 16:37:58,695 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5507 | Iter Mean Loss 13.9436
2020-11-05 16:37:58,700 - root - INFO - Training: Epoch 0299 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3958 | Iter Mean Loss 12.0340
2020-11-05 16:37:58,701 - root - INFO - Evaluate: Epoch 0299 | NDCG 0.0000 | MSE 0.2009
2020-11-05 16:37:58,706 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.3166 | Iter Mean Loss 17.3166
2020-11-05 16:37:58,713 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5849 | Iter Mean Loss 9.9508
2020-11-05 16:37:58,719 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.2383 | Iter Mean Loss 13.7133
2020-11-05 16:37:58,726 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.5162 | Iter Mean Loss 13.9140
2020-11-05 16:37:58,732 - root - INFO - Training: Epoch 0300 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3936 | Iter Mean Loss 12.0099
2020-11-05 16:37:58,733 - root - INFO - Evaluate: Epoch 0300 | NDCG 0.0000 | MSE 0.2008
2020-11-05 16:37:58,739 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2821 | Iter Mean Loss 17.2821
2020-11-05 16:37:58,747 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5814 | Iter Mean Loss 9.9317
2020-11-05 16:37:58,752 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1928 | Iter Mean Loss 13.6854
2020-11-05 16:37:58,759 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4816 | Iter Mean Loss 13.8845
2020-11-05 16:37:58,765 - root - INFO - Training: Epoch 0301 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3913 | Iter Mean Loss 11.9859
2020-11-05 16:37:58,766 - root - INFO - Evaluate: Epoch 0301 | NDCG 0.0000 | MSE 0.2008
2020-11-05 16:37:58,772 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2478 | Iter Mean Loss 17.2478
2020-11-05 16:37:58,779 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5779 | Iter Mean Loss 9.9128
2020-11-05 16:37:58,785 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1476 | Iter Mean Loss 13.6577
2020-11-05 16:37:58,791 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4472 | Iter Mean Loss 13.8551
2020-11-05 16:37:58,796 - root - INFO - Training: Epoch 0302 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3891 | Iter Mean Loss 11.9619
2020-11-05 16:37:58,797 - root - INFO - Evaluate: Epoch 0302 | NDCG 0.0000 | MSE 0.2007
2020-11-05 16:37:58,803 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.2136 | Iter Mean Loss 17.2136
2020-11-05 16:37:58,809 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5743 | Iter Mean Loss 9.8940
2020-11-05 16:37:58,815 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.1025 | Iter Mean Loss 13.6301
2020-11-05 16:37:58,820 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.4127 | Iter Mean Loss 13.8258
2020-11-05 16:37:58,826 - root - INFO - Training: Epoch 0303 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3868 | Iter Mean Loss 11.9380
2020-11-05 16:37:58,827 - root - INFO - Evaluate: Epoch 0303 | NDCG 0.0000 | MSE 0.2007
2020-11-05 16:37:58,832 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1796 | Iter Mean Loss 17.1796
2020-11-05 16:37:58,838 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5708 | Iter Mean Loss 9.8752
2020-11-05 16:37:58,844 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0575 | Iter Mean Loss 13.6026
2020-11-05 16:37:58,850 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3783 | Iter Mean Loss 13.7965
2020-11-05 16:37:58,855 - root - INFO - Training: Epoch 0304 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3846 | Iter Mean Loss 11.9141
2020-11-05 16:37:58,856 - root - INFO - Evaluate: Epoch 0304 | NDCG 0.0000 | MSE 0.2006
2020-11-05 16:37:58,861 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1457 | Iter Mean Loss 17.1457
2020-11-05 16:37:58,867 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5672 | Iter Mean Loss 9.8565
2020-11-05 16:37:58,873 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 21.0127 | Iter Mean Loss 13.5752
2020-11-05 16:37:58,879 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3440 | Iter Mean Loss 13.7674
2020-11-05 16:37:58,884 - root - INFO - Training: Epoch 0305 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3823 | Iter Mean Loss 11.8904
2020-11-05 16:37:58,885 - root - INFO - Evaluate: Epoch 0305 | NDCG 0.0000 | MSE 0.2006
2020-11-05 16:37:58,892 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.1120 | Iter Mean Loss 17.1120
2020-11-05 16:37:58,898 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5636 | Iter Mean Loss 9.8378
2020-11-05 16:37:58,904 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9681 | Iter Mean Loss 13.5479
2020-11-05 16:37:58,911 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.3097 | Iter Mean Loss 13.7383
2020-11-05 16:37:58,916 - root - INFO - Training: Epoch 0306 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3800 | Iter Mean Loss 11.8667
2020-11-05 16:37:58,917 - root - INFO - Evaluate: Epoch 0306 | NDCG 0.0000 | MSE 0.2005
2020-11-05 16:37:58,924 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0785 | Iter Mean Loss 17.0785
2020-11-05 16:37:58,930 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5600 | Iter Mean Loss 9.8192
2020-11-05 16:37:58,935 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.9236 | Iter Mean Loss 13.5207
2020-11-05 16:37:58,942 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2754 | Iter Mean Loss 13.7094
2020-11-05 16:37:58,947 - root - INFO - Training: Epoch 0307 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3777 | Iter Mean Loss 11.8430
2020-11-05 16:37:58,948 - root - INFO - Evaluate: Epoch 0307 | NDCG 0.0000 | MSE 0.2005
2020-11-05 16:37:58,954 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0451 | Iter Mean Loss 17.0451
2020-11-05 16:37:58,961 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5564 | Iter Mean Loss 9.8008
2020-11-05 16:37:58,967 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8792 | Iter Mean Loss 13.4936
2020-11-05 16:37:58,973 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2412 | Iter Mean Loss 13.6805
2020-11-05 16:37:58,978 - root - INFO - Training: Epoch 0308 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3754 | Iter Mean Loss 11.8195
2020-11-05 16:37:58,980 - root - INFO - Evaluate: Epoch 0308 | NDCG 0.0000 | MSE 0.2004
2020-11-05 16:37:58,987 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 17.0119 | Iter Mean Loss 17.0119
2020-11-05 16:37:58,992 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5528 | Iter Mean Loss 9.7823
2020-11-05 16:37:58,998 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.8350 | Iter Mean Loss 13.4666
2020-11-05 16:37:59,004 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.2070 | Iter Mean Loss 13.6517
2020-11-05 16:37:59,009 - root - INFO - Training: Epoch 0309 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3730 | Iter Mean Loss 11.7959
2020-11-05 16:37:59,010 - root - INFO - Evaluate: Epoch 0309 | NDCG 0.0000 | MSE 0.2004
2020-11-05 16:37:59,015 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9788 | Iter Mean Loss 16.9788
2020-11-05 16:37:59,021 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5491 | Iter Mean Loss 9.7640
2020-11-05 16:37:59,027 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7910 | Iter Mean Loss 13.4396
2020-11-05 16:37:59,032 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1729 | Iter Mean Loss 13.6229
2020-11-05 16:37:59,037 - root - INFO - Training: Epoch 0310 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3707 | Iter Mean Loss 11.7725
2020-11-05 16:37:59,038 - root - INFO - Evaluate: Epoch 0310 | NDCG 0.0000 | MSE 0.2003
2020-11-05 16:37:59,044 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9459 | Iter Mean Loss 16.9459
2020-11-05 16:37:59,050 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5455 | Iter Mean Loss 9.7457
2020-11-05 16:37:59,055 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7471 | Iter Mean Loss 13.4128
2020-11-05 16:37:59,061 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1388 | Iter Mean Loss 13.5943
2020-11-05 16:37:59,066 - root - INFO - Training: Epoch 0311 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3683 | Iter Mean Loss 11.7491
2020-11-05 16:37:59,067 - root - INFO - Evaluate: Epoch 0311 | NDCG 0.0000 | MSE 0.2002
2020-11-05 16:37:59,072 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.9131 | Iter Mean Loss 16.9131
2020-11-05 16:37:59,078 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5418 | Iter Mean Loss 9.7275
2020-11-05 16:37:59,084 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.7033 | Iter Mean Loss 13.3861
2020-11-05 16:37:59,090 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.1047 | Iter Mean Loss 13.5657
2020-11-05 16:37:59,096 - root - INFO - Training: Epoch 0312 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3659 | Iter Mean Loss 11.7258
2020-11-05 16:37:59,097 - root - INFO - Evaluate: Epoch 0312 | NDCG 0.0000 | MSE 0.2002
2020-11-05 16:37:59,103 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8805 | Iter Mean Loss 16.8805
2020-11-05 16:37:59,110 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5381 | Iter Mean Loss 9.7093
2020-11-05 16:37:59,116 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.6597 | Iter Mean Loss 13.3594
2020-11-05 16:37:59,121 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0707 | Iter Mean Loss 13.5373
2020-11-05 16:37:59,128 - root - INFO - Training: Epoch 0313 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3635 | Iter Mean Loss 11.7025
2020-11-05 16:37:59,129 - root - INFO - Evaluate: Epoch 0313 | NDCG 0.0000 | MSE 0.2001
2020-11-05 16:37:59,134 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8481 | Iter Mean Loss 16.8481
2020-11-05 16:37:59,140 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5344 | Iter Mean Loss 9.6912
2020-11-05 16:37:59,147 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.6162 | Iter Mean Loss 13.3329
2020-11-05 16:37:59,153 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0368 | Iter Mean Loss 13.5089
2020-11-05 16:37:59,158 - root - INFO - Training: Epoch 0314 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3611 | Iter Mean Loss 11.6793
2020-11-05 16:37:59,160 - root - INFO - Evaluate: Epoch 0314 | NDCG 0.0000 | MSE 0.2001
2020-11-05 16:37:59,166 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.8157 | Iter Mean Loss 16.8157
2020-11-05 16:37:59,171 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5307 | Iter Mean Loss 9.6732
2020-11-05 16:37:59,177 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5729 | Iter Mean Loss 13.3064
2020-11-05 16:37:59,184 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 14.0028 | Iter Mean Loss 13.4805
2020-11-05 16:37:59,189 - root - INFO - Training: Epoch 0315 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3586 | Iter Mean Loss 11.6562
2020-11-05 16:37:59,190 - root - INFO - Evaluate: Epoch 0315 | NDCG 0.0000 | MSE 0.2000
2020-11-05 16:37:59,196 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7835 | Iter Mean Loss 16.7835
2020-11-05 16:37:59,201 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5270 | Iter Mean Loss 9.6552
2020-11-05 16:37:59,207 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.5297 | Iter Mean Loss 13.2801
2020-11-05 16:37:59,212 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9689 | Iter Mean Loss 13.4523
2020-11-05 16:37:59,217 - root - INFO - Training: Epoch 0316 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3562 | Iter Mean Loss 11.6331
2020-11-05 16:37:59,218 - root - INFO - Evaluate: Epoch 0316 | NDCG 0.0000 | MSE 0.2000
2020-11-05 16:37:59,223 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7515 | Iter Mean Loss 16.7515
2020-11-05 16:37:59,229 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5232 | Iter Mean Loss 9.6374
2020-11-05 16:37:59,235 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4867 | Iter Mean Loss 13.2538
2020-11-05 16:37:59,240 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9351 | Iter Mean Loss 13.4241
2020-11-05 16:37:59,245 - root - INFO - Training: Epoch 0317 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3537 | Iter Mean Loss 11.6100
2020-11-05 16:37:59,246 - root - INFO - Evaluate: Epoch 0317 | NDCG 0.0000 | MSE 0.1999
2020-11-05 16:37:59,251 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.7196 | Iter Mean Loss 16.7196
2020-11-05 16:37:59,257 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5195 | Iter Mean Loss 9.6195
2020-11-05 16:37:59,262 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4438 | Iter Mean Loss 13.2276
2020-11-05 16:37:59,268 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.9012 | Iter Mean Loss 13.3960
2020-11-05 16:37:59,273 - root - INFO - Training: Epoch 0318 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3513 | Iter Mean Loss 11.5871
2020-11-05 16:37:59,274 - root - INFO - Evaluate: Epoch 0318 | NDCG 0.0000 | MSE 0.1999
2020-11-05 16:37:59,279 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6878 | Iter Mean Loss 16.6878
2020-11-05 16:37:59,285 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5157 | Iter Mean Loss 9.6018
2020-11-05 16:37:59,290 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.4010 | Iter Mean Loss 13.2015
2020-11-05 16:37:59,296 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8675 | Iter Mean Loss 13.3680
2020-11-05 16:37:59,302 - root - INFO - Training: Epoch 0319 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3488 | Iter Mean Loss 11.5641
2020-11-05 16:37:59,303 - root - INFO - Evaluate: Epoch 0319 | NDCG 0.0000 | MSE 0.1998
2020-11-05 16:37:59,309 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6562 | Iter Mean Loss 16.6562
2020-11-05 16:37:59,316 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5119 | Iter Mean Loss 9.5840
2020-11-05 16:37:59,323 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3584 | Iter Mean Loss 13.1755
2020-11-05 16:37:59,329 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8337 | Iter Mean Loss 13.3400
2020-11-05 16:37:59,335 - root - INFO - Training: Epoch 0320 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3463 | Iter Mean Loss 11.5413
2020-11-05 16:37:59,336 - root - INFO - Evaluate: Epoch 0320 | NDCG 0.0000 | MSE 0.1998
2020-11-05 16:37:59,342 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.6247 | Iter Mean Loss 16.6247
2020-11-05 16:37:59,349 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5081 | Iter Mean Loss 9.5664
2020-11-05 16:37:59,355 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.3159 | Iter Mean Loss 13.1496
2020-11-05 16:37:59,361 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.8000 | Iter Mean Loss 13.3122
2020-11-05 16:37:59,367 - root - INFO - Training: Epoch 0321 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3437 | Iter Mean Loss 11.5185
2020-11-05 16:37:59,368 - root - INFO - Evaluate: Epoch 0321 | NDCG 0.0000 | MSE 0.1997
2020-11-05 16:37:59,374 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5934 | Iter Mean Loss 16.5934
2020-11-05 16:37:59,380 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5043 | Iter Mean Loss 9.5488
2020-11-05 16:37:59,385 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2735 | Iter Mean Loss 13.1237
2020-11-05 16:37:59,392 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7664 | Iter Mean Loss 13.2844
2020-11-05 16:37:59,397 - root - INFO - Training: Epoch 0322 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3412 | Iter Mean Loss 11.4958
2020-11-05 16:37:59,398 - root - INFO - Evaluate: Epoch 0322 | NDCG 0.0000 | MSE 0.1997
2020-11-05 16:37:59,404 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5622 | Iter Mean Loss 16.5622
2020-11-05 16:37:59,409 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.5004 | Iter Mean Loss 9.5313
2020-11-05 16:37:59,415 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.2313 | Iter Mean Loss 13.0980
2020-11-05 16:37:59,420 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.7327 | Iter Mean Loss 13.2567
2020-11-05 16:37:59,425 - root - INFO - Training: Epoch 0323 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3387 | Iter Mean Loss 11.4731
2020-11-05 16:37:59,426 - root - INFO - Evaluate: Epoch 0323 | NDCG 0.0000 | MSE 0.1996
2020-11-05 16:37:59,431 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5311 | Iter Mean Loss 16.5311
2020-11-05 16:37:59,437 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4966 | Iter Mean Loss 9.5138
2020-11-05 16:37:59,442 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1892 | Iter Mean Loss 13.0723
2020-11-05 16:37:59,448 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6992 | Iter Mean Loss 13.2290
2020-11-05 16:37:59,452 - root - INFO - Training: Epoch 0324 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3361 | Iter Mean Loss 11.4504
2020-11-05 16:37:59,453 - root - INFO - Evaluate: Epoch 0324 | NDCG 0.0000 | MSE 0.1995
2020-11-05 16:37:59,459 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.5001 | Iter Mean Loss 16.5001
2020-11-05 16:37:59,464 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4927 | Iter Mean Loss 9.4964
2020-11-05 16:37:59,470 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1473 | Iter Mean Loss 13.0467
2020-11-05 16:37:59,475 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6656 | Iter Mean Loss 13.2014
2020-11-05 16:37:59,480 - root - INFO - Training: Epoch 0325 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3335 | Iter Mean Loss 11.4279
2020-11-05 16:37:59,481 - root - INFO - Evaluate: Epoch 0325 | NDCG 0.0000 | MSE 0.1995
2020-11-05 16:37:59,487 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4693 | Iter Mean Loss 16.4693
2020-11-05 16:37:59,493 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4889 | Iter Mean Loss 9.4791
2020-11-05 16:37:59,500 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.1055 | Iter Mean Loss 13.0212
2020-11-05 16:37:59,505 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.6321 | Iter Mean Loss 13.1739
2020-11-05 16:37:59,511 - root - INFO - Training: Epoch 0326 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3309 | Iter Mean Loss 11.4053
2020-11-05 16:37:59,513 - root - INFO - Evaluate: Epoch 0326 | NDCG 0.0000 | MSE 0.1994
2020-11-05 16:37:59,519 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4386 | Iter Mean Loss 16.4386
2020-11-05 16:37:59,525 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4850 | Iter Mean Loss 9.4618
2020-11-05 16:37:59,531 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0638 | Iter Mean Loss 12.9958
2020-11-05 16:37:59,537 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5986 | Iter Mean Loss 13.1465
2020-11-05 16:37:59,542 - root - INFO - Training: Epoch 0327 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3283 | Iter Mean Loss 11.3829
2020-11-05 16:37:59,543 - root - INFO - Evaluate: Epoch 0327 | NDCG 0.0000 | MSE 0.1994
2020-11-05 16:37:59,550 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.4081 | Iter Mean Loss 16.4081
2020-11-05 16:37:59,556 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4811 | Iter Mean Loss 9.4446
2020-11-05 16:37:59,562 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 20.0222 | Iter Mean Loss 12.9705
2020-11-05 16:37:59,568 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5652 | Iter Mean Loss 13.1191
2020-11-05 16:37:59,573 - root - INFO - Training: Epoch 0328 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3257 | Iter Mean Loss 11.3605
2020-11-05 16:37:59,574 - root - INFO - Evaluate: Epoch 0328 | NDCG 0.0000 | MSE 0.1993
2020-11-05 16:37:59,580 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3776 | Iter Mean Loss 16.3776
2020-11-05 16:37:59,586 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4771 | Iter Mean Loss 9.4274
2020-11-05 16:37:59,592 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9808 | Iter Mean Loss 12.9452
2020-11-05 16:37:59,598 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.5319 | Iter Mean Loss 13.0919
2020-11-05 16:37:59,602 - root - INFO - Training: Epoch 0329 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3231 | Iter Mean Loss 11.3381
2020-11-05 16:37:59,603 - root - INFO - Evaluate: Epoch 0329 | NDCG 0.0000 | MSE 0.1993
2020-11-05 16:37:59,609 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3473 | Iter Mean Loss 16.3473
2020-11-05 16:37:59,614 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4732 | Iter Mean Loss 9.4103
2020-11-05 16:37:59,620 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.9395 | Iter Mean Loss 12.9200
2020-11-05 16:37:59,625 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4985 | Iter Mean Loss 13.0646
2020-11-05 16:37:59,630 - root - INFO - Training: Epoch 0330 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3205 | Iter Mean Loss 11.3158
2020-11-05 16:37:59,631 - root - INFO - Evaluate: Epoch 0330 | NDCG 0.0000 | MSE 0.1992
2020-11-05 16:37:59,638 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.3172 | Iter Mean Loss 16.3172
2020-11-05 16:37:59,644 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4693 | Iter Mean Loss 9.3932
2020-11-05 16:37:59,649 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8983 | Iter Mean Loss 12.8949
2020-11-05 16:37:59,655 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4652 | Iter Mean Loss 13.0375
2020-11-05 16:37:59,659 - root - INFO - Training: Epoch 0331 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3178 | Iter Mean Loss 11.2936
2020-11-05 16:37:59,660 - root - INFO - Evaluate: Epoch 0331 | NDCG 0.0000 | MSE 0.1992
2020-11-05 16:37:59,666 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2871 | Iter Mean Loss 16.2871
2020-11-05 16:37:59,671 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4653 | Iter Mean Loss 9.3762
2020-11-05 16:37:59,677 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8573 | Iter Mean Loss 12.8699
2020-11-05 16:37:59,682 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.4320 | Iter Mean Loss 13.0104
2020-11-05 16:37:59,687 - root - INFO - Training: Epoch 0332 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3151 | Iter Mean Loss 11.2714
2020-11-05 16:37:59,688 - root - INFO - Evaluate: Epoch 0332 | NDCG 0.0000 | MSE 0.1991
2020-11-05 16:37:59,694 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2572 | Iter Mean Loss 16.2572
2020-11-05 16:37:59,700 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4613 | Iter Mean Loss 9.3593
2020-11-05 16:37:59,706 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.8164 | Iter Mean Loss 12.8450
2020-11-05 16:37:59,712 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3988 | Iter Mean Loss 12.9834
2020-11-05 16:37:59,717 - root - INFO - Training: Epoch 0333 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3125 | Iter Mean Loss 11.2492
2020-11-05 16:37:59,718 - root - INFO - Evaluate: Epoch 0333 | NDCG 0.0000 | MSE 0.1991
2020-11-05 16:37:59,724 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.2274 | Iter Mean Loss 16.2274
2020-11-05 16:37:59,730 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4574 | Iter Mean Loss 9.3424
2020-11-05 16:37:59,736 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7756 | Iter Mean Loss 12.8201
2020-11-05 16:37:59,742 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3657 | Iter Mean Loss 12.9565
2020-11-05 16:37:59,747 - root - INFO - Training: Epoch 0334 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3098 | Iter Mean Loss 11.2272
2020-11-05 16:37:59,748 - root - INFO - Evaluate: Epoch 0334 | NDCG 0.0000 | MSE 0.1990
2020-11-05 16:37:59,755 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1977 | Iter Mean Loss 16.1977
2020-11-05 16:37:59,761 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4534 | Iter Mean Loss 9.3255
2020-11-05 16:37:59,766 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.7349 | Iter Mean Loss 12.7953
2020-11-05 16:37:59,772 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.3326 | Iter Mean Loss 12.9296
2020-11-05 16:37:59,778 - root - INFO - Training: Epoch 0335 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3071 | Iter Mean Loss 11.2051
2020-11-05 16:37:59,779 - root - INFO - Evaluate: Epoch 0335 | NDCG 0.0000 | MSE 0.1990
2020-11-05 16:37:59,785 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1681 | Iter Mean Loss 16.1681
2020-11-05 16:37:59,791 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4494 | Iter Mean Loss 9.3087
2020-11-05 16:37:59,796 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6944 | Iter Mean Loss 12.7706
2020-11-05 16:37:59,802 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2995 | Iter Mean Loss 12.9029
2020-11-05 16:37:59,806 - root - INFO - Training: Epoch 0336 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3044 | Iter Mean Loss 11.1832
2020-11-05 16:37:59,807 - root - INFO - Evaluate: Epoch 0336 | NDCG 0.0000 | MSE 0.1989
2020-11-05 16:37:59,813 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1387 | Iter Mean Loss 16.1387
2020-11-05 16:37:59,818 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4453 | Iter Mean Loss 9.2920
2020-11-05 16:37:59,824 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6540 | Iter Mean Loss 12.7460
2020-11-05 16:37:59,829 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2665 | Iter Mean Loss 12.8761
2020-11-05 16:37:59,834 - root - INFO - Training: Epoch 0337 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.3016 | Iter Mean Loss 11.1612
2020-11-05 16:37:59,835 - root - INFO - Evaluate: Epoch 0337 | NDCG 0.0000 | MSE 0.1988
2020-11-05 16:37:59,840 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.1094 | Iter Mean Loss 16.1094
2020-11-05 16:37:59,846 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4413 | Iter Mean Loss 9.2753
2020-11-05 16:37:59,851 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.6137 | Iter Mean Loss 12.7215
2020-11-05 16:37:59,856 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2336 | Iter Mean Loss 12.8495
2020-11-05 16:37:59,861 - root - INFO - Training: Epoch 0338 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2989 | Iter Mean Loss 11.1394
2020-11-05 16:37:59,862 - root - INFO - Evaluate: Epoch 0338 | NDCG 0.0000 | MSE 0.1988
2020-11-05 16:37:59,868 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0802 | Iter Mean Loss 16.0802
2020-11-05 16:37:59,873 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4373 | Iter Mean Loss 9.2587
2020-11-05 16:37:59,879 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5736 | Iter Mean Loss 12.6970
2020-11-05 16:37:59,884 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.2007 | Iter Mean Loss 12.8229
2020-11-05 16:37:59,889 - root - INFO - Training: Epoch 0339 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2961 | Iter Mean Loss 11.1176
2020-11-05 16:37:59,890 - root - INFO - Evaluate: Epoch 0339 | NDCG 0.0000 | MSE 0.1987
2020-11-05 16:37:59,895 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0511 | Iter Mean Loss 16.0511
2020-11-05 16:37:59,901 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4332 | Iter Mean Loss 9.2422
2020-11-05 16:37:59,907 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.5335 | Iter Mean Loss 12.6726
2020-11-05 16:37:59,913 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1679 | Iter Mean Loss 12.7964
2020-11-05 16:37:59,918 - root - INFO - Training: Epoch 0340 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2934 | Iter Mean Loss 11.0958
2020-11-05 16:37:59,919 - root - INFO - Evaluate: Epoch 0340 | NDCG 0.0000 | MSE 0.1987
2020-11-05 16:37:59,925 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 16.0222 | Iter Mean Loss 16.0222
2020-11-05 16:37:59,930 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4291 | Iter Mean Loss 9.2256
2020-11-05 16:37:59,937 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4936 | Iter Mean Loss 12.6483
2020-11-05 16:37:59,942 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1351 | Iter Mean Loss 12.7700
2020-11-05 16:37:59,947 - root - INFO - Training: Epoch 0341 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2906 | Iter Mean Loss 11.0741
2020-11-05 16:37:59,948 - root - INFO - Evaluate: Epoch 0341 | NDCG 0.0000 | MSE 0.1986
2020-11-05 16:37:59,954 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9933 | Iter Mean Loss 15.9933
2020-11-05 16:37:59,960 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4250 | Iter Mean Loss 9.2092
2020-11-05 16:37:59,965 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4538 | Iter Mean Loss 12.6241
2020-11-05 16:37:59,972 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.1024 | Iter Mean Loss 12.7436
2020-11-05 16:37:59,977 - root - INFO - Training: Epoch 0342 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2878 | Iter Mean Loss 11.0525
2020-11-05 16:37:59,978 - root - INFO - Evaluate: Epoch 0342 | NDCG 0.0000 | MSE 0.1986
2020-11-05 16:37:59,984 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9646 | Iter Mean Loss 15.9646
2020-11-05 16:37:59,990 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4210 | Iter Mean Loss 9.1928
2020-11-05 16:37:59,995 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.4142 | Iter Mean Loss 12.5999
2020-11-05 16:38:00,001 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0697 | Iter Mean Loss 12.7174
2020-11-05 16:38:00,005 - root - INFO - Training: Epoch 0343 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2850 | Iter Mean Loss 11.0309
2020-11-05 16:38:00,006 - root - INFO - Evaluate: Epoch 0343 | NDCG 0.0000 | MSE 0.1985
2020-11-05 16:38:00,012 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9360 | Iter Mean Loss 15.9360
2020-11-05 16:38:00,017 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4169 | Iter Mean Loss 9.1764
2020-11-05 16:38:00,022 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3746 | Iter Mean Loss 12.5758
2020-11-05 16:38:00,028 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0371 | Iter Mean Loss 12.6911
2020-11-05 16:38:00,032 - root - INFO - Training: Epoch 0344 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2822 | Iter Mean Loss 11.0094
2020-11-05 16:38:00,033 - root - INFO - Evaluate: Epoch 0344 | NDCG 0.0000 | MSE 0.1985
2020-11-05 16:38:00,039 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.9075 | Iter Mean Loss 15.9075
2020-11-05 16:38:00,044 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4128 | Iter Mean Loss 9.1601
2020-11-05 16:38:00,049 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.3352 | Iter Mean Loss 12.5518
2020-11-05 16:38:00,055 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 13.0046 | Iter Mean Loss 12.6650
2020-11-05 16:38:00,059 - root - INFO - Training: Epoch 0345 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2794 | Iter Mean Loss 10.9879
2020-11-05 16:38:00,060 - root - INFO - Evaluate: Epoch 0345 | NDCG 0.0000 | MSE 0.1984
2020-11-05 16:38:00,065 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8791 | Iter Mean Loss 15.8791
2020-11-05 16:38:00,071 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4086 | Iter Mean Loss 9.1439
2020-11-05 16:38:00,076 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2959 | Iter Mean Loss 12.5279
2020-11-05 16:38:00,081 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9721 | Iter Mean Loss 12.6389
2020-11-05 16:38:00,086 - root - INFO - Training: Epoch 0346 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2766 | Iter Mean Loss 10.9665
2020-11-05 16:38:00,087 - root - INFO - Evaluate: Epoch 0346 | NDCG 0.0000 | MSE 0.1984
2020-11-05 16:38:00,092 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8508 | Iter Mean Loss 15.8508
2020-11-05 16:38:00,098 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4045 | Iter Mean Loss 9.1277
2020-11-05 16:38:00,104 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2567 | Iter Mean Loss 12.5040
2020-11-05 16:38:00,110 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9397 | Iter Mean Loss 12.6129
2020-11-05 16:38:00,115 - root - INFO - Training: Epoch 0347 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2738 | Iter Mean Loss 10.9451
2020-11-05 16:38:00,116 - root - INFO - Evaluate: Epoch 0347 | NDCG 0.0000 | MSE 0.1983
2020-11-05 16:38:00,122 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.8227 | Iter Mean Loss 15.8227
2020-11-05 16:38:00,128 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.4004 | Iter Mean Loss 9.1115
2020-11-05 16:38:00,134 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.2177 | Iter Mean Loss 12.4802
2020-11-05 16:38:00,140 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.9074 | Iter Mean Loss 12.5870
2020-11-05 16:38:00,144 - root - INFO - Training: Epoch 0348 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2710 | Iter Mean Loss 10.9238
2020-11-05 16:38:00,145 - root - INFO - Evaluate: Epoch 0348 | NDCG 0.0000 | MSE 0.1983
2020-11-05 16:38:00,152 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7946 | Iter Mean Loss 15.7946
2020-11-05 16:38:00,157 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3962 | Iter Mean Loss 9.0954
2020-11-05 16:38:00,163 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1787 | Iter Mean Loss 12.4565
2020-11-05 16:38:00,168 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8751 | Iter Mean Loss 12.5612
2020-11-05 16:38:00,173 - root - INFO - Training: Epoch 0349 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2681 | Iter Mean Loss 10.9026
2020-11-05 16:38:00,174 - root - INFO - Evaluate: Epoch 0349 | NDCG 0.0000 | MSE 0.1982
2020-11-05 16:38:00,180 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7667 | Iter Mean Loss 15.7667
2020-11-05 16:38:00,185 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3921 | Iter Mean Loss 9.0794
2020-11-05 16:38:00,191 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1399 | Iter Mean Loss 12.4329
2020-11-05 16:38:00,197 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8429 | Iter Mean Loss 12.5354
2020-11-05 16:38:00,201 - root - INFO - Training: Epoch 0350 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2653 | Iter Mean Loss 10.8814
2020-11-05 16:38:00,202 - root - INFO - Evaluate: Epoch 0350 | NDCG 0.0000 | MSE 0.1981
2020-11-05 16:38:00,208 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7389 | Iter Mean Loss 15.7389
2020-11-05 16:38:00,213 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3879 | Iter Mean Loss 9.0634
2020-11-05 16:38:00,218 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.1012 | Iter Mean Loss 12.4093
2020-11-05 16:38:00,224 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.8108 | Iter Mean Loss 12.5097
2020-11-05 16:38:00,228 - root - INFO - Training: Epoch 0351 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2624 | Iter Mean Loss 10.8602
2020-11-05 16:38:00,229 - root - INFO - Evaluate: Epoch 0351 | NDCG 0.0000 | MSE 0.1981
2020-11-05 16:38:00,235 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.7112 | Iter Mean Loss 15.7112
2020-11-05 16:38:00,240 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3838 | Iter Mean Loss 9.0475
2020-11-05 16:38:00,245 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0626 | Iter Mean Loss 12.3858
2020-11-05 16:38:00,250 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7788 | Iter Mean Loss 12.4841
2020-11-05 16:38:00,255 - root - INFO - Training: Epoch 0352 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2595 | Iter Mean Loss 10.8392
2020-11-05 16:38:00,256 - root - INFO - Evaluate: Epoch 0352 | NDCG 0.0000 | MSE 0.1980
2020-11-05 16:38:00,261 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6836 | Iter Mean Loss 15.6836
2020-11-05 16:38:00,267 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3796 | Iter Mean Loss 9.0316
2020-11-05 16:38:00,272 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 19.0241 | Iter Mean Loss 12.3624
2020-11-05 16:38:00,277 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7469 | Iter Mean Loss 12.4585
2020-11-05 16:38:00,282 - root - INFO - Training: Epoch 0353 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2567 | Iter Mean Loss 10.8182
2020-11-05 16:38:00,283 - root - INFO - Evaluate: Epoch 0353 | NDCG 0.0000 | MSE 0.1980
2020-11-05 16:38:00,288 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6561 | Iter Mean Loss 15.6561
2020-11-05 16:38:00,293 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3754 | Iter Mean Loss 9.0158
2020-11-05 16:38:00,299 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9858 | Iter Mean Loss 12.3391
2020-11-05 16:38:00,304 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.7150 | Iter Mean Loss 12.4331
2020-11-05 16:38:00,309 - root - INFO - Training: Epoch 0354 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2538 | Iter Mean Loss 10.7972
2020-11-05 16:38:00,310 - root - INFO - Evaluate: Epoch 0354 | NDCG 0.0000 | MSE 0.1979
2020-11-05 16:38:00,316 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6287 | Iter Mean Loss 15.6287
2020-11-05 16:38:00,323 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3713 | Iter Mean Loss 9.0000
2020-11-05 16:38:00,329 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9476 | Iter Mean Loss 12.3158
2020-11-05 16:38:00,334 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6832 | Iter Mean Loss 12.4077
2020-11-05 16:38:00,340 - root - INFO - Training: Epoch 0355 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2509 | Iter Mean Loss 10.7763
2020-11-05 16:38:00,341 - root - INFO - Evaluate: Epoch 0355 | NDCG 0.0000 | MSE 0.1979
2020-11-05 16:38:00,346 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.6014 | Iter Mean Loss 15.6014
2020-11-05 16:38:00,352 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3671 | Iter Mean Loss 8.9842
2020-11-05 16:38:00,358 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.9095 | Iter Mean Loss 12.2927
2020-11-05 16:38:00,364 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6515 | Iter Mean Loss 12.3824
2020-11-05 16:38:00,369 - root - INFO - Training: Epoch 0356 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2480 | Iter Mean Loss 10.7555
2020-11-05 16:38:00,370 - root - INFO - Evaluate: Epoch 0356 | NDCG 0.0000 | MSE 0.1978
2020-11-05 16:38:00,376 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5743 | Iter Mean Loss 15.5743
2020-11-05 16:38:00,382 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3629 | Iter Mean Loss 8.9686
2020-11-05 16:38:00,387 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8715 | Iter Mean Loss 12.2695
2020-11-05 16:38:00,393 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.6199 | Iter Mean Loss 12.3571
2020-11-05 16:38:00,398 - root - INFO - Training: Epoch 0357 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2451 | Iter Mean Loss 10.7347
2020-11-05 16:38:00,399 - root - INFO - Evaluate: Epoch 0357 | NDCG 0.0000 | MSE 0.1978
2020-11-05 16:38:00,405 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5472 | Iter Mean Loss 15.5472
2020-11-05 16:38:00,410 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3587 | Iter Mean Loss 8.9529
2020-11-05 16:38:00,415 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.8336 | Iter Mean Loss 12.2465
2020-11-05 16:38:00,421 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5884 | Iter Mean Loss 12.3320
2020-11-05 16:38:00,425 - root - INFO - Training: Epoch 0358 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2422 | Iter Mean Loss 10.7140
2020-11-05 16:38:00,426 - root - INFO - Evaluate: Epoch 0358 | NDCG 0.0000 | MSE 0.1977
2020-11-05 16:38:00,432 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.5203 | Iter Mean Loss 15.5203
2020-11-05 16:38:00,437 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3545 | Iter Mean Loss 8.9374
2020-11-05 16:38:00,442 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7959 | Iter Mean Loss 12.2235
2020-11-05 16:38:00,448 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5570 | Iter Mean Loss 12.3069
2020-11-05 16:38:00,452 - root - INFO - Training: Epoch 0359 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2393 | Iter Mean Loss 10.6934
2020-11-05 16:38:00,453 - root - INFO - Evaluate: Epoch 0359 | NDCG 0.0000 | MSE 0.1977
2020-11-05 16:38:00,458 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4934 | Iter Mean Loss 15.4934
2020-11-05 16:38:00,464 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3503 | Iter Mean Loss 8.9219
2020-11-05 16:38:00,469 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7582 | Iter Mean Loss 12.2006
2020-11-05 16:38:00,474 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.5257 | Iter Mean Loss 12.2819
2020-11-05 16:38:00,479 - root - INFO - Training: Epoch 0360 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2364 | Iter Mean Loss 10.6728
2020-11-05 16:38:00,480 - root - INFO - Evaluate: Epoch 0360 | NDCG 0.0000 | MSE 0.1976
2020-11-05 16:38:00,485 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4667 | Iter Mean Loss 15.4667
2020-11-05 16:38:00,491 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3461 | Iter Mean Loss 8.9064
2020-11-05 16:38:00,496 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.7207 | Iter Mean Loss 12.1778
2020-11-05 16:38:00,502 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4944 | Iter Mean Loss 12.2570
2020-11-05 16:38:00,507 - root - INFO - Training: Epoch 0361 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2335 | Iter Mean Loss 10.6523
2020-11-05 16:38:00,508 - root - INFO - Evaluate: Epoch 0361 | NDCG 0.0000 | MSE 0.1975
2020-11-05 16:38:00,514 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4400 | Iter Mean Loss 15.4400
2020-11-05 16:38:00,519 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3419 | Iter Mean Loss 8.8910
2020-11-05 16:38:00,524 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6833 | Iter Mean Loss 12.1551
2020-11-05 16:38:00,530 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4633 | Iter Mean Loss 12.2321
2020-11-05 16:38:00,535 - root - INFO - Training: Epoch 0362 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2306 | Iter Mean Loss 10.6318
2020-11-05 16:38:00,536 - root - INFO - Evaluate: Epoch 0362 | NDCG 0.0000 | MSE 0.1975
2020-11-05 16:38:00,542 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.4135 | Iter Mean Loss 15.4135
2020-11-05 16:38:00,548 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3377 | Iter Mean Loss 8.8756
2020-11-05 16:38:00,553 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6460 | Iter Mean Loss 12.1324
2020-11-05 16:38:00,559 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4323 | Iter Mean Loss 12.2074
2020-11-05 16:38:00,564 - root - INFO - Training: Epoch 0363 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2276 | Iter Mean Loss 10.6114
2020-11-05 16:38:00,565 - root - INFO - Evaluate: Epoch 0363 | NDCG 0.0000 | MSE 0.1974
2020-11-05 16:38:00,571 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3871 | Iter Mean Loss 15.3871
2020-11-05 16:38:00,576 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3335 | Iter Mean Loss 8.8603
2020-11-05 16:38:00,582 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.6089 | Iter Mean Loss 12.1098
2020-11-05 16:38:00,588 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.4014 | Iter Mean Loss 12.1827
2020-11-05 16:38:00,593 - root - INFO - Training: Epoch 0364 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2247 | Iter Mean Loss 10.5911
2020-11-05 16:38:00,594 - root - INFO - Evaluate: Epoch 0364 | NDCG 0.0000 | MSE 0.1974
2020-11-05 16:38:00,600 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3608 | Iter Mean Loss 15.3608
2020-11-05 16:38:00,605 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3293 | Iter Mean Loss 8.8450
2020-11-05 16:38:00,611 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5718 | Iter Mean Loss 12.0873
2020-11-05 16:38:00,616 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3706 | Iter Mean Loss 12.1581
2020-11-05 16:38:00,621 - root - INFO - Training: Epoch 0365 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2218 | Iter Mean Loss 10.5709
2020-11-05 16:38:00,621 - root - INFO - Evaluate: Epoch 0365 | NDCG 0.0000 | MSE 0.1973
2020-11-05 16:38:00,627 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3346 | Iter Mean Loss 15.3346
2020-11-05 16:38:00,632 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3251 | Iter Mean Loss 8.8298
2020-11-05 16:38:00,638 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.5349 | Iter Mean Loss 12.0649
2020-11-05 16:38:00,644 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3399 | Iter Mean Loss 12.1336
2020-11-05 16:38:00,648 - root - INFO - Training: Epoch 0366 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2188 | Iter Mean Loss 10.5507
2020-11-05 16:38:00,649 - root - INFO - Evaluate: Epoch 0366 | NDCG 0.0000 | MSE 0.1973
2020-11-05 16:38:00,655 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.3085 | Iter Mean Loss 15.3085
2020-11-05 16:38:00,660 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3209 | Iter Mean Loss 8.8147
2020-11-05 16:38:00,665 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4981 | Iter Mean Loss 12.0425
2020-11-05 16:38:00,670 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.3093 | Iter Mean Loss 12.1092
2020-11-05 16:38:00,675 - root - INFO - Training: Epoch 0367 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2159 | Iter Mean Loss 10.5305
2020-11-05 16:38:00,676 - root - INFO - Evaluate: Epoch 0367 | NDCG 0.0000 | MSE 0.1972
2020-11-05 16:38:00,681 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2825 | Iter Mean Loss 15.2825
2020-11-05 16:38:00,686 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3167 | Iter Mean Loss 8.7996
2020-11-05 16:38:00,692 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4613 | Iter Mean Loss 12.0202
2020-11-05 16:38:00,697 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2788 | Iter Mean Loss 12.0848
2020-11-05 16:38:00,702 - root - INFO - Training: Epoch 0368 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2130 | Iter Mean Loss 10.5105
2020-11-05 16:38:00,703 - root - INFO - Evaluate: Epoch 0368 | NDCG 0.0000 | MSE 0.1972
2020-11-05 16:38:00,708 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2566 | Iter Mean Loss 15.2566
2020-11-05 16:38:00,714 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3125 | Iter Mean Loss 8.7846
2020-11-05 16:38:00,720 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.4248 | Iter Mean Loss 11.9980
2020-11-05 16:38:00,726 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2485 | Iter Mean Loss 12.0606
2020-11-05 16:38:00,731 - root - INFO - Training: Epoch 0369 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2100 | Iter Mean Loss 10.4905
2020-11-05 16:38:00,732 - root - INFO - Evaluate: Epoch 0369 | NDCG 0.0000 | MSE 0.1971
2020-11-05 16:38:00,738 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2308 | Iter Mean Loss 15.2308
2020-11-05 16:38:00,744 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3084 | Iter Mean Loss 8.7696
2020-11-05 16:38:00,750 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3883 | Iter Mean Loss 11.9758
2020-11-05 16:38:00,755 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.2182 | Iter Mean Loss 12.0364
2020-11-05 16:38:00,760 - root - INFO - Training: Epoch 0370 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2071 | Iter Mean Loss 10.4706
2020-11-05 16:38:00,761 - root - INFO - Evaluate: Epoch 0370 | NDCG 0.0000 | MSE 0.1970
2020-11-05 16:38:00,767 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.2051 | Iter Mean Loss 15.2051
2020-11-05 16:38:00,773 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3042 | Iter Mean Loss 8.7546
2020-11-05 16:38:00,779 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3519 | Iter Mean Loss 11.9537
2020-11-05 16:38:00,784 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1881 | Iter Mean Loss 12.0123
2020-11-05 16:38:00,789 - root - INFO - Training: Epoch 0371 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2042 | Iter Mean Loss 10.4507
2020-11-05 16:38:00,790 - root - INFO - Evaluate: Epoch 0371 | NDCG 0.0000 | MSE 0.1970
2020-11-05 16:38:00,795 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1795 | Iter Mean Loss 15.1795
2020-11-05 16:38:00,802 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.3000 | Iter Mean Loss 8.7397
2020-11-05 16:38:00,807 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.3157 | Iter Mean Loss 11.9317
2020-11-05 16:38:00,813 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1581 | Iter Mean Loss 11.9883
2020-11-05 16:38:00,817 - root - INFO - Training: Epoch 0372 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.2012 | Iter Mean Loss 10.4309
2020-11-05 16:38:00,818 - root - INFO - Evaluate: Epoch 0372 | NDCG 0.0000 | MSE 0.1969
2020-11-05 16:38:00,823 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1540 | Iter Mean Loss 15.1540
2020-11-05 16:38:00,829 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2958 | Iter Mean Loss 8.7249
2020-11-05 16:38:00,834 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2796 | Iter Mean Loss 11.9098
2020-11-05 16:38:00,839 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.1283 | Iter Mean Loss 11.9644
2020-11-05 16:38:00,844 - root - INFO - Training: Epoch 0373 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1983 | Iter Mean Loss 10.4112
2020-11-05 16:38:00,845 - root - INFO - Evaluate: Epoch 0373 | NDCG 0.0000 | MSE 0.1969
2020-11-05 16:38:00,850 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1286 | Iter Mean Loss 15.1286
2020-11-05 16:38:00,856 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2916 | Iter Mean Loss 8.7101
2020-11-05 16:38:00,861 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2436 | Iter Mean Loss 11.8879
2020-11-05 16:38:00,866 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0985 | Iter Mean Loss 11.9406
2020-11-05 16:38:00,871 - root - INFO - Training: Epoch 0374 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1954 | Iter Mean Loss 10.3915
2020-11-05 16:38:00,871 - root - INFO - Evaluate: Epoch 0374 | NDCG 0.0000 | MSE 0.1968
2020-11-05 16:38:00,877 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.1033 | Iter Mean Loss 15.1033
2020-11-05 16:38:00,882 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2875 | Iter Mean Loss 8.6954
2020-11-05 16:38:00,888 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.2077 | Iter Mean Loss 11.8661
2020-11-05 16:38:00,893 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0689 | Iter Mean Loss 11.9168
2020-11-05 16:38:00,898 - root - INFO - Training: Epoch 0375 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1924 | Iter Mean Loss 10.3720
2020-11-05 16:38:00,898 - root - INFO - Evaluate: Epoch 0375 | NDCG 0.0000 | MSE 0.1968
2020-11-05 16:38:00,904 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0781 | Iter Mean Loss 15.0781
2020-11-05 16:38:00,910 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2833 | Iter Mean Loss 8.6807
2020-11-05 16:38:00,915 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1719 | Iter Mean Loss 11.8444
2020-11-05 16:38:00,921 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0395 | Iter Mean Loss 11.8932
2020-11-05 16:38:00,926 - root - INFO - Training: Epoch 0376 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1895 | Iter Mean Loss 10.3525
2020-11-05 16:38:00,927 - root - INFO - Evaluate: Epoch 0376 | NDCG 0.0000 | MSE 0.1967
2020-11-05 16:38:00,933 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0530 | Iter Mean Loss 15.0530
2020-11-05 16:38:00,938 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2792 | Iter Mean Loss 8.6661
2020-11-05 16:38:00,944 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1362 | Iter Mean Loss 11.8228
2020-11-05 16:38:00,950 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 12.0101 | Iter Mean Loss 11.8696
2020-11-05 16:38:00,955 - root - INFO - Training: Epoch 0377 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1866 | Iter Mean Loss 10.3330
2020-11-05 16:38:00,956 - root - INFO - Evaluate: Epoch 0377 | NDCG 0.0000 | MSE 0.1967
2020-11-05 16:38:00,962 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0280 | Iter Mean Loss 15.0280
2020-11-05 16:38:00,967 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2750 | Iter Mean Loss 8.6515
2020-11-05 16:38:00,973 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.1007 | Iter Mean Loss 11.8012
2020-11-05 16:38:00,979 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9809 | Iter Mean Loss 11.8462
2020-11-05 16:38:00,984 - root - INFO - Training: Epoch 0378 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1837 | Iter Mean Loss 10.3137
2020-11-05 16:38:00,985 - root - INFO - Evaluate: Epoch 0378 | NDCG 0.0000 | MSE 0.1966
2020-11-05 16:38:00,990 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 15.0031 | Iter Mean Loss 15.0031
2020-11-05 16:38:00,996 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2709 | Iter Mean Loss 8.6370
2020-11-05 16:38:01,002 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0652 | Iter Mean Loss 11.7798
2020-11-05 16:38:01,007 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9519 | Iter Mean Loss 11.8228
2020-11-05 16:38:01,012 - root - INFO - Training: Epoch 0379 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1807 | Iter Mean Loss 10.2944
2020-11-05 16:38:01,013 - root - INFO - Evaluate: Epoch 0379 | NDCG 0.0000 | MSE 0.1965
2020-11-05 16:38:01,018 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9784 | Iter Mean Loss 14.9784
2020-11-05 16:38:01,023 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2668 | Iter Mean Loss 8.6226
2020-11-05 16:38:01,029 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 18.0299 | Iter Mean Loss 11.7583
2020-11-05 16:38:01,034 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.9229 | Iter Mean Loss 11.7995
2020-11-05 16:38:01,039 - root - INFO - Training: Epoch 0380 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1778 | Iter Mean Loss 10.2752
2020-11-05 16:38:01,040 - root - INFO - Evaluate: Epoch 0380 | NDCG 0.0000 | MSE 0.1965
2020-11-05 16:38:01,045 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9537 | Iter Mean Loss 14.9537
2020-11-05 16:38:01,050 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2627 | Iter Mean Loss 8.6082
2020-11-05 16:38:01,056 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9947 | Iter Mean Loss 11.7370
2020-11-05 16:38:01,061 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8941 | Iter Mean Loss 11.7763
2020-11-05 16:38:01,066 - root - INFO - Training: Epoch 0381 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1749 | Iter Mean Loss 10.2560
2020-11-05 16:38:01,066 - root - INFO - Evaluate: Epoch 0381 | NDCG 0.0000 | MSE 0.1964
2020-11-05 16:38:01,072 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9291 | Iter Mean Loss 14.9291
2020-11-05 16:38:01,077 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2586 | Iter Mean Loss 8.5938
2020-11-05 16:38:01,082 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9596 | Iter Mean Loss 11.7157
2020-11-05 16:38:01,088 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8655 | Iter Mean Loss 11.7532
2020-11-05 16:38:01,092 - root - INFO - Training: Epoch 0382 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1720 | Iter Mean Loss 10.2369
2020-11-05 16:38:01,093 - root - INFO - Evaluate: Epoch 0382 | NDCG 0.0000 | MSE 0.1964
2020-11-05 16:38:01,099 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.9046 | Iter Mean Loss 14.9046
2020-11-05 16:38:01,104 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2545 | Iter Mean Loss 8.5795
2020-11-05 16:38:01,110 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.9246 | Iter Mean Loss 11.6945
2020-11-05 16:38:01,116 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8370 | Iter Mean Loss 11.7302
2020-11-05 16:38:01,120 - root - INFO - Training: Epoch 0383 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1691 | Iter Mean Loss 10.2179
2020-11-05 16:38:01,121 - root - INFO - Evaluate: Epoch 0383 | NDCG 0.0000 | MSE 0.1963
2020-11-05 16:38:01,127 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8802 | Iter Mean Loss 14.8802
2020-11-05 16:38:01,133 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2504 | Iter Mean Loss 8.5653
2020-11-05 16:38:01,139 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8897 | Iter Mean Loss 11.6734
2020-11-05 16:38:01,144 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.8086 | Iter Mean Loss 11.7072
2020-11-05 16:38:01,150 - root - INFO - Training: Epoch 0384 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1662 | Iter Mean Loss 10.1990
2020-11-05 16:38:01,151 - root - INFO - Evaluate: Epoch 0384 | NDCG 0.0000 | MSE 0.1963
2020-11-05 16:38:01,157 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8559 | Iter Mean Loss 14.8559
2020-11-05 16:38:01,162 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2463 | Iter Mean Loss 8.5511
2020-11-05 16:38:01,169 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8549 | Iter Mean Loss 11.6524
2020-11-05 16:38:01,174 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7804 | Iter Mean Loss 11.6844
2020-11-05 16:38:01,180 - root - INFO - Training: Epoch 0385 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1632 | Iter Mean Loss 10.1802
2020-11-05 16:38:01,181 - root - INFO - Evaluate: Epoch 0385 | NDCG 0.0000 | MSE 0.1962
2020-11-05 16:38:01,187 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8317 | Iter Mean Loss 14.8317
2020-11-05 16:38:01,193 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2422 | Iter Mean Loss 8.5369
2020-11-05 16:38:01,199 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.8203 | Iter Mean Loss 11.6314
2020-11-05 16:38:01,205 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7524 | Iter Mean Loss 11.6616
2020-11-05 16:38:01,209 - root - INFO - Training: Epoch 0386 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1603 | Iter Mean Loss 10.1614
2020-11-05 16:38:01,210 - root - INFO - Evaluate: Epoch 0386 | NDCG 0.0000 | MSE 0.1962
2020-11-05 16:38:01,216 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.8075 | Iter Mean Loss 14.8075
2020-11-05 16:38:01,221 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2382 | Iter Mean Loss 8.5229
2020-11-05 16:38:01,227 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7857 | Iter Mean Loss 11.6105
2020-11-05 16:38:01,232 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.7245 | Iter Mean Loss 11.6390
2020-11-05 16:38:01,237 - root - INFO - Training: Epoch 0387 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1575 | Iter Mean Loss 10.1427
2020-11-05 16:38:01,237 - root - INFO - Evaluate: Epoch 0387 | NDCG 0.0000 | MSE 0.1961
2020-11-05 16:38:01,243 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7835 | Iter Mean Loss 14.7835
2020-11-05 16:38:01,249 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2341 | Iter Mean Loss 8.5088
2020-11-05 16:38:01,257 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7513 | Iter Mean Loss 11.5897
2020-11-05 16:38:01,265 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6967 | Iter Mean Loss 11.6164
2020-11-05 16:38:01,270 - root - INFO - Training: Epoch 0388 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1546 | Iter Mean Loss 10.1240
2020-11-05 16:38:01,271 - root - INFO - Evaluate: Epoch 0388 | NDCG 0.0000 | MSE 0.1960
2020-11-05 16:38:01,277 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7596 | Iter Mean Loss 14.7596
2020-11-05 16:38:01,283 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2301 | Iter Mean Loss 8.4949
2020-11-05 16:38:01,289 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.7170 | Iter Mean Loss 11.5689
2020-11-05 16:38:01,295 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6691 | Iter Mean Loss 11.5940
2020-11-05 16:38:01,300 - root - INFO - Training: Epoch 0389 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1517 | Iter Mean Loss 10.1055
2020-11-05 16:38:01,301 - root - INFO - Evaluate: Epoch 0389 | NDCG 0.0000 | MSE 0.1960
2020-11-05 16:38:01,307 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7358 | Iter Mean Loss 14.7358
2020-11-05 16:38:01,314 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2261 | Iter Mean Loss 8.4809
2020-11-05 16:38:01,321 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6828 | Iter Mean Loss 11.5482
2020-11-05 16:38:01,330 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6417 | Iter Mean Loss 11.5716
2020-11-05 16:38:01,336 - root - INFO - Training: Epoch 0390 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1488 | Iter Mean Loss 10.0870
2020-11-05 16:38:01,337 - root - INFO - Evaluate: Epoch 0390 | NDCG 0.0000 | MSE 0.1959
2020-11-05 16:38:01,344 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.7120 | Iter Mean Loss 14.7120
2020-11-05 16:38:01,351 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2221 | Iter Mean Loss 8.4671
2020-11-05 16:38:01,357 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6487 | Iter Mean Loss 11.5276
2020-11-05 16:38:01,365 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.6144 | Iter Mean Loss 11.5493
2020-11-05 16:38:01,372 - root - INFO - Training: Epoch 0391 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1459 | Iter Mean Loss 10.0686
2020-11-05 16:38:01,373 - root - INFO - Evaluate: Epoch 0391 | NDCG 0.0000 | MSE 0.1959
2020-11-05 16:38:01,382 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6884 | Iter Mean Loss 14.6884
2020-11-05 16:38:01,388 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2181 | Iter Mean Loss 8.4532
2020-11-05 16:38:01,394 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.6147 | Iter Mean Loss 11.5071
2020-11-05 16:38:01,400 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5872 | Iter Mean Loss 11.5271
2020-11-05 16:38:01,405 - root - INFO - Training: Epoch 0392 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1431 | Iter Mean Loss 10.0503
2020-11-05 16:38:01,406 - root - INFO - Evaluate: Epoch 0392 | NDCG 0.0000 | MSE 0.1958
2020-11-05 16:38:01,412 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6649 | Iter Mean Loss 14.6649
2020-11-05 16:38:01,418 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2141 | Iter Mean Loss 8.4395
2020-11-05 16:38:01,423 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5808 | Iter Mean Loss 11.4866
2020-11-05 16:38:01,428 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5603 | Iter Mean Loss 11.5050
2020-11-05 16:38:01,433 - root - INFO - Training: Epoch 0393 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1402 | Iter Mean Loss 10.0320
2020-11-05 16:38:01,434 - root - INFO - Evaluate: Epoch 0393 | NDCG 0.0000 | MSE 0.1958
2020-11-05 16:38:01,439 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6414 | Iter Mean Loss 14.6414
2020-11-05 16:38:01,445 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2101 | Iter Mean Loss 8.4258
2020-11-05 16:38:01,450 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5470 | Iter Mean Loss 11.4662
2020-11-05 16:38:01,455 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5334 | Iter Mean Loss 11.4830
2020-11-05 16:38:01,460 - root - INFO - Training: Epoch 0394 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1373 | Iter Mean Loss 10.0139
2020-11-05 16:38:01,461 - root - INFO - Evaluate: Epoch 0394 | NDCG 0.0000 | MSE 0.1957
2020-11-05 16:38:01,466 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.6180 | Iter Mean Loss 14.6180
2020-11-05 16:38:01,471 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2062 | Iter Mean Loss 8.4121
2020-11-05 16:38:01,477 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.5133 | Iter Mean Loss 11.4459
2020-11-05 16:38:01,482 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.5068 | Iter Mean Loss 11.4611
2020-11-05 16:38:01,487 - root - INFO - Training: Epoch 0395 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1345 | Iter Mean Loss 9.9958
2020-11-05 16:38:01,488 - root - INFO - Evaluate: Epoch 0395 | NDCG 0.0000 | MSE 0.1956
2020-11-05 16:38:01,493 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5948 | Iter Mean Loss 14.5948
2020-11-05 16:38:01,498 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.2023 | Iter Mean Loss 8.3985
2020-11-05 16:38:01,504 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4798 | Iter Mean Loss 11.4256
2020-11-05 16:38:01,510 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4803 | Iter Mean Loss 11.4393
2020-11-05 16:38:01,515 - root - INFO - Training: Epoch 0396 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1316 | Iter Mean Loss 9.9777
2020-11-05 16:38:01,516 - root - INFO - Evaluate: Epoch 0396 | NDCG 0.0000 | MSE 0.1956
2020-11-05 16:38:01,522 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5716 | Iter Mean Loss 14.5716
2020-11-05 16:38:01,528 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1983 | Iter Mean Loss 8.3850
2020-11-05 16:38:01,533 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4463 | Iter Mean Loss 11.4054
2020-11-05 16:38:01,539 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4539 | Iter Mean Loss 11.4175
2020-11-05 16:38:01,544 - root - INFO - Training: Epoch 0397 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1288 | Iter Mean Loss 9.9598
2020-11-05 16:38:01,545 - root - INFO - Evaluate: Epoch 0397 | NDCG 0.0000 | MSE 0.1955
2020-11-05 16:38:01,551 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5485 | Iter Mean Loss 14.5485
2020-11-05 16:38:01,557 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1944 | Iter Mean Loss 8.3715
2020-11-05 16:38:01,563 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.4130 | Iter Mean Loss 11.3853
2020-11-05 16:38:01,568 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4277 | Iter Mean Loss 11.3959
2020-11-05 16:38:01,574 - root - INFO - Training: Epoch 0398 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1260 | Iter Mean Loss 9.9419
2020-11-05 16:38:01,575 - root - INFO - Evaluate: Epoch 0398 | NDCG 0.0000 | MSE 0.1955
2020-11-05 16:38:01,580 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5255 | Iter Mean Loss 14.5255
2020-11-05 16:38:01,586 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1905 | Iter Mean Loss 8.3580
2020-11-05 16:38:01,592 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3797 | Iter Mean Loss 11.3653
2020-11-05 16:38:01,598 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.4017 | Iter Mean Loss 11.3744
2020-11-05 16:38:01,603 - root - INFO - Training: Epoch 0399 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1232 | Iter Mean Loss 9.9241
2020-11-05 16:38:01,604 - root - INFO - Evaluate: Epoch 0399 | NDCG 0.0000 | MSE 0.1954
2020-11-05 16:38:01,610 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.5026 | Iter Mean Loss 14.5026
2020-11-05 16:38:01,616 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1867 | Iter Mean Loss 8.3446
2020-11-05 16:38:01,621 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3466 | Iter Mean Loss 11.3453
2020-11-05 16:38:01,626 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3759 | Iter Mean Loss 11.3529
2020-11-05 16:38:01,631 - root - INFO - Training: Epoch 0400 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1203 | Iter Mean Loss 9.9064
2020-11-05 16:38:01,632 - root - INFO - Evaluate: Epoch 0400 | NDCG 0.0000 | MSE 0.1954
2020-11-05 16:38:01,638 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4798 | Iter Mean Loss 14.4798
2020-11-05 16:38:01,644 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1828 | Iter Mean Loss 8.3313
2020-11-05 16:38:01,649 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.3136 | Iter Mean Loss 11.3254
2020-11-05 16:38:01,654 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3502 | Iter Mean Loss 11.3316
2020-11-05 16:38:01,659 - root - INFO - Training: Epoch 0401 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1175 | Iter Mean Loss 9.8888
2020-11-05 16:38:01,660 - root - INFO - Evaluate: Epoch 0401 | NDCG 0.0000 | MSE 0.1953
2020-11-05 16:38:01,665 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4571 | Iter Mean Loss 14.4571
2020-11-05 16:38:01,670 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1790 | Iter Mean Loss 8.3180
2020-11-05 16:38:01,676 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2806 | Iter Mean Loss 11.3056
2020-11-05 16:38:01,681 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.3246 | Iter Mean Loss 11.3103
2020-11-05 16:38:01,686 - root - INFO - Training: Epoch 0402 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1147 | Iter Mean Loss 9.8712
2020-11-05 16:38:01,686 - root - INFO - Evaluate: Epoch 0402 | NDCG 0.0000 | MSE 0.1953
2020-11-05 16:38:01,692 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4344 | Iter Mean Loss 14.4344
2020-11-05 16:38:01,697 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1751 | Iter Mean Loss 8.3048
2020-11-05 16:38:01,702 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2478 | Iter Mean Loss 11.2858
2020-11-05 16:38:01,708 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2992 | Iter Mean Loss 11.2892
2020-11-05 16:38:01,712 - root - INFO - Training: Epoch 0403 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1120 | Iter Mean Loss 9.8537
2020-11-05 16:38:01,713 - root - INFO - Evaluate: Epoch 0403 | NDCG 0.0000 | MSE 0.1952
2020-11-05 16:38:01,720 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.4119 | Iter Mean Loss 14.4119
2020-11-05 16:38:01,725 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1713 | Iter Mean Loss 8.2916
2020-11-05 16:38:01,731 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.2151 | Iter Mean Loss 11.2661
2020-11-05 16:38:01,737 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2740 | Iter Mean Loss 11.2681
2020-11-05 16:38:01,742 - root - INFO - Training: Epoch 0404 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1092 | Iter Mean Loss 9.8363
2020-11-05 16:38:01,743 - root - INFO - Evaluate: Epoch 0404 | NDCG 0.0000 | MSE 0.1951
2020-11-05 16:38:01,748 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3894 | Iter Mean Loss 14.3894
2020-11-05 16:38:01,754 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1675 | Iter Mean Loss 8.2785
2020-11-05 16:38:01,760 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1825 | Iter Mean Loss 11.2465
2020-11-05 16:38:01,766 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2490 | Iter Mean Loss 11.2471
2020-11-05 16:38:01,771 - root - INFO - Training: Epoch 0405 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1064 | Iter Mean Loss 9.8190
2020-11-05 16:38:01,772 - root - INFO - Evaluate: Epoch 0405 | NDCG 0.0000 | MSE 0.1951
2020-11-05 16:38:01,777 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3670 | Iter Mean Loss 14.3670
2020-11-05 16:38:01,783 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1637 | Iter Mean Loss 8.2654
2020-11-05 16:38:01,789 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1499 | Iter Mean Loss 11.2269
2020-11-05 16:38:01,795 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.2241 | Iter Mean Loss 11.2262
2020-11-05 16:38:01,800 - root - INFO - Training: Epoch 0406 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1036 | Iter Mean Loss 9.8017
2020-11-05 16:38:01,800 - root - INFO - Evaluate: Epoch 0406 | NDCG 0.0000 | MSE 0.1950
2020-11-05 16:38:01,806 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3448 | Iter Mean Loss 14.3448
2020-11-05 16:38:01,812 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1600 | Iter Mean Loss 8.2524
2020-11-05 16:38:01,818 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.1175 | Iter Mean Loss 11.2074
2020-11-05 16:38:01,823 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1994 | Iter Mean Loss 11.2054
2020-11-05 16:38:01,828 - root - INFO - Training: Epoch 0407 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.1009 | Iter Mean Loss 9.7845
2020-11-05 16:38:01,829 - root - INFO - Evaluate: Epoch 0407 | NDCG 0.0000 | MSE 0.1950
2020-11-05 16:38:01,834 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3225 | Iter Mean Loss 14.3225
2020-11-05 16:38:01,839 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1562 | Iter Mean Loss 8.2394
2020-11-05 16:38:01,845 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0852 | Iter Mean Loss 11.1880
2020-11-05 16:38:01,850 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1748 | Iter Mean Loss 11.1847
2020-11-05 16:38:01,855 - root - INFO - Training: Epoch 0408 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0981 | Iter Mean Loss 9.7674
2020-11-05 16:38:01,855 - root - INFO - Evaluate: Epoch 0408 | NDCG 0.0000 | MSE 0.1949
2020-11-05 16:38:01,861 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.3004 | Iter Mean Loss 14.3004
2020-11-05 16:38:01,866 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1525 | Iter Mean Loss 8.2265
2020-11-05 16:38:01,871 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0530 | Iter Mean Loss 11.1686
2020-11-05 16:38:01,877 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1504 | Iter Mean Loss 11.1641
2020-11-05 16:38:01,881 - root - INFO - Training: Epoch 0409 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0954 | Iter Mean Loss 9.7503
2020-11-05 16:38:01,882 - root - INFO - Evaluate: Epoch 0409 | NDCG 0.0000 | MSE 0.1949
2020-11-05 16:38:01,887 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2784 | Iter Mean Loss 14.2784
2020-11-05 16:38:01,893 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1488 | Iter Mean Loss 8.2136
2020-11-05 16:38:01,898 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 17.0209 | Iter Mean Loss 11.1494
2020-11-05 16:38:01,903 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1262 | Iter Mean Loss 11.1436
2020-11-05 16:38:01,908 - root - INFO - Training: Epoch 0410 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0926 | Iter Mean Loss 9.7334
2020-11-05 16:38:01,909 - root - INFO - Evaluate: Epoch 0410 | NDCG 0.0000 | MSE 0.1948
2020-11-05 16:38:01,914 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2564 | Iter Mean Loss 14.2564
2020-11-05 16:38:01,920 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1451 | Iter Mean Loss 8.2008
2020-11-05 16:38:01,926 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9889 | Iter Mean Loss 11.1301
2020-11-05 16:38:01,931 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.1021 | Iter Mean Loss 11.1231
2020-11-05 16:38:01,936 - root - INFO - Training: Epoch 0411 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0899 | Iter Mean Loss 9.7165
2020-11-05 16:38:01,938 - root - INFO - Evaluate: Epoch 0411 | NDCG 0.0000 | MSE 0.1947
2020-11-05 16:38:01,944 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2346 | Iter Mean Loss 14.2346
2020-11-05 16:38:01,949 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1414 | Iter Mean Loss 8.1880
2020-11-05 16:38:01,955 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9569 | Iter Mean Loss 11.1110
2020-11-05 16:38:01,961 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0782 | Iter Mean Loss 11.1028
2020-11-05 16:38:01,966 - root - INFO - Training: Epoch 0412 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0872 | Iter Mean Loss 9.6997
2020-11-05 16:38:01,966 - root - INFO - Evaluate: Epoch 0412 | NDCG 0.0000 | MSE 0.1947
2020-11-05 16:38:01,973 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.2128 | Iter Mean Loss 14.2128
2020-11-05 16:38:01,978 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1378 | Iter Mean Loss 8.1753
2020-11-05 16:38:01,984 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.9251 | Iter Mean Loss 11.0919
2020-11-05 16:38:01,990 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0545 | Iter Mean Loss 11.0825
2020-11-05 16:38:01,995 - root - INFO - Training: Epoch 0413 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0845 | Iter Mean Loss 9.6829
2020-11-05 16:38:01,996 - root - INFO - Evaluate: Epoch 0413 | NDCG 0.0000 | MSE 0.1946
2020-11-05 16:38:02,001 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1911 | Iter Mean Loss 14.1911
2020-11-05 16:38:02,006 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1341 | Iter Mean Loss 8.1626
2020-11-05 16:38:02,012 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8934 | Iter Mean Loss 11.0729
2020-11-05 16:38:02,018 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0309 | Iter Mean Loss 11.0624
2020-11-05 16:38:02,023 - root - INFO - Training: Epoch 0414 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0818 | Iter Mean Loss 9.6663
2020-11-05 16:38:02,024 - root - INFO - Evaluate: Epoch 0414 | NDCG 0.0000 | MSE 0.1946
2020-11-05 16:38:02,029 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1695 | Iter Mean Loss 14.1695
2020-11-05 16:38:02,034 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1305 | Iter Mean Loss 8.1500
2020-11-05 16:38:02,040 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8618 | Iter Mean Loss 11.0539
2020-11-05 16:38:02,045 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 11.0074 | Iter Mean Loss 11.0423
2020-11-05 16:38:02,050 - root - INFO - Training: Epoch 0415 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0791 | Iter Mean Loss 9.6497
2020-11-05 16:38:02,050 - root - INFO - Evaluate: Epoch 0415 | NDCG 0.0000 | MSE 0.1945
2020-11-05 16:38:02,056 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1479 | Iter Mean Loss 14.1479
2020-11-05 16:38:02,061 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1269 | Iter Mean Loss 8.1374
2020-11-05 16:38:02,066 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.8302 | Iter Mean Loss 11.0350
2020-11-05 16:38:02,072 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9842 | Iter Mean Loss 11.0223
2020-11-05 16:38:02,076 - root - INFO - Training: Epoch 0416 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0764 | Iter Mean Loss 9.6331
2020-11-05 16:38:02,077 - root - INFO - Evaluate: Epoch 0416 | NDCG 0.0000 | MSE 0.1945
2020-11-05 16:38:02,083 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1265 | Iter Mean Loss 14.1265
2020-11-05 16:38:02,088 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1233 | Iter Mean Loss 8.1249
2020-11-05 16:38:02,093 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7988 | Iter Mean Loss 11.0162
2020-11-05 16:38:02,099 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9611 | Iter Mean Loss 11.0024
2020-11-05 16:38:02,104 - root - INFO - Training: Epoch 0417 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0738 | Iter Mean Loss 9.6167
2020-11-05 16:38:02,105 - root - INFO - Evaluate: Epoch 0417 | NDCG 0.0000 | MSE 0.1944
2020-11-05 16:38:02,111 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.1051 | Iter Mean Loss 14.1051
2020-11-05 16:38:02,117 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1197 | Iter Mean Loss 8.1124
2020-11-05 16:38:02,122 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7675 | Iter Mean Loss 10.9974
2020-11-05 16:38:02,128 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9381 | Iter Mean Loss 10.9826
2020-11-05 16:38:02,133 - root - INFO - Training: Epoch 0418 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0711 | Iter Mean Loss 9.6003
2020-11-05 16:38:02,134 - root - INFO - Evaluate: Epoch 0418 | NDCG 0.0000 | MSE 0.1944
2020-11-05 16:38:02,140 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0838 | Iter Mean Loss 14.0838
2020-11-05 16:38:02,146 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1161 | Iter Mean Loss 8.1000
2020-11-05 16:38:02,152 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7362 | Iter Mean Loss 10.9787
2020-11-05 16:38:02,157 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.9153 | Iter Mean Loss 10.9629
2020-11-05 16:38:02,163 - root - INFO - Training: Epoch 0419 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0685 | Iter Mean Loss 9.5840
2020-11-05 16:38:02,164 - root - INFO - Evaluate: Epoch 0419 | NDCG 0.0000 | MSE 0.1943
2020-11-05 16:38:02,169 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0626 | Iter Mean Loss 14.0626
2020-11-05 16:38:02,175 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1126 | Iter Mean Loss 8.0876
2020-11-05 16:38:02,181 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.7051 | Iter Mean Loss 10.9601
2020-11-05 16:38:02,186 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8927 | Iter Mean Loss 10.9432
2020-11-05 16:38:02,192 - root - INFO - Training: Epoch 0420 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0658 | Iter Mean Loss 9.5678
2020-11-05 16:38:02,193 - root - INFO - Evaluate: Epoch 0420 | NDCG 0.0000 | MSE 0.1942
2020-11-05 16:38:02,199 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0415 | Iter Mean Loss 14.0415
2020-11-05 16:38:02,204 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1091 | Iter Mean Loss 8.0753
2020-11-05 16:38:02,210 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6740 | Iter Mean Loss 10.9415
2020-11-05 16:38:02,216 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8702 | Iter Mean Loss 10.9237
2020-11-05 16:38:02,221 - root - INFO - Training: Epoch 0421 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0632 | Iter Mean Loss 9.5516
2020-11-05 16:38:02,222 - root - INFO - Evaluate: Epoch 0421 | NDCG 0.0000 | MSE 0.1942
2020-11-05 16:38:02,227 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 14.0204 | Iter Mean Loss 14.0204
2020-11-05 16:38:02,232 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1055 | Iter Mean Loss 8.0630
2020-11-05 16:38:02,238 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6430 | Iter Mean Loss 10.9230
2020-11-05 16:38:02,243 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8479 | Iter Mean Loss 10.9042
2020-11-05 16:38:02,248 - root - INFO - Training: Epoch 0422 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0605 | Iter Mean Loss 9.5355
2020-11-05 16:38:02,248 - root - INFO - Evaluate: Epoch 0422 | NDCG 0.0000 | MSE 0.1941
2020-11-05 16:38:02,254 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9995 | Iter Mean Loss 13.9995
2020-11-05 16:38:02,259 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.1020 | Iter Mean Loss 8.0508
2020-11-05 16:38:02,264 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.6121 | Iter Mean Loss 10.9045
2020-11-05 16:38:02,270 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8258 | Iter Mean Loss 10.8849
2020-11-05 16:38:02,274 - root - INFO - Training: Epoch 0423 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0579 | Iter Mean Loss 9.5195
2020-11-05 16:38:02,275 - root - INFO - Evaluate: Epoch 0423 | NDCG 0.0000 | MSE 0.1941
2020-11-05 16:38:02,280 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9786 | Iter Mean Loss 13.9786
2020-11-05 16:38:02,286 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0986 | Iter Mean Loss 8.0386
2020-11-05 16:38:02,291 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5813 | Iter Mean Loss 10.8862
2020-11-05 16:38:02,297 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.8038 | Iter Mean Loss 10.8656
2020-11-05 16:38:02,301 - root - INFO - Training: Epoch 0424 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0553 | Iter Mean Loss 9.5035
2020-11-05 16:38:02,302 - root - INFO - Evaluate: Epoch 0424 | NDCG 0.0000 | MSE 0.1940
2020-11-05 16:38:02,307 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9577 | Iter Mean Loss 13.9577
2020-11-05 16:38:02,313 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0951 | Iter Mean Loss 8.0264
2020-11-05 16:38:02,320 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5506 | Iter Mean Loss 10.8678
2020-11-05 16:38:02,326 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7819 | Iter Mean Loss 10.8464
2020-11-05 16:38:02,331 - root - INFO - Training: Epoch 0425 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0527 | Iter Mean Loss 9.4876
2020-11-05 16:38:02,332 - root - INFO - Evaluate: Epoch 0425 | NDCG 0.0000 | MSE 0.1940
2020-11-05 16:38:02,338 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9370 | Iter Mean Loss 13.9370
2020-11-05 16:38:02,343 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0917 | Iter Mean Loss 8.0143
2020-11-05 16:38:02,349 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.5200 | Iter Mean Loss 10.8496
2020-11-05 16:38:02,355 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7602 | Iter Mean Loss 10.8272
2020-11-05 16:38:02,360 - root - INFO - Training: Epoch 0426 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0501 | Iter Mean Loss 9.4718
2020-11-05 16:38:02,361 - root - INFO - Evaluate: Epoch 0426 | NDCG 0.0000 | MSE 0.1939
2020-11-05 16:38:02,367 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.9163 | Iter Mean Loss 13.9163
2020-11-05 16:38:02,373 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0882 | Iter Mean Loss 8.0023
2020-11-05 16:38:02,379 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4895 | Iter Mean Loss 10.8314
2020-11-05 16:38:02,385 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7387 | Iter Mean Loss 10.8082
2020-11-05 16:38:02,390 - root - INFO - Training: Epoch 0427 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0476 | Iter Mean Loss 9.4561
2020-11-05 16:38:02,391 - root - INFO - Evaluate: Epoch 0427 | NDCG 0.0000 | MSE 0.1938
2020-11-05 16:38:02,397 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8957 | Iter Mean Loss 13.8957
2020-11-05 16:38:02,403 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0848 | Iter Mean Loss 7.9903
2020-11-05 16:38:02,409 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4591 | Iter Mean Loss 10.8132
2020-11-05 16:38:02,415 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.7173 | Iter Mean Loss 10.7892
2020-11-05 16:38:02,420 - root - INFO - Training: Epoch 0428 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0450 | Iter Mean Loss 9.4404
2020-11-05 16:38:02,421 - root - INFO - Evaluate: Epoch 0428 | NDCG 0.0000 | MSE 0.1938
2020-11-05 16:38:02,426 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8752 | Iter Mean Loss 13.8752
2020-11-05 16:38:02,431 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0814 | Iter Mean Loss 7.9783
2020-11-05 16:38:02,437 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.4287 | Iter Mean Loss 10.7951
2020-11-05 16:38:02,442 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6961 | Iter Mean Loss 10.7704
2020-11-05 16:38:02,447 - root - INFO - Training: Epoch 0429 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0424 | Iter Mean Loss 9.4248
2020-11-05 16:38:02,448 - root - INFO - Evaluate: Epoch 0429 | NDCG 0.0000 | MSE 0.1937
2020-11-05 16:38:02,453 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8548 | Iter Mean Loss 13.8548
2020-11-05 16:38:02,459 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0780 | Iter Mean Loss 7.9664
2020-11-05 16:38:02,464 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3985 | Iter Mean Loss 10.7771
2020-11-05 16:38:02,470 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6750 | Iter Mean Loss 10.7516
2020-11-05 16:38:02,474 - root - INFO - Training: Epoch 0430 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0399 | Iter Mean Loss 9.4092
2020-11-05 16:38:02,475 - root - INFO - Evaluate: Epoch 0430 | NDCG 0.0000 | MSE 0.1937
2020-11-05 16:38:02,481 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8344 | Iter Mean Loss 13.8344
2020-11-05 16:38:02,486 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0747 | Iter Mean Loss 7.9545
2020-11-05 16:38:02,492 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3683 | Iter Mean Loss 10.7591
2020-11-05 16:38:02,497 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6540 | Iter Mean Loss 10.7328
2020-11-05 16:38:02,502 - root - INFO - Training: Epoch 0431 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0373 | Iter Mean Loss 9.3937
2020-11-05 16:38:02,503 - root - INFO - Evaluate: Epoch 0431 | NDCG 0.0000 | MSE 0.1936
2020-11-05 16:38:02,508 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.8141 | Iter Mean Loss 13.8141
2020-11-05 16:38:02,514 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0713 | Iter Mean Loss 7.9427
2020-11-05 16:38:02,519 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3382 | Iter Mean Loss 10.7412
2020-11-05 16:38:02,525 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6332 | Iter Mean Loss 10.7142
2020-11-05 16:38:02,530 - root - INFO - Training: Epoch 0432 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0348 | Iter Mean Loss 9.3783
2020-11-05 16:38:02,531 - root - INFO - Evaluate: Epoch 0432 | NDCG 0.0000 | MSE 0.1936
2020-11-05 16:38:02,537 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7939 | Iter Mean Loss 13.7939
2020-11-05 16:38:02,542 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0680 | Iter Mean Loss 7.9309
2020-11-05 16:38:02,548 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.3082 | Iter Mean Loss 10.7234
2020-11-05 16:38:02,554 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.6126 | Iter Mean Loss 10.6957
2020-11-05 16:38:02,559 - root - INFO - Training: Epoch 0433 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0323 | Iter Mean Loss 9.3630
2020-11-05 16:38:02,560 - root - INFO - Evaluate: Epoch 0433 | NDCG 0.0000 | MSE 0.1935
2020-11-05 16:38:02,566 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7737 | Iter Mean Loss 13.7737
2020-11-05 16:38:02,571 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0647 | Iter Mean Loss 7.9192
2020-11-05 16:38:02,577 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2783 | Iter Mean Loss 10.7056
2020-11-05 16:38:02,583 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5921 | Iter Mean Loss 10.6772
2020-11-05 16:38:02,588 - root - INFO - Training: Epoch 0434 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0297 | Iter Mean Loss 9.3477
2020-11-05 16:38:02,589 - root - INFO - Evaluate: Epoch 0434 | NDCG 0.0000 | MSE 0.1935
2020-11-05 16:38:02,595 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7536 | Iter Mean Loss 13.7536
2020-11-05 16:38:02,601 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0613 | Iter Mean Loss 7.9075
2020-11-05 16:38:02,606 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2484 | Iter Mean Loss 10.6878
2020-11-05 16:38:02,612 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5717 | Iter Mean Loss 10.6588
2020-11-05 16:38:02,617 - root - INFO - Training: Epoch 0435 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0272 | Iter Mean Loss 9.3325
2020-11-05 16:38:02,618 - root - INFO - Evaluate: Epoch 0435 | NDCG 0.0000 | MSE 0.1934
2020-11-05 16:38:02,624 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7336 | Iter Mean Loss 13.7336
2020-11-05 16:38:02,629 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0581 | Iter Mean Loss 7.8958
2020-11-05 16:38:02,635 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.2187 | Iter Mean Loss 10.6701
2020-11-05 16:38:02,641 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5515 | Iter Mean Loss 10.6405
2020-11-05 16:38:02,645 - root - INFO - Training: Epoch 0436 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0247 | Iter Mean Loss 9.3173
2020-11-05 16:38:02,646 - root - INFO - Evaluate: Epoch 0436 | NDCG 0.0000 | MSE 0.1933
2020-11-05 16:38:02,652 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.7137 | Iter Mean Loss 13.7137
2020-11-05 16:38:02,657 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0548 | Iter Mean Loss 7.8842
2020-11-05 16:38:02,662 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1890 | Iter Mean Loss 10.6525
2020-11-05 16:38:02,668 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5314 | Iter Mean Loss 10.6222
2020-11-05 16:38:02,672 - root - INFO - Training: Epoch 0437 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0222 | Iter Mean Loss 9.3022
2020-11-05 16:38:02,673 - root - INFO - Evaluate: Epoch 0437 | NDCG 0.0000 | MSE 0.1933
2020-11-05 16:38:02,679 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6938 | Iter Mean Loss 13.6938
2020-11-05 16:38:02,684 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0515 | Iter Mean Loss 7.8727
2020-11-05 16:38:02,690 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1594 | Iter Mean Loss 10.6349
2020-11-05 16:38:02,695 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.5115 | Iter Mean Loss 10.6041
2020-11-05 16:38:02,700 - root - INFO - Training: Epoch 0438 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0197 | Iter Mean Loss 9.2872
2020-11-05 16:38:02,700 - root - INFO - Evaluate: Epoch 0438 | NDCG 0.0000 | MSE 0.1932
2020-11-05 16:38:02,706 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6741 | Iter Mean Loss 13.6741
2020-11-05 16:38:02,711 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0483 | Iter Mean Loss 7.8612
2020-11-05 16:38:02,717 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1299 | Iter Mean Loss 10.6174
2020-11-05 16:38:02,722 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4917 | Iter Mean Loss 10.5860
2020-11-05 16:38:02,727 - root - INFO - Training: Epoch 0439 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0173 | Iter Mean Loss 9.2722
2020-11-05 16:38:02,728 - root - INFO - Evaluate: Epoch 0439 | NDCG 0.0000 | MSE 0.1932
2020-11-05 16:38:02,734 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6543 | Iter Mean Loss 13.6543
2020-11-05 16:38:02,739 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0450 | Iter Mean Loss 7.8497
2020-11-05 16:38:02,745 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.1005 | Iter Mean Loss 10.5999
2020-11-05 16:38:02,751 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4721 | Iter Mean Loss 10.5680
2020-11-05 16:38:02,756 - root - INFO - Training: Epoch 0440 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0148 | Iter Mean Loss 9.2573
2020-11-05 16:38:02,757 - root - INFO - Evaluate: Epoch 0440 | NDCG 0.0000 | MSE 0.1931
2020-11-05 16:38:02,763 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6347 | Iter Mean Loss 13.6347
2020-11-05 16:38:02,769 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0418 | Iter Mean Loss 7.8383
2020-11-05 16:38:02,774 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0711 | Iter Mean Loss 10.5825
2020-11-05 16:38:02,780 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4525 | Iter Mean Loss 10.5500
2020-11-05 16:38:02,785 - root - INFO - Training: Epoch 0441 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0123 | Iter Mean Loss 9.2425
2020-11-05 16:38:02,786 - root - INFO - Evaluate: Epoch 0441 | NDCG 0.0000 | MSE 0.1931
2020-11-05 16:38:02,792 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.6151 | Iter Mean Loss 13.6151
2020-11-05 16:38:02,798 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0386 | Iter Mean Loss 7.8269
2020-11-05 16:38:02,804 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0418 | Iter Mean Loss 10.5652
2020-11-05 16:38:02,809 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4332 | Iter Mean Loss 10.5322
2020-11-05 16:38:02,814 - root - INFO - Training: Epoch 0442 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0099 | Iter Mean Loss 9.2277
2020-11-05 16:38:02,815 - root - INFO - Evaluate: Epoch 0442 | NDCG 0.0000 | MSE 0.1930
2020-11-05 16:38:02,821 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5956 | Iter Mean Loss 13.5956
2020-11-05 16:38:02,827 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0354 | Iter Mean Loss 7.8155
2020-11-05 16:38:02,832 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 16.0126 | Iter Mean Loss 10.5479
2020-11-05 16:38:02,837 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.4139 | Iter Mean Loss 10.5144
2020-11-05 16:38:02,842 - root - INFO - Training: Epoch 0443 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0074 | Iter Mean Loss 9.2130
2020-11-05 16:38:02,843 - root - INFO - Evaluate: Epoch 0443 | NDCG 0.0000 | MSE 0.1929
2020-11-05 16:38:02,848 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5761 | Iter Mean Loss 13.5761
2020-11-05 16:38:02,854 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0322 | Iter Mean Loss 7.8042
2020-11-05 16:38:02,859 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9835 | Iter Mean Loss 10.5306
2020-11-05 16:38:02,864 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3948 | Iter Mean Loss 10.4967
2020-11-05 16:38:02,869 - root - INFO - Training: Epoch 0444 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0050 | Iter Mean Loss 9.1983
2020-11-05 16:38:02,870 - root - INFO - Evaluate: Epoch 0444 | NDCG 0.0000 | MSE 0.1929
2020-11-05 16:38:02,875 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5568 | Iter Mean Loss 13.5568
2020-11-05 16:38:02,881 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0291 | Iter Mean Loss 7.7929
2020-11-05 16:38:02,886 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9544 | Iter Mean Loss 10.5134
2020-11-05 16:38:02,891 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3758 | Iter Mean Loss 10.4790
2020-11-05 16:38:02,896 - root - INFO - Training: Epoch 0445 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0026 | Iter Mean Loss 9.1837
2020-11-05 16:38:02,896 - root - INFO - Evaluate: Epoch 0445 | NDCG 0.0000 | MSE 0.1928
2020-11-05 16:38:02,902 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5374 | Iter Mean Loss 13.5374
2020-11-05 16:38:02,907 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0259 | Iter Mean Loss 7.7817
2020-11-05 16:38:02,912 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.9254 | Iter Mean Loss 10.4963
2020-11-05 16:38:02,918 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3570 | Iter Mean Loss 10.4614
2020-11-05 16:38:02,922 - root - INFO - Training: Epoch 0446 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 4.0001 | Iter Mean Loss 9.1692
2020-11-05 16:38:02,923 - root - INFO - Evaluate: Epoch 0446 | NDCG 0.0000 | MSE 0.1928
2020-11-05 16:38:02,929 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.5182 | Iter Mean Loss 13.5182
2020-11-05 16:38:02,935 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0228 | Iter Mean Loss 7.7705
2020-11-05 16:38:02,940 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8965 | Iter Mean Loss 10.4791
2020-11-05 16:38:02,945 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3382 | Iter Mean Loss 10.4439
2020-11-05 16:38:02,950 - root - INFO - Training: Epoch 0447 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9977 | Iter Mean Loss 9.1547
2020-11-05 16:38:02,952 - root - INFO - Evaluate: Epoch 0447 | NDCG 0.0000 | MSE 0.1927
2020-11-05 16:38:02,958 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4990 | Iter Mean Loss 13.4990
2020-11-05 16:38:02,963 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0196 | Iter Mean Loss 7.7593
2020-11-05 16:38:02,969 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8677 | Iter Mean Loss 10.4621
2020-11-05 16:38:02,975 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3197 | Iter Mean Loss 10.4265
2020-11-05 16:38:02,980 - root - INFO - Training: Epoch 0448 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9953 | Iter Mean Loss 9.1402
2020-11-05 16:38:02,981 - root - INFO - Evaluate: Epoch 0448 | NDCG 0.0000 | MSE 0.1927
2020-11-05 16:38:02,987 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4798 | Iter Mean Loss 13.4798
2020-11-05 16:38:02,993 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0165 | Iter Mean Loss 7.7482
2020-11-05 16:38:02,998 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8389 | Iter Mean Loss 10.4451
2020-11-05 16:38:03,005 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.3012 | Iter Mean Loss 10.4091
2020-11-05 16:38:03,010 - root - INFO - Training: Epoch 0449 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9929 | Iter Mean Loss 9.1259
2020-11-05 16:38:03,011 - root - INFO - Evaluate: Epoch 0449 | NDCG 0.0000 | MSE 0.1926
2020-11-05 16:38:03,016 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4608 | Iter Mean Loss 13.4608
2020-11-05 16:38:03,022 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0134 | Iter Mean Loss 7.7371
2020-11-05 16:38:03,028 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.8103 | Iter Mean Loss 10.4281
2020-11-05 16:38:03,033 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2828 | Iter Mean Loss 10.3918
2020-11-05 16:38:03,038 - root - INFO - Training: Epoch 0450 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9905 | Iter Mean Loss 9.1116
2020-11-05 16:38:03,039 - root - INFO - Evaluate: Epoch 0450 | NDCG 0.0000 | MSE 0.1925
2020-11-05 16:38:03,044 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4418 | Iter Mean Loss 13.4418
2020-11-05 16:38:03,050 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0103 | Iter Mean Loss 7.7260
2020-11-05 16:38:03,055 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7816 | Iter Mean Loss 10.4112
2020-11-05 16:38:03,061 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2646 | Iter Mean Loss 10.3746
2020-11-05 16:38:03,065 - root - INFO - Training: Epoch 0451 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9881 | Iter Mean Loss 9.0973
2020-11-05 16:38:03,066 - root - INFO - Evaluate: Epoch 0451 | NDCG 0.0000 | MSE 0.1925
2020-11-05 16:38:03,072 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4229 | Iter Mean Loss 13.4229
2020-11-05 16:38:03,077 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0072 | Iter Mean Loss 7.7150
2020-11-05 16:38:03,082 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7531 | Iter Mean Loss 10.3944
2020-11-05 16:38:03,088 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2465 | Iter Mean Loss 10.3574
2020-11-05 16:38:03,092 - root - INFO - Training: Epoch 0452 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9857 | Iter Mean Loss 9.0831
2020-11-05 16:38:03,093 - root - INFO - Evaluate: Epoch 0452 | NDCG 0.0000 | MSE 0.1924
2020-11-05 16:38:03,099 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.4040 | Iter Mean Loss 13.4040
2020-11-05 16:38:03,105 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0041 | Iter Mean Loss 7.7041
2020-11-05 16:38:03,111 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.7246 | Iter Mean Loss 10.3776
2020-11-05 16:38:03,116 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2286 | Iter Mean Loss 10.3403
2020-11-05 16:38:03,121 - root - INFO - Training: Epoch 0453 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9834 | Iter Mean Loss 9.0689
2020-11-05 16:38:03,122 - root - INFO - Evaluate: Epoch 0453 | NDCG 0.0000 | MSE 0.1924
2020-11-05 16:38:03,129 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3852 | Iter Mean Loss 13.3852
2020-11-05 16:38:03,134 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 2.0010 | Iter Mean Loss 7.6931
2020-11-05 16:38:03,140 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6962 | Iter Mean Loss 10.3608
2020-11-05 16:38:03,145 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.2107 | Iter Mean Loss 10.3233
2020-11-05 16:38:03,150 - root - INFO - Training: Epoch 0454 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9810 | Iter Mean Loss 9.0548
2020-11-05 16:38:03,151 - root - INFO - Evaluate: Epoch 0454 | NDCG 0.0000 | MSE 0.1923
2020-11-05 16:38:03,157 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3665 | Iter Mean Loss 13.3665
2020-11-05 16:38:03,163 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9980 | Iter Mean Loss 7.6822
2020-11-05 16:38:03,168 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6679 | Iter Mean Loss 10.3441
2020-11-05 16:38:03,175 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1930 | Iter Mean Loss 10.3063
2020-11-05 16:38:03,180 - root - INFO - Training: Epoch 0455 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9786 | Iter Mean Loss 9.0408
2020-11-05 16:38:03,181 - root - INFO - Evaluate: Epoch 0455 | NDCG 0.0000 | MSE 0.1923
2020-11-05 16:38:03,186 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3478 | Iter Mean Loss 13.3478
2020-11-05 16:38:03,192 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9949 | Iter Mean Loss 7.6714
2020-11-05 16:38:03,198 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6396 | Iter Mean Loss 10.3274
2020-11-05 16:38:03,204 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1754 | Iter Mean Loss 10.2894
2020-11-05 16:38:03,209 - root - INFO - Training: Epoch 0456 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9763 | Iter Mean Loss 9.0268
2020-11-05 16:38:03,210 - root - INFO - Evaluate: Epoch 0456 | NDCG 0.0000 | MSE 0.1922
2020-11-05 16:38:03,215 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3292 | Iter Mean Loss 13.3292
2020-11-05 16:38:03,221 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9919 | Iter Mean Loss 7.6605
2020-11-05 16:38:03,227 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.6114 | Iter Mean Loss 10.3108
2020-11-05 16:38:03,232 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1579 | Iter Mean Loss 10.2726
2020-11-05 16:38:03,237 - root - INFO - Training: Epoch 0457 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9739 | Iter Mean Loss 9.0129
2020-11-05 16:38:03,238 - root - INFO - Evaluate: Epoch 0457 | NDCG 0.0000 | MSE 0.1921
2020-11-05 16:38:03,243 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.3106 | Iter Mean Loss 13.3106
2020-11-05 16:38:03,249 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9889 | Iter Mean Loss 7.6497
2020-11-05 16:38:03,254 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5833 | Iter Mean Loss 10.2943
2020-11-05 16:38:03,259 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1405 | Iter Mean Loss 10.2558
2020-11-05 16:38:03,264 - root - INFO - Training: Epoch 0458 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9716 | Iter Mean Loss 8.9990
2020-11-05 16:38:03,265 - root - INFO - Evaluate: Epoch 0458 | NDCG 0.0000 | MSE 0.1921
2020-11-05 16:38:03,270 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2921 | Iter Mean Loss 13.2921
2020-11-05 16:38:03,275 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9859 | Iter Mean Loss 7.6390
2020-11-05 16:38:03,281 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5552 | Iter Mean Loss 10.2777
2020-11-05 16:38:03,286 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1233 | Iter Mean Loss 10.2391
2020-11-05 16:38:03,290 - root - INFO - Training: Epoch 0459 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9692 | Iter Mean Loss 8.9851
2020-11-05 16:38:03,291 - root - INFO - Evaluate: Epoch 0459 | NDCG 0.0000 | MSE 0.1920
2020-11-05 16:38:03,297 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2737 | Iter Mean Loss 13.2737
2020-11-05 16:38:03,302 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9829 | Iter Mean Loss 7.6283
2020-11-05 16:38:03,307 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.5272 | Iter Mean Loss 10.2613
2020-11-05 16:38:03,313 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.1061 | Iter Mean Loss 10.2225
2020-11-05 16:38:03,318 - root - INFO - Training: Epoch 0460 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9669 | Iter Mean Loss 8.9714
2020-11-05 16:38:03,319 - root - INFO - Evaluate: Epoch 0460 | NDCG 0.0000 | MSE 0.1920
2020-11-05 16:38:03,326 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2553 | Iter Mean Loss 13.2553
2020-11-05 16:38:03,331 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9799 | Iter Mean Loss 7.6176
2020-11-05 16:38:03,337 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4993 | Iter Mean Loss 10.2448
2020-11-05 16:38:03,343 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0891 | Iter Mean Loss 10.2059
2020-11-05 16:38:03,348 - root - INFO - Training: Epoch 0461 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9646 | Iter Mean Loss 8.9576
2020-11-05 16:38:03,349 - root - INFO - Evaluate: Epoch 0461 | NDCG 0.0000 | MSE 0.1919
2020-11-05 16:38:03,355 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2370 | Iter Mean Loss 13.2370
2020-11-05 16:38:03,360 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9769 | Iter Mean Loss 7.6069
2020-11-05 16:38:03,366 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4714 | Iter Mean Loss 10.2284
2020-11-05 16:38:03,372 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0721 | Iter Mean Loss 10.1894
2020-11-05 16:38:03,377 - root - INFO - Training: Epoch 0462 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9623 | Iter Mean Loss 8.9439
2020-11-05 16:38:03,378 - root - INFO - Evaluate: Epoch 0462 | NDCG 0.0000 | MSE 0.1919
2020-11-05 16:38:03,383 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2187 | Iter Mean Loss 13.2187
2020-11-05 16:38:03,389 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9739 | Iter Mean Loss 7.5963
2020-11-05 16:38:03,395 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4436 | Iter Mean Loss 10.2121
2020-11-05 16:38:03,400 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0553 | Iter Mean Loss 10.1729
2020-11-05 16:38:03,406 - root - INFO - Training: Epoch 0463 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9599 | Iter Mean Loss 8.9303
2020-11-05 16:38:03,407 - root - INFO - Evaluate: Epoch 0463 | NDCG 0.0000 | MSE 0.1918
2020-11-05 16:38:03,413 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.2005 | Iter Mean Loss 13.2005
2020-11-05 16:38:03,418 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9709 | Iter Mean Loss 7.5857
2020-11-05 16:38:03,424 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.4158 | Iter Mean Loss 10.1958
2020-11-05 16:38:03,430 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0386 | Iter Mean Loss 10.1565
2020-11-05 16:38:03,435 - root - INFO - Training: Epoch 0464 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9576 | Iter Mean Loss 8.9167
2020-11-05 16:38:03,436 - root - INFO - Evaluate: Epoch 0464 | NDCG 0.0000 | MSE 0.1917
2020-11-05 16:38:03,441 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1824 | Iter Mean Loss 13.1824
2020-11-05 16:38:03,447 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9679 | Iter Mean Loss 7.5752
2020-11-05 16:38:03,452 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3882 | Iter Mean Loss 10.1795
2020-11-05 16:38:03,457 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0220 | Iter Mean Loss 10.1401
2020-11-05 16:38:03,462 - root - INFO - Training: Epoch 0465 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9553 | Iter Mean Loss 8.9032
2020-11-05 16:38:03,463 - root - INFO - Evaluate: Epoch 0465 | NDCG 0.0000 | MSE 0.1917
2020-11-05 16:38:03,468 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1643 | Iter Mean Loss 13.1643
2020-11-05 16:38:03,474 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9650 | Iter Mean Loss 7.5647
2020-11-05 16:38:03,479 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3605 | Iter Mean Loss 10.1633
2020-11-05 16:38:03,484 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 10.0055 | Iter Mean Loss 10.1238
2020-11-05 16:38:03,489 - root - INFO - Training: Epoch 0466 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9530 | Iter Mean Loss 8.8897
2020-11-05 16:38:03,490 - root - INFO - Evaluate: Epoch 0466 | NDCG 0.0000 | MSE 0.1916
2020-11-05 16:38:03,495 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1463 | Iter Mean Loss 13.1463
2020-11-05 16:38:03,501 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9620 | Iter Mean Loss 7.5542
2020-11-05 16:38:03,506 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3330 | Iter Mean Loss 10.1471
2020-11-05 16:38:03,512 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9891 | Iter Mean Loss 10.1076
2020-11-05 16:38:03,516 - root - INFO - Training: Epoch 0467 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9507 | Iter Mean Loss 8.8762
2020-11-05 16:38:03,517 - root - INFO - Evaluate: Epoch 0467 | NDCG 0.0000 | MSE 0.1916
2020-11-05 16:38:03,523 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1283 | Iter Mean Loss 13.1283
2020-11-05 16:38:03,528 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9591 | Iter Mean Loss 7.5437
2020-11-05 16:38:03,534 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.3055 | Iter Mean Loss 10.1310
2020-11-05 16:38:03,540 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9728 | Iter Mean Loss 10.0914
2020-11-05 16:38:03,545 - root - INFO - Training: Epoch 0468 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9484 | Iter Mean Loss 8.8628
2020-11-05 16:38:03,545 - root - INFO - Evaluate: Epoch 0468 | NDCG 0.0000 | MSE 0.1915
2020-11-05 16:38:03,551 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.1104 | Iter Mean Loss 13.1104
2020-11-05 16:38:03,556 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9561 | Iter Mean Loss 7.5333
2020-11-05 16:38:03,562 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2780 | Iter Mean Loss 10.1149
2020-11-05 16:38:03,568 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9566 | Iter Mean Loss 10.0753
2020-11-05 16:38:03,573 - root - INFO - Training: Epoch 0469 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9461 | Iter Mean Loss 8.8495
2020-11-05 16:38:03,573 - root - INFO - Evaluate: Epoch 0469 | NDCG 0.0000 | MSE 0.1914
2020-11-05 16:38:03,580 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0926 | Iter Mean Loss 13.0926
2020-11-05 16:38:03,586 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9532 | Iter Mean Loss 7.5229
2020-11-05 16:38:03,591 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2507 | Iter Mean Loss 10.0988
2020-11-05 16:38:03,598 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9406 | Iter Mean Loss 10.0593
2020-11-05 16:38:03,602 - root - INFO - Training: Epoch 0470 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9439 | Iter Mean Loss 8.8362
2020-11-05 16:38:03,603 - root - INFO - Evaluate: Epoch 0470 | NDCG 0.0000 | MSE 0.1914
2020-11-05 16:38:03,609 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0748 | Iter Mean Loss 13.0748
2020-11-05 16:38:03,615 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9503 | Iter Mean Loss 7.5125
2020-11-05 16:38:03,620 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.2233 | Iter Mean Loss 10.0828
2020-11-05 16:38:03,626 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9246 | Iter Mean Loss 10.0432
2020-11-05 16:38:03,631 - root - INFO - Training: Epoch 0471 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9416 | Iter Mean Loss 8.8229
2020-11-05 16:38:03,632 - root - INFO - Evaluate: Epoch 0471 | NDCG 0.0000 | MSE 0.1913
2020-11-05 16:38:03,640 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0570 | Iter Mean Loss 13.0570
2020-11-05 16:38:03,647 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9474 | Iter Mean Loss 7.5022
2020-11-05 16:38:03,654 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1961 | Iter Mean Loss 10.0668
2020-11-05 16:38:03,660 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.9087 | Iter Mean Loss 10.0273
2020-11-05 16:38:03,665 - root - INFO - Training: Epoch 0472 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9393 | Iter Mean Loss 8.8097
2020-11-05 16:38:03,666 - root - INFO - Evaluate: Epoch 0472 | NDCG 0.0000 | MSE 0.1913
2020-11-05 16:38:03,672 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0394 | Iter Mean Loss 13.0394
2020-11-05 16:38:03,678 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9444 | Iter Mean Loss 7.4919
2020-11-05 16:38:03,683 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1689 | Iter Mean Loss 10.0509
2020-11-05 16:38:03,689 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8929 | Iter Mean Loss 10.0114
2020-11-05 16:38:03,694 - root - INFO - Training: Epoch 0473 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9370 | Iter Mean Loss 8.7965
2020-11-05 16:38:03,695 - root - INFO - Evaluate: Epoch 0473 | NDCG 0.0000 | MSE 0.1912
2020-11-05 16:38:03,700 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0217 | Iter Mean Loss 13.0217
2020-11-05 16:38:03,706 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9415 | Iter Mean Loss 7.4816
2020-11-05 16:38:03,712 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1417 | Iter Mean Loss 10.0350
2020-11-05 16:38:03,717 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8772 | Iter Mean Loss 9.9955
2020-11-05 16:38:03,722 - root - INFO - Training: Epoch 0474 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9348 | Iter Mean Loss 8.7834
2020-11-05 16:38:03,723 - root - INFO - Evaluate: Epoch 0474 | NDCG 0.0000 | MSE 0.1912
2020-11-05 16:38:03,729 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 13.0041 | Iter Mean Loss 13.0041
2020-11-05 16:38:03,735 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9386 | Iter Mean Loss 7.4714
2020-11-05 16:38:03,740 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.1146 | Iter Mean Loss 10.0191
2020-11-05 16:38:03,748 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8616 | Iter Mean Loss 9.9797
2020-11-05 16:38:03,754 - root - INFO - Training: Epoch 0475 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9325 | Iter Mean Loss 8.7703
2020-11-05 16:38:03,756 - root - INFO - Evaluate: Epoch 0475 | NDCG 0.0000 | MSE 0.1911
2020-11-05 16:38:03,764 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9866 | Iter Mean Loss 12.9866
2020-11-05 16:38:03,771 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9357 | Iter Mean Loss 7.4612
2020-11-05 16:38:03,779 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0876 | Iter Mean Loss 10.0033
2020-11-05 16:38:03,785 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8461 | Iter Mean Loss 9.9640
2020-11-05 16:38:03,791 - root - INFO - Training: Epoch 0476 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9302 | Iter Mean Loss 8.7573
2020-11-05 16:38:03,793 - root - INFO - Evaluate: Epoch 0476 | NDCG 0.0000 | MSE 0.1910
2020-11-05 16:38:03,799 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9691 | Iter Mean Loss 12.9691
2020-11-05 16:38:03,805 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9328 | Iter Mean Loss 7.4510
2020-11-05 16:38:03,812 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0606 | Iter Mean Loss 9.9875
2020-11-05 16:38:03,818 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8307 | Iter Mean Loss 9.9483
2020-11-05 16:38:03,824 - root - INFO - Training: Epoch 0477 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9280 | Iter Mean Loss 8.7442
2020-11-05 16:38:03,825 - root - INFO - Evaluate: Epoch 0477 | NDCG 0.0000 | MSE 0.1910
2020-11-05 16:38:03,831 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9517 | Iter Mean Loss 12.9517
2020-11-05 16:38:03,838 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9299 | Iter Mean Loss 7.4408
2020-11-05 16:38:03,844 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0337 | Iter Mean Loss 9.9718
2020-11-05 16:38:03,850 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8153 | Iter Mean Loss 9.9327
2020-11-05 16:38:03,855 - root - INFO - Training: Epoch 0478 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9257 | Iter Mean Loss 8.7313
2020-11-05 16:38:03,856 - root - INFO - Evaluate: Epoch 0478 | NDCG 0.0000 | MSE 0.1909
2020-11-05 16:38:03,861 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9344 | Iter Mean Loss 12.9344
2020-11-05 16:38:03,867 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9271 | Iter Mean Loss 7.4307
2020-11-05 16:38:03,873 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 15.0068 | Iter Mean Loss 9.9561
2020-11-05 16:38:03,879 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.8001 | Iter Mean Loss 9.9171
2020-11-05 16:38:03,884 - root - INFO - Training: Epoch 0479 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9235 | Iter Mean Loss 8.7184
2020-11-05 16:38:03,884 - root - INFO - Evaluate: Epoch 0479 | NDCG 0.0000 | MSE 0.1909
2020-11-05 16:38:03,890 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.9170 | Iter Mean Loss 12.9170
2020-11-05 16:38:03,897 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9242 | Iter Mean Loss 7.4206
2020-11-05 16:38:03,903 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9800 | Iter Mean Loss 9.9404
2020-11-05 16:38:03,909 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7850 | Iter Mean Loss 9.9015
2020-11-05 16:38:03,914 - root - INFO - Training: Epoch 0480 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9212 | Iter Mean Loss 8.7055
2020-11-05 16:38:03,915 - root - INFO - Evaluate: Epoch 0480 | NDCG 0.0000 | MSE 0.1908
2020-11-05 16:38:03,921 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8998 | Iter Mean Loss 12.8998
2020-11-05 16:38:03,926 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9213 | Iter Mean Loss 7.4105
2020-11-05 16:38:03,932 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9532 | Iter Mean Loss 9.9248
2020-11-05 16:38:03,939 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7699 | Iter Mean Loss 9.8861
2020-11-05 16:38:03,945 - root - INFO - Training: Epoch 0481 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9190 | Iter Mean Loss 8.6926
2020-11-05 16:38:03,946 - root - INFO - Evaluate: Epoch 0481 | NDCG 0.0000 | MSE 0.1907
2020-11-05 16:38:03,952 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8826 | Iter Mean Loss 12.8826
2020-11-05 16:38:03,959 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9184 | Iter Mean Loss 7.4005
2020-11-05 16:38:03,965 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.9265 | Iter Mean Loss 9.9092
2020-11-05 16:38:03,971 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 9.8706
2020-11-05 16:38:03,978 - root - INFO - Training: Epoch 0482 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9168 | Iter Mean Loss 8.6798
2020-11-05 16:38:03,979 - root - INFO - Evaluate: Epoch 0482 | NDCG 0.0000 | MSE 0.1907
2020-11-05 16:38:03,985 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8654 | Iter Mean Loss 12.8654
2020-11-05 16:38:03,992 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9156 | Iter Mean Loss 7.3905
2020-11-05 16:38:03,998 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8998 | Iter Mean Loss 9.8936
2020-11-05 16:38:04,004 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7401 | Iter Mean Loss 9.8552
2020-11-05 16:38:04,010 - root - INFO - Training: Epoch 0483 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9145 | Iter Mean Loss 8.6671
2020-11-05 16:38:04,011 - root - INFO - Evaluate: Epoch 0483 | NDCG 0.0000 | MSE 0.1906
2020-11-05 16:38:04,017 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8483 | Iter Mean Loss 12.8483
2020-11-05 16:38:04,023 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9127 | Iter Mean Loss 7.3805
2020-11-05 16:38:04,029 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8732 | Iter Mean Loss 9.8781
2020-11-05 16:38:04,036 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7253 | Iter Mean Loss 9.8399
2020-11-05 16:38:04,041 - root - INFO - Training: Epoch 0484 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9123 | Iter Mean Loss 8.6544
2020-11-05 16:38:04,042 - root - INFO - Evaluate: Epoch 0484 | NDCG 0.0000 | MSE 0.1906
2020-11-05 16:38:04,048 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8312 | Iter Mean Loss 12.8312
2020-11-05 16:38:04,054 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9098 | Iter Mean Loss 7.3705
2020-11-05 16:38:04,059 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8467 | Iter Mean Loss 9.8626
2020-11-05 16:38:04,065 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.7106 | Iter Mean Loss 9.8246
2020-11-05 16:38:04,070 - root - INFO - Training: Epoch 0485 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9100 | Iter Mean Loss 8.6417
2020-11-05 16:38:04,071 - root - INFO - Evaluate: Epoch 0485 | NDCG 0.0000 | MSE 0.1905
2020-11-05 16:38:04,077 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.8142 | Iter Mean Loss 12.8142
2020-11-05 16:38:04,082 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9070 | Iter Mean Loss 7.3606
2020-11-05 16:38:04,088 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.8202 | Iter Mean Loss 9.8471
2020-11-05 16:38:04,094 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6959 | Iter Mean Loss 9.8093
2020-11-05 16:38:04,099 - root - INFO - Training: Epoch 0486 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9078 | Iter Mean Loss 8.6290
2020-11-05 16:38:04,100 - root - INFO - Evaluate: Epoch 0486 | NDCG 0.0000 | MSE 0.1905
2020-11-05 16:38:04,106 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7973 | Iter Mean Loss 12.7973
2020-11-05 16:38:04,113 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9041 | Iter Mean Loss 7.3507
2020-11-05 16:38:04,118 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7937 | Iter Mean Loss 9.8317
2020-11-05 16:38:04,124 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6814 | Iter Mean Loss 9.7941
2020-11-05 16:38:04,129 - root - INFO - Training: Epoch 0487 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9056 | Iter Mean Loss 8.6164
2020-11-05 16:38:04,130 - root - INFO - Evaluate: Epoch 0487 | NDCG 0.0000 | MSE 0.1904
2020-11-05 16:38:04,136 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7804 | Iter Mean Loss 12.7804
2020-11-05 16:38:04,143 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.9013 | Iter Mean Loss 7.3408
2020-11-05 16:38:04,148 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7673 | Iter Mean Loss 9.8163
2020-11-05 16:38:04,154 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6669 | Iter Mean Loss 9.7790
2020-11-05 16:38:04,159 - root - INFO - Training: Epoch 0488 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9034 | Iter Mean Loss 8.6038
2020-11-05 16:38:04,160 - root - INFO - Evaluate: Epoch 0488 | NDCG 0.0000 | MSE 0.1903
2020-11-05 16:38:04,166 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7635 | Iter Mean Loss 12.7635
2020-11-05 16:38:04,173 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8984 | Iter Mean Loss 7.3310
2020-11-05 16:38:04,179 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7410 | Iter Mean Loss 9.8010
2020-11-05 16:38:04,185 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6525 | Iter Mean Loss 9.7639
2020-11-05 16:38:04,191 - root - INFO - Training: Epoch 0489 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.9011 | Iter Mean Loss 8.5913
2020-11-05 16:38:04,192 - root - INFO - Evaluate: Epoch 0489 | NDCG 0.0000 | MSE 0.1903
2020-11-05 16:38:04,197 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7467 | Iter Mean Loss 12.7467
2020-11-05 16:38:04,204 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8955 | Iter Mean Loss 7.3211
2020-11-05 16:38:04,210 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.7147 | Iter Mean Loss 9.7856
2020-11-05 16:38:04,216 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6382 | Iter Mean Loss 9.7488
2020-11-05 16:38:04,222 - root - INFO - Training: Epoch 0490 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8989 | Iter Mean Loss 8.5788
2020-11-05 16:38:04,223 - root - INFO - Evaluate: Epoch 0490 | NDCG 0.0000 | MSE 0.1902
2020-11-05 16:38:04,228 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7299 | Iter Mean Loss 12.7299
2020-11-05 16:38:04,235 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8927 | Iter Mean Loss 7.3113
2020-11-05 16:38:04,241 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6884 | Iter Mean Loss 9.7703
2020-11-05 16:38:04,247 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6240 | Iter Mean Loss 9.7338
2020-11-05 16:38:04,251 - root - INFO - Training: Epoch 0491 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8967 | Iter Mean Loss 8.5663
2020-11-05 16:38:04,252 - root - INFO - Evaluate: Epoch 0491 | NDCG 0.0000 | MSE 0.1902
2020-11-05 16:38:04,258 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.7132 | Iter Mean Loss 12.7132
2020-11-05 16:38:04,264 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8898 | Iter Mean Loss 7.3015
2020-11-05 16:38:04,269 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6622 | Iter Mean Loss 9.7551
2020-11-05 16:38:04,275 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.6099 | Iter Mean Loss 9.7188
2020-11-05 16:38:04,280 - root - INFO - Training: Epoch 0492 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8945 | Iter Mean Loss 8.5539
2020-11-05 16:38:04,281 - root - INFO - Evaluate: Epoch 0492 | NDCG 0.0000 | MSE 0.1901
2020-11-05 16:38:04,286 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6966 | Iter Mean Loss 12.6966
2020-11-05 16:38:04,292 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8870 | Iter Mean Loss 7.2918
2020-11-05 16:38:04,298 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6360 | Iter Mean Loss 9.7399
2020-11-05 16:38:04,303 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5958 | Iter Mean Loss 9.7038
2020-11-05 16:38:04,308 - root - INFO - Training: Epoch 0493 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8922 | Iter Mean Loss 8.5415
2020-11-05 16:38:04,309 - root - INFO - Evaluate: Epoch 0493 | NDCG 0.0000 | MSE 0.1900
2020-11-05 16:38:04,315 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6799 | Iter Mean Loss 12.6799
2020-11-05 16:38:04,322 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8842 | Iter Mean Loss 7.2820
2020-11-05 16:38:04,329 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.6099 | Iter Mean Loss 9.7247
2020-11-05 16:38:04,334 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5818 | Iter Mean Loss 9.6890
2020-11-05 16:38:04,340 - root - INFO - Training: Epoch 0494 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8900 | Iter Mean Loss 8.5292
2020-11-05 16:38:04,341 - root - INFO - Evaluate: Epoch 0494 | NDCG 0.0000 | MSE 0.1900
2020-11-05 16:38:04,347 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6634 | Iter Mean Loss 12.6634
2020-11-05 16:38:04,354 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8813 | Iter Mean Loss 7.2723
2020-11-05 16:38:04,360 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5839 | Iter Mean Loss 9.7095
2020-11-05 16:38:04,366 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5679 | Iter Mean Loss 9.6741
2020-11-05 16:38:04,371 - root - INFO - Training: Epoch 0495 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8878 | Iter Mean Loss 8.5168
2020-11-05 16:38:04,373 - root - INFO - Evaluate: Epoch 0495 | NDCG 0.0000 | MSE 0.1899
2020-11-05 16:38:04,379 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6468 | Iter Mean Loss 12.6468
2020-11-05 16:38:04,385 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8785 | Iter Mean Loss 7.2627
2020-11-05 16:38:04,392 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5578 | Iter Mean Loss 9.6944
2020-11-05 16:38:04,398 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5540 | Iter Mean Loss 9.6593
2020-11-05 16:38:04,404 - root - INFO - Training: Epoch 0496 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8856 | Iter Mean Loss 8.5046
2020-11-05 16:38:04,406 - root - INFO - Evaluate: Epoch 0496 | NDCG 0.0000 | MSE 0.1899
2020-11-05 16:38:04,412 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6304 | Iter Mean Loss 12.6304
2020-11-05 16:38:04,418 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8756 | Iter Mean Loss 7.2530
2020-11-05 16:38:04,424 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5319 | Iter Mean Loss 9.6793
2020-11-05 16:38:04,430 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5402 | Iter Mean Loss 9.6445
2020-11-05 16:38:04,436 - root - INFO - Training: Epoch 0497 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8834 | Iter Mean Loss 8.4923
2020-11-05 16:38:04,438 - root - INFO - Evaluate: Epoch 0497 | NDCG 0.0000 | MSE 0.1898
2020-11-05 16:38:04,444 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.6139 | Iter Mean Loss 12.6139
2020-11-05 16:38:04,450 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8728 | Iter Mean Loss 7.2434
2020-11-05 16:38:04,456 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.5060 | Iter Mean Loss 9.6642
2020-11-05 16:38:04,461 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5265 | Iter Mean Loss 9.6298
2020-11-05 16:38:04,466 - root - INFO - Training: Epoch 0498 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8812 | Iter Mean Loss 8.4801
2020-11-05 16:38:04,467 - root - INFO - Evaluate: Epoch 0498 | NDCG 0.0000 | MSE 0.1897
2020-11-05 16:38:04,473 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5976 | Iter Mean Loss 12.5976
2020-11-05 16:38:04,479 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8699 | Iter Mean Loss 7.2337
2020-11-05 16:38:04,485 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4801 | Iter Mean Loss 9.6492
2020-11-05 16:38:04,491 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.5129 | Iter Mean Loss 9.6151
2020-11-05 16:38:04,496 - root - INFO - Training: Epoch 0499 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8789 | Iter Mean Loss 8.4679
2020-11-05 16:38:04,497 - root - INFO - Evaluate: Epoch 0499 | NDCG 0.0000 | MSE 0.1897
2020-11-05 16:38:04,503 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5812 | Iter Mean Loss 12.5812
2020-11-05 16:38:04,508 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8671 | Iter Mean Loss 7.2242
2020-11-05 16:38:04,514 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4542 | Iter Mean Loss 9.6342
2020-11-05 16:38:04,520 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4993 | Iter Mean Loss 9.6005
2020-11-05 16:38:04,525 - root - INFO - Training: Epoch 0500 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8767 | Iter Mean Loss 8.4557
2020-11-05 16:38:04,526 - root - INFO - Evaluate: Epoch 0500 | NDCG 0.0000 | MSE 0.1896
2020-11-05 16:38:04,531 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5649 | Iter Mean Loss 12.5649
2020-11-05 16:38:04,537 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8643 | Iter Mean Loss 7.2146
2020-11-05 16:38:04,543 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4285 | Iter Mean Loss 9.6192
2020-11-05 16:38:04,549 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4859 | Iter Mean Loss 9.5859
2020-11-05 16:38:04,555 - root - INFO - Training: Epoch 0501 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8745 | Iter Mean Loss 8.4436
2020-11-05 16:38:04,556 - root - INFO - Evaluate: Epoch 0501 | NDCG 0.0000 | MSE 0.1896
2020-11-05 16:38:04,562 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5487 | Iter Mean Loss 12.5487
2020-11-05 16:38:04,568 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8614 | Iter Mean Loss 7.2051
2020-11-05 16:38:04,575 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.4027 | Iter Mean Loss 9.6043
2020-11-05 16:38:04,581 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4724 | Iter Mean Loss 9.5713
2020-11-05 16:38:04,586 - root - INFO - Training: Epoch 0502 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8723 | Iter Mean Loss 8.4315
2020-11-05 16:38:04,588 - root - INFO - Evaluate: Epoch 0502 | NDCG 0.0000 | MSE 0.1895
2020-11-05 16:38:04,594 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5325 | Iter Mean Loss 12.5325
2020-11-05 16:38:04,600 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8586 | Iter Mean Loss 7.1955
2020-11-05 16:38:04,607 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3770 | Iter Mean Loss 9.5894
2020-11-05 16:38:04,613 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4591 | Iter Mean Loss 9.5568
2020-11-05 16:38:04,618 - root - INFO - Training: Epoch 0503 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8701 | Iter Mean Loss 8.4194
2020-11-05 16:38:04,620 - root - INFO - Evaluate: Epoch 0503 | NDCG 0.0000 | MSE 0.1894
2020-11-05 16:38:04,626 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5163 | Iter Mean Loss 12.5163
2020-11-05 16:38:04,632 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8557 | Iter Mean Loss 7.1860
2020-11-05 16:38:04,639 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3514 | Iter Mean Loss 9.5745
2020-11-05 16:38:04,644 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4458 | Iter Mean Loss 9.5423
2020-11-05 16:38:04,649 - root - INFO - Training: Epoch 0504 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8679 | Iter Mean Loss 8.4074
2020-11-05 16:38:04,650 - root - INFO - Evaluate: Epoch 0504 | NDCG 0.0000 | MSE 0.1894
2020-11-05 16:38:04,656 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.5002 | Iter Mean Loss 12.5002
2020-11-05 16:38:04,662 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8529 | Iter Mean Loss 7.1766
2020-11-05 16:38:04,668 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3258 | Iter Mean Loss 9.5596
2020-11-05 16:38:04,673 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4326 | Iter Mean Loss 9.5279
2020-11-05 16:38:04,678 - root - INFO - Training: Epoch 0505 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8657 | Iter Mean Loss 8.3954
2020-11-05 16:38:04,679 - root - INFO - Evaluate: Epoch 0505 | NDCG 0.0000 | MSE 0.1893
2020-11-05 16:38:04,685 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4842 | Iter Mean Loss 12.4842
2020-11-05 16:38:04,691 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8500 | Iter Mean Loss 7.1671
2020-11-05 16:38:04,696 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.3002 | Iter Mean Loss 9.5448
2020-11-05 16:38:04,702 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4194 | Iter Mean Loss 9.5135
2020-11-05 16:38:04,707 - root - INFO - Training: Epoch 0506 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8634 | Iter Mean Loss 8.3835
2020-11-05 16:38:04,708 - root - INFO - Evaluate: Epoch 0506 | NDCG 0.0000 | MSE 0.1893
2020-11-05 16:38:04,713 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4681 | Iter Mean Loss 12.4681
2020-11-05 16:38:04,719 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8472 | Iter Mean Loss 7.1577
2020-11-05 16:38:04,725 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2747 | Iter Mean Loss 9.5300
2020-11-05 16:38:04,730 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.4063 | Iter Mean Loss 9.4991
2020-11-05 16:38:04,735 - root - INFO - Training: Epoch 0507 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8612 | Iter Mean Loss 8.3715
2020-11-05 16:38:04,736 - root - INFO - Evaluate: Epoch 0507 | NDCG 0.0000 | MSE 0.1892
2020-11-05 16:38:04,742 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4522 | Iter Mean Loss 12.4522
2020-11-05 16:38:04,748 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8444 | Iter Mean Loss 7.1483
2020-11-05 16:38:04,753 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2492 | Iter Mean Loss 9.5153
2020-11-05 16:38:04,760 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3933 | Iter Mean Loss 9.4848
2020-11-05 16:38:04,765 - root - INFO - Training: Epoch 0508 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8590 | Iter Mean Loss 8.3596
2020-11-05 16:38:04,766 - root - INFO - Evaluate: Epoch 0508 | NDCG 0.0000 | MSE 0.1891
2020-11-05 16:38:04,771 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4362 | Iter Mean Loss 12.4362
2020-11-05 16:38:04,777 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8415 | Iter Mean Loss 7.1389
2020-11-05 16:38:04,784 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.2238 | Iter Mean Loss 9.5005
2020-11-05 16:38:04,790 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3803 | Iter Mean Loss 9.4705
2020-11-05 16:38:04,796 - root - INFO - Training: Epoch 0509 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8568 | Iter Mean Loss 8.3477
2020-11-05 16:38:04,797 - root - INFO - Evaluate: Epoch 0509 | NDCG 0.0000 | MSE 0.1891
2020-11-05 16:38:04,803 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4204 | Iter Mean Loss 12.4204
2020-11-05 16:38:04,808 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8387 | Iter Mean Loss 7.1295
2020-11-05 16:38:04,815 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1984 | Iter Mean Loss 9.4858
2020-11-05 16:38:04,821 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3674 | Iter Mean Loss 9.4562
2020-11-05 16:38:04,826 - root - INFO - Training: Epoch 0510 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8546 | Iter Mean Loss 8.3359
2020-11-05 16:38:04,828 - root - INFO - Evaluate: Epoch 0510 | NDCG 0.0000 | MSE 0.1890
2020-11-05 16:38:04,834 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.4045 | Iter Mean Loss 12.4045
2020-11-05 16:38:04,840 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8358 | Iter Mean Loss 7.1202
2020-11-05 16:38:04,847 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1731 | Iter Mean Loss 9.4711
2020-11-05 16:38:04,853 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3546 | Iter Mean Loss 9.4420
2020-11-05 16:38:04,857 - root - INFO - Training: Epoch 0511 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8524 | Iter Mean Loss 8.3241
2020-11-05 16:38:04,858 - root - INFO - Evaluate: Epoch 0511 | NDCG 0.0000 | MSE 0.1890
2020-11-05 16:38:04,864 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3887 | Iter Mean Loss 12.3887
2020-11-05 16:38:04,869 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8330 | Iter Mean Loss 7.1108
2020-11-05 16:38:04,875 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1478 | Iter Mean Loss 9.4565
2020-11-05 16:38:04,881 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3418 | Iter Mean Loss 9.4278
2020-11-05 16:38:04,886 - root - INFO - Training: Epoch 0512 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8501 | Iter Mean Loss 8.3123
2020-11-05 16:38:04,887 - root - INFO - Evaluate: Epoch 0512 | NDCG 0.0000 | MSE 0.1889
2020-11-05 16:38:04,892 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3730 | Iter Mean Loss 12.3730
2020-11-05 16:38:04,898 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8301 | Iter Mean Loss 7.1015
2020-11-05 16:38:04,903 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.1226 | Iter Mean Loss 9.4419
2020-11-05 16:38:04,909 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3291 | Iter Mean Loss 9.4137
2020-11-05 16:38:04,914 - root - INFO - Training: Epoch 0513 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8479 | Iter Mean Loss 8.3005
2020-11-05 16:38:04,915 - root - INFO - Evaluate: Epoch 0513 | NDCG 0.0000 | MSE 0.1888
2020-11-05 16:38:04,920 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3573 | Iter Mean Loss 12.3573
2020-11-05 16:38:04,926 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8273 | Iter Mean Loss 7.0923
2020-11-05 16:38:04,931 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0974 | Iter Mean Loss 9.4273
2020-11-05 16:38:04,937 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3164 | Iter Mean Loss 9.3996
2020-11-05 16:38:04,942 - root - INFO - Training: Epoch 0514 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8457 | Iter Mean Loss 8.2888
2020-11-05 16:38:04,943 - root - INFO - Evaluate: Epoch 0514 | NDCG 0.0000 | MSE 0.1888
2020-11-05 16:38:04,948 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3416 | Iter Mean Loss 12.3416
2020-11-05 16:38:04,954 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8244 | Iter Mean Loss 7.0830
2020-11-05 16:38:04,960 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0722 | Iter Mean Loss 9.4127
2020-11-05 16:38:04,966 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.3038 | Iter Mean Loss 9.3855
2020-11-05 16:38:04,971 - root - INFO - Training: Epoch 0515 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8435 | Iter Mean Loss 8.2771
2020-11-05 16:38:04,972 - root - INFO - Evaluate: Epoch 0515 | NDCG 0.0000 | MSE 0.1887
2020-11-05 16:38:04,977 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3260 | Iter Mean Loss 12.3260
2020-11-05 16:38:04,984 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8216 | Iter Mean Loss 7.0738
2020-11-05 16:38:04,990 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0471 | Iter Mean Loss 9.3982
2020-11-05 16:38:04,995 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2913 | Iter Mean Loss 9.3715
2020-11-05 16:38:05,001 - root - INFO - Training: Epoch 0516 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8413 | Iter Mean Loss 8.2654
2020-11-05 16:38:05,002 - root - INFO - Evaluate: Epoch 0516 | NDCG 0.0000 | MSE 0.1886
2020-11-05 16:38:05,008 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.3104 | Iter Mean Loss 12.3104
2020-11-05 16:38:05,014 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8187 | Iter Mean Loss 7.0645
2020-11-05 16:38:05,021 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 14.0220 | Iter Mean Loss 9.3837
2020-11-05 16:38:05,027 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2788 | Iter Mean Loss 9.3575
2020-11-05 16:38:05,032 - root - INFO - Training: Epoch 0517 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8390 | Iter Mean Loss 8.2538
2020-11-05 16:38:05,033 - root - INFO - Evaluate: Epoch 0517 | NDCG 0.0000 | MSE 0.1886
2020-11-05 16:38:05,039 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2948 | Iter Mean Loss 12.2948
2020-11-05 16:38:05,045 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8158 | Iter Mean Loss 7.0553
2020-11-05 16:38:05,051 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9970 | Iter Mean Loss 9.3692
2020-11-05 16:38:05,058 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2664 | Iter Mean Loss 9.3435
2020-11-05 16:38:05,063 - root - INFO - Training: Epoch 0518 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8368 | Iter Mean Loss 8.2422
2020-11-05 16:38:05,064 - root - INFO - Evaluate: Epoch 0518 | NDCG 0.0000 | MSE 0.1885
2020-11-05 16:38:05,070 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2793 | Iter Mean Loss 12.2793
2020-11-05 16:38:05,075 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8130 | Iter Mean Loss 7.0462
2020-11-05 16:38:05,081 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9720 | Iter Mean Loss 9.3548
2020-11-05 16:38:05,086 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2541 | Iter Mean Loss 9.3296
2020-11-05 16:38:05,091 - root - INFO - Training: Epoch 0519 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8346 | Iter Mean Loss 8.2306
2020-11-05 16:38:05,092 - root - INFO - Evaluate: Epoch 0519 | NDCG 0.0000 | MSE 0.1885
2020-11-05 16:38:05,098 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2639 | Iter Mean Loss 12.2639
2020-11-05 16:38:05,103 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8101 | Iter Mean Loss 7.0370
2020-11-05 16:38:05,109 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9470 | Iter Mean Loss 9.3404
2020-11-05 16:38:05,115 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2418 | Iter Mean Loss 9.3157
2020-11-05 16:38:05,120 - root - INFO - Training: Epoch 0520 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8323 | Iter Mean Loss 8.2190
2020-11-05 16:38:05,121 - root - INFO - Evaluate: Epoch 0520 | NDCG 0.0000 | MSE 0.1884
2020-11-05 16:38:05,127 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2485 | Iter Mean Loss 12.2485
2020-11-05 16:38:05,133 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8073 | Iter Mean Loss 7.0279
2020-11-05 16:38:05,138 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.9221 | Iter Mean Loss 9.3260
2020-11-05 16:38:05,145 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2295 | Iter Mean Loss 9.3019
2020-11-05 16:38:05,150 - root - INFO - Training: Epoch 0521 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8301 | Iter Mean Loss 8.2075
2020-11-05 16:38:05,151 - root - INFO - Evaluate: Epoch 0521 | NDCG 0.0000 | MSE 0.1883
2020-11-05 16:38:05,158 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2331 | Iter Mean Loss 12.2331
2020-11-05 16:38:05,164 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8044 | Iter Mean Loss 7.0188
2020-11-05 16:38:05,170 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8973 | Iter Mean Loss 9.3116
2020-11-05 16:38:05,176 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2173 | Iter Mean Loss 9.2880
2020-11-05 16:38:05,181 - root - INFO - Training: Epoch 0522 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8279 | Iter Mean Loss 8.1960
2020-11-05 16:38:05,183 - root - INFO - Evaluate: Epoch 0522 | NDCG 0.0000 | MSE 0.1883
2020-11-05 16:38:05,189 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2178 | Iter Mean Loss 12.2178
2020-11-05 16:38:05,195 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.8015 | Iter Mean Loss 7.0097
2020-11-05 16:38:05,202 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8725 | Iter Mean Loss 9.2973
2020-11-05 16:38:05,208 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.2052 | Iter Mean Loss 9.2742
2020-11-05 16:38:05,213 - root - INFO - Training: Epoch 0523 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8257 | Iter Mean Loss 8.1845
2020-11-05 16:38:05,215 - root - INFO - Evaluate: Epoch 0523 | NDCG 0.0000 | MSE 0.1882
2020-11-05 16:38:05,222 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.2025 | Iter Mean Loss 12.2025
2020-11-05 16:38:05,228 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7987 | Iter Mean Loss 7.0006
2020-11-05 16:38:05,234 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8477 | Iter Mean Loss 9.2830
2020-11-05 16:38:05,241 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1931 | Iter Mean Loss 9.2605
2020-11-05 16:38:05,246 - root - INFO - Training: Epoch 0524 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8234 | Iter Mean Loss 8.1731
2020-11-05 16:38:05,247 - root - INFO - Evaluate: Epoch 0524 | NDCG 0.0000 | MSE 0.1882
2020-11-05 16:38:05,254 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1873 | Iter Mean Loss 12.1873
2020-11-05 16:38:05,260 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7958 | Iter Mean Loss 6.9915
2020-11-05 16:38:05,266 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.8230 | Iter Mean Loss 9.2687
2020-11-05 16:38:05,272 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1811 | Iter Mean Loss 9.2468
2020-11-05 16:38:05,277 - root - INFO - Training: Epoch 0525 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8212 | Iter Mean Loss 8.1617
2020-11-05 16:38:05,277 - root - INFO - Evaluate: Epoch 0525 | NDCG 0.0000 | MSE 0.1881
2020-11-05 16:38:05,283 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1721 | Iter Mean Loss 12.1721
2020-11-05 16:38:05,289 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7929 | Iter Mean Loss 6.9825
2020-11-05 16:38:05,295 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7983 | Iter Mean Loss 9.2544
2020-11-05 16:38:05,301 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1691 | Iter Mean Loss 9.2331
2020-11-05 16:38:05,306 - root - INFO - Training: Epoch 0526 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8189 | Iter Mean Loss 8.1503
2020-11-05 16:38:05,306 - root - INFO - Evaluate: Epoch 0526 | NDCG 0.0000 | MSE 0.1880
2020-11-05 16:38:05,313 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1569 | Iter Mean Loss 12.1569
2020-11-05 16:38:05,319 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7901 | Iter Mean Loss 6.9735
2020-11-05 16:38:05,327 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7737 | Iter Mean Loss 9.2402
2020-11-05 16:38:05,332 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1572 | Iter Mean Loss 9.2195
2020-11-05 16:38:05,337 - root - INFO - Training: Epoch 0527 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8167 | Iter Mean Loss 8.1389
2020-11-05 16:38:05,338 - root - INFO - Evaluate: Epoch 0527 | NDCG 0.0000 | MSE 0.1880
2020-11-05 16:38:05,344 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1418 | Iter Mean Loss 12.1418
2020-11-05 16:38:05,350 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7872 | Iter Mean Loss 6.9645
2020-11-05 16:38:05,356 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7491 | Iter Mean Loss 9.2260
2020-11-05 16:38:05,362 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1453 | Iter Mean Loss 9.2058
2020-11-05 16:38:05,368 - root - INFO - Training: Epoch 0528 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8145 | Iter Mean Loss 8.1276
2020-11-05 16:38:05,369 - root - INFO - Evaluate: Epoch 0528 | NDCG 0.0000 | MSE 0.1879
2020-11-05 16:38:05,375 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1267 | Iter Mean Loss 12.1267
2020-11-05 16:38:05,382 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7843 | Iter Mean Loss 6.9555
2020-11-05 16:38:05,388 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7245 | Iter Mean Loss 9.2119
2020-11-05 16:38:05,394 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1335 | Iter Mean Loss 9.1923
2020-11-05 16:38:05,400 - root - INFO - Training: Epoch 0529 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8122 | Iter Mean Loss 8.1163
2020-11-05 16:38:05,401 - root - INFO - Evaluate: Epoch 0529 | NDCG 0.0000 | MSE 0.1879
2020-11-05 16:38:05,406 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.1117 | Iter Mean Loss 12.1117
2020-11-05 16:38:05,413 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7814 | Iter Mean Loss 6.9466
2020-11-05 16:38:05,419 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.7000 | Iter Mean Loss 9.1977
2020-11-05 16:38:05,425 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1218 | Iter Mean Loss 9.1787
2020-11-05 16:38:05,430 - root - INFO - Training: Epoch 0530 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8100 | Iter Mean Loss 8.1050
2020-11-05 16:38:05,431 - root - INFO - Evaluate: Epoch 0530 | NDCG 0.0000 | MSE 0.1878
2020-11-05 16:38:05,438 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0967 | Iter Mean Loss 12.0967
2020-11-05 16:38:05,443 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7786 | Iter Mean Loss 6.9376
2020-11-05 16:38:05,449 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6756 | Iter Mean Loss 9.1836
2020-11-05 16:38:05,455 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.1101 | Iter Mean Loss 9.1652
2020-11-05 16:38:05,460 - root - INFO - Training: Epoch 0531 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8077 | Iter Mean Loss 8.0937
2020-11-05 16:38:05,461 - root - INFO - Evaluate: Epoch 0531 | NDCG 0.0000 | MSE 0.1877
2020-11-05 16:38:05,467 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0817 | Iter Mean Loss 12.0817
2020-11-05 16:38:05,473 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7757 | Iter Mean Loss 6.9287
2020-11-05 16:38:05,478 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6512 | Iter Mean Loss 9.1695
2020-11-05 16:38:05,484 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0984 | Iter Mean Loss 9.1517
2020-11-05 16:38:05,489 - root - INFO - Training: Epoch 0532 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8055 | Iter Mean Loss 8.0825
2020-11-05 16:38:05,490 - root - INFO - Evaluate: Epoch 0532 | NDCG 0.0000 | MSE 0.1877
2020-11-05 16:38:05,496 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0668 | Iter Mean Loss 12.0668
2020-11-05 16:38:05,501 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7728 | Iter Mean Loss 6.9198
2020-11-05 16:38:05,507 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6268 | Iter Mean Loss 9.1555
2020-11-05 16:38:05,513 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0868 | Iter Mean Loss 9.1383
2020-11-05 16:38:05,517 - root - INFO - Training: Epoch 0533 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8032 | Iter Mean Loss 8.0713
2020-11-05 16:38:05,518 - root - INFO - Evaluate: Epoch 0533 | NDCG 0.0000 | MSE 0.1876
2020-11-05 16:38:05,524 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0520 | Iter Mean Loss 12.0520
2020-11-05 16:38:05,530 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7699 | Iter Mean Loss 6.9109
2020-11-05 16:38:05,535 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.6025 | Iter Mean Loss 9.1414
2020-11-05 16:38:05,541 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0753 | Iter Mean Loss 9.1249
2020-11-05 16:38:05,546 - root - INFO - Training: Epoch 0534 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.8010 | Iter Mean Loss 8.0601
2020-11-05 16:38:05,547 - root - INFO - Evaluate: Epoch 0534 | NDCG 0.0000 | MSE 0.1875
2020-11-05 16:38:05,553 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0371 | Iter Mean Loss 12.0371
2020-11-05 16:38:05,558 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7670 | Iter Mean Loss 6.9021
2020-11-05 16:38:05,564 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5782 | Iter Mean Loss 9.1274
2020-11-05 16:38:05,570 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0638 | Iter Mean Loss 9.1115
2020-11-05 16:38:05,576 - root - INFO - Training: Epoch 0535 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7987 | Iter Mean Loss 8.0490
2020-11-05 16:38:05,576 - root - INFO - Evaluate: Epoch 0535 | NDCG 0.0000 | MSE 0.1875
2020-11-05 16:38:05,582 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0223 | Iter Mean Loss 12.0223
2020-11-05 16:38:05,588 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7641 | Iter Mean Loss 6.8932
2020-11-05 16:38:05,595 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5539 | Iter Mean Loss 9.1135
2020-11-05 16:38:05,600 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0523 | Iter Mean Loss 9.0982
2020-11-05 16:38:05,606 - root - INFO - Training: Epoch 0536 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7965 | Iter Mean Loss 8.0378
2020-11-05 16:38:05,608 - root - INFO - Evaluate: Epoch 0536 | NDCG 0.0000 | MSE 0.1874
2020-11-05 16:38:05,614 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 12.0076 | Iter Mean Loss 12.0076
2020-11-05 16:38:05,620 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7613 | Iter Mean Loss 6.8844
2020-11-05 16:38:05,627 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5298 | Iter Mean Loss 9.0995
2020-11-05 16:38:05,632 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0409 | Iter Mean Loss 9.0849
2020-11-05 16:38:05,638 - root - INFO - Training: Epoch 0537 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7942 | Iter Mean Loss 8.0267
2020-11-05 16:38:05,639 - root - INFO - Evaluate: Epoch 0537 | NDCG 0.0000 | MSE 0.1874
2020-11-05 16:38:05,646 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9929 | Iter Mean Loss 11.9929
2020-11-05 16:38:05,652 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7584 | Iter Mean Loss 6.8756
2020-11-05 16:38:05,658 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.5056 | Iter Mean Loss 9.0856
2020-11-05 16:38:05,664 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0296 | Iter Mean Loss 9.0716
2020-11-05 16:38:05,669 - root - INFO - Training: Epoch 0538 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7919 | Iter Mean Loss 8.0157
2020-11-05 16:38:05,670 - root - INFO - Evaluate: Epoch 0538 | NDCG 0.0000 | MSE 0.1873
2020-11-05 16:38:05,676 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9782 | Iter Mean Loss 11.9782
2020-11-05 16:38:05,682 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7555 | Iter Mean Loss 6.8669
2020-11-05 16:38:05,687 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4815 | Iter Mean Loss 9.0717
2020-11-05 16:38:05,693 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0183 | Iter Mean Loss 9.0584
2020-11-05 16:38:05,698 - root - INFO - Training: Epoch 0539 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7897 | Iter Mean Loss 8.0046
2020-11-05 16:38:05,699 - root - INFO - Evaluate: Epoch 0539 | NDCG 0.0000 | MSE 0.1872
2020-11-05 16:38:05,704 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9636 | Iter Mean Loss 11.9636
2020-11-05 16:38:05,710 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7526 | Iter Mean Loss 6.8581
2020-11-05 16:38:05,715 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4575 | Iter Mean Loss 9.0579
2020-11-05 16:38:05,721 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 9.0070 | Iter Mean Loss 9.0452
2020-11-05 16:38:05,726 - root - INFO - Training: Epoch 0540 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7874 | Iter Mean Loss 7.9936
2020-11-05 16:38:05,727 - root - INFO - Evaluate: Epoch 0540 | NDCG 0.0000 | MSE 0.1872
2020-11-05 16:38:05,733 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9490 | Iter Mean Loss 11.9490
2020-11-05 16:38:05,738 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7497 | Iter Mean Loss 6.8494
2020-11-05 16:38:05,744 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4335 | Iter Mean Loss 9.0441
2020-11-05 16:38:05,750 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9958 | Iter Mean Loss 9.0320
2020-11-05 16:38:05,754 - root - INFO - Training: Epoch 0541 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7851 | Iter Mean Loss 7.9826
2020-11-05 16:38:05,755 - root - INFO - Evaluate: Epoch 0541 | NDCG 0.0000 | MSE 0.1871
2020-11-05 16:38:05,761 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9345 | Iter Mean Loss 11.9345
2020-11-05 16:38:05,767 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7468 | Iter Mean Loss 6.8406
2020-11-05 16:38:05,773 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.4095 | Iter Mean Loss 9.0303
2020-11-05 16:38:05,779 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9847 | Iter Mean Loss 9.0189
2020-11-05 16:38:05,784 - root - INFO - Training: Epoch 0542 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7829 | Iter Mean Loss 7.9717
2020-11-05 16:38:05,785 - root - INFO - Evaluate: Epoch 0542 | NDCG 0.0000 | MSE 0.1870
2020-11-05 16:38:05,791 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9200 | Iter Mean Loss 11.9200
2020-11-05 16:38:05,797 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7439 | Iter Mean Loss 6.8319
2020-11-05 16:38:05,803 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3856 | Iter Mean Loss 9.0165
2020-11-05 16:38:05,809 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9736 | Iter Mean Loss 9.0058
2020-11-05 16:38:05,815 - root - INFO - Training: Epoch 0543 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7806 | Iter Mean Loss 7.9607
2020-11-05 16:38:05,816 - root - INFO - Evaluate: Epoch 0543 | NDCG 0.0000 | MSE 0.1870
2020-11-05 16:38:05,821 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.9055 | Iter Mean Loss 11.9055
2020-11-05 16:38:05,828 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7410 | Iter Mean Loss 6.8233
2020-11-05 16:38:05,834 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3617 | Iter Mean Loss 9.0028
2020-11-05 16:38:05,840 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9625 | Iter Mean Loss 8.9927
2020-11-05 16:38:05,846 - root - INFO - Training: Epoch 0544 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7783 | Iter Mean Loss 7.9498
2020-11-05 16:38:05,847 - root - INFO - Evaluate: Epoch 0544 | NDCG 0.0000 | MSE 0.1869
2020-11-05 16:38:05,853 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8911 | Iter Mean Loss 11.8911
2020-11-05 16:38:05,859 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7381 | Iter Mean Loss 6.8146
2020-11-05 16:38:05,865 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3379 | Iter Mean Loss 8.9890
2020-11-05 16:38:05,871 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9515 | Iter Mean Loss 8.9797
2020-11-05 16:38:05,876 - root - INFO - Training: Epoch 0545 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7760 | Iter Mean Loss 7.9389
2020-11-05 16:38:05,877 - root - INFO - Evaluate: Epoch 0545 | NDCG 0.0000 | MSE 0.1869
2020-11-05 16:38:05,882 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8767 | Iter Mean Loss 11.8767
2020-11-05 16:38:05,888 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7352 | Iter Mean Loss 6.8060
2020-11-05 16:38:05,894 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.3141 | Iter Mean Loss 8.9754
2020-11-05 16:38:05,899 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9405 | Iter Mean Loss 8.9667
2020-11-05 16:38:05,904 - root - INFO - Training: Epoch 0546 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7738 | Iter Mean Loss 7.9281
2020-11-05 16:38:05,905 - root - INFO - Evaluate: Epoch 0546 | NDCG 0.0000 | MSE 0.1868
2020-11-05 16:38:05,910 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8624 | Iter Mean Loss 11.8624
2020-11-05 16:38:05,916 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7323 | Iter Mean Loss 6.7974
2020-11-05 16:38:05,921 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2904 | Iter Mean Loss 8.9617
2020-11-05 16:38:05,927 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9296 | Iter Mean Loss 8.9537
2020-11-05 16:38:05,932 - root - INFO - Training: Epoch 0547 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7715 | Iter Mean Loss 7.9173
2020-11-05 16:38:05,932 - root - INFO - Evaluate: Epoch 0547 | NDCG 0.0000 | MSE 0.1867
2020-11-05 16:38:05,938 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8481 | Iter Mean Loss 11.8481
2020-11-05 16:38:05,944 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7294 | Iter Mean Loss 6.7888
2020-11-05 16:38:05,949 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2668 | Iter Mean Loss 8.9481
2020-11-05 16:38:05,955 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9188 | Iter Mean Loss 8.9408
2020-11-05 16:38:05,959 - root - INFO - Training: Epoch 0548 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7692 | Iter Mean Loss 7.9064
2020-11-05 16:38:05,960 - root - INFO - Evaluate: Epoch 0548 | NDCG 0.0000 | MSE 0.1867
2020-11-05 16:38:05,966 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8339 | Iter Mean Loss 11.8339
2020-11-05 16:38:05,972 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7265 | Iter Mean Loss 6.7802
2020-11-05 16:38:05,978 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2431 | Iter Mean Loss 8.9345
2020-11-05 16:38:05,984 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.9079 | Iter Mean Loss 8.9279
2020-11-05 16:38:05,989 - root - INFO - Training: Epoch 0549 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7669 | Iter Mean Loss 7.8957
2020-11-05 16:38:05,990 - root - INFO - Evaluate: Epoch 0549 | NDCG 0.0000 | MSE 0.1866
2020-11-05 16:38:05,996 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8197 | Iter Mean Loss 11.8197
2020-11-05 16:38:06,002 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7236 | Iter Mean Loss 6.7716
2020-11-05 16:38:06,007 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.2196 | Iter Mean Loss 8.9209
2020-11-05 16:38:06,014 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8972 | Iter Mean Loss 8.9150
2020-11-05 16:38:06,019 - root - INFO - Training: Epoch 0550 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7646 | Iter Mean Loss 7.8849
2020-11-05 16:38:06,020 - root - INFO - Evaluate: Epoch 0550 | NDCG 0.0000 | MSE 0.1866
2020-11-05 16:38:06,026 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.8055 | Iter Mean Loss 11.8055
2020-11-05 16:38:06,032 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7207 | Iter Mean Loss 6.7631
2020-11-05 16:38:06,038 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1961 | Iter Mean Loss 8.9074
2020-11-05 16:38:06,044 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8865 | Iter Mean Loss 8.9022
2020-11-05 16:38:06,050 - root - INFO - Training: Epoch 0551 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7623 | Iter Mean Loss 7.8742
2020-11-05 16:38:06,051 - root - INFO - Evaluate: Epoch 0551 | NDCG 0.0000 | MSE 0.1865
2020-11-05 16:38:06,056 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7914 | Iter Mean Loss 11.7914
2020-11-05 16:38:06,062 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7178 | Iter Mean Loss 6.7546
2020-11-05 16:38:06,069 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1726 | Iter Mean Loss 8.8939
2020-11-05 16:38:06,074 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8758 | Iter Mean Loss 8.8894
2020-11-05 16:38:06,079 - root - INFO - Training: Epoch 0552 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7600 | Iter Mean Loss 7.8635
2020-11-05 16:38:06,080 - root - INFO - Evaluate: Epoch 0552 | NDCG 0.0000 | MSE 0.1864
2020-11-05 16:38:06,086 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7773 | Iter Mean Loss 11.7773
2020-11-05 16:38:06,091 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7149 | Iter Mean Loss 6.7461
2020-11-05 16:38:06,097 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1492 | Iter Mean Loss 8.8804
2020-11-05 16:38:06,103 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8651 | Iter Mean Loss 8.8766
2020-11-05 16:38:06,107 - root - INFO - Training: Epoch 0553 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7578 | Iter Mean Loss 7.8528
2020-11-05 16:38:06,108 - root - INFO - Evaluate: Epoch 0553 | NDCG 0.0000 | MSE 0.1864
2020-11-05 16:38:06,115 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7632 | Iter Mean Loss 11.7632
2020-11-05 16:38:06,120 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7120 | Iter Mean Loss 6.7376
2020-11-05 16:38:06,126 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1258 | Iter Mean Loss 8.8670
2020-11-05 16:38:06,131 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8546 | Iter Mean Loss 8.8639
2020-11-05 16:38:06,136 - root - INFO - Training: Epoch 0554 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7555 | Iter Mean Loss 7.8422
2020-11-05 16:38:06,137 - root - INFO - Evaluate: Epoch 0554 | NDCG 0.0000 | MSE 0.1863
2020-11-05 16:38:06,143 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7492 | Iter Mean Loss 11.7492
2020-11-05 16:38:06,149 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7091 | Iter Mean Loss 6.7292
2020-11-05 16:38:06,155 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.1025 | Iter Mean Loss 8.8536
2020-11-05 16:38:06,160 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8440 | Iter Mean Loss 8.8512
2020-11-05 16:38:06,165 - root - INFO - Training: Epoch 0555 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7532 | Iter Mean Loss 7.8316
2020-11-05 16:38:06,166 - root - INFO - Evaluate: Epoch 0555 | NDCG 0.0000 | MSE 0.1862
2020-11-05 16:38:06,172 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7352 | Iter Mean Loss 11.7352
2020-11-05 16:38:06,177 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7062 | Iter Mean Loss 6.7207
2020-11-05 16:38:06,184 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0792 | Iter Mean Loss 8.8402
2020-11-05 16:38:06,189 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8335 | Iter Mean Loss 8.8385
2020-11-05 16:38:06,194 - root - INFO - Training: Epoch 0556 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7509 | Iter Mean Loss 7.8210
2020-11-05 16:38:06,195 - root - INFO - Evaluate: Epoch 0556 | NDCG 0.0000 | MSE 0.1862
2020-11-05 16:38:06,201 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7213 | Iter Mean Loss 11.7213
2020-11-05 16:38:06,207 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7033 | Iter Mean Loss 6.7123
2020-11-05 16:38:06,213 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0560 | Iter Mean Loss 8.8269
2020-11-05 16:38:06,219 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8231 | Iter Mean Loss 8.8259
2020-11-05 16:38:06,224 - root - INFO - Training: Epoch 0557 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7486 | Iter Mean Loss 7.8105
2020-11-05 16:38:06,225 - root - INFO - Evaluate: Epoch 0557 | NDCG 0.0000 | MSE 0.1861
2020-11-05 16:38:06,231 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.7074 | Iter Mean Loss 11.7074
2020-11-05 16:38:06,238 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.7004 | Iter Mean Loss 6.7039
2020-11-05 16:38:06,244 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0328 | Iter Mean Loss 8.8136
2020-11-05 16:38:06,249 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8127 | Iter Mean Loss 8.8133
2020-11-05 16:38:06,255 - root - INFO - Training: Epoch 0558 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7463 | Iter Mean Loss 7.7999
2020-11-05 16:38:06,256 - root - INFO - Evaluate: Epoch 0558 | NDCG 0.0000 | MSE 0.1861
2020-11-05 16:38:06,261 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6936 | Iter Mean Loss 11.6936
2020-11-05 16:38:06,267 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6975 | Iter Mean Loss 6.6955
2020-11-05 16:38:06,273 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 13.0097 | Iter Mean Loss 8.8003
2020-11-05 16:38:06,279 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.8023 | Iter Mean Loss 8.8008
2020-11-05 16:38:06,284 - root - INFO - Training: Epoch 0559 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7440 | Iter Mean Loss 7.7894
2020-11-05 16:38:06,285 - root - INFO - Evaluate: Epoch 0559 | NDCG 0.0000 | MSE 0.1860
2020-11-05 16:38:06,290 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6798 | Iter Mean Loss 11.6798
2020-11-05 16:38:06,296 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6946 | Iter Mean Loss 6.6872
2020-11-05 16:38:06,301 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9867 | Iter Mean Loss 8.7870
2020-11-05 16:38:06,306 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7920 | Iter Mean Loss 8.7883
2020-11-05 16:38:06,311 - root - INFO - Training: Epoch 0560 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7417 | Iter Mean Loss 7.7790
2020-11-05 16:38:06,312 - root - INFO - Evaluate: Epoch 0560 | NDCG 0.0000 | MSE 0.1859
2020-11-05 16:38:06,319 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6660 | Iter Mean Loss 11.6660
2020-11-05 16:38:06,325 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6917 | Iter Mean Loss 6.6789
2020-11-05 16:38:06,331 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9637 | Iter Mean Loss 8.7738
2020-11-05 16:38:06,336 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7818 | Iter Mean Loss 8.7758
2020-11-05 16:38:06,341 - root - INFO - Training: Epoch 0561 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7394 | Iter Mean Loss 7.7685
2020-11-05 16:38:06,342 - root - INFO - Evaluate: Epoch 0561 | NDCG 0.0000 | MSE 0.1859
2020-11-05 16:38:06,348 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6523 | Iter Mean Loss 11.6523
2020-11-05 16:38:06,353 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6888 | Iter Mean Loss 6.6705
2020-11-05 16:38:06,358 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9407 | Iter Mean Loss 8.7606
2020-11-05 16:38:06,364 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7716 | Iter Mean Loss 8.7633
2020-11-05 16:38:06,369 - root - INFO - Training: Epoch 0562 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7371 | Iter Mean Loss 7.7581
2020-11-05 16:38:06,369 - root - INFO - Evaluate: Epoch 0562 | NDCG 0.0000 | MSE 0.1858
2020-11-05 16:38:06,375 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6386 | Iter Mean Loss 11.6386
2020-11-05 16:38:06,381 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6859 | Iter Mean Loss 6.6623
2020-11-05 16:38:06,387 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.9178 | Iter Mean Loss 8.7475
2020-11-05 16:38:06,393 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7614 | Iter Mean Loss 8.7509
2020-11-05 16:38:06,398 - root - INFO - Training: Epoch 0563 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7348 | Iter Mean Loss 7.7477
2020-11-05 16:38:06,398 - root - INFO - Evaluate: Epoch 0563 | NDCG 0.0000 | MSE 0.1857
2020-11-05 16:38:06,405 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6249 | Iter Mean Loss 11.6249
2020-11-05 16:38:06,416 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6830 | Iter Mean Loss 6.6540
2020-11-05 16:38:06,423 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8950 | Iter Mean Loss 8.7343
2020-11-05 16:38:06,431 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7513 | Iter Mean Loss 8.7386
2020-11-05 16:38:06,437 - root - INFO - Training: Epoch 0564 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7325 | Iter Mean Loss 7.7373
2020-11-05 16:38:06,439 - root - INFO - Evaluate: Epoch 0564 | NDCG 0.0000 | MSE 0.1857
2020-11-05 16:38:06,446 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.6113 | Iter Mean Loss 11.6113
2020-11-05 16:38:06,453 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6802 | Iter Mean Loss 6.6457
2020-11-05 16:38:06,461 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8722 | Iter Mean Loss 8.7212
2020-11-05 16:38:06,469 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7412 | Iter Mean Loss 8.7262
2020-11-05 16:38:06,477 - root - INFO - Training: Epoch 0565 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7302 | Iter Mean Loss 7.7270
2020-11-05 16:38:06,478 - root - INFO - Evaluate: Epoch 0565 | NDCG 0.0000 | MSE 0.1856
2020-11-05 16:38:06,486 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5978 | Iter Mean Loss 11.5978
2020-11-05 16:38:06,493 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6773 | Iter Mean Loss 6.6375
2020-11-05 16:38:06,500 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8495 | Iter Mean Loss 8.7082
2020-11-05 16:38:06,507 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7312 | Iter Mean Loss 8.7139
2020-11-05 16:38:06,514 - root - INFO - Training: Epoch 0566 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7278 | Iter Mean Loss 7.7167
2020-11-05 16:38:06,515 - root - INFO - Evaluate: Epoch 0566 | NDCG 0.0000 | MSE 0.1856
2020-11-05 16:38:06,525 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5842 | Iter Mean Loss 11.5842
2020-11-05 16:38:06,533 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6744 | Iter Mean Loss 6.6293
2020-11-05 16:38:06,539 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8268 | Iter Mean Loss 8.6952
2020-11-05 16:38:06,546 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7212 | Iter Mean Loss 8.7017
2020-11-05 16:38:06,551 - root - INFO - Training: Epoch 0567 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7255 | Iter Mean Loss 7.7064
2020-11-05 16:38:06,552 - root - INFO - Evaluate: Epoch 0567 | NDCG 0.0000 | MSE 0.1855
2020-11-05 16:38:06,559 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5708 | Iter Mean Loss 11.5708
2020-11-05 16:38:06,565 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6715 | Iter Mean Loss 6.6211
2020-11-05 16:38:06,572 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.8042 | Iter Mean Loss 8.6822
2020-11-05 16:38:06,579 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7112 | Iter Mean Loss 8.6894
2020-11-05 16:38:06,585 - root - INFO - Training: Epoch 0568 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7232 | Iter Mean Loss 7.6962
2020-11-05 16:38:06,587 - root - INFO - Evaluate: Epoch 0568 | NDCG 0.0000 | MSE 0.1854
2020-11-05 16:38:06,596 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5573 | Iter Mean Loss 11.5573
2020-11-05 16:38:06,604 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6686 | Iter Mean Loss 6.6130
2020-11-05 16:38:06,613 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7817 | Iter Mean Loss 8.6692
2020-11-05 16:38:06,618 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.7013 | Iter Mean Loss 8.6772
2020-11-05 16:38:06,624 - root - INFO - Training: Epoch 0569 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7209 | Iter Mean Loss 7.6860
2020-11-05 16:38:06,625 - root - INFO - Evaluate: Epoch 0569 | NDCG 0.0000 | MSE 0.1854
2020-11-05 16:38:06,631 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5439 | Iter Mean Loss 11.5439
2020-11-05 16:38:06,636 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6658 | Iter Mean Loss 6.6048
2020-11-05 16:38:06,642 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7592 | Iter Mean Loss 8.6563
2020-11-05 16:38:06,648 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6915 | Iter Mean Loss 8.6651
2020-11-05 16:38:06,653 - root - INFO - Training: Epoch 0570 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7186 | Iter Mean Loss 7.6758
2020-11-05 16:38:06,654 - root - INFO - Evaluate: Epoch 0570 | NDCG 0.0000 | MSE 0.1853
2020-11-05 16:38:06,661 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5305 | Iter Mean Loss 11.5305
2020-11-05 16:38:06,666 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6629 | Iter Mean Loss 6.5967
2020-11-05 16:38:06,672 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7367 | Iter Mean Loss 8.6434
2020-11-05 16:38:06,678 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6817 | Iter Mean Loss 8.6530
2020-11-05 16:38:06,683 - root - INFO - Training: Epoch 0571 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7163 | Iter Mean Loss 7.6656
2020-11-05 16:38:06,683 - root - INFO - Evaluate: Epoch 0571 | NDCG 0.0000 | MSE 0.1852
2020-11-05 16:38:06,689 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5172 | Iter Mean Loss 11.5172
2020-11-05 16:38:06,695 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6600 | Iter Mean Loss 6.5886
2020-11-05 16:38:06,700 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.7143 | Iter Mean Loss 8.6305
2020-11-05 16:38:06,705 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6719 | Iter Mean Loss 8.6409
2020-11-05 16:38:06,710 - root - INFO - Training: Epoch 0572 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7140 | Iter Mean Loss 7.6555
2020-11-05 16:38:06,711 - root - INFO - Evaluate: Epoch 0572 | NDCG 0.0000 | MSE 0.1852
2020-11-05 16:38:06,716 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.5039 | Iter Mean Loss 11.5039
2020-11-05 16:38:06,722 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6572 | Iter Mean Loss 6.5805
2020-11-05 16:38:06,727 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6920 | Iter Mean Loss 8.6177
2020-11-05 16:38:06,732 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6622 | Iter Mean Loss 8.6288
2020-11-05 16:38:06,737 - root - INFO - Training: Epoch 0573 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7117 | Iter Mean Loss 7.6454
2020-11-05 16:38:06,738 - root - INFO - Evaluate: Epoch 0573 | NDCG 0.0000 | MSE 0.1851
2020-11-05 16:38:06,744 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4907 | Iter Mean Loss 11.4907
2020-11-05 16:38:06,749 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6543 | Iter Mean Loss 6.5725
2020-11-05 16:38:06,754 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6698 | Iter Mean Loss 8.6049
2020-11-05 16:38:06,760 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6525 | Iter Mean Loss 8.6168
2020-11-05 16:38:06,764 - root - INFO - Training: Epoch 0574 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7094 | Iter Mean Loss 7.6353
2020-11-05 16:38:06,765 - root - INFO - Evaluate: Epoch 0574 | NDCG 0.0000 | MSE 0.1851
2020-11-05 16:38:06,771 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4775 | Iter Mean Loss 11.4775
2020-11-05 16:38:06,776 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6514 | Iter Mean Loss 6.5645
2020-11-05 16:38:06,782 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6475 | Iter Mean Loss 8.5922
2020-11-05 16:38:06,787 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6429 | Iter Mean Loss 8.6048
2020-11-05 16:38:06,793 - root - INFO - Training: Epoch 0575 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7071 | Iter Mean Loss 7.6253
2020-11-05 16:38:06,794 - root - INFO - Evaluate: Epoch 0575 | NDCG 0.0000 | MSE 0.1850
2020-11-05 16:38:06,800 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4643 | Iter Mean Loss 11.4643
2020-11-05 16:38:06,805 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6486 | Iter Mean Loss 6.5565
2020-11-05 16:38:06,811 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6254 | Iter Mean Loss 8.5794
2020-11-05 16:38:06,817 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6333 | Iter Mean Loss 8.5929
2020-11-05 16:38:06,822 - root - INFO - Training: Epoch 0576 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7048 | Iter Mean Loss 7.6153
2020-11-05 16:38:06,823 - root - INFO - Evaluate: Epoch 0576 | NDCG 0.0000 | MSE 0.1849
2020-11-05 16:38:06,829 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4512 | Iter Mean Loss 11.4512
2020-11-05 16:38:06,835 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6457 | Iter Mean Loss 6.5485
2020-11-05 16:38:06,841 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.6033 | Iter Mean Loss 8.5667
2020-11-05 16:38:06,846 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6237 | Iter Mean Loss 8.5810
2020-11-05 16:38:06,852 - root - INFO - Training: Epoch 0577 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7025 | Iter Mean Loss 7.6053
2020-11-05 16:38:06,853 - root - INFO - Evaluate: Epoch 0577 | NDCG 0.0000 | MSE 0.1849
2020-11-05 16:38:06,859 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4381 | Iter Mean Loss 11.4381
2020-11-05 16:38:06,865 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6429 | Iter Mean Loss 6.5405
2020-11-05 16:38:06,870 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5813 | Iter Mean Loss 8.5541
2020-11-05 16:38:06,876 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6142 | Iter Mean Loss 8.5691
2020-11-05 16:38:06,881 - root - INFO - Training: Epoch 0578 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.7002 | Iter Mean Loss 7.5953
2020-11-05 16:38:06,882 - root - INFO - Evaluate: Epoch 0578 | NDCG 0.0000 | MSE 0.1848
2020-11-05 16:38:06,888 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4251 | Iter Mean Loss 11.4251
2020-11-05 16:38:06,894 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6400 | Iter Mean Loss 6.5326
2020-11-05 16:38:06,899 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5593 | Iter Mean Loss 8.5415
2020-11-05 16:38:06,904 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.6048 | Iter Mean Loss 8.5573
2020-11-05 16:38:06,909 - root - INFO - Training: Epoch 0579 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6978 | Iter Mean Loss 7.5854
2020-11-05 16:38:06,910 - root - INFO - Evaluate: Epoch 0579 | NDCG 0.0000 | MSE 0.1847
2020-11-05 16:38:06,915 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.4121 | Iter Mean Loss 11.4121
2020-11-05 16:38:06,921 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6372 | Iter Mean Loss 6.5246
2020-11-05 16:38:06,926 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5374 | Iter Mean Loss 8.5289
2020-11-05 16:38:06,931 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5954 | Iter Mean Loss 8.5455
2020-11-05 16:38:06,936 - root - INFO - Training: Epoch 0580 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6955 | Iter Mean Loss 7.5755
2020-11-05 16:38:06,937 - root - INFO - Evaluate: Epoch 0580 | NDCG 0.0000 | MSE 0.1847
2020-11-05 16:38:06,942 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3991 | Iter Mean Loss 11.3991
2020-11-05 16:38:06,948 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6344 | Iter Mean Loss 6.5167
2020-11-05 16:38:06,953 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.5156 | Iter Mean Loss 8.5164
2020-11-05 16:38:06,958 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5860 | Iter Mean Loss 8.5338
2020-11-05 16:38:06,963 - root - INFO - Training: Epoch 0581 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6932 | Iter Mean Loss 7.5657
2020-11-05 16:38:06,964 - root - INFO - Evaluate: Epoch 0581 | NDCG 0.0000 | MSE 0.1846
2020-11-05 16:38:06,969 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3862 | Iter Mean Loss 11.3862
2020-11-05 16:38:06,975 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6316 | Iter Mean Loss 6.5089
2020-11-05 16:38:06,980 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4938 | Iter Mean Loss 8.5038
2020-11-05 16:38:06,985 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5767 | Iter Mean Loss 8.5221
2020-11-05 16:38:06,990 - root - INFO - Training: Epoch 0582 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6909 | Iter Mean Loss 7.5558
2020-11-05 16:38:06,991 - root - INFO - Evaluate: Epoch 0582 | NDCG 0.0000 | MSE 0.1846
2020-11-05 16:38:06,997 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3733 | Iter Mean Loss 11.3733
2020-11-05 16:38:07,003 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6287 | Iter Mean Loss 6.5010
2020-11-05 16:38:07,008 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4721 | Iter Mean Loss 8.4914
2020-11-05 16:38:07,014 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5674 | Iter Mean Loss 8.5104
2020-11-05 16:38:07,019 - root - INFO - Training: Epoch 0583 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6886 | Iter Mean Loss 7.5460
2020-11-05 16:38:07,020 - root - INFO - Evaluate: Epoch 0583 | NDCG 0.0000 | MSE 0.1845
2020-11-05 16:38:07,026 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3604 | Iter Mean Loss 11.3604
2020-11-05 16:38:07,031 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6259 | Iter Mean Loss 6.4932
2020-11-05 16:38:07,038 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4505 | Iter Mean Loss 8.4789
2020-11-05 16:38:07,043 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5582 | Iter Mean Loss 8.4987
2020-11-05 16:38:07,048 - root - INFO - Training: Epoch 0584 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6863 | Iter Mean Loss 7.5363
2020-11-05 16:38:07,050 - root - INFO - Evaluate: Epoch 0584 | NDCG 0.0000 | MSE 0.1844
2020-11-05 16:38:07,056 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3476 | Iter Mean Loss 11.3476
2020-11-05 16:38:07,061 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6231 | Iter Mean Loss 6.4854
2020-11-05 16:38:07,067 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4289 | Iter Mean Loss 8.4665
2020-11-05 16:38:07,073 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5490 | Iter Mean Loss 8.4871
2020-11-05 16:38:07,078 - root - INFO - Training: Epoch 0585 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6840 | Iter Mean Loss 7.5265
2020-11-05 16:38:07,079 - root - INFO - Evaluate: Epoch 0585 | NDCG 0.0000 | MSE 0.1844
2020-11-05 16:38:07,085 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3349 | Iter Mean Loss 11.3349
2020-11-05 16:38:07,091 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6203 | Iter Mean Loss 6.4776
2020-11-05 16:38:07,096 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.4073 | Iter Mean Loss 8.4542
2020-11-05 16:38:07,102 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5398 | Iter Mean Loss 8.4756
2020-11-05 16:38:07,107 - root - INFO - Training: Epoch 0586 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6818 | Iter Mean Loss 7.5168
2020-11-05 16:38:07,108 - root - INFO - Evaluate: Epoch 0586 | NDCG 0.0000 | MSE 0.1843
2020-11-05 16:38:07,114 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3221 | Iter Mean Loss 11.3221
2020-11-05 16:38:07,119 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6175 | Iter Mean Loss 6.4698
2020-11-05 16:38:07,125 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3859 | Iter Mean Loss 8.4418
2020-11-05 16:38:07,130 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5307 | Iter Mean Loss 8.4641
2020-11-05 16:38:07,135 - root - INFO - Training: Epoch 0587 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6795 | Iter Mean Loss 7.5071
2020-11-05 16:38:07,136 - root - INFO - Evaluate: Epoch 0587 | NDCG 0.0000 | MSE 0.1842
2020-11-05 16:38:07,142 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.3094 | Iter Mean Loss 11.3094
2020-11-05 16:38:07,148 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6147 | Iter Mean Loss 6.4621
2020-11-05 16:38:07,153 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3645 | Iter Mean Loss 8.4296
2020-11-05 16:38:07,158 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5217 | Iter Mean Loss 8.4526
2020-11-05 16:38:07,163 - root - INFO - Training: Epoch 0588 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6772 | Iter Mean Loss 7.4975
2020-11-05 16:38:07,164 - root - INFO - Evaluate: Epoch 0588 | NDCG 0.0000 | MSE 0.1842
2020-11-05 16:38:07,170 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2968 | Iter Mean Loss 11.2968
2020-11-05 16:38:07,175 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6119 | Iter Mean Loss 6.4544
2020-11-05 16:38:07,180 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3432 | Iter Mean Loss 8.4173
2020-11-05 16:38:07,186 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5127 | Iter Mean Loss 8.4411
2020-11-05 16:38:07,191 - root - INFO - Training: Epoch 0589 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6749 | Iter Mean Loss 7.4879
2020-11-05 16:38:07,191 - root - INFO - Evaluate: Epoch 0589 | NDCG 0.0000 | MSE 0.1841
2020-11-05 16:38:07,197 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2842 | Iter Mean Loss 11.2842
2020-11-05 16:38:07,203 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6092 | Iter Mean Loss 6.4467
2020-11-05 16:38:07,209 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3219 | Iter Mean Loss 8.4051
2020-11-05 16:38:07,214 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.5037 | Iter Mean Loss 8.4297
2020-11-05 16:38:07,219 - root - INFO - Training: Epoch 0590 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6726 | Iter Mean Loss 7.4783
2020-11-05 16:38:07,221 - root - INFO - Evaluate: Epoch 0590 | NDCG 0.0000 | MSE 0.1841
2020-11-05 16:38:07,227 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2716 | Iter Mean Loss 11.2716
2020-11-05 16:38:07,232 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6064 | Iter Mean Loss 6.4390
2020-11-05 16:38:07,238 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.3007 | Iter Mean Loss 8.3929
2020-11-05 16:38:07,244 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4948 | Iter Mean Loss 8.4184
2020-11-05 16:38:07,250 - root - INFO - Training: Epoch 0591 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6703 | Iter Mean Loss 7.4688
2020-11-05 16:38:07,251 - root - INFO - Evaluate: Epoch 0591 | NDCG 0.0000 | MSE 0.1840
2020-11-05 16:38:07,257 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2591 | Iter Mean Loss 11.2591
2020-11-05 16:38:07,263 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6036 | Iter Mean Loss 6.4314
2020-11-05 16:38:07,269 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2796 | Iter Mean Loss 8.3808
2020-11-05 16:38:07,275 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4859 | Iter Mean Loss 8.4070
2020-11-05 16:38:07,280 - root - INFO - Training: Epoch 0592 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6680 | Iter Mean Loss 7.4592
2020-11-05 16:38:07,281 - root - INFO - Evaluate: Epoch 0592 | NDCG 0.0000 | MSE 0.1839
2020-11-05 16:38:07,287 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2466 | Iter Mean Loss 11.2466
2020-11-05 16:38:07,293 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.6009 | Iter Mean Loss 6.4237
2020-11-05 16:38:07,298 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2585 | Iter Mean Loss 8.3687
2020-11-05 16:38:07,304 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4771 | Iter Mean Loss 8.3958
2020-11-05 16:38:07,308 - root - INFO - Training: Epoch 0593 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6658 | Iter Mean Loss 7.4498
2020-11-05 16:38:07,309 - root - INFO - Evaluate: Epoch 0593 | NDCG 0.0000 | MSE 0.1839
2020-11-05 16:38:07,315 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2341 | Iter Mean Loss 11.2341
2020-11-05 16:38:07,322 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5981 | Iter Mean Loss 6.4161
2020-11-05 16:38:07,327 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2375 | Iter Mean Loss 8.3566
2020-11-05 16:38:07,333 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4683 | Iter Mean Loss 8.3845
2020-11-05 16:38:07,337 - root - INFO - Training: Epoch 0594 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6635 | Iter Mean Loss 7.4403
2020-11-05 16:38:07,338 - root - INFO - Evaluate: Epoch 0594 | NDCG 0.0000 | MSE 0.1838
2020-11-05 16:38:07,344 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2217 | Iter Mean Loss 11.2217
2020-11-05 16:38:07,349 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5954 | Iter Mean Loss 6.4086
2020-11-05 16:38:07,355 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.2166 | Iter Mean Loss 8.3446
2020-11-05 16:38:07,360 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4595 | Iter Mean Loss 8.3733
2020-11-05 16:38:07,365 - root - INFO - Training: Epoch 0595 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6612 | Iter Mean Loss 7.4309
2020-11-05 16:38:07,366 - root - INFO - Evaluate: Epoch 0595 | NDCG 0.0000 | MSE 0.1838
2020-11-05 16:38:07,371 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.2093 | Iter Mean Loss 11.2093
2020-11-05 16:38:07,376 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5927 | Iter Mean Loss 6.4010
2020-11-05 16:38:07,382 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1957 | Iter Mean Loss 8.3326
2020-11-05 16:38:07,388 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4508 | Iter Mean Loss 8.3621
2020-11-05 16:38:07,393 - root - INFO - Training: Epoch 0596 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6590 | Iter Mean Loss 7.4215
2020-11-05 16:38:07,394 - root - INFO - Evaluate: Epoch 0596 | NDCG 0.0000 | MSE 0.1837
2020-11-05 16:38:07,401 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1970 | Iter Mean Loss 11.1970
2020-11-05 16:38:07,406 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5900 | Iter Mean Loss 6.3935
2020-11-05 16:38:07,412 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1749 | Iter Mean Loss 8.3206
2020-11-05 16:38:07,418 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4421 | Iter Mean Loss 8.3510
2020-11-05 16:38:07,424 - root - INFO - Training: Epoch 0597 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6567 | Iter Mean Loss 7.4121
2020-11-05 16:38:07,425 - root - INFO - Evaluate: Epoch 0597 | NDCG 0.0000 | MSE 0.1836
2020-11-05 16:38:07,431 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1847 | Iter Mean Loss 11.1847
2020-11-05 16:38:07,437 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5872 | Iter Mean Loss 6.3860
2020-11-05 16:38:07,443 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1542 | Iter Mean Loss 8.3087
2020-11-05 16:38:07,449 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4335 | Iter Mean Loss 8.3399
2020-11-05 16:38:07,454 - root - INFO - Training: Epoch 0598 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6544 | Iter Mean Loss 7.4028
2020-11-05 16:38:07,455 - root - INFO - Evaluate: Epoch 0598 | NDCG 0.0000 | MSE 0.1836
2020-11-05 16:38:07,461 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1724 | Iter Mean Loss 11.1724
2020-11-05 16:38:07,468 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5845 | Iter Mean Loss 6.3785
2020-11-05 16:38:07,473 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1335 | Iter Mean Loss 8.2968
2020-11-05 16:38:07,479 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4250 | Iter Mean Loss 8.3289
2020-11-05 16:38:07,483 - root - INFO - Training: Epoch 0599 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6522 | Iter Mean Loss 7.3935
2020-11-05 16:38:07,484 - root - INFO - Evaluate: Epoch 0599 | NDCG 0.0000 | MSE 0.1835
2020-11-05 16:38:07,490 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1602 | Iter Mean Loss 11.1602
2020-11-05 16:38:07,496 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5818 | Iter Mean Loss 6.3710
2020-11-05 16:38:07,501 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.1129 | Iter Mean Loss 8.2850
2020-11-05 16:38:07,507 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4164 | Iter Mean Loss 8.3178
2020-11-05 16:38:07,512 - root - INFO - Training: Epoch 0600 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6499 | Iter Mean Loss 7.3843
2020-11-05 16:38:07,513 - root - INFO - Evaluate: Epoch 0600 | NDCG 0.0000 | MSE 0.1834
2020-11-05 16:38:07,518 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1480 | Iter Mean Loss 11.1480
2020-11-05 16:38:07,523 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5792 | Iter Mean Loss 6.3636
2020-11-05 16:38:07,529 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0924 | Iter Mean Loss 8.2732
2020-11-05 16:38:07,534 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.4079 | Iter Mean Loss 8.3069
2020-11-05 16:38:07,539 - root - INFO - Training: Epoch 0601 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6477 | Iter Mean Loss 7.3750
2020-11-05 16:38:07,540 - root - INFO - Evaluate: Epoch 0601 | NDCG 0.0000 | MSE 0.1834
2020-11-05 16:38:07,545 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1358 | Iter Mean Loss 11.1358
2020-11-05 16:38:07,551 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5765 | Iter Mean Loss 6.3562
2020-11-05 16:38:07,556 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0720 | Iter Mean Loss 8.2614
2020-11-05 16:38:07,561 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3995 | Iter Mean Loss 8.2959
2020-11-05 16:38:07,566 - root - INFO - Training: Epoch 0602 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6455 | Iter Mean Loss 7.3658
2020-11-05 16:38:07,567 - root - INFO - Evaluate: Epoch 0602 | NDCG 0.0000 | MSE 0.1833
2020-11-05 16:38:07,572 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1237 | Iter Mean Loss 11.1237
2020-11-05 16:38:07,578 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5738 | Iter Mean Loss 6.3488
2020-11-05 16:38:07,583 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0516 | Iter Mean Loss 8.2497
2020-11-05 16:38:07,588 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3911 | Iter Mean Loss 8.2850
2020-11-05 16:38:07,593 - root - INFO - Training: Epoch 0603 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6432 | Iter Mean Loss 7.3567
2020-11-05 16:38:07,594 - root - INFO - Evaluate: Epoch 0603 | NDCG 0.0000 | MSE 0.1833
2020-11-05 16:38:07,600 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.1116 | Iter Mean Loss 11.1116
2020-11-05 16:38:07,606 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5712 | Iter Mean Loss 6.3414
2020-11-05 16:38:07,611 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0313 | Iter Mean Loss 8.2380
2020-11-05 16:38:07,618 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3827 | Iter Mean Loss 8.2742
2020-11-05 16:38:07,623 - root - INFO - Training: Epoch 0604 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6410 | Iter Mean Loss 7.3476
2020-11-05 16:38:07,625 - root - INFO - Evaluate: Epoch 0604 | NDCG 0.0000 | MSE 0.1832
2020-11-05 16:38:07,630 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0996 | Iter Mean Loss 11.0996
2020-11-05 16:38:07,636 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5685 | Iter Mean Loss 6.3341
2020-11-05 16:38:07,642 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 12.0110 | Iter Mean Loss 8.2264
2020-11-05 16:38:07,648 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3744 | Iter Mean Loss 8.2634
2020-11-05 16:38:07,652 - root - INFO - Training: Epoch 0605 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6388 | Iter Mean Loss 7.3385
2020-11-05 16:38:07,653 - root - INFO - Evaluate: Epoch 0605 | NDCG 0.0000 | MSE 0.1831
2020-11-05 16:38:07,660 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0876 | Iter Mean Loss 11.0876
2020-11-05 16:38:07,665 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5659 | Iter Mean Loss 6.3267
2020-11-05 16:38:07,671 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9908 | Iter Mean Loss 8.2148
2020-11-05 16:38:07,677 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3661 | Iter Mean Loss 8.2526
2020-11-05 16:38:07,682 - root - INFO - Training: Epoch 0606 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6366 | Iter Mean Loss 7.3294
2020-11-05 16:38:07,683 - root - INFO - Evaluate: Epoch 0606 | NDCG 0.0000 | MSE 0.1831
2020-11-05 16:38:07,689 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0756 | Iter Mean Loss 11.0756
2020-11-05 16:38:07,695 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5633 | Iter Mean Loss 6.3194
2020-11-05 16:38:07,700 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9707 | Iter Mean Loss 8.2032
2020-11-05 16:38:07,706 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3579 | Iter Mean Loss 8.2419
2020-11-05 16:38:07,710 - root - INFO - Training: Epoch 0607 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6344 | Iter Mean Loss 7.3204
2020-11-05 16:38:07,711 - root - INFO - Evaluate: Epoch 0607 | NDCG 0.0000 | MSE 0.1830
2020-11-05 16:38:07,717 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0637 | Iter Mean Loss 11.0637
2020-11-05 16:38:07,722 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5606 | Iter Mean Loss 6.3122
2020-11-05 16:38:07,728 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9507 | Iter Mean Loss 8.1917
2020-11-05 16:38:07,733 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3497 | Iter Mean Loss 8.2312
2020-11-05 16:38:07,738 - root - INFO - Training: Epoch 0608 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6322 | Iter Mean Loss 7.3114
2020-11-05 16:38:07,738 - root - INFO - Evaluate: Epoch 0608 | NDCG 0.0000 | MSE 0.1830
2020-11-05 16:38:07,744 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0518 | Iter Mean Loss 11.0518
2020-11-05 16:38:07,749 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5580 | Iter Mean Loss 6.3049
2020-11-05 16:38:07,755 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9307 | Iter Mean Loss 8.1802
2020-11-05 16:38:07,760 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3416 | Iter Mean Loss 8.2205
2020-11-05 16:38:07,765 - root - INFO - Training: Epoch 0609 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6300 | Iter Mean Loss 7.3024
2020-11-05 16:38:07,766 - root - INFO - Evaluate: Epoch 0609 | NDCG 0.0000 | MSE 0.1829
2020-11-05 16:38:07,771 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0400 | Iter Mean Loss 11.0400
2020-11-05 16:38:07,777 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5554 | Iter Mean Loss 6.2977
2020-11-05 16:38:07,782 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.9108 | Iter Mean Loss 8.1687
2020-11-05 16:38:07,787 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3335 | Iter Mean Loss 8.2099
2020-11-05 16:38:07,793 - root - INFO - Training: Epoch 0610 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6278 | Iter Mean Loss 7.2935
2020-11-05 16:38:07,793 - root - INFO - Evaluate: Epoch 0610 | NDCG 0.0000 | MSE 0.1828
2020-11-05 16:38:07,799 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0281 | Iter Mean Loss 11.0281
2020-11-05 16:38:07,805 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5529 | Iter Mean Loss 6.2905
2020-11-05 16:38:07,811 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8910 | Iter Mean Loss 8.1573
2020-11-05 16:38:07,816 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3254 | Iter Mean Loss 8.1994
2020-11-05 16:38:07,821 - root - INFO - Training: Epoch 0611 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6256 | Iter Mean Loss 7.2846
2020-11-05 16:38:07,822 - root - INFO - Evaluate: Epoch 0611 | NDCG 0.0000 | MSE 0.1828
2020-11-05 16:38:07,828 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0164 | Iter Mean Loss 11.0164
2020-11-05 16:38:07,834 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5503 | Iter Mean Loss 6.2833
2020-11-05 16:38:07,840 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8713 | Iter Mean Loss 8.1460
2020-11-05 16:38:07,846 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3174 | Iter Mean Loss 8.1888
2020-11-05 16:38:07,851 - root - INFO - Training: Epoch 0612 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6234 | Iter Mean Loss 7.2757
2020-11-05 16:38:07,852 - root - INFO - Evaluate: Epoch 0612 | NDCG 0.0000 | MSE 0.1827
2020-11-05 16:38:07,858 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 11.0046 | Iter Mean Loss 11.0046
2020-11-05 16:38:07,864 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5477 | Iter Mean Loss 6.2762
2020-11-05 16:38:07,869 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8516 | Iter Mean Loss 8.1346
2020-11-05 16:38:07,875 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3094 | Iter Mean Loss 8.1783
2020-11-05 16:38:07,880 - root - INFO - Training: Epoch 0613 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6212 | Iter Mean Loss 7.2669
2020-11-05 16:38:07,881 - root - INFO - Evaluate: Epoch 0613 | NDCG 0.0000 | MSE 0.1827
2020-11-05 16:38:07,887 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9929 | Iter Mean Loss 10.9929
2020-11-05 16:38:07,893 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5452 | Iter Mean Loss 6.2690
2020-11-05 16:38:07,899 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8320 | Iter Mean Loss 8.1234
2020-11-05 16:38:07,904 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.3015 | Iter Mean Loss 8.1679
2020-11-05 16:38:07,909 - root - INFO - Training: Epoch 0614 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6190 | Iter Mean Loss 7.2581
2020-11-05 16:38:07,910 - root - INFO - Evaluate: Epoch 0614 | NDCG 0.0000 | MSE 0.1826
2020-11-05 16:38:07,915 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9812 | Iter Mean Loss 10.9812
2020-11-05 16:38:07,920 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5426 | Iter Mean Loss 6.2619
2020-11-05 16:38:07,926 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.8124 | Iter Mean Loss 8.1121
2020-11-05 16:38:07,931 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2936 | Iter Mean Loss 8.1575
2020-11-05 16:38:07,936 - root - INFO - Training: Epoch 0615 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6169 | Iter Mean Loss 7.2494
2020-11-05 16:38:07,937 - root - INFO - Evaluate: Epoch 0615 | NDCG 0.0000 | MSE 0.1825
2020-11-05 16:38:07,942 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9696 | Iter Mean Loss 10.9696
2020-11-05 16:38:07,948 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5401 | Iter Mean Loss 6.2549
2020-11-05 16:38:07,953 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7930 | Iter Mean Loss 8.1009
2020-11-05 16:38:07,958 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2857 | Iter Mean Loss 8.1471
2020-11-05 16:38:07,963 - root - INFO - Training: Epoch 0616 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6147 | Iter Mean Loss 7.2406
2020-11-05 16:38:07,964 - root - INFO - Evaluate: Epoch 0616 | NDCG 0.0000 | MSE 0.1825
2020-11-05 16:38:07,969 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9580 | Iter Mean Loss 10.9580
2020-11-05 16:38:07,975 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5376 | Iter Mean Loss 6.2478
2020-11-05 16:38:07,980 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7736 | Iter Mean Loss 8.0897
2020-11-05 16:38:07,986 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2779 | Iter Mean Loss 8.1368
2020-11-05 16:38:07,990 - root - INFO - Training: Epoch 0617 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6126 | Iter Mean Loss 7.2319
2020-11-05 16:38:07,991 - root - INFO - Evaluate: Epoch 0617 | NDCG 0.0000 | MSE 0.1824
2020-11-05 16:38:07,997 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9464 | Iter Mean Loss 10.9464
2020-11-05 16:38:08,002 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5351 | Iter Mean Loss 6.2408
2020-11-05 16:38:08,008 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7543 | Iter Mean Loss 8.0786
2020-11-05 16:38:08,014 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2702 | Iter Mean Loss 8.1265
2020-11-05 16:38:08,019 - root - INFO - Training: Epoch 0618 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6104 | Iter Mean Loss 7.2233
2020-11-05 16:38:08,019 - root - INFO - Evaluate: Epoch 0618 | NDCG 0.0000 | MSE 0.1824
2020-11-05 16:38:08,025 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9349 | Iter Mean Loss 10.9349
2020-11-05 16:38:08,031 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5326 | Iter Mean Loss 6.2338
2020-11-05 16:38:08,037 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7350 | Iter Mean Loss 8.0675
2020-11-05 16:38:08,042 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2624 | Iter Mean Loss 8.1162
2020-11-05 16:38:08,048 - root - INFO - Training: Epoch 0619 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6083 | Iter Mean Loss 7.2147
2020-11-05 16:38:08,049 - root - INFO - Evaluate: Epoch 0619 | NDCG 0.0000 | MSE 0.1823
2020-11-05 16:38:08,054 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9234 | Iter Mean Loss 10.9234
2020-11-05 16:38:08,060 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5301 | Iter Mean Loss 6.2268
2020-11-05 16:38:08,066 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.7158 | Iter Mean Loss 8.0565
2020-11-05 16:38:08,072 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2548 | Iter Mean Loss 8.1060
2020-11-05 16:38:08,077 - root - INFO - Training: Epoch 0620 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6062 | Iter Mean Loss 7.2061
2020-11-05 16:38:08,078 - root - INFO - Evaluate: Epoch 0620 | NDCG 0.0000 | MSE 0.1822
2020-11-05 16:38:08,084 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9120 | Iter Mean Loss 10.9120
2020-11-05 16:38:08,090 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5277 | Iter Mean Loss 6.2198
2020-11-05 16:38:08,096 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6967 | Iter Mean Loss 8.0454
2020-11-05 16:38:08,102 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2471 | Iter Mean Loss 8.0959
2020-11-05 16:38:08,107 - root - INFO - Training: Epoch 0621 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6041 | Iter Mean Loss 7.1975
2020-11-05 16:38:08,107 - root - INFO - Evaluate: Epoch 0621 | NDCG 0.0000 | MSE 0.1822
2020-11-05 16:38:08,114 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.9005 | Iter Mean Loss 10.9005
2020-11-05 16:38:08,119 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5252 | Iter Mean Loss 6.2129
2020-11-05 16:38:08,125 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6777 | Iter Mean Loss 8.0345
2020-11-05 16:38:08,130 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2395 | Iter Mean Loss 8.0857
2020-11-05 16:38:08,135 - root - INFO - Training: Epoch 0622 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.6020 | Iter Mean Loss 7.1890
2020-11-05 16:38:08,136 - root - INFO - Evaluate: Epoch 0622 | NDCG 0.0000 | MSE 0.1821
2020-11-05 16:38:08,141 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8891 | Iter Mean Loss 10.8891
2020-11-05 16:38:08,147 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5228 | Iter Mean Loss 6.2060
2020-11-05 16:38:08,153 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6587 | Iter Mean Loss 8.0235
2020-11-05 16:38:08,158 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2320 | Iter Mean Loss 8.0756
2020-11-05 16:38:08,163 - root - INFO - Training: Epoch 0623 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5999 | Iter Mean Loss 7.1805
2020-11-05 16:38:08,164 - root - INFO - Evaluate: Epoch 0623 | NDCG 0.0000 | MSE 0.1821
2020-11-05 16:38:08,169 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8778 | Iter Mean Loss 10.8778
2020-11-05 16:38:08,175 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5203 | Iter Mean Loss 6.1991
2020-11-05 16:38:08,180 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6398 | Iter Mean Loss 8.0126
2020-11-05 16:38:08,185 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2244 | Iter Mean Loss 8.0656
2020-11-05 16:38:08,190 - root - INFO - Training: Epoch 0624 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5978 | Iter Mean Loss 7.1720
2020-11-05 16:38:08,191 - root - INFO - Evaluate: Epoch 0624 | NDCG 0.0000 | MSE 0.1820
2020-11-05 16:38:08,196 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8665 | Iter Mean Loss 10.8665
2020-11-05 16:38:08,202 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5179 | Iter Mean Loss 6.1922
2020-11-05 16:38:08,208 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6210 | Iter Mean Loss 8.0018
2020-11-05 16:38:08,214 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2170 | Iter Mean Loss 8.0556
2020-11-05 16:38:08,219 - root - INFO - Training: Epoch 0625 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5957 | Iter Mean Loss 7.1636
2020-11-05 16:38:08,219 - root - INFO - Evaluate: Epoch 0625 | NDCG 0.0000 | MSE 0.1819
2020-11-05 16:38:08,225 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8552 | Iter Mean Loss 10.8552
2020-11-05 16:38:08,231 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5155 | Iter Mean Loss 6.1854
2020-11-05 16:38:08,237 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.6023 | Iter Mean Loss 7.9910
2020-11-05 16:38:08,242 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2095 | Iter Mean Loss 8.0456
2020-11-05 16:38:08,248 - root - INFO - Training: Epoch 0626 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5936 | Iter Mean Loss 7.1552
2020-11-05 16:38:08,249 - root - INFO - Evaluate: Epoch 0626 | NDCG 0.0000 | MSE 0.1819
2020-11-05 16:38:08,255 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8439 | Iter Mean Loss 10.8439
2020-11-05 16:38:08,261 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5131 | Iter Mean Loss 6.1785
2020-11-05 16:38:08,267 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5836 | Iter Mean Loss 7.9802
2020-11-05 16:38:08,273 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.2021 | Iter Mean Loss 8.0357
2020-11-05 16:38:08,278 - root - INFO - Training: Epoch 0627 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5916 | Iter Mean Loss 7.1469
2020-11-05 16:38:08,279 - root - INFO - Evaluate: Epoch 0627 | NDCG 0.0000 | MSE 0.1818
2020-11-05 16:38:08,285 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8327 | Iter Mean Loss 10.8327
2020-11-05 16:38:08,290 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5107 | Iter Mean Loss 6.1717
2020-11-05 16:38:08,296 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5650 | Iter Mean Loss 7.9695
2020-11-05 16:38:08,302 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1948 | Iter Mean Loss 8.0258
2020-11-05 16:38:08,307 - root - INFO - Training: Epoch 0628 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5895 | Iter Mean Loss 7.1385
2020-11-05 16:38:08,308 - root - INFO - Evaluate: Epoch 0628 | NDCG 0.0000 | MSE 0.1818
2020-11-05 16:38:08,314 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8215 | Iter Mean Loss 10.8215
2020-11-05 16:38:08,321 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5084 | Iter Mean Loss 6.1650
2020-11-05 16:38:08,326 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5464 | Iter Mean Loss 7.9588
2020-11-05 16:38:08,332 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1874 | Iter Mean Loss 8.0160
2020-11-05 16:38:08,336 - root - INFO - Training: Epoch 0629 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5874 | Iter Mean Loss 7.1303
2020-11-05 16:38:08,337 - root - INFO - Evaluate: Epoch 0629 | NDCG 0.0000 | MSE 0.1817
2020-11-05 16:38:08,343 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.8104 | Iter Mean Loss 10.8104
2020-11-05 16:38:08,348 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5060 | Iter Mean Loss 6.1582
2020-11-05 16:38:08,354 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5280 | Iter Mean Loss 7.9481
2020-11-05 16:38:08,359 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1802 | Iter Mean Loss 8.0061
2020-11-05 16:38:08,364 - root - INFO - Training: Epoch 0630 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5854 | Iter Mean Loss 7.1220
2020-11-05 16:38:08,365 - root - INFO - Evaluate: Epoch 0630 | NDCG 0.0000 | MSE 0.1816
2020-11-05 16:38:08,370 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7993 | Iter Mean Loss 10.7993
2020-11-05 16:38:08,376 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5037 | Iter Mean Loss 6.1515
2020-11-05 16:38:08,381 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.5096 | Iter Mean Loss 7.9375
2020-11-05 16:38:08,386 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1729 | Iter Mean Loss 7.9964
2020-11-05 16:38:08,391 - root - INFO - Training: Epoch 0631 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5834 | Iter Mean Loss 7.1138
2020-11-05 16:38:08,392 - root - INFO - Evaluate: Epoch 0631 | NDCG 0.0000 | MSE 0.1816
2020-11-05 16:38:08,398 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7882 | Iter Mean Loss 10.7882
2020-11-05 16:38:08,403 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.5014 | Iter Mean Loss 6.1448
2020-11-05 16:38:08,408 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4913 | Iter Mean Loss 7.9269
2020-11-05 16:38:08,414 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1657 | Iter Mean Loss 7.9866
2020-11-05 16:38:08,419 - root - INFO - Training: Epoch 0632 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5814 | Iter Mean Loss 7.1056
2020-11-05 16:38:08,421 - root - INFO - Evaluate: Epoch 0632 | NDCG 0.0000 | MSE 0.1815
2020-11-05 16:38:08,426 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7772 | Iter Mean Loss 10.7772
2020-11-05 16:38:08,432 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4991 | Iter Mean Loss 6.1381
2020-11-05 16:38:08,437 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4730 | Iter Mean Loss 7.9164
2020-11-05 16:38:08,444 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1586 | Iter Mean Loss 7.9770
2020-11-05 16:38:08,449 - root - INFO - Training: Epoch 0633 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5793 | Iter Mean Loss 7.0974
2020-11-05 16:38:08,450 - root - INFO - Evaluate: Epoch 0633 | NDCG 0.0000 | MSE 0.1815
2020-11-05 16:38:08,456 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7662 | Iter Mean Loss 10.7662
2020-11-05 16:38:08,462 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4968 | Iter Mean Loss 6.1315
2020-11-05 16:38:08,467 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4548 | Iter Mean Loss 7.9059
2020-11-05 16:38:08,473 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1514 | Iter Mean Loss 7.9673
2020-11-05 16:38:08,478 - root - INFO - Training: Epoch 0634 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5773 | Iter Mean Loss 7.0893
2020-11-05 16:38:08,479 - root - INFO - Evaluate: Epoch 0634 | NDCG 0.0000 | MSE 0.1814
2020-11-05 16:38:08,485 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7552 | Iter Mean Loss 10.7552
2020-11-05 16:38:08,491 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4945 | Iter Mean Loss 6.1248
2020-11-05 16:38:08,497 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4367 | Iter Mean Loss 7.8955
2020-11-05 16:38:08,503 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1444 | Iter Mean Loss 7.9577
2020-11-05 16:38:08,508 - root - INFO - Training: Epoch 0635 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5753 | Iter Mean Loss 7.0812
2020-11-05 16:38:08,509 - root - INFO - Evaluate: Epoch 0635 | NDCG 0.0000 | MSE 0.1813
2020-11-05 16:38:08,515 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7442 | Iter Mean Loss 10.7442
2020-11-05 16:38:08,520 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4922 | Iter Mean Loss 6.1182
2020-11-05 16:38:08,525 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4187 | Iter Mean Loss 7.8850
2020-11-05 16:38:08,531 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1373 | Iter Mean Loss 7.9481
2020-11-05 16:38:08,536 - root - INFO - Training: Epoch 0636 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5734 | Iter Mean Loss 7.0732
2020-11-05 16:38:08,536 - root - INFO - Evaluate: Epoch 0636 | NDCG 0.0000 | MSE 0.1813
2020-11-05 16:38:08,542 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7333 | Iter Mean Loss 10.7333
2020-11-05 16:38:08,547 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4899 | Iter Mean Loss 6.1116
2020-11-05 16:38:08,553 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.4007 | Iter Mean Loss 7.8747
2020-11-05 16:38:08,558 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1303 | Iter Mean Loss 7.9386
2020-11-05 16:38:08,563 - root - INFO - Training: Epoch 0637 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5714 | Iter Mean Loss 7.0651
2020-11-05 16:38:08,564 - root - INFO - Evaluate: Epoch 0637 | NDCG 0.0000 | MSE 0.1812
2020-11-05 16:38:08,569 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7224 | Iter Mean Loss 10.7224
2020-11-05 16:38:08,575 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4877 | Iter Mean Loss 6.1051
2020-11-05 16:38:08,580 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3829 | Iter Mean Loss 7.8643
2020-11-05 16:38:08,585 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1233 | Iter Mean Loss 7.9291
2020-11-05 16:38:08,590 - root - INFO - Training: Epoch 0638 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5694 | Iter Mean Loss 7.0571
2020-11-05 16:38:08,591 - root - INFO - Evaluate: Epoch 0638 | NDCG 0.0000 | MSE 0.1812
2020-11-05 16:38:08,597 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7116 | Iter Mean Loss 10.7116
2020-11-05 16:38:08,602 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4855 | Iter Mean Loss 6.0985
2020-11-05 16:38:08,608 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3650 | Iter Mean Loss 7.8540
2020-11-05 16:38:08,613 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1164 | Iter Mean Loss 7.9196
2020-11-05 16:38:08,619 - root - INFO - Training: Epoch 0639 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5675 | Iter Mean Loss 7.0492
2020-11-05 16:38:08,620 - root - INFO - Evaluate: Epoch 0639 | NDCG 0.0000 | MSE 0.1811
2020-11-05 16:38:08,625 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.7008 | Iter Mean Loss 10.7008
2020-11-05 16:38:08,631 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4832 | Iter Mean Loss 6.0920
2020-11-05 16:38:08,637 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3473 | Iter Mean Loss 7.8438
2020-11-05 16:38:08,642 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1095 | Iter Mean Loss 7.9102
2020-11-05 16:38:08,648 - root - INFO - Training: Epoch 0640 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5655 | Iter Mean Loss 7.0413
2020-11-05 16:38:08,649 - root - INFO - Evaluate: Epoch 0640 | NDCG 0.0000 | MSE 0.1811
2020-11-05 16:38:08,655 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6900 | Iter Mean Loss 10.6900
2020-11-05 16:38:08,660 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4810 | Iter Mean Loss 6.0855
2020-11-05 16:38:08,666 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3296 | Iter Mean Loss 7.8335
2020-11-05 16:38:08,672 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.1026 | Iter Mean Loss 7.9008
2020-11-05 16:38:08,677 - root - INFO - Training: Epoch 0641 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5636 | Iter Mean Loss 7.0334
2020-11-05 16:38:08,678 - root - INFO - Evaluate: Epoch 0641 | NDCG 0.0000 | MSE 0.1810
2020-11-05 16:38:08,684 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6792 | Iter Mean Loss 10.6792
2020-11-05 16:38:08,689 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4788 | Iter Mean Loss 6.0790
2020-11-05 16:38:08,695 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.3120 | Iter Mean Loss 7.8234
2020-11-05 16:38:08,700 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0958 | Iter Mean Loss 7.8915
2020-11-05 16:38:08,705 - root - INFO - Training: Epoch 0642 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5617 | Iter Mean Loss 7.0255
2020-11-05 16:38:08,707 - root - INFO - Evaluate: Epoch 0642 | NDCG 0.0000 | MSE 0.1809
2020-11-05 16:38:08,713 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6685 | Iter Mean Loss 10.6685
2020-11-05 16:38:08,718 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4767 | Iter Mean Loss 6.0726
2020-11-05 16:38:08,723 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2945 | Iter Mean Loss 7.8132
2020-11-05 16:38:08,729 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0890 | Iter Mean Loss 7.8822
2020-11-05 16:38:08,734 - root - INFO - Training: Epoch 0643 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5597 | Iter Mean Loss 7.0177
2020-11-05 16:38:08,735 - root - INFO - Evaluate: Epoch 0643 | NDCG 0.0000 | MSE 0.1809
2020-11-05 16:38:08,740 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6578 | Iter Mean Loss 10.6578
2020-11-05 16:38:08,745 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4745 | Iter Mean Loss 6.0662
2020-11-05 16:38:08,751 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2770 | Iter Mean Loss 7.8031
2020-11-05 16:38:08,756 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0823 | Iter Mean Loss 7.8729
2020-11-05 16:38:08,761 - root - INFO - Training: Epoch 0644 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5578 | Iter Mean Loss 7.0099
2020-11-05 16:38:08,762 - root - INFO - Evaluate: Epoch 0644 | NDCG 0.0000 | MSE 0.1808
2020-11-05 16:38:08,767 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6472 | Iter Mean Loss 10.6472
2020-11-05 16:38:08,772 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4723 | Iter Mean Loss 6.0598
2020-11-05 16:38:08,778 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2596 | Iter Mean Loss 7.7930
2020-11-05 16:38:08,783 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0756 | Iter Mean Loss 7.8637
2020-11-05 16:38:08,788 - root - INFO - Training: Epoch 0645 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5559 | Iter Mean Loss 7.0021
2020-11-05 16:38:08,789 - root - INFO - Evaluate: Epoch 0645 | NDCG 0.0000 | MSE 0.1808
2020-11-05 16:38:08,794 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6366 | Iter Mean Loss 10.6366
2020-11-05 16:38:08,800 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4702 | Iter Mean Loss 6.0534
2020-11-05 16:38:08,806 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2422 | Iter Mean Loss 7.7830
2020-11-05 16:38:08,811 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0689 | Iter Mean Loss 7.8545
2020-11-05 16:38:08,816 - root - INFO - Training: Epoch 0646 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5540 | Iter Mean Loss 6.9944
2020-11-05 16:38:08,817 - root - INFO - Evaluate: Epoch 0646 | NDCG 0.0000 | MSE 0.1807
2020-11-05 16:38:08,823 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6260 | Iter Mean Loss 10.6260
2020-11-05 16:38:08,829 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4681 | Iter Mean Loss 6.0470
2020-11-05 16:38:08,835 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2250 | Iter Mean Loss 7.7730
2020-11-05 16:38:08,841 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0622 | Iter Mean Loss 7.8453
2020-11-05 16:38:08,846 - root - INFO - Training: Epoch 0647 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5522 | Iter Mean Loss 6.9867
2020-11-05 16:38:08,847 - root - INFO - Evaluate: Epoch 0647 | NDCG 1.0000 | MSE 0.1807
2020-11-05 16:38:08,853 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6154 | Iter Mean Loss 10.6154
2020-11-05 16:38:08,859 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4660 | Iter Mean Loss 6.0407
2020-11-05 16:38:08,864 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.2078 | Iter Mean Loss 7.7630
2020-11-05 16:38:08,870 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0556 | Iter Mean Loss 7.8362
2020-11-05 16:38:08,876 - root - INFO - Training: Epoch 0648 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5503 | Iter Mean Loss 6.9790
2020-11-05 16:38:08,877 - root - INFO - Evaluate: Epoch 0648 | NDCG 1.0000 | MSE 0.1806
2020-11-05 16:38:08,882 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.6049 | Iter Mean Loss 10.6049
2020-11-05 16:38:08,888 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4639 | Iter Mean Loss 6.0344
2020-11-05 16:38:08,894 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1907 | Iter Mean Loss 7.7531
2020-11-05 16:38:08,900 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0491 | Iter Mean Loss 7.8271
2020-11-05 16:38:08,905 - root - INFO - Training: Epoch 0649 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5484 | Iter Mean Loss 6.9714
2020-11-05 16:38:08,906 - root - INFO - Evaluate: Epoch 0649 | NDCG 1.0000 | MSE 0.1806
2020-11-05 16:38:08,912 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5944 | Iter Mean Loss 10.5944
2020-11-05 16:38:08,917 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4618 | Iter Mean Loss 6.0281
2020-11-05 16:38:08,923 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1736 | Iter Mean Loss 7.7432
2020-11-05 16:38:08,928 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0425 | Iter Mean Loss 7.8181
2020-11-05 16:38:08,933 - root - INFO - Training: Epoch 0650 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5466 | Iter Mean Loss 6.9638
2020-11-05 16:38:08,934 - root - INFO - Evaluate: Epoch 0650 | NDCG 1.0000 | MSE 0.1805
2020-11-05 16:38:08,939 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5839 | Iter Mean Loss 10.5839
2020-11-05 16:38:08,945 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4597 | Iter Mean Loss 6.0218
2020-11-05 16:38:08,950 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1566 | Iter Mean Loss 7.7334
2020-11-05 16:38:08,955 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0360 | Iter Mean Loss 7.8091
2020-11-05 16:38:08,960 - root - INFO - Training: Epoch 0651 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5448 | Iter Mean Loss 6.9562
2020-11-05 16:38:08,961 - root - INFO - Evaluate: Epoch 0651 | NDCG 1.0000 | MSE 0.1804
2020-11-05 16:38:08,967 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5734 | Iter Mean Loss 10.5734
2020-11-05 16:38:08,972 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4576 | Iter Mean Loss 6.0155
2020-11-05 16:38:08,977 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1397 | Iter Mean Loss 7.7236
2020-11-05 16:38:08,983 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0295 | Iter Mean Loss 7.8001
2020-11-05 16:38:08,987 - root - INFO - Training: Epoch 0652 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5429 | Iter Mean Loss 6.9486
2020-11-05 16:38:08,988 - root - INFO - Evaluate: Epoch 0652 | NDCG 1.0000 | MSE 0.1804
2020-11-05 16:38:08,994 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5630 | Iter Mean Loss 10.5630
2020-11-05 16:38:08,999 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4556 | Iter Mean Loss 6.0093
2020-11-05 16:38:09,005 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1228 | Iter Mean Loss 7.7138
2020-11-05 16:38:09,010 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0231 | Iter Mean Loss 7.7911
2020-11-05 16:38:09,015 - root - INFO - Training: Epoch 0653 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5411 | Iter Mean Loss 6.9411
2020-11-05 16:38:09,016 - root - INFO - Evaluate: Epoch 0653 | NDCG 1.0000 | MSE 0.1803
2020-11-05 16:38:09,022 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5526 | Iter Mean Loss 10.5526
2020-11-05 16:38:09,028 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4536 | Iter Mean Loss 6.0031
2020-11-05 16:38:09,033 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.1060 | Iter Mean Loss 7.7041
2020-11-05 16:38:09,039 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0167 | Iter Mean Loss 7.7822
2020-11-05 16:38:09,044 - root - INFO - Training: Epoch 0654 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5393 | Iter Mean Loss 6.9336
2020-11-05 16:38:09,045 - root - INFO - Evaluate: Epoch 0654 | NDCG 1.0000 | MSE 0.1803
2020-11-05 16:38:09,051 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5423 | Iter Mean Loss 10.5423
2020-11-05 16:38:09,057 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4515 | Iter Mean Loss 5.9969
2020-11-05 16:38:09,063 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0893 | Iter Mean Loss 7.6944
2020-11-05 16:38:09,068 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0103 | Iter Mean Loss 7.7734
2020-11-05 16:38:09,073 - root - INFO - Training: Epoch 0655 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5375 | Iter Mean Loss 6.9262
2020-11-05 16:38:09,074 - root - INFO - Evaluate: Epoch 0655 | NDCG 1.0000 | MSE 0.1802
2020-11-05 16:38:09,081 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5320 | Iter Mean Loss 10.5320
2020-11-05 16:38:09,086 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4495 | Iter Mean Loss 5.9907
2020-11-05 16:38:09,092 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0726 | Iter Mean Loss 7.6847
2020-11-05 16:38:09,098 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 8.0040 | Iter Mean Loss 7.7645
2020-11-05 16:38:09,103 - root - INFO - Training: Epoch 0656 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5357 | Iter Mean Loss 6.9188
2020-11-05 16:38:09,104 - root - INFO - Evaluate: Epoch 0656 | NDCG 1.0000 | MSE 0.1802
2020-11-05 16:38:09,110 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5217 | Iter Mean Loss 10.5217
2020-11-05 16:38:09,117 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4475 | Iter Mean Loss 5.9846
2020-11-05 16:38:09,122 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0560 | Iter Mean Loss 7.6751
2020-11-05 16:38:09,127 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9977 | Iter Mean Loss 7.7557
2020-11-05 16:38:09,132 - root - INFO - Training: Epoch 0657 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5339 | Iter Mean Loss 6.9114
2020-11-05 16:38:09,133 - root - INFO - Evaluate: Epoch 0657 | NDCG 1.0000 | MSE 0.1801
2020-11-05 16:38:09,139 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5114 | Iter Mean Loss 10.5114
2020-11-05 16:38:09,144 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4455 | Iter Mean Loss 5.9785
2020-11-05 16:38:09,150 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0395 | Iter Mean Loss 7.6655
2020-11-05 16:38:09,156 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9914 | Iter Mean Loss 7.7470
2020-11-05 16:38:09,161 - root - INFO - Training: Epoch 0658 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5322 | Iter Mean Loss 6.9040
2020-11-05 16:38:09,162 - root - INFO - Evaluate: Epoch 0658 | NDCG 1.0000 | MSE 0.1801
2020-11-05 16:38:09,167 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.5012 | Iter Mean Loss 10.5012
2020-11-05 16:38:09,176 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4436 | Iter Mean Loss 5.9724
2020-11-05 16:38:09,186 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0231 | Iter Mean Loss 7.6559
2020-11-05 16:38:09,193 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9852 | Iter Mean Loss 7.7382
2020-11-05 16:38:09,199 - root - INFO - Training: Epoch 0659 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5304 | Iter Mean Loss 6.8967
2020-11-05 16:38:09,201 - root - INFO - Evaluate: Epoch 0659 | NDCG 1.0000 | MSE 0.1800
2020-11-05 16:38:09,208 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4909 | Iter Mean Loss 10.4909
2020-11-05 16:38:09,215 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4416 | Iter Mean Loss 5.9663
2020-11-05 16:38:09,222 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 11.0067 | Iter Mean Loss 7.6464
2020-11-05 16:38:09,230 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9790 | Iter Mean Loss 7.7295
2020-11-05 16:38:09,237 - root - INFO - Training: Epoch 0660 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5287 | Iter Mean Loss 6.8894
2020-11-05 16:38:09,238 - root - INFO - Evaluate: Epoch 0660 | NDCG 1.0000 | MSE 0.1800
2020-11-05 16:38:09,246 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4808 | Iter Mean Loss 10.4808
2020-11-05 16:38:09,254 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4397 | Iter Mean Loss 5.9602
2020-11-05 16:38:09,262 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9903 | Iter Mean Loss 7.6369
2020-11-05 16:38:09,270 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9728 | Iter Mean Loss 7.7209
2020-11-05 16:38:09,277 - root - INFO - Training: Epoch 0661 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5269 | Iter Mean Loss 6.8821
2020-11-05 16:38:09,278 - root - INFO - Evaluate: Epoch 0661 | NDCG 1.0000 | MSE 0.1799
2020-11-05 16:38:09,287 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4706 | Iter Mean Loss 10.4706
2020-11-05 16:38:09,295 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4377 | Iter Mean Loss 5.9542
2020-11-05 16:38:09,302 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9741 | Iter Mean Loss 7.6275
2020-11-05 16:38:09,309 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9666 | Iter Mean Loss 7.7123
2020-11-05 16:38:09,315 - root - INFO - Training: Epoch 0662 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5252 | Iter Mean Loss 6.8748
2020-11-05 16:38:09,317 - root - INFO - Evaluate: Epoch 0662 | NDCG 1.0000 | MSE 0.1799
2020-11-05 16:38:09,324 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4605 | Iter Mean Loss 10.4605
2020-11-05 16:38:09,330 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4358 | Iter Mean Loss 5.9481
2020-11-05 16:38:09,336 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9578 | Iter Mean Loss 7.6180
2020-11-05 16:38:09,342 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9605 | Iter Mean Loss 7.7037
2020-11-05 16:38:09,347 - root - INFO - Training: Epoch 0663 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5235 | Iter Mean Loss 6.8676
2020-11-05 16:38:09,348 - root - INFO - Evaluate: Epoch 0663 | NDCG 1.0000 | MSE 0.1798
2020-11-05 16:38:09,355 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4504 | Iter Mean Loss 10.4504
2020-11-05 16:38:09,362 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4339 | Iter Mean Loss 5.9421
2020-11-05 16:38:09,369 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9417 | Iter Mean Loss 7.6087
2020-11-05 16:38:09,376 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9544 | Iter Mean Loss 7.6951
2020-11-05 16:38:09,381 - root - INFO - Training: Epoch 0664 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5218 | Iter Mean Loss 6.8604
2020-11-05 16:38:09,382 - root - INFO - Evaluate: Epoch 0664 | NDCG 1.0000 | MSE 0.1797
2020-11-05 16:38:09,387 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4403 | Iter Mean Loss 10.4403
2020-11-05 16:38:09,392 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4320 | Iter Mean Loss 5.9361
2020-11-05 16:38:09,398 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9256 | Iter Mean Loss 7.5993
2020-11-05 16:38:09,403 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9483 | Iter Mean Loss 7.6866
2020-11-05 16:38:09,408 - root - INFO - Training: Epoch 0665 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5201 | Iter Mean Loss 6.8533
2020-11-05 16:38:09,409 - root - INFO - Evaluate: Epoch 0665 | NDCG 1.0000 | MSE 0.1797
2020-11-05 16:38:09,414 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4303 | Iter Mean Loss 10.4303
2020-11-05 16:38:09,420 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4301 | Iter Mean Loss 5.9302
2020-11-05 16:38:09,425 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.9096 | Iter Mean Loss 7.5900
2020-11-05 16:38:09,431 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9423 | Iter Mean Loss 7.6781
2020-11-05 16:38:09,436 - root - INFO - Training: Epoch 0666 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5184 | Iter Mean Loss 6.8461
2020-11-05 16:38:09,438 - root - INFO - Evaluate: Epoch 0666 | NDCG 1.0000 | MSE 0.1796
2020-11-05 16:38:09,443 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4202 | Iter Mean Loss 10.4202
2020-11-05 16:38:09,449 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4282 | Iter Mean Loss 5.9242
2020-11-05 16:38:09,455 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8936 | Iter Mean Loss 7.5807
2020-11-05 16:38:09,461 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9363 | Iter Mean Loss 7.6696
2020-11-05 16:38:09,466 - root - INFO - Training: Epoch 0667 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5167 | Iter Mean Loss 6.8390
2020-11-05 16:38:09,468 - root - INFO - Evaluate: Epoch 0667 | NDCG 1.0000 | MSE 0.1796
2020-11-05 16:38:09,474 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4103 | Iter Mean Loss 10.4103
2020-11-05 16:38:09,480 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4263 | Iter Mean Loss 5.9183
2020-11-05 16:38:09,486 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8777 | Iter Mean Loss 7.5714
2020-11-05 16:38:09,492 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9303 | Iter Mean Loss 7.6612
2020-11-05 16:38:09,498 - root - INFO - Training: Epoch 0668 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5150 | Iter Mean Loss 6.8319
2020-11-05 16:38:09,499 - root - INFO - Evaluate: Epoch 0668 | NDCG 1.0000 | MSE 0.1795
2020-11-05 16:38:09,506 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.4003 | Iter Mean Loss 10.4003
2020-11-05 16:38:09,511 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4245 | Iter Mean Loss 5.9124
2020-11-05 16:38:09,517 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8619 | Iter Mean Loss 7.5622
2020-11-05 16:38:09,523 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9244 | Iter Mean Loss 7.6528
2020-11-05 16:38:09,529 - root - INFO - Training: Epoch 0669 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5134 | Iter Mean Loss 6.8249
2020-11-05 16:38:09,530 - root - INFO - Evaluate: Epoch 0669 | NDCG 1.0000 | MSE 0.1795
2020-11-05 16:38:09,536 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3903 | Iter Mean Loss 10.3903
2020-11-05 16:38:09,542 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4227 | Iter Mean Loss 5.9065
2020-11-05 16:38:09,547 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8461 | Iter Mean Loss 7.5530
2020-11-05 16:38:09,552 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9185 | Iter Mean Loss 7.6444
2020-11-05 16:38:09,557 - root - INFO - Training: Epoch 0670 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5117 | Iter Mean Loss 6.8179
2020-11-05 16:38:09,558 - root - INFO - Evaluate: Epoch 0670 | NDCG 1.0000 | MSE 0.1794
2020-11-05 16:38:09,564 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3804 | Iter Mean Loss 10.3804
2020-11-05 16:38:09,569 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4208 | Iter Mean Loss 5.9006
2020-11-05 16:38:09,575 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8304 | Iter Mean Loss 7.5439
2020-11-05 16:38:09,580 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9126 | Iter Mean Loss 7.6361
2020-11-05 16:38:09,585 - root - INFO - Training: Epoch 0671 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5101 | Iter Mean Loss 6.8109
2020-11-05 16:38:09,586 - root - INFO - Evaluate: Epoch 0671 | NDCG 1.0000 | MSE 0.1794
2020-11-05 16:38:09,591 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3705 | Iter Mean Loss 10.3705
2020-11-05 16:38:09,597 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4190 | Iter Mean Loss 5.8948
2020-11-05 16:38:09,602 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.8148 | Iter Mean Loss 7.5348
2020-11-05 16:38:09,608 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9067 | Iter Mean Loss 7.6278
2020-11-05 16:38:09,613 - root - INFO - Training: Epoch 0672 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5084 | Iter Mean Loss 6.8039
2020-11-05 16:38:09,613 - root - INFO - Evaluate: Epoch 0672 | NDCG 1.0000 | MSE 0.1793
2020-11-05 16:38:09,619 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3607 | Iter Mean Loss 10.3607
2020-11-05 16:38:09,624 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4172 | Iter Mean Loss 5.8889
2020-11-05 16:38:09,630 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7992 | Iter Mean Loss 7.5257
2020-11-05 16:38:09,636 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.9009 | Iter Mean Loss 7.6195
2020-11-05 16:38:09,641 - root - INFO - Training: Epoch 0673 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5068 | Iter Mean Loss 6.7969
2020-11-05 16:38:09,642 - root - INFO - Evaluate: Epoch 0673 | NDCG 1.0000 | MSE 0.1793
2020-11-05 16:38:09,648 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3508 | Iter Mean Loss 10.3508
2020-11-05 16:38:09,653 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4154 | Iter Mean Loss 5.8831
2020-11-05 16:38:09,659 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7836 | Iter Mean Loss 7.5166
2020-11-05 16:38:09,665 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8950 | Iter Mean Loss 7.6112
2020-11-05 16:38:09,670 - root - INFO - Training: Epoch 0674 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5052 | Iter Mean Loss 6.7900
2020-11-05 16:38:09,671 - root - INFO - Evaluate: Epoch 0674 | NDCG 1.0000 | MSE 0.1792
2020-11-05 16:38:09,677 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3410 | Iter Mean Loss 10.3410
2020-11-05 16:38:09,683 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4136 | Iter Mean Loss 5.8773
2020-11-05 16:38:09,689 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7681 | Iter Mean Loss 7.5076
2020-11-05 16:38:09,695 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8893 | Iter Mean Loss 7.6030
2020-11-05 16:38:09,701 - root - INFO - Training: Epoch 0675 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5036 | Iter Mean Loss 6.7831
2020-11-05 16:38:09,702 - root - INFO - Evaluate: Epoch 0675 | NDCG 1.0000 | MSE 0.1792
2020-11-05 16:38:09,707 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3312 | Iter Mean Loss 10.3312
2020-11-05 16:38:09,713 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4118 | Iter Mean Loss 5.8715
2020-11-05 16:38:09,719 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7527 | Iter Mean Loss 7.4986
2020-11-05 16:38:09,725 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8835 | Iter Mean Loss 7.5948
2020-11-05 16:38:09,731 - root - INFO - Training: Epoch 0676 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5020 | Iter Mean Loss 6.7763
2020-11-05 16:38:09,732 - root - INFO - Evaluate: Epoch 0676 | NDCG 1.0000 | MSE 0.1791
2020-11-05 16:38:09,737 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3215 | Iter Mean Loss 10.3215
2020-11-05 16:38:09,743 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4100 | Iter Mean Loss 5.8658
2020-11-05 16:38:09,748 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7374 | Iter Mean Loss 7.4896
2020-11-05 16:38:09,753 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8778 | Iter Mean Loss 7.5867
2020-11-05 16:38:09,758 - root - INFO - Training: Epoch 0677 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.5004 | Iter Mean Loss 6.7694
2020-11-05 16:38:09,759 - root - INFO - Evaluate: Epoch 0677 | NDCG 1.0000 | MSE 0.1791
2020-11-05 16:38:09,764 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3117 | Iter Mean Loss 10.3117
2020-11-05 16:38:09,770 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4083 | Iter Mean Loss 5.8600
2020-11-05 16:38:09,775 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7221 | Iter Mean Loss 7.4807
2020-11-05 16:38:09,780 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8720 | Iter Mean Loss 7.5785
2020-11-05 16:38:09,785 - root - INFO - Training: Epoch 0678 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4988 | Iter Mean Loss 6.7626
2020-11-05 16:38:09,786 - root - INFO - Evaluate: Epoch 0678 | NDCG 1.0000 | MSE 0.1790
2020-11-05 16:38:09,791 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.3020 | Iter Mean Loss 10.3020
2020-11-05 16:38:09,797 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4065 | Iter Mean Loss 5.8543
2020-11-05 16:38:09,802 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.7068 | Iter Mean Loss 7.4718
2020-11-05 16:38:09,808 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8664 | Iter Mean Loss 7.5704
2020-11-05 16:38:09,812 - root - INFO - Training: Epoch 0679 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4973 | Iter Mean Loss 6.7558
2020-11-05 16:38:09,813 - root - INFO - Evaluate: Epoch 0679 | NDCG 1.0000 | MSE 0.1790
2020-11-05 16:38:09,819 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2923 | Iter Mean Loss 10.2923
2020-11-05 16:38:09,824 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4048 | Iter Mean Loss 5.8486
2020-11-05 16:38:09,829 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6916 | Iter Mean Loss 7.4629
2020-11-05 16:38:09,835 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8607 | Iter Mean Loss 7.5624
2020-11-05 16:38:09,840 - root - INFO - Training: Epoch 0680 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4957 | Iter Mean Loss 6.7490
2020-11-05 16:38:09,841 - root - INFO - Evaluate: Epoch 0680 | NDCG 1.0000 | MSE 0.1789
2020-11-05 16:38:09,847 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2827 | Iter Mean Loss 10.2827
2020-11-05 16:38:09,852 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4031 | Iter Mean Loss 5.8429
2020-11-05 16:38:09,858 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6765 | Iter Mean Loss 7.4541
2020-11-05 16:38:09,864 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8550 | Iter Mean Loss 7.5543
2020-11-05 16:38:09,869 - root - INFO - Training: Epoch 0681 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4941 | Iter Mean Loss 6.7423
2020-11-05 16:38:09,870 - root - INFO - Evaluate: Epoch 0681 | NDCG 1.0000 | MSE 0.1789
2020-11-05 16:38:09,876 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2730 | Iter Mean Loss 10.2730
2020-11-05 16:38:09,882 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.4013 | Iter Mean Loss 5.8372
2020-11-05 16:38:09,888 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6614 | Iter Mean Loss 7.4453
2020-11-05 16:38:09,894 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8494 | Iter Mean Loss 7.5463
2020-11-05 16:38:09,899 - root - INFO - Training: Epoch 0682 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4926 | Iter Mean Loss 6.7356
2020-11-05 16:38:09,900 - root - INFO - Evaluate: Epoch 0682 | NDCG 1.0000 | MSE 0.1788
2020-11-05 16:38:09,906 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2634 | Iter Mean Loss 10.2634
2020-11-05 16:38:09,912 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3996 | Iter Mean Loss 5.8315
2020-11-05 16:38:09,918 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6464 | Iter Mean Loss 7.4365
2020-11-05 16:38:09,924 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8438 | Iter Mean Loss 7.5383
2020-11-05 16:38:09,929 - root - INFO - Training: Epoch 0683 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4911 | Iter Mean Loss 6.7289
2020-11-05 16:38:09,931 - root - INFO - Evaluate: Epoch 0683 | NDCG 1.0000 | MSE 0.1788
2020-11-05 16:38:09,936 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2538 | Iter Mean Loss 10.2538
2020-11-05 16:38:09,942 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3979 | Iter Mean Loss 5.8259
2020-11-05 16:38:09,947 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6314 | Iter Mean Loss 7.4277
2020-11-05 16:38:09,953 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8383 | Iter Mean Loss 7.5303
2020-11-05 16:38:09,957 - root - INFO - Training: Epoch 0684 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4895 | Iter Mean Loss 6.7222
2020-11-05 16:38:09,958 - root - INFO - Evaluate: Epoch 0684 | NDCG 1.0000 | MSE 0.1787
2020-11-05 16:38:09,964 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2442 | Iter Mean Loss 10.2442
2020-11-05 16:38:09,969 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3962 | Iter Mean Loss 5.8202
2020-11-05 16:38:09,974 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6165 | Iter Mean Loss 7.4190
2020-11-05 16:38:09,980 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8327 | Iter Mean Loss 7.5224
2020-11-05 16:38:09,984 - root - INFO - Training: Epoch 0685 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4880 | Iter Mean Loss 6.7155
2020-11-05 16:38:09,985 - root - INFO - Evaluate: Epoch 0685 | NDCG 1.0000 | MSE 0.1787
2020-11-05 16:38:09,991 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2347 | Iter Mean Loss 10.2347
2020-11-05 16:38:09,996 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3946 | Iter Mean Loss 5.8146
2020-11-05 16:38:10,001 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.6016 | Iter Mean Loss 7.4103
2020-11-05 16:38:10,007 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8272 | Iter Mean Loss 7.5145
2020-11-05 16:38:10,011 - root - INFO - Training: Epoch 0686 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4865 | Iter Mean Loss 6.7089
2020-11-05 16:38:10,012 - root - INFO - Evaluate: Epoch 0686 | NDCG 1.0000 | MSE 0.1786
2020-11-05 16:38:10,018 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2252 | Iter Mean Loss 10.2252
2020-11-05 16:38:10,023 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3929 | Iter Mean Loss 5.8090
2020-11-05 16:38:10,028 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5868 | Iter Mean Loss 7.4016
2020-11-05 16:38:10,034 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8217 | Iter Mean Loss 7.5066
2020-11-05 16:38:10,039 - root - INFO - Training: Epoch 0687 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4850 | Iter Mean Loss 6.7023
2020-11-05 16:38:10,040 - root - INFO - Evaluate: Epoch 0687 | NDCG 1.0000 | MSE 0.1786
2020-11-05 16:38:10,045 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2157 | Iter Mean Loss 10.2157
2020-11-05 16:38:10,052 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3912 | Iter Mean Loss 5.8034
2020-11-05 16:38:10,057 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5720 | Iter Mean Loss 7.3930
2020-11-05 16:38:10,063 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8162 | Iter Mean Loss 7.4988
2020-11-05 16:38:10,068 - root - INFO - Training: Epoch 0688 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4835 | Iter Mean Loss 6.6957
2020-11-05 16:38:10,069 - root - INFO - Evaluate: Epoch 0688 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:38:10,075 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.2062 | Iter Mean Loss 10.2062
2020-11-05 16:38:10,081 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3895 | Iter Mean Loss 5.7979
2020-11-05 16:38:10,087 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5573 | Iter Mean Loss 7.3843
2020-11-05 16:38:10,093 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8107 | Iter Mean Loss 7.4909
2020-11-05 16:38:10,098 - root - INFO - Training: Epoch 0689 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4820 | Iter Mean Loss 6.6892
2020-11-05 16:38:10,099 - root - INFO - Evaluate: Epoch 0689 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:38:10,105 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1967 | Iter Mean Loss 10.1967
2020-11-05 16:38:10,111 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3879 | Iter Mean Loss 5.7923
2020-11-05 16:38:10,117 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5427 | Iter Mean Loss 7.3758
2020-11-05 16:38:10,123 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.8053 | Iter Mean Loss 7.4831
2020-11-05 16:38:10,128 - root - INFO - Training: Epoch 0690 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4805 | Iter Mean Loss 6.6826
2020-11-05 16:38:10,129 - root - INFO - Evaluate: Epoch 0690 | NDCG 1.0000 | MSE 0.1785
2020-11-05 16:38:10,135 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1873 | Iter Mean Loss 10.1873
2020-11-05 16:38:10,141 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3863 | Iter Mean Loss 5.7868
2020-11-05 16:38:10,146 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5281 | Iter Mean Loss 7.3672
2020-11-05 16:38:10,152 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7998 | Iter Mean Loss 7.4754
2020-11-05 16:38:10,157 - root - INFO - Training: Epoch 0691 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4790 | Iter Mean Loss 6.6761
2020-11-05 16:38:10,158 - root - INFO - Evaluate: Epoch 0691 | NDCG 1.0000 | MSE 0.1784
2020-11-05 16:38:10,164 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1778 | Iter Mean Loss 10.1778
2020-11-05 16:38:10,169 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3846 | Iter Mean Loss 5.7812
2020-11-05 16:38:10,175 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.5135 | Iter Mean Loss 7.3587
2020-11-05 16:38:10,180 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7944 | Iter Mean Loss 7.4676
2020-11-05 16:38:10,185 - root - INFO - Training: Epoch 0692 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4776 | Iter Mean Loss 6.6696
2020-11-05 16:38:10,185 - root - INFO - Evaluate: Epoch 0692 | NDCG 1.0000 | MSE 0.1784
2020-11-05 16:38:10,191 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1684 | Iter Mean Loss 10.1684
2020-11-05 16:38:10,196 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3830 | Iter Mean Loss 5.7757
2020-11-05 16:38:10,202 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4990 | Iter Mean Loss 7.3501
2020-11-05 16:38:10,207 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7891 | Iter Mean Loss 7.4599
2020-11-05 16:38:10,212 - root - INFO - Training: Epoch 0693 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4761 | Iter Mean Loss 6.6631
2020-11-05 16:38:10,212 - root - INFO - Evaluate: Epoch 0693 | NDCG 1.0000 | MSE 0.1783
2020-11-05 16:38:10,218 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1591 | Iter Mean Loss 10.1591
2020-11-05 16:38:10,223 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3814 | Iter Mean Loss 5.7702
2020-11-05 16:38:10,228 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4846 | Iter Mean Loss 7.3417
2020-11-05 16:38:10,234 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7837 | Iter Mean Loss 7.4522
2020-11-05 16:38:10,239 - root - INFO - Training: Epoch 0694 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4747 | Iter Mean Loss 6.6567
2020-11-05 16:38:10,239 - root - INFO - Evaluate: Epoch 0694 | NDCG 1.0000 | MSE 0.1783
2020-11-05 16:38:10,245 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1497 | Iter Mean Loss 10.1497
2020-11-05 16:38:10,251 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3798 | Iter Mean Loss 5.7647
2020-11-05 16:38:10,257 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4702 | Iter Mean Loss 7.3332
2020-11-05 16:38:10,263 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7783 | Iter Mean Loss 7.4445
2020-11-05 16:38:10,268 - root - INFO - Training: Epoch 0695 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4732 | Iter Mean Loss 6.6502
2020-11-05 16:38:10,270 - root - INFO - Evaluate: Epoch 0695 | NDCG 1.0000 | MSE 0.1782
2020-11-05 16:38:10,276 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1404 | Iter Mean Loss 10.1404
2020-11-05 16:38:10,281 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3781 | Iter Mean Loss 5.7593
2020-11-05 16:38:10,288 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4558 | Iter Mean Loss 7.3248
2020-11-05 16:38:10,293 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7730 | Iter Mean Loss 7.4368
2020-11-05 16:38:10,299 - root - INFO - Training: Epoch 0696 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4718 | Iter Mean Loss 6.6438
2020-11-05 16:38:10,300 - root - INFO - Evaluate: Epoch 0696 | NDCG 1.0000 | MSE 0.1782
2020-11-05 16:38:10,306 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1311 | Iter Mean Loss 10.1311
2020-11-05 16:38:10,312 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3765 | Iter Mean Loss 5.7538
2020-11-05 16:38:10,318 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4415 | Iter Mean Loss 7.3164
2020-11-05 16:38:10,325 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7677 | Iter Mean Loss 7.4292
2020-11-05 16:38:10,329 - root - INFO - Training: Epoch 0697 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4703 | Iter Mean Loss 6.6374
2020-11-05 16:38:10,330 - root - INFO - Evaluate: Epoch 0697 | NDCG 1.0000 | MSE 0.1781
2020-11-05 16:38:10,336 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1218 | Iter Mean Loss 10.1218
2020-11-05 16:38:10,341 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3750 | Iter Mean Loss 5.7484
2020-11-05 16:38:10,348 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4272 | Iter Mean Loss 7.3080
2020-11-05 16:38:10,353 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7624 | Iter Mean Loss 7.4216
2020-11-05 16:38:10,358 - root - INFO - Training: Epoch 0698 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4689 | Iter Mean Loss 6.6311
2020-11-05 16:38:10,359 - root - INFO - Evaluate: Epoch 0698 | NDCG 1.0000 | MSE 0.1781
2020-11-05 16:38:10,364 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1125 | Iter Mean Loss 10.1125
2020-11-05 16:38:10,370 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3734 | Iter Mean Loss 5.7429
2020-11-05 16:38:10,375 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.4130 | Iter Mean Loss 7.2996
2020-11-05 16:38:10,380 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7571 | Iter Mean Loss 7.4140
2020-11-05 16:38:10,385 - root - INFO - Training: Epoch 0699 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4675 | Iter Mean Loss 6.6247
2020-11-05 16:38:10,386 - root - INFO - Evaluate: Epoch 0699 | NDCG 1.0000 | MSE 0.1780
2020-11-05 16:38:10,391 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.1032 | Iter Mean Loss 10.1032
2020-11-05 16:38:10,397 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3718 | Iter Mean Loss 5.7375
2020-11-05 16:38:10,402 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3989 | Iter Mean Loss 7.2913
2020-11-05 16:38:10,408 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7519 | Iter Mean Loss 7.4064
2020-11-05 16:38:10,412 - root - INFO - Training: Epoch 0700 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4661 | Iter Mean Loss 6.6184
2020-11-05 16:38:10,413 - root - INFO - Evaluate: Epoch 0700 | NDCG 1.0000 | MSE 0.1780
2020-11-05 16:38:10,421 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0940 | Iter Mean Loss 10.0940
2020-11-05 16:38:10,428 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3702 | Iter Mean Loss 5.7321
2020-11-05 16:38:10,434 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3848 | Iter Mean Loss 7.2830
2020-11-05 16:38:10,441 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7466 | Iter Mean Loss 7.3989
2020-11-05 16:38:10,446 - root - INFO - Training: Epoch 0701 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4647 | Iter Mean Loss 6.6120
2020-11-05 16:38:10,447 - root - INFO - Evaluate: Epoch 0701 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:38:10,454 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0848 | Iter Mean Loss 10.0848
2020-11-05 16:38:10,460 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3686 | Iter Mean Loss 5.7267
2020-11-05 16:38:10,466 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3707 | Iter Mean Loss 7.2747
2020-11-05 16:38:10,473 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7414 | Iter Mean Loss 7.3914
2020-11-05 16:38:10,480 - root - INFO - Training: Epoch 0702 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4633 | Iter Mean Loss 6.6057
2020-11-05 16:38:10,481 - root - INFO - Evaluate: Epoch 0702 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:38:10,488 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0756 | Iter Mean Loss 10.0756
2020-11-05 16:38:10,495 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3671 | Iter Mean Loss 5.7213
2020-11-05 16:38:10,503 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3567 | Iter Mean Loss 7.2664
2020-11-05 16:38:10,510 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7362 | Iter Mean Loss 7.3839
2020-11-05 16:38:10,517 - root - INFO - Training: Epoch 0703 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4619 | Iter Mean Loss 6.5995
2020-11-05 16:38:10,519 - root - INFO - Evaluate: Epoch 0703 | NDCG 1.0000 | MSE 0.1779
2020-11-05 16:38:10,527 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0664 | Iter Mean Loss 10.0664
2020-11-05 16:38:10,535 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3655 | Iter Mean Loss 5.7160
2020-11-05 16:38:10,544 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3427 | Iter Mean Loss 7.2582
2020-11-05 16:38:10,553 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7310 | Iter Mean Loss 7.3764
2020-11-05 16:38:10,560 - root - INFO - Training: Epoch 0704 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4605 | Iter Mean Loss 6.5932
2020-11-05 16:38:10,561 - root - INFO - Evaluate: Epoch 0704 | NDCG 1.0000 | MSE 0.1778
2020-11-05 16:38:10,570 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0572 | Iter Mean Loss 10.0572
2020-11-05 16:38:10,578 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3640 | Iter Mean Loss 5.7106
2020-11-05 16:38:10,585 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3288 | Iter Mean Loss 7.2500
2020-11-05 16:38:10,592 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7258 | Iter Mean Loss 7.3689
2020-11-05 16:38:10,598 - root - INFO - Training: Epoch 0705 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4591 | Iter Mean Loss 6.5870
2020-11-05 16:38:10,599 - root - INFO - Evaluate: Epoch 0705 | NDCG 1.0000 | MSE 0.1778
2020-11-05 16:38:10,606 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0481 | Iter Mean Loss 10.0481
2020-11-05 16:38:10,613 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3624 | Iter Mean Loss 5.7052
2020-11-05 16:38:10,619 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3149 | Iter Mean Loss 7.2418
2020-11-05 16:38:10,625 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7206 | Iter Mean Loss 7.3615
2020-11-05 16:38:10,630 - root - INFO - Training: Epoch 0706 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4577 | Iter Mean Loss 6.5807
2020-11-05 16:38:10,631 - root - INFO - Evaluate: Epoch 0706 | NDCG 1.0000 | MSE 0.1777
2020-11-05 16:38:10,636 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0389 | Iter Mean Loss 10.0389
2020-11-05 16:38:10,642 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3609 | Iter Mean Loss 5.6999
2020-11-05 16:38:10,648 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.3010 | Iter Mean Loss 7.2336
2020-11-05 16:38:10,653 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7155 | Iter Mean Loss 7.3541
2020-11-05 16:38:10,659 - root - INFO - Training: Epoch 0707 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4563 | Iter Mean Loss 6.5745
2020-11-05 16:38:10,660 - root - INFO - Evaluate: Epoch 0707 | NDCG 1.0000 | MSE 0.1777
2020-11-05 16:38:10,666 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0298 | Iter Mean Loss 10.0298
2020-11-05 16:38:10,672 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3594 | Iter Mean Loss 5.6946
2020-11-05 16:38:10,677 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2872 | Iter Mean Loss 7.2255
2020-11-05 16:38:10,684 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7103 | Iter Mean Loss 7.3467
2020-11-05 16:38:10,688 - root - INFO - Training: Epoch 0708 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4550 | Iter Mean Loss 6.5683
2020-11-05 16:38:10,689 - root - INFO - Evaluate: Epoch 0708 | NDCG 1.0000 | MSE 0.1776
2020-11-05 16:38:10,696 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0207 | Iter Mean Loss 10.0207
2020-11-05 16:38:10,702 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3578 | Iter Mean Loss 5.6893
2020-11-05 16:38:10,707 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2735 | Iter Mean Loss 7.2173
2020-11-05 16:38:10,714 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7052 | Iter Mean Loss 7.3393
2020-11-05 16:38:10,719 - root - INFO - Training: Epoch 0709 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4536 | Iter Mean Loss 6.5622
2020-11-05 16:38:10,720 - root - INFO - Evaluate: Epoch 0709 | NDCG 1.0000 | MSE 0.1776
2020-11-05 16:38:10,725 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0117 | Iter Mean Loss 10.0117
2020-11-05 16:38:10,731 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3563 | Iter Mean Loss 5.6840
2020-11-05 16:38:10,737 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2598 | Iter Mean Loss 7.2092
2020-11-05 16:38:10,743 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.7001 | Iter Mean Loss 7.3320
2020-11-05 16:38:10,748 - root - INFO - Training: Epoch 0710 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4523 | Iter Mean Loss 6.5560
2020-11-05 16:38:10,749 - root - INFO - Evaluate: Epoch 0710 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:38:10,755 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 10.0026 | Iter Mean Loss 10.0026
2020-11-05 16:38:10,760 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3548 | Iter Mean Loss 5.6787
2020-11-05 16:38:10,766 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2461 | Iter Mean Loss 7.2012
2020-11-05 16:38:10,771 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6950 | Iter Mean Loss 7.3246
2020-11-05 16:38:10,776 - root - INFO - Training: Epoch 0711 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4509 | Iter Mean Loss 6.5499
2020-11-05 16:38:10,777 - root - INFO - Evaluate: Epoch 0711 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:38:10,782 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9936 | Iter Mean Loss 9.9936
2020-11-05 16:38:10,787 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3533 | Iter Mean Loss 5.6734
2020-11-05 16:38:10,793 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2325 | Iter Mean Loss 7.1931
2020-11-05 16:38:10,798 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6899 | Iter Mean Loss 7.3173
2020-11-05 16:38:10,803 - root - INFO - Training: Epoch 0712 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4495 | Iter Mean Loss 6.5437
2020-11-05 16:38:10,804 - root - INFO - Evaluate: Epoch 0712 | NDCG 1.0000 | MSE 0.1775
2020-11-05 16:38:10,809 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9845 | Iter Mean Loss 9.9845
2020-11-05 16:38:10,815 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3517 | Iter Mean Loss 5.6681
2020-11-05 16:38:10,820 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2189 | Iter Mean Loss 7.1851
2020-11-05 16:38:10,825 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6848 | Iter Mean Loss 7.3100
2020-11-05 16:38:10,830 - root - INFO - Training: Epoch 0713 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4482 | Iter Mean Loss 6.5376
2020-11-05 16:38:10,831 - root - INFO - Evaluate: Epoch 0713 | NDCG 1.0000 | MSE 0.1774
2020-11-05 16:38:10,836 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9755 | Iter Mean Loss 9.9755
2020-11-05 16:38:10,841 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3502 | Iter Mean Loss 5.6629
2020-11-05 16:38:10,847 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.2054 | Iter Mean Loss 7.1770
2020-11-05 16:38:10,853 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6797 | Iter Mean Loss 7.3027
2020-11-05 16:38:10,859 - root - INFO - Training: Epoch 0714 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4469 | Iter Mean Loss 6.5315
2020-11-05 16:38:10,860 - root - INFO - Evaluate: Epoch 0714 | NDCG 1.0000 | MSE 0.1774
2020-11-05 16:38:10,865 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9665 | Iter Mean Loss 9.9665
2020-11-05 16:38:10,871 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3487 | Iter Mean Loss 5.6576
2020-11-05 16:38:10,877 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1919 | Iter Mean Loss 7.1690
2020-11-05 16:38:10,883 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6747 | Iter Mean Loss 7.2955
2020-11-05 16:38:10,888 - root - INFO - Training: Epoch 0715 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4455 | Iter Mean Loss 6.5255
2020-11-05 16:38:10,889 - root - INFO - Evaluate: Epoch 0715 | NDCG 1.0000 | MSE 0.1773
2020-11-05 16:38:10,895 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9576 | Iter Mean Loss 9.9576
2020-11-05 16:38:10,901 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3472 | Iter Mean Loss 5.6524
2020-11-05 16:38:10,907 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1784 | Iter Mean Loss 7.1611
2020-11-05 16:38:10,913 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6696 | Iter Mean Loss 7.2882
2020-11-05 16:38:10,918 - root - INFO - Training: Epoch 0716 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4442 | Iter Mean Loss 6.5194
2020-11-05 16:38:10,919 - root - INFO - Evaluate: Epoch 0716 | NDCG 1.0000 | MSE 0.1773
2020-11-05 16:38:10,925 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9486 | Iter Mean Loss 9.9486
2020-11-05 16:38:10,931 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3457 | Iter Mean Loss 5.6472
2020-11-05 16:38:10,936 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1650 | Iter Mean Loss 7.1531
2020-11-05 16:38:10,942 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6646 | Iter Mean Loss 7.2810
2020-11-05 16:38:10,948 - root - INFO - Training: Epoch 0717 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4429 | Iter Mean Loss 6.5134
2020-11-05 16:38:10,949 - root - INFO - Evaluate: Epoch 0717 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:38:10,954 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9397 | Iter Mean Loss 9.9397
2020-11-05 16:38:10,960 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3442 | Iter Mean Loss 5.6419
2020-11-05 16:38:10,965 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1516 | Iter Mean Loss 7.1452
2020-11-05 16:38:10,970 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6596 | Iter Mean Loss 7.2738
2020-11-05 16:38:10,975 - root - INFO - Training: Epoch 0718 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4416 | Iter Mean Loss 6.5073
2020-11-05 16:38:10,976 - root - INFO - Evaluate: Epoch 0718 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:38:10,981 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9307 | Iter Mean Loss 9.9307
2020-11-05 16:38:10,987 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3427 | Iter Mean Loss 5.6367
2020-11-05 16:38:10,992 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1383 | Iter Mean Loss 7.1373
2020-11-05 16:38:10,997 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6546 | Iter Mean Loss 7.2666
2020-11-05 16:38:11,002 - root - INFO - Training: Epoch 0719 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4402 | Iter Mean Loss 6.5013
2020-11-05 16:38:11,003 - root - INFO - Evaluate: Epoch 0719 | NDCG 1.0000 | MSE 0.1772
2020-11-05 16:38:11,008 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9218 | Iter Mean Loss 9.9218
2020-11-05 16:38:11,014 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3413 | Iter Mean Loss 5.6315
2020-11-05 16:38:11,019 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1250 | Iter Mean Loss 7.1294
2020-11-05 16:38:11,024 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6496 | Iter Mean Loss 7.2594
2020-11-05 16:38:11,029 - root - INFO - Training: Epoch 0720 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4389 | Iter Mean Loss 6.4953
2020-11-05 16:38:11,030 - root - INFO - Evaluate: Epoch 0720 | NDCG 1.0000 | MSE 0.1771
2020-11-05 16:38:11,035 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9129 | Iter Mean Loss 9.9129
2020-11-05 16:38:11,041 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3398 | Iter Mean Loss 5.6263
2020-11-05 16:38:11,046 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.1117 | Iter Mean Loss 7.1215
2020-11-05 16:38:11,052 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6446 | Iter Mean Loss 7.2522
2020-11-05 16:38:11,057 - root - INFO - Training: Epoch 0721 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4376 | Iter Mean Loss 6.4893
2020-11-05 16:38:11,058 - root - INFO - Evaluate: Epoch 0721 | NDCG 1.0000 | MSE 0.1771
2020-11-05 16:38:11,064 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.9040 | Iter Mean Loss 9.9040
2020-11-05 16:38:11,069 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3383 | Iter Mean Loss 5.6212
2020-11-05 16:38:11,075 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0985 | Iter Mean Loss 7.1136
2020-11-05 16:38:11,081 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6396 | Iter Mean Loss 7.2451
2020-11-05 16:38:11,086 - root - INFO - Training: Epoch 0722 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4363 | Iter Mean Loss 6.4833
2020-11-05 16:38:11,087 - root - INFO - Evaluate: Epoch 0722 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:38:11,093 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8952 | Iter Mean Loss 9.8952
2020-11-05 16:38:11,099 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3368 | Iter Mean Loss 5.6160
2020-11-05 16:38:11,105 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0853 | Iter Mean Loss 7.1058
2020-11-05 16:38:11,111 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6346 | Iter Mean Loss 7.2380
2020-11-05 16:38:11,116 - root - INFO - Training: Epoch 0723 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4350 | Iter Mean Loss 6.4774
2020-11-05 16:38:11,118 - root - INFO - Evaluate: Epoch 0723 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:38:11,124 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8863 | Iter Mean Loss 9.8863
2020-11-05 16:38:11,129 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3353 | Iter Mean Loss 5.6108
2020-11-05 16:38:11,136 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0722 | Iter Mean Loss 7.0979
2020-11-05 16:38:11,141 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6296 | Iter Mean Loss 7.2309
2020-11-05 16:38:11,146 - root - INFO - Training: Epoch 0724 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4337 | Iter Mean Loss 6.4714
2020-11-05 16:38:11,148 - root - INFO - Evaluate: Epoch 0724 | NDCG 1.0000 | MSE 0.1770
2020-11-05 16:38:11,154 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8774 | Iter Mean Loss 9.8774
2020-11-05 16:38:11,159 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3339 | Iter Mean Loss 5.6057
2020-11-05 16:38:11,165 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0591 | Iter Mean Loss 7.0901
2020-11-05 16:38:11,170 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6247 | Iter Mean Loss 7.2238
2020-11-05 16:38:11,175 - root - INFO - Training: Epoch 0725 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4324 | Iter Mean Loss 6.4655
2020-11-05 16:38:11,176 - root - INFO - Evaluate: Epoch 0725 | NDCG 1.0000 | MSE 0.1769
2020-11-05 16:38:11,181 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8686 | Iter Mean Loss 9.8686
2020-11-05 16:38:11,187 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3324 | Iter Mean Loss 5.6005
2020-11-05 16:38:11,192 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0460 | Iter Mean Loss 7.0823
2020-11-05 16:38:11,197 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6197 | Iter Mean Loss 7.2167
2020-11-05 16:38:11,202 - root - INFO - Training: Epoch 0726 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4311 | Iter Mean Loss 6.4596
2020-11-05 16:38:11,203 - root - INFO - Evaluate: Epoch 0726 | NDCG 1.0000 | MSE 0.1769
2020-11-05 16:38:11,208 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8598 | Iter Mean Loss 9.8598
2020-11-05 16:38:11,214 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3309 | Iter Mean Loss 5.5954
2020-11-05 16:38:11,219 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0330 | Iter Mean Loss 7.0746
2020-11-05 16:38:11,224 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6148 | Iter Mean Loss 7.2096
2020-11-05 16:38:11,229 - root - INFO - Training: Epoch 0727 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4298 | Iter Mean Loss 6.4537
2020-11-05 16:38:11,230 - root - INFO - Evaluate: Epoch 0727 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:38:11,236 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8510 | Iter Mean Loss 9.8510
2020-11-05 16:38:11,241 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3295 | Iter Mean Loss 5.5902
2020-11-05 16:38:11,246 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0200 | Iter Mean Loss 7.0668
2020-11-05 16:38:11,252 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6099 | Iter Mean Loss 7.2026
2020-11-05 16:38:11,257 - root - INFO - Training: Epoch 0728 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4285 | Iter Mean Loss 6.4478
2020-11-05 16:38:11,258 - root - INFO - Evaluate: Epoch 0728 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:38:11,263 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8422 | Iter Mean Loss 9.8422
2020-11-05 16:38:11,269 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3280 | Iter Mean Loss 5.5851
2020-11-05 16:38:11,275 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 10.0070 | Iter Mean Loss 7.0591
2020-11-05 16:38:11,281 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6049 | Iter Mean Loss 7.1955
2020-11-05 16:38:11,286 - root - INFO - Training: Epoch 0729 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4272 | Iter Mean Loss 6.4419
2020-11-05 16:38:11,287 - root - INFO - Evaluate: Epoch 0729 | NDCG 1.0000 | MSE 0.1768
2020-11-05 16:38:11,292 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8334 | Iter Mean Loss 9.8334
2020-11-05 16:38:11,298 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3265 | Iter Mean Loss 5.5800
2020-11-05 16:38:11,304 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9941 | Iter Mean Loss 7.0514
2020-11-05 16:38:11,310 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.6000 | Iter Mean Loss 7.1885
2020-11-05 16:38:11,316 - root - INFO - Training: Epoch 0730 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4259 | Iter Mean Loss 6.4360
2020-11-05 16:38:11,318 - root - INFO - Evaluate: Epoch 0730 | NDCG 1.0000 | MSE 0.1767
2020-11-05 16:38:11,324 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8247 | Iter Mean Loss 9.8247
2020-11-05 16:38:11,330 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3251 | Iter Mean Loss 5.5749
2020-11-05 16:38:11,337 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9812 | Iter Mean Loss 7.0437
2020-11-05 16:38:11,342 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5951 | Iter Mean Loss 7.1815
2020-11-05 16:38:11,347 - root - INFO - Training: Epoch 0731 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4247 | Iter Mean Loss 6.4301
2020-11-05 16:38:11,348 - root - INFO - Evaluate: Epoch 0731 | NDCG 1.0000 | MSE 0.1767
2020-11-05 16:38:11,354 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8159 | Iter Mean Loss 9.8159
2020-11-05 16:38:11,360 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3236 | Iter Mean Loss 5.5698
2020-11-05 16:38:11,365 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9684 | Iter Mean Loss 7.0360
2020-11-05 16:38:11,371 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5902 | Iter Mean Loss 7.1745
2020-11-05 16:38:11,375 - root - INFO - Training: Epoch 0732 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4234 | Iter Mean Loss 6.4243
2020-11-05 16:38:11,376 - root - INFO - Evaluate: Epoch 0732 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:38:11,382 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.8072 | Iter Mean Loss 9.8072
2020-11-05 16:38:11,387 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3221 | Iter Mean Loss 5.5647
2020-11-05 16:38:11,393 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9556 | Iter Mean Loss 7.0283
2020-11-05 16:38:11,398 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5853 | Iter Mean Loss 7.1675
2020-11-05 16:38:11,403 - root - INFO - Training: Epoch 0733 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4221 | Iter Mean Loss 6.4184
2020-11-05 16:38:11,403 - root - INFO - Evaluate: Epoch 0733 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:38:11,409 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7984 | Iter Mean Loss 9.7984
2020-11-05 16:38:11,414 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3207 | Iter Mean Loss 5.5596
2020-11-05 16:38:11,420 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9428 | Iter Mean Loss 7.0206
2020-11-05 16:38:11,425 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5804 | Iter Mean Loss 7.1606
2020-11-05 16:38:11,430 - root - INFO - Training: Epoch 0734 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4208 | Iter Mean Loss 6.4126
2020-11-05 16:38:11,431 - root - INFO - Evaluate: Epoch 0734 | NDCG 1.0000 | MSE 0.1766
2020-11-05 16:38:11,436 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7897 | Iter Mean Loss 9.7897
2020-11-05 16:38:11,441 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3192 | Iter Mean Loss 5.5545
2020-11-05 16:38:11,447 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9300 | Iter Mean Loss 7.0130
2020-11-05 16:38:11,452 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5755 | Iter Mean Loss 7.1536
2020-11-05 16:38:11,457 - root - INFO - Training: Epoch 0735 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4195 | Iter Mean Loss 6.4068
2020-11-05 16:38:11,458 - root - INFO - Evaluate: Epoch 0735 | NDCG 1.0000 | MSE 0.1765
2020-11-05 16:38:11,464 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7810 | Iter Mean Loss 9.7810
2020-11-05 16:38:11,470 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3178 | Iter Mean Loss 5.5494
2020-11-05 16:38:11,476 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9173 | Iter Mean Loss 7.0054
2020-11-05 16:38:11,482 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5706 | Iter Mean Loss 7.1467
2020-11-05 16:38:11,487 - root - INFO - Training: Epoch 0736 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4183 | Iter Mean Loss 6.4010
2020-11-05 16:38:11,488 - root - INFO - Evaluate: Epoch 0736 | NDCG 1.0000 | MSE 0.1765
2020-11-05 16:38:11,494 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7723 | Iter Mean Loss 9.7723
2020-11-05 16:38:11,500 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3163 | Iter Mean Loss 5.5443
2020-11-05 16:38:11,507 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.9047 | Iter Mean Loss 6.9978
2020-11-05 16:38:11,512 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5657 | Iter Mean Loss 7.1397
2020-11-05 16:38:11,518 - root - INFO - Training: Epoch 0737 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4170 | Iter Mean Loss 6.3952
2020-11-05 16:38:11,519 - root - INFO - Evaluate: Epoch 0737 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:38:11,525 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7637 | Iter Mean Loss 9.7637
2020-11-05 16:38:11,531 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3148 | Iter Mean Loss 5.5392
2020-11-05 16:38:11,537 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8920 | Iter Mean Loss 6.9902
2020-11-05 16:38:11,543 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5608 | Iter Mean Loss 7.1328
2020-11-05 16:38:11,548 - root - INFO - Training: Epoch 0738 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4157 | Iter Mean Loss 6.3894
2020-11-05 16:38:11,549 - root - INFO - Evaluate: Epoch 0738 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:38:11,555 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 9.7550
2020-11-05 16:38:11,561 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3134 | Iter Mean Loss 5.5342
2020-11-05 16:38:11,566 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8794 | Iter Mean Loss 6.9826
2020-11-05 16:38:11,572 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5559 | Iter Mean Loss 7.1259
2020-11-05 16:38:11,577 - root - INFO - Training: Epoch 0739 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4145 | Iter Mean Loss 6.3836
2020-11-05 16:38:11,578 - root - INFO - Evaluate: Epoch 0739 | NDCG 1.0000 | MSE 0.1764
2020-11-05 16:38:11,583 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7463 | Iter Mean Loss 9.7463
2020-11-05 16:38:11,588 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3119 | Iter Mean Loss 5.5291
2020-11-05 16:38:11,594 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8668 | Iter Mean Loss 6.9750
2020-11-05 16:38:11,599 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5510 | Iter Mean Loss 7.1190
2020-11-05 16:38:11,604 - root - INFO - Training: Epoch 0740 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4132 | Iter Mean Loss 6.3779
2020-11-05 16:38:11,605 - root - INFO - Evaluate: Epoch 0740 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:38:11,610 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7377 | Iter Mean Loss 9.7377
2020-11-05 16:38:11,616 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3105 | Iter Mean Loss 5.5241
2020-11-05 16:38:11,621 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8543 | Iter Mean Loss 6.9675
2020-11-05 16:38:11,626 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5462 | Iter Mean Loss 7.1121
2020-11-05 16:38:11,631 - root - INFO - Training: Epoch 0741 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4119 | Iter Mean Loss 6.3721
2020-11-05 16:38:11,632 - root - INFO - Evaluate: Epoch 0741 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:38:11,638 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7290 | Iter Mean Loss 9.7290
2020-11-05 16:38:11,643 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3090 | Iter Mean Loss 5.5190
2020-11-05 16:38:11,649 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8418 | Iter Mean Loss 6.9599
2020-11-05 16:38:11,655 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5413 | Iter Mean Loss 7.1053
2020-11-05 16:38:11,660 - root - INFO - Training: Epoch 0742 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4107 | Iter Mean Loss 6.3663
2020-11-05 16:38:11,661 - root - INFO - Evaluate: Epoch 0742 | NDCG 1.0000 | MSE 0.1763
2020-11-05 16:38:11,667 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7204 | Iter Mean Loss 9.7204
2020-11-05 16:38:11,673 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3075 | Iter Mean Loss 5.5140
2020-11-05 16:38:11,679 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8293 | Iter Mean Loss 6.9524
2020-11-05 16:38:11,684 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5364 | Iter Mean Loss 7.0984
2020-11-05 16:38:11,689 - root - INFO - Training: Epoch 0743 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4094 | Iter Mean Loss 6.3606
2020-11-05 16:38:11,690 - root - INFO - Evaluate: Epoch 0743 | NDCG 1.0000 | MSE 0.1762
2020-11-05 16:38:11,697 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7118 | Iter Mean Loss 9.7118
2020-11-05 16:38:11,703 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3061 | Iter Mean Loss 5.5089
2020-11-05 16:38:11,709 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8168 | Iter Mean Loss 6.9449
2020-11-05 16:38:11,715 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5315 | Iter Mean Loss 7.0916
2020-11-05 16:38:11,720 - root - INFO - Training: Epoch 0744 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4081 | Iter Mean Loss 6.3549
2020-11-05 16:38:11,721 - root - INFO - Evaluate: Epoch 0744 | NDCG 1.0000 | MSE 0.1762
2020-11-05 16:38:11,727 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.7032 | Iter Mean Loss 9.7032
2020-11-05 16:38:11,733 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3046 | Iter Mean Loss 5.5039
2020-11-05 16:38:11,739 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.8044 | Iter Mean Loss 6.9374
2020-11-05 16:38:11,745 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5267 | Iter Mean Loss 7.0847
2020-11-05 16:38:11,750 - root - INFO - Training: Epoch 0745 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4069 | Iter Mean Loss 6.3491
2020-11-05 16:38:11,751 - root - INFO - Evaluate: Epoch 0745 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:38:11,757 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6946 | Iter Mean Loss 9.6946
2020-11-05 16:38:11,763 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3032 | Iter Mean Loss 5.4989
2020-11-05 16:38:11,769 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7920 | Iter Mean Loss 6.9299
2020-11-05 16:38:11,774 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5218 | Iter Mean Loss 7.0779
2020-11-05 16:38:11,779 - root - INFO - Training: Epoch 0746 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4056 | Iter Mean Loss 6.3434
2020-11-05 16:38:11,780 - root - INFO - Evaluate: Epoch 0746 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:38:11,786 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6860 | Iter Mean Loss 9.6860
2020-11-05 16:38:11,791 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3017 | Iter Mean Loss 5.4938
2020-11-05 16:38:11,796 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7796 | Iter Mean Loss 6.9224
2020-11-05 16:38:11,802 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5169 | Iter Mean Loss 7.0711
2020-11-05 16:38:11,807 - root - INFO - Training: Epoch 0747 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4044 | Iter Mean Loss 6.3377
2020-11-05 16:38:11,808 - root - INFO - Evaluate: Epoch 0747 | NDCG 1.0000 | MSE 0.1761
2020-11-05 16:38:11,813 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6774 | Iter Mean Loss 9.6774
2020-11-05 16:38:11,819 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.3002 | Iter Mean Loss 5.4888
2020-11-05 16:38:11,824 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7673 | Iter Mean Loss 6.9150
2020-11-05 16:38:11,829 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5121 | Iter Mean Loss 7.0643
2020-11-05 16:38:11,834 - root - INFO - Training: Epoch 0748 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4031 | Iter Mean Loss 6.3320
2020-11-05 16:38:11,835 - root - INFO - Evaluate: Epoch 0748 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:38:11,841 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6688 | Iter Mean Loss 9.6688
2020-11-05 16:38:11,846 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2988 | Iter Mean Loss 5.4838
2020-11-05 16:38:11,851 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7550 | Iter Mean Loss 6.9075
2020-11-05 16:38:11,857 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5072 | Iter Mean Loss 7.0575
2020-11-05 16:38:11,862 - root - INFO - Training: Epoch 0749 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4018 | Iter Mean Loss 6.3263
2020-11-05 16:38:11,863 - root - INFO - Evaluate: Epoch 0749 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:38:11,869 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6603 | Iter Mean Loss 9.6603
2020-11-05 16:38:11,875 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2973 | Iter Mean Loss 5.4788
2020-11-05 16:38:11,880 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7427 | Iter Mean Loss 6.9001
2020-11-05 16:38:11,886 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.5023 | Iter Mean Loss 7.0507
2020-11-05 16:38:11,891 - root - INFO - Training: Epoch 0750 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.4006 | Iter Mean Loss 6.3206
2020-11-05 16:38:11,892 - root - INFO - Evaluate: Epoch 0750 | NDCG 1.0000 | MSE 0.1760
2020-11-05 16:38:11,899 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6517 | Iter Mean Loss 9.6517
2020-11-05 16:38:11,904 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2958 | Iter Mean Loss 5.4738
2020-11-05 16:38:11,910 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7305 | Iter Mean Loss 6.8927
2020-11-05 16:38:11,917 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4975 | Iter Mean Loss 7.0439
2020-11-05 16:38:11,922 - root - INFO - Training: Epoch 0751 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3993 | Iter Mean Loss 6.3150
2020-11-05 16:38:11,923 - root - INFO - Evaluate: Epoch 0751 | NDCG 1.0000 | MSE 0.1759
2020-11-05 16:38:11,929 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6432 | Iter Mean Loss 9.6432
2020-11-05 16:38:11,935 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2944 | Iter Mean Loss 5.4688
2020-11-05 16:38:11,940 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7183 | Iter Mean Loss 6.8853
2020-11-05 16:38:11,947 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4926 | Iter Mean Loss 7.0371
2020-11-05 16:38:11,952 - root - INFO - Training: Epoch 0752 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3980 | Iter Mean Loss 6.3093
2020-11-05 16:38:11,952 - root - INFO - Evaluate: Epoch 0752 | NDCG 1.0000 | MSE 0.1759
2020-11-05 16:38:11,958 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6346 | Iter Mean Loss 9.6346
2020-11-05 16:38:11,965 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2929 | Iter Mean Loss 5.4638
2020-11-05 16:38:11,970 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.7061 | Iter Mean Loss 6.8779
2020-11-05 16:38:11,976 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4877 | Iter Mean Loss 7.0303
2020-11-05 16:38:11,980 - root - INFO - Training: Epoch 0753 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3968 | Iter Mean Loss 6.3036
2020-11-05 16:38:11,981 - root - INFO - Evaluate: Epoch 0753 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:38:11,987 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6261 | Iter Mean Loss 9.6261
2020-11-05 16:38:11,992 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2914 | Iter Mean Loss 5.4588
2020-11-05 16:38:11,997 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6940 | Iter Mean Loss 6.8705
2020-11-05 16:38:12,003 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4828 | Iter Mean Loss 7.0236
2020-11-05 16:38:12,008 - root - INFO - Training: Epoch 0754 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3955 | Iter Mean Loss 6.2980
2020-11-05 16:38:12,008 - root - INFO - Evaluate: Epoch 0754 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:38:12,014 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6176 | Iter Mean Loss 9.6176
2020-11-05 16:38:12,019 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2900 | Iter Mean Loss 5.4538
2020-11-05 16:38:12,025 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6818 | Iter Mean Loss 6.8631
2020-11-05 16:38:12,030 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4780 | Iter Mean Loss 7.0168
2020-11-05 16:38:12,035 - root - INFO - Training: Epoch 0755 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3943 | Iter Mean Loss 6.2923
2020-11-05 16:38:12,036 - root - INFO - Evaluate: Epoch 0755 | NDCG 1.0000 | MSE 0.1758
2020-11-05 16:38:12,041 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6090 | Iter Mean Loss 9.6090
2020-11-05 16:38:12,047 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2885 | Iter Mean Loss 5.4488
2020-11-05 16:38:12,052 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6697 | Iter Mean Loss 6.8558
2020-11-05 16:38:12,057 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4731 | Iter Mean Loss 7.0101
2020-11-05 16:38:12,062 - root - INFO - Training: Epoch 0756 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3930 | Iter Mean Loss 6.2867
2020-11-05 16:38:12,063 - root - INFO - Evaluate: Epoch 0756 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:38:12,069 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.6005 | Iter Mean Loss 9.6005
2020-11-05 16:38:12,075 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2870 | Iter Mean Loss 5.4438
2020-11-05 16:38:12,081 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6577 | Iter Mean Loss 6.8484
2020-11-05 16:38:12,087 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4682 | Iter Mean Loss 7.0034
2020-11-05 16:38:12,093 - root - INFO - Training: Epoch 0757 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3917 | Iter Mean Loss 6.2810
2020-11-05 16:38:12,094 - root - INFO - Evaluate: Epoch 0757 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:38:12,100 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5920 | Iter Mean Loss 9.5920
2020-11-05 16:38:12,106 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2855 | Iter Mean Loss 5.4388
2020-11-05 16:38:12,113 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6456 | Iter Mean Loss 6.8411
2020-11-05 16:38:12,118 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4633 | Iter Mean Loss 6.9966
2020-11-05 16:38:12,124 - root - INFO - Training: Epoch 0758 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3905 | Iter Mean Loss 6.2754
2020-11-05 16:38:12,125 - root - INFO - Evaluate: Epoch 0758 | NDCG 1.0000 | MSE 0.1757
2020-11-05 16:38:12,131 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5835 | Iter Mean Loss 9.5835
2020-11-05 16:38:12,137 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2840 | Iter Mean Loss 5.4338
2020-11-05 16:38:12,143 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6336 | Iter Mean Loss 6.8337
2020-11-05 16:38:12,149 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4584 | Iter Mean Loss 6.9899
2020-11-05 16:38:12,154 - root - INFO - Training: Epoch 0759 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3892 | Iter Mean Loss 6.2698
2020-11-05 16:38:12,155 - root - INFO - Evaluate: Epoch 0759 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:38:12,160 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5750 | Iter Mean Loss 9.5750
2020-11-05 16:38:12,166 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2826 | Iter Mean Loss 5.4288
2020-11-05 16:38:12,172 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6216 | Iter Mean Loss 6.8264
2020-11-05 16:38:12,178 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4535 | Iter Mean Loss 6.9832
2020-11-05 16:38:12,182 - root - INFO - Training: Epoch 0760 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3879 | Iter Mean Loss 6.2641
2020-11-05 16:38:12,183 - root - INFO - Evaluate: Epoch 0760 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:38:12,189 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5666 | Iter Mean Loss 9.5666
2020-11-05 16:38:12,194 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2811 | Iter Mean Loss 5.4238
2020-11-05 16:38:12,200 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.6097 | Iter Mean Loss 6.8191
2020-11-05 16:38:12,205 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4486 | Iter Mean Loss 6.9765
2020-11-05 16:38:12,210 - root - INFO - Training: Epoch 0761 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3867 | Iter Mean Loss 6.2585
2020-11-05 16:38:12,210 - root - INFO - Evaluate: Epoch 0761 | NDCG 1.0000 | MSE 0.1756
2020-11-05 16:38:12,216 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5581 | Iter Mean Loss 9.5581
2020-11-05 16:38:12,221 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2796 | Iter Mean Loss 5.4188
2020-11-05 16:38:12,227 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5977 | Iter Mean Loss 6.8118
2020-11-05 16:38:12,232 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4437 | Iter Mean Loss 6.9698
2020-11-05 16:38:12,237 - root - INFO - Training: Epoch 0762 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3854 | Iter Mean Loss 6.2529
2020-11-05 16:38:12,238 - root - INFO - Evaluate: Epoch 0762 | NDCG 1.0000 | MSE 0.1755
2020-11-05 16:38:12,243 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5496 | Iter Mean Loss 9.5496
2020-11-05 16:38:12,248 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2781 | Iter Mean Loss 5.4139
2020-11-05 16:38:12,254 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5858 | Iter Mean Loss 6.8045
2020-11-05 16:38:12,259 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4388 | Iter Mean Loss 6.9631
2020-11-05 16:38:12,265 - root - INFO - Training: Epoch 0763 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3841 | Iter Mean Loss 6.2473
2020-11-05 16:38:12,266 - root - INFO - Evaluate: Epoch 0763 | NDCG 1.0000 | MSE 0.1755
2020-11-05 16:38:12,271 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5412 | Iter Mean Loss 9.5412
2020-11-05 16:38:12,277 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2766 | Iter Mean Loss 5.4089
2020-11-05 16:38:12,283 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5739 | Iter Mean Loss 6.7972
2020-11-05 16:38:12,288 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4339 | Iter Mean Loss 6.9564
2020-11-05 16:38:12,293 - root - INFO - Training: Epoch 0764 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3829 | Iter Mean Loss 6.2417
2020-11-05 16:38:12,294 - root - INFO - Evaluate: Epoch 0764 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:38:12,301 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5327 | Iter Mean Loss 9.5327
2020-11-05 16:38:12,307 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2751 | Iter Mean Loss 5.4039
2020-11-05 16:38:12,313 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5621 | Iter Mean Loss 6.7900
2020-11-05 16:38:12,320 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4290 | Iter Mean Loss 6.9497
2020-11-05 16:38:12,325 - root - INFO - Training: Epoch 0765 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3816 | Iter Mean Loss 6.2361
2020-11-05 16:38:12,326 - root - INFO - Evaluate: Epoch 0765 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:38:12,333 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5242 | Iter Mean Loss 9.5242
2020-11-05 16:38:12,339 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2736 | Iter Mean Loss 5.3989
2020-11-05 16:38:12,344 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5502 | Iter Mean Loss 6.7827
2020-11-05 16:38:12,350 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4241 | Iter Mean Loss 6.9430
2020-11-05 16:38:12,356 - root - INFO - Training: Epoch 0766 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3803 | Iter Mean Loss 6.2305
2020-11-05 16:38:12,357 - root - INFO - Evaluate: Epoch 0766 | NDCG 1.0000 | MSE 0.1754
2020-11-05 16:38:12,362 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5158 | Iter Mean Loss 9.5158
2020-11-05 16:38:12,369 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2721 | Iter Mean Loss 5.3939
2020-11-05 16:38:12,374 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5384 | Iter Mean Loss 6.7754
2020-11-05 16:38:12,379 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4191 | Iter Mean Loss 6.9364
2020-11-05 16:38:12,384 - root - INFO - Training: Epoch 0767 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3790 | Iter Mean Loss 6.2249
2020-11-05 16:38:12,385 - root - INFO - Evaluate: Epoch 0767 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:38:12,390 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.5073 | Iter Mean Loss 9.5073
2020-11-05 16:38:12,396 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2706 | Iter Mean Loss 5.3890
2020-11-05 16:38:12,401 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5267 | Iter Mean Loss 6.7682
2020-11-05 16:38:12,407 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4142 | Iter Mean Loss 6.9297
2020-11-05 16:38:12,412 - root - INFO - Training: Epoch 0768 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3778 | Iter Mean Loss 6.2193
2020-11-05 16:38:12,412 - root - INFO - Evaluate: Epoch 0768 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:38:12,418 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4989 | Iter Mean Loss 9.4989
2020-11-05 16:38:12,423 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2691 | Iter Mean Loss 5.3840
2020-11-05 16:38:12,428 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5149 | Iter Mean Loss 6.7610
2020-11-05 16:38:12,434 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4093 | Iter Mean Loss 6.9230
2020-11-05 16:38:12,438 - root - INFO - Training: Epoch 0769 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3765 | Iter Mean Loss 6.2137
2020-11-05 16:38:12,439 - root - INFO - Evaluate: Epoch 0769 | NDCG 1.0000 | MSE 0.1753
2020-11-05 16:38:12,445 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4905 | Iter Mean Loss 9.4905
2020-11-05 16:38:12,450 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2675 | Iter Mean Loss 5.3790
2020-11-05 16:38:12,455 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.5032 | Iter Mean Loss 6.7537
2020-11-05 16:38:12,461 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.4043 | Iter Mean Loss 6.9164
2020-11-05 16:38:12,466 - root - INFO - Training: Epoch 0770 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3752 | Iter Mean Loss 6.2081
2020-11-05 16:38:12,467 - root - INFO - Evaluate: Epoch 0770 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:38:12,473 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4821 | Iter Mean Loss 9.4821
2020-11-05 16:38:12,479 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2660 | Iter Mean Loss 5.3740
2020-11-05 16:38:12,485 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4915 | Iter Mean Loss 6.7465
2020-11-05 16:38:12,491 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3993 | Iter Mean Loss 6.9097
2020-11-05 16:38:12,496 - root - INFO - Training: Epoch 0771 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3739 | Iter Mean Loss 6.2026
2020-11-05 16:38:12,497 - root - INFO - Evaluate: Epoch 0771 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:38:12,503 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4736 | Iter Mean Loss 9.4736
2020-11-05 16:38:12,509 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2645 | Iter Mean Loss 5.3691
2020-11-05 16:38:12,516 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4798 | Iter Mean Loss 6.7393
2020-11-05 16:38:12,521 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3944 | Iter Mean Loss 6.9031
2020-11-05 16:38:12,527 - root - INFO - Training: Epoch 0772 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3726 | Iter Mean Loss 6.1970
2020-11-05 16:38:12,528 - root - INFO - Evaluate: Epoch 0772 | NDCG 1.0000 | MSE 0.1752
2020-11-05 16:38:12,534 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4652 | Iter Mean Loss 9.4652
2020-11-05 16:38:12,540 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2630 | Iter Mean Loss 5.3641
2020-11-05 16:38:12,546 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4681 | Iter Mean Loss 6.7321
2020-11-05 16:38:12,552 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3894 | Iter Mean Loss 6.8964
2020-11-05 16:38:12,556 - root - INFO - Training: Epoch 0773 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3713 | Iter Mean Loss 6.1914
2020-11-05 16:38:12,558 - root - INFO - Evaluate: Epoch 0773 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:38:12,563 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4568 | Iter Mean Loss 9.4568
2020-11-05 16:38:12,569 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2614 | Iter Mean Loss 5.3591
2020-11-05 16:38:12,575 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4565 | Iter Mean Loss 6.7249
2020-11-05 16:38:12,581 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3844 | Iter Mean Loss 6.8898
2020-11-05 16:38:12,585 - root - INFO - Training: Epoch 0774 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3700 | Iter Mean Loss 6.1858
2020-11-05 16:38:12,586 - root - INFO - Evaluate: Epoch 0774 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:38:12,592 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4484 | Iter Mean Loss 9.4484
2020-11-05 16:38:12,597 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2599 | Iter Mean Loss 5.3541
2020-11-05 16:38:12,603 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4449 | Iter Mean Loss 6.7177
2020-11-05 16:38:12,608 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3794 | Iter Mean Loss 6.8831
2020-11-05 16:38:12,613 - root - INFO - Training: Epoch 0775 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3687 | Iter Mean Loss 6.1803
2020-11-05 16:38:12,614 - root - INFO - Evaluate: Epoch 0775 | NDCG 1.0000 | MSE 0.1751
2020-11-05 16:38:12,619 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4400 | Iter Mean Loss 9.4400
2020-11-05 16:38:12,625 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2584 | Iter Mean Loss 5.3492
2020-11-05 16:38:12,630 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4333 | Iter Mean Loss 6.7105
2020-11-05 16:38:12,635 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3744 | Iter Mean Loss 6.8765
2020-11-05 16:38:12,640 - root - INFO - Training: Epoch 0776 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3674 | Iter Mean Loss 6.1747
2020-11-05 16:38:12,641 - root - INFO - Evaluate: Epoch 0776 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:38:12,647 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4316 | Iter Mean Loss 9.4316
2020-11-05 16:38:12,653 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2568 | Iter Mean Loss 5.3442
2020-11-05 16:38:12,658 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4217 | Iter Mean Loss 6.7034
2020-11-05 16:38:12,664 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3694 | Iter Mean Loss 6.8699
2020-11-05 16:38:12,669 - root - INFO - Training: Epoch 0777 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3661 | Iter Mean Loss 6.1691
2020-11-05 16:38:12,670 - root - INFO - Evaluate: Epoch 0777 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:38:12,676 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4232 | Iter Mean Loss 9.4232
2020-11-05 16:38:12,682 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2553 | Iter Mean Loss 5.3392
2020-11-05 16:38:12,687 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.4102 | Iter Mean Loss 6.6962
2020-11-05 16:38:12,693 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3643 | Iter Mean Loss 6.8632
2020-11-05 16:38:12,699 - root - INFO - Training: Epoch 0778 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3648 | Iter Mean Loss 6.1636
2020-11-05 16:38:12,700 - root - INFO - Evaluate: Epoch 0778 | NDCG 1.0000 | MSE 0.1750
2020-11-05 16:38:12,706 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4148 | Iter Mean Loss 9.4148
2020-11-05 16:38:12,712 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2537 | Iter Mean Loss 5.3342
2020-11-05 16:38:12,718 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3986 | Iter Mean Loss 6.6890
2020-11-05 16:38:12,724 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3593 | Iter Mean Loss 6.8566
2020-11-05 16:38:12,729 - root - INFO - Training: Epoch 0779 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3635 | Iter Mean Loss 6.1580
2020-11-05 16:38:12,731 - root - INFO - Evaluate: Epoch 0779 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:38:12,737 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.4064 | Iter Mean Loss 9.4064
2020-11-05 16:38:12,743 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2522 | Iter Mean Loss 5.3293
2020-11-05 16:38:12,750 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3871 | Iter Mean Loss 6.6819
2020-11-05 16:38:12,755 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3543 | Iter Mean Loss 6.8500
2020-11-05 16:38:12,760 - root - INFO - Training: Epoch 0780 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3622 | Iter Mean Loss 6.1524
2020-11-05 16:38:12,761 - root - INFO - Evaluate: Epoch 0780 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:38:12,767 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3980 | Iter Mean Loss 9.3980
2020-11-05 16:38:12,773 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2506 | Iter Mean Loss 5.3243
2020-11-05 16:38:12,780 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3756 | Iter Mean Loss 6.6747
2020-11-05 16:38:12,785 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3492 | Iter Mean Loss 6.8434
2020-11-05 16:38:12,790 - root - INFO - Training: Epoch 0781 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3609 | Iter Mean Loss 6.1469
2020-11-05 16:38:12,791 - root - INFO - Evaluate: Epoch 0781 | NDCG 1.0000 | MSE 0.1749
2020-11-05 16:38:12,796 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3896 | Iter Mean Loss 9.3896
2020-11-05 16:38:12,802 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2490 | Iter Mean Loss 5.3193
2020-11-05 16:38:12,807 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3642 | Iter Mean Loss 6.6676
2020-11-05 16:38:12,812 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3441 | Iter Mean Loss 6.8367
2020-11-05 16:38:12,817 - root - INFO - Training: Epoch 0782 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3596 | Iter Mean Loss 6.1413
2020-11-05 16:38:12,818 - root - INFO - Evaluate: Epoch 0782 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:38:12,824 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3812 | Iter Mean Loss 9.3812
2020-11-05 16:38:12,829 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2475 | Iter Mean Loss 5.3143
2020-11-05 16:38:12,834 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3528 | Iter Mean Loss 6.6605
2020-11-05 16:38:12,840 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3390 | Iter Mean Loss 6.8301
2020-11-05 16:38:12,844 - root - INFO - Training: Epoch 0783 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3583 | Iter Mean Loss 6.1357
2020-11-05 16:38:12,845 - root - INFO - Evaluate: Epoch 0783 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:38:12,851 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3728 | Iter Mean Loss 9.3728
2020-11-05 16:38:12,856 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2459 | Iter Mean Loss 5.3094
2020-11-05 16:38:12,861 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3413 | Iter Mean Loss 6.6533
2020-11-05 16:38:12,867 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3339 | Iter Mean Loss 6.8235
2020-11-05 16:38:12,872 - root - INFO - Training: Epoch 0784 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3570 | Iter Mean Loss 6.1302
2020-11-05 16:38:12,873 - root - INFO - Evaluate: Epoch 0784 | NDCG 1.0000 | MSE 0.1748
2020-11-05 16:38:12,879 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3644 | Iter Mean Loss 9.3644
2020-11-05 16:38:12,885 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2443 | Iter Mean Loss 5.3044
2020-11-05 16:38:12,890 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3299 | Iter Mean Loss 6.6462
2020-11-05 16:38:12,896 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3288 | Iter Mean Loss 6.8169
2020-11-05 16:38:12,901 - root - INFO - Training: Epoch 0785 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3556 | Iter Mean Loss 6.1246
2020-11-05 16:38:12,901 - root - INFO - Evaluate: Epoch 0785 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:38:12,908 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3561 | Iter Mean Loss 9.3561
2020-11-05 16:38:12,913 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2427 | Iter Mean Loss 5.2994
2020-11-05 16:38:12,919 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3186 | Iter Mean Loss 6.6391
2020-11-05 16:38:12,925 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3237 | Iter Mean Loss 6.8103
2020-11-05 16:38:12,930 - root - INFO - Training: Epoch 0786 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3543 | Iter Mean Loss 6.1191
2020-11-05 16:38:12,931 - root - INFO - Evaluate: Epoch 0786 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:38:12,937 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3477 | Iter Mean Loss 9.3477
2020-11-05 16:38:12,943 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2411 | Iter Mean Loss 5.2944
2020-11-05 16:38:12,948 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.3072 | Iter Mean Loss 6.6320
2020-11-05 16:38:12,955 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3186 | Iter Mean Loss 6.8037
2020-11-05 16:38:12,960 - root - INFO - Training: Epoch 0787 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3530 | Iter Mean Loss 6.1135
2020-11-05 16:38:12,961 - root - INFO - Evaluate: Epoch 0787 | NDCG 1.0000 | MSE 0.1747
2020-11-05 16:38:12,966 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3393 | Iter Mean Loss 9.3393
2020-11-05 16:38:12,972 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2395 | Iter Mean Loss 5.2894
2020-11-05 16:38:12,978 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2959 | Iter Mean Loss 6.6249
2020-11-05 16:38:12,983 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3134 | Iter Mean Loss 6.7970
2020-11-05 16:38:12,988 - root - INFO - Training: Epoch 0788 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3517 | Iter Mean Loss 6.1080
2020-11-05 16:38:12,989 - root - INFO - Evaluate: Epoch 0788 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:38:12,994 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3309 | Iter Mean Loss 9.3309
2020-11-05 16:38:13,000 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2379 | Iter Mean Loss 5.2844
2020-11-05 16:38:13,005 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2846 | Iter Mean Loss 6.6178
2020-11-05 16:38:13,010 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3082 | Iter Mean Loss 6.7904
2020-11-05 16:38:13,015 - root - INFO - Training: Epoch 0789 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3503 | Iter Mean Loss 6.1024
2020-11-05 16:38:13,016 - root - INFO - Evaluate: Epoch 0789 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:38:13,021 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3226 | Iter Mean Loss 9.3226
2020-11-05 16:38:13,027 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2363 | Iter Mean Loss 5.2794
2020-11-05 16:38:13,032 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2733 | Iter Mean Loss 6.6107
2020-11-05 16:38:13,037 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.3031 | Iter Mean Loss 6.7838
2020-11-05 16:38:13,042 - root - INFO - Training: Epoch 0790 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3490 | Iter Mean Loss 6.0968
2020-11-05 16:38:13,043 - root - INFO - Evaluate: Epoch 0790 | NDCG 1.0000 | MSE 0.1746
2020-11-05 16:38:13,048 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3142 | Iter Mean Loss 9.3142
2020-11-05 16:38:13,054 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2347 | Iter Mean Loss 5.2744
2020-11-05 16:38:13,059 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2620 | Iter Mean Loss 6.6036
2020-11-05 16:38:13,065 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2979 | Iter Mean Loss 6.7772
2020-11-05 16:38:13,069 - root - INFO - Training: Epoch 0791 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3476 | Iter Mean Loss 6.0913
2020-11-05 16:38:13,070 - root - INFO - Evaluate: Epoch 0791 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:38:13,076 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.3058 | Iter Mean Loss 9.3058
2020-11-05 16:38:13,081 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2331 | Iter Mean Loss 5.2695
2020-11-05 16:38:13,087 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2508 | Iter Mean Loss 6.5966
2020-11-05 16:38:13,093 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2927 | Iter Mean Loss 6.7706
2020-11-05 16:38:13,098 - root - INFO - Training: Epoch 0792 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3463 | Iter Mean Loss 6.0857
2020-11-05 16:38:13,099 - root - INFO - Evaluate: Epoch 0792 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:38:13,105 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2975 | Iter Mean Loss 9.2975
2020-11-05 16:38:13,111 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2315 | Iter Mean Loss 5.2645
2020-11-05 16:38:13,116 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2396 | Iter Mean Loss 6.5895
2020-11-05 16:38:13,123 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2874 | Iter Mean Loss 6.7640
2020-11-05 16:38:13,128 - root - INFO - Training: Epoch 0793 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3449 | Iter Mean Loss 6.0802
2020-11-05 16:38:13,128 - root - INFO - Evaluate: Epoch 0793 | NDCG 1.0000 | MSE 0.1745
2020-11-05 16:38:13,134 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2891 | Iter Mean Loss 9.2891
2020-11-05 16:38:13,140 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2298 | Iter Mean Loss 5.2595
2020-11-05 16:38:13,146 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2284 | Iter Mean Loss 6.5824
2020-11-05 16:38:13,152 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2822 | Iter Mean Loss 6.7574
2020-11-05 16:38:13,157 - root - INFO - Training: Epoch 0794 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3436 | Iter Mean Loss 6.0746
2020-11-05 16:38:13,158 - root - INFO - Evaluate: Epoch 0794 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:38:13,164 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2807 | Iter Mean Loss 9.2807
2020-11-05 16:38:13,169 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2282 | Iter Mean Loss 5.2545
2020-11-05 16:38:13,175 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2172 | Iter Mean Loss 6.5754
2020-11-05 16:38:13,181 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2769 | Iter Mean Loss 6.7508
2020-11-05 16:38:13,186 - root - INFO - Training: Epoch 0795 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3422 | Iter Mean Loss 6.0690
2020-11-05 16:38:13,186 - root - INFO - Evaluate: Epoch 0795 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:38:13,192 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2724 | Iter Mean Loss 9.2724
2020-11-05 16:38:13,197 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2266 | Iter Mean Loss 5.2495
2020-11-05 16:38:13,203 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.2060 | Iter Mean Loss 6.5683
2020-11-05 16:38:13,208 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2716 | Iter Mean Loss 6.7441
2020-11-05 16:38:13,213 - root - INFO - Training: Epoch 0796 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3408 | Iter Mean Loss 6.0635
2020-11-05 16:38:13,214 - root - INFO - Evaluate: Epoch 0796 | NDCG 1.0000 | MSE 0.1744
2020-11-05 16:38:13,219 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2640 | Iter Mean Loss 9.2640
2020-11-05 16:38:13,225 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2249 | Iter Mean Loss 5.2445
2020-11-05 16:38:13,230 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1949 | Iter Mean Loss 6.5613
2020-11-05 16:38:13,235 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2664 | Iter Mean Loss 6.7375
2020-11-05 16:38:13,240 - root - INFO - Training: Epoch 0797 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3395 | Iter Mean Loss 6.0579
2020-11-05 16:38:13,241 - root - INFO - Evaluate: Epoch 0797 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:38:13,246 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2556 | Iter Mean Loss 9.2556
2020-11-05 16:38:13,252 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2233 | Iter Mean Loss 5.2395
2020-11-05 16:38:13,257 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1837 | Iter Mean Loss 6.5542
2020-11-05 16:38:13,263 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2610 | Iter Mean Loss 6.7309
2020-11-05 16:38:13,267 - root - INFO - Training: Epoch 0798 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3381 | Iter Mean Loss 6.0524
2020-11-05 16:38:13,268 - root - INFO - Evaluate: Epoch 0798 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:38:13,274 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2473 | Iter Mean Loss 9.2473
2020-11-05 16:38:13,280 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2216 | Iter Mean Loss 5.2345
2020-11-05 16:38:13,285 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1726 | Iter Mean Loss 6.5472
2020-11-05 16:38:13,292 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2557 | Iter Mean Loss 6.7243
2020-11-05 16:38:13,297 - root - INFO - Training: Epoch 0799 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3367 | Iter Mean Loss 6.0468
2020-11-05 16:38:13,298 - root - INFO - Evaluate: Epoch 0799 | NDCG 1.0000 | MSE 0.1743
2020-11-05 16:38:13,304 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2389 | Iter Mean Loss 9.2389
2020-11-05 16:38:13,310 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2200 | Iter Mean Loss 5.2294
2020-11-05 16:38:13,317 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1615 | Iter Mean Loss 6.5401
2020-11-05 16:38:13,323 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2504 | Iter Mean Loss 6.7177
2020-11-05 16:38:13,329 - root - INFO - Training: Epoch 0800 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3354 | Iter Mean Loss 6.0412
2020-11-05 16:38:13,330 - root - INFO - Evaluate: Epoch 0800 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:38:13,336 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2306 | Iter Mean Loss 9.2306
2020-11-05 16:38:13,342 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2183 | Iter Mean Loss 5.2244
2020-11-05 16:38:13,348 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1505 | Iter Mean Loss 6.5331
2020-11-05 16:38:13,354 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2450 | Iter Mean Loss 6.7111
2020-11-05 16:38:13,360 - root - INFO - Training: Epoch 0801 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3340 | Iter Mean Loss 6.0357
2020-11-05 16:38:13,361 - root - INFO - Evaluate: Epoch 0801 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:38:13,366 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2222 | Iter Mean Loss 9.2222
2020-11-05 16:38:13,372 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2166 | Iter Mean Loss 5.2194
2020-11-05 16:38:13,377 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1394 | Iter Mean Loss 6.5261
2020-11-05 16:38:13,383 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2396 | Iter Mean Loss 6.7045
2020-11-05 16:38:13,388 - root - INFO - Training: Epoch 0802 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3326 | Iter Mean Loss 6.0301
2020-11-05 16:38:13,389 - root - INFO - Evaluate: Epoch 0802 | NDCG 1.0000 | MSE 0.1742
2020-11-05 16:38:13,395 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2138 | Iter Mean Loss 9.2138
2020-11-05 16:38:13,400 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2150 | Iter Mean Loss 5.2144
2020-11-05 16:38:13,406 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1284 | Iter Mean Loss 6.5191
2020-11-05 16:38:13,411 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2342 | Iter Mean Loss 6.6978
2020-11-05 16:38:13,416 - root - INFO - Training: Epoch 0803 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3312 | Iter Mean Loss 6.0245
2020-11-05 16:38:13,416 - root - INFO - Evaluate: Epoch 0803 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:38:13,422 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.2055 | Iter Mean Loss 9.2055
2020-11-05 16:38:13,427 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2133 | Iter Mean Loss 5.2094
2020-11-05 16:38:13,433 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1174 | Iter Mean Loss 6.5120
2020-11-05 16:38:13,438 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2288 | Iter Mean Loss 6.6912
2020-11-05 16:38:13,443 - root - INFO - Training: Epoch 0804 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3298 | Iter Mean Loss 6.0189
2020-11-05 16:38:13,444 - root - INFO - Evaluate: Epoch 0804 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:38:13,449 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1971 | Iter Mean Loss 9.1971
2020-11-05 16:38:13,454 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2116 | Iter Mean Loss 5.2044
2020-11-05 16:38:13,460 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.1064 | Iter Mean Loss 6.5050
2020-11-05 16:38:13,465 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2234 | Iter Mean Loss 6.6846
2020-11-05 16:38:13,470 - root - INFO - Training: Epoch 0805 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3284 | Iter Mean Loss 6.0134
2020-11-05 16:38:13,471 - root - INFO - Evaluate: Epoch 0805 | NDCG 1.0000 | MSE 0.1741
2020-11-05 16:38:13,476 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1888 | Iter Mean Loss 9.1888
2020-11-05 16:38:13,482 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2099 | Iter Mean Loss 5.1993
2020-11-05 16:38:13,487 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0954 | Iter Mean Loss 6.4980
2020-11-05 16:38:13,494 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2179 | Iter Mean Loss 6.6780
2020-11-05 16:38:13,499 - root - INFO - Training: Epoch 0806 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3270 | Iter Mean Loss 6.0078
2020-11-05 16:38:13,500 - root - INFO - Evaluate: Epoch 0806 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:38:13,506 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1804 | Iter Mean Loss 9.1804
2020-11-05 16:38:13,514 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2082 | Iter Mean Loss 5.1943
2020-11-05 16:38:13,520 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0844 | Iter Mean Loss 6.4910
2020-11-05 16:38:13,527 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2124 | Iter Mean Loss 6.6714
2020-11-05 16:38:13,533 - root - INFO - Training: Epoch 0807 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3256 | Iter Mean Loss 6.0022
2020-11-05 16:38:13,534 - root - INFO - Evaluate: Epoch 0807 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:38:13,540 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1721 | Iter Mean Loss 9.1721
2020-11-05 16:38:13,547 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2065 | Iter Mean Loss 5.1893
2020-11-05 16:38:13,554 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0735 | Iter Mean Loss 6.4840
2020-11-05 16:38:13,560 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2069 | Iter Mean Loss 6.6647
2020-11-05 16:38:13,566 - root - INFO - Training: Epoch 0808 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3242 | Iter Mean Loss 5.9966
2020-11-05 16:38:13,567 - root - INFO - Evaluate: Epoch 0808 | NDCG 1.0000 | MSE 0.1740
2020-11-05 16:38:13,574 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1637 | Iter Mean Loss 9.1637
2020-11-05 16:38:13,580 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2048 | Iter Mean Loss 5.1842
2020-11-05 16:38:13,587 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0626 | Iter Mean Loss 6.4770
2020-11-05 16:38:13,593 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.2014 | Iter Mean Loss 6.6581
2020-11-05 16:38:13,598 - root - INFO - Training: Epoch 0809 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3228 | Iter Mean Loss 5.9910
2020-11-05 16:38:13,599 - root - INFO - Evaluate: Epoch 0809 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:38:13,605 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1553 | Iter Mean Loss 9.1553
2020-11-05 16:38:13,611 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2031 | Iter Mean Loss 5.1792
2020-11-05 16:38:13,617 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0517 | Iter Mean Loss 6.4700
2020-11-05 16:38:13,622 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1959 | Iter Mean Loss 6.6515
2020-11-05 16:38:13,627 - root - INFO - Training: Epoch 0810 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3213 | Iter Mean Loss 5.9855
2020-11-05 16:38:13,628 - root - INFO - Evaluate: Epoch 0810 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:38:13,634 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1470 | Iter Mean Loss 9.1470
2020-11-05 16:38:13,640 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.2014 | Iter Mean Loss 5.1742
2020-11-05 16:38:13,646 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0408 | Iter Mean Loss 6.4630
2020-11-05 16:38:13,652 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1903 | Iter Mean Loss 6.6449
2020-11-05 16:38:13,657 - root - INFO - Training: Epoch 0811 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3199 | Iter Mean Loss 5.9799
2020-11-05 16:38:13,658 - root - INFO - Evaluate: Epoch 0811 | NDCG 1.0000 | MSE 0.1739
2020-11-05 16:38:13,664 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1386 | Iter Mean Loss 9.1386
2020-11-05 16:38:13,670 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1996 | Iter Mean Loss 5.1691
2020-11-05 16:38:13,676 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0299 | Iter Mean Loss 6.4561
2020-11-05 16:38:13,682 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1847 | Iter Mean Loss 6.6382
2020-11-05 16:38:13,688 - root - INFO - Training: Epoch 0812 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3185 | Iter Mean Loss 5.9743
2020-11-05 16:38:13,688 - root - INFO - Evaluate: Epoch 0812 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:38:13,695 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1303 | Iter Mean Loss 9.1303
2020-11-05 16:38:13,702 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1979 | Iter Mean Loss 5.1641
2020-11-05 16:38:13,708 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0191 | Iter Mean Loss 6.4491
2020-11-05 16:38:13,715 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1791 | Iter Mean Loss 6.6316
2020-11-05 16:38:13,720 - root - INFO - Training: Epoch 0813 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3171 | Iter Mean Loss 5.9687
2020-11-05 16:38:13,721 - root - INFO - Evaluate: Epoch 0813 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:38:13,728 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1219 | Iter Mean Loss 9.1219
2020-11-05 16:38:13,735 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1962 | Iter Mean Loss 5.1591
2020-11-05 16:38:13,740 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 9.0082 | Iter Mean Loss 6.4421
2020-11-05 16:38:13,748 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1735 | Iter Mean Loss 6.6250
2020-11-05 16:38:13,753 - root - INFO - Training: Epoch 0814 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3156 | Iter Mean Loss 5.9631
2020-11-05 16:38:13,754 - root - INFO - Evaluate: Epoch 0814 | NDCG 1.0000 | MSE 0.1738
2020-11-05 16:38:13,761 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1136 | Iter Mean Loss 9.1136
2020-11-05 16:38:13,768 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1944 | Iter Mean Loss 5.1540
2020-11-05 16:38:13,773 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9974 | Iter Mean Loss 6.4351
2020-11-05 16:38:13,779 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1679 | Iter Mean Loss 6.6183
2020-11-05 16:38:13,785 - root - INFO - Training: Epoch 0815 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3142 | Iter Mean Loss 5.9575
2020-11-05 16:38:13,787 - root - INFO - Evaluate: Epoch 0815 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:38:13,793 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.1052 | Iter Mean Loss 9.1052
2020-11-05 16:38:13,799 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1927 | Iter Mean Loss 5.1490
2020-11-05 16:38:13,805 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9866 | Iter Mean Loss 6.4282
2020-11-05 16:38:13,810 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1622 | Iter Mean Loss 6.6117
2020-11-05 16:38:13,815 - root - INFO - Training: Epoch 0816 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3127 | Iter Mean Loss 5.9519
2020-11-05 16:38:13,816 - root - INFO - Evaluate: Epoch 0816 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:38:13,822 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0969 | Iter Mean Loss 9.0969
2020-11-05 16:38:13,828 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1909 | Iter Mean Loss 5.1439
2020-11-05 16:38:13,833 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9758 | Iter Mean Loss 6.4212
2020-11-05 16:38:13,839 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1565 | Iter Mean Loss 6.6050
2020-11-05 16:38:13,844 - root - INFO - Training: Epoch 0817 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3113 | Iter Mean Loss 5.9463
2020-11-05 16:38:13,845 - root - INFO - Evaluate: Epoch 0817 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:38:13,851 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0885 | Iter Mean Loss 9.0885
2020-11-05 16:38:13,856 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1892 | Iter Mean Loss 5.1389
2020-11-05 16:38:13,862 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9651 | Iter Mean Loss 6.4143
2020-11-05 16:38:13,868 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1508 | Iter Mean Loss 6.5984
2020-11-05 16:38:13,873 - root - INFO - Training: Epoch 0818 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3098 | Iter Mean Loss 5.9407
2020-11-05 16:38:13,874 - root - INFO - Evaluate: Epoch 0818 | NDCG 1.0000 | MSE 0.1737
2020-11-05 16:38:13,880 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0802 | Iter Mean Loss 9.0802
2020-11-05 16:38:13,885 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1874 | Iter Mean Loss 5.1338
2020-11-05 16:38:13,892 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9543 | Iter Mean Loss 6.4073
2020-11-05 16:38:13,898 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1451 | Iter Mean Loss 6.5918
2020-11-05 16:38:13,903 - root - INFO - Training: Epoch 0819 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3084 | Iter Mean Loss 5.9351
2020-11-05 16:38:13,904 - root - INFO - Evaluate: Epoch 0819 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:38:13,910 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0718 | Iter Mean Loss 9.0718
2020-11-05 16:38:13,916 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1857 | Iter Mean Loss 5.1288
2020-11-05 16:38:13,922 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9436 | Iter Mean Loss 6.4004
2020-11-05 16:38:13,930 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1393 | Iter Mean Loss 6.5851
2020-11-05 16:38:13,935 - root - INFO - Training: Epoch 0820 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3069 | Iter Mean Loss 5.9295
2020-11-05 16:38:13,936 - root - INFO - Evaluate: Epoch 0820 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:38:13,943 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0635 | Iter Mean Loss 9.0635
2020-11-05 16:38:13,949 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1839 | Iter Mean Loss 5.1237
2020-11-05 16:38:13,955 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9329 | Iter Mean Loss 6.3934
2020-11-05 16:38:13,962 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1335 | Iter Mean Loss 6.5785
2020-11-05 16:38:13,967 - root - INFO - Training: Epoch 0821 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3055 | Iter Mean Loss 5.9239
2020-11-05 16:38:13,968 - root - INFO - Evaluate: Epoch 0821 | NDCG 1.0000 | MSE 0.1736
2020-11-05 16:38:13,975 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0551 | Iter Mean Loss 9.0551
2020-11-05 16:38:13,981 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1821 | Iter Mean Loss 5.1186
2020-11-05 16:38:13,987 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9222 | Iter Mean Loss 6.3865
2020-11-05 16:38:13,994 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1277 | Iter Mean Loss 6.5718
2020-11-05 16:38:13,999 - root - INFO - Training: Epoch 0822 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3040 | Iter Mean Loss 5.9182
2020-11-05 16:38:14,000 - root - INFO - Evaluate: Epoch 0822 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:38:14,006 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0468 | Iter Mean Loss 9.0468
2020-11-05 16:38:14,011 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1804 | Iter Mean Loss 5.1136
2020-11-05 16:38:14,017 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9115 | Iter Mean Loss 6.3796
2020-11-05 16:38:14,023 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1219 | Iter Mean Loss 6.5652
2020-11-05 16:38:14,027 - root - INFO - Training: Epoch 0823 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3025 | Iter Mean Loss 5.9126
2020-11-05 16:38:14,028 - root - INFO - Evaluate: Epoch 0823 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:38:14,034 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0385 | Iter Mean Loss 9.0385
2020-11-05 16:38:14,040 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1786 | Iter Mean Loss 5.1085
2020-11-05 16:38:14,045 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.9009 | Iter Mean Loss 6.3726
2020-11-05 16:38:14,051 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1161 | Iter Mean Loss 6.5585
2020-11-05 16:38:14,056 - root - INFO - Training: Epoch 0824 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.3011 | Iter Mean Loss 5.9070
2020-11-05 16:38:14,057 - root - INFO - Evaluate: Epoch 0824 | NDCG 1.0000 | MSE 0.1735
2020-11-05 16:38:14,062 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0301 | Iter Mean Loss 9.0301
2020-11-05 16:38:14,068 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1768 | Iter Mean Loss 5.1035
2020-11-05 16:38:14,074 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8903 | Iter Mean Loss 6.3657
2020-11-05 16:38:14,079 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1102 | Iter Mean Loss 6.5518
2020-11-05 16:38:14,084 - root - INFO - Training: Epoch 0825 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2996 | Iter Mean Loss 5.9014
2020-11-05 16:38:14,085 - root - INFO - Evaluate: Epoch 0825 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:38:14,091 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0218 | Iter Mean Loss 9.0218
2020-11-05 16:38:14,097 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1750 | Iter Mean Loss 5.0984
2020-11-05 16:38:14,103 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8796 | Iter Mean Loss 6.3588
2020-11-05 16:38:14,110 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.1043 | Iter Mean Loss 6.5452
2020-11-05 16:38:14,115 - root - INFO - Training: Epoch 0826 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2981 | Iter Mean Loss 5.8958
2020-11-05 16:38:14,116 - root - INFO - Evaluate: Epoch 0826 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:38:14,123 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0134 | Iter Mean Loss 9.0134
2020-11-05 16:38:14,129 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1732 | Iter Mean Loss 5.0933
2020-11-05 16:38:14,135 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8690 | Iter Mean Loss 6.3519
2020-11-05 16:38:14,142 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0984 | Iter Mean Loss 6.5385
2020-11-05 16:38:14,147 - root - INFO - Training: Epoch 0827 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2966 | Iter Mean Loss 5.8902
2020-11-05 16:38:14,148 - root - INFO - Evaluate: Epoch 0827 | NDCG 1.0000 | MSE 0.1734
2020-11-05 16:38:14,155 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 9.0051 | Iter Mean Loss 9.0051
2020-11-05 16:38:14,161 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1714 | Iter Mean Loss 5.0883
2020-11-05 16:38:14,167 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8585 | Iter Mean Loss 6.3450
2020-11-05 16:38:14,174 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0925 | Iter Mean Loss 6.5319
2020-11-05 16:38:14,179 - root - INFO - Training: Epoch 0828 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2951 | Iter Mean Loss 5.8845
2020-11-05 16:38:14,180 - root - INFO - Evaluate: Epoch 0828 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:38:14,186 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9968 | Iter Mean Loss 8.9968
2020-11-05 16:38:14,192 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1696 | Iter Mean Loss 5.0832
2020-11-05 16:38:14,198 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8479 | Iter Mean Loss 6.3381
2020-11-05 16:38:14,204 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0866 | Iter Mean Loss 6.5252
2020-11-05 16:38:14,209 - root - INFO - Training: Epoch 0829 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2936 | Iter Mean Loss 5.8789
2020-11-05 16:38:14,210 - root - INFO - Evaluate: Epoch 0829 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:38:14,216 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9884 | Iter Mean Loss 8.9884
2020-11-05 16:38:14,221 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1678 | Iter Mean Loss 5.0781
2020-11-05 16:38:14,227 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8373 | Iter Mean Loss 6.3312
2020-11-05 16:38:14,232 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0806 | Iter Mean Loss 6.5186
2020-11-05 16:38:14,237 - root - INFO - Training: Epoch 0830 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2922 | Iter Mean Loss 5.8733
2020-11-05 16:38:14,238 - root - INFO - Evaluate: Epoch 0830 | NDCG 1.0000 | MSE 0.1733
2020-11-05 16:38:14,243 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9801 | Iter Mean Loss 8.9801
2020-11-05 16:38:14,252 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1660 | Iter Mean Loss 5.0731
2020-11-05 16:38:14,261 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8268 | Iter Mean Loss 6.3243
2020-11-05 16:38:14,270 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0746 | Iter Mean Loss 6.5119
2020-11-05 16:38:14,279 - root - INFO - Training: Epoch 0831 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2907 | Iter Mean Loss 5.8676
2020-11-05 16:38:14,280 - root - INFO - Evaluate: Epoch 0831 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:38:14,288 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9718 | Iter Mean Loss 8.9718
2020-11-05 16:38:14,295 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1642 | Iter Mean Loss 5.0680
2020-11-05 16:38:14,303 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8163 | Iter Mean Loss 6.3174
2020-11-05 16:38:14,312 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0686 | Iter Mean Loss 6.5052
2020-11-05 16:38:14,317 - root - INFO - Training: Epoch 0832 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2892 | Iter Mean Loss 5.8620
2020-11-05 16:38:14,318 - root - INFO - Evaluate: Epoch 0832 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:38:14,327 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9635 | Iter Mean Loss 8.9635
2020-11-05 16:38:14,335 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1624 | Iter Mean Loss 5.0629
2020-11-05 16:38:14,341 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.8058 | Iter Mean Loss 6.3106
2020-11-05 16:38:14,349 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0625 | Iter Mean Loss 6.4986
2020-11-05 16:38:14,355 - root - INFO - Training: Epoch 0833 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2877 | Iter Mean Loss 5.8564
2020-11-05 16:38:14,356 - root - INFO - Evaluate: Epoch 0833 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:38:14,364 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9551 | Iter Mean Loss 8.9551
2020-11-05 16:38:14,371 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1606 | Iter Mean Loss 5.0579
2020-11-05 16:38:14,380 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7953 | Iter Mean Loss 6.3037
2020-11-05 16:38:14,386 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0565 | Iter Mean Loss 6.4919
2020-11-05 16:38:14,392 - root - INFO - Training: Epoch 0834 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2862 | Iter Mean Loss 5.8508
2020-11-05 16:38:14,393 - root - INFO - Evaluate: Epoch 0834 | NDCG 1.0000 | MSE 0.1732
2020-11-05 16:38:14,400 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9468 | Iter Mean Loss 8.9468
2020-11-05 16:38:14,407 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1588 | Iter Mean Loss 5.0528
2020-11-05 16:38:14,414 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7849 | Iter Mean Loss 6.2968
2020-11-05 16:38:14,422 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0504 | Iter Mean Loss 6.4852
2020-11-05 16:38:14,428 - root - INFO - Training: Epoch 0835 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2847 | Iter Mean Loss 5.8451
2020-11-05 16:38:14,429 - root - INFO - Evaluate: Epoch 0835 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:38:14,436 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9385 | Iter Mean Loss 8.9385
2020-11-05 16:38:14,443 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1570 | Iter Mean Loss 5.0478
2020-11-05 16:38:14,449 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7744 | Iter Mean Loss 6.2900
2020-11-05 16:38:14,456 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0443 | Iter Mean Loss 6.4786
2020-11-05 16:38:14,461 - root - INFO - Training: Epoch 0836 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2832 | Iter Mean Loss 5.8395
2020-11-05 16:38:14,462 - root - INFO - Evaluate: Epoch 0836 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:38:14,469 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9302 | Iter Mean Loss 8.9302
2020-11-05 16:38:14,475 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1552 | Iter Mean Loss 5.0427
2020-11-05 16:38:14,481 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7640 | Iter Mean Loss 6.2831
2020-11-05 16:38:14,487 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0382 | Iter Mean Loss 6.4719
2020-11-05 16:38:14,492 - root - INFO - Training: Epoch 0837 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2817 | Iter Mean Loss 5.8339
2020-11-05 16:38:14,493 - root - INFO - Evaluate: Epoch 0837 | NDCG 1.0000 | MSE 0.1731
2020-11-05 16:38:14,499 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9219 | Iter Mean Loss 8.9219
2020-11-05 16:38:14,505 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1534 | Iter Mean Loss 5.0376
2020-11-05 16:38:14,512 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7536 | Iter Mean Loss 6.2763
2020-11-05 16:38:14,518 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0320 | Iter Mean Loss 6.4652
2020-11-05 16:38:14,524 - root - INFO - Training: Epoch 0838 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2802 | Iter Mean Loss 5.8282
2020-11-05 16:38:14,525 - root - INFO - Evaluate: Epoch 0838 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:38:14,531 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9136 | Iter Mean Loss 8.9136
2020-11-05 16:38:14,537 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1516 | Iter Mean Loss 5.0326
2020-11-05 16:38:14,544 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7432 | Iter Mean Loss 6.2695
2020-11-05 16:38:14,550 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0259 | Iter Mean Loss 6.4586
2020-11-05 16:38:14,557 - root - INFO - Training: Epoch 0839 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2786 | Iter Mean Loss 5.8226
2020-11-05 16:38:14,558 - root - INFO - Evaluate: Epoch 0839 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:38:14,565 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.9053 | Iter Mean Loss 8.9053
2020-11-05 16:38:14,572 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1498 | Iter Mean Loss 5.0275
2020-11-05 16:38:14,578 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7329 | Iter Mean Loss 6.2626
2020-11-05 16:38:14,585 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0197 | Iter Mean Loss 6.4519
2020-11-05 16:38:14,591 - root - INFO - Training: Epoch 0840 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2771 | Iter Mean Loss 5.8170
2020-11-05 16:38:14,592 - root - INFO - Evaluate: Epoch 0840 | NDCG 1.0000 | MSE 0.1730
2020-11-05 16:38:14,598 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8970 | Iter Mean Loss 8.8970
2020-11-05 16:38:14,605 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1479 | Iter Mean Loss 5.0225
2020-11-05 16:38:14,611 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7225 | Iter Mean Loss 6.2558
2020-11-05 16:38:14,617 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0135 | Iter Mean Loss 6.4452
2020-11-05 16:38:14,623 - root - INFO - Training: Epoch 0841 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2756 | Iter Mean Loss 5.8113
2020-11-05 16:38:14,624 - root - INFO - Evaluate: Epoch 0841 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:38:14,630 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8887 | Iter Mean Loss 8.8887
2020-11-05 16:38:14,635 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1461 | Iter Mean Loss 5.0174
2020-11-05 16:38:14,641 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7122 | Iter Mean Loss 6.2490
2020-11-05 16:38:14,647 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0073 | Iter Mean Loss 6.4386
2020-11-05 16:38:14,653 - root - INFO - Training: Epoch 0842 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2741 | Iter Mean Loss 5.8057
2020-11-05 16:38:14,654 - root - INFO - Evaluate: Epoch 0842 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:38:14,660 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8805 | Iter Mean Loss 8.8805
2020-11-05 16:38:14,666 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1443 | Iter Mean Loss 5.0124
2020-11-05 16:38:14,672 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.7019 | Iter Mean Loss 6.2422
2020-11-05 16:38:14,678 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 7.0011 | Iter Mean Loss 6.4319
2020-11-05 16:38:14,683 - root - INFO - Training: Epoch 0843 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2726 | Iter Mean Loss 5.8001
2020-11-05 16:38:14,684 - root - INFO - Evaluate: Epoch 0843 | NDCG 1.0000 | MSE 0.1729
2020-11-05 16:38:14,690 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8722 | Iter Mean Loss 8.8722
2020-11-05 16:38:14,696 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1425 | Iter Mean Loss 5.0073
2020-11-05 16:38:14,702 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6916 | Iter Mean Loss 6.2354
2020-11-05 16:38:14,709 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9948 | Iter Mean Loss 6.4253
2020-11-05 16:38:14,714 - root - INFO - Training: Epoch 0844 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2711 | Iter Mean Loss 5.7944
2020-11-05 16:38:14,715 - root - INFO - Evaluate: Epoch 0844 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:38:14,722 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8639 | Iter Mean Loss 8.8639
2020-11-05 16:38:14,728 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1407 | Iter Mean Loss 5.0023
2020-11-05 16:38:14,735 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6814 | Iter Mean Loss 6.2286
2020-11-05 16:38:14,742 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9885 | Iter Mean Loss 6.4186
2020-11-05 16:38:14,747 - root - INFO - Training: Epoch 0845 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2696 | Iter Mean Loss 5.7888
2020-11-05 16:38:14,749 - root - INFO - Evaluate: Epoch 0845 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:38:14,756 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8557 | Iter Mean Loss 8.8557
2020-11-05 16:38:14,762 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1388 | Iter Mean Loss 4.9973
2020-11-05 16:38:14,770 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6711 | Iter Mean Loss 6.2219
2020-11-05 16:38:14,777 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9822 | Iter Mean Loss 6.4120
2020-11-05 16:38:14,782 - root - INFO - Training: Epoch 0846 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2681 | Iter Mean Loss 5.7832
2020-11-05 16:38:14,784 - root - INFO - Evaluate: Epoch 0846 | NDCG 1.0000 | MSE 0.1728
2020-11-05 16:38:14,791 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8474 | Iter Mean Loss 8.8474
2020-11-05 16:38:14,797 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1370 | Iter Mean Loss 4.9922
2020-11-05 16:38:14,803 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6609 | Iter Mean Loss 6.2151
2020-11-05 16:38:14,809 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9759 | Iter Mean Loss 6.4053
2020-11-05 16:38:14,815 - root - INFO - Training: Epoch 0847 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2666 | Iter Mean Loss 5.7776
2020-11-05 16:38:14,816 - root - INFO - Evaluate: Epoch 0847 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:38:14,822 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8392 | Iter Mean Loss 8.8392
2020-11-05 16:38:14,828 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1352 | Iter Mean Loss 4.9872
2020-11-05 16:38:14,834 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6507 | Iter Mean Loss 6.2083
2020-11-05 16:38:14,840 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9696 | Iter Mean Loss 6.3987
2020-11-05 16:38:14,845 - root - INFO - Training: Epoch 0848 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2651 | Iter Mean Loss 5.7719
2020-11-05 16:38:14,846 - root - INFO - Evaluate: Epoch 0848 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:38:14,852 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8309 | Iter Mean Loss 8.8309
2020-11-05 16:38:14,858 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1334 | Iter Mean Loss 4.9822
2020-11-05 16:38:14,864 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6405 | Iter Mean Loss 6.2016
2020-11-05 16:38:14,869 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9633 | Iter Mean Loss 6.3920
2020-11-05 16:38:14,874 - root - INFO - Training: Epoch 0849 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2635 | Iter Mean Loss 5.7663
2020-11-05 16:38:14,875 - root - INFO - Evaluate: Epoch 0849 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:38:14,881 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8227 | Iter Mean Loss 8.8227
2020-11-05 16:38:14,887 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1316 | Iter Mean Loss 4.9771
2020-11-05 16:38:14,893 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6303 | Iter Mean Loss 6.1949
2020-11-05 16:38:14,899 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9569 | Iter Mean Loss 6.3854
2020-11-05 16:38:14,904 - root - INFO - Training: Epoch 0850 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2620 | Iter Mean Loss 5.7607
2020-11-05 16:38:14,905 - root - INFO - Evaluate: Epoch 0850 | NDCG 1.0000 | MSE 0.1727
2020-11-05 16:38:14,912 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8145 | Iter Mean Loss 8.8145
2020-11-05 16:38:14,918 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1298 | Iter Mean Loss 4.9721
2020-11-05 16:38:14,925 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6201 | Iter Mean Loss 6.1881
2020-11-05 16:38:14,931 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9505 | Iter Mean Loss 6.3787
2020-11-05 16:38:14,937 - root - INFO - Training: Epoch 0851 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2605 | Iter Mean Loss 5.7551
2020-11-05 16:38:14,939 - root - INFO - Evaluate: Epoch 0851 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:38:14,945 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.8063 | Iter Mean Loss 8.8063
2020-11-05 16:38:14,951 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1280 | Iter Mean Loss 4.9671
2020-11-05 16:38:14,959 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.6100 | Iter Mean Loss 6.1814
2020-11-05 16:38:14,965 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9442 | Iter Mean Loss 6.3721
2020-11-05 16:38:14,971 - root - INFO - Training: Epoch 0852 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2590 | Iter Mean Loss 5.7495
2020-11-05 16:38:14,973 - root - INFO - Evaluate: Epoch 0852 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:38:14,979 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7981 | Iter Mean Loss 8.7981
2020-11-05 16:38:14,985 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1262 | Iter Mean Loss 4.9621
2020-11-05 16:38:14,992 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5999 | Iter Mean Loss 6.1747
2020-11-05 16:38:14,998 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9378 | Iter Mean Loss 6.3655
2020-11-05 16:38:15,004 - root - INFO - Training: Epoch 0853 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2575 | Iter Mean Loss 5.7439
2020-11-05 16:38:15,005 - root - INFO - Evaluate: Epoch 0853 | NDCG 1.0000 | MSE 0.1726
2020-11-05 16:38:15,011 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7899 | Iter Mean Loss 8.7899
2020-11-05 16:38:15,018 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1244 | Iter Mean Loss 4.9571
2020-11-05 16:38:15,024 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5898 | Iter Mean Loss 6.1680
2020-11-05 16:38:15,029 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9313 | Iter Mean Loss 6.3589
2020-11-05 16:38:15,035 - root - INFO - Training: Epoch 0854 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2560 | Iter Mean Loss 5.7383
2020-11-05 16:38:15,036 - root - INFO - Evaluate: Epoch 0854 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:38:15,041 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7817 | Iter Mean Loss 8.7817
2020-11-05 16:38:15,047 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1226 | Iter Mean Loss 4.9521
2020-11-05 16:38:15,053 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5797 | Iter Mean Loss 6.1613
2020-11-05 16:38:15,059 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9249 | Iter Mean Loss 6.3522
2020-11-05 16:38:15,064 - root - INFO - Training: Epoch 0855 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2545 | Iter Mean Loss 5.7327
2020-11-05 16:38:15,065 - root - INFO - Evaluate: Epoch 0855 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:38:15,071 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7735 | Iter Mean Loss 8.7735
2020-11-05 16:38:15,077 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1208 | Iter Mean Loss 4.9472
2020-11-05 16:38:15,083 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5697 | Iter Mean Loss 6.1547
2020-11-05 16:38:15,088 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9185 | Iter Mean Loss 6.3456
2020-11-05 16:38:15,094 - root - INFO - Training: Epoch 0856 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2530 | Iter Mean Loss 5.7271
2020-11-05 16:38:15,094 - root - INFO - Evaluate: Epoch 0856 | NDCG 1.0000 | MSE 0.1725
2020-11-05 16:38:15,100 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7654 | Iter Mean Loss 8.7654
2020-11-05 16:38:15,106 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1190 | Iter Mean Loss 4.9422
2020-11-05 16:38:15,112 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5597 | Iter Mean Loss 6.1480
2020-11-05 16:38:15,120 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9120 | Iter Mean Loss 6.3390
2020-11-05 16:38:15,126 - root - INFO - Training: Epoch 0857 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2515 | Iter Mean Loss 5.7215
2020-11-05 16:38:15,127 - root - INFO - Evaluate: Epoch 0857 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:38:15,133 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7572 | Iter Mean Loss 8.7572
2020-11-05 16:38:15,140 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1172 | Iter Mean Loss 4.9372
2020-11-05 16:38:15,146 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5497 | Iter Mean Loss 6.1414
2020-11-05 16:38:15,154 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.9056 | Iter Mean Loss 6.3324
2020-11-05 16:38:15,159 - root - INFO - Training: Epoch 0858 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2500 | Iter Mean Loss 5.7159
2020-11-05 16:38:15,160 - root - INFO - Evaluate: Epoch 0858 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:38:15,168 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7491 | Iter Mean Loss 8.7491
2020-11-05 16:38:15,174 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1154 | Iter Mean Loss 4.9323
2020-11-05 16:38:15,180 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5397 | Iter Mean Loss 6.1347
2020-11-05 16:38:15,188 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8991 | Iter Mean Loss 6.3258
2020-11-05 16:38:15,193 - root - INFO - Training: Epoch 0859 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2485 | Iter Mean Loss 5.7104
2020-11-05 16:38:15,194 - root - INFO - Evaluate: Epoch 0859 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:38:15,201 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7409 | Iter Mean Loss 8.7409
2020-11-05 16:38:15,207 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1137 | Iter Mean Loss 4.9273
2020-11-05 16:38:15,213 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5297 | Iter Mean Loss 6.1281
2020-11-05 16:38:15,220 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8926 | Iter Mean Loss 6.3192
2020-11-05 16:38:15,226 - root - INFO - Training: Epoch 0860 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2470 | Iter Mean Loss 5.7048
2020-11-05 16:38:15,227 - root - INFO - Evaluate: Epoch 0860 | NDCG 1.0000 | MSE 0.1724
2020-11-05 16:38:15,233 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7328 | Iter Mean Loss 8.7328
2020-11-05 16:38:15,238 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1119 | Iter Mean Loss 4.9224
2020-11-05 16:38:15,244 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5197 | Iter Mean Loss 6.1215
2020-11-05 16:38:15,250 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8861 | Iter Mean Loss 6.3127
2020-11-05 16:38:15,255 - root - INFO - Training: Epoch 0861 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2456 | Iter Mean Loss 5.6992
2020-11-05 16:38:15,256 - root - INFO - Evaluate: Epoch 0861 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:38:15,262 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7247 | Iter Mean Loss 8.7247
2020-11-05 16:38:15,268 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1101 | Iter Mean Loss 4.9174
2020-11-05 16:38:15,274 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.5098 | Iter Mean Loss 6.1149
2020-11-05 16:38:15,280 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8796 | Iter Mean Loss 6.3061
2020-11-05 16:38:15,285 - root - INFO - Training: Epoch 0862 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2441 | Iter Mean Loss 5.6937
2020-11-05 16:38:15,286 - root - INFO - Evaluate: Epoch 0862 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:38:15,291 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7167 | Iter Mean Loss 8.7167
2020-11-05 16:38:15,297 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1084 | Iter Mean Loss 4.9125
2020-11-05 16:38:15,303 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4999 | Iter Mean Loss 6.1083
2020-11-05 16:38:15,310 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8731 | Iter Mean Loss 6.2995
2020-11-05 16:38:15,317 - root - INFO - Training: Epoch 0863 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2426 | Iter Mean Loss 5.6881
2020-11-05 16:38:15,318 - root - INFO - Evaluate: Epoch 0863 | NDCG 1.0000 | MSE 0.1723
2020-11-05 16:38:15,325 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7086 | Iter Mean Loss 8.7086
2020-11-05 16:38:15,332 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1066 | Iter Mean Loss 4.9076
2020-11-05 16:38:15,338 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4900 | Iter Mean Loss 6.1017
2020-11-05 16:38:15,345 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8666 | Iter Mean Loss 6.2930
2020-11-05 16:38:15,351 - root - INFO - Training: Epoch 0864 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2411 | Iter Mean Loss 5.6826
2020-11-05 16:38:15,352 - root - INFO - Evaluate: Epoch 0864 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:38:15,359 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.7005 | Iter Mean Loss 8.7005
2020-11-05 16:38:15,366 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1049 | Iter Mean Loss 4.9027
2020-11-05 16:38:15,372 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4802 | Iter Mean Loss 6.0952
2020-11-05 16:38:15,379 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8601 | Iter Mean Loss 6.2864
2020-11-05 16:38:15,385 - root - INFO - Training: Epoch 0865 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2397 | Iter Mean Loss 5.6771
2020-11-05 16:38:15,386 - root - INFO - Evaluate: Epoch 0865 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:38:15,392 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6925 | Iter Mean Loss 8.6925
2020-11-05 16:38:15,399 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1031 | Iter Mean Loss 4.8978
2020-11-05 16:38:15,405 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4703 | Iter Mean Loss 6.0886
2020-11-05 16:38:15,411 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8536 | Iter Mean Loss 6.2799
2020-11-05 16:38:15,417 - root - INFO - Training: Epoch 0866 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2382 | Iter Mean Loss 5.6716
2020-11-05 16:38:15,418 - root - INFO - Evaluate: Epoch 0866 | NDCG 1.0000 | MSE 0.1722
2020-11-05 16:38:15,425 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6844 | Iter Mean Loss 8.6844
2020-11-05 16:38:15,430 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.1014 | Iter Mean Loss 4.8929
2020-11-05 16:38:15,436 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4605 | Iter Mean Loss 6.0821
2020-11-05 16:38:15,442 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8471 | Iter Mean Loss 6.2734
2020-11-05 16:38:15,447 - root - INFO - Training: Epoch 0867 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2367 | Iter Mean Loss 5.6660
2020-11-05 16:38:15,448 - root - INFO - Evaluate: Epoch 0867 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:38:15,454 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6764 | Iter Mean Loss 8.6764
2020-11-05 16:38:15,461 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0997 | Iter Mean Loss 4.8881
2020-11-05 16:38:15,467 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4507 | Iter Mean Loss 6.0756
2020-11-05 16:38:15,474 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8405 | Iter Mean Loss 6.2668
2020-11-05 16:38:15,480 - root - INFO - Training: Epoch 0868 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2353 | Iter Mean Loss 5.6605
2020-11-05 16:38:15,481 - root - INFO - Evaluate: Epoch 0868 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:38:15,487 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6684 | Iter Mean Loss 8.6684
2020-11-05 16:38:15,495 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0980 | Iter Mean Loss 4.8832
2020-11-05 16:38:15,503 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4409 | Iter Mean Loss 6.0691
2020-11-05 16:38:15,510 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8340 | Iter Mean Loss 6.2603
2020-11-05 16:38:15,517 - root - INFO - Training: Epoch 0869 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2339 | Iter Mean Loss 5.6550
2020-11-05 16:38:15,518 - root - INFO - Evaluate: Epoch 0869 | NDCG 1.0000 | MSE 0.1721
2020-11-05 16:38:15,526 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6605 | Iter Mean Loss 8.6605
2020-11-05 16:38:15,535 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0963 | Iter Mean Loss 4.8784
2020-11-05 16:38:15,541 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4312 | Iter Mean Loss 6.0626
2020-11-05 16:38:15,548 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8275 | Iter Mean Loss 6.2538
2020-11-05 16:38:15,554 - root - INFO - Training: Epoch 0870 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2324 | Iter Mean Loss 5.6496
2020-11-05 16:38:15,555 - root - INFO - Evaluate: Epoch 0870 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:38:15,564 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6525 | Iter Mean Loss 8.6525
2020-11-05 16:38:15,570 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0946 | Iter Mean Loss 4.8735
2020-11-05 16:38:15,577 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4215 | Iter Mean Loss 6.0562
2020-11-05 16:38:15,586 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8210 | Iter Mean Loss 6.2474
2020-11-05 16:38:15,593 - root - INFO - Training: Epoch 0871 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2310 | Iter Mean Loss 5.6441
2020-11-05 16:38:15,595 - root - INFO - Evaluate: Epoch 0871 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:38:15,605 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6445 | Iter Mean Loss 8.6445
2020-11-05 16:38:15,615 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0929 | Iter Mean Loss 4.8687
2020-11-05 16:38:15,623 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4118 | Iter Mean Loss 6.0497
2020-11-05 16:38:15,630 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8144 | Iter Mean Loss 6.2409
2020-11-05 16:38:15,635 - root - INFO - Training: Epoch 0872 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2296 | Iter Mean Loss 5.6386
2020-11-05 16:38:15,636 - root - INFO - Evaluate: Epoch 0872 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:38:15,642 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6366 | Iter Mean Loss 8.6366
2020-11-05 16:38:15,649 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0912 | Iter Mean Loss 4.8639
2020-11-05 16:38:15,654 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.4021 | Iter Mean Loss 6.0433
2020-11-05 16:38:15,660 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8079 | Iter Mean Loss 6.2344
2020-11-05 16:38:15,666 - root - INFO - Training: Epoch 0873 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2281 | Iter Mean Loss 5.6332
2020-11-05 16:38:15,667 - root - INFO - Evaluate: Epoch 0873 | NDCG 1.0000 | MSE 0.1720
2020-11-05 16:38:15,673 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6287 | Iter Mean Loss 8.6287
2020-11-05 16:38:15,679 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0895 | Iter Mean Loss 4.8591
2020-11-05 16:38:15,685 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3924 | Iter Mean Loss 6.0369
2020-11-05 16:38:15,690 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.8014 | Iter Mean Loss 6.2280
2020-11-05 16:38:15,695 - root - INFO - Training: Epoch 0874 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2267 | Iter Mean Loss 5.6277
2020-11-05 16:38:15,696 - root - INFO - Evaluate: Epoch 0874 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:38:15,702 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6208 | Iter Mean Loss 8.6208
2020-11-05 16:38:15,708 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0878 | Iter Mean Loss 4.8543
2020-11-05 16:38:15,713 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3828 | Iter Mean Loss 6.0305
2020-11-05 16:38:15,719 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7948 | Iter Mean Loss 6.2216
2020-11-05 16:38:15,724 - root - INFO - Training: Epoch 0875 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2253 | Iter Mean Loss 5.6223
2020-11-05 16:38:15,725 - root - INFO - Evaluate: Epoch 0875 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:38:15,732 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6129 | Iter Mean Loss 8.6129
2020-11-05 16:38:15,738 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0862 | Iter Mean Loss 4.8496
2020-11-05 16:38:15,744 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3731 | Iter Mean Loss 6.0241
2020-11-05 16:38:15,750 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7883 | Iter Mean Loss 6.2151
2020-11-05 16:38:15,756 - root - INFO - Training: Epoch 0876 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2239 | Iter Mean Loss 5.6169
2020-11-05 16:38:15,757 - root - INFO - Evaluate: Epoch 0876 | NDCG 1.0000 | MSE 0.1719
2020-11-05 16:38:15,763 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.6051 | Iter Mean Loss 8.6051
2020-11-05 16:38:15,769 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0845 | Iter Mean Loss 4.8448
2020-11-05 16:38:15,775 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3635 | Iter Mean Loss 6.0177
2020-11-05 16:38:15,782 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7818 | Iter Mean Loss 6.2087
2020-11-05 16:38:15,787 - root - INFO - Training: Epoch 0877 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2225 | Iter Mean Loss 5.6115
2020-11-05 16:38:15,788 - root - INFO - Evaluate: Epoch 0877 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:38:15,794 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5972 | Iter Mean Loss 8.5972
2020-11-05 16:38:15,800 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0829 | Iter Mean Loss 4.8401
2020-11-05 16:38:15,806 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3540 | Iter Mean Loss 6.0114
2020-11-05 16:38:15,812 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7753 | Iter Mean Loss 6.2024
2020-11-05 16:38:15,817 - root - INFO - Training: Epoch 0878 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2211 | Iter Mean Loss 5.6061
2020-11-05 16:38:15,818 - root - INFO - Evaluate: Epoch 0878 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:38:15,825 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5894 | Iter Mean Loss 8.5894
2020-11-05 16:38:15,830 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0813 | Iter Mean Loss 4.8353
2020-11-05 16:38:15,836 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3444 | Iter Mean Loss 6.0050
2020-11-05 16:38:15,841 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7688 | Iter Mean Loss 6.1960
2020-11-05 16:38:15,846 - root - INFO - Training: Epoch 0879 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2198 | Iter Mean Loss 5.6007
2020-11-05 16:38:15,847 - root - INFO - Evaluate: Epoch 0879 | NDCG 1.0000 | MSE 0.1718
2020-11-05 16:38:15,853 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5816 | Iter Mean Loss 8.5816
2020-11-05 16:38:15,858 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0797 | Iter Mean Loss 4.8306
2020-11-05 16:38:15,864 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3349 | Iter Mean Loss 5.9987
2020-11-05 16:38:15,870 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7623 | Iter Mean Loss 6.1896
2020-11-05 16:38:15,875 - root - INFO - Training: Epoch 0880 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2184 | Iter Mean Loss 5.5954
2020-11-05 16:38:15,875 - root - INFO - Evaluate: Epoch 0880 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:38:15,881 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5738 | Iter Mean Loss 8.5738
2020-11-05 16:38:15,887 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0781 | Iter Mean Loss 4.8260
2020-11-05 16:38:15,892 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3254 | Iter Mean Loss 5.9924
2020-11-05 16:38:15,898 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7558 | Iter Mean Loss 6.1833
2020-11-05 16:38:15,903 - root - INFO - Training: Epoch 0881 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2170 | Iter Mean Loss 5.5900
2020-11-05 16:38:15,903 - root - INFO - Evaluate: Epoch 0881 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:38:15,909 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5661 | Iter Mean Loss 8.5661
2020-11-05 16:38:15,915 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0765 | Iter Mean Loss 4.8213
2020-11-05 16:38:15,920 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3159 | Iter Mean Loss 5.9862
2020-11-05 16:38:15,926 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7493 | Iter Mean Loss 6.1769
2020-11-05 16:38:15,931 - root - INFO - Training: Epoch 0882 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2157 | Iter Mean Loss 5.5847
2020-11-05 16:38:15,933 - root - INFO - Evaluate: Epoch 0882 | NDCG 1.0000 | MSE 0.1717
2020-11-05 16:38:15,939 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5583 | Iter Mean Loss 8.5583
2020-11-05 16:38:15,944 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0749 | Iter Mean Loss 4.8166
2020-11-05 16:38:15,950 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.3064 | Iter Mean Loss 5.9799
2020-11-05 16:38:15,956 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7429 | Iter Mean Loss 6.1706
2020-11-05 16:38:15,962 - root - INFO - Training: Epoch 0883 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2143 | Iter Mean Loss 5.5794
2020-11-05 16:38:15,962 - root - INFO - Evaluate: Epoch 0883 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:38:15,968 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5506 | Iter Mean Loss 8.5506
2020-11-05 16:38:15,975 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0733 | Iter Mean Loss 4.8120
2020-11-05 16:38:15,981 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2970 | Iter Mean Loss 5.9736
2020-11-05 16:38:15,987 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7364 | Iter Mean Loss 6.1643
2020-11-05 16:38:15,993 - root - INFO - Training: Epoch 0884 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2130 | Iter Mean Loss 5.5741
2020-11-05 16:38:15,994 - root - INFO - Evaluate: Epoch 0884 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:38:15,999 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5429 | Iter Mean Loss 8.5429
2020-11-05 16:38:16,006 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0718 | Iter Mean Loss 4.8073
2020-11-05 16:38:16,012 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2876 | Iter Mean Loss 5.9674
2020-11-05 16:38:16,018 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7299 | Iter Mean Loss 6.1581
2020-11-05 16:38:16,024 - root - INFO - Training: Epoch 0885 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2117 | Iter Mean Loss 5.5688
2020-11-05 16:38:16,025 - root - INFO - Evaluate: Epoch 0885 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:38:16,030 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5352 | Iter Mean Loss 8.5352
2020-11-05 16:38:16,036 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0702 | Iter Mean Loss 4.8027
2020-11-05 16:38:16,041 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2782 | Iter Mean Loss 5.9612
2020-11-05 16:38:16,047 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7235 | Iter Mean Loss 6.1518
2020-11-05 16:38:16,052 - root - INFO - Training: Epoch 0886 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2104 | Iter Mean Loss 5.5635
2020-11-05 16:38:16,053 - root - INFO - Evaluate: Epoch 0886 | NDCG 1.0000 | MSE 0.1716
2020-11-05 16:38:16,058 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5276 | Iter Mean Loss 8.5276
2020-11-05 16:38:16,064 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0687 | Iter Mean Loss 4.7981
2020-11-05 16:38:16,069 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2688 | Iter Mean Loss 5.9550
2020-11-05 16:38:16,075 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7171 | Iter Mean Loss 6.1455
2020-11-05 16:38:16,080 - root - INFO - Training: Epoch 0887 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2090 | Iter Mean Loss 5.5582
2020-11-05 16:38:16,081 - root - INFO - Evaluate: Epoch 0887 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:38:16,086 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5199 | Iter Mean Loss 8.5199
2020-11-05 16:38:16,092 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0672 | Iter Mean Loss 4.7936
2020-11-05 16:38:16,097 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2595 | Iter Mean Loss 5.9489
2020-11-05 16:38:16,103 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7107 | Iter Mean Loss 6.1393
2020-11-05 16:38:16,108 - root - INFO - Training: Epoch 0888 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2077 | Iter Mean Loss 5.5530
2020-11-05 16:38:16,109 - root - INFO - Evaluate: Epoch 0888 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:38:16,115 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5123 | Iter Mean Loss 8.5123
2020-11-05 16:38:16,121 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0657 | Iter Mean Loss 4.7890
2020-11-05 16:38:16,127 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2502 | Iter Mean Loss 5.9427
2020-11-05 16:38:16,133 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.7043 | Iter Mean Loss 6.1331
2020-11-05 16:38:16,138 - root - INFO - Training: Epoch 0889 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2065 | Iter Mean Loss 5.5478
2020-11-05 16:38:16,139 - root - INFO - Evaluate: Epoch 0889 | NDCG 1.0000 | MSE 0.1715
2020-11-05 16:38:16,145 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.5047 | Iter Mean Loss 8.5047
2020-11-05 16:38:16,151 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0642 | Iter Mean Loss 4.7845
2020-11-05 16:38:16,157 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2409 | Iter Mean Loss 5.9366
2020-11-05 16:38:16,163 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6979 | Iter Mean Loss 6.1269
2020-11-05 16:38:16,169 - root - INFO - Training: Epoch 0890 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2052 | Iter Mean Loss 5.5426
2020-11-05 16:38:16,170 - root - INFO - Evaluate: Epoch 0890 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:38:16,176 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4972 | Iter Mean Loss 8.4972
2020-11-05 16:38:16,182 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0627 | Iter Mean Loss 4.7799
2020-11-05 16:38:16,188 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2316 | Iter Mean Loss 5.9305
2020-11-05 16:38:16,194 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6915 | Iter Mean Loss 6.1208
2020-11-05 16:38:16,199 - root - INFO - Training: Epoch 0891 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2039 | Iter Mean Loss 5.5374
2020-11-05 16:38:16,200 - root - INFO - Evaluate: Epoch 0891 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:38:16,207 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4896 | Iter Mean Loss 8.4896
2020-11-05 16:38:16,212 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0612 | Iter Mean Loss 4.7754
2020-11-05 16:38:16,219 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2223 | Iter Mean Loss 5.9244
2020-11-05 16:38:16,225 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6852 | Iter Mean Loss 6.1146
2020-11-05 16:38:16,230 - root - INFO - Training: Epoch 0892 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2026 | Iter Mean Loss 5.5322
2020-11-05 16:38:16,231 - root - INFO - Evaluate: Epoch 0892 | NDCG 1.0000 | MSE 0.1714
2020-11-05 16:38:16,237 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4821 | Iter Mean Loss 8.4821
2020-11-05 16:38:16,242 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0598 | Iter Mean Loss 4.7709
2020-11-05 16:38:16,247 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2131 | Iter Mean Loss 5.9183
2020-11-05 16:38:16,253 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6789 | Iter Mean Loss 6.1085
2020-11-05 16:38:16,258 - root - INFO - Training: Epoch 0893 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2014 | Iter Mean Loss 5.5270
2020-11-05 16:38:16,259 - root - INFO - Evaluate: Epoch 0893 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:38:16,264 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4746 | Iter Mean Loss 8.4746
2020-11-05 16:38:16,270 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0583 | Iter Mean Loss 4.7665
2020-11-05 16:38:16,275 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.2039 | Iter Mean Loss 5.9123
2020-11-05 16:38:16,280 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6726 | Iter Mean Loss 6.1023
2020-11-05 16:38:16,285 - root - INFO - Training: Epoch 0894 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.2001 | Iter Mean Loss 5.5219
2020-11-05 16:38:16,286 - root - INFO - Evaluate: Epoch 0894 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:38:16,291 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4671 | Iter Mean Loss 8.4671
2020-11-05 16:38:16,297 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0569 | Iter Mean Loss 4.7620
2020-11-05 16:38:16,302 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1947 | Iter Mean Loss 5.9062
2020-11-05 16:38:16,308 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6663 | Iter Mean Loss 6.0963
2020-11-05 16:38:16,313 - root - INFO - Training: Epoch 0895 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1989 | Iter Mean Loss 5.5168
2020-11-05 16:38:16,314 - root - INFO - Evaluate: Epoch 0895 | NDCG 1.0000 | MSE 0.1713
2020-11-05 16:38:16,320 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4597 | Iter Mean Loss 8.4597
2020-11-05 16:38:16,327 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0555 | Iter Mean Loss 4.7576
2020-11-05 16:38:16,333 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1855 | Iter Mean Loss 5.9002
2020-11-05 16:38:16,339 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6600 | Iter Mean Loss 6.0902
2020-11-05 16:38:16,344 - root - INFO - Training: Epoch 0896 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1977 | Iter Mean Loss 5.5117
2020-11-05 16:38:16,345 - root - INFO - Evaluate: Epoch 0896 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:38:16,351 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4522 | Iter Mean Loss 8.4522
2020-11-05 16:38:16,358 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0541 | Iter Mean Loss 4.7532
2020-11-05 16:38:16,363 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1764 | Iter Mean Loss 5.8942
2020-11-05 16:38:16,369 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6538 | Iter Mean Loss 6.0841
2020-11-05 16:38:16,375 - root - INFO - Training: Epoch 0897 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1965 | Iter Mean Loss 5.5066
2020-11-05 16:38:16,376 - root - INFO - Evaluate: Epoch 0897 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:38:16,382 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4448 | Iter Mean Loss 8.4448
2020-11-05 16:38:16,389 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0527 | Iter Mean Loss 4.7488
2020-11-05 16:38:16,395 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1673 | Iter Mean Loss 5.8883
2020-11-05 16:38:16,400 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6475 | Iter Mean Loss 6.0781
2020-11-05 16:38:16,406 - root - INFO - Training: Epoch 0898 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1953 | Iter Mean Loss 5.5015
2020-11-05 16:38:16,407 - root - INFO - Evaluate: Epoch 0898 | NDCG 1.0000 | MSE 0.1712
2020-11-05 16:38:16,413 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4375 | Iter Mean Loss 8.4375
2020-11-05 16:38:16,419 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0513 | Iter Mean Loss 4.7444
2020-11-05 16:38:16,425 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1582 | Iter Mean Loss 5.8823
2020-11-05 16:38:16,431 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6413 | Iter Mean Loss 6.0721
2020-11-05 16:38:16,436 - root - INFO - Training: Epoch 0899 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1941 | Iter Mean Loss 5.4965
2020-11-05 16:38:16,437 - root - INFO - Evaluate: Epoch 0899 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:38:16,442 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4301 | Iter Mean Loss 8.4301
2020-11-05 16:38:16,448 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0500 | Iter Mean Loss 4.7400
2020-11-05 16:38:16,453 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1491 | Iter Mean Loss 5.8764
2020-11-05 16:38:16,459 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6352 | Iter Mean Loss 6.0661
2020-11-05 16:38:16,463 - root - INFO - Training: Epoch 0900 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1929 | Iter Mean Loss 5.4914
2020-11-05 16:38:16,464 - root - INFO - Evaluate: Epoch 0900 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:38:16,470 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4227 | Iter Mean Loss 8.4227
2020-11-05 16:38:16,475 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0486 | Iter Mean Loss 4.7357
2020-11-05 16:38:16,481 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1400 | Iter Mean Loss 5.8705
2020-11-05 16:38:16,486 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6290 | Iter Mean Loss 6.0601
2020-11-05 16:38:16,491 - root - INFO - Training: Epoch 0901 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1917 | Iter Mean Loss 5.4864
2020-11-05 16:38:16,492 - root - INFO - Evaluate: Epoch 0901 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:38:16,497 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4154 | Iter Mean Loss 8.4154
2020-11-05 16:38:16,503 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0473 | Iter Mean Loss 4.7314
2020-11-05 16:38:16,508 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1310 | Iter Mean Loss 5.8646
2020-11-05 16:38:16,513 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6229 | Iter Mean Loss 6.0541
2020-11-05 16:38:16,518 - root - INFO - Training: Epoch 0902 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1906 | Iter Mean Loss 5.4814
2020-11-05 16:38:16,519 - root - INFO - Evaluate: Epoch 0902 | NDCG 1.0000 | MSE 0.1711
2020-11-05 16:38:16,525 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4081 | Iter Mean Loss 8.4081
2020-11-05 16:38:16,530 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0460 | Iter Mean Loss 4.7271
2020-11-05 16:38:16,536 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1220 | Iter Mean Loss 5.8587
2020-11-05 16:38:16,542 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6168 | Iter Mean Loss 6.0482
2020-11-05 16:38:16,547 - root - INFO - Training: Epoch 0903 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1894 | Iter Mean Loss 5.4765
2020-11-05 16:38:16,548 - root - INFO - Evaluate: Epoch 0903 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:38:16,554 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.4009 | Iter Mean Loss 8.4009
2020-11-05 16:38:16,560 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0446 | Iter Mean Loss 4.7228
2020-11-05 16:38:16,566 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1130 | Iter Mean Loss 5.8528
2020-11-05 16:38:16,572 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6107 | Iter Mean Loss 6.0423
2020-11-05 16:38:16,577 - root - INFO - Training: Epoch 0904 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1883 | Iter Mean Loss 5.4715
2020-11-05 16:38:16,578 - root - INFO - Evaluate: Epoch 0904 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:38:16,584 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3936 | Iter Mean Loss 8.3936
2020-11-05 16:38:16,590 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0434 | Iter Mean Loss 4.7185
2020-11-05 16:38:16,596 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.1040 | Iter Mean Loss 5.8470
2020-11-05 16:38:16,602 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.6046 | Iter Mean Loss 6.0364
2020-11-05 16:38:16,607 - root - INFO - Training: Epoch 0905 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1872 | Iter Mean Loss 5.4666
2020-11-05 16:38:16,608 - root - INFO - Evaluate: Epoch 0905 | NDCG 1.0000 | MSE 0.1710
2020-11-05 16:38:16,614 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3864 | Iter Mean Loss 8.3864
2020-11-05 16:38:16,619 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0421 | Iter Mean Loss 4.7142
2020-11-05 16:38:16,625 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0951 | Iter Mean Loss 5.8412
2020-11-05 16:38:16,631 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5986 | Iter Mean Loss 6.0305
2020-11-05 16:38:16,636 - root - INFO - Training: Epoch 0906 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1861 | Iter Mean Loss 5.4616
2020-11-05 16:38:16,637 - root - INFO - Evaluate: Epoch 0906 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:38:16,642 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3792 | Iter Mean Loss 8.3792
2020-11-05 16:38:16,648 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0408 | Iter Mean Loss 4.7100
2020-11-05 16:38:16,654 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0862 | Iter Mean Loss 5.8354
2020-11-05 16:38:16,659 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5926 | Iter Mean Loss 6.0247
2020-11-05 16:38:16,664 - root - INFO - Training: Epoch 0907 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1849 | Iter Mean Loss 5.4567
2020-11-05 16:38:16,665 - root - INFO - Evaluate: Epoch 0907 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:38:16,670 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3720 | Iter Mean Loss 8.3720
2020-11-05 16:38:16,676 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0395 | Iter Mean Loss 4.7058
2020-11-05 16:38:16,681 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0773 | Iter Mean Loss 5.8296
2020-11-05 16:38:16,687 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5866 | Iter Mean Loss 6.0189
2020-11-05 16:38:16,691 - root - INFO - Training: Epoch 0908 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1838 | Iter Mean Loss 5.4519
2020-11-05 16:38:16,692 - root - INFO - Evaluate: Epoch 0908 | NDCG 1.0000 | MSE 0.1709
2020-11-05 16:38:16,698 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3649 | Iter Mean Loss 8.3649
2020-11-05 16:38:16,703 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0383 | Iter Mean Loss 4.7016
2020-11-05 16:38:16,708 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0684 | Iter Mean Loss 5.8239
2020-11-05 16:38:16,713 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5806 | Iter Mean Loss 6.0131
2020-11-05 16:38:16,718 - root - INFO - Training: Epoch 0909 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1828 | Iter Mean Loss 5.4470
2020-11-05 16:38:16,719 - root - INFO - Evaluate: Epoch 0909 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:38:16,724 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3578 | Iter Mean Loss 8.3578
2020-11-05 16:38:16,730 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0371 | Iter Mean Loss 4.6974
2020-11-05 16:38:16,735 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0595 | Iter Mean Loss 5.8181
2020-11-05 16:38:16,741 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5747 | Iter Mean Loss 6.0073
2020-11-05 16:38:16,746 - root - INFO - Training: Epoch 0910 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1817 | Iter Mean Loss 5.4422
2020-11-05 16:38:16,747 - root - INFO - Evaluate: Epoch 0910 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:38:16,753 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3506 | Iter Mean Loss 8.3506
2020-11-05 16:38:16,758 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0359 | Iter Mean Loss 4.6933
2020-11-05 16:38:16,763 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0507 | Iter Mean Loss 5.8124
2020-11-05 16:38:16,770 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5688 | Iter Mean Loss 6.0015
2020-11-05 16:38:16,774 - root - INFO - Training: Epoch 0911 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1806 | Iter Mean Loss 5.4373
2020-11-05 16:38:16,775 - root - INFO - Evaluate: Epoch 0911 | NDCG 1.0000 | MSE 0.1708
2020-11-05 16:38:16,782 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3436 | Iter Mean Loss 8.3436
2020-11-05 16:38:16,788 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0347 | Iter Mean Loss 4.6891
2020-11-05 16:38:16,793 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0419 | Iter Mean Loss 5.8067
2020-11-05 16:38:16,799 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5630 | Iter Mean Loss 5.9958
2020-11-05 16:38:16,805 - root - INFO - Training: Epoch 0912 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1796 | Iter Mean Loss 5.4325
2020-11-05 16:38:16,806 - root - INFO - Evaluate: Epoch 0912 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:38:16,811 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3365 | Iter Mean Loss 8.3365
2020-11-05 16:38:16,817 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0335 | Iter Mean Loss 4.6850
2020-11-05 16:38:16,823 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0331 | Iter Mean Loss 5.8010
2020-11-05 16:38:16,829 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5571 | Iter Mean Loss 5.9900
2020-11-05 16:38:16,834 - root - INFO - Training: Epoch 0913 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1785 | Iter Mean Loss 5.4277
2020-11-05 16:38:16,835 - root - INFO - Evaluate: Epoch 0913 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:38:16,841 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3295 | Iter Mean Loss 8.3295
2020-11-05 16:38:16,846 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0323 | Iter Mean Loss 4.6809
2020-11-05 16:38:16,851 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0243 | Iter Mean Loss 5.7953
2020-11-05 16:38:16,857 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5513 | Iter Mean Loss 5.9843
2020-11-05 16:38:16,861 - root - INFO - Training: Epoch 0914 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1775 | Iter Mean Loss 5.4230
2020-11-05 16:38:16,862 - root - INFO - Evaluate: Epoch 0914 | NDCG 1.0000 | MSE 0.1707
2020-11-05 16:38:16,868 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3224 | Iter Mean Loss 8.3224
2020-11-05 16:38:16,873 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0311 | Iter Mean Loss 4.6768
2020-11-05 16:38:16,879 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0155 | Iter Mean Loss 5.7897
2020-11-05 16:38:16,884 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5456 | Iter Mean Loss 5.9787
2020-11-05 16:38:16,889 - root - INFO - Training: Epoch 0915 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1764 | Iter Mean Loss 5.4182
2020-11-05 16:38:16,890 - root - INFO - Evaluate: Epoch 0915 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:38:16,895 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3155 | Iter Mean Loss 8.3155
2020-11-05 16:38:16,900 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0300 | Iter Mean Loss 4.6727
2020-11-05 16:38:16,906 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 8.0068 | Iter Mean Loss 5.7841
2020-11-05 16:38:16,911 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5398 | Iter Mean Loss 5.9730
2020-11-05 16:38:16,916 - root - INFO - Training: Epoch 0916 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1754 | Iter Mean Loss 5.4135
2020-11-05 16:38:16,917 - root - INFO - Evaluate: Epoch 0916 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:38:16,922 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3085 | Iter Mean Loss 8.3085
2020-11-05 16:38:16,928 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0288 | Iter Mean Loss 4.6687
2020-11-05 16:38:16,933 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9981 | Iter Mean Loss 5.7785
2020-11-05 16:38:16,939 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5341 | Iter Mean Loss 5.9674
2020-11-05 16:38:16,943 - root - INFO - Training: Epoch 0917 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1744 | Iter Mean Loss 5.4088
2020-11-05 16:38:16,944 - root - INFO - Evaluate: Epoch 0917 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:38:16,950 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.3015 | Iter Mean Loss 8.3015
2020-11-05 16:38:16,956 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0277 | Iter Mean Loss 4.6646
2020-11-05 16:38:16,961 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9894 | Iter Mean Loss 5.7729
2020-11-05 16:38:16,967 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5284 | Iter Mean Loss 5.9618
2020-11-05 16:38:16,972 - root - INFO - Training: Epoch 0918 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1734 | Iter Mean Loss 5.4041
2020-11-05 16:38:16,973 - root - INFO - Evaluate: Epoch 0918 | NDCG 1.0000 | MSE 0.1706
2020-11-05 16:38:16,979 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2946 | Iter Mean Loss 8.2946
2020-11-05 16:38:16,985 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0266 | Iter Mean Loss 4.6606
2020-11-05 16:38:16,991 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9807 | Iter Mean Loss 5.7673
2020-11-05 16:38:16,997 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5228 | Iter Mean Loss 5.9562
2020-11-05 16:38:17,002 - root - INFO - Training: Epoch 0919 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1724 | Iter Mean Loss 5.3994
2020-11-05 16:38:17,003 - root - INFO - Evaluate: Epoch 0919 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:38:17,009 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2877 | Iter Mean Loss 8.2877
2020-11-05 16:38:17,015 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0255 | Iter Mean Loss 4.6566
2020-11-05 16:38:17,021 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9720 | Iter Mean Loss 5.7617
2020-11-05 16:38:17,027 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5172 | Iter Mean Loss 5.9506
2020-11-05 16:38:17,032 - root - INFO - Training: Epoch 0920 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1715 | Iter Mean Loss 5.3948
2020-11-05 16:38:17,032 - root - INFO - Evaluate: Epoch 0920 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:38:17,039 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2808 | Iter Mean Loss 8.2808
2020-11-05 16:38:17,044 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0244 | Iter Mean Loss 4.6526
2020-11-05 16:38:17,050 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9634 | Iter Mean Loss 5.7562
2020-11-05 16:38:17,055 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5116 | Iter Mean Loss 5.9451
2020-11-05 16:38:17,060 - root - INFO - Training: Epoch 0921 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1705 | Iter Mean Loss 5.3901
2020-11-05 16:38:17,061 - root - INFO - Evaluate: Epoch 0921 | NDCG 1.0000 | MSE 0.1705
2020-11-05 16:38:17,066 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2740 | Iter Mean Loss 8.2740
2020-11-05 16:38:17,072 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0234 | Iter Mean Loss 4.6487
2020-11-05 16:38:17,077 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9548 | Iter Mean Loss 5.7507
2020-11-05 16:38:17,083 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5060 | Iter Mean Loss 5.9395
2020-11-05 16:38:17,087 - root - INFO - Training: Epoch 0922 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1695 | Iter Mean Loss 5.3855
2020-11-05 16:38:17,088 - root - INFO - Evaluate: Epoch 0922 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:38:17,094 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2671 | Iter Mean Loss 8.2671
2020-11-05 16:38:17,099 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0223 | Iter Mean Loss 4.6447
2020-11-05 16:38:17,104 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9462 | Iter Mean Loss 5.7452
2020-11-05 16:38:17,110 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.5005 | Iter Mean Loss 5.9340
2020-11-05 16:38:17,115 - root - INFO - Training: Epoch 0923 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1686 | Iter Mean Loss 5.3809
2020-11-05 16:38:17,116 - root - INFO - Evaluate: Epoch 0923 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:38:17,122 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2603 | Iter Mean Loss 8.2603
2020-11-05 16:38:17,127 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0212 | Iter Mean Loss 4.6408
2020-11-05 16:38:17,133 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9376 | Iter Mean Loss 5.7397
2020-11-05 16:38:17,138 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4950 | Iter Mean Loss 5.9285
2020-11-05 16:38:17,144 - root - INFO - Training: Epoch 0924 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1676 | Iter Mean Loss 5.3764
2020-11-05 16:38:17,144 - root - INFO - Evaluate: Epoch 0924 | NDCG 1.0000 | MSE 0.1704
2020-11-05 16:38:17,150 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2535 | Iter Mean Loss 8.2535
2020-11-05 16:38:17,157 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0202 | Iter Mean Loss 4.6369
2020-11-05 16:38:17,162 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9290 | Iter Mean Loss 5.7342
2020-11-05 16:38:17,168 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4896 | Iter Mean Loss 5.9231
2020-11-05 16:38:17,173 - root - INFO - Training: Epoch 0925 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1667 | Iter Mean Loss 5.3718
2020-11-05 16:38:17,174 - root - INFO - Evaluate: Epoch 0925 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:38:17,180 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2467 | Iter Mean Loss 8.2467
2020-11-05 16:38:17,186 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0192 | Iter Mean Loss 4.6330
2020-11-05 16:38:17,192 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9205 | Iter Mean Loss 5.7288
2020-11-05 16:38:17,197 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4842 | Iter Mean Loss 5.9176
2020-11-05 16:38:17,203 - root - INFO - Training: Epoch 0926 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1658 | Iter Mean Loss 5.3673
2020-11-05 16:38:17,204 - root - INFO - Evaluate: Epoch 0926 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:38:17,210 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2400 | Iter Mean Loss 8.2400
2020-11-05 16:38:17,215 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0182 | Iter Mean Loss 4.6291
2020-11-05 16:38:17,221 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9119 | Iter Mean Loss 5.7234
2020-11-05 16:38:17,227 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4788 | Iter Mean Loss 5.9122
2020-11-05 16:38:17,232 - root - INFO - Training: Epoch 0927 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1649 | Iter Mean Loss 5.3627
2020-11-05 16:38:17,233 - root - INFO - Evaluate: Epoch 0927 | NDCG 1.0000 | MSE 0.1703
2020-11-05 16:38:17,238 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2332 | Iter Mean Loss 8.2332
2020-11-05 16:38:17,245 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0171 | Iter Mean Loss 4.6252
2020-11-05 16:38:17,250 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.9034 | Iter Mean Loss 5.7179
2020-11-05 16:38:17,255 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4734 | Iter Mean Loss 5.9068
2020-11-05 16:38:17,260 - root - INFO - Training: Epoch 0928 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1640 | Iter Mean Loss 5.3582
2020-11-05 16:38:17,261 - root - INFO - Evaluate: Epoch 0928 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:38:17,267 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2265 | Iter Mean Loss 8.2265
2020-11-05 16:38:17,272 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0162 | Iter Mean Loss 4.6213
2020-11-05 16:38:17,277 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8949 | Iter Mean Loss 5.7125
2020-11-05 16:38:17,283 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4681 | Iter Mean Loss 5.9014
2020-11-05 16:38:17,287 - root - INFO - Training: Epoch 0929 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1631 | Iter Mean Loss 5.3538
2020-11-05 16:38:17,288 - root - INFO - Evaluate: Epoch 0929 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:38:17,294 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2198 | Iter Mean Loss 8.2198
2020-11-05 16:38:17,299 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0152 | Iter Mean Loss 4.6175
2020-11-05 16:38:17,304 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8865 | Iter Mean Loss 5.7072
2020-11-05 16:38:17,310 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4628 | Iter Mean Loss 5.8961
2020-11-05 16:38:17,315 - root - INFO - Training: Epoch 0930 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1622 | Iter Mean Loss 5.3493
2020-11-05 16:38:17,316 - root - INFO - Evaluate: Epoch 0930 | NDCG 1.0000 | MSE 0.1702
2020-11-05 16:38:17,323 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2132 | Iter Mean Loss 8.2132
2020-11-05 16:38:17,328 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0142 | Iter Mean Loss 4.6137
2020-11-05 16:38:17,334 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8780 | Iter Mean Loss 5.7018
2020-11-05 16:38:17,339 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4575 | Iter Mean Loss 5.8907
2020-11-05 16:38:17,344 - root - INFO - Training: Epoch 0931 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1613 | Iter Mean Loss 5.3448
2020-11-05 16:38:17,345 - root - INFO - Evaluate: Epoch 0931 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:38:17,350 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.2065 | Iter Mean Loss 8.2065
2020-11-05 16:38:17,356 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0132 | Iter Mean Loss 4.6099
2020-11-05 16:38:17,362 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8696 | Iter Mean Loss 5.6964
2020-11-05 16:38:17,367 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4523 | Iter Mean Loss 5.8854
2020-11-05 16:38:17,372 - root - INFO - Training: Epoch 0932 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1604 | Iter Mean Loss 5.3404
2020-11-05 16:38:17,374 - root - INFO - Evaluate: Epoch 0932 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:38:17,380 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1999 | Iter Mean Loss 8.1999
2020-11-05 16:38:17,385 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0123 | Iter Mean Loss 4.6061
2020-11-05 16:38:17,391 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8611 | Iter Mean Loss 5.6911
2020-11-05 16:38:17,397 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4471 | Iter Mean Loss 5.8801
2020-11-05 16:38:17,402 - root - INFO - Training: Epoch 0933 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1595 | Iter Mean Loss 5.3360
2020-11-05 16:38:17,403 - root - INFO - Evaluate: Epoch 0933 | NDCG 1.0000 | MSE 0.1701
2020-11-05 16:38:17,409 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1932 | Iter Mean Loss 8.1932
2020-11-05 16:38:17,415 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0113 | Iter Mean Loss 4.6023
2020-11-05 16:38:17,420 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8527 | Iter Mean Loss 5.6858
2020-11-05 16:38:17,427 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4420 | Iter Mean Loss 5.8748
2020-11-05 16:38:17,432 - root - INFO - Training: Epoch 0934 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1587 | Iter Mean Loss 5.3316
2020-11-05 16:38:17,433 - root - INFO - Evaluate: Epoch 0934 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:38:17,438 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1867 | Iter Mean Loss 8.1867
2020-11-05 16:38:17,444 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0104 | Iter Mean Loss 4.5985
2020-11-05 16:38:17,450 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8443 | Iter Mean Loss 5.6805
2020-11-05 16:38:17,455 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4369 | Iter Mean Loss 5.8696
2020-11-05 16:38:17,460 - root - INFO - Training: Epoch 0935 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1578 | Iter Mean Loss 5.3272
2020-11-05 16:38:17,461 - root - INFO - Evaluate: Epoch 0935 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:38:17,466 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1801 | Iter Mean Loss 8.1801
2020-11-05 16:38:17,472 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0095 | Iter Mean Loss 4.5948
2020-11-05 16:38:17,477 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8360 | Iter Mean Loss 5.6752
2020-11-05 16:38:17,482 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4318 | Iter Mean Loss 5.8643
2020-11-05 16:38:17,487 - root - INFO - Training: Epoch 0936 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1570 | Iter Mean Loss 5.3229
2020-11-05 16:38:17,488 - root - INFO - Evaluate: Epoch 0936 | NDCG 1.0000 | MSE 0.1700
2020-11-05 16:38:17,493 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1735 | Iter Mean Loss 8.1735
2020-11-05 16:38:17,499 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0086 | Iter Mean Loss 4.5910
2020-11-05 16:38:17,504 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8276 | Iter Mean Loss 5.6699
2020-11-05 16:38:17,509 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4267 | Iter Mean Loss 5.8591
2020-11-05 16:38:17,514 - root - INFO - Training: Epoch 0937 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1562 | Iter Mean Loss 5.3185
2020-11-05 16:38:17,515 - root - INFO - Evaluate: Epoch 0937 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:38:17,520 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1670 | Iter Mean Loss 8.1670
2020-11-05 16:38:17,526 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0077 | Iter Mean Loss 4.5873
2020-11-05 16:38:17,531 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8193 | Iter Mean Loss 5.6646
2020-11-05 16:38:17,536 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4217 | Iter Mean Loss 5.8539
2020-11-05 16:38:17,541 - root - INFO - Training: Epoch 0938 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1553 | Iter Mean Loss 5.3142
2020-11-05 16:38:17,542 - root - INFO - Evaluate: Epoch 0938 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:38:17,547 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1604 | Iter Mean Loss 8.1604
2020-11-05 16:38:17,553 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0068 | Iter Mean Loss 4.5836
2020-11-05 16:38:17,559 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8110 | Iter Mean Loss 5.6594
2020-11-05 16:38:17,564 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4167 | Iter Mean Loss 5.8487
2020-11-05 16:38:17,569 - root - INFO - Training: Epoch 0939 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1545 | Iter Mean Loss 5.3099
2020-11-05 16:38:17,570 - root - INFO - Evaluate: Epoch 0939 | NDCG 1.0000 | MSE 0.1699
2020-11-05 16:38:17,575 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1539 | Iter Mean Loss 8.1539
2020-11-05 16:38:17,582 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0059 | Iter Mean Loss 4.5799
2020-11-05 16:38:17,587 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.8027 | Iter Mean Loss 5.6542
2020-11-05 16:38:17,593 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4117 | Iter Mean Loss 5.8436
2020-11-05 16:38:17,598 - root - INFO - Training: Epoch 0940 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1537 | Iter Mean Loss 5.3056
2020-11-05 16:38:17,599 - root - INFO - Evaluate: Epoch 0940 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:38:17,605 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1475 | Iter Mean Loss 8.1475
2020-11-05 16:38:17,610 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0050 | Iter Mean Loss 4.5762
2020-11-05 16:38:17,617 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7944 | Iter Mean Loss 5.6490
2020-11-05 16:38:17,622 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4068 | Iter Mean Loss 5.8384
2020-11-05 16:38:17,627 - root - INFO - Training: Epoch 0941 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1529 | Iter Mean Loss 5.3013
2020-11-05 16:38:17,629 - root - INFO - Evaluate: Epoch 0941 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:38:17,635 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1410 | Iter Mean Loss 8.1410
2020-11-05 16:38:17,640 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0042 | Iter Mean Loss 4.5726
2020-11-05 16:38:17,646 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7861 | Iter Mean Loss 5.6438
2020-11-05 16:38:17,652 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.4019 | Iter Mean Loss 5.8333
2020-11-05 16:38:17,657 - root - INFO - Training: Epoch 0942 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1521 | Iter Mean Loss 5.2971
2020-11-05 16:38:17,658 - root - INFO - Evaluate: Epoch 0942 | NDCG 1.0000 | MSE 0.1698
2020-11-05 16:38:17,664 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1345 | Iter Mean Loss 8.1345
2020-11-05 16:38:17,669 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0033 | Iter Mean Loss 4.5689
2020-11-05 16:38:17,675 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7778 | Iter Mean Loss 5.6386
2020-11-05 16:38:17,680 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3971 | Iter Mean Loss 5.8282
2020-11-05 16:38:17,685 - root - INFO - Training: Epoch 0943 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1513 | Iter Mean Loss 5.2928
2020-11-05 16:38:17,686 - root - INFO - Evaluate: Epoch 0943 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:38:17,691 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1281 | Iter Mean Loss 8.1281
2020-11-05 16:38:17,696 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0025 | Iter Mean Loss 4.5653
2020-11-05 16:38:17,702 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7696 | Iter Mean Loss 5.6334
2020-11-05 16:38:17,707 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3923 | Iter Mean Loss 5.8231
2020-11-05 16:38:17,712 - root - INFO - Training: Epoch 0944 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1505 | Iter Mean Loss 5.2886
2020-11-05 16:38:17,712 - root - INFO - Evaluate: Epoch 0944 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:38:17,718 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1217 | Iter Mean Loss 8.1217
2020-11-05 16:38:17,723 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0016 | Iter Mean Loss 4.5616
2020-11-05 16:38:17,729 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7614 | Iter Mean Loss 5.6282
2020-11-05 16:38:17,734 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3875 | Iter Mean Loss 5.8180
2020-11-05 16:38:17,739 - root - INFO - Training: Epoch 0945 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1497 | Iter Mean Loss 5.2844
2020-11-05 16:38:17,740 - root - INFO - Evaluate: Epoch 0945 | NDCG 1.0000 | MSE 0.1697
2020-11-05 16:38:17,745 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1153 | Iter Mean Loss 8.1153
2020-11-05 16:38:17,750 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0008 | Iter Mean Loss 4.5580
2020-11-05 16:38:17,756 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7532 | Iter Mean Loss 5.6231
2020-11-05 16:38:17,762 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3827 | Iter Mean Loss 5.8130
2020-11-05 16:38:17,766 - root - INFO - Training: Epoch 0946 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1489 | Iter Mean Loss 5.2802
2020-11-05 16:38:17,767 - root - INFO - Evaluate: Epoch 0946 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:38:17,773 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1089 | Iter Mean Loss 8.1089
2020-11-05 16:38:17,779 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 1.0000 | Iter Mean Loss 4.5544
2020-11-05 16:38:17,785 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7450 | Iter Mean Loss 5.6179
2020-11-05 16:38:17,790 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3780 | Iter Mean Loss 5.8080
2020-11-05 16:38:17,795 - root - INFO - Training: Epoch 0947 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1482 | Iter Mean Loss 5.2760
2020-11-05 16:38:17,796 - root - INFO - Evaluate: Epoch 0947 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:38:17,802 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.1025 | Iter Mean Loss 8.1025
2020-11-05 16:38:17,808 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9992 | Iter Mean Loss 4.5508
2020-11-05 16:38:17,814 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7368 | Iter Mean Loss 5.6128
2020-11-05 16:38:17,819 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3733 | Iter Mean Loss 5.8029
2020-11-05 16:38:17,824 - root - INFO - Training: Epoch 0948 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1474 | Iter Mean Loss 5.2718
2020-11-05 16:38:17,825 - root - INFO - Evaluate: Epoch 0948 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:38:17,832 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0962 | Iter Mean Loss 8.0962
2020-11-05 16:38:17,837 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9983 | Iter Mean Loss 4.5473
2020-11-05 16:38:17,843 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7286 | Iter Mean Loss 5.6077
2020-11-05 16:38:17,848 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3686 | Iter Mean Loss 5.7979
2020-11-05 16:38:17,853 - root - INFO - Training: Epoch 0949 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1466 | Iter Mean Loss 5.2677
2020-11-05 16:38:17,854 - root - INFO - Evaluate: Epoch 0949 | NDCG 1.0000 | MSE 0.1696
2020-11-05 16:38:17,860 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0898 | Iter Mean Loss 8.0898
2020-11-05 16:38:17,865 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9976 | Iter Mean Loss 4.5437
2020-11-05 16:38:17,870 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7205 | Iter Mean Loss 5.6026
2020-11-05 16:38:17,876 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3640 | Iter Mean Loss 5.7930
2020-11-05 16:38:17,880 - root - INFO - Training: Epoch 0950 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1459 | Iter Mean Loss 5.2635
2020-11-05 16:38:17,881 - root - INFO - Evaluate: Epoch 0950 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:38:17,887 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0835 | Iter Mean Loss 8.0835
2020-11-05 16:38:17,892 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9968 | Iter Mean Loss 4.5401
2020-11-05 16:38:17,897 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7123 | Iter Mean Loss 5.5975
2020-11-05 16:38:17,903 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3594 | Iter Mean Loss 5.7880
2020-11-05 16:38:17,907 - root - INFO - Training: Epoch 0951 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1451 | Iter Mean Loss 5.2594
2020-11-05 16:38:17,908 - root - INFO - Evaluate: Epoch 0951 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:38:17,914 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0772 | Iter Mean Loss 8.0772
2020-11-05 16:38:17,919 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9960 | Iter Mean Loss 4.5366
2020-11-05 16:38:17,924 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.7042 | Iter Mean Loss 5.5925
2020-11-05 16:38:17,929 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3548 | Iter Mean Loss 5.7831
2020-11-05 16:38:17,934 - root - INFO - Training: Epoch 0952 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1444 | Iter Mean Loss 5.2553
2020-11-05 16:38:17,935 - root - INFO - Evaluate: Epoch 0952 | NDCG 1.0000 | MSE 0.1695
2020-11-05 16:38:17,940 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0709 | Iter Mean Loss 8.0709
2020-11-05 16:38:17,946 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9952 | Iter Mean Loss 4.5331
2020-11-05 16:38:17,951 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6961 | Iter Mean Loss 5.5874
2020-11-05 16:38:17,957 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3503 | Iter Mean Loss 5.7781
2020-11-05 16:38:17,961 - root - INFO - Training: Epoch 0953 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1436 | Iter Mean Loss 5.2512
2020-11-05 16:38:17,963 - root - INFO - Evaluate: Epoch 0953 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:38:17,969 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0646 | Iter Mean Loss 8.0646
2020-11-05 16:38:17,974 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9944 | Iter Mean Loss 4.5295
2020-11-05 16:38:17,980 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6880 | Iter Mean Loss 5.5824
2020-11-05 16:38:17,985 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3458 | Iter Mean Loss 5.7732
2020-11-05 16:38:17,991 - root - INFO - Training: Epoch 0954 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1429 | Iter Mean Loss 5.2472
2020-11-05 16:38:17,992 - root - INFO - Evaluate: Epoch 0954 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:38:17,997 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0584 | Iter Mean Loss 8.0584
2020-11-05 16:38:18,003 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9937 | Iter Mean Loss 4.5260
2020-11-05 16:38:18,009 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6800 | Iter Mean Loss 5.5773
2020-11-05 16:38:18,014 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3413 | Iter Mean Loss 5.7683
2020-11-05 16:38:18,020 - root - INFO - Training: Epoch 0955 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1422 | Iter Mean Loss 5.2431
2020-11-05 16:38:18,021 - root - INFO - Evaluate: Epoch 0955 | NDCG 1.0000 | MSE 0.1694
2020-11-05 16:38:18,027 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0521 | Iter Mean Loss 8.0521
2020-11-05 16:38:18,032 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9929 | Iter Mean Loss 4.5225
2020-11-05 16:38:18,038 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6719 | Iter Mean Loss 5.5723
2020-11-05 16:38:18,044 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3369 | Iter Mean Loss 5.7634
2020-11-05 16:38:18,049 - root - INFO - Training: Epoch 0956 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1414 | Iter Mean Loss 5.2390
2020-11-05 16:38:18,050 - root - INFO - Evaluate: Epoch 0956 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:38:18,056 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0459 | Iter Mean Loss 8.0459
2020-11-05 16:38:18,062 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9922 | Iter Mean Loss 4.5190
2020-11-05 16:38:18,067 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6638 | Iter Mean Loss 5.5673
2020-11-05 16:38:18,072 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3324 | Iter Mean Loss 5.7586
2020-11-05 16:38:18,077 - root - INFO - Training: Epoch 0957 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1407 | Iter Mean Loss 5.2350
2020-11-05 16:38:18,078 - root - INFO - Evaluate: Epoch 0957 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:38:18,083 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0397 | Iter Mean Loss 8.0397
2020-11-05 16:38:18,088 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9914 | Iter Mean Loss 4.5155
2020-11-05 16:38:18,094 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6558 | Iter Mean Loss 5.5623
2020-11-05 16:38:18,099 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3281 | Iter Mean Loss 5.7537
2020-11-05 16:38:18,104 - root - INFO - Training: Epoch 0958 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1400 | Iter Mean Loss 5.2310
2020-11-05 16:38:18,105 - root - INFO - Evaluate: Epoch 0958 | NDCG 1.0000 | MSE 0.1693
2020-11-05 16:38:18,110 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0334 | Iter Mean Loss 8.0334
2020-11-05 16:38:18,116 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9907 | Iter Mean Loss 4.5121
2020-11-05 16:38:18,122 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6478 | Iter Mean Loss 5.5573
2020-11-05 16:38:18,127 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3237 | Iter Mean Loss 5.7489
2020-11-05 16:38:18,132 - root - INFO - Training: Epoch 0959 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1393 | Iter Mean Loss 5.2270
2020-11-05 16:38:18,133 - root - INFO - Evaluate: Epoch 0959 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:38:18,138 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0273 | Iter Mean Loss 8.0273
2020-11-05 16:38:18,144 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9899 | Iter Mean Loss 4.5086
2020-11-05 16:38:18,149 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6398 | Iter Mean Loss 5.5523
2020-11-05 16:38:18,155 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3194 | Iter Mean Loss 5.7441
2020-11-05 16:38:18,160 - root - INFO - Training: Epoch 0960 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1386 | Iter Mean Loss 5.2230
2020-11-05 16:38:18,161 - root - INFO - Evaluate: Epoch 0960 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:38:18,167 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0211 | Iter Mean Loss 8.0211
2020-11-05 16:38:18,173 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9892 | Iter Mean Loss 4.5052
2020-11-05 16:38:18,178 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6318 | Iter Mean Loss 5.5474
2020-11-05 16:38:18,184 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3151 | Iter Mean Loss 5.7393
2020-11-05 16:38:18,189 - root - INFO - Training: Epoch 0961 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1379 | Iter Mean Loss 5.2190
2020-11-05 16:38:18,190 - root - INFO - Evaluate: Epoch 0961 | NDCG 1.0000 | MSE 0.1692
2020-11-05 16:38:18,196 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0149 | Iter Mean Loss 8.0149
2020-11-05 16:38:18,201 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9885 | Iter Mean Loss 4.5017
2020-11-05 16:38:18,207 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6238 | Iter Mean Loss 5.5424
2020-11-05 16:38:18,213 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3109 | Iter Mean Loss 5.7345
2020-11-05 16:38:18,218 - root - INFO - Training: Epoch 0962 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1372 | Iter Mean Loss 5.2151
2020-11-05 16:38:18,218 - root - INFO - Evaluate: Epoch 0962 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:38:18,225 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0088 | Iter Mean Loss 8.0088
2020-11-05 16:38:18,231 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9878 | Iter Mean Loss 4.4983
2020-11-05 16:38:18,236 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6158 | Iter Mean Loss 5.5375
2020-11-05 16:38:18,242 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3066 | Iter Mean Loss 5.7298
2020-11-05 16:38:18,247 - root - INFO - Training: Epoch 0963 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1365 | Iter Mean Loss 5.2111
2020-11-05 16:38:18,248 - root - INFO - Evaluate: Epoch 0963 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:38:18,253 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 8.0026 | Iter Mean Loss 8.0026
2020-11-05 16:38:18,259 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9871 | Iter Mean Loss 4.4949
2020-11-05 16:38:18,265 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.6079 | Iter Mean Loss 5.5325
2020-11-05 16:38:18,270 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.3024 | Iter Mean Loss 5.7250
2020-11-05 16:38:18,275 - root - INFO - Training: Epoch 0964 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1358 | Iter Mean Loss 5.2072
2020-11-05 16:38:18,276 - root - INFO - Evaluate: Epoch 0964 | NDCG 1.0000 | MSE 0.1691
2020-11-05 16:38:18,281 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9965 | Iter Mean Loss 7.9965
2020-11-05 16:38:18,287 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9864 | Iter Mean Loss 4.4914
2020-11-05 16:38:18,292 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5999 | Iter Mean Loss 5.5276
2020-11-05 16:38:18,297 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2982 | Iter Mean Loss 5.7203
2020-11-05 16:38:18,302 - root - INFO - Training: Epoch 0965 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1351 | Iter Mean Loss 5.2032
2020-11-05 16:38:18,303 - root - INFO - Evaluate: Epoch 0965 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:38:18,308 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9904 | Iter Mean Loss 7.9904
2020-11-05 16:38:18,314 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9857 | Iter Mean Loss 4.4880
2020-11-05 16:38:18,319 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5920 | Iter Mean Loss 5.5227
2020-11-05 16:38:18,326 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2941 | Iter Mean Loss 5.7155
2020-11-05 16:38:18,331 - root - INFO - Training: Epoch 0966 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1344 | Iter Mean Loss 5.1993
2020-11-05 16:38:18,332 - root - INFO - Evaluate: Epoch 0966 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:38:18,337 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9842 | Iter Mean Loss 7.9842
2020-11-05 16:38:18,342 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9850 | Iter Mean Loss 4.4846
2020-11-05 16:38:18,348 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5841 | Iter Mean Loss 5.5178
2020-11-05 16:38:18,353 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2899 | Iter Mean Loss 5.7108
2020-11-05 16:38:18,358 - root - INFO - Training: Epoch 0967 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1337 | Iter Mean Loss 5.1954
2020-11-05 16:38:18,359 - root - INFO - Evaluate: Epoch 0967 | NDCG 1.0000 | MSE 0.1690
2020-11-05 16:38:18,364 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9781 | Iter Mean Loss 7.9781
2020-11-05 16:38:18,370 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9843 | Iter Mean Loss 4.4812
2020-11-05 16:38:18,376 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5762 | Iter Mean Loss 5.5129
2020-11-05 16:38:18,381 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2858 | Iter Mean Loss 5.7061
2020-11-05 16:38:18,386 - root - INFO - Training: Epoch 0968 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1330 | Iter Mean Loss 5.1915
2020-11-05 16:38:18,387 - root - INFO - Evaluate: Epoch 0968 | NDCG 1.0000 | MSE 0.1689
2020-11-05 16:38:18,393 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9721 | Iter Mean Loss 7.9721
2020-11-05 16:38:18,399 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9836 | Iter Mean Loss 4.4778
2020-11-05 16:38:18,404 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5683 | Iter Mean Loss 5.5080
2020-11-05 16:38:18,412 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2817 | Iter Mean Loss 5.7014
2020-11-05 16:38:18,418 - root - INFO - Training: Epoch 0969 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1323 | Iter Mean Loss 5.1876
2020-11-05 16:38:18,419 - root - INFO - Evaluate: Epoch 0969 | NDCG 1.0000 | MSE 0.1689
2020-11-05 16:38:18,428 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9660 | Iter Mean Loss 7.9660
2020-11-05 16:38:18,435 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9829 | Iter Mean Loss 4.4745
2020-11-05 16:38:18,442 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5604 | Iter Mean Loss 5.5031
2020-11-05 16:38:18,450 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2777 | Iter Mean Loss 5.6968
2020-11-05 16:38:18,457 - root - INFO - Training: Epoch 0970 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1316 | Iter Mean Loss 5.1837
2020-11-05 16:38:18,458 - root - INFO - Evaluate: Epoch 0970 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:38:18,466 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9600 | Iter Mean Loss 7.9600
2020-11-05 16:38:18,473 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9823 | Iter Mean Loss 4.4711
2020-11-05 16:38:18,480 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5525 | Iter Mean Loss 5.4983
2020-11-05 16:38:18,487 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2737 | Iter Mean Loss 5.6921
2020-11-05 16:38:18,493 - root - INFO - Training: Epoch 0971 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1309 | Iter Mean Loss 5.1799
2020-11-05 16:38:18,494 - root - INFO - Evaluate: Epoch 0971 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:38:18,501 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9540 | Iter Mean Loss 7.9540
2020-11-05 16:38:18,509 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9816 | Iter Mean Loss 4.4678
2020-11-05 16:38:18,517 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5446 | Iter Mean Loss 5.4934
2020-11-05 16:38:18,525 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2698 | Iter Mean Loss 5.6875
2020-11-05 16:38:18,532 - root - INFO - Training: Epoch 0972 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1302 | Iter Mean Loss 5.1761
2020-11-05 16:38:18,533 - root - INFO - Evaluate: Epoch 0972 | NDCG 1.0000 | MSE 0.1688
2020-11-05 16:38:18,540 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9480 | Iter Mean Loss 7.9480
2020-11-05 16:38:18,547 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9810 | Iter Mean Loss 4.4645
2020-11-05 16:38:18,554 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5368 | Iter Mean Loss 5.4886
2020-11-05 16:38:18,561 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2659 | Iter Mean Loss 5.6829
2020-11-05 16:38:18,568 - root - INFO - Training: Epoch 0973 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1296 | Iter Mean Loss 5.1723
2020-11-05 16:38:18,570 - root - INFO - Evaluate: Epoch 0973 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:38:18,578 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9420 | Iter Mean Loss 7.9420
2020-11-05 16:38:18,586 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9803 | Iter Mean Loss 4.4612
2020-11-05 16:38:18,594 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5289 | Iter Mean Loss 5.4838
2020-11-05 16:38:18,600 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2621 | Iter Mean Loss 5.6783
2020-11-05 16:38:18,605 - root - INFO - Training: Epoch 0974 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1290 | Iter Mean Loss 5.1685
2020-11-05 16:38:18,607 - root - INFO - Evaluate: Epoch 0974 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:38:18,613 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9360 | Iter Mean Loss 7.9360
2020-11-05 16:38:18,619 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9797 | Iter Mean Loss 4.4579
2020-11-05 16:38:18,627 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5211 | Iter Mean Loss 5.4790
2020-11-05 16:38:18,633 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2582 | Iter Mean Loss 5.6738
2020-11-05 16:38:18,639 - root - INFO - Training: Epoch 0975 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1284 | Iter Mean Loss 5.1647
2020-11-05 16:38:18,640 - root - INFO - Evaluate: Epoch 0975 | NDCG 1.0000 | MSE 0.1687
2020-11-05 16:38:18,645 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9300 | Iter Mean Loss 7.9300
2020-11-05 16:38:18,651 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9791 | Iter Mean Loss 4.4546
2020-11-05 16:38:18,657 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5134 | Iter Mean Loss 5.4742
2020-11-05 16:38:18,663 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2543 | Iter Mean Loss 5.6692
2020-11-05 16:38:18,667 - root - INFO - Training: Epoch 0976 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1278 | Iter Mean Loss 5.1609
2020-11-05 16:38:18,668 - root - INFO - Evaluate: Epoch 0976 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:38:18,674 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9240 | Iter Mean Loss 7.9240
2020-11-05 16:38:18,679 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9785 | Iter Mean Loss 4.4513
2020-11-05 16:38:18,685 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.5057 | Iter Mean Loss 5.4694
2020-11-05 16:38:18,690 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2504 | Iter Mean Loss 5.6646
2020-11-05 16:38:18,695 - root - INFO - Training: Epoch 0977 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1273 | Iter Mean Loss 5.1572
2020-11-05 16:38:18,696 - root - INFO - Evaluate: Epoch 0977 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:38:18,701 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9179 | Iter Mean Loss 7.9179
2020-11-05 16:38:18,706 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9779 | Iter Mean Loss 4.4479
2020-11-05 16:38:18,712 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4980 | Iter Mean Loss 5.4646
2020-11-05 16:38:18,717 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2464 | Iter Mean Loss 5.6600
2020-11-05 16:38:18,722 - root - INFO - Training: Epoch 0978 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1267 | Iter Mean Loss 5.1534
2020-11-05 16:38:18,723 - root - INFO - Evaluate: Epoch 0978 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:38:18,728 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9118 | Iter Mean Loss 7.9118
2020-11-05 16:38:18,734 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9772 | Iter Mean Loss 4.4445
2020-11-05 16:38:18,739 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4904 | Iter Mean Loss 5.4598
2020-11-05 16:38:18,745 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2424 | Iter Mean Loss 5.6555
2020-11-05 16:38:18,749 - root - INFO - Training: Epoch 0979 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1261 | Iter Mean Loss 5.1496
2020-11-05 16:38:18,750 - root - INFO - Evaluate: Epoch 0979 | NDCG 1.0000 | MSE 0.1686
2020-11-05 16:38:18,756 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.9058 | Iter Mean Loss 7.9058
2020-11-05 16:38:18,761 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9764 | Iter Mean Loss 4.4411
2020-11-05 16:38:18,767 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4827 | Iter Mean Loss 5.4550
2020-11-05 16:38:18,772 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2385 | Iter Mean Loss 5.6509
2020-11-05 16:38:18,778 - root - INFO - Training: Epoch 0980 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1253 | Iter Mean Loss 5.1457
2020-11-05 16:38:18,779 - root - INFO - Evaluate: Epoch 0980 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:38:18,784 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8997 | Iter Mean Loss 7.8997
2020-11-05 16:38:18,790 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9757 | Iter Mean Loss 4.4377
2020-11-05 16:38:18,795 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4750 | Iter Mean Loss 5.4501
2020-11-05 16:38:18,801 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2346 | Iter Mean Loss 5.6463
2020-11-05 16:38:18,806 - root - INFO - Training: Epoch 0981 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1245 | Iter Mean Loss 5.1419
2020-11-05 16:38:18,807 - root - INFO - Evaluate: Epoch 0981 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:38:18,813 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8938 | Iter Mean Loss 7.8938
2020-11-05 16:38:18,819 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9750 | Iter Mean Loss 4.4344
2020-11-05 16:38:18,825 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4672 | Iter Mean Loss 5.4453
2020-11-05 16:38:18,831 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2309 | Iter Mean Loss 5.6417
2020-11-05 16:38:18,836 - root - INFO - Training: Epoch 0982 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1236 | Iter Mean Loss 5.1381
2020-11-05 16:38:18,837 - root - INFO - Evaluate: Epoch 0982 | NDCG 1.0000 | MSE 0.1685
2020-11-05 16:38:18,843 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8879 | Iter Mean Loss 7.8879
2020-11-05 16:38:18,849 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9743 | Iter Mean Loss 4.4311
2020-11-05 16:38:18,854 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4592 | Iter Mean Loss 5.4405
2020-11-05 16:38:18,860 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2273 | Iter Mean Loss 5.6372
2020-11-05 16:38:18,866 - root - INFO - Training: Epoch 0983 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1226 | Iter Mean Loss 5.1343
2020-11-05 16:38:18,867 - root - INFO - Evaluate: Epoch 0983 | NDCG 1.0000 | MSE 0.1684
2020-11-05 16:38:18,872 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8822 | Iter Mean Loss 7.8822
2020-11-05 16:38:18,878 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9737 | Iter Mean Loss 4.4279
2020-11-05 16:38:18,883 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4513 | Iter Mean Loss 5.4357
2020-11-05 16:38:18,889 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2239 | Iter Mean Loss 5.6328
2020-11-05 16:38:18,893 - root - INFO - Training: Epoch 0984 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1217 | Iter Mean Loss 5.1305
2020-11-05 16:38:18,894 - root - INFO - Evaluate: Epoch 0984 | NDCG 1.0000 | MSE 0.1684
2020-11-05 16:38:18,900 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8768 | Iter Mean Loss 7.8768
2020-11-05 16:38:18,905 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9731 | Iter Mean Loss 4.4250
2020-11-05 16:38:18,910 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4434 | Iter Mean Loss 5.4311
2020-11-05 16:38:18,916 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2208 | Iter Mean Loss 5.6285
2020-11-05 16:38:18,920 - root - INFO - Training: Epoch 0985 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1209 | Iter Mean Loss 5.1270
2020-11-05 16:38:18,921 - root - INFO - Evaluate: Epoch 0985 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:38:18,927 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8718 | Iter Mean Loss 7.8718
2020-11-05 16:38:18,932 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9727 | Iter Mean Loss 4.4223
2020-11-05 16:38:18,937 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4355 | Iter Mean Loss 5.4267
2020-11-05 16:38:18,943 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2181 | Iter Mean Loss 5.6245
2020-11-05 16:38:18,947 - root - INFO - Training: Epoch 0986 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1202 | Iter Mean Loss 5.1237
2020-11-05 16:38:18,948 - root - INFO - Evaluate: Epoch 0986 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:18,954 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8669 | Iter Mean Loss 7.8669
2020-11-05 16:38:18,959 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9726 | Iter Mean Loss 4.4197
2020-11-05 16:38:18,965 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4277 | Iter Mean Loss 5.4224
2020-11-05 16:38:18,970 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2157 | Iter Mean Loss 5.6207
2020-11-05 16:38:18,975 - root - INFO - Training: Epoch 0987 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1199 | Iter Mean Loss 5.1206
2020-11-05 16:38:18,976 - root - INFO - Evaluate: Epoch 0987 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:18,982 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8616 | Iter Mean Loss 7.8616
2020-11-05 16:38:18,987 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9728 | Iter Mean Loss 4.4172
2020-11-05 16:38:18,993 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4199 | Iter Mean Loss 5.4181
2020-11-05 16:38:18,998 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2131 | Iter Mean Loss 5.6168
2020-11-05 16:38:19,004 - root - INFO - Training: Epoch 0988 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1201 | Iter Mean Loss 5.1175
2020-11-05 16:38:19,005 - root - INFO - Evaluate: Epoch 0988 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:19,010 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8554 | Iter Mean Loss 7.8554
2020-11-05 16:38:19,016 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9731 | Iter Mean Loss 4.4143
2020-11-05 16:38:19,023 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4124 | Iter Mean Loss 5.4137
2020-11-05 16:38:19,028 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2096 | Iter Mean Loss 5.6127
2020-11-05 16:38:19,034 - root - INFO - Training: Epoch 0989 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1209 | Iter Mean Loss 5.1143
2020-11-05 16:38:19,035 - root - INFO - Evaluate: Epoch 0989 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:19,041 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8484 | Iter Mean Loss 7.8484
2020-11-05 16:38:19,046 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9733 | Iter Mean Loss 4.4108
2020-11-05 16:38:19,052 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4059 | Iter Mean Loss 5.4092
2020-11-05 16:38:19,058 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2049 | Iter Mean Loss 5.6081
2020-11-05 16:38:19,063 - root - INFO - Training: Epoch 0990 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1222 | Iter Mean Loss 5.1109
2020-11-05 16:38:19,064 - root - INFO - Evaluate: Epoch 0990 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:19,070 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8416 | Iter Mean Loss 7.8416
2020-11-05 16:38:19,076 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9725 | Iter Mean Loss 4.4071
2020-11-05 16:38:19,081 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4012 | Iter Mean Loss 5.4051
2020-11-05 16:38:19,087 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1992 | Iter Mean Loss 5.6036
2020-11-05 16:38:19,092 - root - INFO - Training: Epoch 0991 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1235 | Iter Mean Loss 5.1076
2020-11-05 16:38:19,092 - root - INFO - Evaluate: Epoch 0991 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:19,098 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8367 | Iter Mean Loss 7.8367
2020-11-05 16:38:19,103 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9708 | Iter Mean Loss 4.4038
2020-11-05 16:38:19,109 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3981 | Iter Mean Loss 5.4019
2020-11-05 16:38:19,115 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1944 | Iter Mean Loss 5.6000
2020-11-05 16:38:19,120 - root - INFO - Training: Epoch 0992 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1237 | Iter Mean Loss 5.1047
2020-11-05 16:38:19,121 - root - INFO - Evaluate: Epoch 0992 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:38:19,127 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8348 | Iter Mean Loss 7.8348
2020-11-05 16:38:19,132 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9688 | Iter Mean Loss 4.4018
2020-11-05 16:38:19,138 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3949 | Iter Mean Loss 5.3995
2020-11-05 16:38:19,143 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1928 | Iter Mean Loss 5.5978
2020-11-05 16:38:19,148 - root - INFO - Training: Epoch 0993 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1218 | Iter Mean Loss 5.1026
2020-11-05 16:38:19,149 - root - INFO - Evaluate: Epoch 0993 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:38:19,155 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8340 | Iter Mean Loss 7.8340
2020-11-05 16:38:19,161 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9684 | Iter Mean Loss 4.4012
2020-11-05 16:38:19,166 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3881 | Iter Mean Loss 5.3968
2020-11-05 16:38:19,172 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1950 | Iter Mean Loss 5.5964
2020-11-05 16:38:19,176 - root - INFO - Training: Epoch 0994 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1181 | Iter Mean Loss 5.1007
2020-11-05 16:38:19,177 - root - INFO - Evaluate: Epoch 0994 | NDCG 1.0000 | MSE 0.1683
2020-11-05 16:38:19,183 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8294 | Iter Mean Loss 7.8294
2020-11-05 16:38:19,189 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9713 | Iter Mean Loss 4.4004
2020-11-05 16:38:19,195 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3759 | Iter Mean Loss 5.3922
2020-11-05 16:38:19,200 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1973 | Iter Mean Loss 5.5935
2020-11-05 16:38:19,205 - root - INFO - Training: Epoch 0995 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1151 | Iter Mean Loss 5.0978
2020-11-05 16:38:19,207 - root - INFO - Evaluate: Epoch 0995 | NDCG 1.0000 | MSE 0.1682
2020-11-05 16:38:19,213 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8177 | Iter Mean Loss 7.8177
2020-11-05 16:38:19,218 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9766 | Iter Mean Loss 4.3971
2020-11-05 16:38:19,225 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3625 | Iter Mean Loss 5.3856
2020-11-05 16:38:19,230 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1935 | Iter Mean Loss 5.5876
2020-11-05 16:38:19,236 - root - INFO - Training: Epoch 0996 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1161 | Iter Mean Loss 5.0933
2020-11-05 16:38:19,237 - root - INFO - Evaluate: Epoch 0996 | NDCG 1.0000 | MSE 0.1680
2020-11-05 16:38:19,243 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8062 | Iter Mean Loss 7.8062
2020-11-05 16:38:19,249 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9791 | Iter Mean Loss 4.3927
2020-11-05 16:38:19,254 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3595 | Iter Mean Loss 5.3816
2020-11-05 16:38:19,261 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1830 | Iter Mean Loss 5.5820
2020-11-05 16:38:19,266 - root - INFO - Training: Epoch 0997 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1215 | Iter Mean Loss 5.0899
2020-11-05 16:38:19,267 - root - INFO - Evaluate: Epoch 0997 | NDCG 1.0000 | MSE 0.1677
2020-11-05 16:38:19,273 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8169 | Iter Mean Loss 7.8169
2020-11-05 16:38:19,279 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9740 | Iter Mean Loss 4.3954
2020-11-05 16:38:19,284 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.3771 | Iter Mean Loss 5.3893
2020-11-05 16:38:19,289 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.1819 | Iter Mean Loss 5.5875
2020-11-05 16:38:19,294 - root - INFO - Training: Epoch 0998 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1257 | Iter Mean Loss 5.0951
2020-11-05 16:38:19,295 - root - INFO - Evaluate: Epoch 0998 | NDCG 1.0000 | MSE 0.1675
2020-11-05 16:38:19,300 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0000 / 0004 | Time 0.0s | Iter Loss 7.8720 | Iter Mean Loss 7.8720
2020-11-05 16:38:19,306 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0001 / 0004 | Time 0.0s | Iter Loss 0.9659 | Iter Mean Loss 4.4190
2020-11-05 16:38:19,312 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0002 / 0004 | Time 0.0s | Iter Loss 7.4073 | Iter Mean Loss 5.4151
2020-11-05 16:38:19,317 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0003 / 0004 | Time 0.0s | Iter Loss 6.2211 | Iter Mean Loss 5.6166
2020-11-05 16:38:19,323 - root - INFO - Training: Epoch 0999 / 1000 | Iter 0004 / 0004 | Time 0.0s | Iter Loss 3.1193 | Iter Mean Loss 5.1171
2020-11-05 16:38:19,324 - root - INFO - Evaluate: Epoch 0999 | NDCG 1.0000 | MSE 0.1673
2020-11-05 16:38:19,324 - root - INFO - [!]-----------training done.
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,355 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,356 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal 700 normal>) = 1.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old South Arabian' (NotoSansOldSouthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lepcha' (NotoSansLepcha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-ThinItalic.ttf) italic normal 200 normal>) = 11.24
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols2' (NotoSansSymbols2-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,357 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaru.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPGothic' (ipagp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans NKo' (NotoSansNKo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Permic' (NotoSansOldPermic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mende Kikakui' (NotoSansMendeKikakui-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear A' (NotoSansLinearA-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,358 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (ipaexm.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Coptic' (NotoSansCoptic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAMincho' (ipam.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Yi' (NotoSansYi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Eastern' (NotoSansSyriacEastern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbola' (Symbola_hint.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cuneiform' (NotoSansCuneiform-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Math' (latinmodern-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Italic' (NotoSansOldItalic-Regular.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,359 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (ipaexg.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoDotum' (UnJamoDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buhid' (NotoSansBuhid-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ugaritic' (NotoSansUgaritic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Parthian' (NotoSansInscriptionalParthian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Glagolitic' (NotoSansGlagolitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,360 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hatran' (NotoSansHatran-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Rejang' (NotoSansRejang-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Regular.ttf) normal normal 400 condensed>) = 10.25
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Inscriptional Pahlavi' (NotoSansInscriptionalPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tamil' (NotoSansTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Heavy.ttf) normal normal 800 normal>) = 10.43
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-BlackItalic.ttf) italic normal 900 normal>) = 11.525
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Estrangela' (NotoSansSyriacEstrangela-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM Big5' (bkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thai' (NotoSansThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'KaiTi' (simkai.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,361 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Music' (NotoMusic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPen' (UnPen.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Hairline.ttf) normal normal 100 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Warang Citi' (NotoSansWarangCiti-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-Light.otf) normal normal 300 normal>) = 10.145
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop' (lmmonoprop10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bassa Vah' (NotoSansBassaVah-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAPMincho' (ipamp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum Math' (texgyrebonum-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,362 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gujarati' (NotoSerifGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnVada' (UnVada.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Vai' (NotoSansVai-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-BoldItalic.ttf) italic normal 700 condensed>) = 11.535
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella Math' (texgyrepagella-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-SemiboldItalic.ttf) italic normal 600 normal>) = 11.24
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Deseret' (NotoSansDeseret-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Le' (NotoSansTaiLe-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osmanya' (NotoSansOsmanya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,363 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Unslanted' (lmromanunsl10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-LightItalic.ttf) italic normal 300 normal>) = 11.145
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Georgian' (NotoSansGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Osage' (NotoSansOsage-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Phoenician' (NotoSansPhoenician-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagalog' (NotoSansTagalog-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Batak' (NotoSansBatak-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Miao' (NotoSansMiao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lao' (NotoSansLao-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khojki' (NotoSansKhojki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Samaritan' (NotoSansSamaritan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ahom' (NotoSerifAhom-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,364 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'WenQuanYi Micro Hei' (wqy-microhei.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sinhala' (NotoSansSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Black.ttf) normal normal 900 normal>) = 10.525
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgiBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Bold.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'webdings' (DeepinOpenSymbol4.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono10-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HairlineItalic.ttf) italic normal 100 normal>) = 11.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL Mingti2L Big5' (bsmi00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gothic' (NotoSansGothic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,365 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoBatang' (UnJamoBatang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Gurmukhi' (NotoSerifGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bengali' (NotoSansBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam Unjoined' (NotoSansAdlamUnjoined-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Elbasan' (NotoSansElbasan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Kufi Arabic' (NotoKufiArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimHei' (simhei.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoNovel' (UnJamoNovel.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lycian' (NotoSansLycian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sora Sompeng' (NotoSansSoraSompeng-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL KaitiM GB' (gkai00mp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hebrew' (NotoSansHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif CJK JP' (NotoSerifCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,366 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Symbols' (NotoSansSymbols-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lohit Devanagari' (Lohit-Devanagari.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre DejaVu Math' (texgyredejavu-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAGothic' (ipag.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Balinese' (NotoSerifBalinese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ethiopic' (NotoSansEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cypriot' (NotoSansCypriot-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-regular.otf) normal normal 600 condensed>) = 10.44
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Sinhala' (NotoSerifSinhala-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Hanunoo' (NotoSansHanunoo-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meetei Mayek' (NotoSansMeeteiMayek-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnJamoSora' (UnJamoSora.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typo' (TlwgTypo-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Brahmi' (NotoSansBrahmi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,367 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Shavian' (NotoSansShavian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono' (lmmono9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sharada' (NotoSansSharada-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Light.ttf) normal normal 300 normal>) = 10.145
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Palmyrene' (NotoSansPalmyrene-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Meroitic' (NotoSansMeroitic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (times.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mandaic' (NotoSansMandaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,368 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Buginese' (NotoSansBuginese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mro' (NotoSansMro-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Caps' (lmromancaps10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Bold.ttc) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Imperial Aramaic' (NotoSansImperialAramaic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Viet' (NotoSansTaiViet-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Psalter Pahlavi' (NotoSansPsalterPahlavi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac Western' (NotoSansSyriacWestern-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Takri' (NotoSansTakri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Grantha' (NotoSansGrantha-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 2' (DeepinOpenSymbol2.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola' (texgyreschola-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbi.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,369 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Malayalam' (NotoSerifMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Bold.ttf) normal normal 700 condensed>) = 10.535
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Gulim' (gulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Semibold.ttf) normal normal 600 normal>) = 10.24
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesi.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mahajani' (NotoSansMahajani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDinaru' (UnDinaruLight.ttf) normal normal 300 normal>) = 10.145
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Duployan' (NotoSansDuployan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,370 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pahawh Hmong' (NotoSansPahawhHmong-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Bengali' (NotoSerifBengali-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Georgian' (NotoSerifGeorgian-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Multani' (NotoSansMultani-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Caucasian Albanian' (NotoSansCaucasianAlbanian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-LightOblique.otf) oblique normal 300 normal>) = 11.145
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Carian' (NotoSansCarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Chakma' (NotoSansChakma-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal 700 normal>) = 0.33499999999999996
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans12-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,371 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Times New Roman' (timesbd.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Armenian' (NotoSansArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Manichaean' (NotoSansManichaean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'AR PL SungtiL GB' (gbsn00lp.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes Math' (texgyretermes-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont CSUR' (unifont_csur.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgi' (UnPilgi.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lisu' (NotoSansLisu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Waree' (Waree-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gujarati' (NotoSansGujarati-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,372 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Devanagari' (NotoSerifDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Schola Math' (texgyreschola-math.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syriac' (NotoSansSyriac-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman17-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'SimSun' (simsun.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Modi' (NotoSansModi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Marchen' (NotoSansMarchen-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Limbu' (NotoSansLimbu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Chorus' (texgyrechorus-mediumitalic.otf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk Book' (PadaukBook-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'OpenSymbol' (opens___.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,373 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnBatang' (UnBatangBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont' (unifont.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Runic' (NotoSansRunic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnTaza' (UnTaza.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans CJK JP' (NotoSansCJK-Regular.ttc) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Termes' (texgyretermes-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings 3' (DeepinOpenSymbol3.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Telugu' (NotoSerifTelugu-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-MediumItalic.ttf) italic normal 500 normal>) = 11.145
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Naskh Arabic' (NotoNaskhArabic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Arabic' (NotoSansArabic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bhaiksuki' (NotoSansBhaiksuki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tai Tham' (NotoSansTaiTham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Display' (NotoSansDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,374 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexMincho' (fonts-japanese-mincho.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kharoshthi' (NotoSansKharoshthi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-HeavyItalic.ttf) italic normal 800 normal>) = 11.43
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kannada' (NotoSansKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnShinmun' (UnShinmun.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ogham' (NotoSansOgham-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Nabataean' (NotoSansNabataean-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Headline' (hline.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-oblique.otf) oblique normal 600 normal>) = 11.24
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Thaana' (NotoSansThaana-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,375 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Myanmar' (NotoSansMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'YouYuan' (SIMYOU.TTF) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans New Tai Lue' (NotoSansNewTaiLue-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typewriter' (TlwgTypewriter-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Syloti Nagri' (NotoSansSylotiNagri-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kayah Li' (NotoSansKayahLi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tifinagh' (NotoSansTifinagh-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mono' (NotoSansMono-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Linear B' (NotoSansLinearB-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Nastaliq Urdu' (NotoNastaliqUrdu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Laksaman' (Laksaman-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,376 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Oriya' (NotoSansOriya-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGungseo' (UnGungseo.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Ol Chiki' (NotoSansOlChiki-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans PhagsPa' (NotoSansPhagsPa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tibetan' (NotoSansTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Pau Cin Hau' (NotoSansPauCinHau-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cherokee' (NotoSansCherokee-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Umpush' (Umpush-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman6-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans17-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldItalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnYetgul' (UnYetgul.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,377 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tibetan' (NotoSerifTibetan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPilgia' (UnPilgia.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Dotum' (dotum.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Lydian' (NotoSansLydian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Demi Cond' (lmsansdemicond10-oblique.otf) oblique normal 600 condensed>) = 11.44
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Caps' (lmmonocaps10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Sundanese' (NotoSansSundanese-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Anatolian Hieroglyphs' (NotoSansAnatolianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Khmer' (NotoSerifKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Bonum' (texgyrebonum-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Ethiopic' (NotoSerifEthiopic-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Hungarian' (NotoSansOldHungarian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Mongolian' (NotoSansMongolian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Telugu' (NotoSansTelugu-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Devanagari' (NotoSansDevanagari-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Kinnari' (Kinnari-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,378 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Malayalam' (NotoSansMalayalam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnGraphic' (UnGraphicBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Newa' (NotoSansNewa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-Italic.ttf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Hebrew' (NotoSerifHebrew-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans' (LiberationSans-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Gurmukhi' (NotoSansGurmukhi-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Adventor' (texgyreadventor-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Saurashtra' (NotoSansSaurashtra-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Sans Narrow' (LiberationSansNarrow-Italic.ttf) italic normal 400 condensed>) = 11.25
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-regular.otf) normal normal 400 condensed>) = 10.25
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Demi' (lmromandemi10-regular.otf) normal normal 600 normal>) = 10.24
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Symbol' (DeepinOpenSymbol6.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant9-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,379 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-Italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnDotum' (UnDotumBold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Math' (NotoSansMath-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Baekmuk Batang' (batang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Avestan' (NotoSansAvestan-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'UnPenheulim' (UnPenheulim.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Mono' (LiberationMono-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Display' (NotoSerifDisplay-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Mono' (TlwgMono.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light' (lmmonolt10-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman7-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old North Arabian' (NotoSansOldNorthArabian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Thai' (NotoSerifThai-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Adlam' (NotoSansAdlam-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,380 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tirhuta' (NotoSansTirhuta-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Tlwg Typist' (TlwgTypist-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman9-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Liberation Serif' (LiberationSerif-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Light Cond' (lmmonoltcond10-oblique.otf) oblique normal 400 condensed>) = 11.25
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Kannada' (NotoSerifKannada-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Dunhill' (lmromandunh10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Canadian Aboriginal' (NotoSansCanadianAboriginal-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Kaithi' (NotoSansKaithi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Egyptian Hieroglyphs' (NotoSansEgyptianHieroglyphs-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'LiSu' (SIMLI.TTF) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'IPAexGothic' (fonts-japanese-gothic.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans Quotation' (lmsansquot8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Mono' (NotoMono-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Medium.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans' (NotoSans-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,381 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Prop Light' (lmmonoproplt10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khudawadi' (NotoSansKhudawadi-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Lao' (NotoSerifLao-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman Slanted' (lmromanslant8-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Armenian' (NotoSerifArmenian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman12-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Sans' (lmsans10-boldoblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Myanmar' (NotoSerifMyanmar-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Cursor' (texgyrecursor-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Padauk' (Padauk-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Bamum' (NotoSansBamum-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'FangSong' (simfang.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Cham' (NotoSansCham-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Wingdings' (DeepinOpenSymbol.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil Slanted' (NotoSerifTamilSlanted-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman8-bold.otf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Sawasdee' (Sawasdee-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros Cn' (texgyreheroscn-italic.otf) italic normal 400 normal>) = 11.05
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Heros' (texgyreheros-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,382 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Tagbanwa' (NotoSansTagbanwa-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Roman' (lmroman5-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif Tamil' (NotoSerifTamil-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Norasi' (Norasi-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Khmer' (NotoSansKhmer-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Purisa' (Purisa-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'TeX Gyre Pagella' (texgyrepagella-bolditalic.otf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Lato' (Lato-Thin.ttf) normal normal 200 normal>) = 10.24
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Loma' (Loma-Oblique.otf) oblique normal 400 normal>) = 11.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'MT Extra' (DeepinOpenSymbol5.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Unifont Upper' (unifont_upper.ttf) normal normal 500 normal>) = 10.145
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Serif' (NotoSerif-BoldItalic.ttf) italic normal 700 normal>) = 11.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Javanese' (NotoSansJavanese-Bold.ttf) normal normal 700 normal>) = 10.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Garuda' (Garuda-BoldOblique.otf) oblique normal 700 normal>) = 11.335
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Turkic' (NotoSansOldTurkic-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Latin Modern Mono Slanted' (lmmonoslant10-regular.otf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: score(<Font 'Noto Sans Old Persian' (NotoSansOldPersian-Regular.ttf) normal normal 400 normal>) = 10.05
2020-11-05 16:38:19,383 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/penguincat/.conda/envs/PY38/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2020-11-05 16:38:19,536 - root - INFO - [!]-----------start testing.
2020-11-05 16:38:19,538 - root - INFO - Real Rank:
2020-11-05 16:38:19,538 - root - INFO - [0]
2020-11-05 16:38:19,538 - root - INFO - Pred Rank:
2020-11-05 16:38:19,538 - root - INFO - [ 0 74]
2020-11-05 16:38:19,538 - root - INFO - Test Result: NDCG 1.0000 | MSE 0.1673
